<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:48:50 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-7546] AtomicSortedColumns.addAllWithSizeDelta has a spin loop that allocates memory</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-7546</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;In order to preserve atomicity, this code attempts to read, clone/update, then CAS the state of the partition.&lt;/p&gt;

&lt;p&gt;Under heavy contention for updating a single partition this can cause some fairly staggering memory growth (the more cores on your machine the worst it gets).&lt;/p&gt;

&lt;p&gt;Whilst many usage patterns don&apos;t do highly concurrent updates to the same partition, hinting today, does, and in this case wild (order(s) of magnitude more than expected) memory allocation rates can be seen (especially when the updates being hinted are small updates to different partitions which can happen very fast on their own) - see &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-7545&quot; title=&quot;Hints for a down node are written to a single partition in system.hints on the coordinator leading to contention&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-7545&quot;&gt;&lt;del&gt;CASSANDRA-7545&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It would be best to eliminate/reduce/limit the spinning memory allocation whilst not slowing down the very common un-contended case.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12727216">CASSANDRA-7546</key>
            <summary>AtomicSortedColumns.addAllWithSizeDelta has a spin loop that allocates memory</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="graham.sanderson">graham sanderson</assignee>
                                    <reporter username="graham sanderson">graham sanderson</reporter>
                        <labels>
                    </labels>
                <created>Tue, 15 Jul 2014 00:56:51 +0000</created>
                <updated>Tue, 16 Apr 2019 09:31:40 +0000</updated>
                            <resolved>Mon, 13 Oct 2014 17:14:17 +0000</resolved>
                                        <fixVersion>2.1.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14061499" author="graham sanderson" created="Tue, 15 Jul 2014 01:04:14 +0000"  >&lt;p&gt;I have attached some code (for 2.0.x) and a pseudo test which compares new and old behavior with a simulation of writing hints to a single partition&lt;/p&gt;

&lt;p&gt;Here is the output on a fast 16 core box&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 1015ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 35 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 564MB vs 8MB; ratio to raw data size = 70.47914095238096
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 849ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 587MB vs 8MB; ratio to raw data size = 73.31190857142857
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 623ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 446MB vs 8MB; ratio to raw data size = 55.77215714285714
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 564ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 481MB vs 8MB; ratio to raw data size = 60.09202095238095
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 436ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 331MB vs 8MB; ratio to raw data size = 41.34096380952381
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 403ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 348MB vs 8MB; ratio to raw data size = 43.445909523809526
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 333ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 274MB vs 8MB; ratio to raw data size = 34.251781904761906
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 333ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 285MB vs 8MB; ratio to raw data size = 35.67829714285714
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 1730ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 99 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 30 collections
    [junit]   Approx allocation = 9842MB vs 8MB; ratio to raw data size = 1228.6645866666668
    [junit]   loopRatio (closest to 1 best) 17.41481 raw 100000/1741481 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1300ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 16 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 561MB vs 8MB; ratio to raw data size = 70.0673819047619
    [junit]   loopRatio (closest to 1 best) 1.00004 raw 258/260 counted 2/2 sync 99741/99742 up 1 down 1
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 215ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 763MB vs 8MB; ratio to raw data size = 95.24857523809524
    [junit]   loopRatio (closest to 1 best) 1.88702 raw 100000/188702 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 208ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 560MB vs 8MB; ratio to raw data size = 69.98852571428571
    [junit]   loopRatio (closest to 1 best) 1.32446 raw 50845/67230 counted 17730/18424 sync 40221/46792 up 10636 down 10329
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 180ms maxConcurrency = 97
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 328MB vs 8MB; ratio to raw data size = 41.03978761904762
    [junit]   loopRatio (closest to 1 best) 1.01959 raw 100000/101959 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 183ms maxConcurrency = 95
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 338MB vs 8MB; ratio to raw data size = 42.207682857142856
    [junit]   loopRatio (closest to 1 best) 1.01961 raw 98172/100033 counted 1852/1855 sync 41/73 up 1825 down 1818
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 180ms maxConcurrency = 96
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 274MB vs 8MB; ratio to raw data size = 34.29566095238095
    [junit]   loopRatio (closest to 1 best) 1.00353 raw 100000/100353 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 179ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 285MB vs 8MB; ratio to raw data size = 35.591366666666666
    [junit]   loopRatio (closest to 1 best) 1.00391 raw 99609/99998 counted 389/389 sync 2/4 up 388 down 387
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 960ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 29 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 564MB vs 26MB; ratio to raw data size = 21.439910434782607
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 976ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 27 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 560MB vs 26MB; ratio to raw data size = 21.31138724637681
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 673ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 453MB vs 26MB; ratio to raw data size = 17.215506086956523
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 589ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 455MB vs 26MB; ratio to raw data size = 17.307048695652174
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 238ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 342MB vs 26MB; ratio to raw data size = 12.99539536231884
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 271ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 341MB vs 26MB; ratio to raw data size = 12.96123536231884
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 233ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 284MB vs 26MB; ratio to raw data size = 10.803777971014492
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 230ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 284MB vs 26MB; ratio to raw data size = 10.822605507246378
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 1996ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 120 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 32 collections
    [junit]   Approx allocation = 10206MB vs 26MB; ratio to raw data size = 387.7607713043478
    [junit]   loopRatio (closest to 1 best) 17.4912 raw 100000/1749120 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1532ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 15 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 581MB vs 26MB; ratio to raw data size = 22.088286666666665
    [junit]   loopRatio (closest to 1 best) 1.00004 raw 341/343 counted 2/2 sync 99658/99659 up 1 down 1
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 220ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 770MB vs 26MB; ratio to raw data size = 29.258727826086957
    [junit]   loopRatio (closest to 1 best) 1.87623 raw 100000/187623 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 216ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 28 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 581MB vs 26MB; ratio to raw data size = 22.077911884057972
    [junit]   loopRatio (closest to 1 best) 1.33551 raw 52282/69043 counted 18308/19001 sync 38617/45507 up 10826 down 10513
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 182ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 361MB vs 26MB; ratio to raw data size = 13.740559130434782
    [junit]   loopRatio (closest to 1 best) 1.01958 raw 100000/101958 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 181ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 361MB vs 26MB; ratio to raw data size = 13.729368985507246
    [junit]   loopRatio (closest to 1 best) 1.01977 raw 98122/100015 counted 1886/1891 sync 39/71 up 1857 down 1853
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 181ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 303MB vs 26MB; ratio to raw data size = 11.513563768115942
    [junit]   loopRatio (closest to 1 best) 1.00402 raw 100000/100402 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 205ms maxConcurrency = 96
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 31 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 302MB vs 26MB; ratio to raw data size = 11.490827826086957
    [junit]   loopRatio (closest to 1 best) 1.00394 raw 99610/100003 counted 389/389 sync 1/2 up 392 down 388
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 832ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 591MB vs 99MB; ratio to raw data size = 5.942641762452107
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 391ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 631MB vs 99MB; ratio to raw data size = 6.343681455938698
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 896ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 27 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 519MB vs 99MB; ratio to raw data size = 5.215628199233716
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 321ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 20 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 552MB vs 99MB; ratio to raw data size = 5.5507787739463605
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 312ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 23 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 415MB vs 99MB; ratio to raw data size = 4.177359923371648
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 293ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 23 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 399MB vs 99MB; ratio to raw data size = 4.008342911877395
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 268ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 23 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 354MB vs 99MB; ratio to raw data size = 3.560803908045977
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 278ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 26 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 351MB vs 99MB; ratio to raw data size = 3.5285575478927202
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 2377ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 143 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 38 collections
    [junit]   Approx allocation = 12034MB vs 99MB; ratio to raw data size = 120.87394314176245
    [junit]   loopRatio (closest to 1 best) 18.17784 raw 100000/1817784 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1305ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 486MB vs 99MB; ratio to raw data size = 4.88428275862069
    [junit]   loopRatio (closest to 1 best) 1.00009 raw 173/180 counted 2/2 sync 99826/99827 up 1 down 1
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 225ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 34 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 853MB vs 99MB; ratio to raw data size = 8.572829348659004
    [junit]   loopRatio (closest to 1 best) 1.89489 raw 100000/189489 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 231ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 42 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 631MB vs 99MB; ratio to raw data size = 6.3455461302681995
    [junit]   loopRatio (closest to 1 best) 1.33684 raw 50954/67619 counted 18453/19130 sync 39872/46935 up 10747 down 10462
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 202ms maxConcurrency = 95
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 411MB vs 99MB; ratio to raw data size = 4.134808582375479
    [junit]   loopRatio (closest to 1 best) 1.01988 raw 100000/101988 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 219ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 35 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 408MB vs 99MB; ratio to raw data size = 4.102220459770115
    [junit]   loopRatio (closest to 1 best) 1.01909 raw 98202/100024 counted 1815/1819 sync 38/66 up 1789 down 1785
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 202ms maxConcurrency = 96
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 31 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 368MB vs 99MB; ratio to raw data size = 3.699853869731801
    [junit]   loopRatio (closest to 1 best) 1.0039 raw 100000/100390 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 206ms maxConcurrency = 95
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 360MB vs 99MB; ratio to raw data size = 3.6165709578544063
    [junit]   loopRatio (closest to 1 best) 1.0037 raw 99638/100005 counted 363/363 sync 1/2 up 367 down 362
    [junit] 
    [junit] 
    [junit] ==================================================
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14061511" author="graham sanderson" created="Tue, 15 Jul 2014 01:18:34 +0000"  >&lt;p&gt;The idea of the change here (which has three copies of the original loop which you could argue is uglier and more complicated, but in some ways is also clearer), is to try to minimize the number of loop attempts which allocate memory then fail the CAS&lt;/p&gt;

&lt;p&gt;The first &quot;raw&quot; loop is largely identical to the old code&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;there is a check of a new non volatile Holder variable, but does no new memory barrier requiring concurrency related checking&lt;/li&gt;
	&lt;li&gt;the CAS is not attempted (as part of the loop condition) if the loop continues due to early-out&lt;/li&gt;
	&lt;li&gt;I moved the deletioninfo stuff after the columns&lt;/li&gt;
	&lt;li&gt;I deferred the creation of the &lt;em&gt;modified&lt;/em&gt; Holder until the last minute (mostly because in the other loops the choice of the last constructor parameter is best made last, and I wanted to keep all versions of the loop with the same structure)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The Holder instance, now tracks a state machine via the new contentionCount AtomicInteger variable. The first loop is used when the  contentionCount is null. Any first loop thread, which fails the first CAS, and then succeeds on a future first loop iteration will install an AtomicInteger(0) value, directing future traffic to the second &quot;count&quot; loop&lt;/p&gt;

&lt;p&gt;The &quot;count&quot; loop incudes a try/finally and tracks the number of concurrent calls in the contentionCount variable... if the contention count is &amp;gt;1 traffic is directed to the third &quot;sync&quot; loop. This &quot;count&quot; loop will also on successful CAS deflate contentionCount to null, if it was at 1 (i.e. there wasn&apos;t any current contention) just before the CAS&lt;/p&gt;

&lt;p&gt;The &quot;sync&quot; loop is protected by a monitor (note choice here over j.u.c.Lock because of Lock owner tracking overhead). This loop can still lose CAS, if another AtomicSortedColumn function is doing the CAS, or another thread is CASing in either the &quot;raw&quot; or the &quot;count&quot; loop still.&lt;/p&gt;

&lt;p&gt;The overall design is intended to be effectively free in the uncontended case, and to adapt to effectively be completely synchronized in the highly contended case (for which the original code was potentially really bad), and to be as good or better than the original code in between.&lt;/p&gt;

&lt;p&gt;To that end, the debug code here today, tracks the ratio of loop iterations attempted (i.e. they do some work before either failing CAS or doing an early out because they know the CAS would fail)... Ideally this would be 1, and should remain close to that in all cases&lt;/p&gt;

&lt;p&gt;The code does not strive to be exact... at any point the contentionCount state could (we don&apos;t except optimistically at one point described above) safely be CASed with a new Holder back to null, it&apos;d just possibly mean more spins that might otherwise have been avoided&lt;/p&gt;</comment>
                            <comment id="14061514" author="graham sanderson" created="Tue, 15 Jul 2014 01:21:46 +0000"  >&lt;p&gt;The stateful learning behavior here seems like a good thing... always attempting one iteration of the first loop only to fail, before doing any form of synchronization would mean a ratio of at least 2 in the highly contended case.&lt;/p&gt;

&lt;p&gt;From looking at the numbers above, you&apos;ll see that this code:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;maintains a ratio of 1 as expected in the uncontended cases&lt;/li&gt;
	&lt;li&gt;maintains a ratio of 1 in the highly contended cases, vs on this box as high as 17 in the original code (which causes massive memory allocation). e.g.
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 1730ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 99 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 30 collections
    [junit]   Approx allocation = 9842MB vs 8MB; ratio to raw data size = 1228.6645866666668
    [junit]   loopRatio (closest to 1 best) 17.41481 raw 100000/1741481 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1300ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 16 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 561MB vs 8MB; ratio to raw data size = 70.0673819047619
    [junit]   loopRatio (closest to 1 best) 1.00004 raw 258/260 counted 2/2 sync 99741/99742 up 1 down 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;seems to max out at about 1.3 for cases in between, with that generally lower or very very close to the original code. e.g.
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 220ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 770MB vs 26MB; ratio to raw data size = 29.258727826086957
    [junit]   loopRatio (closest to 1 best) 1.87623 raw 100000/187623 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 216ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 28 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 581MB vs 26MB; ratio to raw data size = 22.077911884057972
    [junit]   loopRatio (closest to 1 best) 1.33551 raw 52282/69043 counted 18308/19001 sync 38617/45507 up 10826 down 10513
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14061518" author="graham sanderson" created="Tue, 15 Jul 2014 01:24:40 +0000"  >&lt;p&gt;Note that whilst the three loops are at first a bit ugly, I&apos;m not sure that mixing them together would make things clearer - mixing the sync loop in would also require &lt;tt&gt;sun.misc.Unsafe&lt;/tt&gt; to acquire and un-acquire the monitor&lt;/p&gt;</comment>
                            <comment id="14061521" author="graham sanderson" created="Tue, 15 Jul 2014 01:28:04 +0000"  >&lt;p&gt;Prior email thread comment from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&quot;I favour an asynchronous approach permitting only one modifying thread access to the&lt;br/&gt;
structure at a time, with each competing modification simply chaining their&lt;br/&gt;
to-be-merged state to a pending-list, which is repaired at read time if it&lt;br/&gt;
isn&apos;t merged before then. i.e. each writer attempts to take an exclusive&lt;br/&gt;
lock on modification, and if it succeeds it merges its own state and any&lt;br/&gt;
other pending state it sees on entry; if it fails to take the lock it&lt;br/&gt;
appends the unmerged modification to a simple list, and returns success.&lt;/p&gt;

&lt;p&gt;I plan to address this, but probably not until after 3.0, so if you&apos;re in a&lt;br/&gt;
rush it may be worth exploring one of these alternative approaches. The&lt;br/&gt;
simplest, least modifying solution, is probably to use unsafe to acquire&lt;br/&gt;
the object monitor if we fail the first cas (but continue to execute the&lt;br/&gt;
same codepath), so that we simply gate the amount of contention we can&lt;br/&gt;
experience without incurring any extra costs in the common case.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Note that I haven&apos;t tested my suggestion on 2.1 yet but I will do so&lt;/p&gt;</comment>
                            <comment id="14061757" author="graham sanderson" created="Tue, 15 Jul 2014 06:27:49 +0000"  >&lt;p&gt;I tried on 2.1 with pretty similar results (note I used a fresh HeapPool for each iteration, since it got stuck with the default Native stuff) - although the 2.1 BTree is much cheaper than the SnapTreeMap&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 562ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 238MB vs 8MB; ratio to raw data size = 29.79389619047619
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 480ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 239MB vs 8MB; ratio to raw data size = 29.95105523809524
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 376ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 219MB vs 8MB; ratio to raw data size = 27.37058095238095
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 349ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 219MB vs 8MB; ratio to raw data size = 27.40619619047619
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 268ms maxConcurrency = 1
    [junit]   Approx allocation = 198MB vs 8MB; ratio to raw data size = 24.820686666666667
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 277ms maxConcurrency = 1
    [junit]   Approx allocation = 198MB vs 8MB; ratio to raw data size = 24.82146285714286
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 258ms maxConcurrency = 1
    [junit]   Approx allocation = 190MB vs 8MB; ratio to raw data size = 23.770030476190477
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 234ms maxConcurrency = 1
    [junit]   Approx allocation = 190MB vs 8MB; ratio to raw data size = 23.769555238095236
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 3908ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 36 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 10 collections
    [junit]   Approx allocation = 2481MB vs 8MB; ratio to raw data size = 309.730900952381
    [junit]   loopRatio (closest to 1 best) 16.04825 raw 100000/1604825 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 697ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 241MB vs 8MB; ratio to raw data size = 30.141012380952382
    [junit]   loopRatio (closest to 1 best) 1.00004 raw 287/289 counted 2/2 sync 99712/99713 up 1 down 1
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 867ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 378MB vs 8MB; ratio to raw data size = 47.22428
    [junit]   loopRatio (closest to 1 best) 2.03201 raw 100000/203201 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 797ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 252MB vs 8MB; ratio to raw data size = 31.476938095238093
    [junit]   loopRatio (closest to 1 best) 1.17123 raw 22254/30788 counted 7823/8564 sync 74967/77771 up 5846 down 4781
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 545ms maxConcurrency = 96
    [junit]   Approx allocation = 218MB vs 8MB; ratio to raw data size = 27.227550476190476
    [junit]   loopRatio (closest to 1 best) 1.09275 raw 100000/109275 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 668ms maxConcurrency = 98
    [junit]   Approx allocation = 221MB vs 8MB; ratio to raw data size = 27.620777142857143
    [junit]   loopRatio (closest to 1 best) 1.10094 raw 90437/98693 counted 7860/8165 sync 2719/3236 up 7569 down 7598
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 524ms maxConcurrency = 96
    [junit]   Approx allocation = 205MB vs 8MB; ratio to raw data size = 25.604992380952382
    [junit]   loopRatio (closest to 1 best) 1.02883 raw 100000/102883 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 589ms maxConcurrency = 100
    [junit]   Approx allocation = 217MB vs 8MB; ratio to raw data size = 27.18481619047619
    [junit]   loopRatio (closest to 1 best) 1.02795 raw 97415/100035 counted 2544/2581 sync 136/179 up 2530 down 2537
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 685ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 283MB vs 26MB; ratio to raw data size = 10.771714782608695
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 561ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 294MB vs 26MB; ratio to raw data size = 11.198217391304349
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 495ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 273MB vs 26MB; ratio to raw data size = 10.378718550724638
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 539ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 272MB vs 26MB; ratio to raw data size = 10.367084347826086
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 197ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 249MB vs 26MB; ratio to raw data size = 9.492887826086957
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 216ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 251MB vs 26MB; ratio to raw data size = 9.570564347826087
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 229ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 243MB vs 26MB; ratio to raw data size = 9.23958231884058
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 517ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 243MB vs 26MB; ratio to raw data size = 9.258937101449275
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 3728ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 44 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 12 collections
    [junit]   Approx allocation = 3031MB vs 26MB; ratio to raw data size = 115.17077130434782
    [junit]   loopRatio (closest to 1 best) 15.84521 raw 100000/1584521 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 479ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 302MB vs 26MB; ratio to raw data size = 11.507159130434783
    [junit]   loopRatio (closest to 1 best) 1.00188 raw 252/431 counted 7/8 sync 99746/99749 up 4 down 4
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 967ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 18 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 486MB vs 26MB; ratio to raw data size = 18.50185797101449
    [junit]   loopRatio (closest to 1 best) 2.2405 raw 100000/224050 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 442ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 314MB vs 26MB; ratio to raw data size = 11.941331304347827
    [junit]   loopRatio (closest to 1 best) 1.22081 raw 26220/37315 counted 9907/10839 sync 70268/73927 up 7625 down 5981
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 615ms maxConcurrency = 93
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 269MB vs 26MB; ratio to raw data size = 10.220121739130434
    [junit]   loopRatio (closest to 1 best) 1.08956 raw 100000/108956 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 588ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 271MB vs 26MB; ratio to raw data size = 10.32604347826087
    [junit]   loopRatio (closest to 1 best) 1.0914 raw 91675/99366 counted 7106/7372 sync 1984/2402 up 6870 down 6917
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 549ms maxConcurrency = 95
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 254MB vs 26MB; ratio to raw data size = 9.666266956521739
    [junit]   loopRatio (closest to 1 best) 1.02505 raw 100000/102505 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 417ms maxConcurrency = 96
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 255MB vs 26MB; ratio to raw data size = 9.724647246376811
    [junit]   loopRatio (closest to 1 best) 1.02704 raw 97472/100005 counted 2453/2491 sync 166/208 up 2437 down 2448
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 721ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 504MB vs 99MB; ratio to raw data size = 5.068735019157088
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 636ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 29 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 499MB vs 99MB; ratio to raw data size = 5.012685900383142
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 516ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 498MB vs 99MB; ratio to raw data size = 5.003988429118774
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 469ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 489MB vs 99MB; ratio to raw data size = 4.91579908045977
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 419ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 476MB vs 99MB; ratio to raw data size = 4.782679157088123
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 433ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 26 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 470MB vs 99MB; ratio to raw data size = 4.723301609195402
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 423ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 27 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 465MB vs 99MB; ratio to raw data size = 4.679395708812261
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 445ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 35 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 463MB vs 99MB; ratio to raw data size = 4.654131800766284
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 3641ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 79 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 23 collections
    [junit]   Approx allocation = 6272MB vs 99MB; ratio to raw data size = 62.99940222222222
    [junit]   loopRatio (closest to 1 best) 16.84948 raw 100000/1684948 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 637ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 29 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 508MB vs 99MB; ratio to raw data size = 5.109580383141762
    [junit]   loopRatio (closest to 1 best) 1.0001 raw 805/812 counted 3/3 sync 99194/99195 up 1 down 1
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 1261ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 37 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 4 collections
    [junit]   Approx allocation = 963MB vs 99MB; ratio to raw data size = 9.67368030651341
    [junit]   loopRatio (closest to 1 best) 2.30544 raw 100000/230544 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 333ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 19 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 559MB vs 99MB; ratio to raw data size = 5.62049540229885
    [junit]   loopRatio (closest to 1 best) 1.20045 raw 23136/32826 counted 9312/10027 sync 73535/77192 up 6865 down 5302
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 383ms maxConcurrency = 92
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 476MB vs 99MB; ratio to raw data size = 4.786960459770115
    [junit]   loopRatio (closest to 1 best) 1.08511 raw 100000/108511 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 491ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 516MB vs 99MB; ratio to raw data size = 5.188691264367816
    [junit]   loopRatio (closest to 1 best) 1.09487 raw 90981/98803 counted 7476/7714 sync 2486/2970 up 7229 down 7199
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 490ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 21 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 474MB vs 99MB; ratio to raw data size = 4.76750030651341
    [junit]   loopRatio (closest to 1 best) 1.03162 raw 100000/103162 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 363ms maxConcurrency = 92
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 19 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 480MB vs 99MB; ratio to raw data size = 4.826345440613027
    [junit]   loopRatio (closest to 1 best) 1.02209 raw 97920/100011 counted 2041/2057 sync 113/141 up 2032 down 2027
    [junit] 
    [junit] 
    [junit] ==================================================
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14061758" author="graham sanderson" created="Tue, 15 Jul 2014 06:29:35 +0000"  >&lt;p&gt;Note that given we are fine with allocating an object (i.e. ColumnUpdater in 2.1) there is no reason we can&apos;t encapsulate the common  loop logic inside of an instance, to avoid code duplication - leaving the 3 loops may still be clearer if we decide to stick with this route&lt;/p&gt;</comment>
                            <comment id="14061762" author="graham sanderson" created="Tue, 15 Jul 2014 06:32:44 +0000"  >&lt;p&gt;Added version of suggestion1 for 2.1 branch&lt;/p&gt;</comment>
                            <comment id="14062849" author="graham sanderson" created="Tue, 15 Jul 2014 23:20:34 +0000"  >&lt;p&gt;A few random thoughts&lt;/p&gt;

&lt;p&gt;1) for 2.0.x I&apos;d be tempted (pending further review) to use something like my patch&lt;br/&gt;
We could make this a global cassandra.yaml option and/or make it a per CF setting, but I think we should just make sure it looks good and go with it&lt;br/&gt;
2) It might be nice to track approximate (updated without locks) max contention count according to the read of contentionCount, and expose it as a gauge for CF metrics - probably worth a separate issue&lt;br/&gt;
3) for 2.1.x We should probably avoid the the duplicate code by better encapsulating the behavior in an object (possibly an expanded variant of the ColumnUpdater), or move to the suggested 3.0.x approach&lt;/p&gt;

&lt;p&gt;w.r.t. to 3)&lt;br/&gt;
a) It might be nice to do the updates very lazily at least under load, so as to reduce overhead of per mutation partial tree copy-on-write by batching writes (you&apos;d have to roll back and start over in the case one atomic mutation failed mid-operation) - of course now I think about it, your suggestion does effectively do this under load.&lt;br/&gt;
b) Have you given much thought to racing reads...&lt;/p&gt;</comment>
                            <comment id="14068556" author="benedict" created="Mon, 21 Jul 2014 14:17:51 +0000"  >&lt;p&gt;Attaching my suggested alternative approach, which I think is a little simpler to reason about: if we loop for any reason we immediately take the monitor, if unsafe is available to us; if it isn&apos;t we don&apos;t benefit from the optimisation. We don&apos;t change the logic for updating, as taking the monitor doesn&apos;t guarantee we have exclusive access, it only guarantees we have exclusive access versus those writes that have themselves spun once, thereby capping the amount of competition.&lt;/p&gt;

&lt;p&gt;For 2.1 I suggest sticking with the same approach, then in 3.0/.1 we&apos;ll take a look at the more complex approach of making writes lazy under competition.&lt;/p&gt;</comment>
                            <comment id="14068769" author="graham sanderson" created="Mon, 21 Jul 2014 16:51:17 +0000"  >&lt;p&gt;Thanks for taking a look Benedict - I am in the process of actually measuring the effect via cassandra stress in the real world for code paths that might hit this (actual user initiated contended write on a partition, hint based contented write, and low cardinality secondary indexes).&lt;/p&gt;

&lt;p&gt;I had initially shied away from the non obviously paired monitor usage because a) it requires unsafe, and b) whilst monitorenter and monitorexit do exist as separate byte codes, I seem to recall that there is code in the monitor fast path (especially w.r.t. biased locking which we probably wan&apos;t to avoid) that expects them to be trivially paired... c) on the negative side this forces two loops under contention, but that is better than unbounded obviously.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure if b) is an actual issue (or what effect it has - does it matter if the monitor is always inflated for example).&lt;/p&gt;

&lt;p&gt;As for c) I guess I&apos;ll have to measure and see.&lt;/p&gt;

&lt;p&gt;Note I attached the current version of the 2.0 patch I was testing with, which pushed the loop body into a class similar to ColumnUpdater in 2.1 (which I would update accordingly)... &lt;/p&gt;

&lt;p&gt;again any attempt to further simplify the three separate loops, didn&apos;t really make things any simpler looking.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure my code (whilst not blazingly pretty) is insanely hard to reason about... clearly someone always makes progress (since any change in state is dependent on a CAS success or failure due to someone else succeeding); the un-contended and highly contended cases are pretty simple, and any flip-flopping between the &quot;count&quot; and &quot;raw&quot; state again always means we made progress AND must (still) be under low contention anyway.&lt;/p&gt;

&lt;p&gt;In any case, I&apos;ll defer to your judgement as to what you&apos;d like to see in the code base... as I say some actual numbers outside of a synthetic test should help&lt;/p&gt;</comment>
                            <comment id="14068803" author="benedict" created="Mon, 21 Jul 2014 17:09:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure my code (whilst not blazingly pretty) is insanely hard to reason about... &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not suggesting it is by any means abhorrent, only that we can achieve the desired goal with fewer changes, so unless there&apos;s a lot of evidence that the extra complexity is worth it, we should stick with the simpler approach (this also means less pollution of the instruction cache in a very hot part of the codebase, which is a good thing). I would suggest running a stress workload with a fixed number of threads, with increasing numbers of partitions (from 1 up to &amp;gt; number of threads) and see how the curve changes, if you want to benchmark this closely.&lt;/p&gt;

&lt;p&gt;As to (b): since we only ever acquire the lock when we are contending, it must always be inflated anyway, so this shouldn&apos;t be an issue.&lt;/p&gt;</comment>
                            <comment id="14069055" author="graham sanderson" created="Mon, 21 Jul 2014 19:04:13 +0000"  >&lt;p&gt;Yes, I agree with you; simpler is better - I didn&apos;t like the fact that it was hard to disentangle my code.&lt;/p&gt;

&lt;p&gt;So I have attached a different patch 7546.20_2.txt, which is about the same as yours except that it tracks a very minimal state heuristic to avoid the first unlocked loop when it thinks it is contended... this helps under load where it attempts about 1.11 loop per mutation in the heavily contented case vs 1.93 with 7546.20.txt (or about 18 without any patch at all).&lt;/p&gt;

&lt;p&gt;It turns out to be rather hard to measure this with cassandra-stress in isolation - basically the looping causes very high memory allocation rates which may or may not be a problem based on the current state of memory in the JVM (e.g. currently resident recent memtables) and other activity. Also, I may open a separate ticket to allow batch (thrift and maybe CQL) inserts in cassandra-stress to bump up the load a little more.&lt;/p&gt;

&lt;p&gt;That said, clearly this race is undesirable, and we have certainly observed its effects in practice in the hinting case (which is doubly unfortunate since you are already now doing more work per node than you thought, and you are going down a contention path you weren&apos;t expecting based on your own partitioning). Note when it goes wrong it goes really wrong!&lt;/p&gt;

&lt;p&gt;So, I think settling for a patch with minimal code or uncontended path impact, that caps us nicely is the right way to go&lt;/p&gt;</comment>
                            <comment id="14069059" author="graham sanderson" created="Mon, 21 Jul 2014 19:05:12 +0000"  >&lt;p&gt;FYI here are the same synthetic test results for 7546.20_2.txt&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 993ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 34 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 553MB vs 8MB; ratio to raw data size = 69.13799428571429
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 761ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 34 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 579MB vs 8MB; ratio to raw data size = 72.31675047619048
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 780ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 436MB vs 8MB; ratio to raw data size = 54.48992095238095
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 671ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 477MB vs 8MB; ratio to raw data size = 59.545997142857146
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 452ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 321MB vs 8MB; ratio to raw data size = 40.14510761904762
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 460ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 341MB vs 8MB; ratio to raw data size = 42.63770857142857
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 462ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 264MB vs 8MB; ratio to raw data size = 32.99879142857143
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 543ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 272MB vs 8MB; ratio to raw data size = 34.047360952380956
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 2318ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 119 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 32 collections
    [junit]   Approx allocation = 10547MB vs 8MB; ratio to raw data size = 1316.62704
    [junit]   loopRatio (closest to 1 best) 18.35448 raw 100000/1835448 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1315ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 629MB vs 8MB; ratio to raw data size = 78.62949142857143
    [junit]   loopRatio (closest to 1 best) 1.11563 raw 13653/13653 counted 0/0 sync 88223/97910 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 215ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 23 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 776MB vs 8MB; ratio to raw data size = 96.92138285714286
    [junit]   loopRatio (closest to 1 best) 1.95927 raw 100000/195927 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 201ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 530MB vs 8MB; ratio to raw data size = 66.21505238095239
    [junit]   loopRatio (closest to 1 best) 1.26719 raw 72820/72820 counted 0/0 sync 49837/53899 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 187ms maxConcurrency = 96
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 15 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 319MB vs 8MB; ratio to raw data size = 39.93250857142857
    [junit]   loopRatio (closest to 1 best) 1.01989 raw 100000/101989 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 188ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 327MB vs 8MB; ratio to raw data size = 40.83917619047619
    [junit]   loopRatio (closest to 1 best) 1.01869 raw 99963/99963 counted 0/0 sync 1877/1906 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 169ms maxConcurrency = 98
    [junit]   Approx allocation = 274MB vs 8MB; ratio to raw data size = 34.27162761904762
    [junit]   loopRatio (closest to 1 best) 1.00376 raw 100000/100376 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 180ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 278MB vs 8MB; ratio to raw data size = 34.80582571428572
    [junit]   loopRatio (closest to 1 best) 1.00348 raw 99999/99999 counted 0/0 sync 349/349 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 735ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 26 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 553MB vs 26MB; ratio to raw data size = 21.025497101449275
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 384ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 556MB vs 26MB; ratio to raw data size = 21.123911594202898
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 329ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 448MB vs 26MB; ratio to raw data size = 17.03236608695652
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 324ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 449MB vs 26MB; ratio to raw data size = 17.06260608695652
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 692ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 339MB vs 26MB; ratio to raw data size = 12.898537971014493
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 681ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 338MB vs 26MB; ratio to raw data size = 12.876152753623188
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 484ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 282MB vs 26MB; ratio to raw data size = 10.73973768115942
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 463ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 282MB vs 26MB; ratio to raw data size = 10.74182811594203
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 2231ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 121 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 33 collections
    [junit]   Approx allocation = 10752MB vs 26MB; ratio to raw data size = 408.504135942029
    [junit]   loopRatio (closest to 1 best) 18.49143 raw 100000/1849143 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1330ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 587MB vs 26MB; ratio to raw data size = 22.319155362318842
    [junit]   loopRatio (closest to 1 best) 1.12889 raw 16479/16479 counted 0/0 sync 85804/96410 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 227ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 752MB vs 26MB; ratio to raw data size = 28.593344057971013
    [junit]   loopRatio (closest to 1 best) 1.82137 raw 100000/182137 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 204ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 552MB vs 26MB; ratio to raw data size = 21.00069768115942
    [junit]   loopRatio (closest to 1 best) 1.26846 raw 72715/72715 counted 0/0 sync 49948/54131 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 180ms maxConcurrency = 94
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 351MB vs 26MB; ratio to raw data size = 13.347453333333334
    [junit]   loopRatio (closest to 1 best) 1.01903 raw 100000/101903 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 178ms maxConcurrency = 97
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 350MB vs 26MB; ratio to raw data size = 13.320123768115941
    [junit]   loopRatio (closest to 1 best) 1.0193 raw 99954/99954 counted 0/0 sync 1957/1976 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 179ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 292MB vs 26MB; ratio to raw data size = 11.113111884057972
    [junit]   loopRatio (closest to 1 best) 1.00393 raw 100000/100393 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 178ms maxConcurrency = 93
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 293MB vs 26MB; ratio to raw data size = 11.15906231884058
    [junit]   loopRatio (closest to 1 best) 1.00396 raw 99997/99997 counted 0/0 sync 398/399 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 997ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 586MB vs 99MB; ratio to raw data size = 5.885971954022988
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 836ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 42 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 623MB vs 99MB; ratio to raw data size = 6.264844827586207
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 600ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 28 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 508MB vs 99MB; ratio to raw data size = 5.104469731800767
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 572ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 26 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 513MB vs 99MB; ratio to raw data size = 5.159989042145594
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 413ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 440MB vs 99MB; ratio to raw data size = 4.425642222222222
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 368ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 27 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 393MB vs 99MB; ratio to raw data size = 3.948129195402299
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 296ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 27 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 343MB vs 99MB; ratio to raw data size = 3.4517041379310345
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 550ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 35 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 343MB vs 99MB; ratio to raw data size = 3.4461845977011496
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 2343ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 143 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 38 collections
    [junit]   Approx allocation = 12065MB vs 99MB; ratio to raw data size = 121.18560452107279
    [junit]   loopRatio (closest to 1 best) 18.22144 raw 100000/1822144 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1238ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 31 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 569MB vs 99MB; ratio to raw data size = 5.7199810727969345
    [junit]   loopRatio (closest to 1 best) 1.11326 raw 13522/13522 counted 0/0 sync 88452/97804 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 235ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 35 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 792MB vs 99MB; ratio to raw data size = 7.96215540229885
    [junit]   loopRatio (closest to 1 best) 1.79828 raw 100000/179828 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 228ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 618MB vs 99MB; ratio to raw data size = 6.211963754789272
    [junit]   loopRatio (closest to 1 best) 1.26855 raw 75427/75427 counted 0/0 sync 47424/51428 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 189ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 421MB vs 99MB; ratio to raw data size = 4.237997701149426
    [junit]   loopRatio (closest to 1 best) 1.01838 raw 100000/101838 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 199ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 405MB vs 99MB; ratio to raw data size = 4.073938620689655
    [junit]   loopRatio (closest to 1 best) 1.01976 raw 99960/99960 counted 0/0 sync 2000/2016 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 195ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 356MB vs 99MB; ratio to raw data size = 3.577380153256705
    [junit]   loopRatio (closest to 1 best) 1.00401 raw 100000/100401 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 197ms maxConcurrency = 96
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 31 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 352MB vs 99MB; ratio to raw data size = 3.538006283524904
    [junit]   loopRatio (closest to 1 best) 1.00377 raw 99999/99999 counted 0/0 sync 376/378 up 0 down 0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14069065" author="benedict" created="Mon, 21 Jul 2014 19:08:52 +0000"  >&lt;p&gt;I&apos;ll take a look at your patch shortly, but in the meantime it&apos;s worth pointing out cassandra-stress does now support fairly complex CQL inserts including various sizes of batch updates, with fine grained control over how large a partition to generate, and what percentage of that total partition to update at any point. Take a look at the sample stress profiles under the tools hierarchy on latest 2.1&lt;/p&gt;</comment>
                            <comment id="14069173" author="graham sanderson" created="Mon, 21 Jul 2014 19:54:17 +0000"  >&lt;p&gt;Excellent - I will take a look in the 2.1 branch - I was wondering if there were some sample profiles.&lt;/p&gt;

&lt;p&gt;The main problem we have in 2.0.x is that if we are under relatively heavy sustained write load, so we are allocating memtable slabs along with all the small short lived objects in the commit log and write path... you add to that hinting which means more memtable slabs, and now because of single partition for hints, much larger snap trees (whose somewhat contentious lazy-copy-on-write may or may not make things worse, I don&apos;t know)... under that allocation rate we spill huge numbers of small (possibly snap tree nodes) objects into the tenured gen along with the slabs, which tends to lead to promotion failure and need for compaction.&lt;/p&gt;

&lt;p&gt;I&apos;ll have to play around, but I don&apos;t think it is easy to capture the effect of excessive (intended to be) temporary object allocation in a stress test as opposed to excessive CPU because the GC can cope really well until it doesn&apos;t.&lt;/p&gt;

&lt;p&gt;Note my belief is your new tree in 2.1 probably mitigates the problem quite a bit (no contention in the tree, wider nodes, less rebalancing etc), though I suggest we still fix the CAS loop allocation there too.&lt;/p&gt;</comment>
                            <comment id="14069396" author="benedict" created="Mon, 21 Jul 2014 22:04:42 +0000"  >&lt;p&gt;My concern with the approach you&apos;ve outlined is that we&apos;re barely a hair&apos;s breadth from a lock: as soon as we hit &lt;em&gt;any&lt;/em&gt; contention, we inflate to locking behaviour. This is good for large partitions, and most likely bad for small ones, and more to the point seems barely worth the complexity of not just making it a lock in the first place. On further consideration, I think I would perhaps prefer to run this lock-inflation behaviour based on the size of the aborted changes, so if the amount of work we&apos;ve wasted exceeds some threshold we decide it&apos;s high time all threads were stopped to let us finish. We could in this scenario flip a switch that requires all modifications to acquire the monitor once we hit this threshold once; I would be fine with this behaviour, and it would be simple. &lt;/p&gt;

&lt;p&gt;I do wonder how much of a problem this is in 2.1, though. I wonder if the largest problem with these racy modifications isn&apos;t actually the massive amounts of memtable arena allocations they incur in 2.0 with all their transformation.apply() calls (which reallocate the mutation on the arena), which is most likely what causes the promotion failures, as they cannot be collected. I wonder if we shouldn&apos;t simply backport the logic to only allocate these once, or at most twice (the first time we race). It seems much more likely to me that this is where the pain is being felt.&lt;/p&gt;</comment>
                            <comment id="14069504" author="graham sanderson" created="Mon, 21 Jul 2014 23:26:31 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I do wonder how much of a problem this is in 2.1, though. I wonder if the largest problem with these racy modifications isn&apos;t actually the massive amounts of memtable arena allocations they incur in 2.0 with all their transformation.apply() calls (which reallocate the mutation on the arena), which is most likely what causes the promotion failures, as they cannot be collected. I wonder if we shouldn&apos;t simply backport the logic to only allocate these once, or at most twice (the first time we race). It seems much more likely to me that this is where the pain is being felt.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m not sure which changes you are talking about back-porting and whether the &quot;at most twice&quot; refers to looping once then locking, and what is reasonable to modify in 2.0.x now. Certainly avoiding any repeated cloning of the cells is good, however I&apos;m still pretty sure based on PrintFLSStatistics that the slabs themselves are not the biggest problem (I suspect SnapTreeMap nodes, combined with high rebalancing cost of huge trees in the hint case since the keys are almost entirely sorted).&lt;/p&gt;

&lt;p&gt;Are you suggesting a one way switch per Atomic*Columns instance that flips after a number waster &quot;operations&quot;? That sounds reasonable... I&apos;d expect that a partition for a table is either likely to have high contention or not based on the schema design/use case. I have no idea how long these instances hang around in practice (presumably not insanely long) at least if they are being actively used since I assume they get flushed eventually in that case, and if they aren&apos;t it doesn&apos;t really matter anyway&lt;/p&gt;</comment>
                            <comment id="14069666" author="graham sanderson" created="Tue, 22 Jul 2014 01:29:43 +0000"  >&lt;p&gt;Alternatively if you are saying, let each thread keep working while they still believe they can win, or while they have something to do that can be reused if they lose, then maybe give them one last shot to try again if they lose and haven&apos;t done anything reusable, then make them block... I&apos;m okay with that. (of course on 2.0.x. today, that pretty much boils down to your patch!)&lt;/p&gt;</comment>
                            <comment id="14069896" author="benedict" created="Tue, 22 Jul 2014 06:29:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;Alternatively if you are saying, let each thread keep working while they still believe they can win, &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This was my original rationale for the patch I posted, however now I am much more in favour of &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;a one way switch per Atomic*Columns instance that flips after a number waster &quot;operations&quot;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;However whether it is one-way or not is somewhat unimportant for me. This flip would only last the lifetime of a memtable, which is not super lengthy (under heavily load probably only a few minutes), and would not have dramatically negative consequences if it got it slightly wrong&lt;/p&gt;

&lt;p&gt;However^2 I&apos;m still having a hard time believing rebalancing costs in snap tree can be that high, and further if that really is the problem it should not be an issue in 2.1, as the b-tree rebalances with O(lg(N)) allocations. I&apos;d be a little surprised if the snap tree didn&apos;t do the same, as if there were more than O(lg(N)) allocations, the algorithmic complexity would be &amp;gt; O(lg(N)) also. It&apos;s possible somehow that it manages to inter-refererence with on-going copies, so that we get a highly complex graph that retains exponentially more garbage the more competing updates there are, but again I would be very surprised if this were the case. However outside of either of these I would expect the garbage generated to all be immediately collectible, so it would have to be the sheer volume alone that overwhelmed the GC, which is certainly possible but this would entail a &lt;em&gt;lot&lt;/em&gt; of hinting, and I&apos;d be surprised if a node could be receiving a large enough quantity. On the other hand the arena allocations in 2.0 are definitely incapable of being collected and could be allocated almost as rapidly.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure which changes you are talking about back-porting and whether the &quot;at most twice&quot; refers to looping once then locking&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In this instance I&apos;m referring to copying the source ColumnFamily locally in the variable once after failing the cas, so that we do not keep allocating arena space. Alternatively, we could just do it upfront in the method, as the only extra cost is an array allocation proportional in size to the input data, which is fairly cheap.&lt;/p&gt;

&lt;p&gt;All of this said, I think the behaviour of locking after wasting an excessive number of cycles is still a good one, so I&apos;m comfortable introducing it either way, and it would certainly help with all of the above causes.&lt;/p&gt;</comment>
                            <comment id="14069938" author="graham sanderson" created="Tue, 22 Jul 2014 07:37:23 +0000"  >&lt;blockquote&gt;
&lt;p&gt;However whether it is one-way or not is somewhat unimportant for me. This flip would only last the lifetime of a memtable, which is not super lengthy (under heavily load probably only a few minutes), and would not have dramatically negative consequences if it got it slightly wrong&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Cool, that&apos;s what I was asking/thinking.&lt;/p&gt;

&lt;p&gt;As for the tree size/rebalancing, I have no particular proof... when things go wrong we are hinting massively, and so maybe there are hundreds of hint mutation threads each with their own in progress rebalance, pinning a lot of nodes across young GC. That said, the memory allocation rate is truly spectacular, even given the excessive hinting, so I have to suspect the spinning (and as you say probably some of the in arena allocation it does too) - though that would also be surprising since these are hint updates which are a single cell update&lt;/p&gt;

&lt;p&gt;Anyway... we can track cost in the Holder I guess to avoid any atomic operations, and maybe factor in the tree size there too.&lt;/p&gt;

&lt;p&gt;Note as an aside, we are partly to blame for this issue (best practices to be learned, and ways we can mitigate) but the result is surprising enough (because things go bad at random, and usually when we are inserting 100s of times less data than we can easily handle) that others might easily get bitten. I would describe everything that I think is going on in the snowballing of problems, but it is a bit of a comedy of errors.&lt;/p&gt;</comment>
                            <comment id="14069953" author="graham sanderson" created="Tue, 22 Jul 2014 07:52:44 +0000"  >&lt;p&gt;Note the one summary is that lots of small inserts seems to cause a lot more problems than lots of large inserts, presumably because they can happen faster and anything bounded by their intrinsic size rather than their actual overhead can fit more of them&lt;/p&gt;</comment>
                            <comment id="14069981" author="graham sanderson" created="Tue, 22 Jul 2014 08:13:08 +0000"  >&lt;p&gt;My last piece of speculation... these single partition hint trees are probably getting thousands of nodes big, and we probably have hundreds of concurrent mutator threads for them. It may just be that we are hitting a &quot;sweet&quot; spot of allocation rate such that none of the on processor threads get to actually make sufficient progress to reach their cas before we end up needing to GC, at which point they must all safepoint after which I assume, they don&apos;t get any preferential dibs at running next, so we have a much higher ratio of wastage than even in my synthetic test where it was largely proportional to number of cores not number of threads. In this nasty case where we have enough cores to do lots of concurrent work, but enough work per core to cause enough allocation to cause GC before any of them finish the task at hand, you get the worst of both the locking and the spinning worlds.&lt;/p&gt;

&lt;p&gt;Anyways, let me know if you want me to take another stab at the patch including doing the one time allocation outside the loop (or on first pass) - you are more familiar with the code, but it is always good to learn.&lt;/p&gt;</comment>
                            <comment id="14070133" author="benedict" created="Tue, 22 Jul 2014 11:08:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;let me know if you want me to take another stab at the patch&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We&apos;re always keen for competent new comers to start contributing to the project; if you&apos;ve got the time that would be great, and I can review. If not, I&apos;m happy to make this change.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we probably have hundreds of concurrent mutator threads for them&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This should never be the case. By default there are 32 concurrent writers permitted, and this should never be changed to more than a small multiple of the number of physical cores on the machine (unless running batch CL), so if there are hundreds something is going wrong. Furthermore, it makes very little sense that this problem wouldn&apos;t be hit by as many concurrent large modifications: the race condition is the same, but much easier to hit the more work there is being done per concurrent modifier. &lt;/p&gt;

&lt;p&gt;I decided to take a peek at the SnapTreeMap code, since this didn&apos;t make much sense, and I see that there is a very different behaviour if we have many clones() as opposed to many updates (larger updates would necessarily result in a lower incidence/overlap of clone()), as epochs attempt to be allocated. I don&apos;t really have time to waste digging any deeper, but it seems possible that this code path results in a great deal more object allocation (and possibly allocations that are not easily collectible) than simply performing many large updates. If this is the case, then again 2.1 will not suffer this problem. This doesn&apos;t feel like a satisfactory explanation, and nor does the slightly different possible synchronization behaviour with larger updates (snap tree is littered with synchronized() calls, which might possibly overlap more often with many updates).&lt;/p&gt;

&lt;p&gt;Either way, I&apos;m happy to introduce the mitigation strategy we&apos;ve discussed, since it makes sense in and of itself. However we clearly do not fully understand what is happening in your specific scenario, but I do not want to dig further into snap tree - it&apos;s a really ugly contraption!&lt;/p&gt;</comment>
                            <comment id="14070533" author="graham sanderson" created="Tue, 22 Jul 2014 17:11:48 +0000"  >&lt;p&gt;Well that makes sense, I hadn&apos;t checked if there was a limit on mutator threads - we didn&apos;t change it... this probably explains the hard upper bound in my synthetic test (which incidentally does not to the transformation)&lt;/p&gt;

&lt;p&gt;I agree with you on SnapTreeMap, once I see the &quot;essentially&quot; free clone operation has to acquire a lock (or at least wait for no mutations)... I surmised there were probably dragons there that might cause all kinds of nastyness whether it be pain on concurrent updates to horribly unbalancing updates to the tree, or dragging huge amounts of stale data (garbage to be) with it due to overly lazy copy on write (again I didn&apos;t look too closely). BTree looks much better (and probably does less rebalancing since it has wider nodes I think), though as discussed it doesn&apos;t prevent the underlying race we also want to avoid&lt;/p&gt;

&lt;p&gt;So, I&apos;ll see if I have time to work on this later today, but the plan is... for 2.0.x (just checking)&lt;/p&gt;

&lt;p&gt;a) move the transformation.apply out of the loop or do it at most once (I prefer the former since it makes the race window smaller)&lt;br/&gt;
b) do a one way flip flag per AtomicSortedColumns instance, which is flipped when a cost reaches a certain value. I was going to calculate the delta in each mutator thread (probably adding a log-like measure e.g. using Integer.numberOfLeadingZeros(tree.size()) per failing CAS), though looking ugh at SnapTreeMap again, it seems that tree.size() is not a good method to call in the presence of mutations, so I guess Holder can just track the tree size itself. Note the new total cost is CASed in as part of the holder&lt;br/&gt;
c) given this is possibly a temporary solution, is it worth exposing the &quot;cut-off&quot; value even un-documented such that it could be overridden in cassandra.yaml? Note the default should be such that most AtomicSortedColumns instance never get cut-off since they are not heavily contended and large (indicating contended inserts not updates)&lt;/p&gt;

&lt;p&gt;We can re-circle the wagons for 2.1 which needs to be a separate patch anyway&lt;/p&gt;</comment>
                            <comment id="14071167" author="graham sanderson" created="Wed, 23 Jul 2014 00:19:45 +0000"  >&lt;p&gt;I made a new patch 7546.20_3.txt that seems to work quite well&lt;/p&gt;

&lt;p&gt;Open questions&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Any need to expose the wasted work limit as config&lt;/li&gt;
	&lt;li&gt;Would it be nice to update a CF metric (presumably at flush time) with the fraction of rows which had &quot;flipped&quot; for the flushing memtable&lt;/li&gt;
	&lt;li&gt;What to do about deletion info - that is really a separate question&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14071171" author="graham sanderson" created="Wed, 23 Jul 2014 00:22:37 +0000"  >&lt;p&gt;In case anyone is reading them, here is the latest output - note with the current wasted work limit of 100, we actually kick in later except under the higher contention loads, but doing a one time flip, actually do less work overall...&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 996ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 36 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 563MB vs 8MB; ratio to raw data size = 70.37447428571429
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 765ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 38 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 590MB vs 8MB; ratio to raw data size = 73.67167714285715
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 496ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 20 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 448MB vs 8MB; ratio to raw data size = 55.95978857142857
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 574ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 27 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 485MB vs 8MB; ratio to raw data size = 60.56426285714286
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 662ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 333MB vs 8MB; ratio to raw data size = 41.59998095238095
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 241ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 349MB vs 8MB; ratio to raw data size = 43.65317619047619
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 222ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 273MB vs 8MB; ratio to raw data size = 34.18085428571428
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 234ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 286MB vs 8MB; ratio to raw data size = 35.788306666666664
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 64
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1
    [junit]  original code:
    [junit]   Duration = 1383ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 108 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 29 collections
    [junit]   Approx allocation = 9525MB vs 8MB; ratio to raw data size = 1189.0213895238096
    [junit]   loopRatio (closest to 1 best) 16.74471 raw 100000/1674471 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1728ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 572MB vs 8MB; ratio to raw data size = 71.49758761904762
    [junit]   loopRatio (closest to 1 best) 1.00011 raw 144/154 counted 0/0 sync 99856/99857 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 16
    [junit]  original code:
    [junit]   Duration = 223ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 760MB vs 8MB; ratio to raw data size = 94.87286476190476
    [junit]   loopRatio (closest to 1 best) 1.88353 raw 100000/188353 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 206ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 454MB vs 8MB; ratio to raw data size = 56.72647714285714
    [junit]   loopRatio (closest to 1 best) 1.00235 raw 1505/1720 counted 0/0 sync 98495/98515 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 256
    [junit]  original code:
    [junit]   Duration = 189ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 342MB vs 8MB; ratio to raw data size = 42.777810476190474
    [junit]   loopRatio (closest to 1 best) 1.01988 raw 100000/101988 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 190ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 346MB vs 8MB; ratio to raw data size = 43.281460952380954
    [junit]   loopRatio (closest to 1 best) 1.01848 raw 97640/99487 counted 0/0 sync 2360/2361 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 191ms maxConcurrency = 97
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 282MB vs 8MB; ratio to raw data size = 35.20254476190476
    [junit]   loopRatio (closest to 1 best) 1.0037 raw 100000/100370 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 186ms maxConcurrency = 96
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 300MB vs 8MB; ratio to raw data size = 37.474085714285714
    [junit]   loopRatio (closest to 1 best) 1.00365 raw 100000/100365 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 932ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 29 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 560MB vs 26MB; ratio to raw data size = 21.306322898550725
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 715ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 570MB vs 26MB; ratio to raw data size = 21.673085217391304
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 572ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 9 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 457MB vs 26MB; ratio to raw data size = 17.370253623188407
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 805ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 460MB vs 26MB; ratio to raw data size = 17.51271188405797
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 546ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 348MB vs 26MB; ratio to raw data size = 13.242675942028985
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 253ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 349MB vs 26MB; ratio to raw data size = 13.26744347826087
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 457ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 15 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 293MB vs 26MB; ratio to raw data size = 11.139665217391304
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 546ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 15 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 294MB vs 26MB; ratio to raw data size = 11.20318347826087
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 256
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1
    [junit]  original code:
    [junit]   Duration = 1444ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 90 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 30 collections
    [junit]   Approx allocation = 9732MB vs 26MB; ratio to raw data size = 369.75210231884057
    [junit]   loopRatio (closest to 1 best) 16.57088 raw 100000/1657088 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1610ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 17 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 580MB vs 26MB; ratio to raw data size = 22.067385797101448
    [junit]   loopRatio (closest to 1 best) 1.00018 raw 155/172 counted 0/0 sync 99845/99846 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 16
    [junit]  original code:
    [junit]   Duration = 218ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 783MB vs 26MB; ratio to raw data size = 29.776342898550723
    [junit]   loopRatio (closest to 1 best) 1.93609 raw 100000/193609 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 204ms maxConcurrency = 99
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 469MB vs 26MB; ratio to raw data size = 17.852590144927536
    [junit]   loopRatio (closest to 1 best) 1.00213 raw 1866/2073 counted 0/0 sync 98134/98140 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 256
    [junit]  original code:
    [junit]   Duration = 187ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 361MB vs 26MB; ratio to raw data size = 13.738468695652173
    [junit]   loopRatio (closest to 1 best) 1.02042 raw 100000/102042 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 189ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 363MB vs 26MB; ratio to raw data size = 13.825418260869565
    [junit]   loopRatio (closest to 1 best) 1.01876 raw 97150/99024 counted 0/0 sync 2850/2852 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 178ms maxConcurrency = 97
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 301MB vs 26MB; ratio to raw data size = 11.468054492753623
    [junit]   loopRatio (closest to 1 best) 1.00399 raw 100000/100399 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 188ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
    [junit]   Approx allocation = 305MB vs 26MB; ratio to raw data size = 11.606495652173914
    [junit]   loopRatio (closest to 1 best) 1.00398 raw 100000/100398 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 1 THREAD; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 1024ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 596MB vs 99MB; ratio to raw data size = 5.994579233716475
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 848ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 39 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 634MB vs 99MB; ratio to raw data size = 6.374710421455939
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 599ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 540MB vs 99MB; ratio to raw data size = 5.430191570881226
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 812ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 524MB vs 99MB; ratio to raw data size = 5.269081149425287
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 702ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 34 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 414MB vs 99MB; ratio to raw data size = 4.164158697318007
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 618ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 403MB vs 99MB; ratio to raw data size = 4.057552490421456
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 485ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 30 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 356MB vs 99MB; ratio to raw data size = 3.5774026053639845
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 469ms maxConcurrency = 1
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 28 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 360MB vs 99MB; ratio to raw data size = 3.617753026819923
    [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] --------------------------------------------------
    [junit] 100 THREADS; ELEMENT SIZE 1024
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1
    [junit]  original code:
    [junit]   Duration = 2016ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 139 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 39 collections
    [junit]   Approx allocation = 12348MB vs 99MB; ratio to raw data size = 124.02623823754789
    [junit]   loopRatio (closest to 1 best) 18.58224 raw 100000/1858224 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 1401ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 640MB vs 99MB; ratio to raw data size = 6.437993486590038
    [junit]   loopRatio (closest to 1 best) 1.00019 raw 21/39 counted 0/0 sync 99979/99980 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 16
    [junit]  original code:
    [junit]   Duration = 234ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 36 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
    [junit]   Approx allocation = 852MB vs 99MB; ratio to raw data size = 8.563656015325671
    [junit]   loopRatio (closest to 1 best) 1.9605 raw 100000/196050 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 226ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 29 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 484MB vs 99MB; ratio to raw data size = 4.861978007662835
    [junit]   loopRatio (closest to 1 best) 1.00254 raw 897/1143 counted 0/0 sync 99103/99111 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 256
    [junit]  original code:
    [junit]   Duration = 214ms maxConcurrency = 98
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 418MB vs 99MB; ratio to raw data size = 4.201469731800766
    [junit]   loopRatio (closest to 1 best) 1.01951 raw 100000/101951 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 216ms maxConcurrency = 97
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 35 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 409MB vs 99MB; ratio to raw data size = 4.107927662835249
    [junit]   loopRatio (closest to 1 best) 1.01843 raw 96895/98735 counted 0/0 sync 3105/3108 up 0 down 0
    [junit] 
    [junit] 
    [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1024
    [junit]  original code:
    [junit]   Duration = 200ms maxConcurrency = 100
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 31 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 367MB vs 99MB; ratio to raw data size = 3.6926790038314175
    [junit]   loopRatio (closest to 1 best) 1.00402 raw 100000/100402 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit]  modified code: 
    [junit]   Duration = 201ms maxConcurrency = 95
    [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
    [junit]   Approx allocation = 364MB vs 99MB; ratio to raw data size = 3.6609434482758623
    [junit]   loopRatio (closest to 1 best) 1.00399 raw 100000/100399 counted 0/0 sync 0/0 up 0 down 0
    [junit] 
    [junit] 
    [junit] ==================================================
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14071330" author="graham sanderson" created="Wed, 23 Jul 2014 03:45:18 +0000"  >&lt;p&gt;Note w.r.t. deletioninfo... I&apos;m a bit confused about who owns what.&lt;/p&gt;

&lt;p&gt;On 2.1 (And I&apos;m not 100% sure of the exact semantics of when you need to use HeapAllocator.instance vs pure heap allocation, since I haven&apos;t looked at the 2.1 code much)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;                &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (inputDeletionInfoCopy == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
                    inputDeletionInfoCopy = cm.deletionInfo().copy(HeapAllocator.instance);

                deletionInfo = current.deletionInfo.copy().add(inputDeletionInfoCopy);
                updater.allocated(deletionInfo.unsharedHeapSize() - current.deletionInfo.unsharedHeapSize());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, current.deletionInfo.copy() is not done with the HeapAllocator, and the passed inputDeletionInfoCopy&apos;s ranges are RE-copied (without using HeapAllocator.instance) on some code paths inside the .add() method but not others&lt;/p&gt;</comment>
                            <comment id="14071538" author="benedict" created="Wed, 23 Jul 2014 09:13:00 +0000"  >&lt;p&gt;It doesn&apos;t look to me like we re-copy the ranges (only the arrays we store them in)&lt;/p&gt;

&lt;p&gt;On your patch, I have a couple of minor concerns:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I would rather we didn&apos;t increase the amount of memory we use. In 2.1 I&apos;m stricter about this, because in 2.0 we can mitigate it by replacing AtomicReference with a volatile and an AtomicReferenceFieldUpdater. But whatever we do in 2.1 has to be free memory-wise. This means we have 1 integer or 1 reference to play with in the outer class (not the holder), as we can get this for free. We don&apos;t need to maintain a size in 2.1 though, so this is easy. We can track the actual amount of memory allocated (since we already do this).&lt;/li&gt;
	&lt;li&gt;I would rather make the condition for upgrading to locks be based on some rate of wasted work (or, since it works just as well, some rate of wasted memory allocations). The current value seems a bit clunky and difficult to tune, and might be no real indication of contention. However we need to keep this encoded in an integer, and we need to ensure it is free to maintain in the fast case.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So I propose the following: &lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;we decide on a maximum rate of waste (let&apos;s say 100MB/s)&lt;/li&gt;
	&lt;li&gt;when we first waste work we:
	&lt;ul&gt;
		&lt;li&gt;get the current time in ms (but from nanoTime since we need monotonicity);&lt;/li&gt;
		&lt;li&gt;subtract from it our max rate (100Mb/s) converted to K/s, i.e. 100 * 1024, so we have present-100*1024;&lt;/li&gt;
		&lt;li&gt;set our shared counter state to this value&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;whenever we waste work we:
	&lt;ul&gt;
		&lt;li&gt;we calculate how much we wasted&amp;#42; in Kb&lt;/li&gt;
		&lt;li&gt;we add this to our shared counter;&lt;/li&gt;
		&lt;li&gt;if the shared counter has &lt;em&gt;gone past the present time&lt;/em&gt; we know we&apos;ve exceeded our maximum wastage, and we set our counter to Integer.MAX_VALUE which is the flag to everyone to upgrade to locks;&lt;/li&gt;
		&lt;li&gt;if we see it&apos;s too in the past, we reset it to present-(100*1024)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&amp;#42; To calculate wasted work, we track the size you currently are tracking in 2.0, and in 2.1 we use the BTree&apos;s existing size-delta tracking. In 2.0 we multiply the number of updates we had made by by lg2(N) (N = current tree size), and multiple this by 100 (approximate size of snaptree nodes) + ~200 per clone. We divide the result by 1024.&lt;/p&gt;

&lt;p&gt;This is the same scheme I used for tracking wasted cycles in SharedExecutorPool (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-4718&quot; title=&quot;More-efficient ExecutorService for improved throughput&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-4718&quot;&gt;&lt;del&gt;CASSANDRA-4718&lt;/del&gt;&lt;/a&gt;) and I think it works pretty well, and is succinctly represented in memory.&lt;/p&gt;</comment>
                            <comment id="14072081" author="graham sanderson" created="Wed, 23 Jul 2014 18:19:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;It doesn&apos;t look to me like we re-copy the ranges (only the arrays we store them in)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops, yeah you are correct&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I would rather we didn&apos;t increase the amount of memory we use. In 2.1 I&apos;m stricter about this, because in 2.0 we can mitigate it by replacing AtomicReference with a volatile and an AtomicReferenceFieldUpdater. But whatever we do in 2.1 has to be free memory-wise. This means we have 1 integer or 1 reference to play with in the outer class (not the holder), as we can get this for free. We don&apos;t need to maintain a size in 2.1 though, so this is easy. We can track the actual amount of memory allocated (since we already do this).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m all for not wasting memory, after all this is what this patch is about. I&apos;m not sure exactly what 2.1 has to be &lt;em&gt;free&lt;/em&gt; memory wise means... however I assume that the end result is that you don&apos;t want either the Atomic***Columns or the Holder object to grow at all (i.e. another 8 bytes), and I&apos;m assuming you&apos;re calculating space based on compressedoops object layout (so we may have a chance to fill in a spare 32 bit value somewhere; I&apos;ll have to check the 2 classes in 2.0 and 2.1 cases). Note the reason I&apos;m confused about free is that the Object[] for the btree are on heap things and we allocate quite a lot of them. Perhaps by free you mean, no increase in memory usage vs today for this change.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;get the current time in ms (but from nanoTime since we need monotonicity);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Also slight confused; nanoTime is not monotonic but nanoTime minus some static base nanoTime is for all practical purposes, so I assume you mean this. Based on that I guess we can use Integer.MIN_VALUE as a &quot;no one has wasted work yet&quot; flag.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In 2.0 we multiply the number of updates we had made by by lg2(N) (N = current tree size), and multiple this by 100 (approximate size of snaptree nodes) + ~200 per clone&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;by number of updates do you mean individual column attempts?&lt;br/&gt;
which clones are you talking about - I have currently moved them outside the loop which allowed for pre-sharing, and for shrinking the locked work later, but this extra int[] is not free (unless we are only talking about retained space vs temporary).&lt;br/&gt;
I guess we should probably always round up to 1K... that would still be 100,000 CAS fails a second which is certainly bad&lt;/p&gt;

&lt;p&gt;Anyway, I&apos;ll double check the allocation costs in 2.0.x, use and atomic field updater, and make a 2.0.x patch (and see how it behaves)&lt;/p&gt;

&lt;p&gt;Now &quot;max rate&quot; sounds more like something that should be exposable via config (though since it is an implementation detail that will go away eventually, it doesn&apos;t make sense to make it a per CF thing)... I&apos;ll run my test again to see what a good value seems to be. But yeah if something wastes 100M/s ever, I think we can call mark it as &quot;special&quot;.&lt;/p&gt;

&lt;p&gt;Note, the one question other question I have is how big can a single Atomic***Instance get - i.e. is it even possible to allocate 100MB in one, or do they turn over too fast.&lt;/p&gt;</comment>
                            <comment id="14072084" author="graham sanderson" created="Wed, 23 Jul 2014 18:22:04 +0000"  >&lt;p&gt;duh - i&apos;m an idiot, your code catches the allocation waste rate of 100MB/s without actually having to allocation 100M of waste.&lt;br/&gt;
No i&apos;m doubly an idiot - it does actually require you to allocate at least 100MB in a second&lt;/p&gt;</comment>
                            <comment id="14072180" author="benedict" created="Wed, 23 Jul 2014 19:18:21 +0000"  >&lt;p&gt;Well, actually the scheme I outlined isn&apos;t &lt;em&gt;exactly&lt;/em&gt; requiring a rate of 100MB/s; all that actually needs to happen is it consistently exceed a rate of 1Mb/s for a total allocation of 100MB (which can happen if &amp;gt; 100MB are allocated in &amp;lt; 1 second, i.e. 100MB/s, but also if 110Mb is allocated over 10s). We can tweak those numbers however we like (within some window of representable numbers with enough range). For instance exceed a rate of 10MB/s consistently by a total of 10MB, which would require e.g. dividing our bytes allocated by 1k, measuring time in 100ns intervals, and offset the present by 10 * 1024. To capture a rate of 100MB/s, we would need to either expect that memtables never live for more than 0.5 days (probably reasonable, i.e. represent time in 10ns intervals) or require that a single mutator allocates 10k in one run (also quite reasonable) but we&apos;re pushing the limits of what we can safely represent.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;nanoTime is not monotonic&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is monotonic; that&apos;s its main purpose. Although there are no doubt caveats on a given machine/processor for how strictly that is guaranteed&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;which clones are you talking about&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mistype. I mean the number/size of objects we estimate we&apos;ve allocated wastefully for the collection (snap tree / btree). We can estimate this in 2.0 with 200+100*lg2(N), and in 2.1 we measure it exactly.&lt;/p&gt;</comment>
                            <comment id="14072225" author="benedict" created="Wed, 23 Jul 2014 19:51:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;however I assume that the end result is that you don&apos;t want either the Atomic***Columns or the Holder object to grow at all (i.e. another 8 bytes), and I&apos;m assuming you&apos;re calculating space based on compressedoops object layout&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, yes. There&apos;s room for one &apos;free&apos; 32-bit value in the AtomicBTreeColumns is what I meant.&lt;/p&gt;</comment>
                            <comment id="14072465" author="graham sanderson" created="Wed, 23 Jul 2014 22:25:56 +0000"  >&lt;p&gt;OK - I had something else come up today, but yeah I realized my math was wrong... it is certainly takes a bit of massaging to get the correct fidelity of information within 32 bits&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It is monotonic; that&apos;s its main purpose.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess I&apos;m just being pedantic here... it is the low 64 bits of a monotonic number - (even this was broken on early OS/JVM combinations due to bugs, however we can take that as fact now I think); what the actual number is is undefined. It does seem on UNIX variants appear to be rebased to nanonseconds since epoch, and probably on all modern systems is some counter that was at least reset on power cycle, so you are probably ok. In any case, doing the right thing is pretty much always trivial (assuming you don&apos;t expect your JVM to run for 200+ years) and the javadoc does make pains to point out that you can&apos;t rely on anything other than the difference between two values&lt;/p&gt;

&lt;p&gt;&amp;#8211;&lt;/p&gt;

&lt;p&gt;As an aside, can you give me a hint as to how long you expect AtomicSorted/BTreeColumns to last... tuning does seem critical here, since wasting 100M would probably be a reasonable value, but I don&apos;t know in practice if something else would likely end up flushing the memtable before it ever got that far.&lt;/p&gt;</comment>
                            <comment id="14072469" author="benedict" created="Wed, 23 Jul 2014 22:34:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;it is the low 64 bits of a monotonic number&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s pretty pedantic, since with nanos that stretches to 600 years before overflow!&lt;/p&gt;

&lt;p&gt;Either way, I&apos;m not sure if I clarified or not but we should be offsetting this number from the memtable creation time so we can safely stick within 32 bits. I suggest we use the top bit being set as the indicator we&apos;ve hit contention, so we naturally avoid problematic overflow (although really this would just result in our optimisation not running properly, so would also be fine)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;how long you expect AtomicSorted/BTreeColumns to last&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;AtomicBTreeColumns is unlikely to live past 3.1. I would like to get rid of it in 3.0, but that is probably ambitious. So another year or so at bleeding edge; a few more years at various stages downstream no doubt. AtomicSortedColumns will be around as long as 2.0.x is, which is decided by the community really.&lt;/p&gt;

&lt;p&gt;Either way, tuning this value is probably not super helpful, since the goal is simply to avoid lots of wasted memory allocations. We can simply define a sensible slightly cautious criteria for this, and that should be sufficient, since if we are slightly overly cautious the end result is only a small number of partitions seeing slightly reduced throughput for writes. It is not a huge deal either way. It&apos;s only really likely to have a measurable impact at all on very highly contended partitions, on which any sane value will likely yield a very similar improvement.&lt;/p&gt;</comment>
                            <comment id="14072483" author="graham sanderson" created="Wed, 23 Jul 2014 22:41:01 +0000"  >&lt;p&gt;Ignoring the monotonic bit &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; as you say it has to be relative to something anyway&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;AtomicBTreeColumns is unlikely to live past 3.1&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, I meant how long is an instance of one of those classes likely to last? i.e. is it possible to see 100MB of allocation into one single instance, or would another instance have taken over by then. I assume since you are suggesting it that it is possible, but thought I&apos;d double check that that is what you mean.&lt;/p&gt;
</comment>
                            <comment id="14072494" author="benedict" created="Wed, 23 Jul 2014 22:48:48 +0000"  >&lt;p&gt;Under load they don&apos;t last very long (i.e. they stick around until they fill up, which can be just a few minutes, or even faster under really high load), however we don&apos;t care about how much we&apos;re allocating &lt;em&gt;to the memtable&lt;/em&gt; - we care about how much memory we allocation wasteful that &lt;em&gt;do not&lt;/em&gt; make it into the memtable, i.e. all that GC overhead you were seeing - in the worst case you saw 12Gb in only 2.5s against one partition. So whatever numbers we fix for this scheme we will avoid anything like that kind of extreme scenario.&lt;/p&gt;</comment>
                            <comment id="14072530" author="graham sanderson" created="Wed, 23 Jul 2014 23:16:15 +0000"  >&lt;p&gt;Good point - I was mixing the two types of memory allocation in my head... that said I don&apos;t know when we are seeing this in production how long each AtomicSortedColumns instance lives.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;they stick around until they fill up&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I assume you are referring to the memtables there... what defines &quot;full&quot; besides.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;there is a hard(ish) memory limit in yaml&lt;/li&gt;
	&lt;li&gt;MeteredFlusher flushes high traffic stuff&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Basically, I&apos;m just checking that we don&apos;t think our 100MB/s wastage may never trigger due to aggressive flushing... theoretically we must be wasting MUCH more than we are really writing, but I don&apos;t have numbers (I could look at the logs to get them) to see how often hints memtables were being flushed during this process and how big they were.&lt;/p&gt;
</comment>
                            <comment id="14072535" author="benedict" created="Wed, 23 Jul 2014 23:24:49 +0000"  >&lt;p&gt;Yes, I&apos;m referring to the memtables - an AtomicSortedColumns instance lives until its containing memtable is flushed. 100MB/s is around 1M snaptree node allocations, so that is maybe a little high for deciding there&apos;s too much competition (although with ~ 1000 items present this is only 100k inserts), so how about we fix it to 10MB/s, to be exceeded by 10Mb. We could certainly hit 100MB of waste, no trouble (under high competition we&apos;ll see orders of magnitude more wasted than used, and memtables usually store 1Gb+), but I think it&apos;s better to trigger a little more readily&lt;/p&gt;</comment>
                            <comment id="14072718" author="graham sanderson" created="Thu, 24 Jul 2014 02:42:00 +0000"  >&lt;p&gt;cool - makes sense now, It&apos;ll be tomorrow now, but I&apos;ll put up a new version&lt;/p&gt;</comment>
                            <comment id="14074121" author="graham sanderson" created="Fri, 25 Jul 2014 06:08:31 +0000"  >&lt;p&gt;Ok, added 7546.20_4.txt patch against 2.0 (with a bit of static debug stuff we probably don&apos;t need)&lt;/p&gt;

&lt;p&gt;Currently it is set to 10M + 7.5M/s just because it is cleaner with a power of 2 clock divider... We could tweak these (the former is trivial), but this worked well in my tests both on my laptop and on one of our production class machines. It basically did exactly as you&apos;d expect which was to kick in once memory was actually being wasted at a reasonable rate.&lt;/p&gt;

&lt;p&gt;A few random thoughts&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;It would be nice to expose a metric on the CF (I&apos;m not sure whether it should be just total counts, or some fraction)... it&apos;d need to be dealt with maybe in &lt;tt&gt;Memtable.FlushRunnable&lt;/tt&gt;... I left a package protected method - perhaps poorly tensed - &lt;tt&gt;usePessimisticLocking&lt;/tt&gt;. I need your advice on whether/how to expose this metric, but it&apos;d be nice to watch in test (possibly with the actualy synchronization turned off) to see how much it is triggered&lt;/li&gt;
	&lt;li&gt;Note that we are actually running with &lt;tt&gt;concurrent_writes = 256&lt;/tt&gt; in production as we have lots of cores and very fast IO... so it seems likely that we can keep a lot of cores contended in the hinting case... At a minimum of the rule of thumb would have put it at 128 which would still be plenty high - I just thought I&apos;d point that out (my synthetic test runs at 100 threads)&lt;/li&gt;
	&lt;li&gt;I got rid of the unsafe again since we don&apos;t need it. I made a synchronized method rather than plopping some synchronized blocks inside the method bodies because c2 compiler used to be a bit reticent to inline methods with monitor usage and so it is kind of a habit for now (also in this case it is probably just as clean if not cleaner).&lt;/li&gt;
	&lt;li&gt;Oh, as it says as a todo in the code, we should probably make constants for the magic numbers in the memory estimates - and you might want to come up with a better one for the deletioninfo&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14074124" author="graham sanderson" created="Fri, 25 Jul 2014 06:12:30 +0000"  >&lt;p&gt;Once again numbers - note I&apos;m still using the same test driver as before (hence the 0 up/down, count numbers etc), though I have updated it to pass a column cloner in the transform.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[junit] --------------------------------------------------
 [junit] 1 THREAD; ELEMENT SIZE 64
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1
 [junit]  original code:
 [junit]   Duration = 1020ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 37 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
 [junit]   Approx allocation = 589MB vs 8MB; ratio to raw data size = 73.61468285714285
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 963ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 584MB vs 8MB; ratio to raw data size = 72.99738571428571
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 64) partitions = 16
 [junit]  original code:
 [junit]   Duration = 826ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 24 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 496MB vs 8MB; ratio to raw data size = 61.99165047619048
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 746ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 477MB vs 8MB; ratio to raw data size = 59.63136380952381
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 64) partitions = 256
 [junit]  original code:
 [junit]   Duration = 617ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 362MB vs 8MB; ratio to raw data size = 45.24315523809524
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 602ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 366MB vs 8MB; ratio to raw data size = 45.77833523809524
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 64) partitions = 1024
 [junit]  original code:
 [junit]   Duration = 443ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 308MB vs 8MB; ratio to raw data size = 38.468846666666664
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 422ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 309MB vs 8MB; ratio to raw data size = 38.667831428571425
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] --------------------------------------------------
 [junit] 100 THREADS; ELEMENT SIZE 64
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1
 [junit]  original code:
 [junit]   Duration = 2039ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 118 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 34 collections
 [junit]   Approx allocation = 11178MB vs 8MB; ratio to raw data size = 1395.417500952381
 [junit]   loopRatio (closest to 1 best) 18.20478 raw 100000/1820478 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 1299ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 614MB vs 8MB; ratio to raw data size = 76.68355047619048
 [junit]   loopRatio (closest to 1 best) 1.05291 raw 779/6045 counted 0/0 sync 99246/99246 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 64) partitions = 16
 [junit]  original code:
 [junit]   Duration = 224ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 832MB vs 8MB; ratio to raw data size = 103.97120666666666
 [junit]   loopRatio (closest to 1 best) 1.89634 raw 100000/189634 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 226ms maxConcurrency = 99
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 22 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 810MB vs 8MB; ratio to raw data size = 101.20042857142857
 [junit]   loopRatio (closest to 1 best) 1.92036 raw 99094/191116 counted 0/0 sync 920/920 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 64) partitions = 256
 [junit]  original code:
 [junit]   Duration = 188ms maxConcurrency = 99
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 14 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 368MB vs 8MB; ratio to raw data size = 46.03569619047619
 [junit]   loopRatio (closest to 1 best) 1.02239 raw 100000/102239 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 185ms maxConcurrency = 98
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 376MB vs 8MB; ratio to raw data size = 46.975274285714285
 [junit]   loopRatio (closest to 1 best) 1.02077 raw 100000/102077 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 64) partitions = 1024
 [junit]  original code:
 [junit]   Duration = 183ms maxConcurrency = 98
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 309MB vs 8MB; ratio to raw data size = 38.642466666666664
 [junit]   loopRatio (closest to 1 best) 1.00435 raw 100000/100435 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 189ms maxConcurrency = 97
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 315MB vs 8MB; ratio to raw data size = 39.396990476190474
 [junit]   loopRatio (closest to 1 best) 1.00374 raw 100000/100374 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] --------------------------------------------------
 [junit] 1 THREAD; ELEMENT SIZE 256
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1
 [junit]  original code:
 [junit]   Duration = 773ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 20 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 618MB vs 26MB; ratio to raw data size = 23.51672376811594
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 375ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 19 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 618MB vs 26MB; ratio to raw data size = 23.48319043478261
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 256) partitions = 16
 [junit]  original code:
 [junit]   Duration = 330ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 8 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 506MB vs 26MB; ratio to raw data size = 19.239044057971014
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 348ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 8 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 507MB vs 26MB; ratio to raw data size = 19.28066347826087
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 256) partitions = 256
 [junit]  original code:
 [junit]   Duration = 709ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 13 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 393MB vs 26MB; ratio to raw data size = 14.948667826086956
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 619ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 407MB vs 26MB; ratio to raw data size = 15.49846347826087
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 256) partitions = 1024
 [junit]  original code:
 [junit]   Duration = 600ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 343MB vs 26MB; ratio to raw data size = 13.053241739130435
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 551ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 346MB vs 26MB; ratio to raw data size = 13.151993623188405
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] --------------------------------------------------
 [junit] 100 THREADS; ELEMENT SIZE 256
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1
 [junit]  original code:
 [junit]   Duration = 2377ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 131 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 35 collections
 [junit]   Approx allocation = 11554MB vs 26MB; ratio to raw data size = 438.97863014492754
 [junit]   loopRatio (closest to 1 best) 18.38368 raw 100000/1838368 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 1399ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 31 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 634MB vs 26MB; ratio to raw data size = 24.100446666666667
 [junit]   loopRatio (closest to 1 best) 1.05401 raw 1016/6325 counted 0/0 sync 99075/99076 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 256) partitions = 16
 [junit]  original code:
 [junit]   Duration = 237ms maxConcurrency = 99
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 33 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
 [junit]   Approx allocation = 880MB vs 26MB; ratio to raw data size = 33.46811043478261
 [junit]   loopRatio (closest to 1 best) 1.90156 raw 100000/190156 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 220ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 21 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 834MB vs 26MB; ratio to raw data size = 31.701786376811594
 [junit]   loopRatio (closest to 1 best) 1.89694 raw 99747/189437 counted 0/0 sync 256/257 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 256) partitions = 256
 [junit]  original code:
 [junit]   Duration = 187ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 401MB vs 26MB; ratio to raw data size = 15.241803188405797
 [junit]   loopRatio (closest to 1 best) 1.02141 raw 100000/102141 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 183ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 10 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 408MB vs 26MB; ratio to raw data size = 15.502840869565217
 [junit]   loopRatio (closest to 1 best) 1.02057 raw 100000/102057 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 256) partitions = 1024
 [junit]  original code:
 [junit]   Duration = 179ms maxConcurrency = 98
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 12 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 346MB vs 26MB; ratio to raw data size = 13.181417391304349
 [junit]   loopRatio (closest to 1 best) 1.00479 raw 100000/100479 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 189ms maxConcurrency = 97
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 11 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 collections
 [junit]   Approx allocation = 350MB vs 26MB; ratio to raw data size = 13.331782608695653
 [junit]   loopRatio (closest to 1 best) 1.00373 raw 100000/100373 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] --------------------------------------------------
 [junit] 1 THREAD; ELEMENT SIZE 1024
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1
 [junit]  original code:
 [junit]   Duration = 1024ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 35 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
 [junit]   Approx allocation = 722MB vs 99MB; ratio to raw data size = 7.260372490421456
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 799ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 34 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
 [junit]   Approx allocation = 757MB vs 99MB; ratio to raw data size = 7.612250574712644
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 16
 [junit]  original code:
 [junit]   Duration = 562ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
 [junit]   Approx allocation = 641MB vs 99MB; ratio to raw data size = 6.442458850574712
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 528ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 32 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 3 collections
 [junit]   Approx allocation = 651MB vs 99MB; ratio to raw data size = 6.5402478927203065
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 256
 [junit]  original code:
 [junit]   Duration = 665ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 26 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 559MB vs 99MB; ratio to raw data size = 5.618937088122605
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 815ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 28 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 547MB vs 99MB; ratio to raw data size = 5.494165977011495
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 1 elements = 100000 (of size 1024) partitions = 1024
 [junit]  original code:
 [junit]   Duration = 686ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 28 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 490MB vs 99MB; ratio to raw data size = 4.927921072796935
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 702ms maxConcurrency = 1
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 29 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 483MB vs 99MB; ratio to raw data size = 4.851513026819924
 [junit]   loopRatio (closest to 1 best) 1.0 raw 100000/100000 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] --------------------------------------------------
 [junit] 100 THREADS; ELEMENT SIZE 1024
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1
 [junit]  original code:
 [junit]   Duration = 2462ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 160 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 45 collections
 [junit]   Approx allocation = 14795MB vs 99MB; ratio to raw data size = 148.60839471264367
 [junit]   loopRatio (closest to 1 best) 18.92911 raw 100000/1892911 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 1333ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 26 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 763MB vs 99MB; ratio to raw data size = 7.6639096551724135
 [junit]   loopRatio (closest to 1 best) 1.05239 raw 861/6055 counted 0/0 sync 99184/99184 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 16
 [junit]  original code:
 [junit]   Duration = 249ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 38 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 4 collections
 [junit]   Approx allocation = 1158MB vs 99MB; ratio to raw data size = 11.633376168582375
 [junit]   loopRatio (closest to 1 best) 1.98465 raw 100000/198465 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 244ms maxConcurrency = 100
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 44 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 4 collections
 [junit]   Approx allocation = 1004MB vs 99MB; ratio to raw data size = 10.08440398467433
 [junit]   loopRatio (closest to 1 best) 1.92636 raw 99467/192098 counted 0/0 sync 537/538 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 256
 [junit]  original code:
 [junit]   Duration = 207ms maxConcurrency = 97
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 29 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 504MB vs 99MB; ratio to raw data size = 5.063335938697318
 [junit]   loopRatio (closest to 1 best) 1.02225 raw 100000/102225 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 198ms maxConcurrency = 98
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 558MB vs 99MB; ratio to raw data size = 5.614166206896551
 [junit]   loopRatio (closest to 1 best) 1.02187 raw 100000/102187 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit] 
 [junit] Threads = 100 elements = 100000 (of size 1024) partitions = 1024
 [junit]  original code:
 [junit]   Duration = 214ms maxConcurrency = 98
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 27 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 481MB vs 99MB; ratio to raw data size = 4.832893256704981
 [junit]   loopRatio (closest to 1 best) 1.00487 raw 100000/100487 counted 0/0 sync 0/0 up 0 down 0
 [junit] 
 [junit]  modified code: 
 [junit]   Duration = 202ms maxConcurrency = 97
 [junit]   GC &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; PS Scavenge: 25 ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 2 collections
 [junit]   Approx allocation = 500MB vs 99MB; ratio to raw data size = 5.025245363984674
 [junit]   loopRatio (closest to 1 best) 1.00395 raw 100000/100395 counted 0/0 sync 0/0 up 0 down 0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14074127" author="graham sanderson" created="Fri, 25 Jul 2014 06:17:17 +0000"  >&lt;p&gt;Actually looking at my numbers here on the production level h/w, I certainly don&apos;t think the numbers are too aggressive, but as I say it&apos;d be nice to actually watch this in the real world&lt;/p&gt;</comment>
                            <comment id="14076392" author="graham sanderson" created="Mon, 28 Jul 2014 17:00:56 +0000"  >&lt;p&gt;I&apos;ve add 7646.20_5.txt which is the same as 7546_20.4.txt but with a minor change that allows it to function correctly to close to the full 32 bits of time range vs 31 bits.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Any thoughts on metrics?&lt;br/&gt;
I&apos;m thinking a simple CF (and rolled up KS) metric which simply counts number of highly contented rows over time. Note, we do know when a row was partially contented, but I don&apos;t know that we can assign a meaningful value between 0 &amp;amp; 1. Note, we could do a ratio of good vs bad rows on flush, but I think the raw count is more interesting&lt;/li&gt;
	&lt;li&gt;Note, I plan to move the static {} block at the top to a test case for sanity checking - it doesn&apos;t belong mixed in the code... Once we&apos;re all set I&apos;ll submit an actual patch for 2.0.x and 2.1.x - should we patch this in 1.1/1.2 also?&lt;/li&gt;
	&lt;li&gt;Any other thoughts? I&apos;d like to start testing this (but don&apos;t want to do so if it you want to make major changes). I&apos;ll test on top of 2.0.10 in beta with our code and cassandra stress (hopefully some scenarios you have in 2.1 both with a node down for hinting and not), and maybe after that with the tracking/metric on but the synchronized off in production just to check that it exactly detects our hint storms and nothing else in production (we have no application tables that should be heavily contented on the partition level). I&apos;ll make and test a patch on 2.1 also, however I&apos;ll have to finish testing on 2.0.x before I can upgrade a (fast h/w) cluster to 2.1&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14077018" author="benedict" created="Mon, 28 Jul 2014 22:23:12 +0000"  >&lt;p&gt;My biggest concern with metrics is that what we expose as a metric will probably change when we change tack to a lock-free lazy-update design, since it will be more expensive to maintain. Certainly tracking the amount of &apos;wasted&apos; work will be meaningless then, although possibly we could track the raw occurrences of failure to make a change atomically without interference (which in the lazy case would be failure to acquire exclusivity to merge your changes in)&lt;/p&gt;

&lt;p&gt;I&apos;m currently on holiday but will try to review your patch shortly.&lt;/p&gt;</comment>
                            <comment id="14077057" author="graham sanderson" created="Mon, 28 Jul 2014 22:44:04 +0000"  >&lt;p&gt;Ok, thank you... yeah my only reason for recording something in the actual codebase was to indicate that to the user that they had ultra heavy partition contention that might be detrimental to performance, and they should perhaps review their schema. Given that this may not be the case at all in 3.0 (i.e. it may be gracefully handled in all cases), I&apos;ll try out locally with a WARN statement instead. I&apos;ll probably do it at memtable flush anyway which has more useful context (e.g. the CF in question), and would be less spam-y (i.e. one warn with the number of contended partitions, though perhaps the contended key(s) are interesting at a lower log level)... whether we include such logging in the final patch I don&apos;t know.&lt;/p&gt;</comment>
                            <comment id="14087513" author="benedict" created="Wed, 6 Aug 2014 10:44:53 +0000"  >&lt;p&gt;I&apos;ve attached a slightly tweaked version, making things a little clearer (IMO) and removing some of the unnecessary comments, as well as fixing a couple of bugs and removing the AtomicReference&amp;lt;Holder&amp;gt; to recoup the extra space we&apos;re now using in the Holder.&lt;/p&gt;

&lt;p&gt;I must admit I&apos;m still not madly keen on the nested synchronized() calls - I think they&apos;re a little ugly, and also increase call depth which is not ideal. I also cannot find any evidence that invoking unsafe.monitorenter/monitorexit would result in negative optimisations (this discussion on the relevant mailing list makes no such assertion whilst discussing its potential removal &lt;a href=&quot;http://openjdk.5641.n7.nabble.com/Unsafe-removing-the-monitorEnter-monitorExit-tryMonitorEnter-methods-td179462.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://openjdk.5641.n7.nabble.com/Unsafe-removing-the-monitorEnter-monitorExit-tryMonitorEnter-methods-td179462.html&lt;/a&gt;, but suggests exposing them more safely), however mostly I think the usage is clearer than nested calls passing the state of the method (isSynchronized is esp. ugly to me). I am not deadset against it though. Perhaps &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey&quot; class=&quot;user-hover&quot; rel=&quot;iamaleksey&quot;&gt;iamaleksey&lt;/a&gt; can offer a third opinion?&lt;/p&gt;

&lt;p&gt;Otherwise, WDYT &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=graham+sanderson&quot; class=&quot;user-hover&quot; rel=&quot;graham sanderson&quot;&gt;graham sanderson&lt;/a&gt;? Could you give this patch a test and see how it behaves?&lt;/p&gt;</comment>
                            <comment id="14087799" author="graham sanderson" created="Wed, 6 Aug 2014 15:42:42 +0000"  >&lt;p&gt;+1 on another set of eyes (yes the isSynchronized is ugly) - that said, I can move ahead on testing the main functionality of this patch (the waste detection) since we are all agreed I think on the basic mechanism.&lt;/p&gt;

&lt;p&gt;I am reading your patch (thanks for cleaning up - mine was a bit verbose for discussion purposes), I will read it in more detail now, but just from an initial glance in its raw form, why did you make the size in Holder volatile/atomically updated. The holder instances should only be mutated by a single thread&lt;/p&gt;</comment>
                            <comment id="14087814" author="benedict" created="Wed, 6 Aug 2014 15:53:15 +0000"  >&lt;p&gt;Well, technically we never ever call addColumn() directly, but in 2.0 we haven&apos;t removed / UnsupportedOperationException&apos;d that path, so I&apos;m not totally comfortable leaving it as a regular int, as an external call to addColumn would break it (but then, this probably isn&apos;t the end of the world). &lt;/p&gt;

&lt;p&gt;However, I actually introduced a double counting bug in changing that :/   ... and since we don&apos;t want to incur the incAndGet every change, and we don&apos;t want to dup code, let&apos;s settle for the possible race for maintaining size if somebody uses the API in a way it isn;t in the codebase right now.&lt;/p&gt;

&lt;p&gt;&lt;del&gt;However I think I would prefer to make size final in this case.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Looking again, it&apos;s too ugly to make it final, so let&apos;s settle for the ugliness of it being non-final, and revert to your behaviour here. This bit is soon to be superceded by 2.1 anyway, so let&apos;s not agonise over the beauty of it.&lt;/p&gt;</comment>
                            <comment id="14087841" author="graham sanderson" created="Wed, 6 Aug 2014 16:12:54 +0000"  >&lt;p&gt;Cool will do; addColumns also CASes a thread locally modified Holder anyway.&lt;/p&gt;

&lt;p&gt;Yes I agree it is ugly to have a non final in something like Holder (being CASed immutable state) but I think we can live with it since it is not mutated after CAS&lt;/p&gt;

&lt;p&gt;As said, we can revert to monitor enter/exit if you wish... I can&apos;t prove it is worse, and there isn&apos;t a whole lot that needs optimization here&lt;br/&gt;
Note you have a comment&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;in wasteTracker we maintain within EXCESS_WASTE_OFFSET either side of the current time&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We probably mean &quot;to the left&quot; of... &quot;before&quot; or &quot;after&quot; are a bit confusing here!&lt;/p&gt;

&lt;p&gt;I thought about a couple of things while you were on vacation&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Volatile read of the wasteTracker in the &quot;fast&quot; path. We could avoid this thru some ugliness of hijacking the top bit in the tree size to mark pessimistic locking also. Not to concerned about this read - believe it is free on intel anyway&lt;/li&gt;
	&lt;li&gt;Adjacent in memory CASed vars in the AtomicSortedColumns - Again not majorly worried here... I don&apos;t think the (CASed) variables themselves are highly contended, it is more that we are doing lots of slow concurrent work, and then failing the CAS.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14087850" author="benedict" created="Wed, 6 Aug 2014 16:18:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;We probably mean &quot;to the left&quot; of... &quot;before&quot; or &quot;after&quot; are a bit confusing here!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep, good catch!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Volatile read of the wasteTracker in the &quot;fast&quot; path.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;At the moment we mostly optimise for x86 for the moment, and it&apos;s essentially free here as you say. Even on platforms it isn&apos;t, it&apos;s unlikely to be a significant part of the overall costs, so better to keep it cleaner&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Adjacent in memory CASed vars in the AtomicSortedColumns - Again not majorly worried here... I don&apos;t think the (CASed) variables themselves are highly contended, it is more that we are doing lots of slow concurrent work, and then failing the CAS.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Absolutely not worried about this. Like you say, most of the cost is elsewhere. Would be much worse to pollute the cache with padding to avoid it.&lt;/p&gt;</comment>
                            <comment id="14087884" author="graham sanderson" created="Wed, 6 Aug 2014 16:43:00 +0000"  >&lt;p&gt;I haven&apos;t yet tested Benedict&apos;s updated version 7546.20_6.txt, however I am attaching the code I will be testing on 2.0 based on today&apos;s discussions...&lt;/p&gt;</comment>
                            <comment id="14087885" author="benedict" created="Wed, 6 Aug 2014 16:44:18 +0000"  >&lt;p&gt;Sounds good, thanks!&lt;/p&gt;</comment>
                            <comment id="14088738" author="graham sanderson" created="Thu, 7 Aug 2014 03:00:57 +0000"  >&lt;p&gt;I ran my smoke test on this and it is as expected; I have added the patch (with a warn log statement on memtable flush if we have resorted to pessimistic concurrency for some rows) to our 2.0.9 beta env... I will try and repro there with a node down (though this cluster is pretty much limited by commit volumes under high load, so can&apos;t equal production concurrency), but that said I just want to check that everything is OK, before I patch a single node in production (also 2.0.9)&lt;/p&gt;

&lt;p&gt;On a separate note (I don&apos;t have access to a 2.1 cluster ATM), it would be interesting to try something similar to&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.datastax.com/dev/blog/cassandra-2-1-now-over-50-faster&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.datastax.com/dev/blog/cassandra-2-1-now-over-50-faster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;with a node down &amp;amp; hinting as a test case for this on 2.1&lt;/p&gt;</comment>
                            <comment id="14089617" author="graham sanderson" created="Thu, 7 Aug 2014 19:02:24 +0000"  >&lt;p&gt;doh - i should have asked about the double counting - didn&apos;t see it, now I do&lt;/p&gt;</comment>
                            <comment id="14092462" author="graham sanderson" created="Mon, 11 Aug 2014 05:38:46 +0000"  >&lt;p&gt;Had a lot going on... have this running in beta right now (without double counting), but haven&apos;t had a chance to deliberately test it with a node down.&lt;/p&gt;

&lt;p&gt;That said, it does detect OpsCenter.pdps in beta (we generally have OpsCenter turned off in production for high volume stuff, and this would seem to validate our decision)&lt;/p&gt;

&lt;p&gt;Anyway, I myself am now on vacation for the next 10 days... I&apos;d be super interested if we could see some results from 2.1&lt;/p&gt;</comment>
                            <comment id="14092465" author="graham sanderson" created="Mon, 11 Aug 2014 05:45:50 +0000"  >&lt;p&gt;Attaching what we actually have in beta (no double counting, and a warning message)&lt;/p&gt;</comment>
                            <comment id="14116223" author="graham sanderson" created="Sat, 30 Aug 2014 04:11:03 +0000"  >&lt;p&gt;I thought I&apos;d attach an image of the correlation between the hint spikes and the massive memory allocation. There is a chicken and egg thing here, but if a node starts hinting heavily, it may become unresponsive causing a knock on effect.&lt;/p&gt;

&lt;p&gt;Note that the load on the system is largely steady from day to day. the hint spikes do &lt;em&gt;not&lt;/em&gt; correlate with any unusually arduous activity (though the system may be quite busy at the time)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12665535/12665535_young_gen_gc.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12665536/12665536_hint_spikes.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Note on the yellow node, there was a period of about 500 seconds of young gen GC, which equates to about 3TB of garbage&lt;/p&gt;</comment>
                            <comment id="14116226" author="graham sanderson" created="Sat, 30 Aug 2014 04:14:41 +0000"  >&lt;p&gt;In beta, the patch worked well at detecting hint activity. next week we will put it on half the production nodes, to verify that those nodes don&apos;t go into memory allocation craziness in response to hinting under heavy load.&lt;/p&gt;

&lt;p&gt;Assuming all is well, then I would like to request this be targeted for 2.0.11 too&lt;/p&gt;</comment>
                            <comment id="14116656" author="graham sanderson" created="Sun, 31 Aug 2014 07:23:36 +0000"  >&lt;p&gt;While I wait for the ability to test in production, I&apos;ve made an (untested) version of the fix which uses your preferred asynchronous monitor enter/exit: 7546.20_async.txt&lt;/p&gt;</comment>
                            <comment id="14117276" author="slebresne" created="Mon, 1 Sep 2014 10:15:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;Assuming all is well, then I would like to request this be targeted for 2.0.11 too&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m afraid this is a bit too complex in a bit too sensible part of the code to be eligible for 2.0 at this point.&lt;/p&gt;</comment>
                            <comment id="14117845" author="graham sanderson" created="Tue, 2 Sep 2014 02:58:05 +0000"  >&lt;p&gt;Ok, NP, we can do our own custom builds with it in 2.0.x...&lt;/p&gt;

&lt;p&gt;I&apos;ll make and attach a 2.1.x patch for this sensible (sensitive?) part of the code soon.&lt;/p&gt;</comment>
                            <comment id="14117882" author="benedict" created="Tue, 2 Sep 2014 04:44:20 +0000"  >&lt;p&gt;Hi Graham,&lt;/p&gt;

&lt;p&gt;Just an FYI I won&apos;t be in a position for a little while to perform a formal review on something this critical, after having had an accident. Just wanted to let you know I&apos;m not ignoring progress though, and will get to it soon enough.&lt;/p&gt;</comment>
                            <comment id="14117896" author="graham sanderson" created="Tue, 2 Sep 2014 05:07:41 +0000"  >&lt;p&gt;Hi Benedict, I hope you are OK and get well soon... it will likely be a week or two before we can prove in production that this is fixing the problem. I also have been on vacation and then sick, so I have a lot of other catching up to do. Once I have some time, I will play with the new stress testing stuff in 2.1 along with this and try and get some firm evidence there.&lt;/p&gt;

&lt;p&gt;All I ask is that it doesn&apos;t get pushed to 3.0.x &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14117921" author="graham sanderson" created="Tue, 2 Sep 2014 06:04:40 +0000"  >&lt;p&gt;Well, I made a patch for 2.1 anyway in case anyone wants to take a look... I&apos;ll try it out as soon as I can (7546.21_v1.txt)&lt;/p&gt;</comment>
                            <comment id="14123917" author="benedict" created="Sat, 6 Sep 2014 01:03:57 +0000"  >&lt;p&gt;Overall the patch LVGTM, though not giving it an official +1 until I&apos;m closer to 100%.&lt;/p&gt;

&lt;p&gt;Look forward to seeing the results.&lt;/p&gt;</comment>
                            <comment id="14123920" author="graham sanderson" created="Sat, 6 Sep 2014 01:07:30 +0000"  >&lt;p&gt;Yes, I&apos;m actually waiting on one of our main Cassandra Ops guys to come back from vacation on Monday to upgrade one of our clusters to 2.1 before I can run the stress tests, but we do have the patch running in production on 2.0.x.&lt;/p&gt;

&lt;p&gt;It detects hints, and it would also seem (which makes sense) fast hint playback of things with low cardinality keys&lt;/p&gt;

&lt;p&gt;I will certainly change the log level to INFO or DEBUG though... as this shouldn&apos;t really be a WARNING.&lt;/p&gt;</comment>
                            <comment id="14134635" author="graham sanderson" created="Mon, 15 Sep 2014 22:48:16 +0000"  >&lt;p&gt;Finally getting back to this, been doing other things (this slightly lower priority as we have it in production already) as well as keeping breaking myself physically, requiring orthopedic visits! I just realized that the version c6a2c65a75ade being voted on for 2.1.0 that I deployed is not the same as 2.1.0 released. I am now upgrading, since cassandra-stress changes snuck in.&lt;/p&gt;

&lt;p&gt;Note, than I plan to stress using 1024, 256, 16, 1 partitions, with all 5 nodes up, and then with 4 nodes up and one down to test effect of hinting, (note repl factor of 3 and cl=LOCAL_QUORUM), as well as with at least memtable_allocation_type = heap_buffers &amp;amp; off_heap_buffers&lt;/p&gt;

&lt;p&gt;I want to do one cell insert per batch... I&apos;m upgrading in part because of the new visit/revisit stuff - I&apos;m not 100% sure how to use them correctly, I&apos;ll keep playing but you may answer before I have finished upgrading and tried with this. My first attempt on the original 2.1.0 revision, ended up with only one clustering key value per partition which is not what I wanted (because it&apos;ll make trees small)&lt;/p&gt;

&lt;p&gt;Sample YAML for 1024 partitions&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;#
# This is an example YAML profile &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; cassandra-stress
#
# insert data
# cassandra-stress user profile=/home/jake/stress1.yaml ops(insert=1)
#
# read, using query simple1:
# cassandra-stress profile=/home/jake/stress1.yaml ops(simple1=1)
#
# mixed workload (90/10)
# cassandra-stress user profile=/home/jake/stress1.yaml ops(insert=1,simple1=9)


#
# Keyspace info
#
keyspace: stresscql

#
# The CQL &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; creating a keyspace (optional &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; it already exists)
#
keyspace_definition: |
  CREATE KEYSPACE stresscql WITH replication = {&lt;span class=&quot;code-quote&quot;&gt;&apos;class&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;SimpleStrategy&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;replication_factor&apos;&lt;/span&gt;: 3};

#
# Table info
#
table: testtable

#
# The CQL &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; creating a table you wish to stress (optional &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; it already exists)
#
table_definition: |
  CREATE TABLE testtable (
        p text,
        c text,
        v blob,
        PRIMARY KEY(p, c)
  ) WITH COMPACT STORAGE 
    AND compaction = { &lt;span class=&quot;code-quote&quot;&gt;&apos;class&apos;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&apos;LeveledCompactionStrategy&apos;&lt;/span&gt; }
    AND comment=&lt;span class=&quot;code-quote&quot;&gt;&apos;TestTable&apos;&lt;/span&gt;

#
# Optional meta information on the generated columns in the above table
# The min and max only apply to text and blob types
# The distribution field represents the total unique population
# distribution of that column across rows.  Supported types are
# 
#      EXP(min..max)                        An exponential distribution over the range [min..max]
#      EXTREME(min..max,shape)              An extreme value (Weibull) distribution over the range [min..max]
#      GAUSSIAN(min..max,stdvrng)           A gaussian/normal distribution, where mean=(min+max)/2, and stdev is (mean-min)/stdvrng
#      GAUSSIAN(min..max,mean,stdev)        A gaussian/normal distribution, with explicitly defined mean and stdev
#      UNIFORM(min..max)                    A uniform distribution over the range [min, max]
#      FIXED(val)                           A fixed distribution, always returning the same value
#      Aliases: extr, gauss, normal, norm, weibull
#
#      If preceded by ~, the distribution is inverted
#
# Defaults &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all columns are size: uniform(4..8), population: uniform(1..100B), cluster: fixed(1)
#
columnspec:
  - name: p
    size: fixed(16)
    population: uniform(1..1024)     # the range of unique values to select &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the field (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; is 100Billion)
  - name: c
    size: fixed(26)
#    cluster: uniform(1..100B)
  - name: v
    size: gaussian(50..250)

insert:
  partitions: fixed(1)            # number of unique partitions to update in a single operation
                                  # &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; batchcount &amp;gt; 1, multiple batches will be used but all partitions will
                                  # occur in all batches (unless they finish early); only the row counts will vary
  batchtype: LOGGED               # type of batch to use
  visits: fixed(10M)    # not sure about &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;

queries:
   simple1: select * from testtable where k = ? and v = ? LIMIT 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Command-line&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;./cassandra-stress user profile=~/cqlstress-1024.yaml ops\(insert=1\) cl=LOCAL_QUORUM -node $NODES -mode &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; prepared cql3 | tee results/results-2.1.0-p1024-a.txt
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14134674" author="benedict" created="Mon, 15 Sep 2014 23:11:56 +0000"  >&lt;p&gt;Hi Graham,&lt;/p&gt;

&lt;p&gt;I must admit I&apos;m a bit confused, and it&apos;s partially self inflicted. In 2.1.1 we have changed stress again from what we released in 2.1.0, and I can&apos;t tell which version you&apos;re referring to, though it seems 2.1.1. Neither version has a &apos;visits&apos; property in the yaml, but 2.1.1 supports -insert visits= revisit=, which are certainly functions worth exploring and I recommend you use 2.1.1 for stress functionality either way. &lt;/p&gt;

&lt;p&gt;As far as using these functions are concerned, &apos;visits&apos; splits a wide row up into multiple inserts; if a visits value of 10 is produced, and there are on average 100 rows generated for the partition, approximately 10 rows will be inserted, then the state of the partition will be stashed away and the next insert that operates on that partition will pick up where the previous one left off. Which partition is performed next is decided by the &apos;revisit&apos; distribution, which selects from the stash of partially completed inserts, with a value of 1 selecting the most recently stashed (the max value of this distribution defines the total number of partitions to stash); if it ever selects outside of the current stash a new partition is generated instead. &lt;/p&gt;

&lt;p&gt;So the value for &apos;visits&apos; is related to the number of unique clustering columns you generate for each partition, whereas the value for revisit is determined by how diverse the data you operate over in a given time window is.  &lt;/p&gt;

&lt;p&gt;Separately, it&apos;s worth mentioning that offheap_objects is likely a better choice than offheap_buffers, since it is considerably more memory dense.&lt;/p&gt;</comment>
                            <comment id="14134695" author="graham sanderson" created="Mon, 15 Sep 2014 23:35:04 +0000"  >&lt;ol&gt;
	&lt;li&gt;&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=log;h=f099e086f3f002789e24bd6c58e52b7553cd5381&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=log;h=f099e086f3f002789e24bd6c58e52b7553cd5381&lt;/a&gt; is what was released according to the 2.1.0 tag in git vs what &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne&quot; class=&quot;user-hover&quot; rel=&quot;slebresne&quot;&gt;slebresne&lt;/a&gt; said in the email thread regarding no changes after c6a2c65a75adea9a62896269da98dd036c8e57f3 which was 2.1.0-tentative&lt;/li&gt;
	&lt;li&gt;ok, I&apos;ll try offheap_objects instead (or as well)&lt;/li&gt;
	&lt;li&gt;I&apos;m still a bit confused about visit/revisit (which are in the 2.1.0 tagged release)... I want to evenly spread the load across all my partitions (genernally using a new clustering key every time, though I want to put a practical limit on the size of the partitions, so I was hoping to let it wrap at 10M or so unique clustering key values)... so it ounds like i want a visits=fixed(1) and revisits=not quite sure&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14135004" author="benedict" created="Tue, 16 Sep 2014 05:50:12 +0000"  >&lt;p&gt;1: that&apos;s great news &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
3: if you want lots of unique clustering key values per partition, currently stress has some limitations and you will need/want to have multiple clustering columns for it to be able to generate that smoothly without taking donkeys years per insert (on the workload generation side). Its minimum unit of generation (not insert) is a single tier of clustering values, so it would generate all 100B values each time you wanted to insert any number with your spec.&lt;/p&gt;

&lt;p&gt;So, you want to consider a yaml like this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;table_definition: |
  CREATE TABLE testtable (
        p text,
        c1 int, c2 int, c3 int
        v blob,
        PRIMARY KEY(p, c1, c2, c3)
  ) WITH COMPACT STORAGE 
    AND compaction = { &apos;class&apos;:&apos;LeveledCompactionStrategy&apos; }
    AND comment=&apos;TestTable&apos;

columnspec:
  - name: p
    size: fixed(16)
  - name: c1
    cluster: fixed(100)
  - name: c2
    cluster: fixed(100)
  - name: c3
    cluster: fixed(100)
  - name: v
    size: gaussian(50..250)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then you want to consider passing -pop seq=1..1M -insert visits=fixed(1M) revisits=uniform(1..1024)&lt;/p&gt;

&lt;p&gt;The visits parameter here tells stress to split each partition into 1M distinct inserts, which given its deterministic 1M keys means exactly 1 item inserted each visit. The revisits distribution defines the number of partition keys we will operate over until we exhaust one before selecting another to include in our working set. &lt;/p&gt;

&lt;p&gt;Notice I&apos;ve removed the population spec from your partition key in the yaml. This is because it is not necessary to constrain it here, as you can constrain the &lt;em&gt;seed&lt;/em&gt; population with the -pop parameter, which is the better way to do it here (so you can use the same yaml across runs). However, in this case given our revisits() distribution we can also not constrain the seed population, since once our first 1024 have been generated no other PK will be visited until one of these has been fully exhausted (i.e. 1024 * 1M inserts, quite a few...). &lt;/p&gt;

&lt;p&gt;You may also constrain the seed to the same range, which once a key is exhausted would always result in filling back in that key to the working set. It doesn&apos;t matter what distribution you choose in this case, since it will keep generating a value until one not present in the stash crops up, which if they operate over the same domain can only result in 1 item regardless of distribution, so I suggest a sequential distribution to ensure determinism.&lt;/p&gt;</comment>
                            <comment id="14135201" author="slebresne" created="Tue, 16 Sep 2014 09:44:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=log;h=f099e086f3f002789e24bd6c58e52b7553cd5381&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=log;h=f099e086f3f002789e24bd6c58e52b7553cd5381&lt;/a&gt; is what was released according to the 2.1.0 tag in git vs what Sylvain Lebresne said in the email thread regarding no changes after c6a2c65a75adea9a62896269da98dd036c8e57f3 which was 2.1.0-tentative&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I messed up when tagging it, it&apos;s the vote email that was correct, and I apologize for the confusion. I&apos;ve updated the tag to reflect what was actually released.&lt;/p&gt;</comment>
                            <comment id="14135637" author="graham sanderson" created="Tue, 16 Sep 2014 15:55:57 +0000"  >&lt;p&gt;Ok, thanks Sylvain, yes I was a bit confused (also because Benedict&apos;s changes included in the incorrect tag had CHANGES.txt with his new stress change as part of listed 2.1.0 changes - which of course now makes sense); anyways... this is good news for me, I&apos;ll leave the test cluster on what I deployed (2.1.0-tentative == the real 2.1.0 as expected according to how the vote was looking at the time), and update stress.jar on my load machine to come from 2.1 head.&lt;/p&gt;</comment>
                            <comment id="14137777" author="graham sanderson" created="Wed, 17 Sep 2014 19:20:11 +0000"  >&lt;p&gt;OK, so I&apos;m running latest stress.jar on my load machine - given the number of changes to stress in 2.1.1 (and the addition by the looks of things of remote GC logging via cassandra-stress which would be useful in this case), I guess I&apos;ll upgrade the cluster as well.&lt;/p&gt;

&lt;p&gt;Here is my current config (minus the comments) and the launch command... note there were some typos in our conversation above&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;keyspace: stresscql

keyspace_definition: |
  CREATE KEYSPACE stresscql WITH replication = {&lt;span class=&quot;code-quote&quot;&gt;&apos;class&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;SimpleStrategy&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;replication_factor&apos;&lt;/span&gt;: 3};

table: testtable

table_definition: |
  CREATE TABLE testtable (
        p text,
        c1 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, c2 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, c3 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;,
        v blob,
        PRIMARY KEY(p, c1, c2, c3)
  ) WITH COMPACT STORAGE 
    AND compaction = { &lt;span class=&quot;code-quote&quot;&gt;&apos;class&apos;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&apos;LeveledCompactionStrategy&apos;&lt;/span&gt; }
    AND comment=&lt;span class=&quot;code-quote&quot;&gt;&apos;TestTable&apos;&lt;/span&gt;

columnspec:
  - name: p
    size: fixed(16)
  - name: c1
    cluster: fixed(100)
  - name: c2
    cluster: fixed(100)
  - name: c3
    cluster: fixed(1000) # note I made it slightly bigger since 10M is better than 1M &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a max - 1M happens pretty quickly
  - name: v
    size: gaussian(50..250)

queries:
   simple1:
      cql: select * from testtable where k = ? and v = ? LIMIT 10
      fields: samerow
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;./cassandra-stress user profile=~/cqlstress-7546.yaml ops\(insert=1\) cl=LOCAL_QUORUM -node $NODES -mode &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; prepared cql3 -pop seq=1..10M -insert visits=fixed\(10M\) revisit=uniform\(1..1024\) | tee results/results-2.1.0-p1024-a.txt
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As of right now, we&apos;re still (8 minutes later) at:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;INFO  19:11:51 Using data-center name &lt;span class=&quot;code-quote&quot;&gt;&apos;Austin&apos;&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DCAwareRoundRobinPolicy (&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
Connected to cluster: Austin Multi-Tenant Cassandra 1
INFO  19:11:51 New Cassandra host cassandra4.aus.vast.com/172.17.26.14:9042 added
Datatacenter: Austin; Host: cassandra4.aus.vast.com/172.17.26.14; Rack: 98.9
Datatacenter: Austin; Host: /172.17.26.15; Rack: 98.9
Datatacenter: Austin; Host: /172.17.26.13; Rack: 98.9
Datatacenter: Austin; Host: /172.17.26.12; Rack: 98.9
Datatacenter: Austin; Host: /172.17.26.11; Rack: 98.9
INFO  19:11:51 New Cassandra host /172.17.26.12:9042 added
INFO  19:11:51 New Cassandra host /172.17.26.11:9042 added
INFO  19:11:51 New Cassandra host /172.17.26.13:9042 added
INFO  19:11:51 New Cassandra host /172.17.26.15:9042 added
Created schema. Sleeping 5s &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; propagation.
Warming up insert with 250000 iterations...
Failed to connect over JMX; not collecting these stats
Generating batches with [1..1] partitions and [1..1] rows (of [10000000..10000000] total rows in the partitions)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Number of distinct partitions is currently 2365 and growing.&lt;/p&gt;

&lt;p&gt;Is this what we expect? doesn&apos;t seem like 250,000 should have exhausted any partitions?&lt;/p&gt;</comment>
                            <comment id="14137856" author="benedict" created="Wed, 17 Sep 2014 19:52:31 +0000"  >&lt;p&gt;Hmm. This looks like a subtle &quot;bug&quot; with the latest stress when operating over such a small domain. But also highlights a problem with using it for this workload - I may need to do some tweaking tomorrow to make it suitable. To ensure we keep our procedurally generated state for the partition intact we only let one insert thread operate over a given partition at a time. If there is a conflict, we fall back to the underlying id distribution to avoid wasting time. This means that with a small domain we will steadily visit more and more partitions, but also that we will never have competing updates to the same partition, which is a glaring limitation (especially here). As it happens, the latest version of the procedural generation is reasonably easy to safely partition the work across multiple threads without mutual exclusivity, so I&apos;ll try to patch that ASAP.&lt;/p&gt;</comment>
                            <comment id="14137872" author="graham sanderson" created="Wed, 17 Sep 2014 20:02:21 +0000"  >&lt;p&gt;Cool, thanks, I&apos;ll wait on your patch (I have plenty of other things to do &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ). that said, am I relatively safe to upgrade the actual nodes to current head of 2.1 branch (and thusly pick up your latest GC monitoring stuff?) if I have a spare moment before then? Ideally I&apos;d upgrade to the last commit in 2.1 needed to be in place on test nodes for correct latest cassandra-stress operation.&lt;/p&gt;</comment>
                            <comment id="14137883" author="graham sanderson" created="Wed, 17 Sep 2014 20:10:18 +0000"  >&lt;p&gt;Note it is still where it was before, still doing stuff though (albeit very slowly)... sadly jstatd isn&apos;t running on this machine, and I have to kill my shell connection; I&apos;ll try again when I&apos;m on a stable network&lt;/p&gt;

&lt;p&gt;Here is current stack trace - little CPU activity but it is doing stuff I think&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Attaching to process ID 38130, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 24.60-b09
Deadlock Detection:

No deadlocks found.

&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38485: (state = BLOCKED)
 - sun.net.www.protocol.jar.Handler.parseContextSpec(java.net.URL, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=135, line=206 (Interpreted frame)
 - sun.net.www.protocol.jar.Handler.parseURL(java.net.URL, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=115, line=152 (Compiled frame)
 - java.net.URL.&amp;lt;init&amp;gt;(java.net.URL, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.net.URLStreamHandler) @bci=504, line=614 (Compiled frame)
 - java.net.URL.&amp;lt;init&amp;gt;(java.net.URL, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=4, line=482 (Compiled frame)
 - sun.misc.URLClassPath$JarLoader.checkResource(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, java.util.jar.JarEntry) @bci=13, line=757 (Compiled frame)
 - sun.misc.URLClassPath$JarLoader.getResource(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=60, line=842 (Compiled frame)
 - sun.misc.URLClassPath.getResource(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=53, line=199 (Compiled frame)
 - java.net.URLClassLoader$1.run() @bci=26, line=358 (Interpreted frame)
 - java.net.URLClassLoader$1.run() @bci=1, line=355 (Interpreted frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedExceptionAction, java.security.AccessControlContext) @bci=0 (Interpreted frame)
 - java.net.URLClassLoader.findClass(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=13, line=354 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=70, line=425 (Interpreted frame)
 - sun.misc.Launcher$AppClassLoader.loadClass(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=36, line=308 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=3, line=358 (Interpreted frame)
 - org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(org.jboss.netty.channel.ChannelEvent, java.lang.Throwable) @bci=1, line=640 (Interpreted frame)
 - org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext, org.jboss.netty.channel.ChannelEvent) @bci=51, line=599 (Compiled frame)
 - org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(org.jboss.netty.channel.ChannelEvent) @bci=36, line=582 (Compiled frame)
 - org.jboss.netty.channel.Channels.write(org.jboss.netty.channel.Channel, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.net.SocketAddress) @bci=22, line=704 (Interpreted frame)
 - org.jboss.netty.channel.Channels.write(org.jboss.netty.channel.Channel, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=3, line=671 (Interpreted frame)
 - org.jboss.netty.channel.AbstractChannel.write(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=2, line=248 (Interpreted frame)
 - com.datastax.driver.core.Connection.write(com.datastax.driver.core.Connection$ResponseCallback) @bci=128, line=342 (Interpreted frame)
 - com.datastax.driver.core.RequestHandler.query(com.datastax.driver.core.Host) @bci=113, line=126 (Interpreted frame)
 - com.datastax.driver.core.RequestHandler.sendRequest() @bci=45, line=100 (Interpreted frame)
 - com.datastax.driver.core.RequestHandler$1.run() @bci=26, line=175 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38293: (state = BLOCKED)
 - java.util.IdentityHashMap.init(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=13, line=261 (Interpreted frame)
 - java.util.IdentityHashMap.&amp;lt;init&amp;gt;() @bci=12, line=207 (Interpreted frame)
 - java.lang.Throwable.printStackTrace(java.lang.Throwable$PrintStreamOrWriter) @bci=4, line=649 (Interpreted frame)
 - java.lang.Throwable.printStackTrace(java.io.PrintStream) @bci=9, line=643 (Interpreted frame)
 - org.apache.cassandra.stress.StressMetrics$2.run() @bci=152, line=118 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38292: (state = BLOCKED)
 - ch.qos.logback.classic.turbo.ReconfigureOnChangeFilter.decide(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=51, line=114 (Compiled frame)
 - ch.qos.logback.classic.spi.TurboFilterList.getTurboFilterChainDecision(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=33, line=51 (Compiled frame)
 - ch.qos.logback.classic.LoggerContext.getTurboFilterChainDecision_2(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=39, line=272 (Compiled frame)
 - ch.qos.logback.classic.Logger.filterAndLog_2(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, org.slf4j.Marker, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=15, line=422 (Compiled frame)
 - ch.qos.logback.classic.Logger.trace(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=12, line=454 (Compiled frame)
 - com.datastax.driver.core.Connection.write(com.datastax.driver.core.Connection$ResponseCallback) @bci=110, line=340 (Compiled frame)
 - com.datastax.driver.core.RequestHandler.query(com.datastax.driver.core.Host) @bci=113, line=126 (Compiled frame)
 - com.datastax.driver.core.RequestHandler.sendRequest() @bci=45, line=100 (Compiled frame)
 - com.datastax.driver.core.SessionManager.execute(com.datastax.driver.core.RequestHandler$Callback, com.datastax.driver.core.Statement) @bci=22, line=446 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeQuery(com.datastax.driver.core.Message$Request, com.datastax.driver.core.Statement) @bci=24, line=482 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeAsync(com.datastax.driver.core.Statement) @bci=8, line=90 (Compiled frame)
 - com.datastax.driver.core.AbstractSession.execute(com.datastax.driver.core.Statement) @bci=2, line=52 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=311, line=101 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38291: (state = BLOCKED)
 - sun.misc.Unsafe.park(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - java.util.concurrent.locks.LockSupport.park(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=14, line=186 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt() @bci=1, line=834 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=72, line=994 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=24, line=1303 (Compiled frame)
 - com.google.common.util.concurrent.AbstractFuture$Sync.get() @bci=2, line=285 (Compiled frame)
 - com.google.common.util.concurrent.AbstractFuture.get() @bci=4, line=116 (Compiled frame)
 - com.google.common.util.concurrent.Uninterruptibles.getUninterruptibly(java.util.concurrent.Future) @bci=3, line=135 (Compiled frame)
 - com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly() @bci=1, line=170 (Compiled frame)
 - com.datastax.driver.core.AbstractSession.execute(com.datastax.driver.core.Statement) @bci=5, line=52 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=311, line=101 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38290: (state = BLOCKED)
 - sun.misc.Unsafe.park(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - java.util.concurrent.locks.LockSupport.park(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=14, line=186 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt() @bci=1, line=834 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=72, line=994 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=24, line=1303 (Compiled frame)
 - com.google.common.util.concurrent.AbstractFuture$Sync.get() @bci=2, line=285 (Compiled frame)
 - com.google.common.util.concurrent.AbstractFuture.get() @bci=4, line=116 (Compiled frame)
 - com.google.common.util.concurrent.Uninterruptibles.getUninterruptibly(java.util.concurrent.Future) @bci=3, line=135 (Compiled frame)
 - com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly() @bci=1, line=170 (Compiled frame)
 - com.datastax.driver.core.AbstractSession.execute(com.datastax.driver.core.Statement) @bci=5, line=52 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=311, line=101 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38289: (state = BLOCKED)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator.fill(java.util.Queue, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, org.apache.cassandra.stress.generate.values.Generator) @bci=298, line=294 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator.fill(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=101, line=252 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator.seek(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;[]) @bci=67, line=320 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator.reset(&lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=351, line=241 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition.iterator(&lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=8, line=87 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=53, line=70 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38288: (state = BLOCKED)
 - java.lang.StringCoding.encode(java.nio.charset.Charset, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=19, line=350 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.getBytes(java.nio.charset.Charset) @bci=23, line=939 (Interpreted frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=5, line=229 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=211 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38287: (state = BLOCKED)
 - org.apache.commons.math3.random.AbstractWell.setSeed(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=2, line=179 (Compiled frame)
 - org.apache.commons.math3.random.RandomDataGenerator.reSeed(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=5, line=761 (Compiled frame)
 - org.apache.commons.math3.random.RandomDataImpl.reSeed(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=5, line=461 (Compiled frame)
 - org.apache.commons.math3.distribution.AbstractRealDistribution.reseedRandomGenerator(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=15, line=247 (Compiled frame)
 - org.apache.cassandra.stress.generate.DistributionBoundApache.setSeed(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=5, line=58 (Compiled frame)
 - org.apache.cassandra.stress.generate.values.Generator.setSeed(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=10, line=53 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator.advance() @bci=106, line=342 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator$1$1.next() @bci=7, line=447 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator$1$1.next() @bci=1, line=433 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=144, line=79 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38286: (state = BLOCKED)
 - java.nio.charset.CharsetEncoder.&amp;lt;init&amp;gt;(java.nio.charset.Charset, &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;) @bci=5, line=226 (Compiled frame)
 - sun.nio.cs.UTF_8$Encoder.&amp;lt;init&amp;gt;(java.nio.charset.Charset) @bci=6, line=486 (Compiled frame)
 - sun.nio.cs.UTF_8$Encoder.&amp;lt;init&amp;gt;(java.nio.charset.Charset, sun.nio.cs.UTF_8$1) @bci=2, line=482 (Compiled frame)
 - sun.nio.cs.UTF_8.newEncoder() @bci=6, line=72 (Compiled frame)
 - java.lang.StringCoding.encode(java.nio.charset.Charset, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=348 (Compiled frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.getBytes(java.nio.charset.Charset) @bci=23, line=939 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=5, line=229 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=211 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38285: (state = BLOCKED)
 - sun.nio.cs.UTF_8.newEncoder() @bci=0, line=72 (Compiled frame)
 - java.lang.StringCoding.encode(java.nio.charset.Charset, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=348 (Compiled frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.getBytes(java.nio.charset.Charset) @bci=23, line=939 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=5, line=229 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=211 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38284: (state = BLOCKED)
 - com.datastax.driver.core.Metadata.quote(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=0, line=234 (Compiled frame)
 - com.datastax.driver.core.policies.TokenAwarePolicy.newQueryPlan(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, com.datastax.driver.core.Statement) @bci=47, line=104 (Compiled frame)
 - com.datastax.driver.core.RequestHandler.&amp;lt;init&amp;gt;(com.datastax.driver.core.SessionManager, com.datastax.driver.core.RequestHandler$Callback, com.datastax.driver.core.Statement) @bci=34, line=78 (Compiled frame)
 - com.datastax.driver.core.SessionManager.execute(com.datastax.driver.core.RequestHandler$Callback, com.datastax.driver.core.Statement) @bci=19, line=446 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeQuery(com.datastax.driver.core.Message$Request, com.datastax.driver.core.Statement) @bci=24, line=482 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeAsync(com.datastax.driver.core.Statement) @bci=8, line=90 (Compiled frame)
 - com.datastax.driver.core.AbstractSession.execute(com.datastax.driver.core.Statement) @bci=2, line=52 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=311, line=101 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38283: (state = BLOCKED)
 - java.util.Arrays.copyOf(&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=2271 (Compiled frame)
 - org.apache.cassandra.stress.generate.values.Bytes.generate() @bci=111, line=53 (Compiled frame)
 - org.apache.cassandra.stress.generate.values.Bytes.generate() @bci=1, line=30 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator.advance() @bci=120, line=343 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator$1$1.next() @bci=7, line=447 (Compiled frame)
 - org.apache.cassandra.stress.generate.Partition$MultiRowIterator$1$1.next() @bci=1, line=433 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=144, line=79 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38282: (state = BLOCKED)
 - sun.nio.cs.UTF_8.newEncoder() @bci=0, line=72 (Compiled frame)
 - java.lang.StringCoding.encode(java.nio.charset.Charset, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=348 (Compiled frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.getBytes(java.nio.charset.Charset) @bci=23, line=939 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=5, line=229 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=211 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38281: (state = BLOCKED)
 - ch.qos.logback.classic.turbo.ReconfigureOnChangeFilter.decide(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=51, line=114 (Compiled frame)
 - ch.qos.logback.classic.spi.TurboFilterList.getTurboFilterChainDecision(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=33, line=51 (Compiled frame)
 - ch.qos.logback.classic.LoggerContext.getTurboFilterChainDecision_1(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=34, line=262 (Compiled frame)
 - ch.qos.logback.classic.Logger.filterAndLog_1(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, org.slf4j.Marker, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=13, line=403 (Compiled frame)
 - ch.qos.logback.classic.Logger.trace(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=11, line=450 (Compiled frame)
 - com.datastax.driver.core.RequestHandler.sendRequest() @bci=38, line=99 (Compiled frame)
 - com.datastax.driver.core.SessionManager.execute(com.datastax.driver.core.RequestHandler$Callback, com.datastax.driver.core.Statement) @bci=22, line=446 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeQuery(com.datastax.driver.core.Message$Request, com.datastax.driver.core.Statement) @bci=24, line=482 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeAsync(com.datastax.driver.core.Statement) @bci=8, line=90 (Compiled frame)
 - com.datastax.driver.core.AbstractSession.execute(com.datastax.driver.core.Statement) @bci=2, line=52 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=311, line=101 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38280: (state = BLOCKED)
 - sun.misc.Unsafe.park(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - java.util.concurrent.locks.LockSupport.park(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=14, line=186 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt() @bci=1, line=834 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=72, line=994 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=24, line=1303 (Compiled frame)
 - com.google.common.util.concurrent.AbstractFuture$Sync.get() @bci=2, line=285 (Compiled frame)
 - com.google.common.util.concurrent.AbstractFuture.get() @bci=4, line=116 (Compiled frame)
 - com.google.common.util.concurrent.Uninterruptibles.getUninterruptibly(java.util.concurrent.Future) @bci=3, line=135 (Compiled frame)
 - com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly() @bci=1, line=170 (Compiled frame)
 - com.datastax.driver.core.AbstractSession.execute(com.datastax.driver.core.Statement) @bci=5, line=52 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=311, line=101 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38279: (state = BLOCKED)
 - java.nio.HeapByteBuffer.&amp;lt;init&amp;gt;(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=6, line=57 (Compiled frame)
 - java.nio.ByteBuffer.allocate(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=18, line=331 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serializeNoBoxing(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=512 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;) @bci=5, line=508 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=491 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38278: (state = BLOCKED)
 - java.nio.ByteBuffer.allocate(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=12, line=331 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serializeNoBoxing(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=512 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;) @bci=5, line=508 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=491 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38277: (state = BLOCKED)
 - java.nio.HeapByteBuffer.duplicate() @bci=0, line=107 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$BytesCodec.serialize(java.nio.ByteBuffer) @bci=1, line=290 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$BytesCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=277 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38276: (state = BLOCKED)
 - java.nio.HeapByteBuffer.&amp;lt;init&amp;gt;(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=6, line=57 (Compiled frame)
 - java.nio.ByteBuffer.allocate(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=18, line=331 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serializeNoBoxing(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=512 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;) @bci=5, line=508 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=491 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38275: (state = BLOCKED)
 - java.nio.HeapByteBuffer.&amp;lt;init&amp;gt;(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=6, line=57 (Compiled frame)
 - java.nio.ByteBuffer.allocate(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=18, line=331 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serializeNoBoxing(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=512 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;) @bci=5, line=508 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$IntCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=491 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38274: (state = BLOCKED)
 - ch.qos.logback.classic.turbo.ReconfigureOnChangeFilter.decide(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=51, line=114 (Compiled frame)
 - ch.qos.logback.classic.spi.TurboFilterList.getTurboFilterChainDecision(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=33, line=51 (Compiled frame)
 - ch.qos.logback.classic.LoggerContext.getTurboFilterChainDecision_1(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=34, line=262 (Compiled frame)
 - ch.qos.logback.classic.Logger.filterAndLog_1(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, org.slf4j.Marker, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=13, line=403 (Compiled frame)
 - ch.qos.logback.classic.Logger.trace(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=11, line=450 (Compiled frame)
 - com.datastax.driver.core.RequestHandler.sendRequest() @bci=38, line=99 (Compiled frame)
 - com.datastax.driver.core.SessionManager.execute(com.datastax.driver.core.RequestHandler$Callback, com.datastax.driver.core.Statement) @bci=22, line=446 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeQuery(com.datastax.driver.core.Message$Request, com.datastax.driver.core.Statement) @bci=24, line=482 (Compiled frame)
 - com.datastax.driver.core.SessionManager.executeAsync(com.datastax.driver.core.Statement) @bci=8, line=90 (Compiled frame)
 - com.datastax.driver.core.AbstractSession.execute(com.datastax.driver.core.Statement) @bci=2, line=52 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=311, line=101 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38273: (state = BLOCKED)
 - java.lang.StringCoding.encode(java.nio.charset.Charset, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=19, line=350 (Compiled frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.getBytes(java.nio.charset.Charset) @bci=23, line=939 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) @bci=5, line=229 (Compiled frame)
 - com.datastax.driver.core.TypeCodec$StringCodec.serialize(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=5, line=211 (Compiled frame)
 - com.datastax.driver.core.BoundStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=713, line=193 (Compiled frame)
 - com.datastax.driver.core.DefaultPreparedStatement.bind(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]) @bci=11, line=103 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaStatement.bindRow(org.apache.cassandra.stress.generate.Row) @bci=74, line=81 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run() @bci=161, line=80 (Compiled frame)
 - org.apache.cassandra.stress.Operation.timeWithRetry(org.apache.cassandra.stress.Operation$RunOp) @bci=30, line=96 (Compiled frame)
 - org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(org.apache.cassandra.stress.util.JavaDriverClient) @bci=11, line=149 (Compiled frame)
 - org.apache.cassandra.stress.StressAction$Consumer.run() @bci=315, line=318 (Compiled frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38271: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;) @bci=0 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;) @bci=35, line=270 (Interpreted frame)
 - sun.rmi.server.LoaderHandler.loadClassForName(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;) @bci=11, line=1219 (Interpreted frame)
 - sun.rmi.server.LoaderHandler.loadClass(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;) @bci=122, line=174 (Interpreted frame)
 - java.rmi.server.RMIClassLoader$2.loadClass(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;) @bci=3, line=637 (Interpreted frame)
 - java.rmi.server.RMIClassLoader.loadClass(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;) @bci=6, line=264 (Interpreted frame)
 - sun.rmi.server.MarshalInputStream.resolveClass(java.io.ObjectStreamClass) @bci=54, line=214 (Interpreted frame)
 - java.io.ObjectInputStream.readNonProxyDesc(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=108, line=1612 (Interpreted frame)
 - java.io.ObjectInputStream.readClassDesc(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=77, line=1517 (Interpreted frame)
 - java.io.ObjectInputStream.readNonProxyDesc(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=163, line=1622 (Interpreted frame)
 - java.io.ObjectInputStream.readClassDesc(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=77, line=1517 (Interpreted frame)
 - java.io.ObjectInputStream.readNonProxyDesc(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=163, line=1622 (Interpreted frame)
 - java.io.ObjectInputStream.readClassDesc(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=77, line=1517 (Interpreted frame)
 - java.io.ObjectInputStream.readOrdinaryObject(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=22, line=1771 (Interpreted frame)
 - java.io.ObjectInputStream.readObject0(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=389, line=1350 (Interpreted frame)
 - java.io.ObjectInputStream.readObject() @bci=19, line=370 (Interpreted frame)
 - sun.rmi.transport.StreamRemoteCall.executeCall() @bci=195, line=244 (Interpreted frame)
 - sun.rmi.server.UnicastRef.invoke(java.rmi.Remote, java.lang.reflect.Method, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=227, line=161 (Interpreted frame)
 - com.sun.jmx.remote.internal.PRef.invoke(java.rmi.Remote, java.lang.reflect.Method, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=9 (Interpreted frame)
 - javax.management.remote.rmi.RMIConnectionImpl_Stub.getDefaultDomain(javax.security.auth.Subject) @bci=19 (Interpreted frame)
 - javax.management.remote.rmi.RMIConnector$RMIClientCommunicatorAdmin.checkConnection() @bci=27, line=1616 (Interpreted frame)
 - com.sun.jmx.remote.internal.ClientCommunicatorAdmin$Checker.run() @bci=70, line=185 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38270: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Interpreted frame)
 - sun.misc.GC$Daemon.run() @bci=51, line=117 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38269: (state = BLOCKED)
 - java.util.Arrays.copyOfRange(&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=40, line=2694 (Compiled frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.&amp;lt;init&amp;gt;(&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=60, line=203 (Compiled frame)
 - java.lang.StringBuilder.toString() @bci=13, line=405 (Compiled frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.argumentTypesToString(java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;[]) @bci=74, line=2923 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.getDeclaredMethod(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;[]) @bci=52, line=2004 (Interpreted frame)
 - java.io.ObjectStreamClass.getPrivateMethod(java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;[], java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;) @bci=3, line=1431 (Interpreted frame)
 - java.io.ObjectStreamClass.access$1700(java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;[], java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;) @bci=4, line=72 (Interpreted frame)
 - java.io.ObjectStreamClass$2.run() @bci=257, line=500 (Interpreted frame)
 - java.io.ObjectStreamClass$2.run() @bci=1, line=468 (Interpreted frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedAction) @bci=0 (Interpreted frame)
 - java.io.ObjectStreamClass.&amp;lt;init&amp;gt;(java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;) @bci=106, line=468 (Interpreted frame)
 - java.io.ObjectStreamClass.lookup(java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=213, line=365 (Interpreted frame)
 - java.io.ObjectOutputStream.writeObject0(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) @bci=185, line=1133 (Interpreted frame)
 - java.io.ObjectOutputStream.writeObject(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=16, line=347 (Interpreted frame)
 - sun.rmi.transport.DGCImpl_Stub.dirty(java.rmi.server.ObjID[], &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, java.rmi.dgc.Lease) @bci=48 (Interpreted frame)
 - sun.rmi.transport.DGCClient$EndpointEntry.makeDirtyCall(java.util.Set, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=64, line=360 (Interpreted frame)
 - sun.rmi.transport.DGCClient$EndpointEntry.access$1600(sun.rmi.transport.DGCClient$EndpointEntry, java.util.Set, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=3, line=171 (Interpreted frame)
 - sun.rmi.transport.DGCClient$EndpointEntry$RenewCleanThread.run() @bci=233, line=574 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38268: (state = BLOCKED)
 - sun.misc.Unsafe.park(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - java.util.concurrent.locks.LockSupport.park(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=14, line=186 (Interpreted frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await() @bci=42, line=2043 (Interpreted frame)
 - java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take() @bci=24, line=1079 (Interpreted frame)
 - java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take() @bci=1, line=807 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.getTask() @bci=156, line=1068 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=26, line=1130 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38250: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread() @bci=0 (Compiled frame; information may be imprecise)
 - java.util.concurrent.locks.ReentrantReadWriteLock$Sync.tryAcquire(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0, line=395 (Interpreted frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=2, line=1197 (Interpreted frame)
 - java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock() @bci=5, line=945 (Interpreted frame)
 - org.jboss.netty.util.HashedWheelTimer$Worker.fetchExpiredTimeouts(java.util.List, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=12, line=407 (Interpreted frame)
 - org.jboss.netty.util.HashedWheelTimer$Worker.run() @bci=62, line=394 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38249: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread() @bci=0 (Compiled frame; information may be imprecise)
 - java.util.concurrent.locks.ReentrantReadWriteLock$Sync.isHeldExclusively() @bci=4, line=611 (Interpreted frame)
 - java.util.concurrent.locks.ReentrantReadWriteLock$Sync.tryRelease(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=1, line=373 (Interpreted frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.release(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=2, line=1260 (Compiled frame)
 - java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.unlock() @bci=5, line=1131 (Interpreted frame)
 - org.jboss.netty.util.HashedWheelTimer$Worker.fetchExpiredTimeouts(java.util.List, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=93, line=416 (Interpreted frame)
 - org.jboss.netty.util.HashedWheelTimer$Worker.run() @bci=62, line=394 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38248: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioClientBoss.run() @bci=1, line=42 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38247: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38246: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime() @bci=0 (Compiled frame; information may be imprecise)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=49, line=211 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38245: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38244: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38243: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38242: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38241: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38240: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38239: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38238: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime() @bci=0 (Compiled frame; information may be imprecise)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=49, line=211 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38237: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38236: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38235: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38234: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38233: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38232: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38231: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38230: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38229: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38228: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38227: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38226: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38225: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38224: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38223: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38222: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38221: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38220: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38219: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38218: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38217: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38216: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38215: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38214: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38213: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38212: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38211: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime() @bci=0 (Compiled frame; information may be imprecise)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=49, line=211 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38210: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38209: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38208: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38207: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38206: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38205: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38204: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38203: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38202: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38201: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38200: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38199: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38198: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38197: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38196: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38195: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38194: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38193: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38192: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38191: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38190: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38189: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38188: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38187: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38186: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38185: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38184: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38183: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38182: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38181: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38180: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38179: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38178: (state = BLOCKED)
 - ch.qos.logback.classic.turbo.ReconfigureOnChangeFilter.decide(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=51, line=114 (Compiled frame)
 - ch.qos.logback.classic.spi.TurboFilterList.getTurboFilterChainDecision(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=33, line=51 (Compiled frame)
 - ch.qos.logback.classic.LoggerContext.getTurboFilterChainDecision_1(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=34, line=262 (Compiled frame)
 - ch.qos.logback.classic.Logger.filterAndLog_1(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, org.slf4j.Marker, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=13, line=403 (Compiled frame)
 - ch.qos.logback.classic.Logger.trace(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=11, line=450 (Compiled frame)
 - com.datastax.driver.core.Connection$1.operationComplete(org.jboss.netty.channel.ChannelFuture) @bci=164, line=367 (Compiled frame)
 - org.jboss.netty.channel.DefaultChannelFuture.notifyListener(org.jboss.netty.channel.ChannelFutureListener) @bci=2, line=427 (Compiled frame)
 - org.jboss.netty.channel.DefaultChannelFuture.notifyListeners() @bci=12, line=413 (Compiled frame)
 - org.jboss.netty.channel.DefaultChannelFuture.setSuccess() @bci=42, line=362 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.write0(org.jboss.netty.channel.socket.nio.AbstractNioChannel) @bci=253, line=220 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromTaskLoop(org.jboss.netty.channel.socket.nio.AbstractNioChannel) @bci=9, line=151 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioChannel$WriteTask.run() @bci=22, line=335 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue() @bci=21, line=372 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=273, line=296 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38177: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38176: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38175: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38174: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38173: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38172: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38171: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38170: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38169: (state = BLOCKED)
 - java.io.UnixFileSystem.getLastModifiedTime(java.io.File) @bci=0 (Interpreted frame)
 - java.io.File.lastModified() @bci=29, line=937 (Interpreted frame)
 - ch.qos.logback.core.joran.spi.ConfigurationWatchList.changeDetected() @bci=52, line=76 (Interpreted frame)
 - ch.qos.logback.classic.turbo.ReconfigureOnChangeFilter.changeDetected(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=168 (Interpreted frame)
 - ch.qos.logback.classic.turbo.ReconfigureOnChangeFilter.decide(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=61, line=116 (Compiled frame)
 - ch.qos.logback.classic.spi.TurboFilterList.getTurboFilterChainDecision(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[], java.lang.Throwable) @bci=33, line=51 (Compiled frame)
 - ch.qos.logback.classic.LoggerContext.getTurboFilterChainDecision_1(org.slf4j.Marker, ch.qos.logback.classic.Logger, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=34, line=262 (Compiled frame)
 - ch.qos.logback.classic.Logger.filterAndLog_1(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, org.slf4j.Marker, ch.qos.logback.classic.Level, java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, java.lang.Throwable) @bci=13, line=403 (Compiled frame)
 - ch.qos.logback.classic.Logger.trace(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=11, line=450 (Compiled frame)
 - com.datastax.driver.core.Connection$1.operationComplete(org.jboss.netty.channel.ChannelFuture) @bci=164, line=367 (Compiled frame)
 - org.jboss.netty.channel.DefaultChannelFuture.notifyListener(org.jboss.netty.channel.ChannelFutureListener) @bci=2, line=427 (Compiled frame)
 - org.jboss.netty.channel.DefaultChannelFuture.notifyListeners() @bci=12, line=413 (Compiled frame)
 - org.jboss.netty.channel.DefaultChannelFuture.setSuccess() @bci=42, line=362 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.write0(org.jboss.netty.channel.socket.nio.AbstractNioChannel) @bci=253, line=220 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromTaskLoop(org.jboss.netty.channel.socket.nio.AbstractNioChannel) @bci=9, line=151 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioChannel$WriteTask.run() @bci=22, line=335 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue() @bci=21, line=372 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=273, line=296 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38168: (state = BLOCKED)
 - sun.nio.ch.EPollArrayWrapper.epollWait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=0 (Compiled frame; information may be imprecise)
 - sun.nio.ch.EPollArrayWrapper.poll(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=18, line=269 (Compiled frame)
 - sun.nio.ch.EPollSelectorImpl.doSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=28, line=79 (Compiled frame)
 - sun.nio.ch.SelectorImpl.lockAndDoSelect(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=37, line=87 (Compiled frame)
 - sun.nio.ch.SelectorImpl.select(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=30, line=98 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.SelectorUtil.select(java.nio.channels.Selector) @bci=4, line=68 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(java.nio.channels.Selector) @bci=1, line=415 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioSelector.run() @bci=56, line=212 (Compiled frame)
 - org.jboss.netty.channel.socket.nio.AbstractNioWorker.run() @bci=1, line=89 (Interpreted frame)
 - org.jboss.netty.channel.socket.nio.NioWorker.run() @bci=1, line=178 (Interpreted frame)
 - org.jboss.netty.util.ThreadRenamingRunnable.run() @bci=55, line=108 (Interpreted frame)
 - org.jboss.netty.util.internal.DeadLockProofWorker$1.run() @bci=14, line=42 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1145 (Interpreted frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=615 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run() @bci=11, line=745 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38163: (state = BLOCKED)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38162: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Interpreted frame)
 - java.lang.ref.ReferenceQueue.remove(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=44, line=135 (Interpreted frame)
 - java.lang.ref.ReferenceQueue.remove() @bci=2, line=151 (Interpreted frame)
 - java.lang.ref.Finalizer$FinalizerThread.run() @bci=36, line=209 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38161: (state = BLOCKED)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Interpreted frame)
 - java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait() @bci=2, line=503 (Interpreted frame)
 - java.lang.ref.Reference$ReferenceHandler.run() @bci=46, line=133 (Interpreted frame)


&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 38131: (state = BLOCKED)
 - sun.misc.Unsafe.park(&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) @bci=0 (Interpreted frame)
 - java.util.concurrent.locks.LockSupport.park(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;) @bci=14, line=186 (Interpreted frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt() @bci=1, line=834 (Interpreted frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=72, line=994 (Interpreted frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;) @bci=24, line=1303 (Interpreted frame)
 - java.util.concurrent.CountDownLatch.await() @bci=5, line=236 (Interpreted frame)
 - org.apache.cassandra.stress.StressAction.run(org.apache.cassandra.stress.operations.OpDistributionFactory, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, java.util.concurrent.TimeUnit, java.io.PrintStream) @bci=378, line=216 (Interpreted frame)
 - org.apache.cassandra.stress.StressAction.warmup(org.apache.cassandra.stress.operations.OpDistributionFactory) @bci=113, line=92 (Interpreted frame)
 - org.apache.cassandra.stress.StressAction.run() @bci=35, line=61 (Interpreted frame)
 - org.apache.cassandra.stress.Stress.main(java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[]) @bci=202, line=109 (Interpreted frame)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14137885" author="benedict" created="Wed, 17 Sep 2014 20:10:44 +0000"  >&lt;p&gt;It&apos;s hard to say for certain, but glancing at CHANGES.txt, it looks like 2.1.1-HEAD is same ballpark as safe to run as 2.1.0. There are a lot of changes merged, but mostly for tools like cqlsh, and the things in the core application are pretty minor. I don&apos;t officially endorse it though, since we only just shipped to 2.1.0, and haven&apos;t had much time to QA 2.1.1 &lt;/p&gt;</comment>
                            <comment id="14137887" author="graham sanderson" created="Wed, 17 Sep 2014 20:11:59 +0000"  >&lt;p&gt;Hmm - i&apos;ll definitely have to try again - it didn&apos;t respond to SIGHUP or non -F jstack, and isn&apos;t responding to ctrl+C, so maybe close to OOM&lt;/p&gt;</comment>
                            <comment id="14137888" author="graham sanderson" created="Wed, 17 Sep 2014 20:13:21 +0000"  >&lt;p&gt;Yeah, this is only a cluster for my testing this... I just don&apos;t want a massive breakage that stops it working completely! I&apos;ll install head&lt;/p&gt;</comment>
                            <comment id="14139341" author="benedict" created="Thu, 18 Sep 2014 19:03:51 +0000"  >&lt;p&gt;I&apos;ve uploaded a patch &lt;a href=&quot;https://github.com/belliottsmith/cassandra/tree/7964-simultinserts&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;, and another &lt;a href=&quot;https://github.com/belliottsmith/cassandra/tree/7964+7926&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt; which combines it with another stress patch that reduces the risk of OOM (although this risk is pretty low, and almost certainly not what you were hitting) - but as you scale thread count up it becomes more of a risk&lt;/p&gt;

&lt;p&gt;The main 7964 patch includes a couple of small bug fixes as well, and I&apos;ve tested it against your schema and some other related schemas that are trickier to process.&lt;/p&gt;

&lt;p&gt;One thing I would suggest considering is expanding the clustering column count to increase the speed of generation, as 1200 items is still quite a few to create for only sending 1 item, which might end up reducing contention server side. Possibly reduce to only 30-40 items per tier.&lt;/p&gt;</comment>
                            <comment id="14139982" author="graham sanderson" created="Fri, 19 Sep 2014 04:40:21 +0000"  >&lt;p&gt;Ok, cool thanks - I&apos;ve upgraded my 2.1.0 to 2.1.1... &lt;tt&gt;7cfd3ed&lt;/tt&gt; for what it&apos;s worth.&lt;/p&gt;

&lt;p&gt;I merged &lt;tt&gt;7964+7926&lt;/tt&gt; into that and updated my load machine with that.&lt;/p&gt;

&lt;p&gt;I switched to 40x40x40x40 clustering keys as suggested and changed the 10M entries in the command line args to 2560000 accordingly (it now runs successfully)&lt;/p&gt;

&lt;p&gt;The output is below&lt;/p&gt;

&lt;p&gt;Note I ended up with 1275 partitions (note during the warmup I ended up with 1025 so there may be a 1-off bug there also either in stress or my config!)... still not sure this is what we expect - each node has only seen about 3M mutations total (and I&apos;ve run the stress test twice - once without the GC stuff working)&lt;/p&gt;

&lt;p&gt;Anyway, let me know what you think - I won&apos;t be running more tests until tomorrow US time. &lt;/p&gt;

&lt;p&gt;Another question - what do you usually do to get comparable results; right now I have been blowing away the stresscql keyspace every time to at least keep compaction out of the equation. Given the length of the cassandra-stress run, I&apos;m not sure there is much to be gained by bouncing the cluster in between runs, but you probably know better having used it before.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Results:
op rate                   : 10595
partition rate            : 10595
row rate                  : 10595
latency mean              : 85.8
latency median            : 49.9
latency 95th percentile   : 360.0
latency 99th percentile   : 417.9
latency 99.9th percentile : 491.9
latency max               : 552.2
total gc count            : 3
total gc mb               : 19471
total gc time (s)         : 0
avg gc time(ms)           : 67
stdev gc time(ms)         : 5
Total operation time      : 00:00:40
Improvement over 609 threadCount: -1%
             id, total ops , adj row/s,    op/s,    pk/s,   row/s,    mean,     med,     .95,     .99,    .999,     max,   time,   stderr,  gc: #,  max ms,  sum ms,  sdv ms,      mb
  4 threadCount, 6939      ,        -0,     226,     226,     226,    17.6,    16.3,    40.3,    49.4,    51.1,   131.8,   30.6,  0.01464,      0,       0,       0,       0,       0
  8 threadCount, 11827     ,       385,     385,     385,     385,    20.7,    15.1,    47.5,    51.3,    82.1,   111.7,   30.7,  0.02511,      0,       0,       0,       0,       0
 16 threadCount, 19068     ,        -0,     612,     612,     612,    26.1,    28.8,    49.9,    60.6,    89.7,   172.1,   31.2,  0.01924,      0,       0,       0,       0,       0
 24 threadCount, 24441     ,        -0,     775,     775,     775,    30.9,    32.6,    52.1,    80.3,    88.3,   150.4,   31.5,  0.01508,      0,       0,       0,       0,       0
 36 threadCount, 36641     ,        -0,    1155,    1155,    1155,    31.1,    30.2,    59.0,    78.1,    89.7,   172.1,   31.7,  0.01127,      0,       0,       0,       0,       0
 54 threadCount, 55220     ,        -0,    1730,    1730,    1730,    31.1,    29.1,    54.5,    74.3,    84.3,   164.4,   31.9,  0.00883,      0,       0,       0,       0,       0
 81 threadCount, 83460     ,        -0,    2609,    2609,    2609,    31.0,    28.9,    51.2,    71.0,    79.2,   175.4,   32.0,  0.01678,      0,       0,       0,       0,       0
121 threadCount, 140705    ,        -0,    4402,    4402,    4402,    27.4,    25.8,    49.7,    53.2,    70.3,   302.8,   32.0,  0.01438,      2,     462,     462,      11,   12889
181 threadCount, 226213    ,        -0,    7116,    7116,    7116,    25.4,    24.2,    48.8,    51.8,    60.1,   279.0,   31.8,  0.01335,      1,     230,     230,       0,    6401
271 threadCount, 320658    ,        -0,   10089,   10089,   10089,    26.8,    25.0,    48.3,    50.1,    57.4,   297.0,   31.8,  0.01256,      2,     425,     425,      14,   12786
406 threadCount, 342451    ,        -0,   10609,   10609,   10609,    38.2,    40.3,    59.0,    77.5,    81.7,   142.4,   32.3,  0.00920,      0,       0,       0,       0,       0
609 threadCount, 381058    ,        -0,   10651,   10651,   10651,    57.0,    48.6,   171.5,   224.4,   248.4,   342.0,   35.8,  0.01234,      1,      66,      66,       0,    6520
913 threadCount, 432518    ,        -0,   10595,   10595,   10595,    85.8,    49.9,   360.0,   417.9,   491.9,   552.2,   40.8,  0.01471,      3,     200,     200,       5,   19471
END
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14139986" author="graham sanderson" created="Fri, 19 Sep 2014 04:42:13 +0000"  >&lt;p&gt;FYI in case I didn&apos;t mention it, this is a 5 node cluster, and we&apos;re running LOCAL_QUORUM and repl factor 3&lt;/p&gt;</comment>
                            <comment id="14140007" author="graham sanderson" created="Fri, 19 Sep 2014 05:08:52 +0000"  >&lt;p&gt;Didn&apos;t want to deep dive, but out of curiosity I did do one run configured for a single partition&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Results:
op rate                   : 5760
partition rate            : 5760
row rate                  : 5760
latency mean              : 158.7
latency median            : 151.2
latency 95th percentile   : 221.5
latency 99th percentile   : 262.3
latency 99.9th percentile : 282.4
latency max               : 396.0
total gc count            : 3
total gc mb               : 18779
total gc time (s)         : 0
avg gc time(ms)           : 67
stdev gc time(ms)         : 26
Total operation time      : 00:00:35
Improvement over 609 threadCount: 4%
             id, total ops , adj row/s,    op/s,    pk/s,   row/s,    mean,     med,     .95,     .99,    .999,     max,   time,   stderr,  gc: #,  max ms,  sum ms,  sdv ms,      mb
  4 threadCount, 6782      ,        -0,     120,     120,     120,    33.3,    43.8,    50.6,    63.0,    83.9,    85.7,   56.6,  0.01940,      0,       0,       0,       0,       0
  8 threadCount, 6629      ,        -0,     212,     212,     212,    37.7,    39.1,    57.0,    75.0,   127.2,   138.2,   31.3,  0.00868,      0,       0,       0,       0,       0
 16 threadCount, 27730     ,        -0,     566,     566,     566,    28.2,    26.2,    50.6,    75.7,   125.5,   170.4,   49.0,  0.01963,      0,       0,       0,       0,       0
 24 threadCount, 51763     ,       798,     796,     796,     796,    30.1,    29.5,    51.0,    76.9,    90.8,   144.4,   65.0,  0.01977,      2,     203,     203,      10,   12877
 36 threadCount, 74953     ,        -0,    1253,    1253,    1253,    28.7,    27.8,    50.7,    60.5,    79.6,   308.0,   59.8,  0.01938,      0,       0,       0,       0,       0
 54 threadCount, 56948     ,        -0,    1807,    1807,    1807,    29.8,    27.6,    52.6,    63.1,    78.1,   121.1,   31.5,  0.01170,      3,     176,     176,      12,   19816
 81 threadCount, 74856     ,        -0,    2369,    2369,    2369,    34.1,    33.2,    57.2,    67.6,    76.6,   108.6,   31.6,  0.00946,      0,       0,       0,       0,       0
121 threadCount, 100526    ,        -0,    3158,    3158,    3158,    38.2,    37.8,    63.4,    78.9,    89.1,   446.6,   31.8,  0.01805,      2,      93,      93,       1,   13063
181 threadCount, 277875    ,        -0,    4491,    4491,    4491,    40.2,    40.2,    63.1,    79.1,    94.0,   679.7,   61.9,  0.01985,      5,     286,     286,      28,   32541
271 threadCount, 169870    ,        -0,    5205,    5205,    5205,    52.0,    49.2,    84.9,   110.5,   140.5,   843.9,   32.6,  0.01320,      3,     157,     157,      11,   19408
406 threadCount, 187985    ,      5648,    5555,    5555,    5555,    73.0,    64.2,   122.1,   156.0,   285.3,   848.6,   33.8,  0.01421,      3,     173,     173,      12,   19570
609 threadCount, 201184    ,      5540,    5534,    5534,    5534,   110.1,   101.1,   160.5,   230.1,   378.9,   555.6,   36.4,  0.01917,      3,     163,     163,      17,   19709
913 threadCount, 205466    ,      5787,    5760,    5760,    5760,   158.7,   151.2,   221.5,   262.3,   282.4,   396.0,   35.7,  0.01335,      3,     200,     200,      26,   18779
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Obviously I don&apos;t know if the slowdown is on the load end or the server end (though there is some GC increase here - we&apos;ll see what the patch for this issue does). Note that if this is a synchronization problem with the load generator still, we do know for a fact that hinting is a good way of turning a large partition domain into a small partition domain (so I&apos;ll obviously be testing that too, though that isn&apos;t apples to apples either).&lt;/p&gt;</comment>
                            <comment id="14140011" author="graham sanderson" created="Fri, 19 Sep 2014 05:10:01 +0000"  >&lt;p&gt;Oh I should mention the warmup ended up generating 20 partitions, and during the cause of the whole test, it got bumped to 21... maybe that&apos;ll give you an &quot;ah ha&quot; moment.&lt;/p&gt;</comment>
                            <comment id="14140087" author="benedict" created="Fri, 19 Sep 2014 06:40:31 +0000"  >&lt;p&gt;I meant to mention, but forgot, in case you worried about this: for simplicity and performance, we don&apos;t guarantee that we only generate as many partitions as the sample defines, we only guarantee that when sampling we follow that distribution (and so will ignore any overshoot that we generated). Essentially any thread sampling the working set that hits &lt;em&gt;past the end of the set&lt;/em&gt; (i.e. either into an area not yet populated, or one that has been finished and not replaced) will asynchronously generate a new seed, write to it, and &lt;em&gt;then&lt;/em&gt; update the sample. This is because updating the sample is itself costly, and for workloads where the work is likely to be completed in one shot we don&apos;t want to incur that cost.&lt;/p&gt;

&lt;p&gt;That said it should be quite possible to decide upfront if the workload meets these characteristics and, if it doesn&apos;t (like this one), update the sample in advance.&lt;/p&gt;

&lt;p&gt;There&apos;s also sort-of an off-by-1 error for the 1025, though. We&apos;re not taking the minimum index off from the generated sample index, so with a distribution 1..1024, we&apos;re never sampling index 0, and our sample size will be 1025. I&apos;ve pushed a fix for this.&lt;/p&gt;</comment>
                            <comment id="14140158" author="benedict" created="Fri, 19 Sep 2014 08:06:04 +0000"  >&lt;p&gt;force pushed another update that both enforces the sample size &lt;em&gt;if it is likely that multiple visits will be needed&lt;/em&gt;, and also reduces local contention by changing the saved seed position to a scalar from an int[], which can be incremented much more cheaply&lt;/p&gt;</comment>
                            <comment id="14141764" author="graham sanderson" created="Sat, 20 Sep 2014 05:30:03 +0000"  >&lt;p&gt;Thanks - I updated, and have run 1/16/256/1024 partitions against both my baseline 2.1.1, and patched (with 7546.21_v1.txt) 2.1.1 using heap_buffers and all 5 nodes up.&lt;/p&gt;

&lt;p&gt;Things look promising so far, I need to run with a node down (I assume I take it out of the seeds list), and also with native_objects/native_buffers... this is something I can do in parallel with other work, but will still take some time.&lt;/p&gt;

&lt;p&gt;Random cassandra-stress question: Generally it seems that the threadCount where it stops seems to be the one after it has started overloading the system. Maybe this is what is wanted for the final results, but generally it seems that the latency of this final run is not representative of the previous one or two thread counts which were doing about the same number of ops/second (hence why it stopped). Not sure what the thinking is on that, I&apos;m sure it has come up before.&lt;/p&gt;</comment>
                            <comment id="14141766" author="graham sanderson" created="Sat, 20 Sep 2014 05:30:54 +0000"  >&lt;p&gt;I&apos;ll try and make a graph of the data I have so far at some point over the weekend anyway.&lt;/p&gt;</comment>
                            <comment id="14141812" author="graham sanderson" created="Sat, 20 Sep 2014 06:58:56 +0000"  >&lt;p&gt;Make of this what you will (these are the 1-1024 partitions with and without the patch as mentioned above)... You can clearly see the higher mem usage without the patch. Beyond that there looks to be some noise from compaction. As expected, the patch helps under high contention... dosen&apos;t seem to hurt at the low end (some of the low thread count stuff looks like it might be cassandra-stress related), and I&apos;m not sure yet if the small differences in the middle thread counts are just noise.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12670191/12670191_graphs1.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="14141858" author="benedict" created="Sat, 20 Sep 2014 07:53:43 +0000"  >&lt;p&gt;In general the idea for the auto mode is to get a general overview of the various conditions, &lt;em&gt;especially&lt;/em&gt; when run in target uncertainty (err&amp;lt;) mode, which is the default mode. I&apos;ve just committed a minor change, that was previously talked about, that supports running all thread counts in the range unconditionally, however it will log a warning if you run this with target uncertainty mode, as the workloads will be different.&lt;/p&gt;

&lt;p&gt;Really we should be tearing down and rebuilding the cluster between runs. However it looks like the results are pretty much a wash for all modes except those where high contention on a single partition is to be expected. It&apos;s a bit strange that .999%ile is higher with the patch for the highest thread counts but lower contention, but that may be noise. Certainly the heap reduction looks promising.&lt;/p&gt;

&lt;p&gt;It would be great to see runs where the workload is consistently defined (i.e. n=, instead of err&amp;lt;), and to get the raw output&lt;/p&gt;</comment>
                            <comment id="14150409" author="graham sanderson" created="Sat, 27 Sep 2014 04:55:17 +0000"  >&lt;p&gt;Busy week - I I just did native_objects runs. It actually really helps out here a lot too - seems like native allocation starts taking a hit with too much concurrency.&lt;/p&gt;

&lt;p&gt;I was about to do the hinting graphs, but cassandra-stress seems to be pulling the server names from the server (so I can&apos;t start it with one node down) - or maybe I can, and I should just ignore the errors (I just tried giving it 4/5 nodes on the command line)&lt;/p&gt;

&lt;p&gt;What would you like me to do for n= ... I do have the full raw output for all these runs&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12671621/12671621_graph2_7546.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
</comment>
                            <comment id="14153612" author="jbellis" created="Tue, 30 Sep 2014 19:24:57 +0000"  >&lt;p&gt;Yuki will take over review.&lt;/p&gt;</comment>
                            <comment id="14153780" author="graham sanderson" created="Tue, 30 Sep 2014 21:28:30 +0000"  >&lt;p&gt;Just a little update:&lt;/p&gt;

&lt;p&gt;I have numbers for one node down &amp;amp; hinting with heap_buffers, I just need to re-run a few tests since there were a couple of spurious points (might have be due to not using a totally clean cluster every time - this is not a cluster I can easily re-create) that I want to verify before I post them.&lt;/p&gt;

&lt;p&gt;Generally this patch thus far seems to be good, and while there is a non-&quot;sweet spot&quot; where it can be mildly harmful, this is basically on the knife edge of where you are almost overcommitting your hardware, which is probably not where people are hoping to be running.&lt;/p&gt;

&lt;p&gt;The other point to note is that while the excess GC allocation here does not cause huge issues, in a busy cluster which had a huge number of resident slabs to start off with, this can cause major knock on GC - head-aches (with slabs spilling into old gen with other garbage etc)... The GC issue isn&apos;t as much of a problem with the native allocators in 2.1 (though they do seem to become a bottleneck under high allocation rates), the fact that it is still generally faster with this patch suggests we should keep it on for those too.&lt;/p&gt;</comment>
                            <comment id="14155589" author="graham sanderson" created="Wed, 1 Oct 2014 21:35:15 +0000"  >&lt;p&gt;Adding this as patch available since 7546.21_v1.txt is strictly ready for review (by another set of eyes) if poorly named&lt;/p&gt;</comment>
                            <comment id="14163922" author="graham sanderson" created="Wed, 8 Oct 2014 18:29:55 +0000"  >&lt;p&gt;Attached graph3_7546.png, which is heap buffer and one node down (hinting)... things look good - there is some noise in .999&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12673649/12673649_graph3_7546.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="14163937" author="graham sanderson" created="Wed, 8 Oct 2014 18:35:35 +0000"  >&lt;p&gt;Added better named patch (cassandra-2.1-7546.txt) rebased against current 2.1 head and with log statement switched from WARN to DEBUG&lt;/p&gt;

&lt;p&gt;I will do the native_objects test with hinting on, but as far as I&apos;m concerned this patch is ready to go (For me hints and OpsCenter.pdps are the only tables which it affects (the latter because it is highly bursty, dumping lots of (concurrent) low cardinality partioned writes periodically, and as such is neither here nor there when it comes to evaluating this fix))&lt;/p&gt;</comment>
                            <comment id="14163964" author="graham sanderson" created="Wed, 8 Oct 2014 18:48:33 +0000"  >&lt;p&gt;Made minor change to patch (uploaded as cassandra-2.1-7546-v2.txt) - Having switch to DEBUG logging of heavily contended partitions, I changed Memtable flush code to only count the contended partitions when DEBUG logging is enabled (since it involves a volatile read per partition which might have a cost - though likely not a big deal - on non intel h/w)&lt;/p&gt;</comment>
                            <comment id="14164208" author="yukim" created="Wed, 8 Oct 2014 21:33:54 +0000"  >&lt;p&gt;+1 to v2 (it lacks Locks.java but I assume it is unchanged).&lt;/p&gt;

&lt;p&gt;My concern is use of monitorEnter/monitorExit as I&apos;m not sure the downside of those, but I don&apos;t think I have better alternative.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=graham.sanderson&quot; class=&quot;user-hover&quot; rel=&quot;graham.sanderson&quot;&gt;graham.sanderson&lt;/a&gt; can I go ahead and commit to 2.1 or you want me to wait until you do native_objects test?&lt;/p&gt;</comment>
                            <comment id="14167613" author="graham sanderson" created="Fri, 10 Oct 2014 22:00:40 +0000"  >&lt;p&gt;Sorry &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt;, I somehow missed your update - I&apos;m about to attach the test results here... note they show much higher GC issues in native_obj than heap_buffers without the fix, I&apos;m guessing because the spinning is much faster with native_obj. Note as with heap_buffers and hints, we are getting a little bit of noise in the results (likely from compaction)&lt;/p&gt;

&lt;p&gt;As for monitorEnter/monitorExit Benedict and I had a discussion about that above (I originally had it with either multiple copies of the code, or nested functions), but it complicated stuff, and I was unable to prove any issues with monitorEnter or monitorExit (or indeed reference any, other than some vague suspicions I had that maybe this excludes biased locking  or anything else which assumes these are neatly paired in a stack frame). In any case we don&apos;t really care because if we are using them we&apos;ve already proved we&apos;re contended, and the monitor would be inflated anyway. The other issue was the use of Unsafe, but Benedict seemed fine with that also, since without Unsafe (which most people have) you just get the old behavior&lt;/p&gt;

&lt;p&gt;So, I say go ahead and promote the fix as is (yes current 2.1 trunk seemed to have Locks.java already added - I didn&apos;t diff them, but I peeked briefly and it looked about the same)&lt;/p&gt;

&lt;p&gt;It is possible someone will find a usage scenario that this makes slower, in which case we can look at that, but I suspect as mentioned before, in all of these cases where we degrade performance it is probably because the original performance is just on a lucky knife edge between under utilization, and a complete mess!&lt;/p&gt;

&lt;p&gt;Finally, I&apos;ll summarize what Benedict said up above, that whilst we could add a switch for this, this is really an internal implementation fix, the goal of which is eventually that there should be no bottleneck even when mutating the same partition (something he planned to address in version &amp;gt;=3.0 with lazy updates, and repair on read)&lt;/p&gt;</comment>
                            <comment id="14167618" author="graham sanderson" created="Fri, 10 Oct 2014 22:01:51 +0000"  >&lt;p&gt;See previous comment for discussion (note I also realized I didn&apos;t change the labels correctly on graph3, but that was of heap_buffers and hinting)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12674273/12674273_graph4_7546.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="14167633" author="graham sanderson" created="Fri, 10 Oct 2014 22:08:19 +0000"  >&lt;p&gt;Just to be clear from the graphs - that is 70gig of GC during the 913 thread count run!&lt;/p&gt;</comment>
                            <comment id="14168489" author="graham sanderson" created="Sun, 12 Oct 2014 03:04:24 +0000"  >&lt;p&gt;For what it&apos;s worth, I happened to be poking around the JVM source today debugging something, and so stopped to take a look - the monitorEnter does indeed just revoke any bios and inflate the lock... so seems perfectly fine for our purposes (since we expect lock contention anyway)&lt;/p&gt;</comment>
                            <comment id="14168839" author="graham sanderson" created="Sun, 12 Oct 2014 23:23:51 +0000"  >&lt;p&gt;Oops - my bad - Locks.java wasn&apos;t already committed (I though Benedict might have added it as part of something else), but it turns out I just had it in my working copy not commit... uploaded cassandra-2.1-7546-v3.txt which adds it back&lt;/p&gt;</comment>
                            <comment id="14168841" author="graham sanderson" created="Sun, 12 Oct 2014 23:27:15 +0000"  >&lt;p&gt;Actually this is the first time I&apos;ve looked at the Locks.java code in detail myself - it should probably not throw an AssertionError on failure (it should log) since it is optional - and maybe the methods should be renamed to indicate that it may be a noop&lt;/p&gt;</comment>
                            <comment id="14169560" author="yukim" created="Mon, 13 Oct 2014 17:14:17 +0000"  >&lt;p&gt;I committed v3, thanks!&lt;/p&gt;

&lt;p&gt;AssertionError is fine there imo, since Cassandra relies on Unsafe and when AE is thrown, it is logged as ERROR through default exception handler and both methods in Locks be no-op.&lt;/p&gt;</comment>
                            <comment id="14175425" author="graham sanderson" created="Fri, 17 Oct 2014 19:28:00 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt; ... note I just noticed that in CHANGES.txt this is recorded in the &quot;merge from 2.0:&quot; section&lt;/p&gt;</comment>
                            <comment id="14184132" author="jbellis" created="Sat, 25 Oct 2014 15:33:34 +0000"  >&lt;p&gt;fixed CHANGES&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12686866">CASSANDRA-6534</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12727215">CASSANDRA-7545</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12656871" name="7546.20.txt" size="4110" author="benedict" created="Mon, 21 Jul 2014 14:17:51 +0000"/>
                            <attachment id="12656926" name="7546.20_2.txt" size="5739" author="graham sanderson" created="Mon, 21 Jul 2014 19:04:13 +0000"/>
                            <attachment id="12657233" name="7546.20_3.txt" size="11136" author="graham sanderson" created="Wed, 23 Jul 2014 00:19:45 +0000"/>
                            <attachment id="12657784" name="7546.20_4.txt" size="16248" author="graham sanderson" created="Fri, 25 Jul 2014 06:08:31 +0000"/>
                            <attachment id="12658175" name="7546.20_5.txt" size="16730" author="graham sanderson" created="Mon, 28 Jul 2014 17:00:56 +0000"/>
                            <attachment id="12660115" name="7546.20_6.txt" size="18804" author="benedict" created="Wed, 6 Aug 2014 10:44:53 +0000"/>
                            <attachment id="12660173" name="7546.20_7.txt" size="18575" author="graham sanderson" created="Wed, 6 Aug 2014 16:43:00 +0000"/>
                            <attachment id="12660926" name="7546.20_7b.txt" size="20580" author="graham sanderson" created="Mon, 11 Aug 2014 05:45:50 +0000"/>
                            <attachment id="12656885" name="7546.20_alt.txt" size="15901" author="graham sanderson" created="Mon, 21 Jul 2014 16:51:17 +0000"/>
                            <attachment id="12665599" name="7546.20_async.txt" size="22525" author="graham sanderson" created="Sun, 31 Aug 2014 07:23:36 +0000"/>
                            <attachment id="12665848" name="7546.21_v1.txt" size="11844" author="graham sanderson" created="Tue, 2 Sep 2014 06:04:40 +0000"/>
                            <attachment id="12673665" name="cassandra-2.1-7546-v2.txt" size="10801" author="graham sanderson" created="Wed, 8 Oct 2014 18:48:33 +0000"/>
                            <attachment id="12674436" name="cassandra-2.1-7546-v3.txt" size="11932" author="graham sanderson" created="Sun, 12 Oct 2014 23:23:50 +0000"/>
                            <attachment id="12673652" name="cassandra-2.1-7546.txt" size="10714" author="graham sanderson" created="Wed, 8 Oct 2014 18:35:35 +0000"/>
                            <attachment id="12671621" name="graph2_7546.png" size="250549" author="graham sanderson" created="Sat, 27 Sep 2014 04:52:50 +0000"/>
                            <attachment id="12673649" name="graph3_7546.png" size="259107" author="graham sanderson" created="Wed, 8 Oct 2014 18:29:55 +0000"/>
                            <attachment id="12674273" name="graph4_7546.png" size="237442" author="graham sanderson" created="Fri, 10 Oct 2014 22:01:51 +0000"/>
                            <attachment id="12670191" name="graphs1.png" size="307456" author="graham sanderson" created="Sat, 20 Sep 2014 06:55:51 +0000"/>
                            <attachment id="12665536" name="hint_spikes.png" size="26031" author="graham sanderson" created="Sat, 30 Aug 2014 04:11:03 +0000"/>
                            <attachment id="12655655" name="suggestion1.txt" size="30404" author="graham sanderson" created="Tue, 15 Jul 2014 01:02:36 +0000"/>
                            <attachment id="12655704" name="suggestion1_21.txt" size="26937" author="graham sanderson" created="Tue, 15 Jul 2014 06:32:44 +0000"/>
                            <attachment id="12665535" name="young_gen_gc.png" size="76748" author="graham sanderson" created="Sat, 30 Aug 2014 04:11:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>22.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[graham.sanderson]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>405323</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 4 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1xr4n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>405350</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12326830">2.0.9</customfieldvalue>
    <customfieldvalue id="12324159">2.1 rc3</customfieldvalue>
    <customfieldvalue id="12327256">2.1.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>yukim</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[yukim]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>