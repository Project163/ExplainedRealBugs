<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:12:56 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-744] [multi_]get_count should take a SlicePredicate</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-744</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;both to make it more flexible, and to emphasize that counting &quot;everything&quot; is as bad as slicing it&lt;/p&gt;</description>
                <environment></environment>
        <key id="12446705">CASSANDRA-744</key>
            <summary>[multi_]get_count should take a SlicePredicate</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10003" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Low</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="slebresne">Sylvain Lebresne</assignee>
                                    <reporter username="jbellis">Jonathan Ellis</reporter>
                        <labels>
                    </labels>
                <created>Tue, 26 Jan 2010 17:53:58 +0000</created>
                <updated>Tue, 16 Apr 2019 09:33:29 +0000</updated>
                            <resolved>Tue, 20 Apr 2010 14:53:01 +0000</resolved>
                                        <fixVersion>0.7 beta 1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="12858150" author="slebresne" created="Sat, 17 Apr 2010 14:55:05 +0000"  >&lt;p&gt;Got some time to kill, so I&apos;m proposing two (quite trivial) patches.&lt;br/&gt;
First one add the SlicePredicate to get_count, second one add&lt;br/&gt;
a multiget_count.&lt;/p&gt;</comment>
                            <comment id="12858916" author="gdusbabek" created="Tue, 20 Apr 2010 14:49:35 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12858919" author="gdusbabek" created="Tue, 20 Apr 2010 14:53:01 +0000"  >&lt;p&gt;committed.  Thanks Sylvain!&lt;/p&gt;</comment>
                            <comment id="12865512" author="bendiken" created="Sat, 8 May 2010 23:10:33 +0000"  >&lt;p&gt;Would it be possible to specify multiget_count in terms of i64 return values instead of i32, pretty please?&lt;/p&gt;</comment>
                            <comment id="12865518" author="jbellis" created="Sun, 9 May 2010 00:19:02 +0000"  >&lt;p&gt;that&apos;s a little silly, isn&apos;t it?  surely counting over 2B columns isn&apos;t a good idea in the first place...&lt;/p&gt;</comment>
                            <comment id="12865915" author="bendiken" created="Mon, 10 May 2010 20:43:56 +0000"  >&lt;p&gt;Is it? I apologize if I have too high expectations for Cassandra, but we&apos;ve already used rows with up to one hundred million columns. Problems at that scale have been mostly GC churn and compaction related, and since it appears that such issues are being worked on (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1014&quot; title=&quot;GC storming, possible memory leak&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1014&quot;&gt;&lt;del&gt;CASSANDRA-1014&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-16&quot; title=&quot;Memory efficient compactions &quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-16&quot;&gt;&lt;del&gt;CASSANDRA-16&lt;/del&gt;&lt;/a&gt;, and the like), a mere one order of magnitude more doesn&apos;t seem like &lt;b&gt;too&lt;/b&gt; much of a stretch for Cassandra to eventually handle on sufficiently big iron.&lt;/p&gt;</comment>
                            <comment id="12866098" author="slebresne" created="Tue, 11 May 2010 08:56:52 +0000"  >&lt;p&gt;That&apos;s not really the problem of having row with more than MAX_INTEGER columns. What is silly&lt;br/&gt;
is counting those. Counting all the columns in a row is the same than reading the whole row. Excepted&lt;br/&gt;
that you don&apos;t send all those columns over the network. So a call to count will never need a i64 as any &lt;br/&gt;
call that would need an i64 will very likely timeout. &lt;br/&gt;
That&apos;s the &quot;raison d&apos;&#234;tre&quot; of this patch. You can count a huge row by paging (but it&apos;s probably a better&lt;br/&gt;
idea to not count those huge row at all if you can afford it as even with paging this is expensive).&lt;/p&gt;</comment>
                            <comment id="12866113" author="bendiken" created="Tue, 11 May 2010 09:54:07 +0000"  >&lt;p&gt;I guess it depends on your use case. We have one where each Cassandra row represents a very large set, each column name being a 20-byte SHA-1 binary hash identifying an object in that set and each such column&apos;s value being simply the empty string. As I mentioned, we&apos;ve stored up to a hundred million columns per row in this manner. As each SHA-1 column takes 35.5 bytes of space in the SStables, that&apos;s a total of less than 4 gigs of disk storage for a row with 100 million columns. On the big iron we&apos;ve run this on, these are not &lt;em&gt;inherently&lt;/em&gt; infeasible numbers. The limiting factor is Cassandra&apos;s implementation, not the hardware.&lt;/p&gt;

&lt;p&gt;Counting the number of objects in a given set (i.e. the number of columns in a given row) is an important operation for us. It&apos;s fine for the count to take a while, as it is still vastly (many, many orders of magnitude) faster than the infeasible alternative of directly counting the source data (also stored in Cassandra, but apart) that the set data is derived from, which would (prior to your multi_get_count patch, which does alleviate it a little) involve performing an individual get_count operation for each of hundreds of millions (soon to be billions) of distinct source rows.&lt;/p&gt;

&lt;p&gt;Now, given existing GC and SStable compaction issues that we&apos;ve run into with Cassandra 0.6, we&apos;re in practice now manually sharding the larger sets into multiple rows of a size that Cassandra has less issues dealing with (on our hardware, up to 15-20 million columns per row is performing very well).&lt;/p&gt;

&lt;p&gt;t expect that as Cassandra evolves and issues are fixed, we can keep upping this, and I don&apos;t see anything inherently ridiculous about rows of the size I&apos;ve mentioned. It seems a little shortsighted to place incidental limits on the protocol, but then again I suppose the protocol will have broken backwards compatibility a couple of times by the time I get around to testing 2 billion columns with some future Cassandra 1.x version - so perhaps we can revisit this in a year or two &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12866121" author="slebresne" created="Tue, 11 May 2010 10:25:57 +0000"  >&lt;p&gt;But then again, I do not even contest the fact that it could be useful to have row with billions of columns. As you mentioned, &lt;br/&gt;
there is a few limitations to that today but they will hopefully be lifted soon enough. I still think that, despite these current limitations,  &lt;br/&gt;
the sharding  of the row you already do is useful at some point (but maybe this point is 1 billion columns in your case) if only for the &lt;br/&gt;
sake of load distribution. But that&apos;s not my point at all.&lt;/p&gt;

&lt;p&gt;My point is that the time it takes to perform one given individual get_count() operation that count n columns is as long as the time it takes &lt;br/&gt;
to read those n columns (from server-side at least, the only advantage of get_count() over get_slice() is that you don&apos;t send those n columns &lt;br/&gt;
over the network). So, if n &amp;gt; 2 billion, it will takes a bit of time to perform this one get_count() operation, even in a year or two, even with&lt;br/&gt;
super duper SSD drives and even if each column is quite small. I haven&apos;t tried (I don&apos;t have a super duper SSD drive and I don&apos;t live one &lt;br/&gt;
or two year from now) and it&apos;s always dangerous to make assumption in the future, but I bet it will take far time than any reasonable &lt;br/&gt;
timeout you would want to set for your Cassandra operations. &lt;/p&gt;

&lt;p&gt;Hence, the right way to count a row with 2 billions+ columns is to do multiple get_count() operations using a predicate to limit the number &lt;br/&gt;
of counted columns by each individual get_count() operation and sum all those results client side. But then only the sum needs be a 64 bit &lt;br/&gt;
integer, not the result of get_count().   &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12442050" name="ASF.LICENSE.NOT.GRANTED--0001-Add-SlicePredicate-to-get_count.patch" size="4662" author="slebresne" created="Sat, 17 Apr 2010 14:55:05 +0000"/>
                            <attachment id="12442051" name="ASF.LICENSE.NOT.GRANTED--0002-Add-mutliget_count.patch" size="4984" author="slebresne" created="Sat, 17 Apr 2010 14:55:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>19849</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            15 years, 29 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0g0t3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>91561</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12961"><![CDATA[Low]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>