<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:41:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-6345] Endpoint cache invalidation causes CPU spike (on vnode rings?)</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-6345</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;We&apos;ve observed that events which cause invalidation of the endpoint cache (update keyspace, add/remove nodes, etc) in AbstractReplicationStrategy result in several seconds of thundering herd behavior on the entire cluster. &lt;/p&gt;

&lt;p&gt;A thread dump shows over a hundred threads (I stopped counting at that point) with a backtrace like this:&lt;/p&gt;

&lt;p&gt;        at java.net.Inet4Address.getAddress(Inet4Address.java:288)&lt;br/&gt;
        at org.apache.cassandra.locator.TokenMetadata$1.compare(TokenMetadata.java:106)&lt;br/&gt;
        at org.apache.cassandra.locator.TokenMetadata$1.compare(TokenMetadata.java:103)&lt;br/&gt;
        at java.util.TreeMap.getEntryUsingComparator(TreeMap.java:351)&lt;br/&gt;
        at java.util.TreeMap.getEntry(TreeMap.java:322)&lt;br/&gt;
        at java.util.TreeMap.get(TreeMap.java:255)&lt;br/&gt;
        at com.google.common.collect.AbstractMultimap.put(AbstractMultimap.java:200)&lt;br/&gt;
        at com.google.common.collect.AbstractSetMultimap.put(AbstractSetMultimap.java:117)&lt;br/&gt;
        at com.google.common.collect.TreeMultimap.put(TreeMultimap.java:74)&lt;br/&gt;
        at com.google.common.collect.AbstractMultimap.putAll(AbstractMultimap.java:273)&lt;br/&gt;
        at com.google.common.collect.TreeMultimap.putAll(TreeMultimap.java:74)&lt;br/&gt;
        at org.apache.cassandra.utils.SortedBiMultiValMap.create(SortedBiMultiValMap.java:60)&lt;br/&gt;
        at org.apache.cassandra.locator.TokenMetadata.cloneOnlyTokenMap(TokenMetadata.java:598)&lt;br/&gt;
        at org.apache.cassandra.locator.AbstractReplicationStrategy.getNaturalEndpoints(AbstractReplicationStrategy.java:104)&lt;br/&gt;
        at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:2671)&lt;br/&gt;
        at org.apache.cassandra.service.StorageProxy.performWrite(StorageProxy.java:375)&lt;/p&gt;

&lt;p&gt;It looks like there&apos;s a large amount of cost in the TokenMetadata.cloneOnlyTokenMap that AbstractReplicationStrategy.getNaturalEndpoints is calling each time there is a cache miss for an endpoint. It seems as if this would only impact clusters with large numbers of tokens, so it&apos;s probably a vnodes-only issue.&lt;/p&gt;

&lt;p&gt;Proposal: In AbstractReplicationStrategy.getNaturalEndpoints(), cache the cloned TokenMetadata instance returned by TokenMetadata.cloneOnlyTokenMap(), wrapping it with a lock to prevent stampedes, and clearing it in clearEndpointCache(). Thoughts?&lt;/p&gt;</description>
                <environment>&lt;p&gt;30 nodes total, 2 DCs&lt;br/&gt;
Cassandra 1.2.11&lt;br/&gt;
vnodes enabled (256 per node)&lt;/p&gt;</environment>
        <key id="12679044">CASSANDRA-6345</key>
            <summary>Endpoint cache invalidation causes CPU spike (on vnode rings?)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jbellis">Jonathan Ellis</assignee>
                                    <reporter username="rbranson">Rick Branson</reporter>
                        <labels>
                    </labels>
                <created>Wed, 13 Nov 2013 16:06:06 +0000</created>
                <updated>Tue, 16 Apr 2019 09:32:00 +0000</updated>
                            <resolved>Tue, 26 Nov 2013 20:11:15 +0000</resolved>
                                        <fixVersion>1.2.13</fixVersion>
                    <fixVersion>2.0.4</fixVersion>
                                        <due></due>
                            <votes>2</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="13821532" author="jbellis" created="Wed, 13 Nov 2013 17:05:30 +0000"  >&lt;p&gt;Interesting.  Could we optimize cOTM instead?  That would definitely be the simplest solution.&lt;/p&gt;

&lt;p&gt;E.g. it looks like TreeMultimap.putAll actually loops over each entry and calls put one at a time which is the worst-case scenario for binary tree rebalancing &amp;#8211; quadratic time.&lt;/p&gt;</comment>
                            <comment id="13821556" author="jbellis" created="Wed, 13 Nov 2013 17:30:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;it looks like TreeMultimap.putAll actually loops over each entry and calls put one at a time&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t see a way around this: &lt;a href=&quot;https://code.google.com/p/guava-libraries/issues/detail?id=1579&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://code.google.com/p/guava-libraries/issues/detail?id=1579&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13821562" author="benedict" created="Wed, 13 Nov 2013 17:34:59 +0000"  >&lt;p&gt;A Treap? Can be cheaply built, cheaply merged and cheaply cloned.&lt;/p&gt;

&lt;p&gt;Also, anything cheaply cloneable would work for that operation. A SnapTree that is wrapped to support multi-map functionality would also work.&lt;/p&gt;</comment>
                            <comment id="13821599" author="jbellis" created="Wed, 13 Nov 2013 18:01:51 +0000"  >&lt;p&gt;Yes.  Too bad the implementation classes like AbstractSortedKeySortedSetMultimap are package-private.&lt;/p&gt;</comment>
                            <comment id="13821811" author="jbellis" created="Wed, 13 Nov 2013 20:47:36 +0000"  >&lt;p&gt;Actually I think a STM multimap would still get messy quickly since you need to do a &quot;deep&quot; clone &amp;#8211; cloning the top-level Map would leave the values (sub-collections) sharing a reference.&lt;/p&gt;</comment>
                            <comment id="13821816" author="benedict" created="Wed, 13 Nov 2013 20:52:46 +0000"  >&lt;p&gt;Just have the wrapper make any updates to a collection replace the collection instead of modifying it.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;NB: I haven&amp;#39;t looked to see if this would have any negative performance implications on the update side, I&amp;#39;m assuming the reads are more frequent and/or collections small... if not, a Treap is probably the better choice as my old Jjoost implementation (IIRC) supports snapshotting and multiple values are dealt with inside the tree itself, not as a collection&amp;#93;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="13821831" author="jbellis" created="Wed, 13 Nov 2013 21:06:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;Proposal: In AbstractReplicationStrategy.getNaturalEndpoints(), cache the cloned TokenMetadata instance returned by TokenMetadata.cloneOnlyTokenMap(), wrapping it with a lock to prevent stampedes, and clearing it in clearEndpointCache().&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why not just use a sharded lock to prevent stampedes directly w/o the caching complexity, as in the attached?&lt;/p&gt;</comment>
                            <comment id="13821861" author="jbellis" created="Wed, 13 Nov 2013 21:26:40 +0000"  >&lt;p&gt;I see, with vnodes we have enough ranges that we can have a thundering herd even if each range only clones once.&lt;/p&gt;

&lt;p&gt;v2 attached with the approach you described originally.&lt;/p&gt;</comment>
                            <comment id="13821884" author="rbranson" created="Wed, 13 Nov 2013 21:44:04 +0000"  >&lt;p&gt;Attached a patch we deployed to production that fixed the issue.&lt;/p&gt;</comment>
                            <comment id="13821888" author="rbranson" created="Wed, 13 Nov 2013 21:48:40 +0000"  >&lt;p&gt;CPU user% graph during the rollout of the patch I attached on 1 DC (15 nodes) of the cluster. Around ~21:05 the patch starts to roll out and spikes are seen. The node in question receives the patch at ~21:30, and afterwards the spikes are gone. The rollout finishes at ~21:45.&lt;/p&gt;</comment>
                            <comment id="13821979" author="jbellis" created="Wed, 13 Nov 2013 23:26:43 +0000"  >&lt;p&gt;I have to admit I like it better without the custom wrapper class. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13822027" author="rbranson" created="Thu, 14 Nov 2013 00:25:22 +0000"  >&lt;p&gt;Well, I started writing the patch this morning and I don&apos;t write multi-threaded Java code every day, so I&apos;m overly careful &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; The only theoretical advantage to my patch is that it allows concurrent readers.&lt;/p&gt;</comment>
                            <comment id="13823274" author="rbranson" created="Fri, 15 Nov 2013 04:43:50 +0000"  >&lt;p&gt;Unfortunately both of the patches suffer from a deadlock, since the invalidation and fill are wrapped up in TokenMetadata&apos;s locks.&lt;/p&gt;

&lt;p&gt;T1 acquires cache read lock&lt;br/&gt;
T2 acquires TokenMetadata write lock&lt;br/&gt;
T1 acquires cache write lock on miss&lt;br/&gt;
T2 is blocked on cache write lock trying to invalidate&lt;br/&gt;
T1 is blocked on TokenMetadata read lock trying to cloneOnlyTokenMap to fill the cache&lt;/p&gt;

&lt;p&gt;Trying to work on a fix.&lt;/p&gt;</comment>
                            <comment id="13823375" author="rbranson" created="Fri, 15 Nov 2013 07:28:35 +0000"  >&lt;p&gt;Attached a new patch with the deadlock fixed. We&apos;re running this on a production cluster.&lt;/p&gt;

&lt;p&gt;The primary issue was the callback for invalidation from TokenMetadata to all of the registered AbstractReplicationStrategy instances. This was asking for it anyway, so in the patch I replaced the &quot;push&quot; invalidation with simple versioning of the TokenMetadata endpoints. TokenMetadata bumps it&apos;s version number each time the cache would need to be invalidated, and AbstractReplicationStrategy checks it&apos;s version when it needs to do a read, invalidating if necessary. This gets the invalidation out of the gossip threads and into the RPC threads, which is probably a good thing. The only thing I&apos;m not super crazy about is the extra hot path read lock acquisition on TokenMetadata.getEndpointVersion(), which might be avoidable.&lt;/p&gt;</comment>
                            <comment id="13825086" author="jbellis" created="Mon, 18 Nov 2013 03:52:04 +0000"  >&lt;p&gt;I think we can craft a simpler solution (v3) by using an AtomicReference to the TM clone.  This removes the possibility of deadlock since clearEndpointCache now only makes non-blocking calls.&lt;/p&gt;

&lt;p&gt;I&apos;ve also refined it to use a Striped&amp;lt;Lock&amp;gt; per-keyToken, as well as synchronizing the TM clone itself, since concurrent endpoint computation is fine.&lt;/p&gt;</comment>
                            <comment id="13825614" author="rbranson" created="Mon, 18 Nov 2013 18:51:43 +0000"  >&lt;p&gt;I like the simpler approach. I still think the callbacks for invalidation are asking for it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I also think perhaps the stampede lock should be more explicit than a synchronized lock on &quot;this&quot; to prevent unintended blocking from future modifications.&lt;/p&gt;

&lt;p&gt;Either way, I think the only material concern I have is the order that TokenMetadata changes get applied to the caches in AbstractReplicationStrategy instances. Shouldn&apos;t the invalidation take place on all threads in all instances of AbstractReplicationStrategy before returning from an endpoint-mutating write operation in TokenMetadata? It seems as if just setting the cache to empty would allow a period of time where TokenMetadata write methods had returned but not all threads have seen the mutation yet because they are still holding onto the old clone of TM. This might be alright though, I&apos;m not sure. Thoughts?&lt;/p&gt;</comment>
                            <comment id="13827319" author="jbellis" created="Wed, 20 Nov 2013 04:25:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;It seems as if just setting the cache to empty would allow a period of time where TokenMetadata write methods had returned but not all threads have seen the mutation yet&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not 100% sure this is what you&apos;re talking about, but I see this problem with the existing code (and my v3):&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Thread 1                 Thread 2        
getNaturalEndpoints      
cloneOnlyTokenMap        
                         invalidateCachedTokenEndpointValues
endpoints = calculate
cacheEndpoint [based on the now-invalidated token map]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So it doesn&apos;t quite work.  We&apos;d need to introduce another AtomicReference on the cache, so that invalidate could create a new Map (so it doesn&apos;t matter if someone updates the old one).  But I think you&apos;re right that getting rid of the callback approach entirely is better.&lt;/p&gt;</comment>
                            <comment id="13827329" author="jbellis" created="Wed, 20 Nov 2013 04:40:41 +0000"  >&lt;p&gt;v4 attached that uses a versioning approach like yours.  I dropped the readLock acquire on version read since it&apos;s not necessary to block callers during the update.  (A few extra over-broad replica set operations won&apos;t hurt.)&lt;/p&gt;</comment>
                            <comment id="13828097" author="rbranson" created="Wed, 20 Nov 2013 20:49:03 +0000"  >&lt;p&gt;+100 at removing those pub/sub callbacks &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The concurrency issues I bring up are probably because I&apos;m unfamiliar with the &quot;guarantees&quot; needed by TokenMetadata updates. It looks like the current release code is subject to the issue I brought up, where method calls on TokenMetadata that change state return successfully before all threads applying mutations have &quot;seen&quot; the update. There will be some mutations in progress that are using &quot;stale&quot; token data to apply writes even after TokenMetadata write methods returns as successful. So this does not appear to be a regression, but I&apos;m just being overly cautious having been burned by these sort of double-caching scenarios before. You bring up the point that over-broad operations are ok, and I agree, but I&apos;m more concerned about operations that are too narrow. It seems that unless I&apos;m missing something either is possible with the current release code, and thus these patches as well (including mine).&lt;/p&gt;

&lt;p&gt;TokenMetadata#updateNormalTokens is (implicitly) relying on the removeFromMoving call to bump the version, but the tokenToEndpointMap is updated afterwards, which means internal data is updated after the version is bumped. IMHO to be defensive, any time the write lock is acquired in TokenMetadata, the version should be bumped in the finally block before the lock is released. I don&apos;t think this is exposing a bug in the existing patch though, because cloneOnlyTokenMap will be blocked until the write lock is released in the finally block.&lt;/p&gt;

&lt;p&gt;Is the idea with the striped lock on the endpoint cache in AbstractReplicationStrategy to help smooth out the stampede effect when the &quot;global&quot; lock on the cached TM gets released after the fill? How much do you think it&apos;s worth the extra complexity? FWIW, my v2 patch suffers from this issue and it hasn&apos;t reared itself in production. The write load for the machines in the cluster I&apos;ve been looking at is comparatively low though compared to many others at 6-7k/sec peak on an 8-core box.&lt;/p&gt;</comment>
                            <comment id="13830007" author="jbellis" created="Fri, 22 Nov 2013 14:29:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;It seems that unless I&apos;m missing something either is possible with the current release code, and thus these patches as well&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Technically correct, but in practice we&apos;re in pretty good shape.  The sequence is:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Add the changing node to pending ranges&lt;/li&gt;
	&lt;li&gt;Sleep for RING_DELAY so everyone else starts including the new target in their writes&lt;/li&gt;
	&lt;li&gt;Flush data to be transferred&lt;/li&gt;
	&lt;li&gt;Send over data for writes that happened before (1)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Step 1 happens on every coordinator.  2-4 only happen on the node that is giving up a token range.&lt;/p&gt;

&lt;p&gt;The guarantee we need is that any write that happens before the pending range change, completes before the subsequent flush.&lt;/p&gt;

&lt;p&gt;Even if we used TM.lock to protect the entire ARS sequence (guaranteeing that no local write is in progress once the PRC happens) we could still receive writes from other nodes that began their PRC change later.  &lt;/p&gt;

&lt;p&gt;So we rely on the RING_DELAY (30s) sleep.  I suppose a GC pause for instance at just the wrong time could theoretically mean a mutation against the old state gets sent out late, but I don&apos;t see how we can improve it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;IMHO to be defensive, any time the write lock is acquired in TokenMetadata, the version should be bumped in the finally block before the lock is released&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Haven&apos;t thought this through as much.  What are you saying we should bump that we weren&apos;t calling invalidate on before?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is the idea with the striped lock on the endpoint cache in AbstractReplicationStrategy to help smooth out the stampede effect when the &quot;global&quot; lock on the cached TM gets released after the fill?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m trying to avoid a minor stampede on calculateNaturalEndpoints (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-3881&quot; title=&quot;reduce computational complexity of processing topology changes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-3881&quot;&gt;&lt;del&gt;CASSANDRA-3881&lt;/del&gt;&lt;/a&gt;) but it&apos;s probably premature optimization.  v5 attached w/o that.&lt;/p&gt;</comment>
                            <comment id="13832783" author="rbranson" created="Tue, 26 Nov 2013 17:33:23 +0000"  >&lt;p&gt;Thanks for taking the time to explain the consistency story. It makes perfect sense. &lt;/p&gt;

&lt;p&gt;My defensiveness comment suggested bumping the version number each time the TM write lock is released, which would be in addition to the existing invalidations. You&apos;re probably a much better gauge on the usefulness of this, so up to you.&lt;/p&gt;

&lt;p&gt;Really nice that the v5 patch is so compact. Two minor comments: the endpointsLock declaration is still in there, and not to be all nitpicky but there are two typos in the comments (&quot;wo we keep&quot; and &quot;clone got invalidted&quot;).&lt;/p&gt;</comment>
                            <comment id="13832986" author="jbellis" created="Tue, 26 Nov 2013 20:11:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;My defensiveness comment suggested bumping the version number each time the TM write lock is released, which would be in addition to the existing invalidations.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay.  I&apos;m going to leave this be then, because I don&apos;t want to accidentally start invalidating the cache unnecessarily because one of those operations was more common than I thought.  Could address in trunk if you want to open a ticket.&lt;/p&gt;

&lt;p&gt;Committed v5 w/ nits fixed.&lt;/p&gt;</comment>
                            <comment id="13833150" author="rbranson" created="Tue, 26 Nov 2013 22:26:43 +0000"  >&lt;p&gt;LGTM!&lt;/p&gt;</comment>
                            <comment id="13843569" author="cburroughs" created="Mon, 9 Dec 2013 21:24:10 +0000"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;private volatile long ringVersion = 0;

ringVersion++;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If there is something tricky here that makes an increment on a volatile okay then it deserves a comment.&lt;/p&gt;</comment>
                            <comment id="13843717" author="jbellis" created="Mon, 9 Dec 2013 23:50:02 +0000"  >&lt;p&gt;We don&apos;t care about keeping an accurate count, only that once it&apos;s done with that block it&apos;s higher than it was before.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12671666">CASSANDRA-6127</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12614030" name="6345-rbranson-v2.txt" size="10155" author="rbranson" created="Fri, 15 Nov 2013 07:28:35 +0000"/>
                            <attachment id="12613706" name="6345-rbranson.txt" size="5583" author="rbranson" created="Wed, 13 Nov 2013 21:52:21 +0000"/>
                            <attachment id="12613697" name="6345-v2.txt" size="3314" author="jbellis" created="Wed, 13 Nov 2013 21:26:40 +0000"/>
                            <attachment id="12614329" name="6345-v3.txt" size="4296" author="jbellis" created="Mon, 18 Nov 2013 03:52:04 +0000"/>
                            <attachment id="12614786" name="6345-v4.txt" size="8766" author="jbellis" created="Wed, 20 Nov 2013 04:40:41 +0000"/>
                            <attachment id="12615340" name="6345-v5.txt" size="7779" author="jbellis" created="Fri, 22 Nov 2013 14:29:57 +0000"/>
                            <attachment id="12613688" name="6345.txt" size="2738" author="jbellis" created="Wed, 13 Nov 2013 21:06:52 +0000"/>
                            <attachment id="12613704" name="half-way-thru-6345-rbranson-patch-applied.png" size="32169" author="rbranson" created="Wed, 13 Nov 2013 21:48:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[jbellis]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>358409</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 50 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ps9r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>358699</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12325022">1.2.11</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>rbranson</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[rbranson]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>