<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:42:48 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-6622] Streaming session failures during node replace of same address</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-6622</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;When using replace_address, Gossiper ApplicationState is set to hibernate, which is a down state. We are seeing that the peer nodes are seeing streaming plan request even before the Gossiper on them marks the replacing node as dead. As a result, streaming on peer nodes convicts the replacing node by closing the stream handler.  &lt;br/&gt;
I think, making the StorageService thread on the replacing node, sleep for BROADCAST_INTERVAL before bootstrapping, would avoid this scenario.&lt;/p&gt;


&lt;p&gt;Relevant logs from peer node (see that the Gossiper on peer node mark the replacing node as down, 2 secs after  the streaming init request):&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; INFO [STREAM-INIT-/x.x.x.x:46436] 2014-01-26 20:42:24,388 StreamResultFuture.java (line 116) [Stream #5c6cd940-86ca-11e3-90a0-411b913c0e88] Received streaming plan for Bootstrap
....
 INFO [GossipTasks:1] 2014-01-26 20:42:25,240 StreamResultFuture.java (line 181) [Stream #5c6cd940-86ca-11e3-90a0-411b913c0e88] Session with /x.x.x.x is complete
 WARN [GossipTasks:1] 2014-01-26 20:42:25,240 StreamResultFuture.java (line 210) [Stream #5c6cd940-86ca-11e3-90a0-411b913c0e88] Stream failed
 INFO [GossipStage:1] 2014-01-26 20:42:25,242 Gossiper.java (line 850) InetAddress /x.x.x.x is now DOWN
ERROR [STREAM-IN-/x.x.x.x] 2014-01-26 20:42:25,766 StreamSession.java (line 410) [Stream #5c6cd940-86ca-11e3-90a0-411b913c0e88] Streaming error occurred
java.lang.RuntimeException: Outgoing stream handler has been closed
        at org.apache.cassandra.streaming.ConnectionHandler.sendMessage(ConnectionHandler.java:175)
        at org.apache.cassandra.streaming.StreamSession.prepare(StreamSession.java:436)
        at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:358)
        at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:293)
        at java.lang.Thread.run(Thread.java:722)
 INFO [STREAM-IN-/x.x.x.x] 2014-01-26 20:42:25,768 StreamResultFuture.java (line 181) [Stream #5c6cd940-86ca-11e3-90a0-411b913c0e88] Session with /x.x.x.x is complete
 WARN [STREAM-IN-/x.x.x.x] 2014-01-26 20:42:25,768 StreamResultFuture.java (line 210) [Stream #5c6cd940-86ca-11e3-90a0-411b913c0e88] Stream failed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;RHEL6, cassandra-2.0.4&lt;/p&gt;</environment>
        <key id="12691296">CASSANDRA-6622</key>
            <summary>Streaming session failures during node replace of same address</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="brandon.williams">Brandon Williams</assignee>
                                    <reporter username="ravilr">Ravi Prasad</reporter>
                        <labels>
                    </labels>
                <created>Sun, 26 Jan 2014 22:25:26 +0000</created>
                <updated>Tue, 16 Apr 2019 09:31:55 +0000</updated>
                            <resolved>Tue, 11 Feb 2014 23:44:46 +0000</resolved>
                                        <fixVersion>1.2.16</fixVersion>
                    <fixVersion>2.0.6</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13882495" author="brandon.williams" created="Mon, 27 Jan 2014 01:17:47 +0000"  >&lt;p&gt;The failure detector shouldn&apos;t be tracking any nodes with a dead state (since they&apos;re already dead.)  It sounds like you&apos;re doing a replace on the same IP address, before the failure detector has marked the original node being replaced down.&lt;/p&gt;</comment>
                            <comment id="13882538" author="ravilr" created="Mon, 27 Jan 2014 03:09:50 +0000"  >&lt;p&gt;yes, i was replacing the node with same ip address, which was dead before.  Despite being dead before, since we set the state to hibernate and due to the generation change of the replacing node at startup, it gets marked down again.  StorageService thread already sleeps for broadcast_interval, if the replacing address is not same as broadcast address. the attached patch sleeps for same address also.&lt;/p&gt;</comment>
                            <comment id="13882833" author="brandon.williams" created="Mon, 27 Jan 2014 14:18:26 +0000"  >&lt;p&gt;If the node is already marked dead, the FailureDetector isn&apos;t going to convict() again just because it receives a dead state like hibernate.  It will call onDead again for subscribers, but StreamSession doesn&apos;t care about that.  What it does care about, however, is onRestart being called since there was a generation change, and that will fail the session.&lt;/p&gt;

&lt;p&gt;That said, certainly delaying the stream until gossip has propagated should solve the issue, though I&apos;m not sure streaming should be failing based on gossip/FD events (/cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt;).  However, instead of sleeping for BROADCAST_INTERVAL we can save half the time and sleep for RING_DELAY, since if gossip hasn&apos;t propagated fully by then there are bigger problems.  WDYT &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thobbs&quot; class=&quot;user-hover&quot; rel=&quot;thobbs&quot;&gt;thobbs&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13888319" author="thobbs" created="Fri, 31 Jan 2014 23:43:03 +0000"  >&lt;p&gt;Your explanation seems reasonable, and after some quick testing the patch does seem to resolve the problem.  I agree that RING_DELAY should be fine.  I am interested to hear what &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt; has to say about the stream breaking, though.&lt;/p&gt;</comment>
                            <comment id="13888330" author="yukim" created="Fri, 31 Jan 2014 23:54:41 +0000"  >&lt;p&gt;Whether to fail streaming session on gossip/FD events is discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-3569&quot; title=&quot;Failure detector downs should not break streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-3569&quot;&gt;&lt;del&gt;CASSANDRA-3569&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&apos;m fine with failing at gossip DOWN not to push too much data to, say, &quot;choked&quot; node. But thinking it again, I wonder about the frequency the case actually happens...&lt;/p&gt;</comment>
                            <comment id="13888343" author="brandon.williams" created="Sat, 1 Feb 2014 00:19:02 +0000"  >&lt;p&gt;Maybe our best bet here is to not call onRestart for dead states.&lt;/p&gt;</comment>
                            <comment id="13888731" author="brandon.williams" created="Sat, 1 Feb 2014 20:40:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe our best bet here is to not call onRestart for dead states.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Let&apos;s give it shot.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ravilr&quot; class=&quot;user-hover&quot; rel=&quot;ravilr&quot;&gt;ravilr&lt;/a&gt; can you see if this patch solves the problem for you?&lt;/p&gt;</comment>
                            <comment id="13889242" author="ravilr" created="Mon, 3 Feb 2014 05:50:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe our best bet here is to not call onRestart for dead states.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Seeing the same error in original description, with the above patch on cassandra-2.0.&lt;/p&gt;</comment>
                            <comment id="13889546" author="brandon.williams" created="Mon, 3 Feb 2014 15:16:13 +0000"  >&lt;p&gt;Can you attach logs from both the replacing node and the node that is failing the stream session?&lt;/p&gt;</comment>
                            <comment id="13889856" author="ravilr" created="Mon, 3 Feb 2014 20:11:42 +0000"  >&lt;p&gt;In attached logs, .72 was the replacing node, .73 is where the streaming session failed. I had trace logging turned on in .73 for org.apache.cassandra.gms.  Looks like, it is FailureDetector is convicting.  I have to mention that this was with &apos;0001-don-t-signal-restart-of-dead-states.txt&apos; applied on cassandra-2.0.4.&lt;/p&gt;</comment>
                            <comment id="13892506" author="ravilr" created="Wed, 5 Feb 2014 20:03:02 +0000"  >&lt;p&gt;I&apos;m seeing FailureDetector notifying listeners every second invoked through GossiperTask&apos;s doStatusCheck(). Tested sleeping for RING_DELAY (instead of BROADCAST_INTERVAL) before bootstrap, works without any stream session closure. &lt;/p&gt;</comment>
                            <comment id="13893755" author="brandon.williams" created="Thu, 6 Feb 2014 20:32:57 +0000"  >&lt;p&gt;Can you try the patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6658&quot; title=&quot;Nodes flap once at startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6658&quot;&gt;&lt;del&gt;CASSANDRA-6658&lt;/del&gt;&lt;/a&gt;?  I think that&apos;s the problem here, the incorrect FD signal is sent with an extremely high phi value, tripping StreamSession&apos;s convict with greater than two times the normal phi.&lt;/p&gt;</comment>
                            <comment id="13894191" author="ravilr" created="Fri, 7 Feb 2014 04:38:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can you try the patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6658&quot; title=&quot;Nodes flap once at startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6658&quot;&gt;&lt;del&gt;CASSANDRA-6658&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Didn&apos;t help. What i&apos;m seeing is, the other nodes in the ring take around 2-3 seconds for PHI on the replacing node to drop below convict threshold. But, they also receive the stream plan from the replacing node with in 2 seconds of starting of replacing node. &lt;/p&gt;</comment>
                            <comment id="13894609" author="brandon.williams" created="Fri, 7 Feb 2014 15:06:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;What i&apos;m seeing is, the other nodes in the ring take around 2-3 seconds for PHI on the replacing node to drop below convict threshold.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You mean rise above it, so the node is still being convicted?  Can you add new logs?  Maybe now it actually is the restart event, so trying that patch with 6658 might work.&lt;/p&gt;

&lt;p&gt;The problem with just sleeping for RING_DELAY is that the reason we do that during bootstrap is to announce the range, but with replacement that shouldn&apos;t be needed.  If we sleep and it works we&apos;re papering over the real problem without understand what it is.&lt;/p&gt;</comment>
                            <comment id="13895714" author="ravilr" created="Sat, 8 Feb 2014 20:09:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;You mean rise above it, so the node is still being convicted? Can you add new logs? Maybe now it actually is the restart event, so trying that patch with 6658 might work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Tried with 6658 patch and 0001-don-t-signal-restart-of-dead-states.txt applied on cassandra-2.0.5 tag. Still see the same thing, where FD convicts the streaming session. I&apos;m attaching the logs(6622_logs.tgz).  This should be easily reproducible when replacing a dead node in a cluster with same ip address. the issue is, the peer nodes could take 1-3 seconds to see the previously down node (now replacing) to be up(to reset the PHI score of the down node). Since, the streaming request arrives before this reset happens, they could be convicted leading to stream close. So, i think  a couple of seconds sleep time for gossip to settle, before the bootstrap/streaming starts is what is needed?&lt;/p&gt;

&lt;p&gt;1.) node x.x.x.72 was dead&lt;br/&gt;
2.) node x.x.x.80&apos;s FD keeps notifying its listener to convict as PHI for .72 &amp;gt; threshold, every minute.&lt;br/&gt;
3.) node x.x.x.72 is restarted with replace_address=x.x.x.72 at 18:56:27,806&lt;br/&gt;
4.) node x.x.x.72 : Gossip thread started at 18:56:33,308 after shadow gossip round&lt;br/&gt;
5.) node x.xx.72:  Starts stream request at 18:56:35,443&lt;br/&gt;
 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; 2014-02-08 18:56:35,405 StorageService.java (line 947) JOINING: Starting to bootstrap...&lt;br/&gt;
 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; 2014-02-08 18:56:35,443 StreamResultFuture.java (line 82) &lt;a href=&quot;#bb897500-90f2-11e3-9d67-d5d417af8653&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #bb897500-90f2-11e3-9d67-d5d417af8653&lt;/a&gt; Executing streaming plan for Bootstrap&lt;br/&gt;
6.) node x.x.x.80 : still hasn&apos;t seen the gossip from .72 with new generation at 18:56:35,031&lt;br/&gt;
TRACE &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipTasks:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:35,031 FailureDetector.java (line 229) PHI for /x.x.x.72 : 36700.042810594234&lt;br/&gt;
TRACE &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipTasks:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:35,032 FailureDetector.java (line 233) notifying listeners that /x.x.x.72 is down&lt;br/&gt;
7.) node x.x.x.80 : got the stream request at 18:56:35,450&lt;br/&gt;
 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;STREAM-INIT-/x.x.x.72:47408&amp;#93;&lt;/span&gt; 2014-02-08 18:56:35,450 StreamResultFuture.java (line 116) &lt;a href=&quot;#bb897500-90f2-11e3-9d67-d5d417af8653&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #bb897500-90f2-11e3-9d67-d5d417af8653&lt;/a&gt; Received streaming plan for Bootstrap&lt;br/&gt;
8.) node x.x.x.80: at 18:56:36,090, still hasn&apos;t reset the interval times for .72&lt;br/&gt;
TRACE &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipTasks:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:36,090 FailureDetector.java (line 229) PHI for /x.x.x.72 : 36700.87918907657&lt;br/&gt;
TRACE &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipTasks:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:36,090 FailureDetector.java (line 233) notifying listeners that /x.x.x.72 is down&lt;br/&gt;
9.) node x.x.x.80:  closes the stream session due to convict() notification:&lt;br/&gt;
 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipTasks:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:36,090 StreamResultFuture.java (line 181) &lt;a href=&quot;#bb897500-90f2-11e3-9d67-d5d417af8653&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #bb897500-90f2-11e3-9d67-d5d417af8653&lt;/a&gt; Session with /x.x.x.72 is complete&lt;br/&gt;
 WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipTasks:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:36,091 StreamResultFuture.java (line 210) &lt;a href=&quot;#bb897500-90f2-11e3-9d67-d5d417af8653&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #bb897500-90f2-11e3-9d67-d5d417af8653&lt;/a&gt; Stream failed&lt;br/&gt;
10.) node x.x.x.80:  at 18:56:36,097,  Gossiper thread on x.x.x.80 clears the interval times for .72, thereby resetting the PHI.&lt;br/&gt;
DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipStage:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:36,097 Gossiper.java (line 790) Clearing interval times for /x.x.x.72 due to generation change&lt;br/&gt;
TRACE &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipStage:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:36,097 FailureDetector.java (line 203) reporting /x.x.x.72&lt;br/&gt;
11.) node x.x.x.80:  PHI score for .72 at 18:56:37,094&lt;br/&gt;
TRACE &lt;span class=&quot;error&quot;&gt;&amp;#91;GossipTasks:1&amp;#93;&lt;/span&gt; 2014-02-08 18:56:37,094 FailureDetector.java (line 229) PHI for /x.x.x.72 : 0.06483452387313912&lt;/p&gt;

</comment>
                            <comment id="13897987" author="brandon.williams" created="Tue, 11 Feb 2014 16:28:53 +0000"  >&lt;p&gt;So the problem isn&apos;t any gossip event breaking the stream, it&apos;s that streaming is subscribed to the FD directly in order to wait  for double the phi, but this notifies every second regardless of up/down state and ends up racing the stream request before the hibernate state has reached the source node.  We won&apos;t be able to fix that without &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-3569&quot; title=&quot;Failure detector downs should not break streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-3569&quot;&gt;&lt;del&gt;CASSANDRA-3569&lt;/del&gt;&lt;/a&gt;, so we&apos;ll add the RING_DELAY sleep.  v2 conditionally determines sleep length based on whether the IP is the same or not.&lt;/p&gt;</comment>
                            <comment id="13898472" author="thobbs" created="Tue, 11 Feb 2014 23:10:32 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13898510" author="brandon.williams" created="Tue, 11 Feb 2014 23:44:46 +0000"  >&lt;p&gt;Committed.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12626494" name="0001-don-t-signal-restart-of-dead-states.txt" size="1187" author="brandon.williams" created="Sat, 1 Feb 2014 20:40:25 +0000"/>
                            <attachment id="12625312" name="6622-2.0.txt" size="1519" author="ravilr" created="Mon, 27 Jan 2014 03:10:26 +0000"/>
                            <attachment id="12628354" name="6622-v2.txt" size="904" author="brandon.williams" created="Tue, 11 Feb 2014 22:48:00 +0000"/>
                            <attachment id="12627830" name="6622_logs.tgz" size="207587" author="ravilr" created="Sat, 8 Feb 2014 20:09:38 +0000"/>
                            <attachment id="12626729" name="logs.tgz" size="93763" author="ravilr" created="Mon, 3 Feb 2014 20:04:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[brandon.williams]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370041</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 40 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1rs07:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>370343</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12325644">2.0.4</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>thobbs</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[thobbs]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
                        <customfieldname>Since Version</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12325023">2.0.2</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>