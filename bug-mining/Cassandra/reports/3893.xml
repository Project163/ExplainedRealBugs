<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:58:38 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-10421] Potential issue with LogTransaction as it only checks in a single directory for files</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-10421</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;When creating a new LogTransaction we try to create the new logfile in the same directory as the one we are writing to, but as we use &lt;tt&gt;&lt;a href=&quot;https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/lifecycle/LogTransaction.java#L125&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;directories.getDirectoryForNewSSTables()&lt;/a&gt;&lt;/tt&gt; this might end up in &quot;any&quot; of the configured data directories. If it does, we will not be able to clean up leftovers as we check for files in the same directory as the logfile was created: &lt;a href=&quot;https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/lifecycle/LogRecord.java#L163&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/lifecycle/LogRecord.java#L163&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania&quot; class=&quot;user-hover&quot; rel=&quot;stefania&quot;&gt;Stefania&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12901570">CASSANDRA-10421</key>
            <summary>Potential issue with LogTransaction as it only checks in a single directory for files</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10000" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Urgent</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stefania">Stefania Alborghetti</assignee>
                                    <reporter username="marcuse">Marcus Eriksson</reporter>
                        <labels>
                    </labels>
                <created>Wed, 30 Sep 2015 12:14:21 +0000</created>
                <updated>Wed, 15 Oct 2025 09:49:02 +0000</updated>
                            <resolved>Fri, 23 Oct 2015 21:44:55 +0000</resolved>
                                        <fixVersion>3.0.0</fixVersion>
                                    <component>Legacy/Local Write-Read Paths</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14939108" author="stefania" created="Thu, 1 Oct 2015 00:33:10 +0000"  >&lt;p&gt;If we can have a transaction involving sstables located in different folders, or the txn log can end up in a totally different folder as it seems to be the case, then &lt;tt&gt;LogRecord.getExistingFiles()&lt;/tt&gt; definitely needs to be fixed. However, we then have a bigger problem in listing temporary files, in that &lt;tt&gt;LogAwareFileLister&lt;/tt&gt; assumes the txn log is located in the folder it is listing so we might miss temporary files when listing. We would have to either search for txn logs in multiple folders or pin them to a dedicated folder or enhance &lt;tt&gt;LogAwareFileLister&lt;/tt&gt; to list all the sstable possible folders.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; WDYT? &lt;/p&gt;</comment>
                            <comment id="14939363" author="krummas" created="Thu, 1 Oct 2015 06:11:01 +0000"  >&lt;p&gt;Maybe we could lazily create the LogFiles when we do trackNew? And support multiple LogFiles if we get files in separate directories&lt;/p&gt;</comment>
                            <comment id="14939654" author="benedict" created="Thu, 1 Oct 2015 10:32:34 +0000"  >&lt;p&gt;None of these approaches are optimal, as they lose any pretence of atomicity. However &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6696&quot; title=&quot;Partition sstables by token range&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6696&quot;&gt;&lt;del&gt;CASSANDRA-6696&lt;/del&gt;&lt;/a&gt; will solve this problem for us, so assuming that is delivered in 3.2, we only have to survive until then (although we must survive the full 3.0.x line, unfortunately). So whatever seems like the least unpleasant approach to tide us over, I guess.&lt;/p&gt;</comment>
                            <comment id="14939662" author="krummas" created="Thu, 1 Oct 2015 10:43:03 +0000"  >&lt;p&gt;Actually 6696 was why I stumbled on this, for &lt;del&gt;two&lt;/del&gt; three reasons:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I want to model flushing as a single transaction - this means writing files to different data directories under a single txn. I guess this could be done as multiple transactions though&lt;/li&gt;
	&lt;li&gt;Compaction will at times need to write to multiple directories - after say range movements or disk additions (to rebalance the tokens over the disks again)&lt;/li&gt;
	&lt;li&gt;Streaming will have to write one incoming to several directories as the sstables boundaries will not match on the remote node&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14939671" author="benedict" created="Thu, 1 Oct 2015 10:57:00 +0000"  >&lt;p&gt;Well, this messes things up, no doubt about it. Since we can then have the commit fail writing to one txn log, after succeeding writing to another, and then we will abort some - and the txn logs will end up in an inconsistent state. Our definition of &quot;committed&quot; being based on the presence of the &quot;commit&quot; flag is bust.&lt;/p&gt;

&lt;p&gt;I suspect our best/safest/most correct option is to duplicate wholesale the txn log onto all of our affected data drives. This is ugly conceptually, but it means on replay we just check they&apos;re all the same (with the possibility of one extra record in some files versus others). We would then always take the txn log with the most information as the one to consume, but if they are inconsistent perform our most paranoid checks. This way, once we have committed to one txn log, we can semantically-consistently ignore a failure to commit to another, and the transaction will still be considered committed. However we will still detect a corruption caused by a problematic disk, and in that situation leave all files intact.&lt;/p&gt;

&lt;p&gt;(NB: I suspect streaming can also be modelled as multiple transactions, safely)&lt;/p&gt;</comment>
                            <comment id="14939683" author="stefania" created="Thu, 1 Oct 2015 11:06:29 +0000"  >&lt;p&gt;I would prefer to keep a single transaction with a single log and have the transaction support multiple folders. &lt;/p&gt;

&lt;p&gt;As for listing, we pass all possible folders to the file lister; the sstable lister already scans all possible sstable folders. Listing one folder is already non atomic on Windows, so is listing on multiple folders on all platforms, but our add-on logic should still preserve the illusion of atomicity? &lt;/p&gt;</comment>
                            <comment id="14939685" author="krummas" created="Thu, 1 Oct 2015 11:08:08 +0000"  >&lt;p&gt;Note that current LCS also spreads sstables over many disks - we get a new disk for every new sstable we compact to&lt;/p&gt;</comment>
                            <comment id="14939687" author="krummas" created="Thu, 1 Oct 2015 11:09:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania&quot; class=&quot;user-hover&quot; rel=&quot;stefania&quot;&gt;Stefania&lt;/a&gt; problem with that is that if we crash during compaction, and lose the drive with the logs on it, we will not remove the files&lt;/p&gt;</comment>
                            <comment id="14939831" author="stefania" created="Thu, 1 Oct 2015 13:42:15 +0000"  >&lt;p&gt;Thank for explaining. So we&apos;ll have to use multiple identical txn log files, one per data drive involved in the transaction. &lt;/p&gt;

&lt;p&gt;Transaction is committed as long as at least one txn log file has the commit flag, likewise for aborted. Some txn files may be missing the final flag but they should not disagree on the final flag.&lt;/p&gt;

</comment>
                            <comment id="14946454" author="stefania" created="Wed, 7 Oct 2015 07:43:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aweisberg&quot; class=&quot;user-hover&quot; rel=&quot;aweisberg&quot;&gt;aweisberg&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; : I&apos;ve attached a &lt;a href=&quot;https://github.com/stef1927/cassandra/commits/10421-windows-3.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt; and it is ready for review. Don&apos;t be confused by the word &lt;em&gt;windows&lt;/em&gt; in the branch name, it&apos;s just so that we can have CI on Windows as well as on Linux.&lt;/p&gt;

&lt;p&gt;We don&apos;t duplicate all records to all files, only the final commit or abort flag is written to all files. When we read the files on startup we collect all the sstable records from all existing txn files and check that the final flag record is the same in all files (but we do accept if some files are missing the last record and in this case we just warn). Therefore, if a file is lost we continue with the transaction processing but we do not touch the sstables in the folder of that file. Chances are either the entire disk was lost or the user deleted the file and in this case the user probably wanted to keep the sstables. Does this make sense?&lt;/p&gt;

&lt;p&gt;When writing the final commit or abort record we throw &lt;em&gt;only if we fail to write to all files&lt;/em&gt;. &lt;/p&gt;

&lt;p&gt;The abstraction names that I&apos;ve chosen are &lt;tt&gt;LogFileSegment&lt;/tt&gt; to represent an individual log file and &lt;tt&gt;LogFile&lt;/tt&gt; to represent their ensemble. Feel free to suggest something else if you prefer, like &lt;tt&gt;LogFile&lt;/tt&gt; and &lt;tt&gt;LogFileXXXX&lt;/tt&gt;, I just could not come up with a suitable &lt;tt&gt;XXXX&lt;/tt&gt; other than &lt;tt&gt;LogFiles&lt;/tt&gt;, &lt;tt&gt;LogFileManager&lt;/tt&gt;, &lt;tt&gt;LogFileEnsemble&lt;/tt&gt;, none of which I really liked.&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;CILinux%3A&quot;&gt;&lt;/a&gt;CI Linux:&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-testall/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-testall/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-dtest/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-dtest/&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;&lt;a name=&quot;CIWindows%3A&quot;&gt;&lt;/a&gt;CI Windows:&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-utest_win32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-utest_win32/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-dtest_win32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-dtest_win32/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14947768" author="aweisberg" created="Wed, 7 Oct 2015 23:05:16 +0000"  >&lt;p&gt;Can you set the ticket to patch available?&lt;/p&gt;

&lt;p&gt;If rc2 is end of the week I think it&apos;s going to be hard to get to +1 for a new sub-system and patch like this. I&apos;m not going to be able to do more review until tomorrow evening my time.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We don&apos;t duplicate all records to all files, only the final commit or abort flag is written to all files. When we read the files on startup we collect all the sstable records from all existing txn files and check that the final flag record is the same in all files (but we do accept if some files are missing the last record and in this case we just warn). Therefore, if a file is lost we continue with the transaction processing but we do not touch the sstables in the folder of that file. Chances are either the entire disk was lost or the user deleted the file and in this case the user probably wanted to keep the sstables. Does this make sense?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Is there an advantage to writing only the commit record to all the files? Seems conceptually easier for them to all be the same log and since it is low traffic there is no performance motivation. Was there a discussion somewhere else where it seemed like people might delete the file? Are we really ok with losing atomicity if they don&apos;t lose the whole disk?&lt;/p&gt;

&lt;p&gt;If they all had all the records you could just read the contents from any file that has a commit record.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commit/49a2d5f289c98fcf646272cfab777d20001f9b9e#diff-d8721a4dd04f4f35b65e7edeb6c883f6R198&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Can you just have it do nothing if it is called multiple times?&lt;/a&gt;. Maybe save a headache down the road.&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commit/49a2d5f289c98fcf646272cfab777d20001f9b9e#diff-d8721a4dd04f4f35b65e7edeb6c883f6L161&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Why is this check not necessary anymore?&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commit/49a2d5f289c98fcf646272cfab777d20001f9b9e#diff-d8721a4dd04f4f35b65e7edeb6c883f6R283&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Not part of your current work, but relying on modified time for files seems suspect to me, file contents should have the modified time so copying and other operations don&apos;t change it&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I got through a first pass of the implementation. I&apos;m looking at the tests now.&lt;/p&gt;</comment>
                            <comment id="14947866" author="stefania" created="Thu, 8 Oct 2015 00:27:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Is there an advantage to writing only the commit record to all the files? Seems conceptually easier for them to all be the same log and since it is low traffic there is no performance motivation. Was there a discussion somewhere else where it seemed like people might delete the file? Are we really ok with losing atomicity if they don&apos;t lose the whole disk?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There was a brief discussion on IRC between &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=krummas&quot; class=&quot;user-hover&quot; rel=&quot;krummas&quot;&gt;krummas&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; but the conclusion wasn&apos;t clear to me. Here is why so far I chose not to replicate the entire content:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;when we add a new log file lazily, we need to duplicate the content of other existing files (not a problem but something extra to do and that can go wrong)&lt;/li&gt;
	&lt;li&gt;every time we write an sstable record we risk not being able to write this record to a file when we&apos;ve already succeeded writing to another file, at the moment this is necessary only for the last record and on startup we can handle missing file records in some files, so long as they don&apos;t conflict&lt;/li&gt;
	&lt;li&gt;a record could become quite long due to a long relative path (it shouldn&apos;t matter other than for readability of the txn file)&lt;/li&gt;
	&lt;li&gt;at startup we then have the problem of reconciling sstable records not just the final ones and handle the case of missing sstable files that according to the txn should be there (if a disk is removed or files deleted)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I didn&apos;t want to tackle all this until I was sure it is necessary, conceptually it seemed cleaner to have each txn file only handle its own local sstable files but if there are true safety issues with this (Benedict seemed to think so on IRC) then I am happy to change it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can you just have it do nothing if it is called multiple times?. Maybe save a headache down the road.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;tt&gt;readRecords&lt;/tt&gt; used to be called independently, now it&apos;s only called from &lt;tt&gt;verify&lt;/tt&gt; so I guess the assertion could go. Currently we should not attempt to read a file twice so I don&apos;t see why silently doing nothing is better than raising an assertion.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why is this check not necessary anymore?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve changed &lt;tt&gt;record.isValid()&lt;/tt&gt;, called just above. I could not hit that code during unit tests even with invalid records and it occurred to me that it was because error message and record type are both set all the time.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Not part of your current work, but relying on modified time for files seems suspect to me, file contents should have the modified time so copying and other operations don&apos;t change it&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There was a very long discussion about this on &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-7066&quot; title=&quot;Simplify (and unify) cleanup of compaction leftovers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-7066&quot;&gt;&lt;del&gt;CASSANDRA-7066&lt;/del&gt;&lt;/a&gt;; it starts more or less with the last paragraph of &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-7066?focusedCommentId=14645754&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14645754&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;this comment&lt;/a&gt;. We delete files from oldest to newest and the update time is the maximum update time so it should always match with that&apos;s on disk. The reason is that we don&apos;t want to delete files by mistake, as in users coping files from backup without removing a partial txn log that happened to have obsoleted the very same files. There is a comment in &lt;tt&gt;deleteRecord()&lt;/tt&gt; but it doesn&apos;t seem complete so we should probably add more comments about this.&lt;/p&gt;</comment>
                            <comment id="14948380" author="slebresne" created="Thu, 8 Oct 2015 09:35:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;If rc2 is end of the week I think it&apos;s going to be hard to get to +1 for a new sub-system and patch like this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Just as a fyi, we&apos;re now aiming at the end of next week (so Friday 16th) for rc2. Still, we need to figure this out pretty quickly.&lt;/p&gt;</comment>
                            <comment id="14949867" author="stefania" created="Fri, 9 Oct 2015 04:13:34 +0000"  >&lt;p&gt;Just outlining some more options:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The current approach is the most permissive approach, in that we clean up a transaction even if some final files are missing (because a disk was removed for example). My reasoning is that from the transaction point of view, it did complete or abort and so it should not keep old files if the new files have been removed for another reason, or should it?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;If we instead wrote all sstable files to all log files we could detect if some final files are missing and refuse to clean-up. This would be safer but it does however have the disadvantage that we could delete files in a folder even if in that folder there is no txn log. Currently this is incompatible with listing temporary files as we only look at the txn file in the current folder. So this could be counter-intuitive in that an operator might delete the txn log file in a folder, confirm with &lt;tt&gt;sstableutil&lt;/tt&gt; that the stables in that folder are not temporary, and yet we delete those files on startup. So if we went down this route we&apos;d have to extend listing as well, at least when offline.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;There is one more approach, the most pessimistic, which is to refuse to clean up a transaction if any log files are  missing. This we could detect by counting the number of records or log files and adding this number to the final record, protected by the checksum. It would however mean that if a user removed a disk, we would not clean-up the leftovers on a different disk but we could stash them or let the operation handle them manually by printing out all necessary information (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-10112&quot; title=&quot;Refuse to start and print txn log information in case of disk corruption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-10112&quot;&gt;&lt;del&gt;CASSANDRA-10112&lt;/del&gt;&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14950847" author="aweisberg" created="Fri, 9 Oct 2015 17:44:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;The reason is that we don&apos;t want to delete files by mistake, as in users coping files from backup without removing a partial txn log that happened to have obsoleted the very same files. There is a comment in deleteRecord() but it doesn&apos;t seem complete so we should probably add more comments about this.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK yeah that sounds thorny. I get where this is coming from now.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The current approach is the most permissive approach, in that we clean up a transaction even if some final files are missing (because a disk was removed for example). My reasoning is that from the transaction point of view, it did complete or abort and so it should not keep old files if the new files have been removed for another reason, or should it?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;After looking at the discussion &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-7066&quot; title=&quot;Simplify (and unify) cleanup of compaction leftovers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-7066&quot;&gt;&lt;del&gt;CASSANDRA-7066&lt;/del&gt;&lt;/a&gt; I think I have a better understanding of the situations the log is supposed to address. Key points are that correctness is maintained even if atomicity is lost for rollback. This is just trying to clean up after in progress operations, and as a better approach compared to earlier/other mechanisms (system tables, renaming, ancestor analysis). The window at the end where we might fail to clean up because we fail to write one log, or fail to read it on restart aren&apos;t super important.&lt;/p&gt;

&lt;p&gt;I am not sure if losing atomicity on commit is safe. I think it isn&apos;t because you could have a log asking you to remove some files that are ancestors, but no log records telling you to add their replacements in a different location. Do the replacements just silently get added in that case? If so then yes I think it&apos;s fine.&lt;/p&gt;

&lt;p&gt;When disks start going bad and files start disappearing the operator already has to fall back on repair and restoring from backups. But Jonathan did voice a preference for extra data and more compaction when things are going poorly so that is my guiding logic right now. Leave a little bit more data when you have full on corruption/missing files and focus on the common case of restarts. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; WDYT? &lt;/p&gt;

&lt;p&gt;I have some questions about what happens when at runtime when we go to create these log files.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;When writing a commit if we fail to write the commit to all files does that mean we don&apos;t attempt to transition to the new state?&lt;/li&gt;
	&lt;li&gt;The transition to the new state is always going to be applying deletions to obsolete sstables right?&lt;/li&gt;
	&lt;li&gt;What about failing to add a record?&lt;/li&gt;
	&lt;li&gt;If that fails does it abort the transaction?&lt;/li&gt;
	&lt;li&gt;Would that block compaction progress?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;These are all high level questions just from me figuring out how things work. I&apos;ll look at the tests for the changes you have implemented so far now.&lt;/p&gt;</comment>
                            <comment id="14951140" author="aweisberg" created="Fri, 9 Oct 2015 20:27:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/stef1927/cassandra/commit/49a2d5f289c98fcf646272cfab777d20001f9b9e#diff-2b93b5a182c483fe61783561b4d1e211R681&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;This is common to both branches of shouldCommit&lt;/a&gt;. Also shouldn&apos;t both wait for deletions even if none are expected since you are checking to see if it is done incorrectly?&lt;/p&gt;

&lt;p&gt;If am reading the tests correctly on commit failure it&apos;s leaving all the files so some of my previous questions are already answered.&lt;/p&gt;

&lt;p&gt;The tests for the new code are convincing.&lt;/p&gt;

&lt;p&gt;In my mind the only open question is how to handle the scenario where the log on one disk has you remove files while the log on another disk doesn&apos;t have you add their replacements because it&apos;s corrupt. That wouldn&apos;t happen if the log was replicated to all the disks. Even if it was though, and you lost a disk, maybe you need to know you lost a disk containing replacement files and that the transaction actually needs to handle that case where it can&apos;t get to the aborted or committed state.&lt;/p&gt;</comment>
                            <comment id="14952596" author="stefania" created="Mon, 12 Oct 2015 04:05:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;I am not sure if losing atomicity on commit is safe. I think it isn&apos;t because you could have a log asking you to remove some files that are ancestors, but no log records telling you to add their replacements in a different location. Do the replacements just silently get added in that case? If so then yes I think it&apos;s fine.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We strictly do what the txn log files say, if the user deleted the txn log file in the folder where the replacements are, then we would not add them. This is probably a problem, see more at the end of this comment.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When writing a commit if we fail to write the commit to all files does that mean we don&apos;t attempt to transition to the new state?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes the transaction would be rolled back. &lt;tt&gt;LogTransaction&lt;/tt&gt; is only used by &lt;tt&gt;LifecycleTransaction&lt;/tt&gt; so you need to look at its code. It calls &lt;tt&gt;log.commit()&lt;/tt&gt; as the first entry in its &lt;tt&gt;doCommit()&lt;/tt&gt; and it throws in case of error; so if we cannot write to any txn logs we fail the commit and the transaction is rolled back.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The transition to the new state is always going to be applying deletions to obsolete sstables right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, on successful commit the obsoleted sstables are scheduled to be deleted as soon as all the references are released.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What about failing to add a record?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Failing to add a NEW record would result in an exception when creating the sstable writer. Failing to add an OLD record would result in an exception thrown or returned by &lt;tt&gt;LifecycleTransaction&lt;/tt&gt; depending on whether it is called in &lt;tt&gt;doPrepare&lt;/tt&gt; or &lt;tt&gt;doAbort&lt;/tt&gt; (or post cleanup and cancel).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If that fails does it abort the transaction?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;tt&gt;doPrepare&lt;/tt&gt; can throw but &lt;tt&gt;doAbort&lt;/tt&gt; cannot. This second case is for non original tables however, i.e. if they were opened early.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Would that block compaction progress?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes a compaction in progress is a transaction, if &lt;tt&gt;prepare&lt;/tt&gt; throws then the transaction is aborted. See &lt;tt&gt;CompactionAwareWriter.finish&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&amp;#8211;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This is common to both branches of shouldCommit. Also shouldn&apos;t both wait for deletions even if none are expected since you are checking to see if it is done incorrectly?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fixed, thank you.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In my mind the only open question is how to handle the scenario where the log on one disk has you remove files while the log on another disk doesn&apos;t have you add their replacements because it&apos;s corrupt. That wouldn&apos;t happen if the log was replicated to all the disks. Even if it was though, and you lost a disk, maybe you need to know you lost a disk containing replacement files and that the transaction actually needs to handle that case where it can&apos;t get to the aborted or committed state.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree this is the sticky point. Assuming that we should not remove the ancestors (which seems to be the case from your earlier comments on Jonathan&apos;s preference) then I agree: we not only need to duplicate the logs, we also need to detect corrupt replacements. At the moment we focus on detecting corrupt ancestors, not replacements. It is trickier to check if replacements are valid because the files do not yet exist when we start tracking replacements.&lt;/p&gt;

&lt;p&gt;I think we should try to detect if some log files or replacements are missing and in this case log an error and leave everything as is. We can add more information to the final record to detect this cases. WDYT?&lt;/p&gt;</comment>
                            <comment id="14952746" author="benedict" created="Mon, 12 Oct 2015 07:31:43 +0000"  >&lt;p&gt;FTR, IMO (as I expressed on IRC), I think it is both safer and easier to implement duplication to all disks. Since this data is low traffic it also shouldn&apos;t be a major issue that we do this:&lt;/p&gt;

&lt;p&gt;Implementation-wise, the changes can be extremely minimal to the existing logic: on read, we read all files simultaneously, line-by-line, corroborating they are the same (we can even have a special reader that wraps all files, so that the current logic is completely unchanged). If at any point they differ, we confirm there is no proceeding line (if there is we leave everything as is, as it is corruption, much like we normally would), and otherwise we confirm that every file&apos;s last line is a prefix-match of every other. On write we can do similar, ensuring we write to all of them in sequence, treating it as a single action from the POV of the existing logic. This means the only modifications are at the very outermost parts of the logic, so we don&apos;t have to revisit the safety of the basic functionality.&lt;/p&gt;

&lt;p&gt;This also leaves us with much less complexity reasoning about the safety under different scenarios wrt disk corruption, failure, accidental user-error, etc. So, it seems like a win-win AFAICT. The only downside is that users modifying these files would need to modify them all, but this is not overly onerous.&lt;/p&gt;

&lt;p&gt;(I will note I&apos;m not convinced it &lt;em&gt;cannot&lt;/em&gt; be done safely with separate disks, just that it&apos;s going to be fiddlier, and I haven&apos;t had time to consider it beyond that)&lt;/p&gt;</comment>
                            <comment id="14952923" author="stefania" created="Mon, 12 Oct 2015 10:59:39 +0000"  >&lt;p&gt;Thanks for explaining your opinion. The way you envision it, duplicating files does seem easier than segmenting files across disks. It doesn&apos;t however change the fact that we write more and have therefore more chances of failing to do so therefore having to roll back a transaction.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The only downside is that users modifying these files would need to modify them all, but this is not overly onerous.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Users are not supposed to modify these files but if they did delete one txn file then they could be quite surprised to see temporary files disappear on startup because of a txn log in another folder. Especially given that we only list temporary files by looking at the local txn file. That was one of my concerns. Unless you meant to &lt;b&gt;not&lt;/b&gt; store the relative file path (the path of an sstable relative to a txn file), in which case we would only be able to delete temporary files if the txn file in the sstable folder has not been deleted?&lt;/p&gt;

&lt;p&gt;To be clear, we would roll back the transaction if we failed to write a record to &lt;em&gt;any file&lt;/em&gt; except for the last record, where we could tolerate failures provided we have written to at least one file?&lt;/p&gt;</comment>
                            <comment id="14952941" author="benedict" created="Mon, 12 Oct 2015 11:18:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;It doesn&apos;t however change the fact that we write more and have therefore more chances of failing to do so&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right. This isn&apos;t exposing us to anything too terrible though, really, since this clearly should be infrequent or there are bigger problems. If there is a disk failure it is quite reasonable to mark the disk as unavailable and start again (from scratch)&amp;#42;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Unless you meant to not store the relative file path (the path of an sstable relative to a txn file),&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, I think now it is probably best to store the full path (or, if we wanted to be helpful, the relative path to the common ancestor of all data disks)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;To be clear, we would roll back the transaction if we failed to write a record to any file except for the last record, where we could tolerate failures provided we have written to at least one file?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s how I would do it, yes, as it has the most semantic consistency. With one addendum: on restart, I would consider &lt;b&gt;any&lt;/b&gt; incomplete (or missing) final records to be the same as our current incomplete final record behaviour. i.e. we enter paranoid mode and make sure all of the files are present. If they aren&apos;t, we leave them all, just in case. This means we leave some extra duplicate data in disk in some cases during a restart when we had some temporary disk problems, but that&apos;s a fine tradeoff for simplicity and safety in my book, since these should be rare scenarios, and are clearly scenarios of hardware issues, in which paranoia is probably best. This does technically break the semantic consistency argument on restart, but I think acceptably.&lt;/p&gt;

&lt;p&gt;&amp;#42; It may be that we could detect disk failure here and also retain more data, but it is highly unlikely this complexity would pay dividends given the window of effect, and the per-disk vnode allocations coming in the near future.&lt;/p&gt;</comment>
                            <comment id="14953016" author="stefania" created="Mon, 12 Oct 2015 11:38:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;This isn&apos;t exposing us to anything too terrible though, really, since this clearly should be infrequent or there are bigger problems.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed.&lt;/p&gt;

&lt;p&gt;&amp;#8211;&lt;/p&gt;

&lt;p&gt;It&apos;s clearer now, thanks. Unless &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aweisberg&quot; class=&quot;user-hover&quot; rel=&quot;aweisberg&quot;&gt;aweisberg&lt;/a&gt; has any concern I will resume work on this tomorrow.&lt;/p&gt;</comment>
                            <comment id="14953237" author="aweisberg" created="Mon, 12 Oct 2015 15:52:05 +0000"  >&lt;p&gt;So if I understand the proposed action on restart is to retain all available files including the ones that have been newly created in the failed transaction and compact it later? If we can find a record that says a file should be added we know that it is theoretically complete.&lt;/p&gt;

&lt;p&gt;I don&apos;t know if it matters that the files wasn&apos;t completed or what happens if we try and load partial files. Since we support early opening can we retain partial files usefully? Or do we delete files that don&apos;t have some log record somewhere adding them?&lt;/p&gt;</comment>
                            <comment id="14954249" author="stefania" created="Tue, 13 Oct 2015 02:09:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;So if I understand the proposed action on restart is to retain all available files including the ones that have been newly created in the failed transaction and compact it later? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, it is mainly to protect old files but it would leave new files as well. We log an error at the moment and we leave it to the user to handle this. We plan on enhancing this in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-10112&quot; title=&quot;Refuse to start and print txn log information in case of disk corruption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-10112&quot;&gt;&lt;del&gt;CASSANDRA-10112&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we can find a record that says a file should be added we know that it is theoretically complete.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, because we add these records before the new files are even created, to make sure they get deleted at all times should the transaction fail. Only the final commit record indicates that new files are safe to use.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t know if it matters that the files wasn&apos;t completed or what happens if we try and load partial files. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Most likely a corrupt sstable exception will halt start-up depending on disk failure policy. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Since we support early opening can we retain partial files usefully? Or do we delete files that don&apos;t have some log record somewhere adding them?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not at the moment, unless we support this when reading sstables. From the transaction log point of view, early opening is transparent, we track them as any other new sstable file and they become final only when the commit record is added. &lt;/p&gt;</comment>
                            <comment id="14954737" author="stefania" created="Tue, 13 Oct 2015 10:03:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aweisberg&quot; class=&quot;user-hover&quot; rel=&quot;aweisberg&quot;&gt;aweisberg&lt;/a&gt; I have something that passes unit tests but I still have to clean it up a bit. Specifically, I need to improve error messages, test coverage, do a self code review and I will probably also split the &lt;tt&gt;LogFile&lt;/tt&gt; class in two: one for wrapping the replicas on disk and one for the actual txn operations. &lt;/p&gt;

&lt;p&gt;I am not sure if you prefer to take a look at the WIP code given the tight deadline or to wait until it is complete.&lt;/p&gt;

&lt;p&gt;I&apos;ve also renamed the branch to avoid windows dtest running every time, see &lt;a href=&quot;https://github.com/stef1927/cassandra/commits/10421-3.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;. I will only push to the windows branch at the very end to run dtests once.&lt;/p&gt;

&lt;p&gt;New CI links:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-dtest&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-dtest&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-testall&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-testall&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14956574" author="stefania" created="Wed, 14 Oct 2015 09:35:37 +0000"  >&lt;p&gt;Ready for review &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aweisberg&quot; class=&quot;user-hover&quot; rel=&quot;aweisberg&quot;&gt;aweisberg&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14957789" author="aweisberg" created="Wed, 14 Oct 2015 21:17:32 +0000"  >&lt;p&gt;I think this does what we talked about where generally speaking if anything goes wrong LogFile.verify will return false and then LogTransaction.removeUnfinishedLeftovers won&apos;t do anything. The only attempt we make to be a hero is when it&apos;s just the last record that has minor disagreement that indicates missing or partial commit in one file.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Most likely a corrupt sstable exception will halt start-up depending on disk failure policy.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Would this be what happens? We don&apos;t validate checksums of entire files at startup. Or is there a flag somewhere else that allows us to know which files are incomplete?&lt;/p&gt;

&lt;p&gt;I just noticed that it seems to open each file every time to append a record? Since each record is only one table seems like that could end up being a little slow although most transactions won&apos;t touch that many tables so maybe it&apos;s not an issue. It syncs the folder descriptor every time it writes to a file? Seems like the folder only needs to be synced once when the file is created or is that done as a side effect for other operations? Is the intent to sync the file for each record and not the directory?&lt;/p&gt;

&lt;p&gt;LogFile.deleteRecords() applies records of a specific type? Just based on the name I thought it was modifying the log contents somehow. Seems like it and the chain of delegating calls should be named something else like applyRecords.&lt;/p&gt;

&lt;p&gt;Can you add a comment that the LogFile.records is a LinkedHashSet because it must be order preserving? When I saw it floating around without the LHS type and just Set I was confused. Wouldn&apos;t want to it change into something that is not order preserving later on.&lt;/p&gt;</comment>
                            <comment id="14958185" author="stefania" created="Thu, 15 Oct 2015 02:09:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would this be what happens? We don&apos;t validate checksums of entire files at startup. Or is there a flag somewhere else that allows us to know which files are incomplete?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not super expert in reading sstables but if the metadata (statistics file) is missing the sstable won&apos;t be loaded at startup and the metadata is created in BTW &lt;tt&gt;doPrepare&lt;/tt&gt; after the data file is completed. So normally incomplete data files should be detected at startup. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I just noticed that it seems to open each file every time to append a record? Since each record is only one table seems like that could end up being a little slow although most transactions won&apos;t touch that many tables so maybe it&apos;s not an issue. It syncs the folder descriptor every time it writes to a file? Seems like the folder only needs to be synced once when the file is created or is that done as a side effect for other operations? Is the intent to sync the file for each record and not the directory?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We need to sync the folder only when files are created or deleted. At the moment the txn log file is created lazily when the first record is added, hence the sync when appending records. Now that we have a wrapper class around the file and folder descriptor, &lt;tt&gt;LogReplica&lt;/tt&gt;, and since this class happens to need a close method to release the folder descriptor, we can keep a file writer open and so I&apos;ve changed it to this effect. This might break some unit tests on Windows however, so I&apos;ve started CI on Windows as well.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;LogFile.deleteRecords() applies records of a specific type? Just based on the name I thought it was modifying the log contents somehow. Seems like it and the chain of delegating calls should be named something else like applyRecords.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It deletes the files of the records with a specific type. I&apos;ve renamed &lt;tt&gt;deleteRecords&lt;/tt&gt; to &lt;tt&gt;deleteFilesForRecordsOfType&lt;/tt&gt; and &lt;tt&gt;deleteRecord&lt;/tt&gt; to &lt;tt&gt;deleteRecordFiles&lt;/tt&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can you add a comment that the LogFile.records is a LinkedHashSet because it must be order preserving? When I saw it floating around without the LHS type and just Set I was confused. Wouldn&apos;t want to it change into something that is not order preserving later on.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sure, it done.&lt;/p&gt;</comment>
                            <comment id="14959729" author="aweisberg" created="Thu, 15 Oct 2015 22:14:08 +0000"  >&lt;p&gt;So what I think I see is that when the LogTransaction completes it first writes to the log the commit record, and then starts making permanent changes to the the files on disk (deleting the old ones). But if it hasn&apos;t actually synced the log to disk then on a restart we could have a partial log and attempt to roll back, but it is too late because before the crash we had already deleted parts of the before state. At the end we should sync the log files before deleting the obsolete files right?&lt;/p&gt;

&lt;p&gt;Before we add a new file that we want to have cleaned up maybe we also want to make sure the record is one disk so that it will definitely be cleaned up? Maybe not necessary since it is just additional data that will be compacted later.&lt;/p&gt;

&lt;p&gt;Maybe optimizing for power failure isn&apos;t necessary, but then why are we syncing directories?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/cassandra/commit/8e02e47e1a4a86428bec61d8975a9706c544003b#diff-a7c36820cf8658b605948a23e3033f88R76&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Here it seems like you don&apos;t sync the folder when appending every record?&lt;/a&gt;. Was the intent to sync the folder when creating the log file or when adding a record which indicates the addition of other data files?&lt;/p&gt;

&lt;p&gt;I am generally +1 other then my confusion over how syncing of the log file contents is handled.&lt;/p&gt;

&lt;p&gt;The tests don&apos;t seem to match trunk. I gave them another spin on the 3.0 branch to get another sample. &lt;/p&gt;</comment>
                            <comment id="14959979" author="stefania" created="Fri, 16 Oct 2015 01:07:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;So what I think I see is that when the LogTransaction completes it first writes to the log the commit record, and then starts making permanent changes to the the files on disk (deleting the old ones). But if it hasn&apos;t actually synced the log to disk then on a restart we could have a partial log and attempt to roll back, but it is too late because before the crash we had already deleted parts of the before state. At the end we should sync the log files before deleting the obsolete files right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes this is correct, that&apos;s why we flush after writing every record but if we want to survive a power cut then we should call &lt;tt&gt;fsync&lt;/tt&gt;. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Was the intent to sync the folder when creating the log file or when adding a record which indicates the addition of other data files?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The intent was to sync the folder when creating the file and to sync the content of the file with a flush when appending data to it. However flushing only passes the data to the operating system; it won&apos;t protect us from a power cut. This wasn&apos;t clear to me yesterday. At a minimum we should &lt;tt&gt;fsync&lt;/tt&gt; after adding the final record and probably also when adding new records as you correctly pointed out. Therefore, I would strongly prefer to leave it as it was before and call &lt;tt&gt;fsync&lt;/tt&gt; on the folder whenever we add a record, so in case of a power cut we have the most up-to-date data. This is what I did in the latest commit. Let me know if you have performance concerns.&lt;/p&gt;

&lt;p&gt;I also had to add several &lt;tt&gt;log.txnFile().close();&lt;/tt&gt; to the unit tests (whenever we test &lt;tt&gt;removeUnfinishedLeftovers&lt;/tt&gt;) because on Windows we cannot delete files that are open. This is a bit ugly so maybe we should also go back to using &lt;tt&gt;FileUtils::appendLine&lt;/tt&gt;, unless again you have performance concerns.&lt;/p&gt;

&lt;p&gt;I&apos;ve rebased on 3.0 and started a new CI run on both Linux and Windows.&lt;/p&gt;</comment>
                            <comment id="14960123" author="aweisberg" created="Fri, 16 Oct 2015 03:46:40 +0000"  >&lt;p&gt;Syncing the directory won&apos;t sync the log file. You need sync the log file specifically to have that data be available. Syncing the directory makes rename and file creation durable, but not the files contained in the directory.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I also had to add several log.txnFile().close(); to the unit tests (whenever we test removeUnfinishedLeftovers) because on Windows we cannot delete files that are open. This is a bit ugly so maybe we should also go back to using FileUtils::appendLine, unless again you have performance concerns.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t mind opening the file every time. However to sync it after every write you will need to keep it open long enough to do that. Or open it O_SYNC or something.&lt;/p&gt;</comment>
                            <comment id="14960241" author="stefania" created="Fri, 16 Oct 2015 06:33:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;Syncing the directory won&apos;t sync the log file. You need sync the log file specifically to have that data be available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks, I should&apos;ve read the entire documentation of fsync.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t mind opening the file every time. However to sync it after every write you will need to keep it open long enough to do that. Or open it O_SYNC or something.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We can actually append and sync via &lt;tt&gt;Files.write&lt;/tt&gt; with &lt;tt&gt;StandardOpenOption.SYNC&lt;/tt&gt;. &lt;/p&gt;

&lt;p&gt;Latest commit is &lt;a href=&quot;https://github.com/stef1927/cassandra/commit/4866ce93328108ab09dcc10596ab1ea0c4b76f9d&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&apos;m monitoring dtests, it seem we get lots of timeouts but when I run the tests locally they pass, let&apos;s see if the next batch is better.&lt;/p&gt;</comment>
                            <comment id="14961022" author="aweisberg" created="Fri, 16 Oct 2015 17:10:03 +0000"  >&lt;p&gt;3.0 actually had a passing run just now. Looks like it started getting better very recently. Kudos to the people that got us there. The dtests look good to me on your branch.&lt;/p&gt;

&lt;p&gt;Some tests look like they might be hard failing like org.apache.cassandra.io.sstable.LegacySSTableTest.testLegacyCqlTables. But maybe that only just got better on trunk.&lt;/p&gt;

&lt;p&gt;I am +1 on the code. My gut says the tests are good, but can you rebase one more time and we can see if we can get the utests to match?&lt;/p&gt;</comment>
                            <comment id="14962710" author="stefania" created="Mon, 19 Oct 2015 00:33:15 +0000"  >&lt;p&gt;Rebased on latest 3.0, repeating CI links here for convenience:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-testall&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-testall&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-dtest&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-3.0-dtest&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;BatchlogManagerTest.testAddBatch&lt;/tt&gt; and &lt;tt&gt;LegacySSTableTest.testLegacyCqlTables&lt;/tt&gt; were failing on 3.0 until build #193.&lt;/p&gt;</comment>
                            <comment id="14962755" author="stefania" created="Mon, 19 Oct 2015 02:04:33 +0000"  >&lt;p&gt;Still 2 utests failing that are not failing on the latest build of 3.0 (#197):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;MoveTest.BeforeFirstTest&lt;/tt&gt; timed out before the first test. I cannot reproduce this locally but it also seems that it never happened on 3.0 (I went back 30 builds). I&apos;ve looked at the log and it seems it was quite slow at initializing the schema.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LeveledCompactionStrategyTest.testCompactionProgress&lt;/tt&gt; : this passes locally and it &lt;a href=&quot;http://cassci.datastax.com/job/cassandra-3.0_testall/170/testReport/org.apache.cassandra.db.compaction/LeveledCompactionStrategyTest/testCompactionProgress_compression/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;failed on 3.0&lt;/a&gt; at the same line on build #170 (albeit with compression enabled). I think the problem is in the test, specifically in &lt;tt&gt;waitForLeveling&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ve launched one more run.&lt;/p&gt;</comment>
                            <comment id="14963597" author="aweisberg" created="Mon, 19 Oct 2015 16:54:28 +0000"  >&lt;p&gt;LeveledCompactionStrategyTest.testCompactionProgress has been unreliable for a very long time.&lt;/p&gt;

&lt;p&gt;If you can&apos;t reproduce MoveTest.BeforeFirstTest I would call it good.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;
</comment>
                            <comment id="14964392" author="stefania" created="Tue, 20 Oct 2015 02:11:19 +0000"  >&lt;p&gt;It could not be reproduced in the last build. I&apos;ve scheduled one more build for unit tests and if that too is OK I will move this to ready for commit.&lt;/p&gt;</comment>
                            <comment id="14964856" author="stefania" created="Tue, 20 Oct 2015 09:28:47 +0000"  >&lt;p&gt;We had another timeout problem, albeit in a different test. I think we need to take a look as these timeouts do not occur on 3.0. I&apos;ll post another update once I&apos;ve had a chance to look at the logs.&lt;/p&gt;</comment>
                            <comment id="14968459" author="stefania" created="Thu, 22 Oct 2015 03:44:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aweisberg&quot; class=&quot;user-hover&quot; rel=&quot;aweisberg&quot;&gt;aweisberg&lt;/a&gt; : one more &lt;a href=&quot;https://github.com/stef1927/cassandra/commit/bf18a71be49d4b6cd9242e97846fcf69653a53cd&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;commit&lt;/a&gt; to review.&lt;/p&gt;

&lt;p&gt;I found some exceptions reported for the compressed versions of the tests that were timing out. Unsure why this behavior on Jenkins, that is why the compressed tests were not reported as failing whereas the normal tests were reported as timing out. However, the same identical thing happened twice with &lt;tt&gt;MoveTest&lt;/tt&gt; and &lt;tt&gt;CellTest&lt;/tt&gt;, so I am pretty sure the cause of the timeouts were the exceptions below, which I&apos;ve fixed. I&apos;ve started a new CI run.&lt;/p&gt;

&lt;p&gt;Here are the exceptions:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;WARN  [MemtableFlushWriter:1] 2015-10-19 01:29:08,076 open(build/test/cassandra/data:241/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6, O_RDONLY) failed, errno (2).
ERROR [MemtableFlushWriter:1] 2015-10-19 01:29:08,102 Fatal exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[MemtableFlushWriter:1,5,main]
java.lang.NullPointerException: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        at java.util.Objects.requireNonNull(Objects.java:203) ~[na:1.8.0_45]
        at java.util.Arrays$ArrayList.&amp;lt;init&amp;gt;(Arrays.java:3813) ~[na:1.8.0_45]
        at java.util.Arrays.asList(Arrays.java:3800) ~[na:1.8.0_45]
        at org.apache.cassandra.db.lifecycle.LogRecord.getExistingFiles(LogRecord.java:243) ~[main/:na]
        at org.apache.cassandra.db.lifecycle.LogRecord.make(LogRecord.java:129) ~[main/:na]
        at org.apache.cassandra.db.lifecycle.LogFile.makeRecord(LogFile.java:272) ~[main/:na]
        at org.apache.cassandra.db.lifecycle.LogFile.add(LogFile.java:262) ~[main/:na]
        at org.apache.cassandra.db.lifecycle.LogTransaction.trackNew(LogTransaction.java:133) ~[main/:na]
        at org.apache.cassandra.db.lifecycle.LifecycleTransaction.trackNew(LifecycleTransaction.java:517) ~[main/:na]
        at org.apache.cassandra.io.sstable.format.big.BigTableWriter.&amp;lt;init&amp;gt;(BigTableWriter.java:68) ~[main/:na]
        at org.apache.cassandra.io.sstable.format.big.BigFormat$WriterFactory.open(BigFormat.java:93) ~[main/:na]
        at org.apache.cassandra.io.sstable.format.SSTableWriter.create(SSTableWriter.java:96) ~[main/:na]
        at org.apache.cassandra.io.sstable.SimpleSSTableMultiWriter.create(SimpleSSTableMultiWriter.java:114) ~[main/:na]
        at org.apache.cassandra.db.compaction.AbstractCompactionStrategy.createSSTableMultiWriter(AbstractCompactionStrategy.java:514) ~[main/:na]
        at org.apache.cassandra.db.compaction.CompactionStrategyManager.createSSTableMultiWriter(CompactionStrategyManager.java:506) ~[main/:na]
        at org.apache.cassandra.db.ColumnFamilyStore.createSSTableMultiWriter(ColumnFamilyStore.java:472) ~[main/:na]
        at org.apache.cassandra.db.Memtable$FlushRunnable.createFlushWriter(Memtable.java:429) ~[main/:na]
        at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:366) ~[main/:na]
        at org.apache.cassandra.db.Memtable$FlushRunnable.runMayThrow(Memtable.java:352) ~[main/:na]
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]
        at com.google.common.util.concurrent.MoreExecutors$DirectExecutorService.execute(MoreExecutors.java:299) ~[guava-18.0.jar:na]
        at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1037) ~[main/:na]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_45]
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745) ~[na:1.8.0_45]
ERROR [Reference-Reaper:1] 2015-10-19 01:29:11,444 LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@60b352b3) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.db.lifecycle.LogTransaction$TransactionTidier@632410305:[build/test/cassandra/data:241/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/ma_txn_flush_cadfa480-7600-11e5-a7c7-1d8546d0512d.log]  was not released before the reference was garbage collected
ERROR [Reference-Reaper:1] 2015-10-19 01:29:11,445 Allocate trace org.apache.cassandra.utils.concurrent.Ref$State@60b352b3:
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[MemtableFlushWriter:1,5,main]
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.getStackTrace(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:1552)
        at org.apache.cassandra.utils.concurrent.Ref$Debug.&amp;lt;init&amp;gt;(Ref.java:218)
        at org.apache.cassandra.utils.concurrent.Ref$State.&amp;lt;init&amp;gt;(Ref.java:148)
        at org.apache.cassandra.utils.concurrent.Ref.&amp;lt;init&amp;gt;(Ref.java:70)
        at org.apache.cassandra.db.lifecycle.LogTransaction.&amp;lt;init&amp;gt;(LogTransaction.java:122)
        at org.apache.cassandra.db.lifecycle.LifecycleTransaction.offline(LifecycleTransaction.java:147)
        at org.apache.cassandra.db.Memtable$FlushRunnable.createFlushWriter(Memtable.java:426)
        at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:366)
        at org.apache.cassandra.db.Memtable$FlushRunnable.runMayThrow(Memtable.java:352)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
        at com.google.common.util.concurrent.MoreExecutors$DirectExecutorService.execute(MoreExecutors.java:299)
        at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1037)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

ERROR [Reference-Reaper:1] 2015-10-19 01:29:11,445 Error when closing &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.db.lifecycle.LogTransaction$TransactionTidier@632410305:[build/test/cassandra/data:241/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/ma_txn_flush_cadfa480-7600-11e5-a7c7-1d8546d0512d.log] 
java.lang.AssertionError: Expected a completed transaction: [build/test/cassandra/data:241/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/ma_txn_flush_cadfa480-7600-11e5-a7c7-1d8546d0512d.log] 
        at org.apache.cassandra.db.lifecycle.LogTransaction$TransactionTidier.run(LogTransaction.java:243) ~[main/:na]
        at org.apache.cassandra.db.lifecycle.LogTransaction$TransactionTidier.tidy(LogTransaction.java:230) ~[main/:na]
        at org.apache.cassandra.utils.concurrent.Ref$GlobalState.release(Ref.java:294) ~[main/:na]
        at org.apache.cassandra.utils.concurrent.Ref$State.release(Ref.java:193) ~[main/:na]
        at org.apache.cassandra.utils.concurrent.Ref$ReferenceReaper.run(Ref.java:342) [main/:na]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_45]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745) [na:1.8.0_45]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14968676" author="stefania" created="Thu, 22 Oct 2015 07:15:33 +0000"  >&lt;p&gt;CI testall seems fine now. After 2 runs, failing tests are similar to 3.0 (&lt;tt&gt;testRecoverPITUnordered&lt;/tt&gt; also timed out on 3.0, build #202).&lt;/p&gt;</comment>
                            <comment id="14969495" author="aweisberg" created="Thu, 22 Oct 2015 17:22:50 +0000"  >&lt;p&gt;Can you update the Windows branch so we can see how it does on Windows before committing?&lt;/p&gt;

&lt;p&gt;I reviewed the additional commit and it looks good. You are fixing multiples failures right? Let&apos;s  see if I can list them so I am sure I understand.&lt;/p&gt;

&lt;p&gt;The first was the bad assumption in LogRecord.getExistingFiles, which caused it to throw, which exposed the missing exception handling in Memtable (leaking the transaction) which exposed the fact that leaked transactions when cleaned up by the garbage collector fail to cleanup due to an incorrect assertion.&lt;/p&gt;

&lt;p&gt;So when you fixed the assertion you call abort. What happens if a transaction commits, but isn&apos;t closed and that leads to the commit followed by an abort? Or is closing the only way to get a commit?&lt;/p&gt;</comment>
                            <comment id="14970203" author="stefania" created="Fri, 23 Oct 2015 00:43:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can you update the Windows branch so we can see how it does on Windows before committing?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Windows branch updated and jobs are scheduled:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-utest_win32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-utest_win32/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-dtest_win32/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-10421-windows-3.0-dtest_win32/&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The first was the bad assumption in LogRecord.getExistingFiles, which caused it to throw, which exposed the missing exception handling in Memtable (leaking the transaction) which exposed the fact that leaked transactions when cleaned up by the garbage collector fail to cleanup due to an incorrect assertion.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Your 100% correct. This once again highlights how beneficial testing this component with failure injection would be. Another example is &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-10538&quot; title=&quot;Assertion failed in LogFile when disk is full&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-10538&quot;&gt;&lt;del&gt;CASSANDRA-10538&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So when you fixed the assertion you call abort. What happens if a transaction commits, but isn&apos;t closed and that leads to the commit followed by an abort? Or is closing the only way to get a commit?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If a transaction commits then it is completed and we will not call abort. I think the only risk is if we throw an exception in the commit operation &lt;em&gt;after writing to file and before updating the records in memory&lt;/em&gt;, in which case we would end up with a corrupt file as you said. But after &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-10538&quot; title=&quot;Assertion failed in LogFile when disk is full&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-10538&quot;&gt;&lt;del&gt;CASSANDRA-10538&lt;/del&gt;&lt;/a&gt; is applied, we will update the records just after writing to file, so this should be safe.&lt;/p&gt;</comment>
                            <comment id="14971656" author="aweisberg" created="Fri, 23 Oct 2015 19:16:03 +0000"  >&lt;p&gt;This looks ready to commit. The windows utests and dtests seem to match the 3.0 windows branch.&lt;/p&gt;</comment>
                            <comment id="14971929" author="jmckenzie" created="Fri, 23 Oct 2015 21:44:55 +0000"  >&lt;p&gt;Committed as &lt;tt&gt;73781a9a497de99d8cf2088d804173a11a3982f0&lt;/tt&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12709760">CASSANDRA-7066</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[stefania]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 4 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2mgaf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>aweisberg</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[aweisberg]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12963"><![CDATA[Critical]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>