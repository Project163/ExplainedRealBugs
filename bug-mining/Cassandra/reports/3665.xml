<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:55:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-9686] FSReadError and LEAK DETECTED after upgrading</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-9686</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;After upgrading one of 15 nodes from 2.1.7 to 2.2.0-rc1 I get FSReadError and LEAK DETECTED on start. Deleting the listed files, the failure goes away.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;system.log&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [SSTableBatchOpen:1] 2015-06-29 14:38:34,554 DebuggableThreadPoolExecutor.java:242 - Error in ThreadPoolExecutor
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1c42271
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:178) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:117) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:86) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:142) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:101) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:178) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:681) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:644) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:443) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:350) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:480) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1c42271
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:174) ~[apache-cassandra-2.2.0-rc1.jar:2.2.0-rc1]
	... 15 common frames omitted
ERROR [Reference-Reaper:1] 2015-06-29 14:38:34,734 Ref.java:189 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@3e547f) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@1926439:D:\Programme\Cassandra\data\data\system\compactions_in_progress\system-compactions_in_progress-ka-6866 was not released before the reference was garbage collected
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Windows-7-32 bit, 3.2GB RAM, Java 1.7.0_55&lt;/p&gt;</environment>
        <key id="12841657">CASSANDRA-9686</key>
            <summary>FSReadError and LEAK DETECTED after upgrading</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stefania">Stefania Alborghetti</assignee>
                                    <reporter username="Andie78">Andreas Schnitzerling</reporter>
                        <labels>
                    </labels>
                <created>Tue, 30 Jun 2015 10:48:57 +0000</created>
                <updated>Wed, 15 Oct 2025 09:48:55 +0000</updated>
                            <resolved>Mon, 13 Jul 2015 17:32:12 +0000</resolved>
                                        <fixVersion>2.1.9</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                    <fixVersion>3.0 alpha 1</fixVersion>
                                    <component>Legacy/Local Write-Read Paths</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="14608560" author="philipthompson" created="Tue, 30 Jun 2015 15:54:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania&quot; class=&quot;user-hover&quot; rel=&quot;stefania&quot;&gt;Stefania&lt;/a&gt;, I know your plate is full, but can you look at this, and see if it looks bad enough to block rc2? Marcus is out for the week.&lt;/p&gt;</comment>
                            <comment id="14609433" author="stefania" created="Wed, 1 Jul 2015 01:48:55 +0000"  >&lt;p&gt;The LEAK errors are a consequence of the exception. We should fix it but we don&apos;t need to block rc2 since the garbage collector will release the resources when it collects the reader. In &lt;tt&gt;SSTableReader.open()&lt;/tt&gt; we should put a &lt;tt&gt;try&lt;/tt&gt; to make sure we close the reader in case of exception and increase the reference count by one just before returning it (but before closing it). &lt;/p&gt;

&lt;p&gt;I tried to reproduce the CompressionMetadata exception by interrupting a stress write on 2.1.7 and then launching 2.2.0-rc1 but I couldn&apos;t. The exception is simply saying that there are no compression chunks, which I assume there should be. Without the files it&apos;s difficult to say what the problem is.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Andie78&quot; class=&quot;user-hover&quot; rel=&quot;Andie78&quot;&gt;Andie78&lt;/a&gt; it would help if you could provide us with some of the system files causing the problem (one system cf such as compactions_in_progress should do), along with cassandra.yaml (before and after the upgrade if different) and any steps you took during the upgrade. If you cannot provide the data files, a log file at DEBUG level might help a bit more.&lt;/p&gt;

&lt;p&gt;There is also this warning that looks concerning:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;WARN  [main] 2015-06-29 16:58:12,169 CLibrary.java:72 - JNA link failure, one or more &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; method will be unavailable.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At debug level it should print the cause of the failure. Perhaps it&apos;s due to a 32-bit incompatibility that we introduced recently, or perhaps it has always been there, I&apos;m not sure. &lt;/p&gt;</comment>
                            <comment id="14609502" author="stefania" created="Wed, 1 Jul 2015 03:23:57 +0000"  >&lt;p&gt;I&apos;ve prepared a 2.2 patch for the leak errors, available &lt;a href=&quot;https://github.com/stef1927/cassandra/commits/9686-2.2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For verification purposes, the code I used to simulate the main exception is this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;diff --git a/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java b/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
index 23a9f3e..b92971d 100644
--- a/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
+++ b/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
@@ -170,7 +170,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;CompressionMetadata
         &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;
         {
             chunkCount = input.readInt();
-            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (chunkCount &amp;lt;= 0)
+            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (chunkCount &amp;lt;= 0 || indexFilePath.contains(&lt;span class=&quot;code-quote&quot;&gt;&quot;compactions_in_progress&quot;&lt;/span&gt;))
                 &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Compressed file with 0 chunks encountered: &quot;&lt;/span&gt; + input);
         }
         &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14609797" author="andie78" created="Wed, 1 Jul 2015 09:15:18 +0000"  >&lt;p&gt;I made a copy of the C* 2.1.7 instance before upgrading. So I attached the files before upgrade, which cause the leak errors after upgrade. &lt;br/&gt;
The upgrade-steps:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I copied the C* instance.&lt;/li&gt;
	&lt;li&gt;I replaced the folders except the data, commitlog and saved_caches folders.&lt;/li&gt;
	&lt;li&gt;I put data, commitlog and saved_caches folders into a new parent data-folder.&lt;/li&gt;
	&lt;li&gt;I made changes in cassandra.bat. Mainly limited RAM to 1 GB and jmxremote.&lt;/li&gt;
	&lt;li&gt;I changed necessary preferences in cassandra.yaml via diff.&lt;/li&gt;
	&lt;li&gt;I reinstalled the C*-service.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14610579" author="jmckenzie" created="Wed, 1 Jul 2015 16:16:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;There is also this warning that looks concerning:&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s a standard message on Windows. Most, if not all, of the members in CLibrary aren&apos;t going to be found in the Windows libc implementation regardless of 32v64.&lt;/p&gt;

&lt;p&gt;This ticket reminds me of &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8192&quot; title=&quot;Better error logging on corrupt compressed SSTables: currently AssertionError in Memory.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8192&quot;&gt;&lt;del&gt;CASSANDRA-8192&lt;/del&gt;&lt;/a&gt; and looks like it might be related. I modified CompressionMetadata to throw that exception rather than fail an assertion to give us more idea that we were dealing with a corrupt file. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Andie78&quot; class=&quot;user-hover&quot; rel=&quot;Andie78&quot;&gt;Andie78&lt;/a&gt;: Have you run a scrub on those sstables after upgrade? As your previous corrupt file was all 0&apos;s, if this is the same situation I don&apos;t know how much help scrub will be as it should just drop corrupt data but might be worth a shot.&lt;/p&gt;

&lt;p&gt;I&apos;m surprised that the files read fine on 2.1.7 and then fail on 2.2.0; the implication to me is that something caused corruption on those files during the upgrade process. Given that we&apos;re on a 32-bit JVM w/1GB dedicated to the heap, there&apos;s at least a couple of big elephants in the room that might be causing unexpected behavior here.&lt;/p&gt;</comment>
                            <comment id="14611557" author="stefania" created="Thu, 2 Jul 2015 06:41:20 +0000"  >&lt;p&gt;Using Andrea&apos;s compactions_in_progress sstable files I can reproduce the exception in &lt;b&gt;2.1.7&lt;/b&gt; regardless of heap size and on Linux 64bit:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR 05:51:50 Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[SSTableBatchOpen:1,5,main]
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@4854d57
        at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:205) ~[main/:na]
        at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:127) ~[main/:na]
        at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:85) ~[main/:na]
        at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:79) ~[main/:na]
        at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:72) ~[main/:na]
        at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:168) ~[main/:na]
        at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:721) ~[main/:na]
        at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:676) ~[main/:na]
        at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:482) ~[main/:na]
        at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:381) ~[main/:na]
        at org.apache.cassandra.io.sstable.SSTableReader$4.run(SSTableReader.java:519) ~[main/:na]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_45]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_45]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745) [na:1.8.0_45]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@4854d57
        at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:183) ~[main/:na]
        ... 15 common frames omitted
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Aside from the LEAK errors for which we have a patch, it&apos;s very much the same issue as &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8192&quot; title=&quot;Better error logging on corrupt compressed SSTables: currently AssertionError in Memory.java&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8192&quot;&gt;&lt;del&gt;CASSANDRA-8192&lt;/del&gt;&lt;/a&gt;. The following files contain only zeros:&lt;/p&gt;

&lt;p&gt;xxd -p system-compactions_in_progress-ka-6866-CompressionInfo.db&lt;br/&gt;
00000000000000000000000000000000000000000000000000000000000000000000000000000000000000&lt;/p&gt;

&lt;p&gt;xxd -p system-compactions_in_progress-ka-6866-Digest.sha1   &lt;br/&gt;
00000000000000000000&lt;/p&gt;

&lt;p&gt;xxd -p system-compactions_in_progress-ka-6866-TOC.txt&lt;br/&gt;
000000000000000000000000000000000000000000000000000000000000&lt;br/&gt;
000000000000000000000000000000000000000000000000000000000000&lt;br/&gt;
000000000000000000000000000000000000000000000000000000000000&lt;br/&gt;
000000000000000000&lt;/p&gt;

&lt;p&gt;The other files contain some data. I have no idea how they got to become like this. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Andie78&quot; class=&quot;user-hover&quot; rel=&quot;Andie78&quot;&gt;Andie78&lt;/a&gt; do you see any assertion failures or other exceptions in the log files before the upgrade? Do you do any offline operations on the files at all? And how do you stop the process normally?&lt;/p&gt;
</comment>
                            <comment id="14611681" author="andie78" created="Thu, 2 Jul 2015 09:05:26 +0000"  >&lt;p&gt;I checked the 2.1.7 instance, which I copied before upgrading. There is the same issue and I have an idea: Our computers are in 3 different laboratories for electronic engineers. C* is running there as a backround-job. We have regular emergency-tests once a month in the morning. They switch off power and computers are not shut-down. I think I cannot change the process there and in laboratories it can always happen during electronic-tests, that fuses are triggered. That can happen anywhere since not everybody uses power-backup. For my opinion, invalid files like here should be deleted - maybe with a warning in the log - especially if we don&apos;t loose data like here for temporary process-infos.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;system.log v2.1.7&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [SSTableBatchOpen:1] 2015-06-24 14:12:02,033 CassandraDaemon.java:223 - Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[SSTableBatchOpen:1,5,main]
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1a32dcf
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:205) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:127) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:85) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:79) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:72) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:168) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:721) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:676) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:482) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:381) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader$4.run(SSTableReader.java:519) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1a32dcf
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:183) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	... 15 common frames omitted
ERROR [SSTableBatchOpen:1] 2015-06-24 14:12:02,123 CassandraDaemon.java:223 - Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[SSTableBatchOpen:1,5,main]
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@11ca50a
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:205) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:127) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:85) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:79) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:72) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:168) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:721) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:676) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:482) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:381) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at org.apache.cassandra.io.sstable.SSTableReader$4.run(SSTableReader.java:519) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) ~[na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@11ca50a
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:183) ~[apache-cassandra-2.1.7-SNAPSHOT.jar:2.1.7-SNAPSHOT]
	... 15 common frames omitted
ERROR [Reference-Reaper:1] 2015-06-24 14:12:02,593 Ref.java:179 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@111283) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.io.util.PoolingSegmentedFile$Cleanup@714273:C:\VirtualDrives\D\Programme\cassandra\data\system\sstable_activity\system-sstable_activity-ka-1597-Index.db was not released before the reference was garbage collected
ERROR [Reference-Reaper:1] 2015-06-24 14:12:02,593 Ref.java:179 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@185571) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.io.sstable.SSTableReader$InstanceTidier@26308560:C:\VirtualDrives\D\Programme\cassandra\data\system\sstable_activity\system-sstable_activity-ka-1597 was not released before the reference was garbage collected
ERROR [Reference-Reaper:1] 2015-06-24 14:12:02,593 Ref.java:179 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@3eaef5) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@22054172:[Memory@[0..4), Memory@[0..18)] was not released before the reference was garbage collected
ERROR [Reference-Reaper:1] 2015-06-24 14:12:02,593 Ref.java:179 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@936f7e) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@24953003:[Memory@[0..14), Memory@[0..e1)] was not released before the reference was garbage collected
ERROR [Reference-Reaper:1] 2015-06-24 14:12:02,593 Ref.java:179 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@1afb805) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.io.sstable.SSTableReader$InstanceTidier@22709880:C:\VirtualDrives\D\Programme\cassandra\data\system\compactions_in_progress\system-compactions_in_progress-ka-6866 was not released before the reference was garbage collected
ERROR [Reference-Reaper:1] 2015-06-24 14:12:02,603 Ref.java:179 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@13e1f0a) to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.cassandra.io.util.PoolingSegmentedFile$Cleanup@23584166:C:\VirtualDrives\D\Programme\cassandra\data\system\compactions_in_progress\system-compactions_in_progress-ka-6866-Index.db was not released before the reference was garbage collected
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14611734" author="stefania" created="Thu, 2 Jul 2015 09:57:11 +0000"  >&lt;p&gt;Yes a disk corruption due to a power cut could explain it. I don&apos;t think we should delete corrupt sstables though, but we could maybe move them somewhere else - where they wouldn&apos;t be automatically loaded. Then the scrub tool could copy the fixed version back into the right folder, but this is kind of opposite of what it does at the moment (save a backup and then fix the original).&lt;/p&gt;

&lt;p&gt;I need someone a bit more experienced to comment on this. I&apos;ll ask on the IRC channel.&lt;/p&gt;</comment>
                            <comment id="14613039" author="stefania" created="Fri, 3 Jul 2015 09:12:29 +0000"  >&lt;p&gt;No one volunteered on IRC so let&apos;s wait for &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=krummas&quot; class=&quot;user-hover&quot; rel=&quot;krummas&quot;&gt;krummas&lt;/a&gt; to be back next week regarding handling of corrupt sstables.&lt;/p&gt;</comment>
                            <comment id="14614676" author="krummas" created="Mon, 6 Jul 2015 07:57:59 +0000"  >&lt;p&gt;The patch looks good to suppress the LEAK errors, but we should also honor the disk_failure_policy here - if we have &apos;die&apos; or &apos;stop&apos; etc configured, we should not allow cassandra to start with a corrupt sstable.&lt;/p&gt;

&lt;p&gt;We could probably have a look at the exception with FileUtils#handleFSError() in SSTR#openAll()&lt;/p&gt;</comment>
                            <comment id="14616396" author="stefania" created="Tue, 7 Jul 2015 09:11:45 +0000"  >&lt;p&gt;Thanks - I&apos;ll make sure to apply the correct disk failure policy to this exception and then submit a complete patch.&lt;/p&gt;</comment>
                            <comment id="14618207" author="stefania" created="Wed, 8 Jul 2015 08:25:32 +0000"  >&lt;p&gt;This is ready for review.&lt;/p&gt;

&lt;p&gt;I added handling of &lt;tt&gt;CorruptSSTableException&lt;/tt&gt; and &lt;tt&gt;FSError&lt;/tt&gt; when loading sstables. When the disk failure policy is &lt;tt&gt;die&lt;/tt&gt;, the process will exit as expected. For &lt;tt&gt;CorruptSSTableException&lt;/tt&gt;, the transports will be stopped only with &lt;tt&gt;stop_paranoid&lt;/tt&gt;, not just &lt;tt&gt;stop&lt;/tt&gt;, as per documentation in the yaml file. &lt;/p&gt;

&lt;p&gt;One potential issue is that tables are loaded during the initial health checks, before the transports are started. So stopping the transports has no effect. Later on they are started as if nothing happened. So effectively only the &lt;tt&gt;die&lt;/tt&gt; policy is honored in this scenario. Not sure what to do about this as it could be legit to want to restart the transports later on via JMX.&lt;/p&gt;

&lt;p&gt;CI results:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-testall/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-testall/lastCompletedBuild/testReport/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-dtest/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-dtest/lastCompletedBuild/testReport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One flacky dtest, I&apos;ve scheduled a new build (#4).&lt;/p&gt;</comment>
                            <comment id="14618209" author="stefania" created="Wed, 8 Jul 2015 08:28:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=krummas&quot; class=&quot;user-hover&quot; rel=&quot;krummas&quot;&gt;krummas&lt;/a&gt; are you happy to review since you already checked the partial patch?&lt;/p&gt;</comment>
                            <comment id="14618214" author="krummas" created="Wed, 8 Jul 2015 08:30:22 +0000"  >&lt;p&gt;sure, will have a look soon&lt;/p&gt;</comment>
                            <comment id="14618399" author="andie78" created="Wed, 8 Jul 2015 10:48:20 +0000"  >&lt;p&gt;I applied the patch. The only thing disturbing me, is that everytime, I restart C*, I get long stacktraces as well starting with:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [SSTableBatchOpen:1] (stacktrace)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. The error-one-liner &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [Reference-Reaper:1] LEAK DETECTED + Filename&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; should be enough not to blow up log since corrupted file is not handled by the user yet. Moving the corrupted files somewhere else would-be a good idea too for my opinion.&lt;/p&gt;</comment>
                            <comment id="14618610" author="krummas" created="Wed, 8 Jul 2015 13:47:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Andie78&quot; class=&quot;user-hover&quot; rel=&quot;Andie78&quot;&gt;Andie78&lt;/a&gt; I think having exceptions when starting with corrupt sstables is something you have to live with. But, do you still see the LEAK DETECTED errors?&lt;/p&gt;</comment>
                            <comment id="14618634" author="krummas" created="Wed, 8 Jul 2015 14:09:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;One potential issue is that tables are loaded during the initial health checks, before the transports are started.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania&quot; class=&quot;user-hover&quot; rel=&quot;stefania&quot;&gt;Stefania&lt;/a&gt; could we perhaps set a special startup exception boolean somewhere (StorageProxy) to not start transports + gossip on startup if we have configured &apos;stop&apos; and find corrupted sstables? This would still allow them to be started via JMX, but we would not automatically start the node with the corrupt sstables&lt;/p&gt;</comment>
                            <comment id="14619836" author="stefania" created="Thu, 9 Jul 2015 03:49:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;could we perhaps set a special startup exception boolean somewhere (StorageProxy) to not start transports + gossip on startup if we have configured &apos;stop&apos; and find corrupted sstables?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We could but Gossip is slightly problematic because of the local application states and it needs a little bit of refactoring. I am a bit hesitant hiding a Gossip change behind a ticket about corrupt sstables. So I would prefer to open another ticket stating clearly what we are doing. An alternative approach is to force a &quot;die&quot; policy during the startup checks or, better but slightly more work, make SystemKeyspace.checkHealth() throw a ConfigurationException if it notices some sstables were skipped. Do you think it&apos;s reasonable to refuse to start-up if the system keyspace has corrupt sstables even if the disk_failure_policy says to carry on?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Andie78&quot; class=&quot;user-hover&quot; rel=&quot;Andie78&quot;&gt;Andie78&lt;/a&gt; There shouldn&apos;t be any more LEAK DETECTED errors, at least I don&apos;t see any when starting up with corrupt files, please let us know if you see any.&lt;/p&gt;</comment>
                            <comment id="14619908" author="krummas" created="Thu, 9 Jul 2015 05:14:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania&quot; class=&quot;user-hover&quot; rel=&quot;stefania&quot;&gt;Stefania&lt;/a&gt; Agreed, lets not refactor gossip startup here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; How about we add a &quot;handleStartupFSError&quot; in FileUtils that just makes sure we die with a good error message if we have configured die/stop/stop_paranoid? Reason for stop/stop_paranoid is that operators might want to inspect the node with JMX/nodetool etc, but there is not much to inspect before starting up properly, so dying should be acceptable&lt;/p&gt;</comment>
                            <comment id="14619960" author="stefania" created="Thu, 9 Jul 2015 06:04:28 +0000"  >&lt;p&gt;Sounds good, thanks.&lt;/p&gt;</comment>
                            <comment id="14621574" author="stefania" created="Fri, 10 Jul 2015 01:32:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=krummas&quot; class=&quot;user-hover&quot; rel=&quot;krummas&quot;&gt;krummas&lt;/a&gt;, the last part is ready for review. &lt;/p&gt;

&lt;p&gt;CI seems OK:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-testall/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-testall/lastCompletedBuild/testReport/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-dtest/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.2-dtest/lastCompletedBuild/testReport/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14621869" author="krummas" created="Fri, 10 Jul 2015 07:11:52 +0000"  >&lt;p&gt;this looks good to me, +1&lt;/p&gt;

&lt;p&gt;we should push this to 2.1 as well I think, could you backport (and squash etc)?&lt;/p&gt;</comment>
                            <comment id="14621937" author="stefania" created="Fri, 10 Jul 2015 08:00:08 +0000"  >&lt;p&gt;It&apos;s &lt;a href=&quot;https://github.com/stef1927/cassandra/commits/9686-2.1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;done&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I will post the CI results once they are available.&lt;/p&gt;</comment>
                            <comment id="14623160" author="stefania" created="Sat, 11 Jul 2015 01:14:48 +0000"  >&lt;p&gt;CI results for 2.1:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.1-testall/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.1-testall/lastCompletedBuild/testReport/&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.1-dtest/lastCompletedBuild/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cassci.datastax.com/view/Dev/view/stef1927/job/stef1927-9686-2.1-dtest/lastCompletedBuild/testReport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There seems to be a few flacky dtests so I launched a second dtest build.&lt;/p&gt;</comment>
                            <comment id="14623252" author="jjirsa" created="Sat, 11 Jul 2015 06:04:41 +0000"  >&lt;p&gt;Is this related to &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9774&quot; title=&quot;fix sstableverify dtest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9774&quot;&gt;&lt;del&gt;CASSANDRA-9774&lt;/del&gt;&lt;/a&gt; ? &lt;/p&gt;</comment>
                            <comment id="14624431" author="stefania" created="Mon, 13 Jul 2015 09:35:39 +0000"  >&lt;p&gt;I don&apos;t think so. If I understood correctly, the problem with &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9774&quot; title=&quot;fix sstableverify dtest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9774&quot;&gt;&lt;del&gt;CASSANDRA-9774&lt;/del&gt;&lt;/a&gt; is that the test relied incorrectly on a LEAK DETECTED error that got fixed - but it cannot have been fixed by this patch since we haven&apos;t committed yet. In any case the solution for &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9774&quot; title=&quot;fix sstableverify dtest&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9774&quot;&gt;&lt;del&gt;CASSANDRA-9774&lt;/del&gt;&lt;/a&gt; is to fix the test since it appears the LEAK error is gone already.&lt;/p&gt;</comment>
                            <comment id="14624561" author="andie78" created="Mon, 13 Jul 2015 11:58:36 +0000"  >&lt;p&gt;After applying all patches, the server stops now on corrupted files with several exceptions. LEAK ERROR I liked more since the server kept on running. Can we not move those files to another directory since the hard-drive is not corrupted? Is it necessary to stop on policy &quot;stop&quot; for these errors?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;system.log&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;WARN  [main] 2015-07-13 13:43:49,838 CLibrary.java:72 - JNA link failure, one or more &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; method will be unavailable.
WARN  [main] 2015-07-13 13:43:49,838 StartupChecks.java:148 - 32bit JVM detected.  It is recommended to run Cassandra on a 64bit JVM &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; better performance.
WARN  [main] 2015-07-13 13:43:50,048 SigarLibrary.java:167 - Cassandra server running in degraded mode. Is swap disabled? : &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;,  Address space adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,  nofile limit adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, nproc limit adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; 
ERROR [SSTableBatchOpen:1] 2015-07-13 13:44:07,959 SSTableReader.java:503 - Cannot read sstable D:\Programme\Cassandra\data\data\logdata\onlinedata\la-115-big=[Data.db, Index.db, Filter.db, CompressionInfo.db, Statistics.db, TOC.txt, Digest.adler32]; file system error, skipping table
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@18340c2
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:117) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:86) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:142) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:101) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:695) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:656) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:450) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:356) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:493) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@18340c2
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:174) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	... 15 common frames omitted
ERROR [SSTableBatchOpen:1] 2015-07-13 13:44:07,959 FileUtils.java:464 - Exiting forcefully due to file system exception on startup, disk failure policy &lt;span class=&quot;code-quote&quot;&gt;&quot;stop&quot;&lt;/span&gt;
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@18340c2
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:117) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:86) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:142) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:101) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:695) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:656) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:450) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:356) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:493) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@18340c2
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:174) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	... 15 common frames omitted
WARN  [main] 2015-07-13 13:44:21,439 CLibrary.java:72 - JNA link failure, one or more &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; method will be unavailable.
WARN  [main] 2015-07-13 13:44:21,439 StartupChecks.java:148 - 32bit JVM detected.  It is recommended to run Cassandra on a 64bit JVM &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; better performance.
WARN  [main] 2015-07-13 13:44:21,489 SigarLibrary.java:167 - Cassandra server running in degraded mode. Is swap disabled? : &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;,  Address space adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,  nofile limit adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, nproc limit adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; 
ERROR [SSTableBatchOpen:1] 2015-07-13 13:44:30,170 SSTableReader.java:503 - Cannot read sstable D:\Programme\Cassandra\data\data\logdata\onlinedata\la-115-big=[Index.db, Filter.db, CompressionInfo.db, TOC.txt, Data.db, Statistics.db, Digest.adler32]; file system error, skipping table
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1ec3e42
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:117) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:86) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:142) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:101) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:695) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:656) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:450) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:356) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:493) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1ec3e42
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:174) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	... 15 common frames omitted
ERROR [SSTableBatchOpen:1] 2015-07-13 13:44:30,170 FileUtils.java:464 - Exiting forcefully due to file system exception on startup, disk failure policy &lt;span class=&quot;code-quote&quot;&gt;&quot;stop&quot;&lt;/span&gt;
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1ec3e42
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:117) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:86) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:142) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:101) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:695) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:656) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:450) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:356) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:493) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@1ec3e42
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:174) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	... 15 common frames omitted
WARN  [main] 2015-07-13 13:44:53,400 CLibrary.java:72 - JNA link failure, one or more &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt; method will be unavailable.
WARN  [main] 2015-07-13 13:44:53,410 StartupChecks.java:148 - 32bit JVM detected.  It is recommended to run Cassandra on a 64bit JVM &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; better performance.
WARN  [main] 2015-07-13 13:44:53,450 SigarLibrary.java:167 - Cassandra server running in degraded mode. Is swap disabled? : &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;,  Address space adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,  nofile limit adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, nproc limit adequate? : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; 
ERROR [SSTableBatchOpen:2] 2015-07-13 13:45:02,611 SSTableReader.java:503 - Cannot read sstable D:\Programme\Cassandra\data\data\logdata\onlinedata\la-115-big=[Index.db, Filter.db, CompressionInfo.db, TOC.txt, Data.db, Statistics.db, Digest.adler32]; file system error, skipping table
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@310c8b
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:117) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:86) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:142) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:101) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:695) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:656) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:450) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:356) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:493) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@310c8b
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:174) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	... 15 common frames omitted
ERROR [SSTableBatchOpen:2] 2015-07-13 13:45:02,611 FileUtils.java:464 - Exiting forcefully due to file system exception on startup, disk failure policy &lt;span class=&quot;code-quote&quot;&gt;&quot;stop&quot;&lt;/span&gt;
org.apache.cassandra.io.FSReadError: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@310c8b
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.&amp;lt;init&amp;gt;(CompressionMetadata.java:117) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:86) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:142) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:101) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:178) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:695) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:656) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:450) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:356) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:493) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0_55]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0_55]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source) [na:1.7.0_55]
Caused by: java.io.IOException: Compressed file with 0 chunks encountered: java.io.DataInputStream@310c8b
	at org.apache.cassandra.io.compress.CompressionMetadata.readChunkOffsets(CompressionMetadata.java:174) ~[apache-cassandra-2.2.0-rc2-SNAPSHOT.jar:2.2.0-rc2-SNAPSHOT]
	... 15 common frames omitted
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14624650" author="stefania" created="Mon, 13 Jul 2015 13:38:09 +0000"  >&lt;p&gt;That&apos;s the expected behavior, see the discussion above regarding carrying on with corrupt system tables. It&apos;s a bug that &lt;em&gt;stop&lt;/em&gt; allows the transports and gossip to be started after we have encountered corrupt sstable files. If it happened after startup, &lt;em&gt;stop&lt;/em&gt; would leave the process running but with no gossip or transports, so that you cannot do anything with it other than analyzing the status via JMX. During startup, gossip or the transports aren&apos;t started yet, so they are not stopped and later they start. We decided the easiest way to fix this was to stop the process if we encounter corrupt sstables at startup.&lt;/p&gt;

&lt;p&gt;You can use the &lt;em&gt;ignore&lt;/em&gt; policy to carry on, but you really should fix corrupt sstable files, or the system may become unstable depending on which sstable files are corrupt.&lt;/p&gt;

&lt;p&gt;If standalone scrub (sstablescrub) recovers the files (it couldn&apos;t with yours) then it would move them as well. Perhaps you could open a ticket to enhance sstablescrub to always move files, even if they cannot be recovered. So I suggest you try standalone scrub and open a ticket with a request to move the files, perhaps via a command line argument? The idea would be: cassandra fails fast (it won&apos;t start), you run standalone scrub and restart. Better like this than ignoring corrupt sstable files IMO.&lt;/p&gt;</comment>
                            <comment id="14624687" author="andie78" created="Mon, 13 Jul 2015 14:10:04 +0000"  >&lt;p&gt;Would-be nice if I could decide that behavior with a parameter and not ignoring all in general. If I&apos;m not in my company for some days or on weekend, I cannot inspect the files. I have to rely on the cluster, even on hard reset of the nodes.&lt;/p&gt;</comment>
                            <comment id="14624998" author="krummas" created="Mon, 13 Jul 2015 17:32:12 +0000"  >&lt;p&gt;committed&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Andie78&quot; class=&quot;user-hover&quot; rel=&quot;Andie78&quot;&gt;Andie78&lt;/a&gt; if you have a good use case for allowing startup on corrupt files, but closing down if we find corrupt files during runtime, please file a new ticket&lt;/p&gt;</comment>
                            <comment id="14626108" author="andie78" created="Tue, 14 Jul 2015 09:35:09 +0000"  >&lt;p&gt;I just want the same behavior as in prior versions of C*. Means not to stop on corrupted files since I have replication and regular repair of important keyspaces. So I have to use IGNORE to reach that since I&apos;m not at work everyday and C* is used everyday.&lt;/p&gt;</comment>
                            <comment id="14627911" author="andie78" created="Wed, 15 Jul 2015 11:30:23 +0000"  >&lt;p&gt;I filed a new ticket &quot;Handle corrupted files during startup.&quot; (&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-9812&quot; title=&quot;Handle corrupted files during startup.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-9812&quot;&gt;CASSANDRA-9812&lt;/a&gt;).&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12743028" name="cassandra.bat" size="7175" author="Andie78" created="Wed, 1 Jul 2015 09:15:18 +0000"/>
                            <attachment id="12743027" name="cassandra.yaml" size="40653" author="Andie78" created="Wed, 1 Jul 2015 09:15:18 +0000"/>
                            <attachment id="12743025" name="compactions_in_progress.zip" size="2611" author="Andie78" created="Wed, 1 Jul 2015 09:15:18 +0000"/>
                            <attachment id="12743026" name="sstable_activity.zip" size="19676" author="Andie78" created="Wed, 1 Jul 2015 09:15:18 +0000"/>
                            <attachment id="12742778" name="system.log" size="34453" author="Andie78" created="Tue, 30 Jun 2015 10:48:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[stefania]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 18 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2goi7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>marcuse</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[marcuse]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
                        <customfieldname>Since Version</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332370">2.2.0 rc1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>