<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:45:54 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-7275] Errors in FlushRunnable may leave threads hung</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-7275</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;In Memtable.FlushRunnable, the CountDownLatch will never be counted down if there are errors, which results in hanging any threads that are waiting for the flush to complete.  For example, an error like this causes the problem:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [FlushWriter:474] 2014-05-20 12:10:31,137 CassandraDaemon.java (line 198) Exception in thread Thread[FlushWriter:474,5,main]
java.lang.IllegalArgumentException
    at java.nio.Buffer.position(Unknown Source)
    at org.apache.cassandra.db.marshal.AbstractCompositeType.getBytes(AbstractCompositeType.java:64)
    at org.apache.cassandra.db.marshal.AbstractCompositeType.getWithShortLength(AbstractCompositeType.java:72)
    at org.apache.cassandra.db.marshal.AbstractCompositeType.split(AbstractCompositeType.java:138)
    at org.apache.cassandra.io.sstable.ColumnNameHelper.minComponents(ColumnNameHelper.java:103)
    at org.apache.cassandra.db.ColumnFamily.getColumnStats(ColumnFamily.java:439)
    at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:194)
    at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:397)
    at org.apache.cassandra.db.Memtable$FlushRunnable.runWith(Memtable.java:350)
    at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48)
    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
    at java.lang.Thread.run(Unknown Source)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12715643">CASSANDRA-7275</key>
            <summary>Errors in FlushRunnable may leave threads hung</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10003" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Low</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="2">Won&apos;t Fix</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="thobbs">Tom Hobbs</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 May 2014 00:14:48 +0000</created>
                <updated>Tue, 14 Oct 2025 12:13:59 +0000</updated>
                            <resolved>Mon, 24 Aug 2015 16:23:57 +0000</resolved>
                                                            <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="14004287" author="jbellis" created="Wed, 21 May 2014 03:33:38 +0000"  >&lt;p&gt;(Disagree that this is critical since the real bug is the IAE.)&lt;/p&gt;</comment>
                            <comment id="14029737" author="jbellis" created="Thu, 12 Jun 2014 20:18:30 +0000"  >&lt;p&gt;Attaching Mikhail&apos;s patch.&lt;/p&gt;</comment>
                            <comment id="14029923" author="thobbs" created="Thu, 12 Jun 2014 22:17:22 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="14030172" author="mishail" created="Fri, 13 Jun 2014 02:17:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis&quot; class=&quot;user-hover&quot; rel=&quot;jbellis&quot;&gt;jbellis&lt;/a&gt; we need this for 1.2 as well, right?&lt;/p&gt;</comment>
                            <comment id="14036106" author="thobbs" created="Wed, 18 Jun 2014 18:32:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mishail&quot; class=&quot;user-hover&quot; rel=&quot;mishail&quot;&gt;mishail&lt;/a&gt; yes, 1.2 has the same problem.&lt;/p&gt;</comment>
                            <comment id="14036923" author="mishail" created="Thu, 19 Jun 2014 03:58:32 +0000"  >&lt;p&gt;Committed &lt;/p&gt;</comment>
                            <comment id="14036941" author="yukim" created="Thu, 19 Jun 2014 04:25:56 +0000"  >&lt;p&gt;If we countdown latch when writing SSTable failed, then we shuold not proceed to discard commit log in postFlushExecutor. I think we need to check exception somehow.&lt;/p&gt;</comment>
                            <comment id="14037514" author="yukim" created="Thu, 19 Jun 2014 16:55:32 +0000"  >&lt;p&gt;I reopen this and will attach alternative solution to remove latch.&lt;/p&gt;</comment>
                            <comment id="14037516" author="yukim" created="Thu, 19 Jun 2014 16:56:43 +0000"  >&lt;p&gt;Patch removes latch completely and use ListenableFuture instead. This way we can submit post flush process only if related flushes succeed.&lt;br/&gt;
(patch is against 2.0 branch, but maybe 2.1 is suitable for the change)&lt;/p&gt;</comment>
                            <comment id="14038506" author="mishail" created="Fri, 20 Jun 2014 06:05:41 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [javac] Compiling 865 source files to /Users/mikhail/Documents/workspace/cassandra/build/classes/main
    [javac] /Users/mikhail/Documents/workspace/cassandra/src/java/org/apache/cassandra/db/ColumnFamilyStore.java:29: error: cannot find symbol
    [javac] &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; javax.annotation.Nullable;
    [javac]                        ^
    [javac]   symbol:   &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Nullable
    [javac]   location: &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt; javax.annotation
    [javac] /Users/mikhail/Documents/workspace/cassandra/src/java/org/apache/cassandra/db/ColumnFamilyStore.java:807: error: cannot find symbol
    [javac]                 &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void onSuccess(@Nullable &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; result)
    [javac]                                        ^
    [javac]   symbol: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Nullable
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Otherwise +1&lt;/p&gt;</comment>
                            <comment id="14038635" author="benedict" created="Fri, 20 Jun 2014 10:01:40 +0000"  >&lt;p&gt;This will break the commit log, by causing records to be discarded out of order. The future does not get placed on the executor until the onSuccess is called now, so run order is simply in order of flush completion and no longer in order of submission, but the only point of separating the work onto the postFlush is to ensure it is run in submission order (but not before the flush is finished - see the comment that is now attached to onSuccess). &lt;/p&gt;

&lt;p&gt;The simplest correct solution is probably to annotate the post flush runnable with a state variable indicating success/failure, which is set before the latch is triggered.&lt;/p&gt;

&lt;p&gt;If you&apos;re modifying these parts of the code where correctness is paramount and not always obvious, it would be great if you could explicitly run it past a third set of eyes, as I only happened to spot this in the commits@ feeds, and as it&apos;s a concurrency bug could easily have not been spotted. Although we could no doubt craft a specific test to look for this scenario, and perhaps we should.&lt;/p&gt;</comment>
                            <comment id="14039316" author="jbellis" created="Fri, 20 Jun 2014 20:34:20 +0000"  >&lt;p&gt;I&apos;ve reverted the original commit pending a new fix, so we don&apos;t block 1.2.17 or 2.0.9 in the meantime.&lt;/p&gt;</comment>
                            <comment id="14246399" author="xedin" created="Mon, 15 Dec 2014 07:32:36 +0000"  >&lt;p&gt;First take on this problem, I&apos;ve added Flush info with stores boolean (was successful or not) per-cfid being flushed and only disregards commit log per-cfid if the flush was a success.&lt;/p&gt;</comment>
                            <comment id="14246780" author="jbellis" created="Mon, 15 Dec 2014 16:09:04 +0000"  >&lt;p&gt;(&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict&quot; class=&quot;user-hover&quot; rel=&quot;benedict&quot;&gt;benedict&lt;/a&gt; to review)&lt;/p&gt;</comment>
                            <comment id="14246852" author="benedict" created="Mon, 15 Dec 2014 17:09:49 +0000"  >&lt;p&gt;I&apos;m not sure this really improves the current state of affairs very much, and introduces a bug as well.&lt;/p&gt;

&lt;p&gt;If we fail to flush and simply carry on without clearing the CL, then the host will retain the memtable it wanted to flush forever, leaving it in a potentially severely degraded state (increasing risk of exceeding heap limit, or possible failing to ever accept writes in 2.1 due to insufficient memory). If the same table has another flush backed up (or another is later scheduled) then we will also end up expiring the commit log records anyway, despite not having flushed successfully.&lt;/p&gt;

&lt;p&gt;Either we need to reattempt the flush, prevent any further flushes on that column family from ever succeeding, or - more simply - kill the C* process.&lt;/p&gt;</comment>
                            <comment id="14247074" author="xedin" created="Mon, 15 Dec 2014 19:21:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure this really improves the current state of affairs very much, and introduces a bug as well.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It improve the current state of affairs in the way that failures in the flush are not going to incur compaction freeze anymore.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we fail to flush and simply carry on without clearing the CL, then the host will retain the memtable it wanted to flush forever, leaving it in a potentially severely degraded state (increasing risk of exceeding heap limit, or possible failing to ever accept writes in 2.1 due to insufficient memory). If the same table has another flush backed up (or another is later scheduled) then we will also end up expiring the commit log records anyway, despite not having flushed successfully.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think what we can do to prevent CL expiry is to mark it as discarded but without deleting actual file on disk, this way it can be replayed on start up and memtable flushes that follow are not going to delete any potentially unflushed data. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Either we need to reattempt the flush, prevent any further flushes on that column family from ever succeeding, or - more simply - kill the C* process.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Let&apos;s start with reattempting flush - we don&apos;t really have enough information to make a decision to re-attempt flushing as it can fail for the number of reasons, I/O error is just being one of them.&lt;br/&gt;
Killing C* process is harmful as if we have code problem in writeSortedContents or replaceFlushed code it would potentially result in shutdown of the whole cluster or at least of all of the neighbors sharing replica range.&lt;/p&gt;</comment>
                            <comment id="14247461" author="benedict" created="Tue, 16 Dec 2014 00:01:15 +0000"  >&lt;p&gt;What happens if the process stays up longer than tombstone grace period? Or we introduce &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6434&quot; title=&quot;Repair-aware gc grace period&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6434&quot;&gt;&lt;del&gt;CASSANDRA-6434&lt;/del&gt;&lt;/a&gt;? This approach seems like a minefield to me, ignoring the operational risks of running a very degraded server without the operators realising it. &lt;/p&gt;

&lt;p&gt;Generally we take the approach of dying if a non-recoverable error occurs, and while I agree the risk of killing a whole cluster through a bug is suboptimal, we already run that risk in a number of places in the codebase (current behaviour here included, just with less alacrity). In my opinion this is preferable to potentially re-introducing dead data, or having the complexity of safely keeping the process alive as a zombie, and ensuring that zombie doesn&apos;t degrade cluster performance by hobbling instead of dying.&lt;/p&gt;

&lt;p&gt;Other than dying, periodically trying to reflush and only keeling over when we run out of room or have failed for a long period (possibly random? to avoid the tiny risk of bunching) seems like a good idea.&lt;/p&gt;</comment>
                            <comment id="14247538" author="xedin" created="Tue, 16 Dec 2014 01:06:29 +0000"  >&lt;p&gt;There is an option to die on the I/O error and I&apos;m happy to make it so we die if we got FSWriteError or similar if requested by config.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Generally we take the approach of dying if a non-recoverable error occurs, and while I agree the risk of killing a whole cluster through a bug is suboptimal, we already run that risk in a number of places in the codebase (current behaviour here included, just with less alacrity). In my opinion this is preferable to potentially re-introducing dead data, or having the complexity of safely keeping the process alive as a zombie, and ensuring that zombie doesn&apos;t degrade cluster performance by hobbling instead of dying.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Here is your real world scenario, which we are hitting from time to time, right now if I/O error occurs in the replaceFlushed (e.g. trying to create hard-link for system.compactions_in_progress) all of the compaction threads are going to get blocked and performance is going to gradually degrade until it gets to the point when alerts from compaction pending trigger, at that time somebody has to (most luckily wake up) figure out what is going on and restart the node, once it starts back up the amount of catching up it has to do in terms of the compaction is substantial. This problem happens on the number of machines at the same time so if we were to kill the nodes right when aforementioned error occurs (although it&apos;s not affecting actual flush or compaction) that would mean that part of the ring just went dark and one just has to pray that those nodes weren&apos;t neighbors, so in this case serve some stale reads (which is not even the case if failure in in bookeeping CF) with error in the log is much better than loose portion of the cluster for (possibly tens) minutes without any idea of what is going on.&lt;/p&gt;

&lt;p&gt;In this situation I would rather ignore problems with book-keeping CFs or save CL segments forget about it and/or bumping up read-repair chance at the same time.&lt;/p&gt;

&lt;p&gt;Everybody who is running Cassandra or any other database/system wants a peace of mind that&apos;s why regular repairs and all sorts of the alerting/monitoring systems are in-place, if there is something in the log which indicates a problem it gives people time to think about their next steps instead of chaotically trying to fix what ever mess we left on failure.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Other than dying, periodically trying to re-flush and only keeling over when we run out of room or have failed for a long period (possibly random? to avoid the tiny risk of bunching) seems like a good idea.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not going to help if the problem data driven or external, you just going to trash flusher threads without doing any useful work.&lt;/p&gt;</comment>
                            <comment id="14248554" author="benedict" created="Tue, 16 Dec 2014 17:50:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;This is not going to help if the problem data driven or external, you just going to trash flusher threads without doing any useful work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, let&apos;s try and address each problem independently. A data induced bug that can occur across many nodes simultaneously is likely to occur repeatedly and cause the cluster to degrade probably quite rapidly, and will likely occur on all owners of a given token at once. Coupled with the stop-gap measures we&apos;re discussing might well run the risk of actual data loss or data corruption cross-cluster. Read repair would &lt;em&gt;not&lt;/em&gt; help for such a data bug, since none of the nodes would be in a safe state.&lt;/p&gt;

&lt;p&gt;However the transient file system problems you&apos;re encountering would be helped by reattempting the flush. So, an initial and completely safe approach would be to retry a few times and &lt;em&gt;then&lt;/em&gt; crash the server (possibly with some random waiting involved to avoid a disastrous cascade of cluster-wide death). Wasting work isn&apos;t really a big problem if the system cannot make progress without this success, so I don&apos;t see a downside on that front. It&apos;s possible if, once this fails, we could negotiate a safe crash with our peers, so that if there is a data bug at most one replica dies, the operator is well aware of the problem, but the cluster continues to operate. Although this is difficult with vnodes, and perhaps a little contrived for the current state of c*.&lt;/p&gt;

&lt;p&gt;Separately, we can look into perhaps weakening our constraints in various ways. The big issue you raise is that compaction is specifically held up. There seem to be two things we can do to help this:&lt;/p&gt;

&lt;p&gt;1) We can make the dependency queue for marking commit log records unused table-specific, so that compactions only get held up if there has been an error on the compaction queue;&lt;br/&gt;
2) We can report these exceptions back to the waiter on the Future result, and this waiter can choose how to behave. If, say, the memtable of a system column family that can be worked-around fails to flush (for instance, compactions_in_progress) then instead of retrying, it can simply take some other action to ensure the system continues to make safe progress. If a data table fails to flush it can attempt to retry. &lt;/p&gt;

&lt;p&gt;Eventually, if it cannot recover safely, it should die though, as there will need to be some operator involvement and the reality is not everybody monitors their log files. I am very -1 on introducing a change that knowingly produces a complex failure condition that will not be widely known or understood, but I may be alone on that.&lt;/p&gt;</comment>
                            <comment id="14249033" author="jbellis" created="Tue, 16 Dec 2014 21:57:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;Killing C* process is harmful as if we have code problem in writeSortedContents or replaceFlushed code it would potentially result in shutdown of the whole cluster or at least of all of the neighbors sharing replica range.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m much more comfortable with &quot;things die if something goes catastrophically wrong&quot; than &quot;things start returning nonsense on reads&quot; which is what happens if we mark something flushed that actually wasn&apos;t.&lt;/p&gt;

&lt;p&gt;That said, I&apos;d be okay using disk failure policy as a guide.  If people opt into best effort behavior and are okay with those implications, so be it.&lt;/p&gt;</comment>
                            <comment id="14249053" author="xedin" created="Tue, 16 Dec 2014 22:09:13 +0000"  >&lt;p&gt;I understand it might be hard for you, Benedict, but just consider there could be a programming error in the flush of the memtable or replacing flushed one, which is only triggered when metadata about compaction is written back at the end of that compaction e.g. CompactionTask.runMayThrow() L225, e.g. error mentioned in the description or &quot;duplicate hard-link failure&quot; or something similar which has nothing to do with the underlaying (file-)system which means that #1 suggestion is not going to help because compaction is blocked in SystemKeyspace.finishCompaction() and flush retry is not going to help because it will just fail again and again trying to flush the same data. As an end user I would prefer that nobody actually takes a decision to fail on the floor for me except me because it means data loss even when problem is not affecting actual write/read path, I would be fine though to fail on FS{Read, Write}Error if user explicitly sets it to fail on I/O errors (e.g. &quot;disk_failure_policy&quot;, it is like of your #2 but not exactly) otherwise I would rather get notified in the log and carry on so I can take informed decision on my next actions.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Eventually, if it cannot recover safely, it should die though, as there will need to be some operator involvement and the reality is not everybody monitors their log files.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m going to ignore this argument until you actually have experience of running Cassandra in production, otherwise it&apos;s the same as talking to the wall.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m much more comfortable with &quot;things die if something goes catastrophically wrong&quot; than &quot;things start returning nonsense on reads&quot; which is what happens if we mark something flushed that actually wasn&apos;t.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I remember it was already the same when the disk is full in the DSE, did people actually have fun restoring cluster after it went completely dark? I&apos;m also &lt;b&gt;not&lt;/b&gt; saying that we shouldn&apos;t fail on FS{Read, Write}Error if &quot;disk_failure_policy&quot; says otherwise.&lt;/p&gt;</comment>
                            <comment id="14249077" author="jbellis" created="Tue, 16 Dec 2014 22:28:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;consider there could be a programming error in the flush of the memtable or replacing flushed one&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t know that hand waving about potential bugs gets us anywhere.  There could be programming errors anywhere, including in &quot;mark the segment flushed when it wasn&apos;t&quot; panic mode.  The right solution to bugs is QA, not hoping that you can guess where unexpected exceptions will happen and provide a safety net.&lt;/p&gt;

&lt;p&gt;Edit: which is to say that I think the right scope here is, &quot;what do we do if we can&apos;t flush because of an i/o error,&quot; which is an expected condition that C* should be able to cope with cleanly.&lt;/p&gt;</comment>
                            <comment id="14249148" author="jasobrown" created="Tue, 16 Dec 2014 23:15:33 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; The right solution to bugs is QA&lt;/p&gt;

&lt;p&gt;I kind of agree with this, but QA can only confirm that we&apos;ve fixed what we&apos;ve discovered as faulty. Strange things will always happen in the real world, and unfortunately QA cannot discover (all of) those.&lt;/p&gt;

&lt;p&gt;This is a problem we have today - now, in fact. Unfortunately, blindly shutting down nodes for us (and, I suspect, most installations) isn&apos;t a viable solution as it could result in an uncontrolled cascade of shutdowns. I&apos;m not saying we shouldn&apos;t shut down on real file system problems (especially if the operator has set disk_failure_policy properly), but here&apos;s our situation: all compactions completely shut down when we fail to create the hard link for incremental backups, simply on a system CF with only metadata. This could be a legit file system problem, that affects the entire system, or it could be something minor, but perhaps we can be smarter about the known things that can fail that we deem not fatal (and then choose how we want to react to those). In our case, while it&apos;s unfortunate that some incremental backup data might be lost, it would be (and is) much worse to crash the system. If it&apos;s a programming bug, perhaps we should follow what the operator sets up for the disk_failure_policy, but it seems a shame to shutdown on something trivial like failing to create a hard link, especially on system metadata CFs. &lt;/p&gt;
</comment>
                            <comment id="14249160" author="jbellis" created="Tue, 16 Dec 2014 23:26:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;it seems a shame to shutdown on something trivial like failing to create a hard link, especially on system metadata CFs&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, if the disk is erroring out, failing to create a hard link is only the first problem you&apos;ll have. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  But again, disk failure policy covers this, so sure, go ahead and take evasive action if you prefer.  I think Pavel&apos;s suggestion of dropping the memtable but leaving the commitlog marked to-replay is reasonable for that scenario.&lt;/p&gt;

&lt;p&gt;If it&apos;s our bug, then you may need a temporary patch while we figure out the cause, but I still don&apos;t think that kind of &lt;tt&gt;// this shouldn&apos;t happen&lt;/tt&gt; code should be shipped officially.&lt;/p&gt;</comment>
                            <comment id="14249174" author="xedin" created="Tue, 16 Dec 2014 23:47:37 +0000"  >&lt;p&gt;The problem is that there is no way to tell if hard-link problem is a actual fs/disk problem or programming error, right now it looks like a programming error because it snapshot tries to create duplicate hard-link to the same file as I mentioned in the &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8476&quot; title=&quot;RE in writeSortedContents or replaceFlushed blocks compaction threads indefinitely.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8476&quot;&gt;&lt;del&gt;CASSANDRA-8476&lt;/del&gt;&lt;/a&gt; so if there is no way to tell how reasonable is it to enforce shutdown or any rule from &quot;disk_failure_policy&quot;?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If it&apos;s our bug, then you may need a temporary patch while we figure out the cause, but I still don&apos;t think that kind of // this shouldn&apos;t happen code should be shipped officially.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If it&apos;s your problem it&apos;s my problem as well, we have a work-around for now (as I guess most of the people do) but my intention in this ticket to fix this problem for good instead of just fixing the symptom of it (being aforementioned &quot;duplicate hard-link&quot; problem).&lt;/p&gt;</comment>
                            <comment id="14249718" author="benedict" created="Wed, 17 Dec 2014 11:16:07 +0000"  >&lt;p&gt;I&apos;ve filed &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8496&quot; title=&quot;Remove MemtablePostFlusher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8496&quot;&gt;CASSANDRA-8496&lt;/a&gt;, which would help with this problem in 2.1 only. It isn&apos;t sufficient to ensure the server stays stable, but would both avoid forward progress being stopped by errors on the post flusher, and that the affected commit log records would be retained indefinitely without resulting in infinite commit log growth. I&apos;ve also filed &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8497&quot; title=&quot;Do not replay commit log records for tables that have been repaired since&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8497&quot;&gt;&lt;del&gt;CASSANDRA-8497&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8498&quot; title=&quot;Replaying commit log records that are older than gc_grace is dangerous&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8498&quot;&gt;CASSANDRA-8498&lt;/a&gt; which should help avoid data corruption in the cluster.&lt;/p&gt;</comment>
                            <comment id="14249719" author="slebresne" created="Wed, 17 Dec 2014 11:16:46 +0000"  >&lt;p&gt;The current behavior is that an unexpected flush error blocks any flush thereon. It does seems to me that changing it so that it blocks only flushes for the column family on which there was a problem (which is not exactly what the patch does, and I do agree with Benedict that it does need to do that) is an improvement: if the problem happens for every CF then we&apos;re no worst than currently, but if it&apos;s a one-time event it might leave time for operators to take proper actions (of course, we should log a scary error, it&apos;s not something that should be ignored). So maybe we can start there since we don&apos;t seem to agree on whether crashing the node is an even better improvement?&lt;/p&gt;

&lt;p&gt;As far as my own opinion goes, I do am not in favor of crashing in that case because again, if you hold enough memtables in memory that your node become unresponsive, you&apos;re not really worth off that if you had crashed it right away, but if the problem ends up impacting a low traffic table (for instance a system table), you might be able to fix the problem in a way that is less impactful for your cluster.&lt;/p&gt;

&lt;p&gt;I&apos;ll note however that I would agree that if the error is a IO one, we should respect the disk_failure_policy. And I don&apos;t know, maybe we need another failure policy (best_effort/crash) for unexpected errors (aka bugs) that have the potential of destabilizing a node (I would agree that adding this is pushing the problem to our users, but it appears not everyone has the same idea on what is the best strategy, and there is maybe not a single good answer).&lt;/p&gt;</comment>
                            <comment id="14249733" author="benedict" created="Wed, 17 Dec 2014 11:28:02 +0000"  >&lt;p&gt;Just to add to what Sylvain says about the size of the memtable, to hopefully help target a solution (spoken agnostically): in 2.1 we could become almost immediately unusable for writes if the memtable(s) we are retaining after this (or multiple exceptions) exceed a certain proportion of memory, as we will stop even trying to flush. So for 2.1 at least if we&apos;re going to try and stay alive we need to consider if we would prefer to drop writes on the floor (agressively, to avoid build up in the queue) if the set of memtables in limbo is too large, or if we drop memtables until we reclaim enough space to proceed, or if we introduce some special logic for flushing in this event.&lt;/p&gt;

&lt;p&gt;In 2.0, conversely, we may flush millions of tiny sstables in the wrong scenario, but this would not prevent function unless it permitted excess heap growth, or a compaction death spiral. &lt;/p&gt;</comment>
                            <comment id="14250118" author="jbellis" created="Wed, 17 Dec 2014 16:58:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;if you hold enough memtables in memory that your node become unresponsive, you&apos;re not really worse off than if you had crashed it right away&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I disagree: we have a ton of evidence to date that a node that slowly falls over as it OOMs is much worse than a node that dies and gets marked down quickly by the FD.&lt;/p&gt;</comment>
                            <comment id="14250519" author="xedin" created="Wed, 17 Dec 2014 20:51:10 +0000"  >&lt;p&gt;Just to re-iterate, I still don&apos;t understand why we would prefer to crash the process if error happens on the system CF flush e.g. at the end of compaction which is not even essential for the operation like compactions_in_progress and still there is no clear answer how do we distinguish between FS&lt;/p&gt;
{Read, Write}
&lt;p&gt;Error which is generated as a response to FS or system failure and the one which is generated as a response to incorrect call that Cassandra made e.g. &quot;duplicate hard-link&quot;? &lt;/p&gt;

&lt;p&gt;I would prefer that if the failure was in the system CF we log the message, leave commitlog and let everything carry on instead of just crashing because it could essentially result in dropping incoming data, the story is different for actual user memtables tho, as I mentioned couple of times in my previous comments, I&apos;m total fine crashing if normal memtable flush fails and disk_failure_policy says so.&lt;/p&gt;</comment>
                            <comment id="14250554" author="tupshin" created="Wed, 17 Dec 2014 21:10:22 +0000"  >&lt;p&gt;Strongly in favor of the opt in policy based approach that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbellis&quot; class=&quot;user-hover&quot; rel=&quot;jbellis&quot;&gt;jbellis&lt;/a&gt; mentioned.  There isn&apos;t a one size fits all approach to deal with this &lt;/p&gt;</comment>
                            <comment id="14251586" author="benedict" created="Thu, 18 Dec 2014 12:23:54 +0000"  >&lt;p&gt;I agree with Pavel that &lt;em&gt;if we can do so safely&lt;/em&gt; we should not crash on failing to update internal book-keeping. But only if we can guarantee that failing to keep the bookkeeping up-to-date won&apos;t cause other problems. Which is why I suggest:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;2) We can report these exceptions back to the waiter on the Future result, and this waiter can choose how to behave. If, say, the memtable of a system column family that can be worked-around fails to flush (for instance, compactions_in_progress) then instead of retrying, it can simply take some other action to ensure the system continues to make safe progress.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="14253086" author="xedin" created="Fri, 19 Dec 2014 07:12:38 +0000"  >&lt;p&gt;Benedict, as I mentioned - I agree with #2 with one correction - there is no actual way to tell what exactly went wrong from FS{Read, Write}Error alone so it&apos;s probably not a lot of sense to give back exception (as it was logged already by thread pool) for processing but rather have a set of white listed system CFs fail to flush of which is &quot;acceptable&quot;... Would be nice of course to separate commitlogs so it&apos;s less error prone when it comes to flushing/recovery but this is going to be way off this ticket scope.&lt;/p&gt;</comment>
                            <comment id="14253271" author="benedict" created="Fri, 19 Dec 2014 11:00:08 +0000"  >&lt;p&gt;I should clarify, since it sounds like we are not too far in disagreement on this point: I&apos;m suggesting only that the failure is reported to the flush call site, not so the callsite can specialised on the kind of exception, but so that if this specific callsite can safely cope with &lt;em&gt;any&lt;/em&gt; failure, it can be specialised to do so, with remedial action if necessary. A whitelist would be a subset of this approach, and hence simpler - but only if it&apos;s genuinely safe to just drop the problem on the floor; I&apos;m not sufficiently familiar with these system tables to say for sure, but I do recollect problems safely starting a node when compactions_in_progress was not properly maintained, so I expect &lt;em&gt;some&lt;/em&gt; remedial action will probably be necessary, perhaps on a case-by-case basis.&lt;/p&gt;</comment>
                            <comment id="14254342" author="xedin" created="Sat, 20 Dec 2014 00:19:19 +0000"  >&lt;p&gt;Sure, it sounds like we need conceptually similar to multimap of (cfId, List&amp;lt;Exception&amp;gt;) which is going to get checked when there is an exception returned from the FlushInfo, also FDYT about previous idea of keeping commit logs even for failed flushes?&lt;/p&gt;</comment>
                            <comment id="14254652" author="benedict" created="Sat, 20 Dec 2014 11:13:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;WDYT about previous idea of keeping commit logs even for failed flushes?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m worried about replaying these records after gc_grace expires. For local-only replication this could be non-recoverable, which is why I favour taking remedial action and just dropping the records if possible to do so safely; if it isn&apos;t possible it means corruption has to be avoided, so we would likely have to do one of:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Keep all CL records since the failure for the table (possibly only necessary for local-only replication)
	&lt;ol&gt;
		&lt;li&gt;By normal mechanism, but this could retain every CL segment&lt;/li&gt;
		&lt;li&gt;By copying relevant CL records out into their own stream, so the rest can be expired&lt;/li&gt;
		&lt;li&gt;By giving each table its own CL, or perhaps only on failure, or only system tables?&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;Periodically replay into new memtables, merge with existing data, reinsert into CL and reattempt flush logic, to ensure we are never older than gc_grace (basically just rolling the problem forward each time)&lt;/li&gt;
	&lt;li&gt;Replay CL records only, periodically, sans any deleted items&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;All of the above are a bit clunky or complicated though, and might have their own bugs or encounter the same hardware problems. I&apos;m sure some other actions are also possible, but probably equally ugly.&lt;/p&gt;</comment>
                            <comment id="14254694" author="xedin" created="Sat, 20 Dec 2014 12:14:19 +0000"  >&lt;p&gt;I&apos;m fine with dropping the records if we only consider system cf which are &quot;acceptable&quot; to fail to flush, maybe CL for those is not that important e.g. compactions_in_progress, sstable_activity and compaction_history. I am also thinking maybe we could add additional checks to the CLReplayer class, so when it picks up RM for replay it could actually drop what ever records are past gc_grace (RM has information about RangeTombstone and DeletedColumn), because there is no real point of replaying them anyway, just to be safe.&lt;/p&gt;</comment>
                            <comment id="14254703" author="benedict" created="Sat, 20 Dec 2014 12:21:32 +0000"  >&lt;p&gt;Yes, see &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8498&quot; title=&quot;Replaying commit log records that are older than gc_grace is dangerous&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8498&quot;&gt;CASSANDRA-8498&lt;/a&gt; I filed to address that since it&apos;s potentially a more general concern. The problem here is that by not replaying you could be corrupting your data just as much as you might through replay. The difference is you can (hopefully) fix it through repair, but you cannot do this for local-only tables, and if the problem is a data-induced bug it could be broken cluster wide.&lt;/p&gt;</comment>
                            <comment id="14255045" author="xedin" created="Sun, 21 Dec 2014 05:09:04 +0000"  >&lt;p&gt;Ok, so how about we change CL behavior in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8498&quot; title=&quot;Replaying commit log records that are older than gc_grace is dangerous&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8498&quot;&gt;CASSANDRA-8498&lt;/a&gt; and maybe in scope of this ticket we just do failure FlushInfo (from my previous) patch and change which is going to while list some of the system CFs othewise check disk_failure_policy and fail if needed?&lt;/p&gt;</comment>
                            <comment id="14255125" author="benedict" created="Sun, 21 Dec 2014 11:03:51 +0000"  >&lt;p&gt;I think somebody with better knowledge of the bookkeeping tables needs to chime in here, to give an opinion on if we can safely do this to any we care about.&lt;/p&gt;

&lt;p&gt;We still need to decide what to do about the non-whitelisted tables, though. They most likely want to not mark the CL clean at least for their affected segments, but possibly (esp. for local-only) indefinitely for the affected table, until reboot, to guarantee no data bugs.&lt;/p&gt;</comment>
                            <comment id="14255133" author="xedin" created="Sun, 21 Dec 2014 11:30:49 +0000"  >&lt;p&gt;In case of non-whitelisted CFs we just follow on what disk_failure_policy dictates us to do, if we want to work on that in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8498&quot; title=&quot;Replaying commit log records that are older than gc_grace is dangerous&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8498&quot;&gt;CASSANDRA-8498&lt;/a&gt; we should probably move that discussion there.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne&quot; class=&quot;user-hover&quot; rel=&quot;slebresne&quot;&gt;slebresne&lt;/a&gt; What do you think about the idea of white listing some of the system CFs which are not crucial to normal operation and ignoring flush errors in them with all of the exceptions being tracked in the log on ERROR level? I took a look into what some of them and I do think it&apos;s safe to have compactions-in-progress (failure in this one just blocks all of the compactions because finishCompaction blocks on switchMemtable result which, in case of failure, never counts down the latch), sstable_activity and compaction history at least.&lt;/p&gt;</comment>
                            <comment id="14255136" author="benedict" created="Sun, 21 Dec 2014 11:34:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8498&quot; title=&quot;Replaying commit log records that are older than gc_grace is dangerous&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8498&quot;&gt;CASSANDRA-8498&lt;/a&gt; is only about replay. It can, in conjunction with repair, help avoid data corruption in a replicated table that did not experience a cross-cluster data-induced bug, but it won&apos;t help a corrupted system table that dropped intervening commit log records. So even with best_effort we need to take some remedial action to ensure non-whitelisted system tables are not corrupted.&lt;/p&gt;</comment>
                            <comment id="14255139" author="xedin" created="Sun, 21 Dec 2014 11:43:56 +0000"  >&lt;p&gt;Sure, I&apos;m just trying to say that non-whitelisted and most luckily essential tables should be no different from user CFs for disk_failure_policy and probably have a special repair phrase dedicated to them, the only CFs I know for sure could be repaired properly by just removing data is schema_* operator just need to trigger that right now, other CFs like peers and NodeInfo can be auto-regenerated if missing or corrupted so maybe if we keep exception information from FlushInfo around we can do some of that work automatically on repair request.&lt;/p&gt;

&lt;p&gt;Also I want to point out that &quot;repair&quot; within gc_grace_seconds at least once is a hard requirement, most (if not all of the people) who run in production are doing frequently e.g. once a week on Sunday night.&lt;/p&gt;</comment>
                            <comment id="14255145" author="benedict" created="Sun, 21 Dec 2014 12:09:57 +0000"  >&lt;p&gt;That all sounds eminently reasonable, although I don&apos;t know much about the system tables. So long as we make sure there aren&apos;t any that could be corrupted and be non-recoverable, we&apos;re good in my book, and I&apos;ll let others more qualified make the decision about which tables that&apos;s true of. We should probably introduce some tests to ensure this is indeed safe for each table, though.&lt;/p&gt;</comment>
                            <comment id="14264623" author="benedict" created="Mon, 5 Jan 2015 14:32:56 +0000"  >&lt;p&gt;Accidentally assigned myself this ticket. Sorry if that caused any confusion.&lt;/p&gt;</comment>
                            <comment id="14481349" author="JIRAUSER308715" created="Mon, 6 Apr 2015 15:58:01 +0000"  >&lt;p&gt;Just had a java.io.SyncFailedException cause this.  After the exception MemtablePostFlush was stuck.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [MemtableFlushWriter:6] 2015-04-03 01:57:06,973  CassandraDaemon.java:167 - Exception in thread Thread[MemtableFlushWriter:6,5,main]
org.apache.cassandra.io.FSWriteError: java.io.SyncFailedException: sync failed
        at org.apache.cassandra.io.util.SequentialWriter.syncDataOnlyInternal(SequentialWriter.java:254) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.io.util.SequentialWriter.syncInternal(SequentialWriter.java:263) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.io.util.SequentialWriter.close(SequentialWriter.java:451) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.io.sstable.SSTableWriter$IndexWriter.close(SSTableWriter.java:664) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.java:495) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.io.sstable.SSTableWriter.finish(SSTableWriter.java:448) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:440) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:435) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:377) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.db.Memtable$FlushRunnable.runMayThrow(Memtable.java:327) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) ~[guava-16.0.1.jar:na]
        at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1097) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_40]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_40]
        at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_40]
Caused by: java.io.SyncFailedException: sync failed
        at java.io.FileDescriptor.sync(Native Method) ~[na:1.8.0_40]
        at org.apache.cassandra.io.util.SequentialWriter.syncDataOnlyInternal(SequentialWriter.java:250) ~[cassandra-all-2.1.3.329.jar:2.1.3.329]
        ... 15 common frames omitted
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14517366" author="benedict" created="Tue, 28 Apr 2015 16:43:24 +0000"  >&lt;p&gt;Since this has come up again a few times, I propose that in 3.X we deliver &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-8496&quot; title=&quot;Remove MemtablePostFlusher&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-8496&quot;&gt;CASSANDRA-8496&lt;/a&gt;, since this would prevent threads being locked up - it would only leave CommitLog records to replay and memtable space unreclaimed, which would be a big improvement from the status quo at least. It is by itself not super challenging, and relatively safe. Deciding how we safely recover &lt;em&gt;fully&lt;/em&gt; is a more challenging question.&lt;/p&gt;</comment>
                            <comment id="14709558" author="jbellis" created="Mon, 24 Aug 2015 16:23:57 +0000"  >&lt;p&gt;Resolving in favor of 8496.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12761506">CASSANDRA-8476</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12825572">CASSANDRA-9255</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12762258">CASSANDRA-8496</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12762266">CASSANDRA-8498</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12762264">CASSANDRA-8497</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12720228">CASSANDRA-7373</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12650132" name="0001-Move-latch.countDown-into-finally-block.patch" size="1423" author="jbellis" created="Thu, 12 Jun 2014 20:18:30 +0000"/>
                            <attachment id="12651445" name="7252-2.0-v2.txt" size="8056" author="yukim" created="Thu, 19 Jun 2014 16:56:43 +0000"/>
                            <attachment id="12687192" name="CASSANDRA-7275-flush-info.patch" size="6931" author="xedin" created="Mon, 15 Dec 2014 07:32:36 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>393928</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 13 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1vttb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>394068</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12961"><![CDATA[Low]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>