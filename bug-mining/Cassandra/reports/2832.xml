<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:45:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-6525] Cannot select data which using &quot;WHERE&quot;</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-6525</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;I am developing a system on my single machine using VMware Player with 1GB Ram and 1Gb HHD. When I select all data, I didn&apos;t have any problems. But when I using &quot;WHERE&quot; and it has just below 10 records. I have got this error in system log:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR [ReadStage:41] 2013-12-25 18:52:11,913 CassandraDaemon.java (line 187) Exception in thread Thread[ReadStage:41,5,main]
java.io.IOError: java.io.EOFException
        at org.apache.cassandra.db.Column$1.computeNext(Column.java:79)
        at org.apache.cassandra.db.Column$1.computeNext(Column.java:64)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:88)
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:37)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.hasNext(SSTableSliceIterator.java:82)
        at org.apache.cassandra.db.filter.QueryFilter$2.getNext(QueryFilter.java:157)
        at org.apache.cassandra.db.filter.QueryFilter$2.hasNext(QueryFilter.java:140)
        at org.apache.cassandra.utils.MergeIterator$Candidate.advance(MergeIterator.java:144)
        at org.apache.cassandra.utils.MergeIterator$ManyToOne.&amp;lt;init&amp;gt;(MergeIterator.java:87)
        at org.apache.cassandra.utils.MergeIterator.get(MergeIterator.java:46)
        at org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:120)
        at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:80)
        at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:72)
        at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:297)
        at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1487)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1306)
        at org.apache.cassandra.db.Keyspace.getRow(Keyspace.java:332)
        at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:65)
        at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1401)
        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1936)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.lang.Thread.run(Unknown Source)
Caused by: java.io.EOFException
        at java.io.RandomAccessFile.readFully(Unknown Source)
        at java.io.RandomAccessFile.readFully(Unknown Source)
        at org.apache.cassandra.io.util.RandomAccessReader.readBytes(RandomAccessReader.java:348)
        at org.apache.cassandra.utils.ByteBufferUtil.read(ByteBufferUtil.java:392)
        at org.apache.cassandra.utils.ByteBufferUtil.readWithShortLength(ByteBufferUtil.java:371)
        at org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:74)
        at org.apache.cassandra.db.Column$1.computeNext(Column.java:75)
        ... 27 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;E.g.&lt;br/&gt;
&lt;tt&gt;SELECT * FROM table;&lt;/tt&gt;&lt;br/&gt;
Its fine.&lt;br/&gt;
&lt;tt&gt;SELECT * FROM table WHERE field = &apos;N&apos;;&lt;/tt&gt;&lt;br/&gt;
field is the partition key.&lt;br/&gt;
Its said &quot;Request did not complete within rpc_timeout.&quot; in cqlsh&lt;/p&gt;</description>
                <environment>&lt;p&gt;Linux RHEL5&lt;br/&gt;
RAM: 1GB&lt;br/&gt;
Cassandra 2.0.3&lt;br/&gt;
CQL spec 3.1.1&lt;br/&gt;
Thrift protocol 19.38.0&lt;/p&gt;</environment>
        <key id="12686346">CASSANDRA-6525</key>
            <summary>Cannot select data which using &quot;WHERE&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thobbs">Tom Hobbs</assignee>
                                    <reporter username="silence.chow">Silence Chow</reporter>
                        <labels>
                    </labels>
                <created>Wed, 25 Dec 2013 10:59:50 +0000</created>
                <updated>Tue, 16 Apr 2019 09:31:57 +0000</updated>
                            <resolved>Wed, 21 May 2014 09:46:03 +0000</resolved>
                                        <fixVersion>2.0.8</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>19</watches>
                                                                                                                <comments>
                            <comment id="13856930" author="jbellis" created="Thu, 26 Dec 2013 16:38:33 +0000"  >&lt;p&gt;Can you describe how to reproduce starting with a fresh Cassandra install?&lt;/p&gt;</comment>
                            <comment id="13858003" author="silence.chow" created="Sat, 28 Dec 2013 11:13:43 +0000"  >&lt;p&gt;My table have 4 field only&lt;br/&gt;
For example&lt;br/&gt;
CREATE TABLE test (&lt;br/&gt;
  hidden text,&lt;br/&gt;
  field2 text,&lt;br/&gt;
  field3 text,&lt;br/&gt;
  field4 text,&lt;br/&gt;
  PRIMARY KEY (hidden, field2 , field3)&lt;br/&gt;
);&lt;/p&gt;

&lt;p&gt;The query using CQL3: SELECT * FROM test WHERE hidden = &apos;N&apos;;&lt;/p&gt;</comment>
                            <comment id="13858627" author="silence.chow" created="Mon, 30 Dec 2013 07:21:03 +0000"  >&lt;p&gt;I think I know how to reproduce my situation now.&lt;br/&gt;
I have created a new table same as that table. I can run the query something like SELECT * FROM test WHERE hidden = &apos;N&apos;; at the beginning, After that I have run a stress test which made all the physical RAM and swap exhaust. Then, the problem happen again.&lt;/p&gt;</comment>
                            <comment id="13877955" author="vayasin" created="Tue, 21 Jan 2014 22:54:29 +0000"  >&lt;p&gt;I got the exact same error message and problem. But for me it was a small table of about 20 rows and i did not stress test.&lt;br/&gt;
running a compactions fixed the problem for me. I&apos;m not sure what the cause was but i recently dropped and recreated the table. &lt;/p&gt;</comment>
                            <comment id="13935077" author="enigmacurry" created="Fri, 14 Mar 2014 14:34:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mshuler&quot; class=&quot;user-hover&quot; rel=&quot;mshuler&quot;&gt;mshuler&lt;/a&gt; can you reproduce?&lt;/p&gt;</comment>
                            <comment id="13935623" author="mshuler" created="Fri, 14 Mar 2014 20:51:31 +0000"  >&lt;p&gt;I tested using cassandra-2.0 git branch on my laptop (16G), which ran fine. I tried on a 4G box and 2G box - both ran fine looping through the script below, while running cassandra-stress in another shell, also. I&apos;m about 10 or so loops through, while looping stress read and write on a 1G virtualbox vm, and it&apos;s slow, but I&apos;ve had no errors, so far. I&apos;ll let it keep running a while to see if I can get a timeout or error of some sort&lt;/p&gt;

&lt;p&gt;&lt;b&gt;update&lt;/b&gt; 2.5 hours of looping this while looping stress read/write on my vbox vm and all is well.&lt;br/&gt;
&lt;b&gt;update2&lt;/b&gt; tried the same after dropping my vbox vm to 512M - 45k row load takes about 60 sec. to import and the read takes a little longer to output - vm starts swapping on the 45k read and the load avg nears 40, but it&apos;s still working.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;#!/bin/sh

# create some data:
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in $(seq 1 50); &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; echo &lt;span class=&quot;code-quote&quot;&gt;&quot;N,text blah blah$i,text blah blah$i,text blah blah$i&quot;&lt;/span&gt; &amp;gt;&amp;gt; c6525_1-50.csv ; done
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in $(seq 51 500); &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; echo &lt;span class=&quot;code-quote&quot;&gt;&quot;N,text blah blah$i,text blah blah$i,text blah blah$i&quot;&lt;/span&gt; &amp;gt;&amp;gt; c6525_51-500.csv ; done
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in $(seq 501 5000); &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; echo &lt;span class=&quot;code-quote&quot;&gt;&quot;N,text blah blah$i,text blah blah$i,text blah blah$i&quot;&lt;/span&gt; &amp;gt;&amp;gt; c6525_501-5000.csv ; done
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in $(seq 5001 50000); &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; echo &lt;span class=&quot;code-quote&quot;&gt;&quot;N,text blah blah$i,text blah blah$i,text blah blah$i&quot;&lt;/span&gt; &amp;gt;&amp;gt; c6525_5001-50000.csv ; done

# create our cql to drop/create/&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt;
cat &amp;lt;&amp;lt; &lt;span class=&quot;code-quote&quot;&gt;&apos;EOF&apos;&lt;/span&gt; &amp;gt; c6525_run.cql
DROP KEYSPACE c6525;

CREATE KEYSPACE c6525 WITH replication = {&lt;span class=&quot;code-quote&quot;&gt;&apos;class&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;SimpleStrategy&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;replication_factor&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt;};

CREATE TABLE c6525.test (hidden text, field2 text, field3 text, field4 text, PRIMARY KEY (hidden, field2, field3));

COPY c6525.test (hidden, field2, field3, field4) FROM &lt;span class=&quot;code-quote&quot;&gt;&apos;c6525_1-50.csv&apos;&lt;/span&gt;;
SELECT * from c6525.test WHERE hidden = &lt;span class=&quot;code-quote&quot;&gt;&apos;N&apos;&lt;/span&gt;;

COPY c6525.test (hidden, field2, field3, field4) FROM &lt;span class=&quot;code-quote&quot;&gt;&apos;c6525_51-500.csv&apos;&lt;/span&gt;;
SELECT * from c6525.test WHERE hidden = &lt;span class=&quot;code-quote&quot;&gt;&apos;N&apos;&lt;/span&gt;;

COPY c6525.test (hidden, field2, field3, field4) FROM &lt;span class=&quot;code-quote&quot;&gt;&apos;c6525_501-5000.csv&apos;&lt;/span&gt;;
SELECT * from c6525.test WHERE hidden = &lt;span class=&quot;code-quote&quot;&gt;&apos;N&apos;&lt;/span&gt;;

COPY c6525.test (hidden, field2, field3, field4) FROM &lt;span class=&quot;code-quote&quot;&gt;&apos;c6525_5001-50000.csv&apos;&lt;/span&gt;;
SELECT * from c6525.test WHERE hidden = &lt;span class=&quot;code-quote&quot;&gt;&apos;N&apos;&lt;/span&gt; LIMIT 51000;
EOF

echo; echo &lt;span class=&quot;code-quote&quot;&gt;&quot;*** Hit CTL-C to stop looping..***&quot;&lt;/span&gt;; echo
sleep 3

# loop it
&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; echo &lt;span class=&quot;code-quote&quot;&gt;&quot;SOURCE &lt;span class=&quot;code-quote&quot;&gt;&apos;c6525_run.cql&apos;&lt;/span&gt;;&quot;&lt;/span&gt; | cqlsh ; sleep 1 ; done
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13935924" author="jbellis" created="Sat, 15 Mar 2014 01:40:13 +0000"  >&lt;p&gt;Thanks, Michael.&lt;/p&gt;</comment>
                            <comment id="13966429" author="shyamkg" created="Fri, 11 Apr 2014 11:36:08 +0000"  >&lt;p&gt;I am still getting this error in DSE 2.0.5 and 2.0.6.. Tried in various machine mac &amp;amp; ubuntu. &lt;/p&gt;

&lt;p&gt;Steps :&lt;br/&gt;
1 -&amp;gt; CREATE TABLE DSQ (&lt;br/&gt;
        exchange text,&lt;br/&gt;
        sc_code int,&lt;br/&gt;
        load_date timeuuid, /* tried timestamp also but same behaviour */&lt;br/&gt;
        PRIMARY KEY (exchange, sc_code, load_date)&lt;br/&gt;
) &lt;br/&gt;
2 -&amp;gt; Did SSTable load&lt;br/&gt;
writer.newRow(compositeColumn.builder().add(bytes(entry.stock_exchange)).add(bytes(entry.sc_code)).add(bytes(new com.eaio.uuid.UUID().toString())).build());&lt;br/&gt;
3 -&amp;gt; sstablesload &lt;br/&gt;
Established connection to initial hosts&lt;br/&gt;
Opening sstables and calculating sections to stream&lt;br/&gt;
Streaming relevant part of stock/DSQ/stock-DSQ-ib-1-Data.db to &lt;span class=&quot;error&quot;&gt;&amp;#91;/127.0.0.1&amp;#93;&lt;/span&gt;&lt;br/&gt;
progress: &lt;span class=&quot;error&quot;&gt;&amp;#91;/127.0.0.1 1/1 (100%)&amp;#93;&lt;/span&gt; [total: 100% - 2147483647MB/s (avg: 2MB/s)                            &lt;br/&gt;
4 -&amp;gt; No errors in server log&lt;br/&gt;
5 -&amp;gt; Log into cqlsh and select * from DSQ; &lt;br/&gt;
6 --&amp;gt; errors in Server log: &lt;br/&gt;
Exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;ReadStage:51,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.io.IOError: java.io.EOFException&lt;br/&gt;
	at org.apache.cassandra.db.Column$1.computeNext(Column.java:79)&lt;br/&gt;
	at org.apache.cassandra.db.Column$1.computeNext(Column.java:64)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)&lt;br/&gt;
	at org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:88)&lt;br/&gt;
	at org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:37)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)&lt;br/&gt;
	at org.apache.cassandra.db.columniterator.SSTableSliceIterator.hasNext(SSTableSliceIterator.java:82)&lt;br/&gt;
	at org.apache.cassandra.db.columniterator.LazyColumnIterator.computeNext(LazyColumnIterator.java:82)&lt;br/&gt;
	at org.apache.cassandra.db.columniterator.LazyColumnIterator.computeNext(LazyColumnIterator.java:59)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)&lt;br/&gt;
	at org.apache.cassandra.db.filter.QueryFilter$2.getNext(QueryFilter.java:157)&lt;br/&gt;
	at org.apache.cassandra.db.filter.QueryFilter$2.hasNext(QueryFilter.java:140)&lt;br/&gt;
	at org.apache.cassandra.utils.MergeIterator$Candidate.advance(MergeIterator.java:144)&lt;br/&gt;
	at org.apache.cassandra.utils.MergeIterator$ManyToOne.&amp;lt;init&amp;gt;(MergeIterator.java:87)&lt;br/&gt;
	at org.apache.cassandra.utils.MergeIterator.get(MergeIterator.java:46)&lt;br/&gt;
	at org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:120)&lt;br/&gt;
	at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:80)&lt;br/&gt;
	at org.apache.cassandra.db.RowIteratorFactory$2.getReduced(RowIteratorFactory.java:101)&lt;br/&gt;
	at org.apache.cassandra.db.RowIteratorFactory$2.getReduced(RowIteratorFactory.java:75)&lt;br/&gt;
	at org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:115)&lt;br/&gt;
	at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:98)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore$9.computeNext(ColumnFamilyStore.java:1607)&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore$9.computeNext(ColumnFamilyStore.java:1603)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)&lt;br/&gt;
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore.filter(ColumnFamilyStore.java:1754)&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore.getRangeSlice(ColumnFamilyStore.java:1718)&lt;br/&gt;
	at org.apache.cassandra.db.RangeSliceCommand.executeLocally(RangeSliceCommand.java:137)&lt;br/&gt;
	at org.apache.cassandra.service.StorageProxy$LocalRangeSliceRunnable.runMayThrow(StorageProxy.java:1418)&lt;br/&gt;
	at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1931)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:744)&lt;br/&gt;
Caused by: java.io.EOFException&lt;br/&gt;
	at java.io.RandomAccessFile.readUnsignedShort(RandomAccessFile.java:713)&lt;br/&gt;
	at org.apache.cassandra.utils.ByteBufferUtil.readShortLength(ByteBufferUtil.java:361)&lt;br/&gt;
	at org.apache.cassandra.utils.ByteBufferUtil.readWithShortLength(ByteBufferUtil.java:371)&lt;br/&gt;
	at org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:74)&lt;br/&gt;
	at org.apache.cassandra.db.Column$1.computeNext(Column.java:75)&lt;br/&gt;
	... 37 more&lt;br/&gt;
7 -&amp;gt; client shows Request did not complete within rpc_timeout.&lt;/p&gt;</comment>
                            <comment id="13966670" author="thobbs" created="Fri, 11 Apr 2014 15:50:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6981&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/CASSANDRA-6981&lt;/a&gt; is a dupe of this.  I&apos;m re-opening this to investigate further.  Besides this ticket and 6981, I&apos;ve seen one other case of this: &lt;a href=&quot;https://github.com/datastax/python-driver/issues/106&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/datastax/python-driver/issues/106&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13966676" author="thobbs" created="Fri, 11 Apr 2014 15:57:44 +0000"  >&lt;p&gt;It&apos;s worth noting that in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6981&quot; title=&quot;java.io.EOFException from Cassandra when doing select&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6981&quot;&gt;&lt;del&gt;CASSANDRA-6981&lt;/del&gt;&lt;/a&gt;, setting &lt;tt&gt;disk_access_mode: standard&lt;/tt&gt; seemed to fix the problem.&lt;/p&gt;</comment>
                            <comment id="13966868" author="mbligh" created="Fri, 11 Apr 2014 17:50:19 +0000"  >&lt;p&gt;(copied from 6981)&lt;br/&gt;
I thought it was interesting how far apart these two numbers were:&lt;/p&gt;

&lt;p&gt;&quot;java.io.IOError: java.io.IOException: mmap segment underflow; remaining is 20402577 but 1879048192 requested&quot;&lt;/p&gt;

&lt;p&gt;And that the requested number is vaguely close to 2^^31 - did something do a negative number and wrap a 32 bit signed here?&lt;br/&gt;
To be fair, it&apos;s not that close to 2^^31, but still way off what was expected?&lt;/p&gt;</comment>
                            <comment id="13967092" author="enigmacurry" created="Fri, 11 Apr 2014 20:58:19 +0000"  >&lt;p&gt;fwiw, I&apos;ve written a multi-threaded test for this using the python-driver. It&apos;s attached above as 6981_test.py. I used the criteria stated in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6981&quot; title=&quot;java.io.EOFException from Cassandra when doing select&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6981&quot;&gt;&lt;del&gt;CASSANDRA-6981&lt;/del&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;created about 16 tables, all the same, each with about 5 text fields and 5 binary fields. Most of those fields had a secondary index. Then insert into all the tables in parallel.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m using 16 tables, each with 5 text fields, 5 blob fields, inserting 10,000 rows into each table in parallel, and then selecting that data out based on a single field (blob5) that has 5 diffent options.&lt;/p&gt;

&lt;p&gt;I could not reproduce the error in this ticket, however I did get this error several times:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [ReadStage:136] 2014-04-11 16:55:36,312 CassandraDaemon.java (line 198) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[ReadStage:136,5,main]
java.lang.RuntimeException: java.lang.NullPointerException
        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1920)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
Caused by: java.lang.NullPointerException
        at org.apache.cassandra.io.util.RandomAccessReader.getTotalBufferSize(RandomAccessReader.java:157)
        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.getTotalBufferSize(CompressedRandomAccessReader.java:159)
        at org.apache.cassandra.service.FileCacheService.get(FileCacheService.java:96)
        at org.apache.cassandra.io.util.PoolingSegmentedFile.getSegment(PoolingSegmentedFile.java:36)
        at org.apache.cassandra.io.sstable.SSTableReader.getFileDataInput(SSTableReader.java:1195)
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.&amp;lt;init&amp;gt;(SimpleSliceReader.java:57)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.createReader(SSTableSliceIterator.java:65)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.&amp;lt;init&amp;gt;(SSTableSliceIterator.java:42)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:167)
        at org.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFilter.java:62)
        at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:250)
        at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1540)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1369)
        at org.apache.cassandra.db.index.composites.CompositesSearcher$1.computeNext(CompositesSearcher.java:260)
        at org.apache.cassandra.db.index.composites.CompositesSearcher$1.computeNext(CompositesSearcher.java:103)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at org.apache.cassandra.db.ColumnFamilyStore.filter(ColumnFamilyStore.java:1735)
        at org.apache.cassandra.db.index.composites.CompositesSearcher.search(CompositesSearcher.java:50)
        at org.apache.cassandra.db.index.SecondaryIndexManager.search(SecondaryIndexManager.java:556)
        at org.apache.cassandra.db.ColumnFamilyStore.search(ColumnFamilyStore.java:1723)
        at org.apache.cassandra.db.RangeSliceCommand.executeLocally(RangeSliceCommand.java:135)
        at org.apache.cassandra.service.StorageProxy$LocalRangeSliceRunnable.runMayThrow(StorageProxy.java:1374)
        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1916)
        ... 3 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13967134" author="enigmacurry" created="Fri, 11 Apr 2014 21:40:32 +0000"  >&lt;p&gt;Running this a few more times, I was able to get this on 2.0.5:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [ReadStage:90] 2014-04-11 17:37:57,768 CassandraDaemon.java (line 192) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[ReadStage:90,5,main]
java.lang.RuntimeException: org.apache.cassandra.io.sstable.CorruptSSTableException: java.io.EOFException: EOF after 46084 bytes out of 48857
        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1935)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
Caused by: org.apache.cassandra.io.sstable.CorruptSSTableException: java.io.EOFException: EOF after 46084 bytes out of 48857
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.&amp;lt;init&amp;gt;(SimpleSliceReader.java:82)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.createReader(SSTableSliceIterator.java:65)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.&amp;lt;init&amp;gt;(SSTableSliceIterator.java:42)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:167)
        at org.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFilter.java:62)
        at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:250)
        at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1560)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1379)
        at org.apache.cassandra.db.index.composites.CompositesSearcher$1.computeNext(CompositesSearcher.java:166)
        at org.apache.cassandra.db.index.composites.CompositesSearcher$1.computeNext(CompositesSearcher.java:105)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at org.apache.cassandra.db.ColumnFamilyStore.filter(ColumnFamilyStore.java:1754)
        at org.apache.cassandra.db.index.composites.CompositesSearcher.search(CompositesSearcher.java:53)
        at org.apache.cassandra.db.index.SecondaryIndexManager.search(SecondaryIndexManager.java:537)
        at org.apache.cassandra.db.ColumnFamilyStore.search(ColumnFamilyStore.java:1742)
        at org.apache.cassandra.db.RangeSliceCommand.executeLocally(RangeSliceCommand.java:135)
        at org.apache.cassandra.service.StorageProxy$LocalRangeSliceRunnable.runMayThrow(StorageProxy.java:1418)
        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1931)
        ... 3 more
Caused by: java.io.EOFException: EOF after 46084 bytes out of 48857
        at org.apache.cassandra.io.util.FileUtils.skipBytesFully(FileUtils.java:392)
        at org.apache.cassandra.utils.ByteBufferUtil.skipShortLength(ByteBufferUtil.java:382)
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.&amp;lt;init&amp;gt;(SimpleSliceReader.java:70)
        ... 22 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13967148" author="enigmacurry" created="Fri, 11 Apr 2014 21:51:36 +0000"  >&lt;p&gt;This repros on git:cassandra-2.0 HEAD as well:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [ReadStage:82] 2014-04-11 17:49:50,903 CassandraDaemon.java (line 216) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[ReadStage:82,5,main]
org.apache.cassandra.io.sstable.CorruptSSTableException: java.io.EOFException: EOF after 35761 bytes out of 48857
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.&amp;lt;init&amp;gt;(SimpleSliceReader.java:82)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.createReader(SSTableSliceIterator.java:65)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.&amp;lt;init&amp;gt;(SSTableSliceIterator.java:42)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:167)
        at org.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFilter.java:62)
        at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:250)
        at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1540)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1369)
        at org.apache.cassandra.db.index.composites.CompositesSearcher$1.computeNext(CompositesSearcher.java:164)
        at org.apache.cassandra.db.index.composites.CompositesSearcher$1.computeNext(CompositesSearcher.java:103)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at org.apache.cassandra.db.ColumnFamilyStore.filter(ColumnFamilyStore.java:1735)
        at org.apache.cassandra.db.index.composites.CompositesSearcher.search(CompositesSearcher.java:50)
        at org.apache.cassandra.db.index.SecondaryIndexManager.search(SecondaryIndexManager.java:556)
        at org.apache.cassandra.db.ColumnFamilyStore.search(ColumnFamilyStore.java:1723)
        at org.apache.cassandra.db.RangeSliceCommand.executeLocally(RangeSliceCommand.java:135)
        at org.apache.cassandra.service.StorageProxy$LocalRangeSliceRunnable.runMayThrow(StorageProxy.java:1374)
        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1916)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
Caused by: java.io.EOFException: EOF after 35761 bytes out of 48857
        at org.apache.cassandra.io.util.FileUtils.skipBytesFully(FileUtils.java:394)
        at org.apache.cassandra.utils.ByteBufferUtil.skipShortLength(ByteBufferUtil.java:382)
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.&amp;lt;init&amp;gt;(SimpleSliceReader.java:70)
        ... 22 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13980524" author="shyamkg" created="Fri, 25 Apr 2014 00:02:11 +0000"  >&lt;p&gt;FYI... Same issue also exist in 2.0.7 version as well. &lt;/p&gt;</comment>
                            <comment id="13980877" author="shyamkg" created="Fri, 25 Apr 2014 10:59:09 +0000"  >&lt;p&gt;I tried couple of things this morning and would like to update&lt;/p&gt;

&lt;p&gt;I changed the table definition to have COMPACT STORAGE with LevelCompactionStrategy and loaded the data. &lt;/p&gt;

&lt;p&gt;Server log: &lt;br/&gt;
INFO 06:51:06,415 &lt;a href=&quot;#80a0b380-cc67-11e3-a1a2-fb95dccb4714&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #80a0b380-cc67-11e3-a1a2-fb95dccb4714&lt;/a&gt; Received streaming plan for Bulk Load&lt;br/&gt;
 INFO 06:51:06,416 &lt;a href=&quot;#80a0b380-cc67-11e3-a1a2-fb95dccb4714&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #80a0b380-cc67-11e3-a1a2-fb95dccb4714&lt;/a&gt; Prepare completed. Receiving 1 files(199308 bytes), sending 0 files(0 bytes)&lt;br/&gt;
 INFO 06:51:06,466 Enqueuing flush of Memtable-compactions_in_progress@2119789616(131/1310 serialized/live bytes, 7 ops)&lt;br/&gt;
 WARN 06:51:06,466 setting live ratio to maximum of 64.0 instead of Infinity&lt;br/&gt;
 INFO 06:51:06,466 CFS(Keyspace=&apos;system&apos;, ColumnFamily=&apos;compactions_in_progress&apos;) liveRatio is 64.0 (just-counted was 64.0).  calculation took 0ms for 0 cells&lt;br/&gt;
 INFO 06:51:06,467 Writing Memtable-compactions_in_progress@2119789616(131/1310 serialized/live bytes, 7 ops)&lt;br/&gt;
 INFO 06:51:06,467 &lt;a href=&quot;#80a0b380-cc67-11e3-a1a2-fb95dccb4714&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #80a0b380-cc67-11e3-a1a2-fb95dccb4714&lt;/a&gt; Session with /192.168.1.73 is complete&lt;br/&gt;
 INFO 06:51:06,468 &lt;a href=&quot;#80a0b380-cc67-11e3-a1a2-fb95dccb4714&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Stream #80a0b380-cc67-11e3-a1a2-fb95dccb4714&lt;/a&gt; All sessions completed&lt;br/&gt;
 INFO 06:51:06,479 Completed flushing ***/apache-cassandra-2.0.7/data/data/system/compactions_in_progress/system-compactions_in_progress-jb-6-Data.db (158 bytes) for commitlog position ReplayPosition(segmentId=1398421195982, position=197721)&lt;br/&gt;
 INFO 06:51:06,483 Compacting &lt;span class=&quot;error&quot;&gt;&amp;#91;SSTableReader(path=&amp;#39;***/apache-cassandra-2.0.7/data/data/stock/dailystockquote/stock-dailystockquote-jb-6-Data.db&amp;#39;), SSTableReader(path=&amp;#39;***/apache-cassandra-2.0.7/data/data/stock/dailystockquote/stock-dailystockquote-jb-5-Data.db&amp;#39;)&amp;#93;&lt;/span&gt;&lt;br/&gt;
 INFO 06:51:06,485 Enqueuing flush of Memtable-compactions_in_progress@729498316(0/0 serialized/live bytes, 1 ops)&lt;br/&gt;
 INFO 06:51:06,491 Writing Memtable-compactions_in_progress@729498316(0/0 serialized/live bytes, 1 ops)&lt;br/&gt;
 INFO 06:51:06,500 Completed flushing ***/apache-cassandra-2.0.7/data/data/system/compactions_in_progress/system-compactions_in_progress-jb-7-Data.db (42 bytes) for commitlog position ReplayPosition(segmentId=1398421195982, position=197800)&lt;/p&gt;

&lt;p&gt;Behavioral changes:&lt;br/&gt;
Able to query table with no errors at server log but no data was loaded. &lt;/p&gt;</comment>
                            <comment id="13993980" author="thobbs" created="Fri, 9 May 2014 22:12:15 +0000"  >&lt;p&gt;This seems to require near-OOM conditions to occur.  So far I&apos;ve only been able to reproduce this in a low-memory environment (~1GB), and it either occurs just before an OOM or when the JVM is on the brink of exhausting its heap space.&lt;/p&gt;</comment>
                            <comment id="13994022" author="thobbs" created="Fri, 9 May 2014 23:00:55 +0000"  >&lt;p&gt;Interestingly, this doesn&apos;t seem to be reproduceable when the keyspace isn&apos;t dropped and recreated.  (Just modify the repro script to remove the &quot;DROP KEYSPACE&quot; and use &quot;IF NOT EXISTS&quot; on the create statements.)&lt;/p&gt;</comment>
                            <comment id="13994056" author="thobbs" created="Fri, 9 May 2014 23:37:28 +0000"  >&lt;p&gt;Considering that drop/recreate seems to be necessary to reproduce the issue and that using a disk_access_mode of &quot;standard&quot; with no compression seems to fix the issue, I believe the problem is that old FileCacheService entries are being reused with new SSTables.  The FileCacheService is only used for PoolingSegmentedFiles, which are used if compression or mmap disk access mode are enabled.  Since FileCacheService uses (String) file paths as keys, new SSTables with the same filename can lookup old entries.&lt;/p&gt;

&lt;p&gt;The only question is why the old FileCacheService entries are not being invalidated; this basically means that SSTableReader.close() is not being called in some cases.&lt;/p&gt;</comment>
                            <comment id="13996985" author="thobbs" created="Tue, 13 May 2014 22:28:02 +0000"  >&lt;p&gt;My initial guess about FileCacheService entries not being invalidated was wrong; they&apos;re all being invalidated correctly.  Furthermore, this isn&apos;t specific to compressed sstables (it reproduces with and without compression) or to a particular disk_access_mode (both standard and mmap have errors, although the specific errors are different).&lt;/p&gt;</comment>
                            <comment id="13997968" author="thobbs" created="Wed, 14 May 2014 20:07:42 +0000"  >&lt;p&gt;The problem is that key cache entries stick around after the keyspace is dropped.  After it&apos;s recreated and read, there are key cache hits that return old positions.  I&apos;m not sure why it only seems to be a problem for the secondary index tables; my guess is that the key-cache preheating that happens after compaction is replacing the old entries in the key cache for the data tables.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-5202&quot; title=&quot;CFs should have globally and temporally unique CF IDs to prevent &amp;quot;reusing&amp;quot; data from earlier incarnation of same CF name&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-5202&quot;&gt;&lt;del&gt;CASSANDRA-5202&lt;/del&gt;&lt;/a&gt; is the correct permanent solution for this, but that&apos;s for 2.1.  For 2.0, perhaps we should do something similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6351&quot; title=&quot;When dropping a CF, row cache is not invalidated&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6351&quot;&gt;&lt;del&gt;CASSANDRA-6351&lt;/del&gt;&lt;/a&gt; and go through the key cache to invalidate all entries for the CF when it&apos;s dropped.&lt;/p&gt;</comment>
                            <comment id="13998551" author="slebresne" created="Thu, 15 May 2014 07:51:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;For 2.0, perhaps we should do something similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-6351&quot; title=&quot;When dropping a CF, row cache is not invalidated&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-6351&quot;&gt;&lt;del&gt;CASSANDRA-6351&lt;/del&gt;&lt;/a&gt; and go through the key cache to invalidate all entries for the CF when it&apos;s dropped.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That makes sense to me.&lt;/p&gt;</comment>
                            <comment id="14000102" author="thobbs" created="Fri, 16 May 2014 18:32:16 +0000"  >&lt;p&gt;Attached patch (and &lt;a href=&quot;https://github.com/thobbs/cassandra/tree/CASSANDRA-6525-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;) invalidates relevant key cache entries when a table is dropped.&lt;/p&gt;</comment>
                            <comment id="14001471" author="slebresne" created="Mon, 19 May 2014 07:51:07 +0000"  >&lt;p&gt;Patch lgtm, but wouldn&apos;t make sense to do also invalidate for truncate in CFS.truncateBlocking, just to be on the safe side?&lt;/p&gt;</comment>
                            <comment id="14003874" author="thobbs" created="Tue, 20 May 2014 19:35:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;wouldn&apos;t make sense to do also invalidate for truncate in CFS.truncateBlocking, just to be on the safe side?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Truncates don&apos;t reset the SSTable generation counter (&lt;tt&gt;CFS.fileIndexGenerator&lt;/tt&gt;), so new tables will have different generation numbers (and hence different key cache keys).&lt;/p&gt;</comment>
                            <comment id="14003915" author="vkuptcov" created="Tue, 20 May 2014 20:14:10 +0000"  >&lt;p&gt;We have a cluster with 5 nodes in one DC and a cluster with two nodes in the other without a replication between these datacenters. In all DC we use C* 2.0.5.&lt;/p&gt;

&lt;p&gt;Today we&apos;ve found a bug with similar messages but with the different result. We have dropped and recreated one table in the DC with 5 nodes and just truncated the same table in another DC.&lt;br/&gt;
After ~10 hours we have noticed appearing of the following messages in the first DC logs:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR [ReadStage:231469] 2014-05-20 21:05:20,349 CassandraDaemon.java (line 192) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[ReadStage:231469,5,main]
java.io.IOError: java.io.EOFException
        at org.apache.cassandra.db.Column$1.computeNext(Column.java:79)
        at org.apache.cassandra.db.Column$1.computeNext(Column.java:64)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.computeNext(SimpleSliceReader.java:88)
:
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For the node, on which this messages started, we found several messages like on the other nodes&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; INFO [GossipTasks:1] 2014-05-20 21:20:31,864 Gossiper.java (line 863) InetAddress /10.33.20.91 is now DOWN
 INFO [RequestResponseStage:10] 2014-05-20 21:20:32,186 Gossiper.java (line 849) InetAddress /10.33.20.91 is now UP
 INFO [GossipTasks:1] 2014-05-20 21:26:51,965 Gossiper.java (line 863) InetAddress /10.33.20.91 is now DOWN
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and finally the node has stopped.&lt;/p&gt;


&lt;p&gt;We found such effect only in the DC, where we have dropped and recreated table. In the DC with truncate everything is OK.&lt;/p&gt;</comment>
                            <comment id="14003948" author="thobbs" created="Tue, 20 May 2014 20:42:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vkuptcov&quot; class=&quot;user-hover&quot; rel=&quot;vkuptcov&quot;&gt;vkuptcov&lt;/a&gt; that seems consistent with what I found.  I suggest invalidating your key cache in the problematic DC.  You can use &lt;tt&gt;nodetool invalidatekeycache&lt;/tt&gt; to do this.&lt;/p&gt;</comment>
                            <comment id="14003958" author="vkuptcov" created="Tue, 20 May 2014 20:50:27 +0000"  >&lt;p&gt;Yes, it looks like this. We have deleted the data from /var/lib/cassandra/saved_caches/* and after nodes restarting we don&apos;t notice the mentioned exceptions.&lt;/p&gt;</comment>
                            <comment id="14004445" author="slebresne" created="Wed, 21 May 2014 07:33:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Truncates don&apos;t reset the SSTable generation counter&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fair enough (though it would still feel cleaner to invalidate the key cache entries, even if it don&apos;t result in a bug). But anyway, +1 on the patch.&lt;/p&gt;</comment>
                            <comment id="14004532" author="slebresne" created="Wed, 21 May 2014 09:46:03 +0000"  >&lt;p&gt;Patch committed (I want to start a vote for 2.0.8), thanks.&lt;/p&gt;</comment>
                            <comment id="14019753" author="jeromatron" created="Fri, 6 Jun 2014 11:01:08 +0000"  >&lt;p&gt;Darn jira hotkeys.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12706485">CASSANDRA-6981</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12645287" name="6525-2.0.txt" size="1160" author="thobbs" created="Fri, 16 May 2014 18:32:16 +0000"/>
                            <attachment id="12639872" name="6981_test.py" size="3117" author="enigmacurry" created="Fri, 11 Apr 2014 21:36:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[thobbs]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365330</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 24 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1qyxb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>365632</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Reproduced In</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12325322">2.0.3</customfieldvalue>
    <customfieldvalue id="12325644">2.0.4</customfieldvalue>
    <customfieldvalue id="12326170">2.0.6</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>slebresne</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>