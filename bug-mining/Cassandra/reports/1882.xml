<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:35:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-3306] Failed streaming may cause duplicate SSTable reference</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-3306</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;during stress testing, i always get this error making leveledcompaction strategy unusable. Should be easy to reproduce - just write fast.&lt;/p&gt;

&lt;p&gt;ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;CompactionExecutor:6&amp;#93;&lt;/span&gt; 2011-10-04 15:48:52,179 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;CompactionExecutor:6,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.AssertionError&lt;br/&gt;
	at org.apache.cassandra.db.DataTracker$View.newSSTables(DataTracker.java:580)&lt;br/&gt;
	at org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:546)&lt;br/&gt;
	at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:268)&lt;br/&gt;
	at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:232)&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:960)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:199)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.LeveledCompactionTask.execute(LeveledCompactionTask.java:47)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:131)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:114)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:662)&lt;/p&gt;

&lt;p&gt;and this is in json data for table:&lt;/p&gt;

&lt;p&gt;{&lt;br/&gt;
  &quot;generations&quot; : [ &lt;/p&gt;
{
    &quot;generation&quot; : 0,
    &quot;members&quot; : [ 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484 ]
  }
&lt;p&gt;, &lt;/p&gt;
{
    &quot;generation&quot; : 1,
    &quot;members&quot; : [ ]
  }
&lt;p&gt;, &lt;/p&gt;
{
    &quot;generation&quot; : 2,
    &quot;members&quot; : [ ]
  }
&lt;p&gt;, &lt;/p&gt;
{
    &quot;generation&quot; : 3,
    &quot;members&quot; : [ ]
  }
&lt;p&gt;, &lt;/p&gt;
{
    &quot;generation&quot; : 4,
    &quot;members&quot; : [ ]
  }
&lt;p&gt;, &lt;/p&gt;
{
    &quot;generation&quot; : 5,
    &quot;members&quot; : [ ]
  }
&lt;p&gt;, &lt;/p&gt;
{
    &quot;generation&quot; : 6,
    &quot;members&quot; : [ ]
  }
&lt;p&gt;, &lt;/p&gt;
{
    &quot;generation&quot; : 7,
    &quot;members&quot; : [ ]
  }
&lt;p&gt; ]&lt;br/&gt;
}&lt;/p&gt;</description>
                <environment></environment>
        <key id="12525677">CASSANDRA-3306</key>
            <summary>Failed streaming may cause duplicate SSTable reference</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10002" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Normal</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yukim">Yuki Morishita</assignee>
                                    <reporter username="hsn">Radim Kolar</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Oct 2011 14:39:28 +0000</created>
                <updated>Tue, 16 Apr 2019 09:32:49 +0000</updated>
                            <resolved>Wed, 31 Oct 2012 16:13:45 +0000</resolved>
                                        <fixVersion>1.1.7</fixVersion>
                    <fixVersion>1.2.0 beta 2</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="13120207" author="hsn" created="Tue, 4 Oct 2011 15:18:55 +0000"  >&lt;p&gt;another problem. why not store data in some system CF? would be probably safer choice.&lt;/p&gt;

&lt;p&gt;ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;CompactionExecutor:5&amp;#93;&lt;/span&gt; 2011-10-04 17:13:13,922 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;CompactionExecutor:5,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.io.IOError: java.io.IOException: Failed to rename \var\lib\cassandra\data\test\sipdb.json to \var\lib\cassandra\data\test\sipdb-old.json&lt;br/&gt;
	at org.apache.cassandra.db.compaction.LeveledManifest.serialize(LeveledManifest.java:382)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.LeveledManifest.promote(LeveledManifest.java:182)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:152)&lt;br/&gt;
	at org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:466)&lt;br/&gt;
	at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:275)&lt;br/&gt;
	at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:232)&lt;br/&gt;
	at org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:960)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:199)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.LeveledCompactionTask.execute(LeveledCompactionTask.java:47)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:131)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.CompactionManager$1.call(CompactionManager.java:114)&lt;br/&gt;
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:662)&lt;br/&gt;
Caused by: java.io.IOException: Failed to rename \var\lib\cassandra\data\test\sipdb.json to \var\lib\cassandra\data\test\sipdb-old.json&lt;br/&gt;
	at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:64)&lt;br/&gt;
	at org.apache.cassandra.db.compaction.LeveledManifest.serialize(LeveledManifest.java:375)&lt;br/&gt;
	... 15 more&lt;/p&gt;</comment>
                            <comment id="13120214" author="jbellis" created="Tue, 4 Oct 2011 15:27:07 +0000"  >&lt;p&gt;Because then you get into hairy cyclical situations where you can&apos;t read the manifest until you replay the commitlog, but replaying the commitlog requires writing new sstables and thus knowing the manifest&lt;/p&gt;</comment>
                            <comment id="13120229" author="hsn" created="Tue, 4 Oct 2011 15:52:40 +0000"  >&lt;p&gt;as i understand new flushed tables are placed at level 0. Just replay commitlog and put all new stuff in lvl 0. after comitlog is done, it can do voodoo shuffles.&lt;/p&gt;

&lt;p&gt;but why not to rename tables like table-h-333-l1-Data.db?&lt;/p&gt;

&lt;p&gt;idea to have stables with non overlapping key ranges is interesting, but read performance is kinda slow (about 50% of normal) here. Its cassandra core modified to get advantage of leveled tables? i.e. search one sstable at level1, one at lvl2 using bloom filters for key?&lt;/p&gt;</comment>
                            <comment id="13120240" author="jbellis" created="Tue, 4 Oct 2011 16:01:27 +0000"  >&lt;p&gt;This isn&apos;t really a great place to rehash &lt;a href=&quot;http://leveldb.googlecode.com/svn/trunk/doc/impl.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://leveldb.googlecode.com/svn/trunk/doc/impl.html&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1608&quot; title=&quot;Redesigned Compaction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1608&quot;&gt;&lt;del&gt;CASSANDRA-1608&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13120241" author="brandon.williams" created="Tue, 4 Oct 2011 16:04:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;why not store data in some system CF? would be probably safer choice.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This has historically been a bad idea, see &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1155&quot; title=&quot;keep persistent row statistics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1155&quot;&gt;&lt;del&gt;CASSANDRA-1155&lt;/del&gt;&lt;/a&gt;, then &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1318&quot; title=&quot;CommitLogTest and RecoveryManager2Test is failing in trunk&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1318&quot;&gt;&lt;del&gt;CASSANDRA-1318&lt;/del&gt;&lt;/a&gt; and finally &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-1430&quot; title=&quot;SSTable statistics causing intermittent CL test failures in trunk.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-1430&quot;&gt;&lt;del&gt;CASSANDRA-1430&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13134088" author="slebresne" created="Mon, 24 Oct 2011 14:25:42 +0000"  >&lt;p&gt;I don&apos;t suppose you were using column family truncation in your tests, where you? &lt;/p&gt;</comment>
                            <comment id="13134219" author="hsn" created="Mon, 24 Oct 2011 16:42:01 +0000"  >&lt;p&gt;no truncation, no supercolumns.&lt;/p&gt;</comment>
                            <comment id="13134226" author="slebresne" created="Mon, 24 Oct 2011 16:45:52 +0000"  >&lt;p&gt;Are you still able to reproduce reliably? Because we aren&apos;t and being able to would help considerably, so if you are and could share whatever script you&apos;re using to reproduce, that would be awesome.&lt;/p&gt;</comment>
                            <comment id="13134781" author="hsn" created="Tue, 25 Oct 2011 06:33:38 +0000"  >&lt;p&gt;i tested it on 1.0 final and it worked without error for 1 test run. i will give it another test without index.&lt;/p&gt;</comment>
                            <comment id="13136071" author="slebresne" created="Wed, 26 Oct 2011 16:14:07 +0000"  >&lt;p&gt;I&apos;ll note that Ramesh Natarajan reported on the mailing list what clearly appears to be the same bug (&lt;a href=&quot;http://www.mail-archive.com/user@cassandra.apache.org/msg18146.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.mail-archive.com/user@cassandra.apache.org/msg18146.html&lt;/a&gt;), but while not using leveled compaction. I also think he was using the 1.0.0 final.&lt;/p&gt;</comment>
                            <comment id="13144240" author="slebresne" created="Fri, 4 Nov 2011 18:32:42 +0000"  >&lt;p&gt;I&apos;ll note that more info have been added to the messages thrown by the exception here in 1.0.1. So if someone can reproduce this issue on 1.0.1, it would be useful to get the stacktrace (the full system.log would actually be even better).&lt;/p&gt;</comment>
                            <comment id="13156473" author="jonma" created="Thu, 24 Nov 2011 02:16:39 +0000"  >&lt;p&gt;This&#12288;AssertionError happened always in cassandra1.0.0 ,not just only in LeveledCompactionStrategy&lt;/p&gt;</comment>
                            <comment id="13156474" author="jonma" created="Thu, 24 Nov 2011 02:24:04 +0000"  >&lt;p&gt;I suppose it&apos;s a bug in DataTracker .&lt;/p&gt;</comment>
                            <comment id="13156589" author="slebresne" created="Thu, 24 Nov 2011 08:10:53 +0000"  >&lt;p&gt;As I already said, if you are able to reproduce this, please try reproducing with 1.0.3. And if you are still able to, please attach you system.log with the exception here because it will have more info on the error that should help. And if you&apos;re not able to reproduce with 1.0.3, then I guess it means we&apos;ve fixed it without knowing.&lt;/p&gt;</comment>
                            <comment id="13161076" author="joelastpass" created="Thu, 1 Dec 2011 19:42:01 +0000"  >&lt;p&gt;Running under 1.0.4, can easily reproduce this by just kicking of a repair of any LeveledCompactionStrategy CF.  &lt;/p&gt;

&lt;p&gt;The &apos;zero&apos; on the assert indicates the value (added that to the code to see what the value was): &lt;/p&gt;

&lt;p&gt;java.lang.AssertionError: 0&lt;br/&gt;
        at org.apache.cassandra.db.compaction.LeveledManifest.promote(LeveledManifest.java:178)&lt;br/&gt;
        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:141)&lt;br/&gt;
        at org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:481)&lt;br/&gt;
        at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:275)&lt;br/&gt;
        at org.apache.cassandra.db.DataTracker.addSSTables(DataTracker.java:237)&lt;br/&gt;
        at org.apache.cassandra.db.DataTracker.addStreamedSSTable(DataTracker.java:242)&lt;br/&gt;
        at org.apache.cassandra.db.ColumnFamilyStore.addSSTable(ColumnFamilyStore.java:920)&lt;br/&gt;
        at org.apache.cassandra.streaming.StreamInSession.closeIfFinished(StreamInSession.java:141)&lt;br/&gt;
        at org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:103)&lt;br/&gt;
        at org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:184)&lt;br/&gt;
        at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:81)&lt;/p&gt;


&lt;p&gt;Relevant lines from system.log leading up the it: &lt;/p&gt;

&lt;p&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;FlushWriter:794&amp;#93;&lt;/span&gt; 2011-12-01 14:23:22,966 Memtable.java (line 275) Completed flushing /var/lib/cassandra/data/sso/Sessions-hc-12524-Data.db (1119784 bytes)&lt;br/&gt;
 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;CompactionExecutor:2379&amp;#93;&lt;/span&gt; 2011-12-01 14:23:22,969 CompactionTask.java (line 112) Compacting &lt;span class=&quot;error&quot;&gt;&amp;#91;SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12501-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12517-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12513-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12512-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12502-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12507-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12519-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12500-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12508-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12504-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12510-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12515-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12509-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12524-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12514-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12518-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12505-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12516-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12511-Data.db&amp;#39;), SSTableReader(path=&amp;#39;/var/lib/cassandra/data/sso/Sessions-hc-12506-Data.db&amp;#39;)&amp;#93;&lt;/span&gt;&lt;br/&gt;
 INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;AntiEntropyStage:1&amp;#93;&lt;/span&gt; 2011-12-01 14:25:06,321 AntiEntropyService.java (line 186) &lt;a href=&quot;#ea080b70-1c51-11e1-0000-692e0c239dfd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;repair #ea080b70-1c51-11e1-0000-692e0c239dfd&lt;/a&gt; Received merkle tree for Sessions from /xxxxxxxx&lt;br/&gt;
ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-177&amp;#93;&lt;/span&gt; 2011-12-01 14:25:17,863 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-177,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.AssertionError: 0  &lt;span class=&quot;error&quot;&gt;&amp;#91;see above&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;If you want more let me know I can reproduce instantly.&lt;/p&gt;</comment>
                            <comment id="13161426" author="jbellis" created="Fri, 2 Dec 2011 05:36:16 +0000"  >&lt;p&gt;Joe, your assertion is the one in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-3536&quot; title=&quot;Assertion error during bootstraping cassandra&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-3536&quot;&gt;&lt;del&gt;CASSANDRA-3536&lt;/del&gt;&lt;/a&gt; (where I&apos;ve attached a patch fixing it).  Closing this other one as cantrepro.&lt;/p&gt;</comment>
                            <comment id="13482768" author="yukim" created="Tue, 23 Oct 2012 22:44:08 +0000"  >&lt;p&gt;This error actually happens on 1.1. And I can easily reproduce with unit test(Test code attached).&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    [junit] ERROR 17:34:46,696 Fatal exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[CompactionExecutor:3,1,main]
    [junit] java.lang.AssertionError: Expecting &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; size of 2, got 1 &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; replacing [SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-1-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-5-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-2-Data.db&apos;&lt;/span&gt;)] by [SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-6-Data.db&apos;&lt;/span&gt;)] in View(pending_count=0, sstables=[SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-1-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-2-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-5-Data.db&apos;&lt;/span&gt;)], compacting=[SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-1-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-5-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-4-Data.db&apos;&lt;/span&gt;), SSTableReader(path=&lt;span class=&quot;code-quote&quot;&gt;&apos;build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-hf-2-Data.db&apos;&lt;/span&gt;)])
    [junit] 	at org.apache.cassandra.db.DataTracker$View.newSSTables(DataTracker.java:651)
    [junit] 	at org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:616)
    [junit] 	at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:320)
    [junit] 	at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:253)
    [junit] 	at org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:994)
    [junit] 	at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:200)
    [junit] 	at org.apache.cassandra.db.compaction.CompactionManager$1.runMayThrow(CompactionManager.java:154)
    [junit] 	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
    [junit] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
    [junit] 	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
    [junit] 	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    [junit] 	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:680)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The cause is actually in streaming. StreamInSession can add duplicate reference to SSTable to DataTracker when it is left even after stream session finishes. This typically happens when source node is marked as dead by FailureDetector during streaming session(GC storm is the one I saw) and keep sending file in same session after the node comes back.&lt;/p&gt;</comment>
                            <comment id="13482770" author="yukim" created="Tue, 23 Oct 2012 22:45:05 +0000"  >&lt;p&gt;Test code attached. Compaction strategy is not related.&lt;/p&gt;</comment>
                            <comment id="13483157" author="slebresne" created="Wed, 24 Oct 2012 12:11:13 +0000"  >&lt;p&gt;Good analysis Yuki. I&apos;m not really sure what is the right fix though. Given that this should very rarely happen (repair uses a much higher failure detection threshold than the normal one, though maybe we can increase it even more to make this even less likely) and that I don&apos;t seen any obvious way to avoid that kind of situation, maybe making DataTracker handle duplicate addition of a SSTableReader is the simplest thing to do. The obvious way to do that would be to change the View sstables List to a Set, which leads me to the current commentary in the code:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;        // We can&apos;t use a SortedSet here because &quot;the ordering maintained by a sorted set (whether or not an
        // explicit comparator is provided) must be &amp;lt;i&amp;gt;consistent with equals&amp;lt;/i&amp;gt;.&quot;  In particular,
        // ImmutableSortedSet will ignore any objects that compare equally with an existing Set member.
        // Obviously, dropping sstables whose max column timestamp happens to be equal to another&apos;s
        // is not acceptable for us.  So, we use a List instead.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think that comment is obsolete. Namely, it was added with &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-2498&quot; title=&quot;Improve read performance in update-intensive workload&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-2498&quot;&gt;&lt;del&gt;CASSANDRA-2498&lt;/del&gt;&lt;/a&gt; and at the time the list of sstable was kept in max timestamp order at all time. But since then, we&apos;ve moved the sorting in max timestamp in CollationController directly (which is less fragile), so the order inside DataTracker doesn&apos;t matter anymore.&lt;/p&gt;</comment>
                            <comment id="13483576" author="jbellis" created="Wed, 24 Oct 2012 20:46:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;This typically happens when source node is marked as dead by FailureDetector during streaming session(GC storm is the one I saw) and keep sending file in same session after the node comes back&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But we close the session on convict, so shouldn&apos;t it start a new one?&lt;/p&gt;</comment>
                            <comment id="13483641" author="yukim" created="Wed, 24 Oct 2012 22:00:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;But we close the session on convict, so shouldn&apos;t it start a new one?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, StreamInSession gets closed and removed on convict &lt;em&gt;once&lt;/em&gt;. But if GC pause happens in the middle of streaming session, the node resumes streaming in the same session after GC. Since resumed stream carries session ID that is once closed on receiver side, StreamInSession is created again with the same old session ID and this time just 1 file to receive.&lt;br/&gt;
This continues again and again until source node&apos;s StreamingOutSession sends all files.&lt;br/&gt;
You can see this in receiver&apos;s log file like below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;INFO [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-50] 2012-10-20 13:13:26,574 StreamInSession.java (line 214) Finished streaming session 10 from /10.xx.xx.xx
INFO [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-51] 2012-10-20 13:13:29,691 StreamInSession.java (line 214) Finished streaming session 10 from /10.xx.xx.xx
INFO [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-52] 2012-10-20 13:13:32,957 StreamInSession.java (line 214) Finished streaming session 10 from /10.xx.xx.xx
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Duplication happens during this partially broken streaming session. Because StreamInSession is removed after sending SESSION_FINISHED reply, and StreamOutSession keeps sending files, sometimes the same StreamInSession instance receives more than 1 file and calls closeIfFinished every time it received the file.&lt;br/&gt;
(Sorry, this is hard to explain in words.&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/cassandra/blob/cassandra-1.1.6/src/java/org/apache/cassandra/streaming/StreamInSession.java#L181&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/cassandra/blob/cassandra-1.1.6/src/java/org/apache/cassandra/streaming/StreamInSession.java#L181&lt;/a&gt; this part is executed multiple times with &lt;em&gt;readers&lt;/em&gt; growing by received new file.)&lt;/p&gt;

&lt;p&gt;So as Sylvain stated above, changing DataTracker.View&apos;s sstable to Set is one way to eliminate duplicate reference and we should do it. In addition, I&apos;m thinking not to create duplicate StreamInSession by checking StreamHeader.pendingFiles because this field is only filled when initiating streaming.&lt;/p&gt;</comment>
                            <comment id="13483951" author="slebresne" created="Thu, 25 Oct 2012 07:44:01 +0000"  >&lt;p&gt;That code is a mess so let me give a shot at describing what happens for the record. Say node1 wants to stream files A, B and C to node2. If everything goes well what happens is:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;node1 sends the first file A with a StreamHeader that says that A, B and C are pending files and A is the currently sent file. On node2, a new StreamInSession is created with those information.&lt;/li&gt;
	&lt;li&gt;Once A is finished, node2 remove A from the pending file in the StreamInSession send an acknowledgement to node1, and then node1 sends B with a StreamHeader with no pending files (basically the list of pending files is only sent the first time so that the StreamInSession on node2 knows when everything is finished) and B as current file. When node2 received that StreamHeader, it retrieve the StreamInSession, setting B as the current files.&lt;/li&gt;
	&lt;li&gt;Once B is finished, node2 removes it from pending files, acks to node1 and node1 sends C with a StreamHeader with no pending file and C as current file.  Node2 retrieven the StreamInSession and modify it accordingly.&lt;/li&gt;
	&lt;li&gt;At last, once C is finished, node2 removes it from the pending files. Then it realizes the pending files are empty and so that the streaming is finished and at that point it adds all the SSTableReader created so far to the cfs (and acks to node1 the end of the streaming).&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Now, the problem is if say node1 is marked dead by mistake by node2 during say the streaming of A. I that happens, the only thing we do on node2 is to close the session and remove the streamInSession from the global sessions map.  However we don&apos;t shutdown the stream or anything, so if node1 is in fact still alive, what will happen is:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;A will finish his transfer correctly. Once that&apos;s done, node2 will still send an acknowledgement (probably the first mistake, we could check that the session has been closed and send an error instead).&lt;/li&gt;
	&lt;li&gt;Node1 getting it&apos;s acknowledgement will send B with a StreamHeader that has B as current file and no pending files as usual. On reception, node2 will not find any StreamInSession (it has been removed during the close), and so it will create a new one as if that was the beginning of a transfer. And that session will have no pending file (second mistake: if we have to create a new StreamInSession but there is no pending file at all something wrong has happened).&lt;/li&gt;
	&lt;li&gt;Once B is fully streamed, node2 will acknowledge it to node1 and remove it from it&apos;s streamInSession. But that session the new one we just created with no pending file. So the streamInSession will consider the streaming is finished, and it will thus add the SSTableReader for B to the cfs.&lt;/li&gt;
	&lt;li&gt;Because B has been acknowledged, node1 will start sending C (again, with no pending file in the StreamHeader). This will be done as soon as B was finished, and so concurrently with the streamInSession on node2 closing itself.&lt;/li&gt;
	&lt;li&gt;So when node2 receives the StreamHeader with C, it will try to retrieve the session and will find the previous session. And will happily add C as the current file for that session (third and fourth mistake: StreamInSession should not add a file as current unless it is a pending file for this session, and a session could detect that it&apos;s being reused even though it has just detected itself as finished).&lt;/li&gt;
	&lt;li&gt;Now when C transfer finishes, the seesion will be notify and since it still has no pending files, it will once again consider the streaming as complete.  But since it&apos;s still the same session, it still has the SSTableReader for B in its list of created reader (as well as the one for C now). And that&apos;s when it adds B for a second time to the DataTracker.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I also not that we end up without having ever add the SSTableReader for A to the cfs since the very first StreamInSession was never finished. This is not a big deal in that the stream itself has been indicated as failed to the client anyway, but just to say that it&apos;s not just a problem of duplicating a SSTableReader preference.&lt;/p&gt;

&lt;p&gt;Anyway, let me back on what I said earlier. We should definitively fix some if not all of the &quot;mistake&quot; above (and send a SESSION_FAILURE to node1 as soon as we detect something is wrong).&lt;/p&gt;

&lt;p&gt;But that being said, my comment on the comment in DataTracker being obsolete still stand, and replacing the list by a set in there would have at least the advantage of slightly simplifying the code of DataTracker.View.newSSTables(), as well as being more resilient if a SSTableReader is added twice. Not a big deal though.&lt;/p&gt;</comment>
                            <comment id="13486314" author="yukim" created="Mon, 29 Oct 2012 20:28:38 +0000"  >&lt;p&gt;Attaching first attempt.&lt;br/&gt;
I changed DataTracker.View&apos;s sstables to Set, and made stream fail when file arrives after StreamInSession failed.&lt;/p&gt;

&lt;p&gt;Changing List to Set for sstables sometimes makes CollationControllerTest fail. It was introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-4116&quot; title=&quot;check most recent TS values in SSTables when a row tombstone has already been encountered&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-4116&quot;&gt;&lt;del&gt;CASSANDRA-4116&lt;/del&gt;&lt;/a&gt;, and I think the test and CollationController#collectAllData expect sstables to be ordered by timestamp. I&apos;m not sure if the test is obsolete or we really need sstables to be sorted all the time.&lt;br/&gt;
0002 patch alone will fix the issue, so we can apply that for now.&lt;/p&gt;</comment>
                            <comment id="13486727" author="slebresne" created="Tue, 30 Oct 2012 08:15:53 +0000"  >&lt;p&gt;For patch 0002, we shouldn&apos;t check the FailureDetector otherwise we don&apos;t really fix the issue. The only way we know this bug can happen is wher the FailureDetector &lt;b&gt;had&lt;/b&gt; marked a node down while it shouldn&apos;t have (besides, we just got something from a node so it&apos;s fair to assume it is alive).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;and I think the test and CollationController#collectAllData expect sstables to be ordered by timestamp&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It doesn&apos;t seem to me that collectAllData needs sstable ordered. In fact, I think that it does a second pass over the sstables iterators just because it doesn&apos;t assume sstables are ordered by max timestamp. Moreover, I&apos;m pretty sure it would be a bug to assume that. If you look at DataTracker.View.newSSTables, it ends by &lt;tt&gt;Iterables.addAll(newSSTables, replacements)&lt;/tt&gt; which clearly won&apos;t maintain any specific ordering of sstables.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure if the test is obsolete.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think the test is obsolete but I think we have a minor bug in CollationController. The test want to test that we correctly exclude sstable whose maxTimestamp is less than the most recent row tombstone we have. But that test checks controller.getSstablesIterated(), and for collectAllData, it will count every sstable it include in the first iteration of collectAllData but don&apos;t remove those that are remove by the second pass. In other words, I think the correct fix is to decrement stablesIterated in CollationController when in the second pass we remove a sstable (or more simply to set it to iterators.size() just before we collate everything).&lt;/p&gt;</comment>
                            <comment id="13487319" author="yukim" created="Tue, 30 Oct 2012 22:34:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;we shouldn&apos;t check the FailureDetector otherwise we don&apos;t really fix the issue.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok. I&apos;ve fixed this and reattached 0002.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The test want to test that we correctly exclude sstable whose maxTimestamp is less than the most recent row tombstone we have.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right. But I think the test assumes that SSTables are added to List in order of flush, and that&apos;s true as long as we use List. So what I suggest is to remove that part from the test since we no longer use List.&lt;br/&gt;
And sstablesIterated counter in collectAllData is doing fine because we actually read the data from sstable when we go over&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;IColumnIterator iter = filter.getSSTableColumnIterator(sstable);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;before incrementing counter.&lt;/p&gt;

&lt;p&gt;So I removed that test from CollationControllerTest in 0001-change-DataTracker.View-s-sstables-from-List-to-Set.patch.&lt;/p&gt;</comment>
                            <comment id="13487641" author="slebresne" created="Wed, 31 Oct 2012 09:48:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;Ok. I&apos;ve fixed this and reattached 0002.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Alright, +1 on 0002. Let&apos;s commit that for now to 1.1/1.2 as this fix this ticket.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;the test assumes that SSTables are added to List in order of flush&lt;br/&gt;
And sstablesIterated counter in collectAllData is doing fine because we actually read the data&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right. I guess what I meant is that what is tested right now is not really sensible. Relying on the order of flush is only valid for a small, controlled test, but in reality as soon as compaction kicks in, the order of sstable in DataTracker will be meaningless even with a List instead of a Set. Basically the guarantee collectAll gives us today is that it will eliminate sstables whose maxTimestamp &amp;lt; mostRecentTombstone with just having read the sstable row header, not the full data. But that&apos;s not what sstablesIterated counts so it&apos;s broken.&lt;/p&gt;

&lt;p&gt;That being said, I think we can improve collectAll in the way described in &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-4883&quot; title=&quot;Optimize mostRecentTomstone vs maxTimestamp check in CollationController.collectAllData&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-4883&quot;&gt;&lt;del&gt;CASSANDRA-4883&lt;/del&gt;&lt;/a&gt;. If we do so, the test will pass again without relying on any assumption of the order of sstables in DataTracker. So overall I suggest moving all of this to &lt;a href=&quot;https://issues.apache.org/jira/browse/CASSANDRA-4883&quot; title=&quot;Optimize mostRecentTomstone vs maxTimestamp check in CollationController.collectAllData&quot; class=&quot;issue-link&quot; data-issue-key=&quot;CASSANDRA-4883&quot;&gt;&lt;del&gt;CASSANDRA-4883&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13487902" author="yukim" created="Wed, 31 Oct 2012 16:13:45 +0000"  >&lt;p&gt;Committed 0002 to 1.1 and trunk.&lt;/p&gt;</comment>
                            <comment id="14357452" author="dashv" created="Wed, 11 Mar 2015 19:44:40 +0000"  >&lt;p&gt;I understand that this has been fixed in newer versions of Cassandra.&lt;/p&gt;

&lt;p&gt;But I&apos;m currently seeing this exact issue on a production 1.1.1 node in my cluster.&lt;/p&gt;

&lt;p&gt;What should be my next step?&lt;/p&gt;

&lt;p&gt;Do I simply restart it?&lt;/p&gt;

&lt;p&gt;Run cleanup? Scrub? Repair?&lt;/p&gt;

&lt;p&gt;Sounds like repair would just fail with the same problem.&lt;/p&gt;

&lt;p&gt;Any advice would be appreciated.&lt;/p&gt;</comment>
                            <comment id="14357472" author="yukim" created="Wed, 11 Mar 2015 19:56:20 +0000"  >&lt;p&gt;Yes, restarting the node will help.&lt;br/&gt;
No need to clean up/scrub.&lt;/p&gt;

&lt;p&gt;Please use user@cassandra.apache.org mailing list for these type of questions.&lt;/p&gt;</comment>
                            <comment id="14357543" author="dashv" created="Wed, 11 Mar 2015 20:32:13 +0000"  >&lt;p&gt;Thanks for the swift reply and I will use the mailing list in the future.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12550547" name="0001-CASSANDRA-3306-test.patch" size="5228" author="yukim" created="Tue, 23 Oct 2012 22:45:05 +0000"/>
                            <attachment id="12551435" name="0001-change-DataTracker.View-s-sstables-from-List-to-Set.patch" size="6853" author="yukim" created="Tue, 30 Oct 2012 22:34:21 +0000"/>
                            <attachment id="12551436" name="0002-fail-stream-session-for-invalid-request.patch" size="3125" author="yukim" created="Tue, 30 Oct 2012 22:34:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[yukim]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>44375</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 36 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0aym7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>61881</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>slebresne</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12962"><![CDATA[Normal]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>