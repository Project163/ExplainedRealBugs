<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 22:38:04 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CASSANDRA-5418] streaming fails</title>
                <link>https://issues.apache.org/jira/browse/CASSANDRA-5418</link>
                <project id="12310865" key="CASSANDRA">Apache Cassandra</project>
                    <description>&lt;p&gt;When I run &lt;b&gt;nodetool repair&lt;/b&gt; on cas01 node it get&apos;s stuck at some point.&lt;/p&gt;

&lt;p&gt;I see following exceptions in cas01 system.log:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;Streaming to /10.10.45.60:28&amp;#93;&lt;/span&gt; 2013-04-02 09:03:55,353 CassandraDaemon.java (line 132) Exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;Streaming to /10.10.45.60:28,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.RuntimeException: java.io.EOFException&lt;br/&gt;
	at com.google.common.base.Throwables.propagate(Throwables.java:160)&lt;br/&gt;
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)&lt;br/&gt;
	at java.lang.Thread.run(Unknown Source)&lt;br/&gt;
Caused by: java.io.EOFException&lt;br/&gt;
	at java.io.DataInputStream.readInt(Unknown Source)&lt;br/&gt;
	at org.apache.cassandra.streaming.FileStreamTask.receiveReply(FileStreamTask.java:193)&lt;br/&gt;
	at org.apache.cassandra.streaming.compress.CompressedFileStreamTask.stream(CompressedFileStreamTask.java:114)&lt;br/&gt;
	at org.apache.cassandra.streaming.FileStreamTask.runMayThrow(FileStreamTask.java:91)&lt;br/&gt;
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)&lt;br/&gt;
	... 3 more&lt;/p&gt;


&lt;p&gt;ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-2076&amp;#93;&lt;/span&gt; 2013-04-02 09:07:12,261 CassandraDaemon.java (line 132) Exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-2076,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.AssertionError: incorrect row data size 130921 written to /var/lib/cassandra/data/EDITED/content_list/footballsite-content_list-tmp-ib-3660-Data.db; correct is 131074&lt;br/&gt;
	at org.apache.cassandra.io.sstable.SSTableWriter.appendFromStream(SSTableWriter.java:285)&lt;br/&gt;
	at org.apache.cassandra.streaming.IncomingStreamReader.streamIn(IncomingStreamReader.java:179)&lt;br/&gt;
	at org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:122)&lt;br/&gt;
	at org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:238)&lt;br/&gt;
	at org.apache.cassandra.net.IncomingTcpConnection.handleStream(IncomingTcpConnection.java:178)&lt;br/&gt;
	at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:78)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On other machines there are some exceptions too:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-1424&amp;#93;&lt;/span&gt; 2013-04-02 09:07:12,248 CassandraDaemon.java (line 132) Exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-1424,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.AssertionError: incorrect row data size 130921 written to /var/lib/cassandra/data/EDITED/content_list/footballsite-content_list-tmp-ib-2268-Data.db; correct is 131074&lt;br/&gt;
	at org.apache.cassandra.io.sstable.SSTableWriter.appendFromStream(SSTableWriter.java:285)&lt;br/&gt;
	at org.apache.cassandra.streaming.IncomingStreamReader.streamIn(IncomingStreamReader.java:179)&lt;br/&gt;
	at org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:122)&lt;br/&gt;
	at org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:238)&lt;br/&gt;
	at org.apache.cassandra.net.IncomingTcpConnection.handleStream(IncomingTcpConnection.java:178)&lt;br/&gt;
	at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:78)&lt;br/&gt;
ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;Streaming to /10.10.45.58:55&amp;#93;&lt;/span&gt; 2013-04-02 09:07:12,263 CassandraDaemon.java (line 132) Exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;Streaming to /10.10.45.58:55,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.RuntimeException: java.io.EOFException&lt;br/&gt;
	at com.google.common.base.Throwables.propagate(Throwables.java:160)&lt;br/&gt;
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)&lt;br/&gt;
	at java.lang.Thread.run(Unknown Source)&lt;br/&gt;
Caused by: java.io.EOFException&lt;br/&gt;
	at java.io.DataInputStream.readInt(Unknown Source)&lt;br/&gt;
	at org.apache.cassandra.streaming.FileStreamTask.receiveReply(FileStreamTask.java:193)&lt;br/&gt;
	at org.apache.cassandra.streaming.compress.CompressedFileStreamTask.stream(CompressedFileStreamTask.java:114)&lt;br/&gt;
	at org.apache.cassandra.streaming.FileStreamTask.runMayThrow(FileStreamTask.java:91)&lt;br/&gt;
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)&lt;br/&gt;
	... 3 more&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then I see frozen status in &lt;b&gt;nodetool netstats&lt;/b&gt; and repair never completes.&lt;/p&gt;</description>
                <environment>&lt;p&gt;5 nodes, vnodes enabled, encryption disabled, compression enabled, RackInferring snitch, Centos 6, Oracle JVM with JNA enabled.&lt;/p&gt;</environment>
        <key id="12640335">CASSANDRA-5418</key>
            <summary>streaming fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10000" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Urgent</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="slebresne">Sylvain Lebresne</assignee>
                                    <reporter username="radev">Igor Ivanov</reporter>
                        <labels>
                    </labels>
                <created>Tue, 2 Apr 2013 17:11:01 +0000</created>
                <updated>Tue, 16 Apr 2019 09:32:15 +0000</updated>
                            <resolved>Thu, 11 Apr 2013 16:13:43 +0000</resolved>
                                        <fixVersion>1.2.5</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13620117" author="brandon.williams" created="Tue, 2 Apr 2013 18:43:13 +0000"  >&lt;p&gt;You have corruption and need to run scrub first.  That said, we could probably at least abort the repair session in this case.  What do you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim&quot; class=&quot;user-hover&quot; rel=&quot;yukim&quot;&gt;yukim&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="13620540" author="radev" created="Wed, 3 Apr 2013 02:44:57 +0000"  >&lt;p&gt;I&apos;ve run &lt;b&gt;nodetool scrub&lt;/b&gt; on each node, it went over all column families.&lt;br/&gt;
And yet on next run of &lt;b&gt;nodetool repair&lt;/b&gt; I still see exceptions in logs:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; INFO [AntiEntropyStage:1] 2013-04-02 19:37:11,095 StreamOutSession.java (line 162) Streaming to /10.10.45.59
ERROR [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-2171] 2013-04-02 19:37:11,184 CassandraDaemon.java (line 132) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-2171,5,main]
java.lang.AssertionError: incorrect row data size 729492 written to /&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/lib/cassandra/data/footballsite/content_list/footballsite-content_list-tmp-ib-2235-Data.db; correct is 731241
	at org.apache.cassandra.io.sstable.SSTableWriter.appendFromStream(SSTableWriter.java:285)
	at org.apache.cassandra.streaming.IncomingStreamReader.streamIn(IncomingStreamReader.java:179)
	at org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:122)
	at org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:238)
	at org.apache.cassandra.net.IncomingTcpConnection.handleStream(IncomingTcpConnection.java:178)
	at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:78)
ERROR [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-2173] 2013-04-02 19:37:11,187 CassandraDaemon.java (line 132) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-2173,5,main]
java.lang.AssertionError: incorrect row data size 241378 written to /&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/lib/cassandra/data/footballsite/content_list/footballsite-content_list-tmp-ib-2236-Data.db; correct is 241696
	at org.apache.cassandra.io.sstable.SSTableWriter.appendFromStream(SSTableWriter.java:285)
	at org.apache.cassandra.streaming.IncomingStreamReader.streamIn(IncomingStreamReader.java:179)
	at org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:122)
	at org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:238)
	at org.apache.cassandra.net.IncomingTcpConnection.handleStream(IncomingTcpConnection.java:178)
	at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:78)
 INFO [Streaming to /10.10.45.60:6] 2013-04-02 19:37:11,190 StreamReplyVerbHandler.java (line 44) Successfully sent /&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/lib/cassandra/data/footballsite/content_list/footballsite-content_list-ib-2176-Data.db to /10.10.45.60
 INFO [Streaming to /10.10.45.59:4] 2013-04-02 19:37:11,216 StreamReplyVerbHandler.java (line 44) Successfully sent /&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/lib/cassandra/data/footballsite/content_list/footballsite-content_list-ib-2176-Data.db to /10.10.45.59
ERROR [Streaming to /10.10.45.60:6] 2013-04-02 19:37:11,243 CassandraDaemon.java (line 132) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[Streaming to /10.10.45.60:6,5,main]
java.lang.RuntimeException: java.io.EOFException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(Unknown Source)
	at org.apache.cassandra.streaming.FileStreamTask.receiveReply(FileStreamTask.java:193)
	at org.apache.cassandra.streaming.compress.CompressedFileStreamTask.stream(CompressedFileStreamTask.java:114)
	at org.apache.cassandra.streaming.FileStreamTask.runMayThrow(FileStreamTask.java:91)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	... 3 more
 INFO [AntiEntropyStage:1] 2013-04-02 19:37:11,251 StreamingRepairTask.java (line 223) [streaming task #62cdba10-9c07-11e2-a79f-1fa905df867b] task succeeded
ERROR [Streaming to /10.10.45.59:4] 2013-04-02 19:37:11,265 CassandraDaemon.java (line 132) Exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[Streaming to /10.10.45.59:4,5,main]
java.lang.RuntimeException: java.io.EOFException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(Unknown Source)
	at org.apache.cassandra.streaming.FileStreamTask.receiveReply(FileStreamTask.java:193)
	at org.apache.cassandra.streaming.compress.CompressedFileStreamTask.stream(CompressedFileStreamTask.java:114)
	at org.apache.cassandra.streaming.FileStreamTask.runMayThrow(FileStreamTask.java:91)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	... 3 more

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13620647" author="krummas" created="Wed, 3 Apr 2013 05:47:32 +0000"  >&lt;p&gt;are you running internode encryption?&lt;/p&gt;</comment>
                            <comment id="13620649" author="radev" created="Wed, 3 Apr 2013 05:55:28 +0000"  >&lt;p&gt;No, but I&apos;m using vnodes, if that&apos;s making any difference.&lt;/p&gt;</comment>
                            <comment id="13623692" author="radev" created="Fri, 5 Apr 2013 15:04:53 +0000"  >&lt;p&gt;Since that I&apos;ve tried to run offline sstablescrub, it didn&apos;t help. As was suggested on IRC, I&apos;ve tried sstable2json on data file and it worked. But when joining node tries to stream file - it fails repeatedly on the same file.&lt;/p&gt;</comment>
                            <comment id="13623696" author="radev" created="Fri, 5 Apr 2013 15:06:55 +0000"  >&lt;p&gt;Also, I&apos;ve tried shutting down one node, moving it&apos;s files to another box and starting it up with different IP/hostname - node was up and serving properly, but problem persisted.&lt;/p&gt;</comment>
                            <comment id="13623875" author="arya" created="Fri, 5 Apr 2013 18:04:17 +0000"  >&lt;p&gt;I upgraded our 4 node sandbox cluster from 1.1.10 to 1.2.3. It is impossible to run repair on any node. They all get stuck without any exception in the log. Could my issue be related? Is there a workaround? I have 2 more days till my gc_grace.&lt;/p&gt;</comment>
                            <comment id="13625016" author="radev" created="Sun, 7 Apr 2013 20:48:50 +0000"  >&lt;p&gt;I&apos;ve tried to build latest source from 1.2 branch. And it worked properly, our cluster is repairing again and performing normally.&lt;/p&gt;</comment>
                            <comment id="13627729" author="radev" created="Wed, 10 Apr 2013 12:29:48 +0000"  >&lt;p&gt;Actually, it helped only temporarily, and appendFromStream now asserts when I try to bootstrap new node.&lt;/p&gt;</comment>
                            <comment id="13627733" author="radev" created="Wed, 10 Apr 2013 12:31:49 +0000"  >&lt;p&gt;We are not using internode encryption, but compression is used.&lt;/p&gt;</comment>
                            <comment id="13627903" author="yukim" created="Wed, 10 Apr 2013 15:25:16 +0000"  >&lt;p&gt;Igor, can you provide more info about this?&lt;br/&gt;
Do you see the same AssertionError for every CFs or the specific one? If the latter, can you post the definition of that CF?&lt;/p&gt;</comment>
                            <comment id="13628239" author="radev" created="Wed, 10 Apr 2013 20:57:09 +0000"  >&lt;p&gt;It&apos;s the same column family. We&apos;re doing lot&apos;s of deletes for it.&lt;br/&gt;
Seems that assertion is caused by element written twice on ColumnIndexer block boundary.&lt;br/&gt;
But column_index_size_in_kb is same on every node and set to default 64k.&lt;/p&gt;</comment>
                            <comment id="13628317" author="radev" created="Wed, 10 Apr 2013 21:55:51 +0000"  >&lt;p&gt;Avoid duplication of columns on index block boundary when appending from stream (source stream already duplicated them).&lt;/p&gt;</comment>
                            <comment id="13628318" author="radev" created="Wed, 10 Apr 2013 21:56:32 +0000"  >&lt;p&gt;Patch against branch 1.2&lt;/p&gt;</comment>
                            <comment id="13628632" author="yukim" created="Thu, 11 Apr 2013 03:32:12 +0000"  >&lt;p&gt;Igor, thanks for the patch.&lt;br/&gt;
I think that would probably work, since the only code path that could write extra bytes is there, but I want to confirm by writing unit test for this. I&apos;m working on it right now.&lt;/p&gt;</comment>
                            <comment id="13628818" author="radev" created="Thu, 11 Apr 2013 10:32:46 +0000"  >&lt;p&gt;I&apos;ve looked over the ColumnIndex.Builder code again and saw that it can build incorrect index (endPosition updated twice). So, added fromStream flag and skip logic to ColumnIndex.Builder.&lt;/p&gt;</comment>
                            <comment id="13628820" author="radev" created="Thu, 11 Apr 2013 10:37:32 +0000"  >&lt;p&gt;v3 includes assertion, maybe will catch if column_index_size_in_kb is changed.&lt;/p&gt;</comment>
                            <comment id="13628879" author="slebresne" created="Thu, 11 Apr 2013 12:35:22 +0000"  >&lt;p&gt;I agree on the source of the problem. On the patch however, since the goal should be to write only what we get from the stream (since we&apos;ve used the dataSize from the stream), it would feel more natural to me to just skip tombstoneTracker.writeOpenedMarker (in which case we really can skip the tombstone tracker completely and save a few CPU cycles). I&apos;m attaching a v5 patch that implement this (imo simpler) alternative.&lt;/p&gt;

&lt;p&gt;Now as was noted above, this fix (whatever version of the patch we use) has the small downside that if the source and destination don&apos;t have the same column_index_size_in_kb, we&apos;ll be screwed. This is definitively a much less problem that this issue and so we should still fix this, but for 2.0, once CASSANRA-4180 gets in, then we should more or less revert this fix because it won&apos;t be necessary anymore. I&apos;ve create CASSANRA-5454 so we don&apos;t forget about it.&lt;/p&gt;</comment>
                            <comment id="13629016" author="yukim" created="Thu, 11 Apr 2013 15:31:51 +0000"  >&lt;p&gt;So I created unit test to stream RangeTombstones between column index boundaries. (Patch attached)&lt;br/&gt;
It fails with the same stack trace here on current 1.2 branch, but it passes with 5418-v4.&lt;br/&gt;
So I will commit v4 and test.&lt;/p&gt;</comment>
                            <comment id="13629061" author="yukim" created="Thu, 11 Apr 2013 16:13:43 +0000"  >&lt;p&gt;Committed.&lt;br/&gt;
Thanks Igor and Sylvain!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12578229" name="0001-add-RangeTombstone-transfer-test.patch" size="2987" author="yukim" created="Thu, 11 Apr 2013 15:31:51 +0000"/>
                            <attachment id="12578187" name="5418-1.2-v2.txt" size="4293" author="radev" created="Thu, 11 Apr 2013 10:32:46 +0000"/>
                            <attachment id="12578191" name="5418-1.2-v3.txt" size="4491" author="radev" created="Thu, 11 Apr 2013 10:37:32 +0000"/>
                            <attachment id="12578090" name="5418-1.2.txt" size="1460" author="radev" created="Wed, 10 Apr 2013 21:56:32 +0000"/>
                            <attachment id="12578203" name="5418-v4.txt" size="4235" author="slebresne" created="Thu, 11 Apr 2013 12:35:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12313920" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Authors</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[slebresne]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>320798</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 32 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1jcmn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>321139</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>yukim</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313420" key="com.atlassian.jira.plugin.system.customfieldtypes:multiuserpicker">
                        <customfieldname>Reviewers</customfieldname>
                        <customfieldvalues>
                                    <customfieldvalue><![CDATA[yukim]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12313820" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Severity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="12963"><![CDATA[Critical]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>