diff --git a/CHANGES.txt b/CHANGES.txt
index f93821a3b4..17dce6217c 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -3,8 +3,10 @@
  * lower-latency read repair (CASSANDRA-2069)
  * add hinted_handoff_throttle_delay_in_ms option (CASSANDRA-2161)
  * fixes for cache save/load (CASSANDRA-2172, -2174)
+ * Handle whole-row deletions in CFOutputFormat (CASSANDRA-2014)
  * Make memtable_flush_writers flush in parallel (CASSANDRA-2178)
 
+
 0.7.2
  * copy DecoratedKey.key when inserting into caches to avoid retaining
    a reference to the underlying buffer (CASSANDRA-2102)
diff --git a/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java b/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java
index 7b7fd8dcf6..c6f665bff0 100644
--- a/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java
+++ b/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java
@@ -143,33 +143,23 @@ implements org.apache.hadoop.mapred.RecordWriter<ByteBuffer,List<org.apache.cass
     {
         Mutation mutation = new Mutation();
         org.apache.cassandra.avro.ColumnOrSuperColumn acosc = amut.column_or_supercolumn;
-        if (acosc != null)
-        {
-            // creation
-            ColumnOrSuperColumn cosc = new ColumnOrSuperColumn();
-            mutation.setColumn_or_supercolumn(cosc);
-            if (acosc.column != null)
-                // standard column
-                cosc.setColumn(avroToThrift(acosc.column));
-            else
-            {
-                // super column
-                ByteBuffer scolname = acosc.super_column.name;
-                List<Column> scolcols = new ArrayList<Column>(acosc.super_column.columns.size());
-                for (org.apache.cassandra.avro.Column acol : acosc.super_column.columns)
-                    scolcols.add(avroToThrift(acol));
-                cosc.setSuper_column(new SuperColumn(scolname, scolcols));
-            }
-        }
-        else
+        if (acosc == null)
         {
             // deletion
+            assert amut.deletion != null;
             Deletion deletion = new Deletion(amut.deletion.timestamp);
             mutation.setDeletion(deletion);
+
             org.apache.cassandra.avro.SlicePredicate apred = amut.deletion.predicate;
-            if (amut.deletion.super_column != null)
+            if (apred == null && amut.deletion.super_column == null)
+            {
+                // leave Deletion alone to delete entire row
+            }
+            else if (amut.deletion.super_column != null)
+            {
                 // super column
                 deletion.setSuper_column(ByteBufferUtil.getArray(amut.deletion.super_column));
+            }
             else if (apred.column_names != null)
             {
                 // column names
@@ -184,6 +174,24 @@ implements org.apache.hadoop.mapred.RecordWriter<ByteBuffer,List<org.apache.cass
                 deletion.setPredicate(new SlicePredicate().setSlice_range(avroToThrift(apred.slice_range)));
             }
         }
+        else
+        {
+            // creation
+            ColumnOrSuperColumn cosc = new ColumnOrSuperColumn();
+            mutation.setColumn_or_supercolumn(cosc);
+            if (acosc.column != null)
+                // standard column
+                cosc.setColumn(avroToThrift(acosc.column));
+            else
+            {
+                // super column
+                ByteBuffer scolname = acosc.super_column.name;
+                List<Column> scolcols = new ArrayList<Column>(acosc.super_column.columns.size());
+                for (org.apache.cassandra.avro.Column acol : acosc.super_column.columns)
+                    scolcols.add(avroToThrift(acol));
+                cosc.setSuper_column(new SuperColumn(scolname, scolcols));
+            }
+        }
         return mutation;
     }
 
