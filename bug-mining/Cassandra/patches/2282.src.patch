diff --git a/CHANGES.txt b/CHANGES.txt
index da1ec20ac9..377b5a1473 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -6,6 +6,8 @@
  * Allow compacting 2Is via nodetool (CASSANDRA-5670)
  * Hex-encode non-String keys in OPP (CASSANDRA-5793)
  * nodetool history logging (CASSANDRA-5823)
+ * (Hadoop) fix support for Thrift tables in CqlPagingRecordReader 
+   (CASSANDRA-5752)
 
 
 1.2.8
diff --git a/src/java/org/apache/cassandra/hadoop/cql3/CqlPagingRecordReader.java b/src/java/org/apache/cassandra/hadoop/cql3/CqlPagingRecordReader.java
index fc071317ff..db77c9ecd6 100644
--- a/src/java/org/apache/cassandra/hadoop/cql3/CqlPagingRecordReader.java
+++ b/src/java/org/apache/cassandra/hadoop/cql3/CqlPagingRecordReader.java
@@ -29,6 +29,9 @@ import com.google.common.collect.Iterables;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.cql3.CFDefinition;
+import org.apache.cassandra.cql3.ColumnIdentifier;
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.CompositeType;
 import org.apache.cassandra.db.marshal.LongType;
@@ -671,6 +674,11 @@ public class CqlPagingRecordReader extends RecordReader<Map<String, ByteBuffer>,
 
         for (String key : keys)
             partitionBoundColumns.add(new BoundColumn(key));
+        if (partitionBoundColumns.size() == 0)
+        {
+            retrieveKeysForThriftTables();
+            return;
+        }
 
         keyString = ByteBufferUtil.string(ByteBuffer.wrap(cqlRow.columns.get(1).getValue()));
         logger.debug("cluster columns: {}", keyString);
@@ -679,10 +687,35 @@ public class CqlPagingRecordReader extends RecordReader<Map<String, ByteBuffer>,
         for (String key : keys)
             clusterColumns.add(new BoundColumn(key));
 
-        Column rawKeyValidator = cqlRow.columns.get(2);
-        String validator = ByteBufferUtil.string(ByteBuffer.wrap(rawKeyValidator.getValue()));
-        logger.debug("row key validator: {}", validator);
-        keyValidator = parseType(validator);
+        parseKeyValidators(ByteBufferUtil.string(ByteBuffer.wrap(cqlRow.columns.get(2).getValue())));
+    }
+
+    /** 
+     * retrieve the fake partition keys and cluster keys for classic thrift table 
+     * use CFDefinition to get keys and columns
+     * */
+    private void retrieveKeysForThriftTables() throws Exception
+    {
+        KsDef ksDef = client.describe_keyspace(keyspace);
+        for (CfDef cfDef : ksDef.cf_defs)
+        {
+            if (cfDef.name.equalsIgnoreCase(cfName))
+            {
+                CFMetaData cfMeta = CFMetaData.fromThrift(cfDef);
+                CFDefinition cfDefinition = new CFDefinition(cfMeta);
+                for (ColumnIdentifier columnIdentifier : cfDefinition.keys.keySet())
+                    partitionBoundColumns.add(new BoundColumn(columnIdentifier.toString()));
+                parseKeyValidators(cfDef.key_validation_class);
+                return;
+            }
+        }
+    }
+
+    /** parse key validators */
+    private void parseKeyValidators(String rowKeyValidator) throws IOException
+    {
+        logger.debug("row key validator: {} ", rowKeyValidator);
+        keyValidator = parseType(rowKeyValidator);
 
         if (keyValidator instanceof CompositeType)
         {
diff --git a/src/java/org/apache/cassandra/hadoop/cql3/CqlRecordWriter.java b/src/java/org/apache/cassandra/hadoop/cql3/CqlRecordWriter.java
index 612f86ae28..76d419ef09 100644
--- a/src/java/org/apache/cassandra/hadoop/cql3/CqlRecordWriter.java
+++ b/src/java/org/apache/cassandra/hadoop/cql3/CqlRecordWriter.java
@@ -26,6 +26,9 @@ import java.util.concurrent.ConcurrentHashMap;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.cql3.CFDefinition;
+import org.apache.cassandra.cql3.ColumnIdentifier;
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.CompositeType;
 import org.apache.cassandra.db.marshal.LongType;
@@ -337,6 +340,11 @@ final class CqlRecordWriter extends AbstractColumnFamilyRecordWriter<Map<String,
         logger.debug("partition keys: " + keyString);
 
         List<String> keys = FBUtilities.fromJsonList(keyString);
+        if (keys.size() == 0)
+        {
+            retrieveKeysForThriftTables(client);
+            return;
+        }
         partitionKeyColumns = new String[keys.size()];
         int i = 0;
         for (String key : keys)
@@ -352,6 +360,31 @@ final class CqlRecordWriter extends AbstractColumnFamilyRecordWriter<Map<String,
         clusterColumns = FBUtilities.fromJsonList(clusterColumnString);
     }
 
+    /** 
+     * retrieve the fake partition keys and cluster keys for classic thrift table 
+     * use CFDefinition to get keys and columns
+     * */
+    private void retrieveKeysForThriftTables(Cassandra.Client client) throws Exception
+    {
+        String keyspace = ConfigHelper.getOutputKeyspace(conf);
+        String cfName = ConfigHelper.getOutputColumnFamily(conf);
+        KsDef ksDef = client.describe_keyspace(keyspace);
+        for (CfDef cfDef : ksDef.cf_defs)
+        {
+            if (cfDef.name.equalsIgnoreCase(cfName))
+            {
+                CFMetaData cfMeta = CFMetaData.fromThrift(cfDef);
+                CFDefinition cfDefinition = new CFDefinition(cfMeta);
+                int i = 0;
+                for (ColumnIdentifier column : cfDefinition.keys.keySet())
+                {
+                    partitionKeyColumns[i] = column.toString();
+                    i++;
+                }
+                return;
+            }
+        }
+    }
     private AbstractType<?> parseType(String type) throws ConfigurationException
     {
         try
