diff --git a/CHANGES.txt b/CHANGES.txt
index 404a744aa8..b566c6f3b6 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -3,6 +3,8 @@
  * ensure unique streaming session id's (CASSANDRA-4223)
  * kick off background compaction when min/max thresholds change 
    (CASSANDRA-4279)
+ * improve ability of STCS.getBuckets to deal with 100s of 1000s of
+   sstables, such as when convertinb back from LCS (CASSANDRA-4287)
 
 
 1.0.10
diff --git a/src/java/org/apache/cassandra/db/compaction/SizeTieredCompactionStrategy.java b/src/java/org/apache/cassandra/db/compaction/SizeTieredCompactionStrategy.java
index 380982f417..747edcca59 100644
--- a/src/java/org/apache/cassandra/db/compaction/SizeTieredCompactionStrategy.java
+++ b/src/java/org/apache/cassandra/db/compaction/SizeTieredCompactionStrategy.java
@@ -122,7 +122,7 @@ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy
             }
         });
 
-        Map<List<T>, Long> buckets = new HashMap<List<T>, Long>();
+        Map<Long, List<T>> buckets = new HashMap<Long, List<T>>();
 
         for (Pair<T, Long> pair: sortedFiles)
         {
@@ -132,19 +132,19 @@ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy
             // look for a bucket containing similar-sized files:
             // group in the same bucket if it's w/in 50% of the average for this bucket,
             // or this file and the bucket are all considered "small" (less than `minSSTableSize`)
-            for (Entry<List<T>, Long> entry : buckets.entrySet())
+            for (Entry<Long, List<T>> entry : buckets.entrySet())
             {
-                List<T> bucket = entry.getKey();
-                long averageSize = entry.getValue();
-                if ((size > (averageSize / 2) && size < (3 * averageSize) / 2)
-                    || (size < minSSTableSize && averageSize < minSSTableSize))
+                List<T> bucket = entry.getValue();
+                long oldAverageSize = entry.getKey();
+                if ((size > (oldAverageSize / 2) && size < (3 * oldAverageSize) / 2)
+                    || (size < minSSTableSize && oldAverageSize < minSSTableSize))
                 {
-                    // remove and re-add because adding changes the hash
-                    buckets.remove(bucket);
-                    long totalSize = bucket.size() * averageSize;
-                    averageSize = (totalSize + size) / (bucket.size() + 1);
+                    // remove and re-add under new new average size
+                    buckets.remove(oldAverageSize);
+                    long totalSize = bucket.size() * oldAverageSize;
+                    long newAverageSize = (totalSize + size) / (bucket.size() + 1);
                     bucket.add(pair.left);
-                    buckets.put(bucket, averageSize);
+                    buckets.put(newAverageSize, bucket);
                     bFound = true;
                     break;
                 }
@@ -154,11 +154,11 @@ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy
             {
                 ArrayList<T> bucket = new ArrayList<T>();
                 bucket.add(pair.left);
-                buckets.put(bucket, size);
+                buckets.put(size, bucket);
             }
         }
 
-        return new ArrayList<List<T>>(buckets.keySet());
+        return new ArrayList<List<T>>(buckets.values());
     }
 
     private void updateEstimatedCompactionsByTasks(List<AbstractCompactionTask> tasks)
