diff --git a/CHANGES.txt b/CHANGES.txt
index 4e6c0cf03a..3be1061d30 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -11,6 +11,7 @@
  * Use faster bytes comparison (CASSANDRA-3434)
  * Bulk loader is no longer a fat client, (HADOOP) bulk load output format
    (CASSANDRA-3045)
+ * remove assumption that keys and token are in bijection (CASSANDRA-1034)
 
 
 1.0.5
diff --git a/src/java/org/apache/cassandra/client/RingCache.java b/src/java/org/apache/cassandra/client/RingCache.java
index 12b1ace033..8d6648c8ff 100644
--- a/src/java/org/apache/cassandra/client/RingCache.java
+++ b/src/java/org/apache/cassandra/client/RingCache.java
@@ -50,7 +50,7 @@ public class RingCache
     private final IPartitioner<?> partitioner;
     private final Configuration conf;
 
-    private Multimap<Range, InetAddress> rangeMap;
+    private Multimap<Range<Token>, InetAddress> rangeMap;
 
     public RingCache(Configuration conf) throws IOException
     {
@@ -72,7 +72,7 @@ public class RingCache
                 {
                     Token<?> left = partitioner.getTokenFactory().fromString(range.start_token);
                     Token<?> right = partitioner.getTokenFactory().fromString(range.end_token);
-                    Range r = new Range(left, right, partitioner);
+                    Range<Token> r = new Range<Token>(left, right, partitioner);
                     for (String host : range.endpoints)
                     {
                         try
@@ -101,7 +101,7 @@ public class RingCache
         }
 
     /** ListMultimap promises to return a List for get(K) */
-    public List<InetAddress> getEndpoint(Range range)
+    public List<InetAddress> getEndpoint(Range<Token> range)
     {
         return (List<InetAddress>) rangeMap.get(range);
     }
@@ -111,11 +111,11 @@ public class RingCache
         return getEndpoint(getRange(key));
     }
 
-    public Range getRange(ByteBuffer key)
+    public Range<Token> getRange(ByteBuffer key)
     {
         // TODO: naive linear search of the token map
         Token<?> t = partitioner.getToken(key);
-        for (Range range : rangeMap.keySet())
+        for (Range<Token> range : rangeMap.keySet())
             if (range.contains(t))
                 return range;
 
diff --git a/src/java/org/apache/cassandra/config/DatabaseDescriptor.java b/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
index 61aea22569..21b29fc042 100644
--- a/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
+++ b/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
@@ -580,6 +580,12 @@ public class DatabaseDescriptor
     {
         return partitioner;
     }
+
+    /* For tests ONLY, don't use otherwise or all hell will break loose */
+    public static void setPartitioner(IPartitioner newPartitioner)
+    {
+        partitioner = newPartitioner;
+    }
     
     public static IEndpointSnitch getEndpointSnitch()
     {
diff --git a/src/java/org/apache/cassandra/cql/QueryProcessor.java b/src/java/org/apache/cassandra/cql/QueryProcessor.java
index ae48026dfc..d80240fa22 100644
--- a/src/java/org/apache/cassandra/cql/QueryProcessor.java
+++ b/src/java/org/apache/cassandra/cql/QueryProcessor.java
@@ -45,7 +45,6 @@ import org.apache.cassandra.db.marshal.MarshalException;
 import org.apache.cassandra.db.marshal.TypeParser;
 import org.apache.cassandra.db.migration.*;
 import org.apache.cassandra.dht.*;
-import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.service.StorageProxy;
 import org.apache.cassandra.service.StorageService;
@@ -151,23 +150,23 @@ public class QueryProcessor
 
         AbstractType<?> keyType = Schema.instance.getCFMetaData(metadata.ksName, select.getColumnFamily()).getKeyValidator();
 
-        ByteBuffer startKey = (select.getKeyStart() != null)
-                               ? select.getKeyStart().getByteBuffer(keyType)
-                               : (new Term()).getByteBuffer();
+        ByteBuffer startKeyBytes = (select.getKeyStart() != null)
+                                   ? select.getKeyStart().getByteBuffer(keyType)
+                                   : (new Term()).getByteBuffer();
 
-        ByteBuffer finishKey = (select.getKeyFinish() != null)
-                                ? select.getKeyFinish().getByteBuffer(keyType)
-                                : (new Term()).getByteBuffer();
+        ByteBuffer finishKeyBytes = (select.getKeyFinish() != null)
+                                    ? select.getKeyFinish().getByteBuffer(keyType)
+                                    : (new Term()).getByteBuffer();
 
-        Token startToken = p.getToken(startKey), finishToken = p.getToken(finishKey);
-        if (startToken.compareTo(finishToken) > 0 && !finishToken.equals(p.getMinimumToken()))
+        RowPosition startKey = p.decorateKey(startKeyBytes), finishKey = p.decorateKey(finishKeyBytes);
+        if (startKey.compareTo(finishKey) > 0 && !finishKey.isMinimum(p))
         {
             if (p instanceof RandomPartitioner)
-                throw new InvalidRequestException("Start key's md5 sorts after end key's md5. This is not allowed; you probably should not specify end key at all, under RandomPartitioner");
+                throw new InvalidRequestException("Start key sorts after end key. This is not allowed; you probably should not specify end key at all, under RandomPartitioner");
             else
                 throw new InvalidRequestException("Start key must sort before (or equal to) finish key in your partitioner!");
         }
-        AbstractBounds bounds = new Bounds(startToken, finishToken);
+        AbstractBounds<RowPosition> bounds = new Bounds<RowPosition>(startKey, finishKey);
         
         // XXX: Our use of Thrift structs internally makes me Sad. :(
         SlicePredicate thriftSlicePredicate = slicePredicateFromSelect(select, metadata);
diff --git a/src/java/org/apache/cassandra/db/ColumnFamilyStore.java b/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
index 6bf4882331..f412e9ca95 100644
--- a/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
+++ b/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
@@ -1228,7 +1228,7 @@ public class ColumnFamilyStore implements ColumnFamilyStoreMBean
      */
     public ViewFragment markReferenced(DecoratedKey key)
     {
-        assert !key.isEmpty();
+        assert !key.isMinimum();
         DataTracker.View view;
         List<SSTableReader> sstables;
         while (true)
@@ -1246,7 +1246,7 @@ public class ColumnFamilyStore implements ColumnFamilyStoreMBean
      * @return a ViewFragment containing the sstables and memtables that may need to be merged
      * for rows between @param startWith and @param stopAt, inclusive, according to the interval tree
      */
-    public ViewFragment markReferenced(DecoratedKey startWith, DecoratedKey stopAt)
+    public ViewFragment markReferenced(RowPosition startWith, RowPosition stopAt)
     {
         DataTracker.View view;
         List<SSTableReader> sstables;
@@ -1255,7 +1255,7 @@ public class ColumnFamilyStore implements ColumnFamilyStoreMBean
             view = data.getView();
             // startAt == minimum is ok, but stopAt == minimum is confusing because all IntervalTree deals with
             // is Comparable, so it won't know to special-case that.
-            Comparable stopInTree = stopAt.isEmpty() ? view.intervalTree.max() : stopAt;
+            Comparable stopInTree = stopAt.isMinimum() ? view.intervalTree.max() : stopAt;
             sstables = view.intervalTree.search(new Interval(startWith, stopInTree));
             if (SSTableReader.acquireReferences(sstables))
                 break;
@@ -1282,15 +1282,15 @@ public class ColumnFamilyStore implements ColumnFamilyStoreMBean
       * @param columnFilter description of the columns we're interested in for each row
       * @return true if we found all keys we were looking for, otherwise false
      */
-    public List<Row> getRangeSlice(ByteBuffer superColumn, final AbstractBounds range, int maxResults, IFilter columnFilter)
+    public List<Row> getRangeSlice(ByteBuffer superColumn, final AbstractBounds<RowPosition> range, int maxResults, IFilter columnFilter)
     throws ExecutionException, InterruptedException
     {
         assert range instanceof Bounds
-               || (!((Range)range).isWrapAround() || range.right.equals(StorageService.getPartitioner().getMinimumToken()))
+               || !((Range)range).isWrapAround() || range.right.isMinimum()
                : range;
 
-        DecoratedKey startWith = new DecoratedKey(range.left, null);
-        DecoratedKey stopAt = new DecoratedKey(range.right, null);
+        RowPosition startWith = range.left;
+        RowPosition stopAt = range.right;
 
         QueryFilter filter = new QueryFilter(null, new QueryPath(columnFamily, superColumn, null), columnFilter);
         int gcBefore = (int)(System.currentTimeMillis() / 1000) - metadata.getGcGraceSeconds();
@@ -1311,7 +1311,7 @@ public class ColumnFamilyStore implements ColumnFamilyStoreMBean
                     Row current = iterator.next();
                     DecoratedKey key = current.key;
 
-                    if (!stopAt.isEmpty() && stopAt.compareTo(key) < 0)
+                    if (!stopAt.isMinimum() && stopAt.compareTo(key) < 0)
                         return rows;
 
                     // skip first one
@@ -1352,7 +1352,7 @@ public class ColumnFamilyStore implements ColumnFamilyStoreMBean
         return rows;
     }
 
-    public List<Row> search(IndexClause clause, AbstractBounds range, IFilter dataFilter)
+    public List<Row> search(IndexClause clause, AbstractBounds<RowPosition> range, IFilter dataFilter)
     {
         return indexManager.search(clause, range, dataFilter);
     }
@@ -1520,7 +1520,7 @@ public class ColumnFamilyStore implements ColumnFamilyStoreMBean
         return Iterables.concat(samples);
     }
 
-    public Iterable<DecoratedKey> keySamples(Range range)
+    public Iterable<DecoratedKey> keySamples(Range<Token> range)
     {
         Collection<SSTableReader> sstables = getSSTables();
         Iterable<DecoratedKey>[] samples = new Iterable[sstables.size()];
diff --git a/src/java/org/apache/cassandra/db/DecoratedKey.java b/src/java/org/apache/cassandra/db/DecoratedKey.java
index 51fcf44879..9f954e5651 100644
--- a/src/java/org/apache/cassandra/db/DecoratedKey.java
+++ b/src/java/org/apache/cassandra/db/DecoratedKey.java
@@ -23,6 +23,7 @@ import java.util.Comparator;
 
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.dht.RingPosition;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
@@ -35,9 +36,9 @@ import org.apache.cassandra.utils.ByteBufferUtil;
  * if this matters, you can subclass RP to use a stronger hash, or use a non-lossy tokenization scheme (as in the
  * OrderPreservingPartitioner classes).
  */
-public class DecoratedKey<T extends Token> implements Comparable<DecoratedKey>
+public class DecoratedKey<T extends Token> extends RowPosition
 {
-    private static IPartitioner partitioner = StorageService.getPartitioner();
+    private static final IPartitioner partitioner = StorageService.getPartitioner();
 
     public static final Comparator<DecoratedKey> comparator = new Comparator<DecoratedKey>()
     {
@@ -52,8 +53,7 @@ public class DecoratedKey<T extends Token> implements Comparable<DecoratedKey>
 
     public DecoratedKey(T token, ByteBuffer key)
     {
-        super();
-        assert token != null;
+        assert token != null && key != null && key.remaining() > 0;
         this.token = token;
         this.key = key;
     }
@@ -61,7 +61,7 @@ public class DecoratedKey<T extends Token> implements Comparable<DecoratedKey>
     @Override
     public int hashCode()
     {
-        return token.hashCode();
+        return key.hashCode(); // hash of key is enough
     }
 
     @Override
@@ -69,23 +69,37 @@ public class DecoratedKey<T extends Token> implements Comparable<DecoratedKey>
     {
         if (this == obj)
             return true;
-        if (obj == null)
-            return false;
-        if (getClass() != obj.getClass())
+        if (obj == null || this.getClass() != obj.getClass())
             return false;
 
-        DecoratedKey other = (DecoratedKey) obj;
-        return token.equals(other.token);
+        DecoratedKey other = (DecoratedKey)obj;
+
+        return ByteBufferUtil.compareUnsigned(key, other.key) == 0; // we compare faster than BB.equals for array backed BB
+    }
+
+    public int compareTo(RowPosition pos)
+    {
+        if (this == pos)
+            return 0;
+
+        // delegate to Token.KeyBound if needed
+        if (!(pos instanceof DecoratedKey))
+            return -pos.compareTo(this);
+
+        DecoratedKey otherKey = (DecoratedKey) pos;
+        int cmp = token.compareTo(otherKey.getToken());
+        return cmp == 0 ? ByteBufferUtil.compareUnsigned(key, otherKey.key) : cmp;
     }
 
-    public int compareTo(DecoratedKey other)
+    public boolean isMinimum(IPartitioner partitioner)
     {
-        return token.compareTo(other.token);
+        // A DecoratedKey can never be the minimum position on the ring
+        return false;
     }
 
-    public boolean isEmpty()
+    public RowPosition.Kind kind()
     {
-        return token.equals(partitioner.getMinimumToken());
+        return RowPosition.Kind.ROW_KEY;
     }
 
     @Override
@@ -94,4 +108,9 @@ public class DecoratedKey<T extends Token> implements Comparable<DecoratedKey>
         String keystring = key == null ? "null" : ByteBufferUtil.bytesToHex(key);
         return "DecoratedKey(" + token + ", " + keystring + ")";
     }
+
+    public T getToken()
+    {
+        return token;
+    }
 }
diff --git a/src/java/org/apache/cassandra/db/HintedHandOffManager.java b/src/java/org/apache/cassandra/db/HintedHandOffManager.java
index e9f8c8cd60..0d18f8abc7 100644
--- a/src/java/org/apache/cassandra/db/HintedHandOffManager.java
+++ b/src/java/org/apache/cassandra/db/HintedHandOffManager.java
@@ -402,8 +402,8 @@ public class HintedHandOffManager implements HintedHandOffManagerMBean
 
         // From keys "" to ""...
         IPartitioner<?> partitioner = StorageService.getPartitioner();
-        ByteBuffer empty = ByteBufferUtil.EMPTY_BYTE_BUFFER;
-        Range range = new Range(partitioner.getToken(empty), partitioner.getToken(empty));
+        RowPosition minPos = partitioner.getMinimumToken().minKeyBound();
+        Range<RowPosition> range = new Range<RowPosition>(minPos, minPos);
 
         // Get a bunch of rows!
         List<Row> rows;
diff --git a/src/java/org/apache/cassandra/db/IndexScanCommand.java b/src/java/org/apache/cassandra/db/IndexScanCommand.java
index b821e137ef..f9cec3c2ff 100644
--- a/src/java/org/apache/cassandra/db/IndexScanCommand.java
+++ b/src/java/org/apache/cassandra/db/IndexScanCommand.java
@@ -23,10 +23,14 @@ import java.io.*;
 import java.util.Arrays;
 
 import org.apache.cassandra.dht.AbstractBounds;
-import org.apache.cassandra.io.ISerializer;
+import org.apache.cassandra.dht.Bounds;
+import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.io.util.FastByteArrayInputStream;
 import org.apache.cassandra.net.Message;
+import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.net.MessageProducer;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.thrift.IndexClause;
@@ -44,9 +48,9 @@ public class IndexScanCommand implements MessageProducer
     public final String column_family;
     public final IndexClause index_clause;
     public final SlicePredicate predicate;
-    public final AbstractBounds range;
+    public final AbstractBounds<RowPosition> range;
 
-    public IndexScanCommand(String keyspace, String column_family, IndexClause index_clause, SlicePredicate predicate, AbstractBounds range)
+    public IndexScanCommand(String keyspace, String column_family, IndexClause index_clause, SlicePredicate predicate, AbstractBounds<RowPosition> range)
     {
 
         this.keyspace = keyspace;
@@ -61,7 +65,7 @@ public class IndexScanCommand implements MessageProducer
         DataOutputBuffer dob = new DataOutputBuffer();
         try
         {
-            serializer.serialize(this, dob);
+            serializer.serialize(this, dob, version);
         }
         catch (IOException e)
         {
@@ -77,22 +81,22 @@ public class IndexScanCommand implements MessageProducer
     {
         byte[] bytes = message.getMessageBody();
         FastByteArrayInputStream bis = new FastByteArrayInputStream(bytes);
-        return serializer.deserialize(new DataInputStream(bis));
+        return serializer.deserialize(new DataInputStream(bis), message.getVersion());
     }
 
-    private static class IndexScanCommandSerializer implements ISerializer<IndexScanCommand>
+    private static class IndexScanCommandSerializer implements IVersionedSerializer<IndexScanCommand>
     {
-        public void serialize(IndexScanCommand o, DataOutput out) throws IOException
+        public void serialize(IndexScanCommand o, DataOutput out, int version) throws IOException
         {
             out.writeUTF(o.keyspace);
             out.writeUTF(o.column_family);
             TSerializer ser = new TSerializer(new TBinaryProtocol.Factory());
             FBUtilities.serialize(ser, o.index_clause, out);
             FBUtilities.serialize(ser, o.predicate, out);
-            AbstractBounds.serializer().serialize(o.range, out);
+            AbstractBounds.serializer().serialize(o.range, out, version);
         }
 
-        public IndexScanCommand deserialize(DataInput in) throws IOException
+        public IndexScanCommand deserialize(DataInput in, int version) throws IOException
         {
             String keyspace = in.readUTF();
             String columnFamily = in.readUTF();
@@ -102,12 +106,11 @@ public class IndexScanCommand implements MessageProducer
             FBUtilities.deserialize(dser, indexClause, in);
             SlicePredicate predicate = new SlicePredicate();
             FBUtilities.deserialize(dser, predicate, in);
-            AbstractBounds range = AbstractBounds.serializer().deserialize(in);
-
+            AbstractBounds<RowPosition> range = AbstractBounds.serializer().deserialize(in, version).toRowBounds();
             return new IndexScanCommand(keyspace, columnFamily, indexClause, predicate, range);
         }
 
-        public long serializedSize(IndexScanCommand object)
+        public long serializedSize(IndexScanCommand object, int version)
         {
             throw new UnsupportedOperationException();
         }
diff --git a/src/java/org/apache/cassandra/db/Memtable.java b/src/java/org/apache/cassandra/db/Memtable.java
index 9a9ae50dae..a500172802 100644
--- a/src/java/org/apache/cassandra/db/Memtable.java
+++ b/src/java/org/apache/cassandra/db/Memtable.java
@@ -74,7 +74,10 @@ public class Memtable
     private final AtomicLong currentThroughput = new AtomicLong(0);
     private final AtomicLong currentOperations = new AtomicLong(0);
 
-    private final ConcurrentNavigableMap<DecoratedKey, ColumnFamily> columnFamilies = new ConcurrentSkipListMap<DecoratedKey, ColumnFamily>();
+    // We index the memtable by RowPosition only for the purpose of being able
+    // to select key range using Token.KeyBound. However put() ensures that we
+    // actually only store DecoratedKey.
+    private final ConcurrentNavigableMap<RowPosition, ColumnFamily> columnFamilies = new ConcurrentSkipListMap<RowPosition, ColumnFamily>();
     public final ColumnFamilyStore cfs;
     private final long creationTime;
 
@@ -157,7 +160,7 @@ public class Memtable
                 // So to reduce the memory overhead of doing a measurement, we break it up to row-at-a-time.
                 long deepSize = meter.measure(columnFamilies);
                 int objects = 0;
-                for (Map.Entry<DecoratedKey, ColumnFamily> entry : columnFamilies.entrySet())
+                for (Map.Entry<RowPosition, ColumnFamily> entry : columnFamilies.entrySet())
                 {
                     deepSize += meter.measureDeep(entry.getKey()) + meter.measureDeep(entry.getValue());
                     objects += entry.getValue().getColumnCount();
@@ -225,7 +228,7 @@ public class Memtable
     {
         StringBuilder builder = new StringBuilder();
         builder.append("{");
-        for (Map.Entry<DecoratedKey, ColumnFamily> entry : columnFamilies.entrySet())
+        for (Map.Entry<RowPosition, ColumnFamily> entry : columnFamilies.entrySet())
         {
             builder.append(entry.getKey()).append(": ").append(entry.getValue()).append(", ");
         }
@@ -239,8 +242,12 @@ public class Memtable
         logger.info("Writing " + this);
 
         long keySize = 0;
-        for (DecoratedKey key : columnFamilies.keySet())
-            keySize += key.key.remaining();
+        for (RowPosition key : columnFamilies.keySet())
+        {
+            //  make sure we don't write non-sensical keys
+            assert key instanceof DecoratedKey;
+            keySize += ((DecoratedKey)key).key.remaining();
+        }
         long estimatedSize = (long) ((keySize // index entries
                                       + keySize // keys in data file
                                       + currentThroughput.get()) // data
@@ -252,7 +259,7 @@ public class Memtable
         {
             // (we can't clear out the map as-we-go to free up memory,
             //  since the memtable is being used for queries in the "pending flush" category)
-            for (Map.Entry<DecoratedKey, ColumnFamily> entry : columnFamilies.entrySet())
+            for (Map.Entry<RowPosition, ColumnFamily> entry : columnFamilies.entrySet())
             {
                 ColumnFamily cf = entry.getValue();
                 if (cf.isMarkedForDelete())
@@ -263,7 +270,7 @@ public class Memtable
                     // is a CF level tombstone to ensure the delete makes it into an SSTable.
                     ColumnFamilyStore.removeDeletedColumnsOnly(cf, Integer.MIN_VALUE);
                 }
-                writer.append(entry.getKey(), cf);
+                writer.append((DecoratedKey)entry.getKey(), cf);
             }
 
             ssTable = writer.closeAndOpenReader();
@@ -300,9 +307,30 @@ public class Memtable
      * @param startWith Include data in the result from and including this key and to the end of the memtable
      * @return An iterator of entries with the data from the start key 
      */
-    public Iterator<Map.Entry<DecoratedKey, ColumnFamily>> getEntryIterator(DecoratedKey startWith)
+    public Iterator<Map.Entry<DecoratedKey, ColumnFamily>> getEntryIterator(final RowPosition startWith)
     {
-        return columnFamilies.tailMap(startWith).entrySet().iterator();
+        return new Iterator<Map.Entry<DecoratedKey, ColumnFamily>>()
+        {
+            private Iterator<Map.Entry<RowPosition, ColumnFamily>> iter = columnFamilies.tailMap(startWith).entrySet().iterator();
+
+            public boolean hasNext()
+            {
+                return iter.hasNext();
+            }
+
+            public Map.Entry<DecoratedKey, ColumnFamily> next()
+            {
+                Map.Entry<RowPosition, ColumnFamily> entry = iter.next();
+                // Actual stored key should be true DecoratedKey
+                assert entry.getKey() instanceof DecoratedKey;
+                return (Map.Entry<DecoratedKey, ColumnFamily>)(Object)entry; // yes, it's ugly
+            }
+
+            public void remove()
+            {
+                iter.remove();
+            }
+        };
     }
 
     public boolean isClean()
diff --git a/src/java/org/apache/cassandra/db/RangeSliceCommand.java b/src/java/org/apache/cassandra/db/RangeSliceCommand.java
index 41e6406e5d..cc200ae37f 100644
--- a/src/java/org/apache/cassandra/db/RangeSliceCommand.java
+++ b/src/java/org/apache/cassandra/db/RangeSliceCommand.java
@@ -41,6 +41,7 @@ import java.nio.ByteBuffer;
 import java.util.Arrays;
 
 import org.apache.cassandra.dht.AbstractBounds;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.io.util.FastByteArrayInputStream;
@@ -67,15 +68,15 @@ public class RangeSliceCommand implements MessageProducer, IReadCommand
 
     public final SlicePredicate predicate;
 
-    public final AbstractBounds range;
+    public final AbstractBounds<RowPosition> range;
     public final int max_keys;
 
-    public RangeSliceCommand(String keyspace, ColumnParent column_parent, SlicePredicate predicate, AbstractBounds range, int max_keys)
+    public RangeSliceCommand(String keyspace, ColumnParent column_parent, SlicePredicate predicate, AbstractBounds<RowPosition> range, int max_keys)
     {
         this(keyspace, column_parent.getColumn_family(), column_parent.super_column, predicate, range, max_keys);
     }
 
-    public RangeSliceCommand(String keyspace, String column_family, ByteBuffer super_column, SlicePredicate predicate, AbstractBounds range, int max_keys)
+    public RangeSliceCommand(String keyspace, String column_family, ByteBuffer super_column, SlicePredicate predicate, AbstractBounds<RowPosition> range, int max_keys)
     {
         this.keyspace = keyspace;
         this.column_family = column_family;
@@ -133,7 +134,7 @@ class RangeSliceCommandSerializer implements IVersionedSerializer<RangeSliceComm
 
         TSerializer ser = new TSerializer(new TBinaryProtocol.Factory());
         FBUtilities.serialize(ser, sliceCommand.predicate, dos);
-        AbstractBounds.serializer().serialize(sliceCommand.range, dos);
+        AbstractBounds.serializer().serialize(sliceCommand.range, dos, version);
         dos.writeInt(sliceCommand.max_keys);
     }
 
@@ -154,8 +155,8 @@ class RangeSliceCommandSerializer implements IVersionedSerializer<RangeSliceComm
         TDeserializer dser = new TDeserializer(new TBinaryProtocol.Factory());
         SlicePredicate pred = new SlicePredicate();
         FBUtilities.deserialize(dser, pred, dis);
+        AbstractBounds<RowPosition> range = AbstractBounds.serializer().deserialize(dis, version).toRowBounds();
 
-        AbstractBounds range = AbstractBounds.serializer().deserialize(dis);
         int max_keys = dis.readInt();
         return new RangeSliceCommand(keyspace, column_family, super_column, pred, range, max_keys);
     }
diff --git a/src/java/org/apache/cassandra/db/RowIteratorFactory.java b/src/java/org/apache/cassandra/db/RowIteratorFactory.java
index a835a216db..5f350bc4db 100644
--- a/src/java/org/apache/cassandra/db/RowIteratorFactory.java
+++ b/src/java/org/apache/cassandra/db/RowIteratorFactory.java
@@ -58,8 +58,8 @@ public class RowIteratorFactory
      */
     public static CloseableIterator<Row> getIterator(final Iterable<Memtable> memtables,
                                           final Collection<SSTableReader> sstables,
-                                          final DecoratedKey startWith,
-                                          final DecoratedKey stopAt,
+                                          final RowPosition startWith,
+                                          final RowPosition stopAt,
                                           final QueryFilter filter,
                                           final AbstractType comparator,
                                           final ColumnFamilyStore cfs)
@@ -73,7 +73,7 @@ public class RowIteratorFactory
             public boolean apply(IColumnIterator row)
             {
                 return startWith.compareTo(row.getKey()) <= 0
-                       && (stopAt.isEmpty() || row.getKey().compareTo(stopAt) <= 0);
+                       && (stopAt.isMinimum() || row.getKey().compareTo(stopAt) <= 0);
             }
         };
 
diff --git a/src/java/org/apache/cassandra/db/RowPosition.java b/src/java/org/apache/cassandra/db/RowPosition.java
new file mode 100644
index 0000000000..2bdfc5ccd4
--- /dev/null
+++ b/src/java/org/apache/cassandra/db/RowPosition.java
@@ -0,0 +1,111 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.cassandra.db;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+
+import org.apache.cassandra.dht.*;
+import org.apache.cassandra.io.ISerializer;
+import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.utils.ByteBufferUtil;
+
+public abstract class RowPosition implements RingPosition<RowPosition>
+{
+    public static enum Kind
+    {
+        // Only add new values to the end of the enum, the ordinal is used
+        // during serialization
+        ROW_KEY, MIN_BOUND, MAX_BOUND;
+
+        private static final Kind[] allKinds = Kind.values();
+
+        static Kind fromOrdinal(int ordinal)
+        {
+            return allKinds[ordinal];
+        }
+    }
+
+    private static final RowPositionSerializer serializer = new RowPositionSerializer();
+    public static RowPositionSerializer serializer()
+    {
+        return serializer;
+    }
+
+    public static RowPosition forKey(ByteBuffer key, IPartitioner p)
+    {
+        return key == null || key.remaining() == 0 ? p.getMinimumToken().minKeyBound() : p.decorateKey(key);
+    }
+
+    public abstract Token getToken();
+    public abstract Kind kind();
+
+    public boolean isMinimum()
+    {
+        return isMinimum(StorageService.getPartitioner());
+    }
+
+    public static class RowPositionSerializer implements ISerializer<RowPosition>
+    {
+        /*
+         * We need to be able to serialize both Token.KeyBound and
+         * DecoratedKey. To make this compact, we first write a byte whose
+         * meaning is:
+         *   - 0: DecoratedKey
+         *   - 1: a 'minimum' Token.KeyBound
+         *   - 2: a 'maximum' Token.KeyBound
+         * In the case of the DecoratedKey, we then serialize the key (the
+         * token is recreated on the other side). In the other cases, we then
+         * serialize the token.
+         */
+        public void serialize(RowPosition pos, DataOutput dos) throws IOException
+        {
+            Kind kind = pos.kind();
+            dos.writeByte(kind.ordinal());
+            if (kind == Kind.ROW_KEY)
+                ByteBufferUtil.writeWithShortLength(((DecoratedKey)pos).key, dos);
+            else
+                Token.serializer().serialize(pos.getToken(), dos);
+        }
+
+        public RowPosition deserialize(DataInput dis) throws IOException
+        {
+            Kind kind = Kind.fromOrdinal(dis.readByte());
+            if (kind == Kind.ROW_KEY)
+            {
+                ByteBuffer k = ByteBufferUtil.readWithShortLength(dis);
+                return StorageService.getPartitioner().decorateKey(k);
+            }
+            else
+            {
+                Token t = Token.serializer().deserialize(dis);
+                return kind == Kind.MIN_BOUND ? t.minKeyBound() : t.maxKeyBound();
+            }
+        }
+
+        public long serializedSize(RowPosition pos)
+        {
+            Kind kind = pos.kind();
+            return DBConstants.boolSize
+                + (kind == Kind.ROW_KEY ? DBConstants.shortSize + ((DecoratedKey)pos).key.remaining()
+                                        : Token.serializer().serializedSize(pos.getToken()));
+        }
+    }
+}
diff --git a/src/java/org/apache/cassandra/db/compaction/CompactionManager.java b/src/java/org/apache/cassandra/db/compaction/CompactionManager.java
index c9d8fcb05e..c3fbdaba94 100644
--- a/src/java/org/apache/cassandra/db/compaction/CompactionManager.java
+++ b/src/java/org/apache/cassandra/db/compaction/CompactionManager.java
@@ -40,6 +40,7 @@ import org.apache.cassandra.db.*;
 import org.apache.cassandra.db.compaction.CompactionInfo.Holder;
 import org.apache.cassandra.db.index.SecondaryIndexBuilder;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.sstable.*;
 import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.io.util.RandomAccessReader;
@@ -650,7 +651,7 @@ public class CompactionManager implements CompactionManagerMBean
     {
         assert !cfs.isIndex();
         Table table = cfs.table;
-        Collection<Range> ranges = StorageService.instance.getLocalRanges(table.name);
+        Collection<Range<Token>> ranges = StorageService.instance.getLocalRanges(table.name);
         boolean isCommutative = cfs.metadata.getDefaultValidator().isCommutative();
         if (ranges.isEmpty())
         {
@@ -693,7 +694,7 @@ public class CompactionManager implements CompactionManagerMBean
                     if (ci.isStopped())
                         throw new UserInterruptedException(ci.getCompactionInfo());
                     SSTableIdentityIterator row = (SSTableIdentityIterator) scanner.next();
-                    if (Range.isTokenInRanges(row.getKey().token, ranges))
+                    if (Range.isInRanges(row.getKey().token, ranges))
                     {
                         AbstractCompactedRow compactedRow = controller.getCompactedRow(row);
                         if (compactedRow.isEmpty())
@@ -944,14 +945,14 @@ public class CompactionManager implements CompactionManagerMBean
 
     private static class ValidationCompactionIterable extends CompactionIterable
     {
-        public ValidationCompactionIterable(ColumnFamilyStore cfs, Collection<SSTableReader> sstables, Range range) throws IOException
+        public ValidationCompactionIterable(ColumnFamilyStore cfs, Collection<SSTableReader> sstables, Range<Token> range) throws IOException
         {
             super(OperationType.VALIDATION,
                   getScanners(sstables, range),
                   new CompactionController(cfs, sstables, getDefaultGcBefore(cfs), true));
         }
 
-        protected static List<SSTableScanner> getScanners(Iterable<SSTableReader> sstables, Range range) throws IOException
+        protected static List<SSTableScanner> getScanners(Iterable<SSTableReader> sstables, Range<Token> range) throws IOException
         {
             ArrayList<SSTableScanner> scanners = new ArrayList<SSTableScanner>();
             for (SSTableReader sstable : sstables)
diff --git a/src/java/org/apache/cassandra/db/compaction/LeveledManifest.java b/src/java/org/apache/cassandra/db/compaction/LeveledManifest.java
index 5f7ed4adef..6052798d86 100644
--- a/src/java/org/apache/cassandra/db/compaction/LeveledManifest.java
+++ b/src/java/org/apache/cassandra/db/compaction/LeveledManifest.java
@@ -34,6 +34,7 @@ import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.DecoratedKey;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.sstable.SSTable;
 import org.apache.cassandra.io.sstable.SSTableReader;
 import org.apache.cassandra.io.util.FileUtils;
@@ -298,10 +299,10 @@ public class LeveledManifest
         List<SSTableReader> overlapped = new ArrayList<SSTableReader>();
         overlapped.add(sstable);
 
-        Range promotedRange = new Range(sstable.first.token, sstable.last.token);
+        Range<Token> promotedRange = new Range<Token>(sstable.first.token, sstable.last.token);
         for (SSTableReader candidate : candidates)
         {
-            Range candidateRange = new Range(candidate.first.token, candidate.last.token);
+            Range<Token> candidateRange = new Range<Token>(candidate.first.token, candidate.last.token);
             if (candidateRange.intersects(promotedRange))
                 overlapped.add(candidate);
         }
diff --git a/src/java/org/apache/cassandra/db/index/SecondaryIndexManager.java b/src/java/org/apache/cassandra/db/index/SecondaryIndexManager.java
index 88528ede7d..8ccec64bac 100644
--- a/src/java/org/apache/cassandra/db/index/SecondaryIndexManager.java
+++ b/src/java/org/apache/cassandra/db/index/SecondaryIndexManager.java
@@ -490,7 +490,7 @@ public class SecondaryIndexManager
      * @param dataFilter the column range to restrict to
      * @return found indexed rows
      */
-    public List<Row> search(IndexClause clause, AbstractBounds range, IFilter dataFilter)
+    public List<Row> search(IndexClause clause, AbstractBounds<RowPosition> range, IFilter dataFilter)
     {
         List<SecondaryIndexSearcher> indexSearchers = getIndexSearchersForQuery(clause);
                
diff --git a/src/java/org/apache/cassandra/db/index/SecondaryIndexSearcher.java b/src/java/org/apache/cassandra/db/index/SecondaryIndexSearcher.java
index d26ccc35ba..4fe9f2aab9 100644
--- a/src/java/org/apache/cassandra/db/index/SecondaryIndexSearcher.java
+++ b/src/java/org/apache/cassandra/db/index/SecondaryIndexSearcher.java
@@ -87,6 +87,5 @@ public abstract class SecondaryIndexSearcher
         return new NamesQueryFilter(columns);
     }
     
-    
-    public abstract List<Row> search(IndexClause clause, AbstractBounds range, IFilter dataFilter);
+    public abstract List<Row> search(IndexClause clause, AbstractBounds<RowPosition> range, IFilter dataFilter);
 }
diff --git a/src/java/org/apache/cassandra/db/index/keys/KeysSearcher.java b/src/java/org/apache/cassandra/db/index/keys/KeysSearcher.java
index 2347410211..ed8e681599 100644
--- a/src/java/org/apache/cassandra/db/index/keys/KeysSearcher.java
+++ b/src/java/org/apache/cassandra/db/index/keys/KeysSearcher.java
@@ -85,7 +85,7 @@ public class KeysSearcher extends SecondaryIndexSearcher
     }
     
     @Override
-    public List<Row> search(IndexClause clause, AbstractBounds range, IFilter dataFilter)
+    public List<Row> search(IndexClause clause, AbstractBounds<RowPosition> range, IFilter dataFilter)
     {
         // Start with the most-restrictive indexed clause, then apply remaining clauses
         // to each row matching that clause.
@@ -181,9 +181,9 @@ public class KeysSearcher extends SecondaryIndexSearcher
                     logger.debug("fetching {}",column.name());
 
                 DecoratedKey dk = baseCfs.partitioner.decorateKey(dataKey);
-                if (!range.right.equals(baseCfs.partitioner.getMinimumToken()) && range.right.compareTo(dk.token) < 0)
+                if (!range.right.isMinimum(baseCfs.partitioner) && range.right.compareTo(dk) < 0)
                     break outer;
-                if (!range.contains(dk.token) || dataKey.equals(lastDataKey))
+                if (!range.contains(dk) || dataKey.equals(lastDataKey))
                     continue;
 
                 // get the row columns requested, and additional columns for the expressions if necessary
diff --git a/src/java/org/apache/cassandra/db/marshal/LocalByPartionerType.java b/src/java/org/apache/cassandra/db/marshal/LocalByPartionerType.java
index f064acb856..a19f48d3b9 100644
--- a/src/java/org/apache/cassandra/db/marshal/LocalByPartionerType.java
+++ b/src/java/org/apache/cassandra/db/marshal/LocalByPartionerType.java
@@ -23,6 +23,7 @@ import java.nio.ByteBuffer;
 
 import org.apache.commons.lang.NotImplementedException;
 
+import org.apache.cassandra.db.RowPosition;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.utils.ByteBufferUtil;
@@ -60,7 +61,8 @@ public class LocalByPartionerType<T extends Token> extends AbstractType<ByteBuff
 
     public int compare(ByteBuffer o1, ByteBuffer o2)
     {
-        return partitioner.decorateKey(o1).compareTo(partitioner.decorateKey(o2));
+        // o1 and o2 can be empty so we need to use RowPosition, not DecoratedKey
+        return RowPosition.forKey(o1, partitioner).compareTo(RowPosition.forKey(o2, partitioner));
     }
 
     public void validate(ByteBuffer bytes) throws MarshalException
diff --git a/src/java/org/apache/cassandra/dht/AbstractBounds.java b/src/java/org/apache/cassandra/dht/AbstractBounds.java
index 534ee84a69..da218ef646 100644
--- a/src/java/org/apache/cassandra/dht/AbstractBounds.java
+++ b/src/java/org/apache/cassandra/dht/AbstractBounds.java
@@ -27,10 +27,12 @@ import java.io.IOException;
 import java.io.Serializable;
 import java.util.*;
 
-import org.apache.cassandra.io.ISerializer;
+import org.apache.cassandra.db.RowPosition;
+import org.apache.cassandra.io.IVersionedSerializer;
+import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.utils.Pair;
 
-public abstract class AbstractBounds implements Serializable
+public abstract class AbstractBounds<T extends RingPosition> implements Serializable
 {
     private static final long serialVersionUID = 1L;
     private static AbstractBoundsSerializer serializer = new AbstractBoundsSerializer();
@@ -46,12 +48,12 @@ public abstract class AbstractBounds implements Serializable
         BOUNDS
     }
 
-    public final Token left;
-    public final Token right;
+    public final T left;
+    public final T right;
 
     protected transient final IPartitioner partitioner;
 
-    public AbstractBounds(Token left, Token right, IPartitioner partitioner)
+    public AbstractBounds(T left, T right, IPartitioner partitioner)
     {
         this.left = left;
         this.right = right;
@@ -59,18 +61,18 @@ public abstract class AbstractBounds implements Serializable
     }
 
     /**
-     * Given token T and AbstractBounds ?L,R], returns Pair(?L,T], ?T,R])
+     * Given token T and AbstractBounds ?L,R], returns Pair(?L,T], ]T,R])
      * (where ? means that the same type of Bounds is returned -- Range or Bounds -- as the original.)
      * The original AbstractBounds must contain the token T.
      * If the split would cause one of the left or right side to be empty, it will be null in the result pair.
      */
-    public Pair<AbstractBounds,AbstractBounds> split(Token token)
+    public Pair<AbstractBounds<T>,AbstractBounds<T>> split(T pos)
     {
-        assert left.equals(token) || contains(token);
-        AbstractBounds lb = createFrom(token);
+        assert left.equals(pos) || contains(pos);
+        AbstractBounds<T> lb = createFrom(pos);
         // we contain this token, so only one of the left or right can be empty
-        AbstractBounds rb = lb != null && token.equals(right) ? null : new Range(token, right);
-        return new Pair<AbstractBounds,AbstractBounds>(lb, rb);
+        AbstractBounds<T> rb = lb != null && pos.equals(right) ? null : new Range<T>(pos, right);
+        return new Pair<AbstractBounds<T>,AbstractBounds<T>>(lb, rb);
     }
 
     @Override
@@ -79,30 +81,28 @@ public abstract class AbstractBounds implements Serializable
         return 31 * left.hashCode() + right.hashCode();
     }
 
-    public abstract boolean equals(Object obj);
+    public abstract boolean contains(T start);
 
-    public abstract boolean contains(Token start);
+    /** @return A clone of this AbstractBounds with a new right T, or null if an identical range would be created. */
+    public abstract AbstractBounds<T> createFrom(T right);
 
-    /** @return A clone of this AbstractBounds with a new right Token, or null if an identical range would be created. */
-    public abstract AbstractBounds createFrom(Token right);
-
-    public abstract List<AbstractBounds> unwrap();
+    public abstract List<? extends AbstractBounds<T>> unwrap();
 
     /**
      * @return A copy of the given list of with all bounds unwrapped, sorted by bound.left and with overlapping bounds merged.
      * This method does not allow allow to mix Range and Bound in the input list.
      */
-    public static List<AbstractBounds> normalize(Collection<? extends AbstractBounds> bounds)
+    public static <T extends RingPosition> List<AbstractBounds<T>> normalize(Collection<? extends AbstractBounds<T>> bounds)
     {
         // unwrap all
-        List<AbstractBounds> output = new ArrayList<AbstractBounds>();
-        for (AbstractBounds bound : bounds)
+        List<AbstractBounds<T>> output = new ArrayList<AbstractBounds<T>>();
+        for (AbstractBounds<T> bound : bounds)
             output.addAll(bound.unwrap());
 
         // sort by left
-        Collections.sort(output, new Comparator<AbstractBounds>()
+        Collections.sort(output, new Comparator<AbstractBounds<T>>()
         {
-            public int compare(AbstractBounds b1, AbstractBounds b2)
+            public int compare(AbstractBounds<T> b1, AbstractBounds<T> b2)
             {
                 return b1.left.compareTo(b2.left);
             }
@@ -116,31 +116,31 @@ public abstract class AbstractBounds implements Serializable
      * Given a list of unwrapped bounds sorted by left token, return a list a equivalent
      * list of bounds but with no overlapping bounds.
      */
-    private static List<AbstractBounds> deoverlap(List<AbstractBounds> bounds)
+    private static <T extends RingPosition> List<AbstractBounds<T>> deoverlap(List<AbstractBounds<T>> bounds)
     {
         if (bounds.isEmpty())
             return bounds;
 
-        List<AbstractBounds> output = new ArrayList<AbstractBounds>();
+        List<AbstractBounds<T>> output = new ArrayList<AbstractBounds<T>>();
 
-        Iterator<AbstractBounds> iter = bounds.iterator();
-        AbstractBounds current = iter.next();
+        Iterator<AbstractBounds<T>> iter = bounds.iterator();
+        AbstractBounds<T> current = iter.next();
         boolean isRange = current instanceof Range;
 
-        Token min = current.partitioner.getMinimumToken();
+        T min = (T) current.partitioner.minValue(current.left.getClass());
         while (iter.hasNext())
         {
             if (current.right.equals(min))
             {
                 // If one of the bound is the full range, we return only that
                 if (current.left.equals(min))
-                    return Collections.<AbstractBounds>singletonList(current);
+                    return Collections.<AbstractBounds<T>>singletonList(current);
 
                 output.add(current.createFrom(min));
                 return output;
             }
 
-            AbstractBounds next = iter.next();
+            AbstractBounds<T> next = iter.next();
             assert isRange ? next instanceof Range : next instanceof Bounds;
 
             // For Ranges, if next left is equal to current right, we do not intersect per se, but replacing (A, B] and (B, C] by (A, C] is
@@ -149,11 +149,11 @@ public abstract class AbstractBounds implements Serializable
             {
                 // We do overlap
                 // (we've handler current.right.equals(min) already)
-                Token newRight = next.right.equals(min) || current.right.compareTo(next.right) < 0 ? next.right : current.right;
+                T newRight = next.right.equals(min) || current.right.compareTo(next.right) < 0 ? next.right : current.right;
                 current = current.createFrom(newRight);
                 if (current == null)
                     // current is the full ring, can only happen for Range
-                    return Collections.<AbstractBounds>singletonList(new Range(min, min));
+                    return Collections.<AbstractBounds<T>>singletonList(new Range<T>(min, min));
             }
             else
             {
@@ -165,26 +165,75 @@ public abstract class AbstractBounds implements Serializable
         return output;
     }
 
-    public static class AbstractBoundsSerializer implements ISerializer<AbstractBounds>
+    /**
+     * Transform this abstract bounds to equivalent covering bounds of row positions.
+     * If this abstract bounds was already an abstractBounds of row positions, this is a noop.
+     */
+    public abstract AbstractBounds<RowPosition> toRowBounds();
+
+    /**
+     * Transform this abstract bounds to a token abstract bounds.
+     * If this abstract bounds was already an abstractBounds of token, this is a noop, otherwise this use the row position tokens.
+     */
+    public abstract AbstractBounds<Token> toTokenBounds();
+
+    public static class AbstractBoundsSerializer implements IVersionedSerializer<AbstractBounds<?>>
     {
-        public void serialize(AbstractBounds range, DataOutput out) throws IOException
+        public void serialize(AbstractBounds<?> range, DataOutput out, int version) throws IOException
         {
-            out.writeInt(range instanceof Range ? Type.RANGE.ordinal() : Type.BOUNDS.ordinal());
-            Token.serializer().serialize(range.left, out);
-            Token.serializer().serialize(range.right, out);
+            // Older version don't know how to handle abstract bounds of keys
+            // However, the serialization has been designed so that token bounds are serialized the same way that before 1.1
+            if (version < MessagingService.VERSION_11)
+                range = range.toTokenBounds();
+
+            /*
+             * The first int tells us if it's a range or bounds (depending on the value) _and_ if it's tokens or keys (depending on the
+             * sign). We use negative kind for keys so as to preserve the serialization of token from older version.
+             */
+            boolean isToken = range.left instanceof Token;
+            int kind = range instanceof Range ? Type.RANGE.ordinal() : Type.BOUNDS.ordinal();
+            if (!isToken)
+                kind = -(kind+1);
+            out.writeInt(kind);
+            if (isToken)
+            {
+                Token.serializer().serialize((Token)range.left, out);
+                Token.serializer().serialize((Token)range.right, out);
+            }
+            else
+            {
+                RowPosition.serializer().serialize((RowPosition)range.left, out);
+                RowPosition.serializer().serialize((RowPosition)range.right, out);
+            }
         }
 
-        public AbstractBounds deserialize(DataInput in) throws IOException
+        public AbstractBounds<?> deserialize(DataInput in, int version) throws IOException
         {
-            if (in.readInt() == Type.RANGE.ordinal())
-                return new Range(Token.serializer().deserialize(in), Token.serializer().deserialize(in));
-            return new Bounds(Token.serializer().deserialize(in), Token.serializer().deserialize(in));
+            int kind = in.readInt();
+            boolean isToken = kind >= 0;
+            if (!isToken)
+                kind = -(kind+1);
+
+            RingPosition left, right;
+            if (isToken)
+            {
+                left = Token.serializer().deserialize(in);
+                right = Token.serializer().deserialize(in);
+            }
+            else
+            {
+                left = RowPosition.serializer().deserialize(in);
+                right = RowPosition.serializer().deserialize(in);
+            }
+
+            if (kind == Type.RANGE.ordinal())
+                return new Range(left, right);
+            return new Bounds(left, right);
         }
 
-        public long serializedSize(AbstractBounds abstractBounds)
+        public long serializedSize(AbstractBounds<?> abstractBounds, int version)
         {
             throw new UnsupportedOperationException();
         }
     }
 }
-
diff --git a/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java b/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java
index f4f8ae9a49..3f085e9c1a 100644
--- a/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java
@@ -32,7 +32,7 @@ import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.Hex;
 import org.apache.cassandra.utils.Pair;
 
-public abstract class AbstractByteOrderedPartitioner implements IPartitioner<BytesToken>
+public abstract class AbstractByteOrderedPartitioner extends AbstractPartitioner<BytesToken>
 {
     public static final BytesToken MINIMUM = new BytesToken(ArrayUtils.EMPTY_BYTE_ARRAY);
 
@@ -180,14 +180,14 @@ public abstract class AbstractByteOrderedPartitioner implements IPartitioner<Byt
     {
         // allTokens will contain the count and be returned, sorted_ranges is shorthand for token<->token math.
         Map<Token, Float> allTokens = new HashMap<Token, Float>();
-        List<Range> sortedRanges = new ArrayList<Range>();
+        List<Range<Token>> sortedRanges = new ArrayList<Range<Token>>();
 
         // this initializes the counts to 0 and calcs the ranges in order.
         Token lastToken = sortedTokens.get(sortedTokens.size() - 1);
         for (Token node : sortedTokens)
         {
             allTokens.put(node, new Float(0.0));
-            sortedRanges.add(new Range(lastToken, node));
+            sortedRanges.add(new Range<Token>(lastToken, node));
             lastToken = node;
         }
 
@@ -195,7 +195,7 @@ public abstract class AbstractByteOrderedPartitioner implements IPartitioner<Byt
         {
             for (CFMetaData cfmd : Schema.instance.getKSMetaData(ks).cfMetaData().values())
             {
-                for (Range r : sortedRanges)
+                for (Range<Token> r : sortedRanges)
                 {
                     // Looping over every KS:CF:Range, get the splits size and add it to the count
                     allTokens.put(r.right, allTokens.get(r.right) + StorageService.instance.getSplits(ks, cfmd.cfName, r, 1).size());
diff --git a/src/java/org/apache/cassandra/dht/AbstractPartitioner.java b/src/java/org/apache/cassandra/dht/AbstractPartitioner.java
new file mode 100644
index 0000000000..c81102fc00
--- /dev/null
+++ b/src/java/org/apache/cassandra/dht/AbstractPartitioner.java
@@ -0,0 +1,30 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.cassandra.dht;
+
+public abstract class AbstractPartitioner<T extends Token> implements IPartitioner<T>
+{
+    public <R extends RingPosition> R minValue(Class<R> klass)
+    {
+        Token minToken = getMinimumToken();
+        if (minToken.getClass().equals(klass))
+            return (R)minToken;
+        else
+            return (R)minToken.minKeyBound();
+    }
+}
diff --git a/src/java/org/apache/cassandra/dht/BootStrapper.java b/src/java/org/apache/cassandra/dht/BootStrapper.java
index 90f4ee43b9..5b84867411 100644
--- a/src/java/org/apache/cassandra/dht/BootStrapper.java
+++ b/src/java/org/apache/cassandra/dht/BootStrapper.java
@@ -80,13 +80,13 @@ public class BootStrapper
         if (logger.isDebugEnabled())
             logger.debug("Beginning bootstrap process");
 
-        final Multimap<String, Map.Entry<InetAddress, Collection<Range>>> rangesToFetch = HashMultimap.create();
+        final Multimap<String, Map.Entry<InetAddress, Collection<Range<Token>>>> rangesToFetch = HashMultimap.create();
 
         int requests = 0;
         for (String table : Schema.instance.getNonSystemTables())
         {
-            Map<InetAddress, Collection<Range>> workMap = getWorkMap(getRangesWithSources(table)).asMap();
-            for (Map.Entry<InetAddress, Collection<Range>> entry : workMap.entrySet())
+            Map<InetAddress, Collection<Range<Token>>> workMap = getWorkMap(getRangesWithSources(table)).asMap();
+            for (Map.Entry<InetAddress, Collection<Range<Token>>> entry : workMap.entrySet())
             {
                 requests++;
                 rangesToFetch.put(table, entry);
@@ -97,9 +97,10 @@ public class BootStrapper
         for (final String table : rangesToFetch.keySet())
         {
             /* Send messages to respective folks to stream data over to me */
-            for (Map.Entry<InetAddress, Collection<Range>> entry : rangesToFetch.get(table))
+            for (Map.Entry<InetAddress, Collection<Range<Token>>> entry : rangesToFetch.get(table))
             {
                 final InetAddress source = entry.getKey();
+                Collection<Range<Token>> ranges = entry.getValue();
                 final Runnable callback = new Runnable()
                 {
                     public void run()
@@ -111,8 +112,8 @@ public class BootStrapper
                     }
                 };
                 if (logger.isDebugEnabled())
-                    logger.debug("Bootstrapping from " + source + " ranges " + StringUtils.join(entry.getValue(), ", "));
-                StreamIn.requestRanges(source, table, entry.getValue(), callback, OperationType.BOOTSTRAP);
+                    logger.debug("Bootstrapping from " + source + " ranges " + StringUtils.join(ranges, ", "));
+                StreamIn.requestRanges(source, table, ranges, callback, OperationType.BOOTSTRAP);
             }
         }
 
@@ -197,17 +198,17 @@ public class BootStrapper
     }
 
     /** get potential sources for each range, ordered by proximity (as determined by EndpointSnitch) */
-    Multimap<Range, InetAddress> getRangesWithSources(String table)
+    Multimap<Range<Token>, InetAddress> getRangesWithSources(String table)
     {
         assert tokenMetadata.sortedTokens().size() > 0;
         final AbstractReplicationStrategy strat = Table.open(table).getReplicationStrategy();
-        Collection<Range> myRanges = strat.getPendingAddressRanges(tokenMetadata, token, address);
+        Collection<Range<Token>> myRanges = strat.getPendingAddressRanges(tokenMetadata, token, address);
 
-        Multimap<Range, InetAddress> myRangeAddresses = ArrayListMultimap.create();
-        Multimap<Range, InetAddress> rangeAddresses = strat.getRangeAddresses(tokenMetadata);
-        for (Range myRange : myRanges)
+        Multimap<Range<Token>, InetAddress> myRangeAddresses = ArrayListMultimap.create();
+        Multimap<Range<Token>, InetAddress> rangeAddresses = strat.getRangeAddresses(tokenMetadata);
+        for (Range<Token> myRange : myRanges)
         {
-            for (Range range : rangeAddresses.keySet())
+            for (Range<Token> range : rangeAddresses.keySet())
             {
                 if (range.contains(myRange))
                 {
@@ -243,21 +244,21 @@ public class BootStrapper
         throw new RuntimeException("Bootstrap failed, could not obtain token from: " + maxEndpoint);
     }
 
-    public static Multimap<InetAddress, Range> getWorkMap(Multimap<Range, InetAddress> rangesWithSourceTarget)
+    public static Multimap<InetAddress, Range<Token>> getWorkMap(Multimap<Range<Token>, InetAddress> rangesWithSourceTarget)
     {
         return getWorkMap(rangesWithSourceTarget, FailureDetector.instance);
     }
 
-    static Multimap<InetAddress, Range> getWorkMap(Multimap<Range, InetAddress> rangesWithSourceTarget, IFailureDetector failureDetector)
+    static Multimap<InetAddress, Range<Token>> getWorkMap(Multimap<Range<Token>, InetAddress> rangesWithSourceTarget, IFailureDetector failureDetector)
     {
         /*
          * Map whose key is the source node and the value is a map whose key is the
          * target and value is the list of ranges to be sent to it.
         */
-        Multimap<InetAddress, Range> sources = ArrayListMultimap.create();
+        Multimap<InetAddress, Range<Token>> sources = ArrayListMultimap.create();
 
         // TODO look for contiguous ranges and map them to the same source
-        for (Range range : rangesWithSourceTarget.keySet())
+        for (Range<Token> range : rangesWithSourceTarget.keySet())
         {
             for (InetAddress source : rangesWithSourceTarget.get(range))
             {
diff --git a/src/java/org/apache/cassandra/dht/Bounds.java b/src/java/org/apache/cassandra/dht/Bounds.java
index 21e6619458..f2cbeffd7e 100644
--- a/src/java/org/apache/cassandra/dht/Bounds.java
+++ b/src/java/org/apache/cassandra/dht/Bounds.java
@@ -24,48 +24,69 @@ package org.apache.cassandra.dht;
 import java.util.Collections;
 import java.util.List;
 
+import org.apache.cassandra.db.RowPosition;
 import org.apache.cassandra.service.StorageService;
 
-public class Bounds extends AbstractBounds
+public class Bounds<T extends RingPosition> extends AbstractBounds<T>
 {
-    public Bounds(Token left, Token right)
+    public Bounds(T left, T right)
     {
         this(left, right, StorageService.getPartitioner());
     }
 
-    Bounds(Token left, Token right, IPartitioner partitioner)
+    Bounds(T left, T right, IPartitioner partitioner)
     {
         super(left, right, partitioner);
         // unlike a Range, a Bounds may not wrap
-        assert left.compareTo(right) <= 0 || right.equals(partitioner.getMinimumToken()) : "[" + left + "," + right + "]";
+        assert left.compareTo(right) <= 0 || right.isMinimum(partitioner) : "[" + left + "," + right + "]";
     }
 
-    public boolean contains(Token token)
+    public boolean contains(T position)
     {
-        return Range.contains(left, right, token) || left.equals(token);
+        return Range.contains(left, right, position) || left.equals(position);
     }
 
-    public AbstractBounds createFrom(Token token)
+    public AbstractBounds<T> createFrom(T position)
     {
-        return new Bounds(left, token, partitioner);
+        return new Bounds<T>(left, position, partitioner);
     }
 
-    public List<AbstractBounds> unwrap()
+    public List<? extends AbstractBounds<T>> unwrap()
     {
         // Bounds objects never wrap
-        return Collections.<AbstractBounds>singletonList(this);
+        return Collections.<AbstractBounds<T>>singletonList(this);
     }
 
+    @Override
     public boolean equals(Object o)
     {
         if (!(o instanceof Bounds))
             return false;
-        Bounds rhs = (Bounds)o;
+        Bounds<T> rhs = (Bounds<T>)o;
         return left.equals(rhs.left) && right.equals(rhs.right);
     }
 
+    @Override
     public String toString()
     {
         return "[" + left + "," + right + "]";
     }
+
+    /**
+     * Compute a bounds of keys corresponding to a given bounds of token.
+     */
+    public static Bounds<RowPosition> makeRowBounds(Token left, Token right, IPartitioner partitioner)
+    {
+        return new Bounds<RowPosition>(left.minKeyBound(partitioner), right.maxKeyBound(partitioner), partitioner);
+    }
+
+    public AbstractBounds<RowPosition> toRowBounds()
+    {
+        return (left instanceof Token) ? makeRowBounds((Token)left, (Token)right, partitioner) : (Bounds<RowPosition>)this;
+    }
+
+    public AbstractBounds<Token> toTokenBounds()
+    {
+        return (left instanceof RowPosition) ? new Bounds<Token>(((RowPosition)left).getToken(), ((RowPosition)right).getToken(), partitioner) : (Bounds<Token>)this;
+    }
 }
diff --git a/src/java/org/apache/cassandra/dht/IPartitioner.java b/src/java/org/apache/cassandra/dht/IPartitioner.java
index fdf94fc984..aaa75fa0d0 100644
--- a/src/java/org/apache/cassandra/dht/IPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/IPartitioner.java
@@ -84,4 +84,6 @@ public interface IPartitioner<T extends Token>
      * @return the mapping from 'token' to 'percentage of the ring owned by that token'.
      */
     public Map<Token, Float> describeOwnership(List<Token> sortedTokens);
+
+    public <T extends RingPosition> T minValue(Class<T> klass);
 }
diff --git a/src/java/org/apache/cassandra/dht/LocalPartitioner.java b/src/java/org/apache/cassandra/dht/LocalPartitioner.java
index f03d4e41a4..dfc05e3d22 100644
--- a/src/java/org/apache/cassandra/dht/LocalPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/LocalPartitioner.java
@@ -28,7 +28,7 @@ import org.apache.cassandra.db.DecoratedKey;
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
-public class LocalPartitioner implements IPartitioner<LocalToken>
+public class LocalPartitioner extends AbstractPartitioner<LocalToken>
 {
     private final AbstractType comparator;
 
diff --git a/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java b/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java
index 5f6b0f19bc..6c781f03cb 100644
--- a/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java
@@ -31,7 +31,7 @@ import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.Pair;
 
-public class OrderPreservingPartitioner implements IPartitioner<StringToken>
+public class OrderPreservingPartitioner extends AbstractPartitioner<StringToken>
 {
     public static final StringToken MINIMUM = new StringToken("");
 
@@ -176,14 +176,14 @@ public class OrderPreservingPartitioner implements IPartitioner<StringToken>
     {
         // allTokens will contain the count and be returned, sorted_ranges is shorthand for token<->token math.
         Map<Token, Float> allTokens = new HashMap<Token, Float>();
-        List<Range> sortedRanges = new ArrayList<Range>();
+        List<Range<Token>> sortedRanges = new ArrayList<Range<Token>>();
 
         // this initializes the counts to 0 and calcs the ranges in order.
         Token lastToken = sortedTokens.get(sortedTokens.size() - 1);
         for (Token node : sortedTokens)
         {
             allTokens.put(node, new Float(0.0));
-            sortedRanges.add(new Range(lastToken, node));
+            sortedRanges.add(new Range<Token>(lastToken, node));
             lastToken = node;
         }
 
@@ -191,7 +191,7 @@ public class OrderPreservingPartitioner implements IPartitioner<StringToken>
         {
             for (CFMetaData cfmd : Schema.instance.getKSMetaData(ks).cfMetaData().values())
             {
-                for (Range r : sortedRanges)
+                for (Range<Token> r : sortedRanges)
                 {
                     // Looping over every KS:CF:Range, get the splits size and add it to the count
                     allTokens.put(r.right, allTokens.get(r.right) + StorageService.instance.getSplits(ks, cfmd.cfName, r, DatabaseDescriptor.getIndexInterval()).size());
diff --git a/src/java/org/apache/cassandra/dht/RandomPartitioner.java b/src/java/org/apache/cassandra/dht/RandomPartitioner.java
index cca885890b..c4c9091f34 100644
--- a/src/java/org/apache/cassandra/dht/RandomPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/RandomPartitioner.java
@@ -34,7 +34,7 @@ import org.apache.cassandra.utils.Pair;
 /**
  * This class generates a BigIntegerToken using MD5 hash.
  */
-public class RandomPartitioner implements IPartitioner<BigIntegerToken>
+public class RandomPartitioner extends AbstractPartitioner<BigIntegerToken>
 {
     public static final BigInteger ZERO = new BigInteger("0");
     public static final BigIntegerToken MINIMUM = new BigIntegerToken("-1");
diff --git a/src/java/org/apache/cassandra/dht/Range.java b/src/java/org/apache/cassandra/dht/Range.java
index 071c44d1a4..e9675f44dd 100644
--- a/src/java/org/apache/cassandra/dht/Range.java
+++ b/src/java/org/apache/cassandra/dht/Range.java
@@ -25,6 +25,7 @@ import java.util.*;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.commons.lang.ObjectUtils;
 
+import org.apache.cassandra.db.RowPosition;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.FBUtilities;
 
@@ -33,21 +34,21 @@ import org.apache.cassandra.utils.FBUtilities;
  *
  * A Range is responsible for the tokens between (left, right].
  */
-public class Range extends AbstractBounds implements Comparable<Range>, Serializable
+public class Range<T extends RingPosition> extends AbstractBounds<T> implements Comparable<Range<T>>, Serializable
 {
     public static final long serialVersionUID = 1L;
     
-    public Range(Token left, Token right)
+    public Range(T left, T right)
     {
         this(left, right, StorageService.getPartitioner());
     }
 
-    public Range(Token left, Token right, IPartitioner partitioner)
+    public Range(T left, T right, IPartitioner partitioner)
     {
         super(left, right, partitioner);
     }
 
-    public static boolean contains(Token left, Token right, Token bi)
+    public static <T extends RingPosition> boolean contains(T left, T right, T bi)
     {
         if (isWrapAround(left, right))
         {
@@ -68,11 +69,11 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
             /*
              * This is the range (a, b] where a < b. 
              */
-            return ( compare(bi,left) > 0 && compare(right,bi) >= 0);
+            return bi.compareTo(left) > 0 && right.compareTo(bi) >= 0;
         }
     }
 
-    public boolean contains(Range that)
+    public boolean contains(Range<T> that)
     {
         if (this.left.equals(this.right))
         {
@@ -84,13 +85,13 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
         boolean thatwraps = isWrapAround(that.left, that.right);
         if (thiswraps == thatwraps)
         {
-            return compare(left,that.left) <= 0 && compare(that.right,right) <= 0;
+            return left.compareTo(that.left) <= 0 && that.right.compareTo(right) <= 0;
         }
         else if (thiswraps)
         {
             // wrapping might contain non-wrapping
             // that is contained if both its tokens are in one of our wrap segments
-            return compare(left,that.left) <= 0 || compare(that.right,right) <= 0;
+            return left.compareTo(that.left) <= 0 || that.right.compareTo(right) <= 0;
         }
         else
         {
@@ -106,7 +107,7 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
      * @param bi point in question
      * @return true if the point contains within the range else false.
      */
-    public boolean contains(Token bi)
+    public boolean contains(T bi)
     {
         return contains(left, right, bi);
     }
@@ -115,14 +116,19 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
      * @param that range to check for intersection
      * @return true if the given range intersects with this range.
      */
-    public boolean intersects(Range that)
+    public boolean intersects(Range<T> that)
     {
         return intersectionWith(that).size() > 0;
     }
 
-    public static Set<Range> rangeSet(Range ... ranges)
+    public static <T extends RingPosition> Set<Range<T>> rangeSet(Range<T> ... ranges)
     {
-        return Collections.unmodifiableSet(new HashSet<Range>(Arrays.asList(ranges)));
+        return Collections.unmodifiableSet(new HashSet<Range<T>>(Arrays.asList(ranges)));
+    }
+
+    public static <T extends RingPosition> Set<Range<T>> rangeSet(Range<T> range)
+    {
+        return Collections.singleton(range);
     }
 
     /**
@@ -131,7 +137,7 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
      * say you have nodes G and M, with query range (D,T]; the intersection is (M-T] and (D-G].
      * If there is no intersection, an empty list is returned.
      */
-    public Set<Range> intersectionWith(Range that)
+    public Set<Range<T>> intersectionWith(Range<T> that)
     {
         if (that.contains(this))
             return rangeSet(this);
@@ -145,9 +151,9 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
             // neither wraps.  the straightforward case.
             if (!(left.compareTo(that.right) < 0 && that.left.compareTo(right) < 0))
                 return Collections.emptySet();
-            return rangeSet(new Range((Token)ObjectUtils.max(this.left, that.left),
-                                      (Token)ObjectUtils.min(this.right, that.right),
-                                      partitioner));
+            return rangeSet(new Range<T>((T)ObjectUtils.max(this.left, that.left),
+                                         (T)ObjectUtils.min(this.right, that.right),
+                                         partitioner));
         }
         if (thiswraps && thatwraps)
         {
@@ -171,82 +177,53 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
         return intersectionOneWrapping(that, this);
     }
 
-    private static Set<Range> intersectionBothWrapping(Range first, Range that)
+    private static <T extends RingPosition> Set<Range<T>> intersectionBothWrapping(Range<T> first, Range<T> that)
     {
-        Set<Range> intersection = new HashSet<Range>(2);
+        Set<Range<T>> intersection = new HashSet<Range<T>>(2);
         if (that.right.compareTo(first.left) > 0)
-            intersection.add(new Range(first.left, that.right, first.partitioner));
-        intersection.add(new Range(that.left, first.right, first.partitioner));
+            intersection.add(new Range<T>(first.left, that.right, first.partitioner));
+        intersection.add(new Range<T>(that.left, first.right, first.partitioner));
         return Collections.unmodifiableSet(intersection);
     }
 
-    private static Set<Range> intersectionOneWrapping(Range wrapping, Range other)
+    private static <T extends RingPosition> Set<Range<T>> intersectionOneWrapping(Range<T> wrapping, Range<T> other)
     {
-        Set<Range> intersection = new HashSet<Range>(2);
+        Set<Range<T>> intersection = new HashSet<Range<T>>(2);
         if (other.contains(wrapping.right))
-            intersection.add(new Range(other.left, wrapping.right, wrapping.partitioner));
+            intersection.add(new Range<T>(other.left, wrapping.right, wrapping.partitioner));
         // need the extra compareto here because ranges are asymmetrical; wrapping.left _is not_ contained by the wrapping range
         if (other.contains(wrapping.left) && wrapping.left.compareTo(other.right) < 0)
-            intersection.add(new Range(wrapping.left, other.right, wrapping.partitioner));
+            intersection.add(new Range<T>(wrapping.left, other.right, wrapping.partitioner));
         return Collections.unmodifiableSet(intersection);
     }
 
-    public AbstractBounds createFrom(Token token)
+    public AbstractBounds<T> createFrom(T pos)
     {
-        if (token.equals(left))
+        if (pos.equals(left))
             return null;
-        return new Range(left, token, partitioner);
+        return new Range<T>(left, pos, partitioner);
     }
 
-    public List<AbstractBounds> unwrap()
+    public List<? extends AbstractBounds<T>> unwrap()
     {
-        if (!isWrapAround() || right.equals(partitioner.getMinimumToken()))
-            return (List)Arrays.asList(this);
-        List<AbstractBounds> unwrapped = new ArrayList<AbstractBounds>(2);
-        unwrapped.add(new Range(left, partitioner.getMinimumToken(), partitioner));
-        unwrapped.add(new Range(partitioner.getMinimumToken(), right, partitioner));
+        T minValue = (T) partitioner.minValue(right.getClass());
+        if (!isWrapAround() || right.equals(minValue))
+            return Arrays.asList(this);
+        List<AbstractBounds<T>> unwrapped = new ArrayList<AbstractBounds<T>>(2);
+        unwrapped.add(new Range<T>(left, minValue, partitioner));
+        unwrapped.add(new Range<T>(minValue, right, partitioner));
         return unwrapped;
     }
 
     /**
      * Tells if the given range is a wrap around.
      */
-    public static boolean isWrapAround(Token left, Token right)
+    public static <T extends RingPosition> boolean isWrapAround(T left, T right)
     {
-       return compare(left,right) >= 0;           
+       return left.compareTo(right) >= 0;
     }
-    
-    public static int compare(Token left, Token right)
-    {
-        ByteBuffer l,r;
 
-        if (left.token instanceof byte[])
-        {
-            l  = ByteBuffer.wrap((byte[]) left.token);
-        }
-        else if (left.token instanceof ByteBuffer)
-        {
-            l  = (ByteBuffer) left.token;
-        }
-        else
-        {
-            //Handles other token types
-            return left.compareTo(right);
-        }
-
-        if (right.token instanceof byte[])
-        {
-            r  = ByteBuffer.wrap((byte[]) right.token);
-        }
-        else
-        {
-            r  = (ByteBuffer) right.token;
-        }
-
-        return ByteBufferUtil.compareUnsigned(l, r);
-     }
-    
-    public int compareTo(Range rhs)
+    public int compareTo(Range<T> rhs)
     {
         /* 
          * If the range represented by the "this" pointer
@@ -258,7 +235,7 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
         if ( isWrapAround(rhs.left, rhs.right) )
             return 1;
         
-        return compare(right,rhs.right);
+        return right.compareTo(rhs.right);
     }
 
     /**
@@ -268,14 +245,14 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
      * @return An ArrayList of the Ranges left after subtracting contained
      * from this.
      */
-    private ArrayList<Range> subtractContained(Range contained)
+    private ArrayList<Range<T>> subtractContained(Range<T> contained)
     {
-        ArrayList<Range> difference = new ArrayList<Range>();
+        ArrayList<Range<T>> difference = new ArrayList<Range<T>>();
 
         if (!left.equals(contained.left))
-            difference.add(new Range(left, contained.left, partitioner));
+            difference.add(new Range<T>(left, contained.left, partitioner));
         if (!right.equals(contained.right))
-            difference.add(new Range(contained.right, right, partitioner));
+            difference.add(new Range<T>(contained.right, right, partitioner));
         return difference;
     }
 
@@ -287,13 +264,13 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
      * @param rhs range to calculate difference
      * @return set of difference ranges
      */
-    public Set<Range> differenceToFetch(Range rhs)
+    public Set<Range<T>> differenceToFetch(Range<T> rhs)
     {
-        Set<Range> result;
-        Set<Range> intersectionSet = this.intersectionWith(rhs);
+        Set<Range<T>> result;
+        Set<Range<T>> intersectionSet = this.intersectionWith(rhs);
         if (intersectionSet.isEmpty())
         {
-            result = new HashSet<Range>();
+            result = new HashSet<Range<T>>();
             result.add(rhs);
         }
         else
@@ -302,29 +279,29 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
             intersectionSet.toArray(intersections);
             if (intersections.length == 1)
             {
-                result = new HashSet<Range>(rhs.subtractContained(intersections[0]));
+                result = new HashSet<Range<T>>(rhs.subtractContained(intersections[0]));
             }
             else
             {
                 // intersections.length must be 2
-                Range first = intersections[0];
-                Range second = intersections[1];
-                ArrayList<Range> temp = rhs.subtractContained(first);
+                Range<T> first = intersections[0];
+                Range<T> second = intersections[1];
+                ArrayList<Range<T>> temp = rhs.subtractContained(first);
 
                 // Because there are two intersections, subtracting only one of them
                 // will yield a single Range.
-                Range single = temp.get(0);
-                result = new HashSet<Range>(single.subtractContained(second));
+                Range<T> single = temp.get(0);
+                result = new HashSet<Range<T>>(single.subtractContained(second));
             }
         }
         return result;
     }
 
-    public static boolean isTokenInRanges(Token token, Iterable<Range> ranges)
+    public static <T extends RingPosition> boolean isInRanges(T token, Iterable<Range<T>> ranges)
     {
         assert ranges != null;
 
-        for (Range range : ranges)
+        for (Range<T> range : ranges)
         {
             if (range.contains(token))
             {
@@ -334,14 +311,16 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
         return false;
     }
 
+    @Override
     public boolean equals(Object o)
     {
         if (!(o instanceof Range))
             return false;
-        Range rhs = (Range)o;
-        return compare(left,rhs.left) == 0 && compare(right,rhs.right) == 0;
+        Range<T> rhs = (Range<T>)o;
+        return left.equals(rhs.left) && right.equals(rhs.right);
     }
-    
+
+    @Override
     public String toString()
     {
         return "(" + left + "," + right + "]";
@@ -351,4 +330,22 @@ public class Range extends AbstractBounds implements Comparable<Range>, Serializ
     {
         return isWrapAround(left, right);
     }
+
+    /**
+     * Compute a range of keys corresponding to a given range of token.
+     */
+    public static Range<RowPosition> makeRowRange(Token left, Token right, IPartitioner partitioner)
+    {
+        return new Range<RowPosition>(left.maxKeyBound(partitioner), right.maxKeyBound(partitioner), partitioner);
+    }
+
+    public AbstractBounds<RowPosition> toRowBounds()
+    {
+        return (left instanceof Token) ? makeRowRange((Token)left, (Token)right, partitioner) : (Range<RowPosition>)this;
+    }
+
+    public AbstractBounds<Token> toTokenBounds()
+    {
+        return (left instanceof RowPosition) ? new Range<Token>(((RowPosition)left).getToken(), ((RowPosition)right).getToken(), partitioner) : (Range<Token>)this;
+    }
 }
diff --git a/src/java/org/apache/cassandra/dht/RingPosition.java b/src/java/org/apache/cassandra/dht/RingPosition.java
new file mode 100644
index 0000000000..1617e4fadd
--- /dev/null
+++ b/src/java/org/apache/cassandra/dht/RingPosition.java
@@ -0,0 +1,39 @@
+/*
+* Licensed to the Apache Software Foundation (ASF) under one
+* or more contributor license agreements.  See the NOTICE file
+* distributed with this work for additional information
+* regarding copyright ownership.  The ASF licenses this file
+* to you under the Apache License, Version 2.0 (the
+* "License"); you may not use this file except in compliance
+* with the License.  You may obtain a copy of the License at
+*
+*    http://www.apache.org/licenses/LICENSE-2.0
+*
+* Unless required by applicable law or agreed to in writing,
+* software distributed under the License is distributed on an
+* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+* KIND, either express or implied.  See the License for the
+* specific language governing permissions and limitations
+* under the License.
+*/
+package org.apache.cassandra.dht;
+
+import java.io.DataInput;
+import java.io.DataOutput;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+
+import org.apache.cassandra.db.DecoratedKey;
+import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.utils.ByteBufferUtil;
+
+/**
+ * Interface representing a position on the ring.
+ * Both Token and DecoratedKey represent a position in the ring, a token being
+ * less precise than a DecoratedKey (a token is really a range of keys).
+ */
+public interface RingPosition<T> extends Comparable<T>
+{
+    public Token getToken();
+    public boolean isMinimum(IPartitioner partitioner);
+}
diff --git a/src/java/org/apache/cassandra/dht/Token.java b/src/java/org/apache/cassandra/dht/Token.java
index 236318cecb..dcbea16833 100644
--- a/src/java/org/apache/cassandra/dht/Token.java
+++ b/src/java/org/apache/cassandra/dht/Token.java
@@ -25,11 +25,12 @@ import java.io.Serializable;
 import java.nio.ByteBuffer;
 
 import org.apache.cassandra.config.ConfigurationException;
+import org.apache.cassandra.db.RowPosition;
 import org.apache.cassandra.io.ISerializer;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
-public abstract class Token<T> implements Comparable<Token<T>>, Serializable
+public abstract class Token<T> implements RingPosition<Token<T>>, Serializable
 {
     private static final long serialVersionUID = 1L;
 
@@ -41,6 +42,9 @@ public abstract class Token<T> implements Comparable<Token<T>>, Serializable
 
     public final T token;
 
+    private final transient KeyBound minimumBound = new KeyBound(true);
+    private final transient KeyBound maximumBound = new KeyBound(false);
+
     protected Token(T token)
     {
         this.token = token;
@@ -51,19 +55,24 @@ public abstract class Token<T> implements Comparable<Token<T>>, Serializable
      */
     abstract public int compareTo(Token<T> o);
 
+    @Override
     public String toString()
     {
         return token.toString();
     }
 
+    @Override
     public boolean equals(Object obj)
     {
-        if (!(obj instanceof Token)) {
+        if (this == obj)
+            return true;
+        if (obj == null || this.getClass() != obj.getClass())
             return false;
-        }
-        return token.equals(((Token)obj).token);
+
+        return token.equals(((Token<T>)obj).token);
     }
 
+    @Override
     public int hashCode()
     {
         return token.hashCode();
@@ -102,4 +111,132 @@ public abstract class Token<T> implements Comparable<Token<T>>, Serializable
             throw new UnsupportedOperationException();
         }
     }
+
+    public Token<T> getToken()
+    {
+        return this;
+    }
+
+    public boolean isMinimum(IPartitioner partitioner)
+    {
+        return this.equals(partitioner.getMinimumToken());
+    }
+
+    public boolean isMinimum()
+    {
+        return isMinimum(StorageService.getPartitioner());
+    }
+
+    /*
+     * A token corresponds to the range of all the keys having this token.
+     * A token is thus no comparable directly to a key. But to be able to select
+     * keys given tokens, we introduce two "fake" keys for each token T:
+     *   - lowerBoundKey: a "fake" key representing the lower bound T represents.
+     *                    In other words, lowerBoundKey is the smallest key that
+     *                    have token T.
+     *   - upperBoundKey: a "fake" key representing the upper bound T represents.
+     *                    In other words, upperBoundKey is the largest key that
+     *                    have token T.
+     *
+     * Note that those are "fake" keys and should only be used for comparison
+     * of other keys, for selection of keys when only a token is known.
+     */
+    public KeyBound minKeyBound(IPartitioner partitioner)
+    {
+        return minimumBound;
+    }
+
+    public KeyBound minKeyBound()
+    {
+        return minKeyBound(null);
+    }
+
+    public KeyBound maxKeyBound(IPartitioner partitioner)
+    {
+        /*
+         * For each token, we needs both minKeyBound and maxKeyBound
+         * because a token corresponds to a range of keys. But the minimun
+         * token corresponds to no key, so it is valid and actually much
+         * simpler to associate the same value for minKeyBound and
+         * maxKeyBound for the minimun token.
+         */
+        if (isMinimum(partitioner))
+            return minimumBound;
+        return maximumBound;
+    }
+
+    public KeyBound maxKeyBound()
+    {
+        return maxKeyBound(StorageService.getPartitioner());
+    }
+
+    public <T extends RingPosition> T asSplitValue(Class<T> klass)
+    {
+        if (klass.equals(getClass()))
+            return (T)this;
+        else
+            return (T)maxKeyBound();
+    }
+
+    public class KeyBound extends RowPosition
+    {
+        public final boolean isMinimumBound;
+
+        private KeyBound(boolean isMinimumBound)
+        {
+            this.isMinimumBound = isMinimumBound;
+        }
+
+        public Token getToken()
+        {
+            return Token.this;
+        }
+
+        public int compareTo(RowPosition pos)
+        {
+            if (this == pos)
+                return 0;
+
+            int cmp = getToken().compareTo(pos.getToken());
+            if (cmp != 0)
+                return cmp;
+
+            // We've already eliminated the == case
+            return isMinimumBound ? -1 : 1;
+        }
+
+        public boolean isMinimum(IPartitioner partitioner)
+        {
+            return getToken().isMinimum(partitioner);
+        }
+
+        public RowPosition.Kind kind()
+        {
+            return isMinimumBound ? RowPosition.Kind.MIN_BOUND : RowPosition.Kind.MAX_BOUND;
+        }
+
+        @Override
+        public boolean equals(Object obj)
+        {
+            if (this == obj)
+                return true;
+            if (obj == null || this.getClass() != obj.getClass())
+                return false;
+
+            KeyBound other = (KeyBound)obj;
+            return getToken().equals(other.getToken());
+        }
+
+        @Override
+        public int hashCode()
+        {
+            return getToken().hashCode() + (isMinimumBound ? 0 : 1);
+        }
+
+        @Override
+        public String toString()
+        {
+            return String.format("%s(%s)", isMinimumBound ? "min" : "max", getToken().toString());
+        }
+    }
 }
diff --git a/src/java/org/apache/cassandra/hadoop/ColumnFamilyInputFormat.java b/src/java/org/apache/cassandra/hadoop/ColumnFamilyInputFormat.java
index d89f285001..4b42d563fc 100644
--- a/src/java/org/apache/cassandra/hadoop/ColumnFamilyInputFormat.java
+++ b/src/java/org/apache/cassandra/hadoop/ColumnFamilyInputFormat.java
@@ -38,6 +38,7 @@ import java.util.concurrent.Future;
 import org.apache.cassandra.db.IColumn;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.thrift.Cassandra;
 import org.apache.cassandra.thrift.InvalidRequestException;
 import org.apache.cassandra.thrift.KeyRange;
@@ -110,16 +111,16 @@ public class ColumnFamilyInputFormat extends InputFormat<ByteBuffer, SortedMap<B
             List<Future<List<InputSplit>>> splitfutures = new ArrayList<Future<List<InputSplit>>>();
             KeyRange jobKeyRange = ConfigHelper.getInputKeyRange(conf);
             IPartitioner partitioner = null;
-            Range jobRange = null;
+            Range<Token> jobRange = null;
             if (jobKeyRange != null)
             {
                 partitioner = ConfigHelper.getPartitioner(context.getConfiguration());
                 assert partitioner.preservesOrder() : "ConfigHelper.setInputKeyRange(..) can only be used with a order preserving paritioner";
                 assert jobKeyRange.start_key == null : "only start_token supported";
                 assert jobKeyRange.end_key == null : "only end_token supported";
-                jobRange = new Range(partitioner.getTokenFactory().fromString(jobKeyRange.start_token),
-                                     partitioner.getTokenFactory().fromString(jobKeyRange.end_token),
-                                     partitioner);
+                jobRange = new Range<Token>(partitioner.getTokenFactory().fromString(jobKeyRange.start_token),
+                                            partitioner.getTokenFactory().fromString(jobKeyRange.end_token),
+                                            partitioner);
             }
 
             for (TokenRange range : masterRangeNodes)
@@ -131,13 +132,13 @@ public class ColumnFamilyInputFormat extends InputFormat<ByteBuffer, SortedMap<B
                 }
                 else
                 {
-                    Range dhtRange = new Range(partitioner.getTokenFactory().fromString(range.start_token),
-                                               partitioner.getTokenFactory().fromString(range.end_token),
-                                               partitioner);
+                    Range<Token> dhtRange = new Range<Token>(partitioner.getTokenFactory().fromString(range.start_token),
+                                                             partitioner.getTokenFactory().fromString(range.end_token),
+                                                             partitioner);
 
                     if (dhtRange.intersects(jobRange))
                     {
-                        for (Range intersection: dhtRange.intersectionWith(jobRange))
+                        for (Range<Token> intersection: dhtRange.intersectionWith(jobRange))
                         {
                             range.start_token = partitioner.getTokenFactory().toString(intersection.left);
                             range.end_token = partitioner.getTokenFactory().toString(intersection.right);
diff --git a/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java b/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java
index f50eb1831f..328a0f7ac5 100644
--- a/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java
+++ b/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java
@@ -31,6 +31,7 @@ import java.util.concurrent.TimeUnit;
 
 import org.apache.cassandra.client.RingCache;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.thrift.*;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.Pair;
@@ -119,7 +120,7 @@ implements org.apache.hadoop.mapred.RecordWriter<ByteBuffer,List<Mutation>>
     @Override
     public void write(ByteBuffer keybuff, List<Mutation> value) throws IOException
     {
-        Range range = ringCache.getRange(keybuff);
+        Range<Token> range = ringCache.getRange(keybuff);
 
         // get the client for the given range, or create a new one
         RangeClient client = clients.get(range);
diff --git a/src/java/org/apache/cassandra/io/sstable/IndexSummary.java b/src/java/org/apache/cassandra/io/sstable/IndexSummary.java
index c5bacdb8a7..68530cf162 100644
--- a/src/java/org/apache/cassandra/io/sstable/IndexSummary.java
+++ b/src/java/org/apache/cassandra/io/sstable/IndexSummary.java
@@ -26,6 +26,7 @@ import java.util.List;
 
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.DecoratedKey;
+import org.apache.cassandra.db.RowPosition;
 
 /**
  * Two approaches to building an IndexSummary:
@@ -86,10 +87,12 @@ public class IndexSummary
      */
     public static final class KeyPosition implements Comparable<KeyPosition>
     {
-        public final DecoratedKey<?> key;
+        // We allow RowPosition for the purpose of being able to select keys given a token, but the index
+        // should only contain true user provided keys, i.e. DecoratedKey, which is enforced by addEntry.
+        public final RowPosition key;
         public final long indexPosition;
 
-        public KeyPosition(DecoratedKey<?> key, long indexPosition)
+        public KeyPosition(RowPosition key, long indexPosition)
         {
             this.key = key;
             this.indexPosition = indexPosition;
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableBoundedScanner.java b/src/java/org/apache/cassandra/io/sstable/SSTableBoundedScanner.java
index 2a982fe5a5..262394df49 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableBoundedScanner.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableBoundedScanner.java
@@ -25,6 +25,7 @@ import java.util.Iterator;
 
 import org.apache.cassandra.db.columniterator.IColumnIterator;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.utils.Pair;
 
 /**
@@ -35,7 +36,7 @@ public class SSTableBoundedScanner extends SSTableScanner
     private final Iterator<Pair<Long, Long>> rangeIterator;
     private Pair<Long, Long> currentRange;
 
-    SSTableBoundedScanner(SSTableReader sstable, boolean skipCache, Range range)
+    SSTableBoundedScanner(SSTableReader sstable, boolean skipCache, Range<Token> range)
     {
         super(sstable, skipCache);
         this.rangeIterator = sstable.getPositionsForRanges(Collections.singletonList(range)).iterator();
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableLoader.java b/src/java/org/apache/cassandra/io/sstable/SSTableLoader.java
index ee85bc9b8d..9c7a9a3f74 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableLoader.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableLoader.java
@@ -30,6 +30,7 @@ import java.util.concurrent.TimeUnit;
 import org.apache.cassandra.config.ConfigurationException;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.streaming.*;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.Pair;
@@ -114,12 +115,12 @@ public class SSTableLoader
             return new LoaderFuture(0);
         }
 
-        Map<InetAddress, Collection<Range>> endpointToRanges = client.getEndpointToRangesMap();
+        Map<InetAddress, Collection<Range<Token>>> endpointToRanges = client.getEndpointToRangesMap();
         outputHandler.output(String.format("Streaming revelant part of %sto %s", names(sstables), endpointToRanges.keySet()));
 
         // There will be one streaming session by endpoint
         LoaderFuture future = new LoaderFuture(endpointToRanges.size());
-        for (Map.Entry<InetAddress, Collection<Range>> entry : endpointToRanges.entrySet())
+        for (Map.Entry<InetAddress, Collection<Range<Token>>> entry : endpointToRanges.entrySet())
         {
             InetAddress remote = entry.getKey();
             if (toIgnore.contains(remote))
@@ -127,7 +128,7 @@ public class SSTableLoader
                 future.latch.countDown();
                 continue;
             }
-            Collection<Range> ranges = entry.getValue();
+            Collection<Range<Token>> ranges = entry.getValue();
             StreamOutSession session = StreamOutSession.create(keyspace, remote, new CountDownCallback(future.latch, remote));
             // transferSSTables assumes references have been acquired
             SSTableReader.acquireReferences(sstables);
@@ -228,7 +229,7 @@ public class SSTableLoader
 
     public static abstract class Client
     {
-        private final Map<InetAddress, Collection<Range>> endpointToRanges = new HashMap<InetAddress, Collection<Range>>();
+        private final Map<InetAddress, Collection<Range<Token>>> endpointToRanges = new HashMap<InetAddress, Collection<Range<Token>>>();
         private IPartitioner partitioner;
 
         /**
@@ -253,7 +254,7 @@ public class SSTableLoader
          */
         public abstract boolean validateColumnFamily(String keyspace, String cfName);
 
-        public Map<InetAddress, Collection<Range>> getEndpointToRangesMap()
+        public Map<InetAddress, Collection<Range<Token>>> getEndpointToRangesMap()
         {
             return endpointToRanges;
         }
@@ -268,12 +269,12 @@ public class SSTableLoader
             return partitioner;
         }
 
-        protected void addRangeForEndpoint(Range range, InetAddress endpoint)
+        protected void addRangeForEndpoint(Range<Token> range, InetAddress endpoint)
         {
-            Collection<Range> ranges = endpointToRanges.get(endpoint);
+            Collection<Range<Token>> ranges = endpointToRanges.get(endpoint);
             if (ranges == null)
             {
-                ranges = new HashSet<Range>();
+                ranges = new HashSet<Range<Token>>();
                 endpointToRanges.put(endpoint, ranges);
             }
             ranges.add(range);
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableReader.java b/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
index 9acf84bda6..fd6f044444 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
@@ -44,6 +44,7 @@ import org.apache.cassandra.db.filter.QueryFilter;
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.compress.CompressionMetadata;
 import org.apache.cassandra.io.util.*;
 import org.apache.cassandra.service.StorageService;
@@ -387,10 +388,10 @@ public class SSTableReader extends SSTable
     }
 
     /** get the position in the index file to start scanning to find the given key (at most indexInterval keys away) */
-    private IndexSummary.KeyPosition getIndexScanPosition(DecoratedKey decoratedKey)
+    private IndexSummary.KeyPosition getIndexScanPosition(RowPosition key)
     {
         assert indexSummary.getIndexPositions() != null && indexSummary.getIndexPositions().size() > 0;
-        int index = Collections.binarySearch(indexSummary.getIndexPositions(), new IndexSummary.KeyPosition(decoratedKey, -1));
+        int index = Collections.binarySearch(indexSummary.getIndexPositions(), new IndexSummary.KeyPosition(key, -1));
         if (index < 0)
         {
             // binary search gives us the first index _greater_ than the key searched for,
@@ -451,7 +452,7 @@ public class SSTableReader extends SSTable
      * @param ranges
      * @return An estimate of the number of keys for given ranges in this SSTable.
      */
-    public long estimatedKeysForRanges(Collection<Range> ranges)
+    public long estimatedKeysForRanges(Collection<Range<Token>> ranges)
     {
         long sampleKeyCount = 0;
         List<Pair<Integer, Integer>> sampleIndexes = getSampleIndexesForRanges(indexSummary.getIndexPositions(), ranges);
@@ -469,24 +470,26 @@ public class SSTableReader extends SSTable
                                       new Function<IndexSummary.KeyPosition, DecoratedKey>(){
                                           public DecoratedKey apply(IndexSummary.KeyPosition kp)
                                           {
-                                              return kp.key;
+                                              // the index should only contain valid row key, we only allow RowPosition in KeyPosition for search purposes
+                                              assert kp.key instanceof DecoratedKey;
+                                              return (DecoratedKey)kp.key;
                                           }
                                       });
     }
 
-    private static List<Pair<Integer,Integer>> getSampleIndexesForRanges(List<IndexSummary.KeyPosition> samples, Collection<Range> ranges)
+    private static List<Pair<Integer,Integer>> getSampleIndexesForRanges(List<IndexSummary.KeyPosition> samples, Collection<Range<Token>> ranges)
     {
         // use the index to determine a minimal section for each range
         List<Pair<Integer,Integer>> positions = new ArrayList<Pair<Integer,Integer>>();
         if (samples.isEmpty())
             return positions;
 
-        for (AbstractBounds range : AbstractBounds.normalize(ranges))
+        for (AbstractBounds<Token> range : AbstractBounds.<Token>normalize(ranges))
         {
-            DecoratedKey leftKey = new DecoratedKey(range.left, null);
-            DecoratedKey rightKey = new DecoratedKey(range.right, null);
+            RowPosition leftPosition = range.left.maxKeyBound();
+            RowPosition rightPosition = range.left.maxKeyBound();
 
-            int left = Collections.binarySearch(samples, new IndexSummary.KeyPosition(leftKey, -1));
+            int left = Collections.binarySearch(samples, new IndexSummary.KeyPosition(leftPosition, -1));
             if (left < 0)
                 left = (left + 1) * -1;
             else
@@ -498,7 +501,7 @@ public class SSTableReader extends SSTable
 
             int right = Range.isWrapAround(range.left, range.right)
                       ? samples.size() - 1
-                      : Collections.binarySearch(samples, new IndexSummary.KeyPosition(rightKey, -1));
+                      : Collections.binarySearch(samples, new IndexSummary.KeyPosition(rightPosition, -1));
             if (right < 0)
             {
                 // range are end inclusive so we use the previous index from what binarySearch give us
@@ -518,7 +521,7 @@ public class SSTableReader extends SSTable
         return positions;
     }
 
-    public Iterable<DecoratedKey> getKeySamples(final Range range)
+    public Iterable<DecoratedKey> getKeySamples(final Range<Token> range)
     {
         final List<IndexSummary.KeyPosition> samples = indexSummary.getIndexPositions();
 
@@ -555,7 +558,10 @@ public class SSTableReader extends SSTable
 
                     public DecoratedKey next()
                     {
-                        return samples.get(idx++).key;
+                        RowPosition k = samples.get(idx++).key;
+                        // the index should only contain valid row key, we only allow RowPosition in KeyPosition for search purposes
+                        assert k instanceof DecoratedKey;
+                        return (DecoratedKey)k;
                     }
 
                     public void remove()
@@ -571,17 +577,18 @@ public class SSTableReader extends SSTable
      * Determine the minimal set of sections that can be extracted from this SSTable to cover the given ranges.
      * @return A sorted list of (offset,end) pairs that cover the given ranges in the datafile for this SSTable.
      */
-    public List<Pair<Long,Long>> getPositionsForRanges(Collection<Range> ranges)
+    public List<Pair<Long,Long>> getPositionsForRanges(Collection<Range<Token>> ranges)
     {
         // use the index to determine a minimal section for each range
         List<Pair<Long,Long>> positions = new ArrayList<Pair<Long,Long>>();
-        for (AbstractBounds range : AbstractBounds.normalize(ranges))
+        for (AbstractBounds<Token> range : AbstractBounds.normalize(ranges))
         {
-            long left = getPosition(new DecoratedKey(range.left, null), Operator.GT);
+            AbstractBounds<RowPosition> keyRange = range.toRowBounds();
+            long left = getPosition(keyRange.left, Operator.GT);
             if (left == -1)
                 // left is past the end of the file
                 continue;
-            long right = getPosition(new DecoratedKey(range.right, null), Operator.GT);
+            long right = getPosition(keyRange.right, Operator.GT);
             if (right == -1 || Range.isWrapAround(range.left, range.right))
                 // right is past the end of the file, or it wraps
                 right = uncompressedLength();
@@ -595,7 +602,6 @@ public class SSTableReader extends SSTable
 
     public void cacheKey(DecoratedKey key, Long info)
     {
-        assert key.key != null;
         // avoid keeping a permanent reference to the original key buffer
         DecoratedKey copiedKey = new DecoratedKey(key.token, ByteBufferUtil.clone(key.key));
         keyCache.put(new Pair<Descriptor, DecoratedKey>(descriptor, copiedKey), info);
@@ -614,23 +620,25 @@ public class SSTableReader extends SSTable
     }
 
     /**
-     * @param decoratedKey The key to apply as the rhs to the given Operator.
+     * @param key The key to apply as the rhs to the given Operator. A 'fake' key is allowed to
+     * allow key selection by token bounds but only if op != * EQ
      * @param op The Operator defining matching keys: the nearest key to the target matching the operator wins.
      * @return The position in the data file to find the key, or -1 if the key is not present
      */
-    public long getPosition(DecoratedKey decoratedKey, Operator op)
+    public long getPosition(RowPosition key, Operator op)
     {
         // first, check bloom filter
         if (op == Operator.EQ)
         {
-            assert decoratedKey.key != null; // null is ok for GE scans
-            if (!bf.isPresent(decoratedKey.key))
+            assert key instanceof DecoratedKey; // EQ only make sense if the key is a valid row key
+            if (!bf.isPresent(((DecoratedKey)key).key))
                 return -1;
         }
 
-        // next, the key cache
-        if (op == Operator.EQ || op == Operator.GE)
+        // next, the key cache (only make sense for valid row key)
+        if ((op == Operator.EQ || op == Operator.GE) && (key instanceof DecoratedKey))
         {
+            DecoratedKey decoratedKey = (DecoratedKey)key;
             Pair<Descriptor, DecoratedKey> unifiedKey = new Pair<Descriptor, DecoratedKey>(descriptor, decoratedKey);
             Long cachedPosition = getCachedPosition(unifiedKey, true);
             if (cachedPosition != null)
@@ -638,7 +646,7 @@ public class SSTableReader extends SSTable
         }
 
         // next, see if the sampled index says it's impossible for the key to be present
-        IndexSummary.KeyPosition sampledPosition = getIndexScanPosition(decoratedKey);
+        IndexSummary.KeyPosition sampledPosition = getIndexScanPosition(key);
         if (sampledPosition == null)
         {
             if (op == Operator.EQ)
@@ -660,15 +668,16 @@ public class SSTableReader extends SSTable
                     DecoratedKey indexDecoratedKey = decodeKey(partitioner, descriptor, ByteBufferUtil.readWithShortLength(input));
                     long dataPosition = input.readLong();
 
-                    int comparison = indexDecoratedKey.compareTo(decoratedKey);
+                    int comparison = indexDecoratedKey.compareTo(key);
                     int v = op.apply(comparison);
                     if (v == 0)
                     {
                         if (comparison == 0 && keyCache != null && keyCache.getCapacity() > 0)
                         {
+                            assert key instanceof DecoratedKey; // key can be == to the index key only if it's a true row key
+                            DecoratedKey decoratedKey = (DecoratedKey)key;
                             // store exact match for the key
-                            if (decoratedKey.key != null)
-                                cacheKey(decoratedKey, dataPosition);
+                            cacheKey(decoratedKey, dataPosition);
                         }
                         if (op == Operator.EQ)
                             bloomFilterTracker.addTruePositive();
@@ -795,7 +804,7 @@ public class SSTableReader extends SSTable
     * @param range the range of keys to cover
     * @return A Scanner for seeking over the rows of the SSTable.
     */
-    public SSTableScanner getDirectScanner(Range range)
+    public SSTableScanner getDirectScanner(Range<Token> range)
     {
         return new SSTableBoundedScanner(this, true, range);
     }
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java b/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java
index efa957abbf..0a5240ac44 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java
@@ -28,6 +28,7 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.apache.cassandra.db.DecoratedKey;
+import org.apache.cassandra.db.RowPosition;
 import org.apache.cassandra.db.columniterator.IColumnIterator;
 import org.apache.cassandra.db.filter.QueryFilter;
 import org.apache.cassandra.io.util.RandomAccessReader;
@@ -84,7 +85,7 @@ public class SSTableScanner implements CloseableIterator<IColumnIterator>
         file.close();
     }
 
-    public void seekTo(DecoratedKey<?> seekKey)
+    public void seekTo(RowPosition seekKey)
     {
         try
         {
diff --git a/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java b/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
index 49e2c41f99..3093c15513 100644
--- a/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
+++ b/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
@@ -30,6 +30,7 @@ import org.slf4j.LoggerFactory;
 
 import org.apache.cassandra.config.ConfigurationException;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.RingPosition;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.service.DatacenterSyncWriteResponseHandler;
 import org.apache.cassandra.service.DatacenterWriteResponseHandler;
@@ -83,14 +84,15 @@ public abstract class AbstractReplicationStrategy
     }
 
     /**
-     * get the (possibly cached) endpoints that should store the given Token
+     * get the (possibly cached) endpoints that should store the given Token.
      * Note that while the endpoints are conceptually a Set (no duplicates will be included),
      * we return a List to avoid an extra allocation when sorting by proximity later
      * @param searchToken the token the natural endpoints are requested for
      * @return a copy of the natural endpoints for the given token
      */
-    public ArrayList<InetAddress> getNaturalEndpoints(Token searchToken)
+    public ArrayList<InetAddress> getNaturalEndpoints(RingPosition searchPosition)
     {
+        Token searchToken = searchPosition.getToken();
         Token keyToken = TokenMetadata.firstToken(tokenMetadata.sortedTokens(), searchToken);
         ArrayList<InetAddress> endpoints = getCachedEndpoints(keyToken);
         if (endpoints == null)
@@ -142,13 +144,13 @@ public abstract class AbstractReplicationStrategy
      * (fixing this would probably require merging tokenmetadata into replicationstrategy,
      * so we could cache/invalidate cleanly.)
      */
-    public Multimap<InetAddress, Range> getAddressRanges(TokenMetadata metadata)
+    public Multimap<InetAddress, Range<Token>> getAddressRanges(TokenMetadata metadata)
     {
-        Multimap<InetAddress, Range> map = HashMultimap.create();
+        Multimap<InetAddress, Range<Token>> map = HashMultimap.create();
 
         for (Token token : metadata.sortedTokens())
         {
-            Range range = metadata.getPrimaryRangeFor(token);
+            Range<Token> range = metadata.getPrimaryRangeFor(token);
             for (InetAddress ep : calculateNaturalEndpoints(token, metadata))
             {
                 map.put(ep, range);
@@ -158,13 +160,13 @@ public abstract class AbstractReplicationStrategy
         return map;
     }
 
-    public Multimap<Range, InetAddress> getRangeAddresses(TokenMetadata metadata)
+    public Multimap<Range<Token>, InetAddress> getRangeAddresses(TokenMetadata metadata)
     {
-        Multimap<Range, InetAddress> map = HashMultimap.create();
+        Multimap<Range<Token>, InetAddress> map = HashMultimap.create();
 
         for (Token token : metadata.sortedTokens())
         {
-            Range range = metadata.getPrimaryRangeFor(token);
+            Range<Token> range = metadata.getPrimaryRangeFor(token);
             for (InetAddress ep : calculateNaturalEndpoints(token, metadata))
             {
                 map.put(range, ep);
@@ -174,12 +176,12 @@ public abstract class AbstractReplicationStrategy
         return map;
     }
 
-    public Multimap<InetAddress, Range> getAddressRanges()
+    public Multimap<InetAddress, Range<Token>> getAddressRanges()
     {
         return getAddressRanges(tokenMetadata);
     }
 
-    public Collection<Range> getPendingAddressRanges(TokenMetadata metadata, Token pendingToken, InetAddress pendingAddress)
+    public Collection<Range<Token>> getPendingAddressRanges(TokenMetadata metadata, Token pendingToken, InetAddress pendingAddress)
     {
         TokenMetadata temp = metadata.cloneOnlyTokenMap();
         temp.updateNormalToken(pendingToken, pendingAddress);
diff --git a/src/java/org/apache/cassandra/locator/TokenMetadata.java b/src/java/org/apache/cassandra/locator/TokenMetadata.java
index b64865606b..6d6f009b72 100644
--- a/src/java/org/apache/cassandra/locator/TokenMetadata.java
+++ b/src/java/org/apache/cassandra/locator/TokenMetadata.java
@@ -71,7 +71,7 @@ public class TokenMetadata
     // (don't need to record Token here since it's still part of tokenToEndpointMap until it's done leaving)
     private Set<InetAddress> leavingEndpoints = new HashSet<InetAddress>();
     // this is a cache of the calculation from {tokenToEndpointMap, bootstrapTokens, leavingEndpoints}
-    private ConcurrentMap<String, Multimap<Range, InetAddress>> pendingRanges = new ConcurrentHashMap<String, Multimap<Range, InetAddress>>();
+    private ConcurrentMap<String, Multimap<Range<Token>, InetAddress>> pendingRanges = new ConcurrentHashMap<String, Multimap<Range<Token>, InetAddress>>();
 
     // nodes which are migrating to the new tokens in the ring
     private Set<Pair<Token, InetAddress>> movingEndpoints = new HashSet<Pair<Token, InetAddress>>();
@@ -108,7 +108,7 @@ public class TokenMetadata
     public int pendingRangeChanges(InetAddress source)
     {
         int n = 0;
-        Range sourceRange = getPrimaryRangeFor(getToken(source));
+        Range<Token> sourceRange = getPrimaryRangeFor(getToken(source));
         for (Token token : bootstrapTokens.keySet())
             if (sourceRange.contains(token))
                 n++;
@@ -423,9 +423,9 @@ public class TokenMetadata
         }
     }
 
-    public Range getPrimaryRangeFor(Token right)
+    public Range<Token> getPrimaryRangeFor(Token right)
     {
-        return new Range(getPredecessor(right), right);
+        return new Range<Token>(getPredecessor(right), right);
     }
 
     public ArrayList<Token> sortedTokens()
@@ -441,13 +441,13 @@ public class TokenMetadata
         }
     }
 
-    private Multimap<Range, InetAddress> getPendingRangesMM(String table)
+    private Multimap<Range<Token>, InetAddress> getPendingRangesMM(String table)
     {
-        Multimap<Range, InetAddress> map = pendingRanges.get(table);
+        Multimap<Range<Token>, InetAddress> map = pendingRanges.get(table);
         if (map == null)
         {
             map = HashMultimap.create();
-            Multimap<Range, InetAddress> priorMap = pendingRanges.putIfAbsent(table, map);
+            Multimap<Range<Token>, InetAddress> priorMap = pendingRanges.putIfAbsent(table, map);
             if (priorMap != null)
                 map = priorMap;
         }
@@ -455,15 +455,15 @@ public class TokenMetadata
     }
 
     /** a mutable map may be returned but caller should not modify it */
-    public Map<Range, Collection<InetAddress>> getPendingRanges(String table)
+    public Map<Range<Token>, Collection<InetAddress>> getPendingRanges(String table)
     {
         return getPendingRangesMM(table).asMap();
     }
 
-    public List<Range> getPendingRanges(String table, InetAddress endpoint)
+    public List<Range<Token>> getPendingRanges(String table, InetAddress endpoint)
     {
-        List<Range> ranges = new ArrayList<Range>();
-        for (Map.Entry<Range, InetAddress> entry : getPendingRangesMM(table).entries())
+        List<Range<Token>> ranges = new ArrayList<Range<Token>>();
+        for (Map.Entry<Range<Token>, InetAddress> entry : getPendingRangesMM(table).entries())
         {
             if (entry.getValue().equals(endpoint))
             {
@@ -473,7 +473,7 @@ public class TokenMetadata
         return ranges;
     }
 
-    public void setPendingRanges(String table, Multimap<Range, InetAddress> rangeMap)
+    public void setPendingRanges(String table, Multimap<Range<Token>, InetAddress> rangeMap)
     {
         pendingRanges.put(table, rangeMap);
     }
@@ -545,7 +545,7 @@ public class TokenMetadata
             return includeMin ? Iterators.singletonIterator(StorageService.getPartitioner().getMinimumToken())
                               : Iterators.<Token>emptyIterator();
 
-        final boolean insertMin = (includeMin && !ring.get(0).equals(StorageService.getPartitioner().getMinimumToken())) ? true : false;
+        final boolean insertMin = (includeMin && !ring.get(0).isMinimum()) ? true : false;
         final int startIndex = firstTokenIndex(ring, start, insertMin);
         return new AbstractIterator<Token>()
         {
@@ -647,9 +647,9 @@ public class TokenMetadata
     {
         StringBuilder sb = new StringBuilder();
 
-        for (Map.Entry<String, Multimap<Range, InetAddress>> entry : pendingRanges.entrySet())
+        for (Map.Entry<String, Multimap<Range<Token>, InetAddress>> entry : pendingRanges.entrySet())
         {
-            for (Map.Entry<Range, InetAddress> rmap : entry.getValue().entries())
+            for (Map.Entry<Range<Token>, InetAddress> rmap : entry.getValue().entries())
             {
                 sb.append(rmap.getValue() + ":" + rmap.getKey());
                 sb.append(System.getProperty("line.separator"));
@@ -689,13 +689,13 @@ public class TokenMetadata
      */
     public Collection<InetAddress> getWriteEndpoints(Token token, String table, Collection<InetAddress> naturalEndpoints)
     {
-        Map<Range, Collection<InetAddress>> ranges = getPendingRanges(table);
+        Map<Range<Token>, Collection<InetAddress>> ranges = getPendingRanges(table);
         if (ranges.isEmpty())
             return naturalEndpoints;
 
         Set<InetAddress> endpoints = new HashSet<InetAddress>(naturalEndpoints);
 
-        for (Map.Entry<Range, Collection<InetAddress>> entry : ranges.entrySet())
+        for (Map.Entry<Range<Token>, Collection<InetAddress>> entry : ranges.entrySet())
         {
             if (entry.getKey().contains(token))
             {
diff --git a/src/java/org/apache/cassandra/net/MessagingService.java b/src/java/org/apache/cassandra/net/MessagingService.java
index 331b9aaa9a..2cca6bbc93 100644
--- a/src/java/org/apache/cassandra/net/MessagingService.java
+++ b/src/java/org/apache/cassandra/net/MessagingService.java
@@ -67,7 +67,8 @@ public final class MessagingService implements MessagingServiceMBean
     public static final int VERSION_07 = 1;
     public static final int VERSION_080 = 2;
     public static final int VERSION_10 = 3;
-    public static final int version_ = VERSION_10;
+    public static final int VERSION_11 = 4;
+    public static final int version_ = VERSION_11;
 
     static SerializerType serializerType_ = SerializerType.BINARY;
 
diff --git a/src/java/org/apache/cassandra/service/AntiEntropyService.java b/src/java/org/apache/cassandra/service/AntiEntropyService.java
index c87fd3e1ad..28f7caf8f2 100644
--- a/src/java/org/apache/cassandra/service/AntiEntropyService.java
+++ b/src/java/org/apache/cassandra/service/AntiEntropyService.java
@@ -41,6 +41,7 @@ import org.apache.cassandra.db.Table;
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.RandomPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.gms.*;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.FastByteArrayInputStream;
@@ -118,7 +119,7 @@ public class AntiEntropyService
     /**
      * Requests repairs for the given table and column families, and blocks until all repairs have been completed.
      */
-    public RepairFuture submitRepairSession(Range range, String tablename, String... cfnames)
+    public RepairFuture submitRepairSession(Range<Token> range, String tablename, String... cfnames)
     {
         RepairFuture futureTask = new RepairSession(range, tablename, cfnames).getFuture();
         executor.execute(futureTask);
@@ -145,10 +146,10 @@ public class AntiEntropyService
     /**
      * Return all of the neighbors with whom we share data.
      */
-    static Set<InetAddress> getNeighbors(String table, Range range)
+    static Set<InetAddress> getNeighbors(String table, Range<Token> range)
     {
         StorageService ss = StorageService.instance;
-        Map<Range, List<InetAddress>> replicaSets = ss.getRangeToAddressMap(table);
+        Map<Range<Token>, List<InetAddress>> replicaSets = ss.getRangeToAddressMap(table);
         if (!replicaSets.containsKey(range))
             return Collections.emptySet();
         Set<InetAddress> neighbors = new HashSet<InetAddress>(replicaSets.get(range));
@@ -209,7 +210,7 @@ public class AntiEntropyService
     /**
      * Requests a tree from the given node, and returns the request that was sent.
      */
-    TreeRequest request(String sessionid, InetAddress remote, Range range, String ksname, String cfname)
+    TreeRequest request(String sessionid, InetAddress remote, Range<Token> range, String ksname, String cfname)
     {
         TreeRequest request = new TreeRequest(sessionid, remote, range, new CFPair(ksname, cfname));
         MessagingService.instance().sendOneWay(TreeRequestVerbHandler.makeVerb(request, Gossiper.instance.getVersion(remote)), remote);
@@ -429,7 +430,7 @@ public class AntiEntropyService
             dos.writeUTF(request.cf.left);
             dos.writeUTF(request.cf.right);
             if (version > MessagingService.VERSION_07)
-                AbstractBounds.serializer().serialize(request.range, dos);
+                AbstractBounds.serializer().serialize(request.range, dos, version);
         }
 
         public TreeRequest deserialize(DataInput dis, int version) throws IOException
@@ -437,11 +438,11 @@ public class AntiEntropyService
             String sessId = dis.readUTF();
             InetAddress endpoint = CompactEndpointSerializationHelper.deserialize(dis);
             CFPair cfpair = new CFPair(dis.readUTF(), dis.readUTF());
-            Range range;
+            Range<Token> range;
             if (version > MessagingService.VERSION_07)
-                range = (Range) AbstractBounds.serializer().deserialize(dis);
+                range = (Range<Token>) AbstractBounds.serializer().deserialize(dis, version);
             else
-                range = new Range(StorageService.getPartitioner().getMinimumToken(), StorageService.getPartitioner().getMinimumToken());
+                range = new Range<Token>(StorageService.getPartitioner().getMinimumToken(), StorageService.getPartitioner().getMinimumToken());
 
             return new TreeRequest(sessId, endpoint, range, cfpair);
         }
@@ -555,10 +556,10 @@ public class AntiEntropyService
     {
         public final String sessionid;
         public final InetAddress endpoint;
-        public final Range range;
+        public final Range<Token> range;
         public final CFPair cf;
 
-        public TreeRequest(String sessionid, InetAddress endpoint, Range range, CFPair cf)
+        public TreeRequest(String sessionid, InetAddress endpoint, Range<Token> range, CFPair cf)
         {
             this.sessionid = sessionid;
             this.endpoint = endpoint;
@@ -598,7 +599,7 @@ public class AntiEntropyService
         private final String sessionName;
         private final String tablename;
         private final String[] cfnames;
-        private final Range range;
+        private final Range<Token> range;
         private volatile Exception exception;
         private final AtomicBoolean isFailed = new AtomicBoolean(false);
 
@@ -617,12 +618,12 @@ public class AntiEntropyService
             AntiEntropyService.instance.sessions.put(getName(), this);
         }
 
-        public RepairSession(Range range, String tablename, String... cfnames)
+        public RepairSession(Range<Token> range, String tablename, String... cfnames)
         {
             this(UUIDGen.makeType1UUIDFromHost(FBUtilities.getBroadcastAddress()).toString(), range, tablename, cfnames);
         }
 
-        private RepairSession(String id, Range range, String tablename, String[] cfnames)
+        private RepairSession(String id, Range<Token> range, String tablename, String[] cfnames)
         {
             this.sessionName = id;
             this.tablename = tablename;
@@ -895,14 +896,14 @@ public class AntiEntropyService
             public final String cfname;
             public final TreeResponse r1;
             public final TreeResponse r2;
-            public List<Range> differences;
+            public List<Range<Token>> differences;
 
             Differencer(String cfname, TreeResponse r1, TreeResponse r2)
             {
                 this.cfname = cfname;
                 this.r1 = r1;
                 this.r2 = r2;
-                this.differences = new ArrayList<Range>();
+                this.differences = new ArrayList<Range<Token>>();
             }
 
             /**
diff --git a/src/java/org/apache/cassandra/service/StorageProxy.java b/src/java/org/apache/cassandra/service/StorageProxy.java
index a8af00cd6a..9afdf57455 100644
--- a/src/java/org/apache/cassandra/service/StorageProxy.java
+++ b/src/java/org/apache/cassandra/service/StorageProxy.java
@@ -50,6 +50,7 @@ import org.apache.cassandra.db.filter.QueryFilter;
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.Bounds;
 import org.apache.cassandra.dht.IPartitioner;
+import org.apache.cassandra.dht.RingPosition;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.gms.FailureDetector;
 import org.apache.cassandra.gms.Gossiper;
@@ -259,8 +260,9 @@ public class StorageProxy implements StorageProxyMBean
     private static Collection<InetAddress> getWriteEndpoints(String table, ByteBuffer key)
     {
         StorageService ss = StorageService.instance;
-        List<InetAddress> naturalEndpoints = ss.getNaturalEndpoints(table, key);
-        return ss.getTokenMetadata().getWriteEndpoints(StorageService.getPartitioner().getToken(key), table, naturalEndpoints);
+        Token tk = StorageService.getPartitioner().getToken(key);
+        List<InetAddress> naturalEndpoints = ss.getNaturalEndpoints(table, tk);
+        return ss.getTokenMetadata().getWriteEndpoints(tk, table, naturalEndpoints);
     }
 
     /**
@@ -817,8 +819,8 @@ public class StorageProxy implements StorageProxyMBean
         try
         {
             rows = new ArrayList<Row>(command.max_keys);
-            List<AbstractBounds> ranges = getRestrictedRanges(command.range);
-            for (AbstractBounds range : ranges)
+            List<AbstractBounds<RowPosition>> ranges = getRestrictedRanges(command.range);
+            for (AbstractBounds<RowPosition> range : ranges)
             {
                 List<InetAddress> liveEndpoints = StorageService.instance.getLiveNaturalEndpoints(command.keyspace, range.right);
                 DatabaseDescriptor.getEndpointSnitch().sortByProximity(FBUtilities.getBroadcastAddress(), liveEndpoints);
@@ -979,10 +981,10 @@ public class StorageProxy implements StorageProxyMBean
      * Compute all ranges we're going to query, in sorted order. Nodes can be replica destinations for many ranges,
      * so we need to restrict each scan to the specific range we want, or else we'd get duplicate results.
      */
-    static List<AbstractBounds> getRestrictedRanges(final AbstractBounds queryRange)
+    static <T extends RingPosition> List<AbstractBounds<T>> getRestrictedRanges(final AbstractBounds<T> queryRange)
     {
         // special case for bounds containing exactly 1 (non-minimum) token
-        if (queryRange instanceof Bounds && queryRange.left.equals(queryRange.right) && !queryRange.left.equals(StorageService.getPartitioner().getMinimumToken()))
+        if (queryRange instanceof Bounds && queryRange.left.equals(queryRange.right) && !queryRange.left.isMinimum(StorageService.getPartitioner()))
         {
             if (logger.isDebugEnabled())
                 logger.debug("restricted single token match for query {}", queryRange);
@@ -991,17 +993,28 @@ public class StorageProxy implements StorageProxyMBean
 
         TokenMetadata tokenMetadata = StorageService.instance.getTokenMetadata();
 
-        List<AbstractBounds> ranges = new ArrayList<AbstractBounds>();
+        List<AbstractBounds<T>> ranges = new ArrayList<AbstractBounds<T>>();
         // divide the queryRange into pieces delimited by the ring and minimum tokens
-        Iterator<Token> ringIter = TokenMetadata.ringIterator(tokenMetadata.sortedTokens(), queryRange.left, true);
-        AbstractBounds remainder = queryRange;
+        Iterator<Token> ringIter = TokenMetadata.ringIterator(tokenMetadata.sortedTokens(), queryRange.left.getToken(), true);
+        AbstractBounds<T> remainder = queryRange;
         while (ringIter.hasNext())
         {
             Token token = ringIter.next();
-            if (remainder == null || !(remainder.left.equals(token) || remainder.contains(token)))
+            /*
+             * remainder can be a range/bounds of token _or_ keys and we want to split it with a token:
+             *   - if remainder is tokens, then we'll just split using the provided token.
+             *   - if reaminer is keys, we want to split using token.upperBoundKey. For instance, if remainder
+             *     is [DK(10, 'foo'), DK(20, 'bar')], and we have 3 nodes with tokens 0, 15, 30. We want to
+             *     split remainder to A=[DK(10, 'foo'), 15] and B=(15, DK(20, 'bar')]. But since we can't mix
+             *     tokens and keys at the same time in a range, we uses 15.upperBoundKey() to have A include all
+             *     keys having 15 as token and B include none of those (since that is what our node owns).
+             * asSplitValue() abstracts that choice.
+             */
+            T splitValue = (T)token.asSplitValue(queryRange.left.getClass());
+            if (remainder == null || !(remainder.left.equals(splitValue) || remainder.contains(splitValue)))
                 // no more splits
                 break;
-            Pair<AbstractBounds,AbstractBounds> splits = remainder.split(token);
+            Pair<AbstractBounds<T>,AbstractBounds<T>> splits = remainder.split(splitValue);
             if (splits.left != null)
                 ranges.add(splits.left);
             remainder = splits.right;
@@ -1094,13 +1107,13 @@ public class StorageProxy implements StorageProxyMBean
     {
         IPartitioner p = StorageService.getPartitioner();
 
-        Token leftToken = index_clause.start_key == null ? p.getMinimumToken() : p.getToken(index_clause.start_key);
-        List<AbstractBounds> ranges = getRestrictedRanges(new Bounds(leftToken, p.getMinimumToken()));
+        RowPosition leftPos = RowPosition.forKey(index_clause.start_key, p);
+        List<AbstractBounds<RowPosition>> ranges = getRestrictedRanges(new Bounds<RowPosition>(leftPos, p.getMinimumToken().minKeyBound()));
         logger.debug("scan ranges are {}", StringUtils.join(ranges, ","));
 
         // now scan until we have enough results
         List<Row> rows = new ArrayList<Row>(index_clause.count);
-        for (AbstractBounds range : ranges)
+        for (AbstractBounds<RowPosition> range : ranges)
         {
             List<InetAddress> liveEndpoints = StorageService.instance.getLiveNaturalEndpoints(keyspace, range.right);
             DatabaseDescriptor.getEndpointSnitch().sortByProximity(FBUtilities.getBroadcastAddress(), liveEndpoints);
diff --git a/src/java/org/apache/cassandra/service/StorageService.java b/src/java/org/apache/cassandra/service/StorageService.java
index 53e916c6a4..e0269ccd65 100644
--- a/src/java/org/apache/cassandra/service/StorageService.java
+++ b/src/java/org/apache/cassandra/service/StorageService.java
@@ -180,12 +180,12 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
         return instance.partitioner;
     }
 
-    public Collection<Range> getLocalRanges(String table)
+    public Collection<Range<Token>> getLocalRanges(String table)
     {
         return getRangesForEndpoint(table, FBUtilities.getBroadcastAddress());
     }
 
-    public Range getLocalPrimaryRange()
+    public Range<Token> getLocalPrimaryRange()
     {
         return getPrimaryRangeForEndpoint(FBUtilities.getBroadcastAddress());
     }
@@ -660,11 +660,11 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param keyspace
      * @return
      */
-    public Map<Range, List<String>> getRangeToEndpointMap(String keyspace)
+    public Map<Range<Token>, List<String>> getRangeToEndpointMap(String keyspace)
     {
         /* All the ranges for the tokens */
-        Map<Range, List<String>> map = new HashMap<Range, List<String>>();
-        for (Map.Entry<Range,List<InetAddress>> entry : getRangeToAddressMap(keyspace).entrySet())
+        Map<Range<Token>, List<String>> map = new HashMap<Range<Token>, List<String>>();
+        for (Map.Entry<Range<Token>,List<InetAddress>> entry : getRangeToAddressMap(keyspace).entrySet())
         {
             map.put(entry.getKey(), stringify(entry.getValue()));
         }
@@ -691,11 +691,11 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param keyspace
      * @return
      */
-    public Map<Range, List<String>> getRangeToRpcaddressMap(String keyspace)
+    public Map<Range<Token>, List<String>> getRangeToRpcaddressMap(String keyspace)
     {
         /* All the ranges for the tokens */
-        Map<Range, List<String>> map = new HashMap<Range, List<String>>();
-        for (Map.Entry<Range,List<InetAddress>> entry : getRangeToAddressMap(keyspace).entrySet())
+        Map<Range<Token>, List<String>> map = new HashMap<Range<Token>, List<String>>();
+        for (Map.Entry<Range<Token>, List<InetAddress>> entry : getRangeToAddressMap(keyspace).entrySet())
         {
             List<String> rpcaddrs = new ArrayList<String>();
             for (InetAddress endpoint: entry.getValue())
@@ -707,15 +707,15 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
         return map;
     }
 
-    public Map<Range, List<String>> getPendingRangeToEndpointMap(String keyspace)
+    public Map<Range<Token>, List<String>> getPendingRangeToEndpointMap(String keyspace)
     {
         // some people just want to get a visual representation of things. Allow null and set it to the first
         // non-system table.
         if (keyspace == null)
             keyspace = Schema.instance.getNonSystemTables().get(0);
 
-        Map<Range, List<String>> map = new HashMap<Range, List<String>>();
-        for (Map.Entry<Range, Collection<InetAddress>> entry : tokenMetadata_.getPendingRanges(keyspace).entrySet())
+        Map<Range<Token>, List<String>> map = new HashMap<Range<Token>, List<String>>();
+        for (Map.Entry<Range<Token>, Collection<InetAddress>> entry : tokenMetadata_.getPendingRanges(keyspace).entrySet())
         {
             List<InetAddress> l = new ArrayList<InetAddress>(entry.getValue());
             map.put(entry.getKey(), stringify(l));
@@ -723,14 +723,14 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
         return map;
     }
 
-    public Map<Range, List<InetAddress>> getRangeToAddressMap(String keyspace)
+    public Map<Range<Token>, List<InetAddress>> getRangeToAddressMap(String keyspace)
     {
         // some people just want to get a visual representation of things. Allow null and set it to the first
         // non-system table.
         if (keyspace == null)
             keyspace = Schema.instance.getNonSystemTables().get(0);
 
-        List<Range> ranges = getAllRanges(tokenMetadata_.sortedTokens());
+        List<Range<Token>> ranges = getAllRanges(tokenMetadata_.sortedTokens());
         return constructRangeToEndpointMap(keyspace, ranges);
     }
 
@@ -751,10 +751,10 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param ranges
      * @return mapping of ranges to the replicas responsible for them.
     */
-    private Map<Range, List<InetAddress>> constructRangeToEndpointMap(String keyspace, List<Range> ranges)
+    private Map<Range<Token>, List<InetAddress>> constructRangeToEndpointMap(String keyspace, List<Range<Token>> ranges)
     {
-        Map<Range, List<InetAddress>> rangeToEndpointMap = new HashMap<Range, List<InetAddress>>();
-        for (Range range : ranges)
+        Map<Range<Token>, List<InetAddress>> rangeToEndpointMap = new HashMap<Range<Token>, List<InetAddress>>();
+        for (Range<Token> range : ranges)
         {
             rangeToEndpointMap.put(range, Table.open(keyspace).getReplicationStrategy().getNaturalEndpoints(range.right));
         }
@@ -1098,7 +1098,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
     public static void calculatePendingRanges(AbstractReplicationStrategy strategy, String table)
     {
         TokenMetadata tm = StorageService.instance.getTokenMetadata();
-        Multimap<Range, InetAddress> pendingRanges = HashMultimap.create();
+        Multimap<Range<Token>, InetAddress> pendingRanges = HashMultimap.create();
         Map<Token, InetAddress> bootstrapTokens = tm.getBootstrapTokens();
         Set<InetAddress> leavingEndpoints = tm.getLeavingEndpoints();
 
@@ -1110,19 +1110,19 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             return;
         }
 
-        Multimap<InetAddress, Range> addressRanges = strategy.getAddressRanges();
+        Multimap<InetAddress, Range<Token>> addressRanges = strategy.getAddressRanges();
 
         // Copy of metadata reflecting the situation after all leave operations are finished.
         TokenMetadata allLeftMetadata = tm.cloneAfterAllLeft();
 
         // get all ranges that will be affected by leaving nodes
-        Set<Range> affectedRanges = new HashSet<Range>();
+        Set<Range<Token>> affectedRanges = new HashSet<Range<Token>>();
         for (InetAddress endpoint : leavingEndpoints)
             affectedRanges.addAll(addressRanges.get(endpoint));
 
         // for each of those ranges, find what new nodes will be responsible for the range when
         // all leaving nodes are gone.
-        for (Range range : affectedRanges)
+        for (Range<Token> range : affectedRanges)
         {
             Set<InetAddress> currentEndpoints = ImmutableSet.copyOf(strategy.calculateNaturalEndpoints(range.right, tm));
             Set<InetAddress> newEndpoints = ImmutableSet.copyOf(strategy.calculateNaturalEndpoints(range.right, allLeftMetadata));
@@ -1139,7 +1139,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             InetAddress endpoint = entry.getValue();
 
             allLeftMetadata.updateNormalToken(entry.getKey(), endpoint);
-            for (Range range : strategy.getAddressRanges(allLeftMetadata).get(endpoint))
+            for (Range<Token> range : strategy.getAddressRanges(allLeftMetadata).get(endpoint))
                 pendingRanges.put(range, endpoint);
             allLeftMetadata.removeEndpoint(endpoint);
         }
@@ -1156,7 +1156,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             //  moving.left is a new token of the endpoint
             allLeftMetadata.updateNormalToken(moving.left, endpoint);
 
-            for (Range range : strategy.getAddressRanges(allLeftMetadata).get(endpoint))
+            for (Range<Token> range : strategy.getAddressRanges(allLeftMetadata).get(endpoint))
             {
                 pendingRanges.put(range, endpoint);
             }
@@ -1177,15 +1177,15 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param ranges the ranges to find sources for
      * @return multimap of addresses to ranges the address is responsible for
      */
-    private Multimap<InetAddress, Range> getNewSourceRanges(String table, Set<Range> ranges)
+    private Multimap<InetAddress, Range<Token>> getNewSourceRanges(String table, Set<Range<Token>> ranges) 
     {
         InetAddress myAddress = FBUtilities.getBroadcastAddress();
-        Multimap<Range, InetAddress> rangeAddresses = Table.open(table).getReplicationStrategy().getRangeAddresses(tokenMetadata_);
-        Multimap<InetAddress, Range> sourceRanges = HashMultimap.create();
+        Multimap<Range<Token>, InetAddress> rangeAddresses = Table.open(table).getReplicationStrategy().getRangeAddresses(tokenMetadata_);
+        Multimap<InetAddress, Range<Token>> sourceRanges = HashMultimap.create();
         IFailureDetector failureDetector = FailureDetector.instance;
 
         // find alive sources for our new ranges
-        for (Range range : ranges)
+        for (Range<Token> range : ranges)
         {
             Collection<InetAddress> possibleRanges = rangeAddresses.get(range);
             IEndpointSnitch snitch = DatabaseDescriptor.getEndpointSnitch();
@@ -1246,21 +1246,21 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
     private void restoreReplicaCount(InetAddress endpoint, final InetAddress notifyEndpoint)
     {
         final Multimap<InetAddress, String> fetchSources = HashMultimap.create();
-        Multimap<String, Map.Entry<InetAddress, Collection<Range>>> rangesToFetch = HashMultimap.create();
+        Multimap<String, Map.Entry<InetAddress, Collection<Range<Token>>>> rangesToFetch = HashMultimap.create();
 
         final InetAddress myAddress = FBUtilities.getBroadcastAddress();
 
         for (String table : Schema.instance.getNonSystemTables())
         {
-            Multimap<Range, InetAddress> changedRanges = getChangedRangesForLeaving(table, endpoint);
-            Set<Range> myNewRanges = new HashSet<Range>();
-            for (Map.Entry<Range, InetAddress> entry : changedRanges.entries())
+            Multimap<Range<Token>, InetAddress> changedRanges = getChangedRangesForLeaving(table, endpoint); 
+            Set<Range<Token>> myNewRanges = new HashSet<Range<Token>>();
+            for (Map.Entry<Range<Token>, InetAddress> entry : changedRanges.entries())
             {
                 if (entry.getValue().equals(myAddress))
                     myNewRanges.add(entry.getKey());
             }
-            Multimap<InetAddress, Range> sourceRanges = getNewSourceRanges(table, myNewRanges);
-            for (Map.Entry<InetAddress, Collection<Range>> entry : sourceRanges.asMap().entrySet())
+            Multimap<InetAddress, Range<Token>> sourceRanges = getNewSourceRanges(table, myNewRanges);
+            for (Map.Entry<InetAddress, Collection<Range<Token>>> entry : sourceRanges.asMap().entrySet())
             {
                 fetchSources.put(entry.getKey(), table);
                 rangesToFetch.put(table, entry);
@@ -1269,10 +1269,10 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
 
         for (final String table : rangesToFetch.keySet())
         {
-            for (Map.Entry<InetAddress, Collection<Range>> entry : rangesToFetch.get(table))
+            for (Map.Entry<InetAddress, Collection<Range<Token>>> entry : rangesToFetch.get(table))
             {
                 final InetAddress source = entry.getKey();
-                Collection<Range> ranges = entry.getValue();
+                Collection<Range<Token>> ranges = entry.getValue();
                 final Runnable callback = new Runnable()
                 {
                     public void run()
@@ -1293,18 +1293,18 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
     }
 
     // needs to be modified to accept either a table or ARS.
-    private Multimap<Range, InetAddress> getChangedRangesForLeaving(String table, InetAddress endpoint)
+    private Multimap<Range<Token>, InetAddress> getChangedRangesForLeaving(String table, InetAddress endpoint)
     {
         // First get all ranges the leaving endpoint is responsible for
-        Collection<Range> ranges = getRangesForEndpoint(table, endpoint);
+        Collection<Range<Token>> ranges = getRangesForEndpoint(table, endpoint);
 
         if (logger_.isDebugEnabled())
             logger_.debug("Node " + endpoint + " ranges [" + StringUtils.join(ranges, ", ") + "]");
 
-        Map<Range, List<InetAddress>> currentReplicaEndpoints = new HashMap<Range, List<InetAddress>>();
+        Map<Range<Token>, List<InetAddress>> currentReplicaEndpoints = new HashMap<Range<Token>, List<InetAddress>>();
 
         // Find (for each range) all nodes that store replicas for these ranges as well
-        for (Range range : ranges)
+        for (Range<Token> range : ranges)
             currentReplicaEndpoints.put(range, Table.open(table).getReplicationStrategy().calculateNaturalEndpoints(range.right, tokenMetadata_));
 
         TokenMetadata temp = tokenMetadata_.cloneAfterAllLeft();
@@ -1314,14 +1314,14 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
         if (temp.isMember(endpoint))
             temp.removeEndpoint(endpoint);
 
-        Multimap<Range, InetAddress> changedRanges = HashMultimap.create();
+        Multimap<Range<Token>, InetAddress> changedRanges = HashMultimap.create();
 
         // Go through the ranges and for each range check who will be
         // storing replicas for these ranges when the leaving endpoint
         // is gone. Whoever is present in newReplicaEndpoints list, but
         // not in the currentReplicaEndpoints list, will be needing the
         // range.
-        for (Range range : ranges)
+        for (Range<Token> range : ranges)
         {
             Collection<InetAddress> newReplicaEndpoints = Table.open(table).getReplicationStrategy().calculateNaturalEndpoints(range.right, temp);
             newReplicaEndpoints.removeAll(currentReplicaEndpoints.get(range));
@@ -1688,12 +1688,12 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             return;
 
 
-        Collection<Range> ranges = getLocalRanges(tableName);
+        Collection<Range<Token>> ranges = getLocalRanges(tableName);
         int cmd = nextRepairCommand.incrementAndGet();
         logger_.info("Starting repair command #{}, repairing {} ranges.", cmd, ranges.size());
 
         List<AntiEntropyService.RepairFuture> futures = new ArrayList<AntiEntropyService.RepairFuture>(ranges.size());
-        for (Range range : ranges)
+        for (Range<Token> range : ranges)
         {
             AntiEntropyService.RepairFuture future = forceTableRepair(range, tableName, columnFamilies);
             futures.add(future);
@@ -1747,7 +1747,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
         }
     }
 
-    public AntiEntropyService.RepairFuture forceTableRepair(final Range range, final String tableName, final String... columnFamilies) throws IOException
+    public AntiEntropyService.RepairFuture forceTableRepair(final Range<Token> range, final String tableName, final String... columnFamilies) throws IOException
     {
         ArrayList<String> names = new ArrayList<String>();
         for (ColumnFamilyStore cfStore : getValidColumnFamilies(tableName, columnFamilies))
@@ -1789,7 +1789,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param ep endpoint we are interested in.
      * @return range for the specified endpoint.
      */
-    public Range getPrimaryRangeForEndpoint(InetAddress ep)
+    public Range<Token> getPrimaryRangeForEndpoint(InetAddress ep)
     {
         return tokenMetadata_.getPrimaryRangeFor(tokenMetadata_.getToken(ep));
     }
@@ -1799,7 +1799,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param ep endpoint we are interested in.
      * @return ranges for the specified endpoint.
      */
-    Collection<Range> getRangesForEndpoint(String table, InetAddress ep)
+    Collection<Range<Token>> getRangesForEndpoint(String table, InetAddress ep)
     {
         return Table.open(table).getReplicationStrategy().getAddressRanges().get(ep);
     }
@@ -1810,21 +1810,21 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * ranges.
      * @return ranges in sorted order
     */
-    public List<Range> getAllRanges(List<Token> sortedTokens)
+    public List<Range<Token>> getAllRanges(List<Token> sortedTokens)
     {
         if (logger_.isDebugEnabled())
             logger_.debug("computing ranges for " + StringUtils.join(sortedTokens, ", "));
 
         if (sortedTokens.isEmpty())
             return Collections.emptyList();
-        List<Range> ranges = new ArrayList<Range>();
+        List<Range<Token>> ranges = new ArrayList<Range<Token>>();
         int size = sortedTokens.size();
         for (int i = 1; i < size; ++i)
         {
-            Range range = new Range(sortedTokens.get(i - 1), sortedTokens.get(i));
+            Range<Token> range = new Range<Token>(sortedTokens.get(i - 1), sortedTokens.get(i));
             ranges.add(range);
         }
-        Range range = new Range(sortedTokens.get(size - 1), sortedTokens.get(0));
+        Range<Token> range = new Range<Token>(sortedTokens.get(size - 1), sortedTokens.get(0));
         ranges.add(range);
 
         return ranges;
@@ -1854,12 +1854,12 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * This method returns the N endpoints that are responsible for storing the
      * specified key i.e for replication.
      *
-     * @param token - token for which we need to find the endpoint return value -
+     * @param position - position for which we need to find the endpoint return value -
      * the endpoint responsible for this token
      */
-    public List<InetAddress> getNaturalEndpoints(String table, Token token)
+    public List<InetAddress> getNaturalEndpoints(String table, RingPosition pos)
     {
-        return Table.open(table).getReplicationStrategy().getNaturalEndpoints(token);
+        return Table.open(table).getReplicationStrategy().getNaturalEndpoints(pos);
     }
 
     /**
@@ -1871,13 +1871,13 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      */
     public List<InetAddress> getLiveNaturalEndpoints(String table, ByteBuffer key)
     {
-        return getLiveNaturalEndpoints(table, partitioner.getToken(key));
+        return getLiveNaturalEndpoints(table, partitioner.decorateKey(key));
     }
 
-    public List<InetAddress> getLiveNaturalEndpoints(String table, Token token)
+    public List<InetAddress> getLiveNaturalEndpoints(String table, RingPosition pos)
     {
         List<InetAddress> liveEps = new ArrayList<InetAddress>();
-        List<InetAddress> endpoints = Table.open(table).getReplicationStrategy().getNaturalEndpoints(token);
+        List<InetAddress> endpoints = Table.open(table).getReplicationStrategy().getNaturalEndpoints(pos);
 
         for (InetAddress endpoint : endpoints)
         {
@@ -1898,7 +1898,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
     /**
      * @return list of Tokens (_not_ keys!) breaking up the data this node is responsible for into pieces of roughly keysPerSplit
      */
-    public List<Token> getSplits(String table, String cfName, Range range, int keysPerSplit)
+    public List<Token> getSplits(String table, String cfName, Range<Token> range, int keysPerSplit)
     {
         List<Token> tokens = new ArrayList<Token>();
         // we use the actual Range token for the first and last brackets of the splits to ensure correctness
@@ -1931,7 +1931,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
     /** return a token to which if a node bootstraps it will get about 1/2 of this node's range */
     public Token getBootstrapToken()
     {
-        Range range = getLocalPrimaryRange();
+        Range<Token> range = getLocalPrimaryRange();
         List<DecoratedKey> keys = new ArrayList<DecoratedKey>();
         for (ColumnFamilyStore cfs : ColumnFamilyStore.all())
         {
@@ -2030,11 +2030,11 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
 
     private void unbootstrap(final Runnable onFinish)
     {
-        Map<String, Multimap<Range, InetAddress>> rangesToStream = new HashMap<String, Multimap<Range, InetAddress>>();
+        Map<String, Multimap<Range<Token>, InetAddress>> rangesToStream = new HashMap<String, Multimap<Range<Token>, InetAddress>>();
 
         for (final String table : Schema.instance.getNonSystemTables())
         {
-            Multimap<Range, InetAddress> rangesMM = getChangedRangesForLeaving(table, FBUtilities.getBroadcastAddress());
+            Multimap<Range<Token>, InetAddress> rangesMM = getChangedRangesForLeaving(table, FBUtilities.getBroadcastAddress());
 
             if (logger_.isDebugEnabled())
                 logger_.debug("Ranges needing transfer are [" + StringUtils.join(rangesMM.keySet(), ",") + "]");
@@ -2100,8 +2100,8 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
 
         IEndpointSnitch snitch = DatabaseDescriptor.getEndpointSnitch();
 
-        Map<String, Multimap<InetAddress, Range>> rangesToFetch = new HashMap<String, Multimap<InetAddress, Range>>();
-        Map<String, Multimap<Range, InetAddress>> rangesToStreamByTable = new HashMap<String, Multimap<Range, InetAddress>>();
+        Map<String, Multimap<InetAddress, Range<Token>>> rangesToFetch = new HashMap<String, Multimap<InetAddress, Range<Token>>>();
+        Map<String, Multimap<Range<Token>, InetAddress>> rangesToStreamByTable = new HashMap<String, Multimap<Range<Token>, InetAddress>>();
 
         TokenMetadata tokenMetaClone = tokenMetadata_.cloneAfterAllSettled();
 
@@ -2113,25 +2113,25 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             AbstractReplicationStrategy strategy = Table.open(table).getReplicationStrategy();
 
             // getting collection of the currently used ranges by this keyspace
-            Collection<Range> currentRanges = getRangesForEndpoint(table, localAddress);
+            Collection<Range<Token>> currentRanges = getRangesForEndpoint(table, localAddress);
             // collection of ranges which this node will serve after move to the new token
-            Collection<Range> updatedRanges = strategy.getPendingAddressRanges(tokenMetadata_, newToken, localAddress);
+            Collection<Range<Token>> updatedRanges = strategy.getPendingAddressRanges(tokenMetadata_, newToken, localAddress);
 
             // ring ranges and endpoints associated with them
             // this used to determine what nodes should we ping about range data
-            Multimap<Range, InetAddress> rangeAddresses = strategy.getRangeAddresses(tokenMetadata_);
+            Multimap<Range<Token>, InetAddress> rangeAddresses = strategy.getRangeAddresses(tokenMetadata_);
 
             // calculated parts of the ranges to request/stream from/to nodes in the ring
-            Pair<Set<Range>, Set<Range>> rangesPerTable = calculateStreamAndFetchRanges(currentRanges, updatedRanges);
+            Pair<Set<Range<Token>>, Set<Range<Token>>> rangesPerTable = calculateStreamAndFetchRanges(currentRanges, updatedRanges);
 
             /**
              * In this loop we are going through all ranges "to fetch" and determining
              * nodes in the ring responsible for data we are interested in
              */
-            Multimap<Range, InetAddress> rangesToFetchWithPreferredEndpoints = ArrayListMultimap.create();
-            for (Range toFetch : rangesPerTable.right)
+            Multimap<Range<Token>, InetAddress> rangesToFetchWithPreferredEndpoints = ArrayListMultimap.create();
+            for (Range<Token> toFetch : rangesPerTable.right)
             {
-                for (Range range : rangeAddresses.keySet())
+                for (Range<Token> range : rangeAddresses.keySet())
                 {
                     if (range.contains(toFetch))
                     {
@@ -2144,9 +2144,9 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
 
             // calculating endpoints to stream current ranges to if needed
             // in some situations node will handle current ranges as part of the new ranges
-            Multimap<Range, InetAddress> rangeWithEndpoints = HashMultimap.create();
+            Multimap<Range<Token>, InetAddress> rangeWithEndpoints = HashMultimap.create();
 
-            for (Range toStream : rangesPerTable.left)
+            for (Range<Token> toStream : rangesPerTable.left)
             {
                 Set<InetAddress> currentEndpoints = ImmutableSet.copyOf(strategy.calculateNaturalEndpoints(toStream.right, tokenMetadata_));
                 Set<InetAddress> newEndpoints = ImmutableSet.copyOf(strategy.calculateNaturalEndpoints(toStream.right, tokenMetaClone));
@@ -2156,7 +2156,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             // associating table with range-to-endpoints map
             rangesToStreamByTable.put(table, rangeWithEndpoints);
 
-            Multimap<InetAddress, Range> workMap = BootStrapper.getWorkMap(rangesToFetchWithPreferredEndpoints);
+            Multimap<InetAddress, Range<Token>> workMap = BootStrapper.getWorkMap(rangesToFetchWithPreferredEndpoints);
             rangesToFetch.put(table, workMap);
 
             if (logger_.isDebugEnabled())
@@ -2287,7 +2287,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
 
             // get all ranges that change ownership (that is, a node needs
             // to take responsibility for new range)
-            Multimap<Range, InetAddress> changedRanges = getChangedRangesForLeaving(table, endpoint);
+            Multimap<Range<Token>, InetAddress> changedRanges = getChangedRangesForLeaving(table, endpoint);
             IFailureDetector failureDetector = FailureDetector.instance;
             for (InetAddress ep : changedRanges.values())
             {
@@ -2548,12 +2548,12 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param rangesToStreamByTable tables and data ranges with endpoints included for each
      * @return latch to count down
      */
-    private CountDownLatch streamRanges(final Map<String, Multimap<Range, InetAddress>> rangesToStreamByTable)
+    private CountDownLatch streamRanges(final Map<String, Multimap<Range<Token>, InetAddress>> rangesToStreamByTable)
     {
         final CountDownLatch latch = new CountDownLatch(rangesToStreamByTable.keySet().size());
         for (final String table : rangesToStreamByTable.keySet())
         {
-            Multimap<Range, InetAddress> rangesWithEndpoints = rangesToStreamByTable.get(table);
+            Multimap<Range<Token>, InetAddress> rangesWithEndpoints = rangesToStreamByTable.get(table);
 
             if (rangesWithEndpoints.isEmpty())
             {
@@ -2561,11 +2561,11 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
                 continue;
             }
 
-            final Set<Map.Entry<Range, InetAddress>> pending = new HashSet<Map.Entry<Range, InetAddress>>(rangesWithEndpoints.entries());
+            final Set<Map.Entry<Range<Token>, InetAddress>> pending = new HashSet<Map.Entry<Range<Token>, InetAddress>>(rangesWithEndpoints.entries());
 
-            for (final Map.Entry<Range, InetAddress> entry : rangesWithEndpoints.entries())
+            for (final Map.Entry<Range<Token>, InetAddress> entry : rangesWithEndpoints.entries())
             {
-                final Range range = entry.getKey();
+                final Range<Token> range = entry.getKey();
                 final InetAddress newEndpoint = entry.getValue();
 
                 final Runnable callback = new Runnable()
@@ -2600,12 +2600,12 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param ranges ranges to fetch as map of the preferred address and range collection
      * @return latch to count down
      */
-    private CountDownLatch requestRanges(final Map<String, Multimap<InetAddress, Range>> ranges)
+    private CountDownLatch requestRanges(final Map<String, Multimap<InetAddress, Range<Token>>> ranges)
     {
         final CountDownLatch latch = new CountDownLatch(ranges.keySet().size());
         for (final String table : ranges.keySet())
         {
-            Multimap<InetAddress, Range> endpointWithRanges = ranges.get(table);
+            Multimap<InetAddress, Range<Token>> endpointWithRanges = ranges.get(table);
 
             if (endpointWithRanges.isEmpty())
             {
@@ -2618,7 +2618,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             // Send messages to respective folks to stream data over to me
             for (final InetAddress source: endpointWithRanges.keySet())
             {
-                Collection<Range> toFetch = endpointWithRanges.get(source);
+                Collection<Range<Token>> toFetch = endpointWithRanges.get(source);
 
                 final Runnable callback = new Runnable()
                 {
@@ -2642,7 +2642,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
     }
 
     // see calculateStreamAndFetchRanges(Iterator, Iterator) for description
-    private Pair<Set<Range>, Set<Range>> calculateStreamAndFetchRanges(Collection<Range> current, Collection<Range> updated)
+    private Pair<Set<Range<Token>>, Set<Range<Token>>> calculateStreamAndFetchRanges(Collection<Range<Token>> current, Collection<Range<Token>> updated)
     {
         return calculateStreamAndFetchRanges(current.iterator(), updated.iterator());
     }
@@ -2655,15 +2655,15 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
      * @param updated collection of the ranges after token is changed
      * @return pair of ranges to stream/fetch for given current and updated range collections
      */
-    private Pair<Set<Range>, Set<Range>> calculateStreamAndFetchRanges(Iterator<Range> current, Iterator<Range> updated)
+    private Pair<Set<Range<Token>>, Set<Range<Token>>> calculateStreamAndFetchRanges(Iterator<Range<Token>> current, Iterator<Range<Token>> updated)
     {
-        Set<Range> toStream = new HashSet<Range>();
-        Set<Range> toFetch  = new HashSet<Range>();
+        Set<Range<Token>> toStream = new HashSet<Range<Token>>();
+        Set<Range<Token>> toFetch  = new HashSet<Range<Token>>();
 
         while (current.hasNext() && updated.hasNext())
         {
-            Range r1 = current.next();
-            Range r2 = updated.next();
+            Range<Token> r1 = current.next();
+            Range<Token> r2 = updated.next();
 
             // if ranges intersect we need to fetch only missing part
             if (r1.intersects(r2))
@@ -2676,14 +2676,14 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
                 if (!r2.contains(r1))
                 {
                     // (A, B] & (C, D]
-                    if (Range.compare(r1.left, r2.left) < 0) // if A < C
+                    if (r1.left.compareTo(r2.left) < 0) // if A < C
                     {
-                        toStream.add(new Range(r1.left, r2.left)); // seed (A, C]
+                        toStream.add(new Range<Token>(r1.left, r2.left)); // seed (A, C]
                     }
 
-                    if (Range.compare(r1.right, r2.right) > 0) // if B > D
+                    if (r1.right.compareTo(r2.right) > 0) // if B > D
                     {
-                        toStream.add(new Range(r2.right, r1.right)); // seed (D, B]
+                        toStream.add(new Range<Token>(r2.right, r1.right)); // seed (D, B]
                     }
                 }
             }
@@ -2694,7 +2694,7 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
             }
         }
 
-        return new Pair<Set<Range>, Set<Range>>(toStream, toFetch);
+        return new Pair<Set<Range<Token>>, Set<Range<Token>>>(toStream, toFetch);
     }
 
     public void bulkLoad(String directory)
@@ -2708,9 +2708,9 @@ public class StorageService implements IEndpointStateChangeSubscriber, StorageSe
         {
             public void init(String keyspace)
             {
-                for (Map.Entry<Range, List<InetAddress>> entry : StorageService.instance.getRangeToAddressMap(keyspace).entrySet())
+                for (Map.Entry<Range<Token>, List<InetAddress>> entry : StorageService.instance.getRangeToAddressMap(keyspace).entrySet())
                 {
-                    Range range = entry.getKey();
+                    Range<Token> range = entry.getKey();
                     for (InetAddress endpoint : entry.getValue())
                         addRangeForEndpoint(range, endpoint);
                 }
diff --git a/src/java/org/apache/cassandra/service/StorageServiceMBean.java b/src/java/org/apache/cassandra/service/StorageServiceMBean.java
index 5012c09dc8..0f1dabf868 100644
--- a/src/java/org/apache/cassandra/service/StorageServiceMBean.java
+++ b/src/java/org/apache/cassandra/service/StorageServiceMBean.java
@@ -116,7 +116,7 @@ public interface StorageServiceMBean
      *
      * @return mapping of ranges to end points
      */
-    public Map<Range, List<String>> getRangeToEndpointMap(String keyspace);
+    public Map<Range<Token>, List<String>> getRangeToEndpointMap(String keyspace);
 
     /**
      * Retrieve a map of range to rpc addresses that describe the ring topology
@@ -124,14 +124,14 @@ public interface StorageServiceMBean
      *
      * @return mapping of ranges to rpc addresses
      */
-    public Map<Range, List<String>> getRangeToRpcaddressMap(String keyspace);
+    public Map<Range<Token>, List<String>> getRangeToRpcaddressMap(String keyspace);
 
     /**
      * Retrieve a map of pending ranges to endpoints that describe the ring topology
      * @param keyspace the keyspace to get the pending range map for.
      * @return a map of pending ranges to endpoints
      */
-    public Map<Range, List<String>> getPendingRangeToEndpointMap(String keyspace);
+    public Map<Range<Token>, List<String>> getPendingRangeToEndpointMap(String keyspace);
 
     /**
      * Retrieve a map of tokens to endpoints, including the bootstrapping
diff --git a/src/java/org/apache/cassandra/streaming/StreamIn.java b/src/java/org/apache/cassandra/streaming/StreamIn.java
index 1f76e253af..75a23a22bf 100644
--- a/src/java/org/apache/cassandra/streaming/StreamIn.java
+++ b/src/java/org/apache/cassandra/streaming/StreamIn.java
@@ -37,6 +37,7 @@ import org.slf4j.LoggerFactory;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Table;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.MessagingService;
@@ -52,7 +53,7 @@ public class StreamIn
     private static Logger logger = LoggerFactory.getLogger(StreamIn.class);
 
     /** Request ranges for all column families in the given keyspace. */
-    public static void requestRanges(InetAddress source, String tableName, Collection<Range> ranges, Runnable callback, OperationType type)
+    public static void requestRanges(InetAddress source, String tableName, Collection<Range<Token>> ranges, Runnable callback, OperationType type)
     {
         requestRanges(source, tableName, Table.open(tableName).getColumnFamilyStores(), ranges, callback, type);
     }
@@ -60,7 +61,7 @@ public class StreamIn
     /**
      * Request ranges to be transferred from specific CFs
      */
-    public static void requestRanges(InetAddress source, String tableName, Collection<ColumnFamilyStore> columnFamilies, Collection<Range> ranges, Runnable callback, OperationType type)
+    public static void requestRanges(InetAddress source, String tableName, Collection<ColumnFamilyStore> columnFamilies, Collection<Range<Token>> ranges, Runnable callback, OperationType type)
     {
         assert ranges.size() > 0;
 
diff --git a/src/java/org/apache/cassandra/streaming/StreamOut.java b/src/java/org/apache/cassandra/streaming/StreamOut.java
index 2e5c224fec..517bc0e3bd 100644
--- a/src/java/org/apache/cassandra/streaming/StreamOut.java
+++ b/src/java/org/apache/cassandra/streaming/StreamOut.java
@@ -33,6 +33,7 @@ import org.slf4j.LoggerFactory;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Table;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SSTable;
 import org.apache.cassandra.io.sstable.SSTableReader;
@@ -80,7 +81,7 @@ public class StreamOut
     /**
      * Stream the given ranges to the target endpoint from each CF in the given keyspace.
     */
-    public static void transferRanges(InetAddress target, Table table, Collection<Range> ranges, Runnable callback, OperationType type)
+    public static void transferRanges(InetAddress target, Table table, Collection<Range<Token>> ranges, Runnable callback, OperationType type)
     {
         StreamOutSession session = StreamOutSession.create(table.name, target, callback);
         transferRanges(session, table.getColumnFamilyStores(), ranges, type);
@@ -107,7 +108,7 @@ public class StreamOut
     /**
      * Stream the given ranges to the target endpoint from each of the given CFs.
     */
-    public static void transferRanges(StreamOutSession session, Iterable<ColumnFamilyStore> cfses, Collection<Range> ranges, OperationType type)
+    public static void transferRanges(StreamOutSession session, Iterable<ColumnFamilyStore> cfses, Collection<Range<Token>> ranges, OperationType type)
     {
         assert ranges.size() > 0;
 
@@ -131,7 +132,7 @@ public class StreamOut
      * Low-level transfer of matching portions of a group of sstables from a single table to the target endpoint.
      * You should probably call transferRanges instead. This moreover assumes that references have been acquired on the sstables.
      */
-    public static void transferSSTables(StreamOutSession session, Iterable<SSTableReader> sstables, Collection<Range> ranges, OperationType type) throws IOException
+    public static void transferSSTables(StreamOutSession session, Iterable<SSTableReader> sstables, Collection<Range<Token>> ranges, OperationType type) throws IOException
     {
         List<PendingFile> pending = createPendingFiles(sstables, ranges, type);
 
@@ -142,7 +143,7 @@ public class StreamOut
     }
 
     // called prior to sending anything.
-    private static List<PendingFile> createPendingFiles(Iterable<SSTableReader> sstables, Collection<Range> ranges, OperationType type)
+    private static List<PendingFile> createPendingFiles(Iterable<SSTableReader> sstables, Collection<Range<Token>> ranges, OperationType type)
     {
         List<PendingFile> pending = new ArrayList<PendingFile>();
         for (SSTableReader sstable : sstables)
diff --git a/src/java/org/apache/cassandra/streaming/StreamRequestMessage.java b/src/java/org/apache/cassandra/streaming/StreamRequestMessage.java
index 6e0e37fd14..c5179ba398 100644
--- a/src/java/org/apache/cassandra/streaming/StreamRequestMessage.java
+++ b/src/java/org/apache/cassandra/streaming/StreamRequestMessage.java
@@ -31,6 +31,7 @@ import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Table;
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.FastByteArrayOutputStream;
 import org.apache.cassandra.net.CompactEndpointSerializationHelper;
@@ -67,12 +68,12 @@ class StreamRequestMessage implements MessageProducer
     protected final PendingFile file;
     
     // if these are specified, file shoud not be.
-    protected final Collection<Range> ranges;
+    protected final Collection<Range<Token>> ranges;
     protected final String table;
     protected final Iterable<ColumnFamilyStore> columnFamilies;
     protected final OperationType type;
 
-    StreamRequestMessage(InetAddress target, Collection<Range> ranges, String table, Iterable<ColumnFamilyStore> columnFamilies, long sessionId, OperationType type)
+    StreamRequestMessage(InetAddress target, Collection<Range<Token>> ranges, String table, Iterable<ColumnFamilyStore> columnFamilies, long sessionId, OperationType type)
     {
         this.target = target;
         this.ranges = ranges;
@@ -120,7 +121,7 @@ class StreamRequestMessage implements MessageProducer
             sb.append("@");
             sb.append(target);
             sb.append("------->");
-            for ( Range range : ranges )
+            for ( Range<Token> range : ranges )
             {
                 sb.append(range);
                 sb.append(" ");
@@ -150,9 +151,9 @@ class StreamRequestMessage implements MessageProducer
                 dos.writeBoolean(false);
                 dos.writeUTF(srm.table);
                 dos.writeInt(srm.ranges.size());
-                for (Range range : srm.ranges)
+                for (Range<Token> range : srm.ranges)
                 {
-                    AbstractBounds.serializer().serialize(range, dos);
+                    AbstractBounds.serializer().serialize(range, dos, version);
                 }
 
                 if (version > MessagingService.VERSION_07)
@@ -181,10 +182,10 @@ class StreamRequestMessage implements MessageProducer
             {
                 String table = dis.readUTF();
                 int size = dis.readInt();
-                List<Range> ranges = (size == 0) ? null : new ArrayList<Range>();
+                List<Range<Token>> ranges = (size == 0) ? null : new ArrayList<Range<Token>>();
                 for( int i = 0; i < size; ++i )
                 {
-                    ranges.add((Range) AbstractBounds.serializer().deserialize(dis));
+                    ranges.add((Range<Token>) AbstractBounds.serializer().deserialize(dis, version).toTokenBounds());
                 }
                 OperationType type = OperationType.RESTORE_REPLICA_COUNT;
                 if (version > MessagingService.VERSION_07)
diff --git a/src/java/org/apache/cassandra/streaming/StreamingRepairTask.java b/src/java/org/apache/cassandra/streaming/StreamingRepairTask.java
index 1953886ad5..ab341ed4b1 100644
--- a/src/java/org/apache/cassandra/streaming/StreamingRepairTask.java
+++ b/src/java/org/apache/cassandra/streaming/StreamingRepairTask.java
@@ -32,6 +32,7 @@ import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Table;
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.gms.Gossiper;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.sstable.SSTableReader;
@@ -61,10 +62,10 @@ public class StreamingRepairTask implements Runnable
 
     private final String tableName;
     private final String cfName;
-    private final Collection<Range> ranges;
+    private final Collection<Range<Token>> ranges;
     private final Runnable callback;
 
-    private StreamingRepairTask(UUID id, InetAddress owner, InetAddress src, InetAddress dst, String tableName, String cfName, Collection<Range> ranges, Runnable callback)
+    private StreamingRepairTask(UUID id, InetAddress owner, InetAddress src, InetAddress dst, String tableName, String cfName, Collection<Range<Token>> ranges, Runnable callback)
     {
         this.id = id;
         this.owner = owner;
@@ -76,7 +77,7 @@ public class StreamingRepairTask implements Runnable
         this.callback = callback;
     }
 
-    public static StreamingRepairTask create(InetAddress ep1, InetAddress ep2, String tableName, String cfName, Collection<Range> ranges, Runnable callback)
+    public static StreamingRepairTask create(InetAddress ep1, InetAddress ep2, String tableName, String cfName, Collection<Range<Token>> ranges, Runnable callback)
     {
         InetAddress local = FBUtilities.getBroadcastAddress();
         UUID id = UUIDGen.makeType1UUIDFromHost(local);
@@ -278,9 +279,9 @@ public class StreamingRepairTask implements Runnable
             dos.writeUTF(task.tableName);
             dos.writeUTF(task.cfName);
             dos.writeInt(task.ranges.size());
-            for (Range range : task.ranges)
+            for (Range<Token> range : task.ranges)
             {
-                AbstractBounds.serializer().serialize(range, dos);
+                AbstractBounds.serializer().serialize(range, dos, version);
             }
             // We don't serialize the callback on purpose
         }
@@ -294,10 +295,10 @@ public class StreamingRepairTask implements Runnable
             String tableName = dis.readUTF();
             String cfName = dis.readUTF();
             int rangesCount = dis.readInt();
-            List<Range> ranges = new ArrayList<Range>(rangesCount);
+            List<Range<Token>> ranges = new ArrayList<Range<Token>>(rangesCount);
             for (int i = 0; i < rangesCount; ++i)
             {
-                ranges.add((Range) AbstractBounds.serializer().deserialize(dis));
+                ranges.add((Range<Token>) AbstractBounds.serializer().deserialize(dis, version).toTokenBounds());
             }
             return new StreamingRepairTask(id, owner, src, dst, tableName, cfName, ranges, makeReplyingCallback(owner, id));
         }
diff --git a/src/java/org/apache/cassandra/thrift/CassandraServer.java b/src/java/org/apache/cassandra/thrift/CassandraServer.java
index f9a7096c88..49961ab572 100644
--- a/src/java/org/apache/cassandra/thrift/CassandraServer.java
+++ b/src/java/org/apache/cassandra/thrift/CassandraServer.java
@@ -675,17 +675,17 @@ public class CassandraServer implements Cassandra.Iface
         try
         {
             IPartitioner p = StorageService.getPartitioner();
-            AbstractBounds bounds;
+            AbstractBounds<RowPosition> bounds;
             if (range.start_key == null)
             {
                 Token.TokenFactory tokenFactory = p.getTokenFactory();
                 Token left = tokenFactory.fromString(range.start_token);
                 Token right = tokenFactory.fromString(range.end_token);
-                bounds = new Range(left, right);
+                bounds = Range.makeRowRange(left, right, p);
             }
             else
             {
-                bounds = new Bounds(p.getToken(range.start_key), p.getToken(range.end_key));
+                bounds = new Bounds<RowPosition>(RowPosition.forKey(range.start_key, p), RowPosition.forKey(range.end_key, p));
             }
             schedule(DatabaseDescriptor.getRpcTimeout());
             try
@@ -789,9 +789,9 @@ public class CassandraServer implements Cassandra.Iface
         List<TokenRange> ranges = new ArrayList<TokenRange>();
         Token.TokenFactory tf = StorageService.getPartitioner().getTokenFactory();
 
-        for (Map.Entry<Range, List<InetAddress>> entry : StorageService.instance.getRangeToAddressMap(keyspace).entrySet())
+        for (Map.Entry<Range<Token>, List<InetAddress>> entry : StorageService.instance.getRangeToAddressMap(keyspace).entrySet())
         {
-            Range range = entry.getKey();
+            Range<Token> range = entry.getKey();
             List<String> endpoints = new ArrayList<String>();
             List<String> rpc_endpoints = new ArrayList<String>();
             List<EndpointDetails> epDetails = new ArrayList<EndpointDetails>();
@@ -837,7 +837,7 @@ public class CassandraServer implements Cassandra.Iface
     {
         // TODO: add keyspace authorization call post CASSANDRA-1425
         Token.TokenFactory tf = StorageService.getPartitioner().getTokenFactory();
-        List<Token> tokens = StorageService.instance.getSplits(state().getKeyspace(), cfName, new Range(tf.fromString(start_token), tf.fromString(end_token)), keys_per_split);
+        List<Token> tokens = StorageService.instance.getSplits(state().getKeyspace(), cfName, new Range<Token>(tf.fromString(start_token), tf.fromString(end_token)), keys_per_split);
         List<String> splits = new ArrayList<String>(tokens.size());
         for (Token token : tokens)
         {
diff --git a/src/java/org/apache/cassandra/thrift/ThriftValidation.java b/src/java/org/apache/cassandra/thrift/ThriftValidation.java
index 7103eb3e5b..393f999210 100644
--- a/src/java/org/apache/cassandra/thrift/ThriftValidation.java
+++ b/src/java/org/apache/cassandra/thrift/ThriftValidation.java
@@ -498,7 +498,7 @@ public class ThriftValidation
             IPartitioner p = StorageService.getPartitioner();
             Token startToken = p.getToken(range.start_key);
             Token endToken = p.getToken(range.end_key);
-            if (startToken.compareTo(endToken) > 0 && !endToken.equals(p.getMinimumToken()))
+            if (startToken.compareTo(endToken) > 0 && !endToken.isMinimum(p))
             {
                 if (p instanceof RandomPartitioner)
                     throw new InvalidRequestException("start key's md5 sorts after end key's md5.  this is not allowed; you probably should not specify end key at all, under RandomPartitioner");
diff --git a/src/java/org/apache/cassandra/tools/BulkLoader.java b/src/java/org/apache/cassandra/tools/BulkLoader.java
index 8ec837e328..292a7a112f 100644
--- a/src/java/org/apache/cassandra/tools/BulkLoader.java
+++ b/src/java/org/apache/cassandra/tools/BulkLoader.java
@@ -201,7 +201,7 @@ public class BulkLoader
 
                     for (TokenRange tr : tokenRanges)
                     {
-                        Range range = new Range(tkFactory.fromString(tr.start_token), tkFactory.fromString(tr.end_token));
+                        Range<Token> range = new Range<Token>(tkFactory.fromString(tr.start_token), tkFactory.fromString(tr.end_token));
                         for (String ep : tr.endpoints)
                         {
                             addRangeForEndpoint(range, InetAddress.getByName(ep));
diff --git a/src/java/org/apache/cassandra/utils/FBUtilities.java b/src/java/org/apache/cassandra/utils/FBUtilities.java
index 2cdff22e8c..2b14e1813e 100644
--- a/src/java/org/apache/cassandra/utils/FBUtilities.java
+++ b/src/java/org/apache/cassandra/utils/FBUtilities.java
@@ -398,7 +398,7 @@ public class FBUtilities
         }
     }
 
-    public static void sortSampledKeys(List<DecoratedKey> keys, Range range)
+    public static void sortSampledKeys(List<DecoratedKey> keys, Range<Token> range)
     {
         if (range.left.compareTo(range.right) >= 0)
         {
diff --git a/src/java/org/apache/cassandra/utils/MerkleTree.java b/src/java/org/apache/cassandra/utils/MerkleTree.java
index e8cc0e4a33..fc71be2440 100644
--- a/src/java/org/apache/cassandra/utils/MerkleTree.java
+++ b/src/java/org/apache/cassandra/utils/MerkleTree.java
@@ -71,7 +71,7 @@ public class MerkleTree implements Serializable
      * the request so we can add it back post-deserialization (as for the
      * partitioner).
      */
-    public transient Range fullRange;
+    public transient Range<Token> fullRange;
 
     private transient IPartitioner partitioner;
 
@@ -131,7 +131,7 @@ public class MerkleTree implements Serializable
      *        of the key space covered by each subrange of a fully populated tree.
      * @param maxsize The maximum number of subranges in the tree.
      */
-    public MerkleTree(IPartitioner partitioner, Range range, byte hashdepth, long maxsize)
+    public MerkleTree(IPartitioner partitioner, Range<Token> range, byte hashdepth, long maxsize)
     {
         assert hashdepth < Byte.MAX_VALUE;
         this.fullRange = range;
@@ -359,11 +359,11 @@ public class MerkleTree implements Serializable
      * @return Null if any subrange of the range is invalid, or if the exact
      *         range cannot be calculated using this tree.
      */
-    public byte[] hash(Range range)
+    public byte[] hash(Range<Token> range)
     {
         try
         {
-            return hashHelper(root, new Range(fullRange.left, fullRange.right), range);
+            return hashHelper(root, new Range<Token>(fullRange.left, fullRange.right), range);
         }
         catch (StopRecursion e)
         {
@@ -374,7 +374,7 @@ public class MerkleTree implements Serializable
     /**
      * @throws StopRecursion If no match could be found for the range.
      */
-    private byte[] hashHelper(Hashable hashable, Range active, Range range) throws StopRecursion
+    private byte[] hashHelper(Hashable hashable, Range<Token> active, Range<Token> range) throws StopRecursion
     {
         if (hashable instanceof Leaf)
         {
@@ -386,8 +386,8 @@ public class MerkleTree implements Serializable
         // else: node.
         
         Inner node = (Inner)hashable;
-        Range leftactive = new Range(active.left, node.token);
-        Range rightactive = new Range(node.token, active.right);
+        Range<Token> leftactive = new Range<Token>(active.left, node.token);
+        Range<Token> rightactive = new Range<Token>(node.token, active.right);
 
         if (range.contains(active))
         {
@@ -495,7 +495,7 @@ public class MerkleTree implements Serializable
      * will allow someone to modify the hash. Alternatively, a TreeRange
      * may be created with a null tree, indicating that it is read only.
      */
-    public static class TreeRange extends Range
+    public static class TreeRange extends Range<Token>
     {
         public static final long serialVersionUID = 1L;
         private final MerkleTree tree;
diff --git a/test/unit/org/apache/cassandra/Util.java b/test/unit/org/apache/cassandra/Util.java
index 2d1a3c3dae..c80486e3ab 100644
--- a/test/unit/org/apache/cassandra/Util.java
+++ b/test/unit/org/apache/cassandra/Util.java
@@ -56,6 +56,16 @@ public class Util
         return StorageService.getPartitioner().decorateKey(ByteBufferUtil.bytes(key));
     }
 
+    public static RowPosition rp(String key)
+    {
+        return rp(key, StorageService.getPartitioner());
+    }
+
+    public static RowPosition rp(String key, IPartitioner partitioner)
+    {
+        return RowPosition.forKey(ByteBufferUtil.bytes(key), partitioner);
+    }
+
     public static Column column(String name, String value, long timestamp)
     {
         return new Column(ByteBufferUtil.bytes(name), ByteBufferUtil.bytes(value), timestamp);
@@ -74,19 +84,19 @@ public class Util
         return StorageService.getPartitioner().getToken(ByteBufferUtil.bytes(key));
     }
 
-    public static Range range(String left, String right)
+    public static Range<RowPosition> range(String left, String right)
     {
-        return new Range(token(left), token(right));
+        return new Range<RowPosition>(rp(left), rp(right));
     }
 
-    public static Range range(IPartitioner p, String left, String right)
+    public static Range<RowPosition> range(IPartitioner p, String left, String right)
     {
-        return new Range(p.getToken(ByteBufferUtil.bytes(left)), p.getToken(ByteBufferUtil.bytes(right)));
+        return new Range<RowPosition>(rp(left, p), rp(right, p));
     }
 
-    public static Bounds bounds(String left, String right)
+    public static Bounds<RowPosition> bounds(String left, String right)
     {
-        return new Bounds(token(left), token(right));
+        return new Bounds<RowPosition>(rp(left), rp(right));
     }
 
     public static void addMutation(RowMutation rm, String columnFamilyName, String superColumnName, long columnName, String value, long timestamp)
@@ -121,7 +131,7 @@ public class Util
     {
         Token min = StorageService.getPartitioner().getMinimumToken();
         return cfs.getRangeSlice(superColumn,
-                                 new Bounds(min, min),
+                                 new Bounds<Token>(min, min).toRowBounds(),
                                  10000,
                                  new IdentityQueryFilter());
     }
diff --git a/test/unit/org/apache/cassandra/db/CleanupTest.java b/test/unit/org/apache/cassandra/db/CleanupTest.java
index db8a035400..7edab90f97 100644
--- a/test/unit/org/apache/cassandra/db/CleanupTest.java
+++ b/test/unit/org/apache/cassandra/db/CleanupTest.java
@@ -40,6 +40,7 @@ import org.apache.cassandra.db.index.SecondaryIndex;
 import org.apache.cassandra.dht.BytesToken;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.sstable.SSTableReader;
 import org.apache.cassandra.locator.TokenMetadata;
 import org.apache.cassandra.service.StorageService;
@@ -118,7 +119,7 @@ public class CleanupTest extends CleanupHelper
         IndexClause clause = new IndexClause(Arrays.asList(expr), ByteBufferUtil.EMPTY_BYTE_BUFFER, Integer.MAX_VALUE);
         IFilter filter = new IdentityQueryFilter();
         IPartitioner p = StorageService.getPartitioner();
-        Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
+        Range<RowPosition> range = Util.range("", "");
         rows = table.getColumnFamilyStore(CF1).search(clause, range, filter);
         assertEquals(LOOPS, rows.size());
 
@@ -134,7 +135,7 @@ public class CleanupTest extends CleanupHelper
         CompactionManager.instance.performCleanup(cfs, new NodeId.OneShotRenewer());
 
         // row data should be gone
-        rows = cfs.getRangeSlice(null, Util.range("", ""), 1000, new IdentityQueryFilter());
+        rows = cfs.getRangeSlice(null, range, 1000, new IdentityQueryFilter());
         assertEquals(0, rows.size());
 
         // not only should it be gone but there should be no data on disk, not even tombstones
diff --git a/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java b/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
index a0af4e0042..cf86ed7d5b 100644
--- a/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
+++ b/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
@@ -191,7 +191,7 @@ public class ColumnFamilyStoreTest extends CleanupHelper
         IndexClause clause = new IndexClause(Arrays.asList(expr), ByteBufferUtil.EMPTY_BYTE_BUFFER, 100);
         IFilter filter = new IdentityQueryFilter();
         IPartitioner p = StorageService.getPartitioner();
-        Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
+        Range<RowPosition> range = Util.range("", "");
         List<Row> rows = Table.open("Keyspace1").getColumnFamilyStore("Indexed1").indexManager.search(clause, range, filter);
 
         assert rows != null;
@@ -260,7 +260,7 @@ public class ColumnFamilyStoreTest extends CleanupHelper
         IndexClause clause = new IndexClause(Arrays.asList(expr, expr2), ByteBufferUtil.EMPTY_BYTE_BUFFER, 100);
         IFilter filter = new IdentityQueryFilter();
         IPartitioner p = StorageService.getPartitioner();
-        Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
+        Range<RowPosition> range = Util.range("", "");
         List<Row> rows = Table.open("Keyspace1").getColumnFamilyStore("Indexed1").search(clause, range, filter);
 
         assert rows != null;
@@ -286,7 +286,7 @@ public class ColumnFamilyStoreTest extends CleanupHelper
         IndexClause clause = new IndexClause(Arrays.asList(expr), ByteBufferUtil.EMPTY_BYTE_BUFFER, 100);
         IFilter filter = new IdentityQueryFilter();
         IPartitioner p = StorageService.getPartitioner();
-        Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
+        Range<RowPosition> range = Util.range("", "");
         List<Row> rows = cfs.search(clause, range, filter);
         assert rows.size() == 1 : StringUtils.join(rows, ",");
         String key = ByteBufferUtil.string(rows.get(0).key.key);
@@ -385,7 +385,7 @@ public class ColumnFamilyStoreTest extends CleanupHelper
         IndexClause clause = new IndexClause(Arrays.asList(expr), ByteBufferUtil.EMPTY_BYTE_BUFFER, 100);
         IFilter filter = new IdentityQueryFilter();
         IPartitioner p = StorageService.getPartitioner();
-        Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
+        Range<RowPosition> range = Util.range("", "");
         List<Row> rows = table.getColumnFamilyStore("Indexed1").search(clause, range, filter);
         assert rows.size() == 0;
 
@@ -438,7 +438,7 @@ public class ColumnFamilyStoreTest extends CleanupHelper
         IndexClause clause = new IndexClause(Arrays.asList(new IndexExpression[]{ expr1, expr2 }), ByteBufferUtil.EMPTY_BYTE_BUFFER, 1);
         IFilter filter = new IdentityQueryFilter();
         IPartitioner p = StorageService.getPartitioner();
-        Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
+        Range<RowPosition> range = Util.range("", "");
         List<Row> rows = Table.open("Keyspace1").getColumnFamilyStore("Indexed1").search(clause, range, filter);
 
         assert rows != null;
@@ -483,12 +483,25 @@ public class ColumnFamilyStoreTest extends CleanupHelper
         IndexClause clause = new IndexClause(Arrays.asList(expr), ByteBufferUtil.EMPTY_BYTE_BUFFER, 100);
         IFilter filter = new IdentityQueryFilter();
         IPartitioner p = StorageService.getPartitioner();
-        Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
-        List<Row> rows = table.getColumnFamilyStore("Indexed2").search(clause, range, filter);
+        List<Row> rows = table.getColumnFamilyStore("Indexed2").search(clause, Util.range("", ""), filter);
         assert rows.size() == 1 : StringUtils.join(rows, ",");
         assertEquals("k1", ByteBufferUtil.string(rows.get(0).key.key));
     }
 
+    @Test
+    public void testInclusiveBounds() throws IOException, ExecutionException, InterruptedException
+    {
+        ColumnFamilyStore cfs = insertKey1Key2();
+
+        IPartitioner p = StorageService.getPartitioner();
+        List<Row> result = cfs.getRangeSlice(ByteBufferUtil.EMPTY_BYTE_BUFFER,
+                                             Util.bounds("key1", "key2"),
+                                             10,
+                                             new NamesQueryFilter(ByteBufferUtil.bytes("asdf")));
+        assertEquals(2, result.size());
+        assert result.get(0).key.key.equals(ByteBufferUtil.bytes("key1"));
+    }
+
     @Test
     public void testDeleteSuperRowSticksAfterFlush() throws Throwable
     {
diff --git a/test/unit/org/apache/cassandra/db/KeyCollisionTest.java b/test/unit/org/apache/cassandra/db/KeyCollisionTest.java
new file mode 100644
index 0000000000..f32ffe2cbe
--- /dev/null
+++ b/test/unit/org/apache/cassandra/db/KeyCollisionTest.java
@@ -0,0 +1,212 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.cassandra.db;
+
+import java.io.IOException;
+import java.math.BigDecimal;
+import java.math.BigInteger;
+import java.nio.ByteBuffer;
+import java.nio.charset.CharacterCodingException;
+import java.util.*;
+
+import org.junit.Test;
+
+import org.apache.cassandra.CleanupHelper;
+import org.apache.cassandra.db.columniterator.IdentityQueryFilter;
+import org.apache.cassandra.db.filter.QueryPath;
+import org.apache.cassandra.dht.*;
+import org.apache.cassandra.config.*;
+import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.utils.*;
+import static org.apache.cassandra.Util.dk;
+
+
+/**
+ * Test cases where multiple keys collides, ie have the same token.
+ * Order preserving partitioner have no possible collision and creating
+ * collision for the RandomPartitioner is ... difficult, so we create a dumb
+ * length partitioner that takes the length of the key as token, making
+ * collision easy and predictable.
+ */
+public class KeyCollisionTest extends CleanupHelper
+{
+    IPartitioner oldPartitioner;
+    private static final String KEYSPACE = "Keyspace1";
+    private static final String CF = "Standard1";
+
+    protected void setUp()
+    {
+        oldPartitioner = DatabaseDescriptor.getPartitioner();
+        DatabaseDescriptor.setPartitioner(new LengthPartitioner());
+    }
+
+    protected void tearDown()
+    {
+        DatabaseDescriptor.setPartitioner(oldPartitioner);
+    }
+
+    @Test
+    public void testGetSliceWithCollision() throws Exception
+    {
+        Table table = Table.open(KEYSPACE);
+        ColumnFamilyStore cfs = table.getColumnFamilyStore(CF);
+        cfs.clearUnsafe();
+
+        insert("k1", "k2", "k3");       // token = 2
+        insert("key1", "key2", "key3"); // token = 4
+        insert("longKey1", "longKey2"); // token = 8
+
+        List<Row> rows = cfs.getRangeSlice(null, new Bounds<RowPosition>(dk("k2"), dk("key2")), 10000, new IdentityQueryFilter());
+        assert rows.size() == 4 : "Expecting 4 keys, got " + rows.size();
+        assert rows.get(0).key.key.equals(ByteBufferUtil.bytes("k2"));
+        assert rows.get(1).key.key.equals(ByteBufferUtil.bytes("k3"));
+        assert rows.get(2).key.key.equals(ByteBufferUtil.bytes("key1"));
+        assert rows.get(3).key.key.equals(ByteBufferUtil.bytes("key2"));
+    }
+
+    private void insert(String... keys) throws IOException
+    {
+        for (String key : keys)
+            insert(key);
+    }
+
+    private void insert(String key) throws IOException
+    {
+        RowMutation rm;
+        rm = new RowMutation(KEYSPACE, ByteBufferUtil.bytes(key));
+        rm.add(new QueryPath(CF, null, ByteBufferUtil.bytes("column")), ByteBufferUtil.bytes("asdf"), 0);
+        rm.apply();
+    }
+
+    public static class LengthPartitioner extends AbstractPartitioner<BigIntegerToken>
+    {
+        public static final BigInteger ZERO = new BigInteger("0");
+        public static final BigIntegerToken MINIMUM = new BigIntegerToken("-1");
+
+        private static final byte DELIMITER_BYTE = ":".getBytes()[0];
+
+        public DecoratedKey<BigIntegerToken> decorateKey(ByteBuffer key)
+        {
+            return new DecoratedKey<BigIntegerToken>(getToken(key), key);
+        }
+
+        public DecoratedKey<BigIntegerToken> convertFromDiskFormat(ByteBuffer fromdisk)
+        {
+            throw new UnsupportedOperationException();
+        }
+
+        public Token midpoint(Token ltoken, Token rtoken)
+        {
+            // the symbolic MINIMUM token should act as ZERO: the empty bit array
+            BigInteger left = ltoken.equals(MINIMUM) ? ZERO : ((BigIntegerToken)ltoken).token;
+            BigInteger right = rtoken.equals(MINIMUM) ? ZERO : ((BigIntegerToken)rtoken).token;
+            Pair<BigInteger,Boolean> midpair = FBUtilities.midpoint(left, right, 127);
+            // discard the remainder
+            return new BigIntegerToken(midpair.left);
+        }
+
+        public BigIntegerToken getMinimumToken()
+        {
+            return MINIMUM;
+        }
+
+        public BigIntegerToken getRandomToken()
+        {
+            return new BigIntegerToken(BigInteger.valueOf(new Random().nextInt(15)));
+        }
+
+        private final Token.TokenFactory<BigInteger> tokenFactory = new Token.TokenFactory<BigInteger>() {
+            public ByteBuffer toByteArray(Token<BigInteger> bigIntegerToken)
+            {
+                return ByteBuffer.wrap(bigIntegerToken.token.toByteArray());
+            }
+
+            public Token<BigInteger> fromByteArray(ByteBuffer bytes)
+            {
+                return new BigIntegerToken(new BigInteger(ByteBufferUtil.getArray(bytes)));
+            }
+
+            public String toString(Token<BigInteger> bigIntegerToken)
+            {
+                return bigIntegerToken.token.toString();
+            }
+
+            public Token<BigInteger> fromString(String string)
+            {
+                return new BigIntegerToken(new BigInteger(string));
+            }
+
+            public void validate(String token) {}
+        };
+
+        public Token.TokenFactory<BigInteger> getTokenFactory()
+        {
+            return tokenFactory;
+        }
+
+        public boolean preservesOrder()
+        {
+            return false;
+        }
+
+        public BigIntegerToken getToken(ByteBuffer key)
+        {
+            if (key.remaining() == 0)
+                return MINIMUM;
+            return new BigIntegerToken(BigInteger.valueOf(key.remaining()));
+        }
+
+        public Map<Token, Float> describeOwnership(List<Token> sortedTokens)
+        {
+            // allTokens will contain the count and be returned, sorted_ranges is shorthand for token<->token math.
+            Map<Token, Float> allTokens = new HashMap<Token, Float>();
+            List<Range<Token>> sortedRanges = new ArrayList<Range<Token>>();
+
+            // this initializes the counts to 0 and calcs the ranges in order.
+            Token lastToken = sortedTokens.get(sortedTokens.size() - 1);
+            for (Token node : sortedTokens)
+            {
+                allTokens.put(node, new Float(0.0));
+                sortedRanges.add(new Range<Token>(lastToken, node));
+                lastToken = node;
+            }
+
+            for (String ks : Schema.instance.getTables())
+            {
+                for (CFMetaData cfmd : Schema.instance.getKSMetaData(ks).cfMetaData().values())
+                {
+                    for (Range<Token> r : sortedRanges)
+                    {
+                        // Looping over every KS:CF:Range, get the splits size and add it to the count
+                        allTokens.put(r.right, allTokens.get(r.right) + StorageService.instance.getSplits(ks, cfmd.cfName, r, 1).size());
+                    }
+                }
+            }
+
+            // Sum every count up and divide count/total for the fractional ownership.
+            Float total = new Float(0.0);
+            for (Float f : allTokens.values())
+                total += f;
+            for (Map.Entry<Token, Float> row : allTokens.entrySet())
+                allTokens.put(row.getKey(), row.getValue() / total);
+
+            return allTokens;
+        }
+    }
+}
diff --git a/test/unit/org/apache/cassandra/db/SerializationsTest.java b/test/unit/org/apache/cassandra/db/SerializationsTest.java
index 67575ef5b8..1fa03d8c44 100644
--- a/test/unit/org/apache/cassandra/db/SerializationsTest.java
+++ b/test/unit/org/apache/cassandra/db/SerializationsTest.java
@@ -28,6 +28,7 @@ import org.apache.cassandra.db.filter.QueryPath;
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.MessageSerializer;
 import org.apache.cassandra.net.MessagingService;
@@ -65,7 +66,7 @@ public class SerializationsTest extends AbstractSerializationsTester
         SlicePredicate nonEmptyRangePred = new SlicePredicate();
         nonEmptyRangePred.slice_range = nonEmptySliceRange;
         IPartitioner part = StorageService.getPartitioner();
-        AbstractBounds bounds = new Range(part.getRandomToken(), part.getRandomToken());
+        AbstractBounds<RowPosition> bounds = new Range<Token>(part.getRandomToken(), part.getRandomToken()).toRowBounds();
         
         Message namesCmd = new RangeSliceCommand(Statics.KS, "Standard1", null, namesPred, bounds, 100).getMessage(MessagingService.version_);
         Message emptyRangeCmd = new RangeSliceCommand(Statics.KS, "Standard1", null, emptyRangePred, bounds, 100).getMessage(MessagingService.version_);
diff --git a/test/unit/org/apache/cassandra/dht/AbstractBoundsTest.java b/test/unit/org/apache/cassandra/dht/AbstractBoundsTest.java
index 38d1daf7c8..5e007ac4a0 100644
--- a/test/unit/org/apache/cassandra/dht/AbstractBoundsTest.java
+++ b/test/unit/org/apache/cassandra/dht/AbstractBoundsTest.java
@@ -23,21 +23,23 @@ import static java.util.Arrays.asList;
 
 import org.junit.Test;
 
+import org.apache.cassandra.db.RowPosition;
+import org.apache.cassandra.dht.RingPosition;
 import static org.apache.cassandra.Util.range;
 import static org.apache.cassandra.Util.bounds;
 
 public class AbstractBoundsTest
 {
-    private void assertNormalize(List<? extends AbstractBounds> input, List<? extends AbstractBounds> expected)
+    private <T extends RingPosition> void assertNormalize(List<? extends AbstractBounds<T>> input, List<? extends AbstractBounds<T>> expected)
     {
-        List<AbstractBounds> result = AbstractBounds.normalize(input);
+        List<AbstractBounds<T>> result = AbstractBounds.normalize(input);
         assert result.equals(expected) : "Expecting " + expected + " but got " + result;
     }
 
     @Test
     public void testNormalizeNoop()
     {
-        List<? extends AbstractBounds> l;
+        List<? extends AbstractBounds<RowPosition>> l;
 
         l = asList(range("1", "3"), range("4", "5"));
         assert AbstractBounds.normalize(l).equals(l);
@@ -49,7 +51,7 @@ public class AbstractBoundsTest
     @Test
     public void testNormalizeSimpleOverlap()
     {
-        List<? extends AbstractBounds> input, expected;
+        List<? extends AbstractBounds<RowPosition>> input, expected;
 
         input = asList(range("1", "4"), range("3", "5"));
         expected = asList(range("1", "5"));
@@ -75,7 +77,7 @@ public class AbstractBoundsTest
     @Test
     public void testNormalizeSort()
     {
-        List<? extends AbstractBounds> input, expected;
+        List<? extends AbstractBounds<RowPosition>> input, expected;
 
         input = asList(range("4", "5"), range("1", "3"));
         expected = asList(range("1", "3"), range("4", "5"));
@@ -89,7 +91,7 @@ public class AbstractBoundsTest
     @Test
     public void testNormalizeUnwrap()
     {
-        List<? extends AbstractBounds> input, expected;
+        List<? extends AbstractBounds<RowPosition>> input, expected;
 
         input = asList(range("9", "2"));
         expected = asList(range("", "2"), range("9", ""));
@@ -101,7 +103,7 @@ public class AbstractBoundsTest
     @Test
     public void testNormalizeComplex()
     {
-        List<? extends AbstractBounds> input, expected;
+        List<? extends AbstractBounds<RowPosition>> input, expected;
 
         input = asList(range("8", "2"), range("7", "9"), range("4", "5"));
         expected = asList(range("", "2"), range("4", "5"), range("7", ""));
diff --git a/test/unit/org/apache/cassandra/dht/BootStrapperTest.java b/test/unit/org/apache/cassandra/dht/BootStrapperTest.java
index 1bbc738579..1095dd3c99 100644
--- a/test/unit/org/apache/cassandra/dht/BootStrapperTest.java
+++ b/test/unit/org/apache/cassandra/dht/BootStrapperTest.java
@@ -82,7 +82,7 @@ public class BootStrapperTest extends CleanupHelper
             assert bootstrapSource.equals(addrs[i]) : String.format("expected %s but got %s for %d", addrs[i], bootstrapSource, i);
             assert !ss.getTokenMetadata().getBootstrapTokens().containsValue(bootstrapSource);
             
-            Range range = ss.getPrimaryRangeForEndpoint(bootstrapSource);
+            Range<Token> range = ss.getPrimaryRangeForEndpoint(bootstrapSource);
             Token token = StorageService.getPartitioner().midpoint(range.left, range.right);
             assert range.contains(token);
             ss.onChange(bootstrapAddrs[i], ApplicationState.STATUS, StorageService.instance.valueFactory.bootstrapping(token));
@@ -100,7 +100,7 @@ public class BootStrapperTest extends CleanupHelper
         }
         
         // indicate that one of the nodes is done. see if the node it was bootstrapping from is still available.
-        Range range = ss.getPrimaryRangeForEndpoint(addrs[2]);
+        Range<Token> range = ss.getPrimaryRangeForEndpoint(addrs[2]);
         Token token = StorageService.getPartitioner().midpoint(range.left, range.right);
         ss.onChange(bootstrapAddrs[2], ApplicationState.STATUS, StorageService.instance.valueFactory.normal(token));
         load.put(bootstrapAddrs[2], 0d);
@@ -131,7 +131,7 @@ public class BootStrapperTest extends CleanupHelper
         assert five.equals(source) : five + " != " + source;
 
         InetAddress myEndpoint = InetAddress.getByName("127.0.0.1");
-        Range range5 = ss.getPrimaryRangeForEndpoint(five);
+        Range<Token> range5 = ss.getPrimaryRangeForEndpoint(five);
         Token fakeToken = StorageService.getPartitioner().midpoint(range5.left, range5.right);
         assert range5.contains(fakeToken);
         ss.onChange(myEndpoint, ApplicationState.STATUS, StorageService.instance.valueFactory.bootstrapping(fakeToken));
@@ -165,10 +165,10 @@ public class BootStrapperTest extends CleanupHelper
         TokenMetadata tmd = ss.getTokenMetadata();
         assertEquals(numOldNodes, tmd.sortedTokens().size());
         BootStrapper b = new BootStrapper(myEndpoint, myToken, tmd);
-        Multimap<Range, InetAddress> res = b.getRangesWithSources(table);
+        Multimap<Range<Token>, InetAddress> res = b.getRangesWithSources(table);
         
         int transferCount = 0;
-        for (Map.Entry<Range, Collection<InetAddress>> e : res.asMap().entrySet())
+        for (Map.Entry<Range<Token>, Collection<InetAddress>> e : res.asMap().entrySet())
         {
             assert e.getValue() != null && e.getValue().size() > 0 : StringUtils.join(e.getValue(), ", ");
             transferCount++;
@@ -189,7 +189,7 @@ public class BootStrapperTest extends CleanupHelper
             public void remove(InetAddress ep) { throw new UnsupportedOperationException(); }
             public void clear(InetAddress ep) { throw new UnsupportedOperationException(); }
         };
-        Multimap<InetAddress, Range> temp = BootStrapper.getWorkMap(res, mockFailureDetector);
+        Multimap<InetAddress, Range<Token>> temp = BootStrapper.getWorkMap(res, mockFailureDetector);
         // there isn't any point in testing the size of these collections for any specific size.  When a random partitioner
         // is used, they will vary.
         assert temp.keySet().size() > 0;
diff --git a/test/unit/org/apache/cassandra/dht/PartitionerTestCase.java b/test/unit/org/apache/cassandra/dht/PartitionerTestCase.java
index e7ea6bd788..26708bcbfb 100644
--- a/test/unit/org/apache/cassandra/dht/PartitionerTestCase.java
+++ b/test/unit/org/apache/cassandra/dht/PartitionerTestCase.java
@@ -65,7 +65,7 @@ public abstract class PartitionerTestCase<T extends Token>
     private void assertMidpoint(Token left, Token right, Random rand, int depth)
     {
         Token mid = partitioner.midpoint(left, right);
-        assert new Range(left, right).contains(mid)
+        assert new Range<Token>(left, right).contains(mid)
                 : "For " + left + "," + right + ": range did not contain mid:" + mid;
         if (depth < 1)
             return;
diff --git a/test/unit/org/apache/cassandra/dht/RangeTest.java b/test/unit/org/apache/cassandra/dht/RangeTest.java
index d2c19b5b8d..7c27787320 100644
--- a/test/unit/org/apache/cassandra/dht/RangeTest.java
+++ b/test/unit/org/apache/cassandra/dht/RangeTest.java
@@ -300,17 +300,17 @@ public class RangeTest
         Token t2 = new BytesToken(ByteBuffer.wrap(new byte[] { 1,2,3 }));
         Token t3 = new BytesToken(ByteBuffer.wrap(new byte[]{1, 2, 3, 4}));
 
-        assert Range.compare(t1, t2) == 0;
-        assert Range.compare(t1, t3) == -1;
-        assert Range.compare(t3, t1) == 1;
-        assert Range.compare(t1, t1) == 0;
+        assert t1.compareTo(t2) == 0;
+        assert t1.compareTo(t3) < 0;
+        assert t3.compareTo(t1) > 0;
+        assert t1.compareTo(t1) == 0;
 
         Token t4 = new BytesToken(new byte[] { 1,2,3 });
         Token t5 = new BytesToken(new byte[] { 4,5,6,7 });
 
-        assert Range.compare(t4, t5) < 0;
-        assert Range.compare(t5, t4) > 0;
-        assert Range.compare(t1, t4) == 0;
+        assert t4.compareTo(t5) < 0;
+        assert t5.compareTo(t4) > 0;
+        assert t1.compareTo(t4) == 0;
     }
 
     private Range makeRange(String token1, String token2)
diff --git a/test/unit/org/apache/cassandra/io/CompactSerializerTest.java b/test/unit/org/apache/cassandra/io/CompactSerializerTest.java
index de4c8a32e5..e8e20686dc 100644
--- a/test/unit/org/apache/cassandra/io/CompactSerializerTest.java
+++ b/test/unit/org/apache/cassandra/io/CompactSerializerTest.java
@@ -43,6 +43,7 @@ public class CompactSerializerTest extends CleanupHelper
     {
         expectedClassNames = new HashSet<String>();
         expectedClassNames.add("RangeSliceCommandSerializer");
+        expectedClassNames.add("IndexScanCommandSerializer");
         expectedClassNames.add("ReadCommandSerializer");
         expectedClassNames.add("ReadResponseSerializer");
         expectedClassNames.add("RowSerializer");
@@ -68,6 +69,7 @@ public class CompactSerializerTest extends CleanupHelper
         expectedClassNames.add("CounterMutationSerializer");
         expectedClassNames.add("HashableSerializer");
         expectedClassNames.add("StreamingRepairTaskSerializer");
+        expectedClassNames.add("AbstractBoundsSerializer");
         
         discoveredClassNames = new ArrayList<String>();
         String cp = System.getProperty("java.class.path");
diff --git a/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java b/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
index 83b03fec62..b2e3756092 100644
--- a/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
@@ -72,15 +72,15 @@ public class SSTableReaderTest extends CleanupHelper
         store.forceBlockingFlush();
         CompactionManager.instance.performMaximal(store);
 
-        List<Range> ranges = new ArrayList<Range>();
+        List<Range<Token>> ranges = new ArrayList<Range<Token>>();
         // 1 key
-        ranges.add(new Range(t(0), t(1)));
+        ranges.add(new Range<Token>(t(0), t(1)));
         // 2 keys
-        ranges.add(new Range(t(2), t(4)));
+        ranges.add(new Range<Token>(t(2), t(4)));
         // wrapping range from key to end
-        ranges.add(new Range(t(6), StorageService.getPartitioner().getMinimumToken()));
+        ranges.add(new Range<Token>(t(6), StorageService.getPartitioner().getMinimumToken()));
         // empty range (should be ignored)
-        ranges.add(new Range(t(9), t(91)));
+        ranges.add(new Range<Token>(t(9), t(91)));
 
         // confirm that positions increase continuously
         SSTableReader sstable = store.getSSTables().iterator().next();
@@ -188,9 +188,9 @@ public class SSTableReaderTest extends CleanupHelper
         assert p.right == p7;
     }
 
-    private List<Range> makeRanges(Token left, Token right)
+    private List<Range<Token>> makeRanges(Token left, Token right)
     {
-        return Arrays.asList(new Range[]{ new Range(left, right) });
+        return Arrays.<Range<Token>>asList(new Range[]{ new Range<Token>(left, right) });
     }
 
     private DecoratedKey k(int i)
diff --git a/test/unit/org/apache/cassandra/service/AntiEntropyServiceTestAbstract.java b/test/unit/org/apache/cassandra/service/AntiEntropyServiceTestAbstract.java
index 05546853ed..7eb48428fa 100644
--- a/test/unit/org/apache/cassandra/service/AntiEntropyServiceTestAbstract.java
+++ b/test/unit/org/apache/cassandra/service/AntiEntropyServiceTestAbstract.java
@@ -59,7 +59,7 @@ public abstract class AntiEntropyServiceTestAbstract extends CleanupHelper
     public ColumnFamilyStore store;
     public InetAddress LOCAL, REMOTE;
 
-    public Range local_range;
+    public Range<Token> local_range;
 
     private boolean initialized;
 
@@ -140,7 +140,7 @@ public abstract class AntiEntropyServiceTestAbstract extends CleanupHelper
 
         // confirm that the tree was validated
         Token min = validator.tree.partitioner().getMinimumToken();
-        assert null != validator.tree.hash(new Range(min, min));
+        assert null != validator.tree.hash(new Range<Token>(min, min));
     }
 
     @Test
@@ -166,9 +166,9 @@ public abstract class AntiEntropyServiceTestAbstract extends CleanupHelper
         // generate rf+1 nodes, and ensure that all nodes are returned
         Set<InetAddress> expected = addTokens(1 + Table.open(tablename).getReplicationStrategy().getReplicationFactor());
         expected.remove(FBUtilities.getBroadcastAddress());
-        Collection<Range> ranges = StorageService.instance.getLocalRanges(tablename);
+        Collection<Range<Token>> ranges = StorageService.instance.getLocalRanges(tablename);
         Set<InetAddress> neighbors = new HashSet<InetAddress>();
-        for (Range range : ranges)
+        for (Range<Token> range : ranges)
         {
             neighbors.addAll(AntiEntropyService.getNeighbors(tablename, range));
         }
@@ -184,14 +184,14 @@ public abstract class AntiEntropyServiceTestAbstract extends CleanupHelper
         addTokens(2 * Table.open(tablename).getReplicationStrategy().getReplicationFactor());
         AbstractReplicationStrategy ars = Table.open(tablename).getReplicationStrategy();
         Set<InetAddress> expected = new HashSet<InetAddress>();
-        for (Range replicaRange : ars.getAddressRanges().get(FBUtilities.getBroadcastAddress()))
+        for (Range<Token> replicaRange : ars.getAddressRanges().get(FBUtilities.getBroadcastAddress()))
         {
             expected.addAll(ars.getRangeAddresses(tmd).get(replicaRange));
         }
         expected.remove(FBUtilities.getBroadcastAddress());
-        Collection<Range> ranges = StorageService.instance.getLocalRanges(tablename);
+        Collection<Range<Token>> ranges = StorageService.instance.getLocalRanges(tablename);
         Set<InetAddress> neighbors = new HashSet<InetAddress>();
-        for (Range range : ranges)
+        for (Range<Token> range : ranges)
         {
             neighbors.addAll(AntiEntropyService.getNeighbors(tablename, range));
         }
diff --git a/test/unit/org/apache/cassandra/service/MoveTest.java b/test/unit/org/apache/cassandra/service/MoveTest.java
index 223d020dda..284c201428 100644
--- a/test/unit/org/apache/cassandra/service/MoveTest.java
+++ b/test/unit/org/apache/cassandra/service/MoveTest.java
@@ -184,35 +184,35 @@ public class MoveTest extends CleanupHelper
         *  }
         */
 
-        Multimap<InetAddress, Range> keyspace1ranges = tableStrategyMap.get("Keyspace1").getAddressRanges();
-        Collection<Range> ranges1 = keyspace1ranges.get(InetAddress.getByName("127.0.0.1"));
+        Multimap<InetAddress, Range<Token>> keyspace1ranges = tableStrategyMap.get("Keyspace1").getAddressRanges();
+        Collection<Range<Token>> ranges1 = keyspace1ranges.get(InetAddress.getByName("127.0.0.1"));
         assertEquals(collectionSize(ranges1), 1);
         assertTrue(ranges1.iterator().next().equals(generateRange(92, 0)));
-        Collection<Range> ranges2 = keyspace1ranges.get(InetAddress.getByName("127.0.0.2"));
+        Collection<Range<Token>> ranges2 = keyspace1ranges.get(InetAddress.getByName("127.0.0.2"));
         assertEquals(collectionSize(ranges2), 1);
         assertTrue(ranges2.iterator().next().equals(generateRange(0, 10)));
-        Collection<Range> ranges3 = keyspace1ranges.get(InetAddress.getByName("127.0.0.3"));
+        Collection<Range<Token>> ranges3 = keyspace1ranges.get(InetAddress.getByName("127.0.0.3"));
         assertEquals(collectionSize(ranges3), 1);
         assertTrue(ranges3.iterator().next().equals(generateRange(10, 20)));
-        Collection<Range> ranges4 = keyspace1ranges.get(InetAddress.getByName("127.0.0.4"));
+        Collection<Range<Token>> ranges4 = keyspace1ranges.get(InetAddress.getByName("127.0.0.4"));
         assertEquals(collectionSize(ranges4), 1);
         assertTrue(ranges4.iterator().next().equals(generateRange(20, 30)));
-        Collection<Range> ranges5 = keyspace1ranges.get(InetAddress.getByName("127.0.0.5"));
+        Collection<Range<Token>> ranges5 = keyspace1ranges.get(InetAddress.getByName("127.0.0.5"));
         assertEquals(collectionSize(ranges5), 1);
         assertTrue(ranges5.iterator().next().equals(generateRange(30, 40)));
-        Collection<Range> ranges6 = keyspace1ranges.get(InetAddress.getByName("127.0.0.6"));
+        Collection<Range<Token>> ranges6 = keyspace1ranges.get(InetAddress.getByName("127.0.0.6"));
         assertEquals(collectionSize(ranges6), 1);
         assertTrue(ranges6.iterator().next().equals(generateRange(40, 50)));
-        Collection<Range> ranges7 = keyspace1ranges.get(InetAddress.getByName("127.0.0.7"));
+        Collection<Range<Token>> ranges7 = keyspace1ranges.get(InetAddress.getByName("127.0.0.7"));
         assertEquals(collectionSize(ranges7), 1);
         assertTrue(ranges7.iterator().next().equals(generateRange(50, 62)));
-        Collection<Range> ranges8 = keyspace1ranges.get(InetAddress.getByName("127.0.0.8"));
+        Collection<Range<Token>> ranges8 = keyspace1ranges.get(InetAddress.getByName("127.0.0.8"));
         assertEquals(collectionSize(ranges8), 1);
         assertTrue(ranges8.iterator().next().equals(generateRange(62, 70)));
-        Collection<Range> ranges9 = keyspace1ranges.get(InetAddress.getByName("127.0.0.9"));
+        Collection<Range<Token>> ranges9 = keyspace1ranges.get(InetAddress.getByName("127.0.0.9"));
         assertEquals(collectionSize(ranges9), 1);
         assertTrue(ranges9.iterator().next().equals(generateRange(70, 82)));
-        Collection<Range> ranges10 = keyspace1ranges.get(InetAddress.getByName("127.0.0.10"));
+        Collection<Range<Token>> ranges10 = keyspace1ranges.get(InetAddress.getByName("127.0.0.10"));
         assertEquals(collectionSize(ranges10), 1);
         assertTrue(ranges10.iterator().next().equals(generateRange(82, 92)));
 
@@ -233,7 +233,7 @@ public class MoveTest extends CleanupHelper
         * }
         */
 
-        Multimap<InetAddress, Range> keyspace3ranges = tableStrategyMap.get("Keyspace3").getAddressRanges();
+        Multimap<InetAddress, Range<Token>> keyspace3ranges = tableStrategyMap.get("Keyspace3").getAddressRanges();
         ranges1 = keyspace3ranges.get(InetAddress.getByName("127.0.0.1"));
         assertEquals(collectionSize(ranges1), 5);
         assertTrue(ranges1.equals(generateRanges(92, 0, 70, 82, 50, 62, 82, 92, 62, 70)));
@@ -281,7 +281,7 @@ public class MoveTest extends CleanupHelper
          *      /127.0.0.10=[(70,82], (82,92], (62,70]]
          *  }
          */
-        Multimap<InetAddress, Range> keyspace4ranges = tableStrategyMap.get("Keyspace4").getAddressRanges();
+        Multimap<InetAddress, Range<Token>> keyspace4ranges = tableStrategyMap.get("Keyspace4").getAddressRanges();
         ranges1 = keyspace4ranges.get(InetAddress.getByName("127.0.0.1"));
         assertEquals(collectionSize(ranges1), 3);
         assertTrue(ranges1.equals(generateRanges(92, 0, 70, 82, 82, 92)));
@@ -535,12 +535,12 @@ public class MoveTest extends CleanupHelper
         return count;
     }
 
-    private Collection<Range> generateRanges(int... rangePairs)
+    private Collection<Range<Token>> generateRanges(int... rangePairs)
     {
         if (rangePairs.length % 2 == 1)
             throw new RuntimeException("generateRanges argument count should be even");
 
-        Set<Range> ranges = new HashSet<Range>();
+        Set<Range<Token>> ranges = new HashSet<Range<Token>>();
 
         for (int i = 0; i < rangePairs.length; i+=2)
         {
@@ -550,8 +550,8 @@ public class MoveTest extends CleanupHelper
         return ranges;
     }
 
-    private Range generateRange(int left, int right)
+    private Range<Token> generateRange(int left, int right)
     {
-        return new Range(new BigIntegerToken(String.valueOf(left)), new BigIntegerToken(String.valueOf(right)));
+        return new Range<Token>(new BigIntegerToken(String.valueOf(left)), new BigIntegerToken(String.valueOf(right)));
     }
 }
diff --git a/test/unit/org/apache/cassandra/service/SerializationsTest.java b/test/unit/org/apache/cassandra/service/SerializationsTest.java
index 710e0ecff0..5ee32d5c04 100644
--- a/test/unit/org/apache/cassandra/service/SerializationsTest.java
+++ b/test/unit/org/apache/cassandra/service/SerializationsTest.java
@@ -42,7 +42,7 @@ public class SerializationsTest extends AbstractSerializationsTester
 {
     private static MessageSerializer messageSerializer = new MessageSerializer();
 
-    public static Range FULL_RANGE = new Range(StorageService.getPartitioner().getMinimumToken(), StorageService.getPartitioner().getMinimumToken());
+    public static Range<Token> FULL_RANGE = new Range<Token>(StorageService.getPartitioner().getMinimumToken(), StorageService.getPartitioner().getMinimumToken());
 
     private void testTreeRequestWrite() throws IOException
     {
diff --git a/test/unit/org/apache/cassandra/service/StorageProxyTest.java b/test/unit/org/apache/cassandra/service/StorageProxyTest.java
index 5bb1bfc4e7..6b90d87eb8 100644
--- a/test/unit/org/apache/cassandra/service/StorageProxyTest.java
+++ b/test/unit/org/apache/cassandra/service/StorageProxyTest.java
@@ -26,15 +26,52 @@ import org.junit.Test;
 import static org.junit.Assert.assertEquals;
 
 import org.apache.cassandra.CleanupHelper;
-import static org.apache.cassandra.Util.range;
-import static org.apache.cassandra.Util.bounds;
 import static org.apache.cassandra.Util.token;
+import static org.apache.cassandra.Util.rp;
 
+import org.apache.cassandra.db.DecoratedKey;
+import org.apache.cassandra.db.RowPosition;
 import org.apache.cassandra.dht.AbstractBounds;
+import org.apache.cassandra.dht.Bounds;
+import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.locator.TokenMetadata;
+import org.apache.cassandra.utils.ByteBufferUtil;
+
+import java.util.Arrays;
 
 public class StorageProxyTest extends CleanupHelper
 {
+    private static Range<RowPosition> range(RowPosition left, RowPosition right)
+    {
+        return new Range<RowPosition>(left, right);
+    }
+
+    private static Bounds<RowPosition> bounds(RowPosition left, RowPosition right)
+    {
+        return new Bounds<RowPosition>(left, right);
+    }
+
+    private static RowPosition startOf(String key)
+    {
+        return StorageService.getPartitioner().getToken(ByteBufferUtil.bytes(key)).minKeyBound();
+    }
+
+    private static RowPosition endOf(String key)
+    {
+        return StorageService.getPartitioner().getToken(ByteBufferUtil.bytes(key)).maxKeyBound();
+    }
+
+    private static Range<Token> tokenRange(String left, String right)
+    {
+        return new Range<Token>(token(left), token(right));
+    }
+
+    private static Bounds<Token> tokenBounds(String left, String right)
+    {
+        return new Bounds<Token>(token(left), token(right));
+    }
+
     @BeforeClass
     public static void beforeClass() throws Throwable
     {
@@ -43,72 +80,137 @@ public class StorageProxyTest extends CleanupHelper
         tmd.updateNormalToken(token("6"), InetAddress.getByName("127.0.0.6"));
     }
 
-    private void testGRR(AbstractBounds queryRange, AbstractBounds... expected)
+    // test getRestrictedRanges for token
+    private void testGRR(AbstractBounds<Token> queryRange, AbstractBounds<Token>... expected)
     {
-        List<AbstractBounds> restricted = StorageProxy.getRestrictedRanges(queryRange);
+        // Testing for tokens
+        List<AbstractBounds<Token>> restricted = StorageProxy.getRestrictedRanges(queryRange);
         assertEquals(restricted.toString(), expected.length, restricted.size());
         for (int i = 0; i < expected.length; i++)
             assertEquals("Mismatch for index " + i + ": " + restricted, expected[i], restricted.get(i));
     }
 
+    // test getRestrictedRanges for keys
+    private void testGRRKeys(AbstractBounds<RowPosition> queryRange, AbstractBounds<RowPosition>... expected)
+    {
+        // Testing for keys
+        List<AbstractBounds<RowPosition>> restrictedKeys = StorageProxy.getRestrictedRanges(queryRange);
+        assertEquals(restrictedKeys.toString(), expected.length, restrictedKeys.size());
+        for (int i = 0; i < expected.length; i++)
+            assertEquals("Mismatch for index " + i + ": " + restrictedKeys, expected[i], restrictedKeys.get(i));
+
+    }
+
     @Test
     public void testGRR() throws Throwable
     {
         // no splits
-        testGRR(range("2", "5"), range("2", "5"));
-        testGRR(bounds("2", "5"), bounds("2", "5"));
+        testGRR(tokenRange("2", "5"), tokenRange("2", "5"));
+        testGRR(tokenBounds("2", "5"), tokenBounds("2", "5"));
         // single split
-        testGRR(range("2", "7"), range("2", "6"), range("6", "7"));
-        testGRR(bounds("2", "7"), bounds("2", "6"), range("6", "7"));
+        testGRR(tokenRange("2", "7"), tokenRange("2", "6"), tokenRange("6", "7"));
+        testGRR(tokenBounds("2", "7"), tokenBounds("2", "6"), tokenRange("6", "7"));
         // single split starting from min
-        testGRR(range("", "2"), range("", "1"), range("1", "2"));
-        testGRR(bounds("", "2"), bounds("", "1"), range("1", "2"));
+        testGRR(tokenRange("", "2"), tokenRange("", "1"), tokenRange("1", "2"));
+        testGRR(tokenBounds("", "2"), tokenBounds("", "1"), tokenRange("1", "2"));
         // single split ending with max
-        testGRR(range("5", ""), range("5", "6"), range("6", ""));
-        testGRR(bounds("5", ""), bounds("5", "6"), range("6", ""));
+        testGRR(tokenRange("5", ""), tokenRange("5", "6"), tokenRange("6", ""));
+        testGRR(tokenBounds("5", ""), tokenBounds("5", "6"), tokenRange("6", ""));
         // two splits
-        testGRR(range("0", "7"), range("0", "1"), range("1", "6"), range("6", "7"));
-        testGRR(bounds("0", "7"), bounds("0", "1"), range("1", "6"), range("6", "7"));
+        testGRR(tokenRange("0", "7"), tokenRange("0", "1"), tokenRange("1", "6"), tokenRange("6", "7"));
+        testGRR(tokenBounds("0", "7"), tokenBounds("0", "1"), tokenRange("1", "6"), tokenRange("6", "7"));
+
+
+        // Keys
+        // no splits
+        testGRRKeys(range(rp("2"), rp("5")), range(rp("2"), rp("5")));
+        testGRRKeys(bounds(rp("2"), rp("5")), bounds(rp("2"), rp("5")));
+        // single split testGRRKeys(range("2", "7"), range(rp("2"), endOf("6")), range(endOf("6"), rp("7")));
+        testGRRKeys(bounds(rp("2"), rp("7")), bounds(rp("2"), endOf("6")), range(endOf("6"), rp("7")));
+        // single split starting from min
+        testGRRKeys(range(rp(""), rp("2")), range(rp(""), endOf("1")), range(endOf("1"), rp("2")));
+        testGRRKeys(bounds(rp(""), rp("2")), bounds(rp(""), endOf("1")), range(endOf("1"), rp("2")));
+        // single split ending with max
+        testGRRKeys(range(rp("5"), rp("")), range(rp("5"), endOf("6")), range(endOf("6"), rp("")));
+        testGRRKeys(bounds(rp("5"), rp("")), bounds(rp("5"), endOf("6")), range(endOf("6"), rp("")));
+        // two splits
+        testGRRKeys(range(rp("0"), rp("7")), range(rp("0"), endOf("1")), range(endOf("1"), endOf("6")), range(endOf("6"), rp("7")));
+        testGRRKeys(bounds(rp("0"), rp("7")), bounds(rp("0"), endOf("1")), range(endOf("1"), endOf("6")), range(endOf("6"), rp("7")));
+
     }
 
     @Test
     public void testGRRExact() throws Throwable
     {
         // min
-        testGRR(range("1", "5"), range("1", "5"));
-        testGRR(bounds("1", "5"), bounds("1", "1"), range("1", "5"));
+        testGRR(tokenRange("1", "5"), tokenRange("1", "5"));
+        testGRR(tokenBounds("1", "5"), tokenBounds("1", "1"), tokenRange("1", "5"));
         // max
-        testGRR(range("2", "6"), range("2", "6"));
-        testGRR(bounds("2", "6"), bounds("2", "6"));
+        testGRR(tokenRange("2", "6"), tokenRange("2", "6"));
+        testGRR(tokenBounds("2", "6"), tokenBounds("2", "6"));
         // both
-        testGRR(range("1", "6"), range("1", "6"));
-        testGRR(bounds("1", "6"), bounds("1", "1"), range("1", "6"));
+        testGRR(tokenRange("1", "6"), tokenRange("1", "6"));
+        testGRR(tokenBounds("1", "6"), tokenBounds("1", "1"), tokenRange("1", "6"));
+
+
+        // Keys
+        // min
+        testGRRKeys(range(endOf("1"), endOf("5")), range(endOf("1"), endOf("5")));
+        testGRRKeys(range(rp("1"), endOf("5")), range(rp("1"), endOf("1")), range(endOf("1"), endOf("5")));
+        testGRRKeys(bounds(startOf("1"), endOf("5")), bounds(startOf("1"), endOf("1")), range(endOf("1"), endOf("5")));
+        // max
+        testGRRKeys(range(endOf("2"), endOf("6")), range(endOf("2"), endOf("6")));
+        testGRRKeys(bounds(startOf("2"), endOf("6")), bounds(startOf("2"), endOf("6")));
+        // bothKeys
+        testGRRKeys(range(rp("1"), rp("6")), range(rp("1"), endOf("1")), range(endOf("1"), rp("6")));
+        testGRRKeys(bounds(rp("1"), rp("6")), bounds(rp("1"), endOf("1")), range(endOf("1"), rp("6")));
     }
 
     @Test
     public void testGRRWrapped() throws Throwable
     {
         // one token in wrapped range
-        testGRR(range("7", "0"), range("7", ""), range("", "0"));
+        testGRR(tokenRange("7", "0"), tokenRange("7", ""), tokenRange("", "0"));
         // two tokens in wrapped range
-        testGRR(range("5", "0"), range("5", "6"), range("6", ""), range("", "0"));
-        testGRR(range("7", "2"), range("7", ""), range("", "1"), range("1", "2"));
+        testGRR(tokenRange("5", "0"), tokenRange("5", "6"), tokenRange("6", ""), tokenRange("", "0"));
+        testGRR(tokenRange("7", "2"), tokenRange("7", ""), tokenRange("", "1"), tokenRange("1", "2"));
         // full wraps
-        testGRR(range("0", "0"), range("0", "1"), range("1", "6"), range("6", ""), range("", "0"));
-        testGRR(range("", ""), range("", "1"), range("1", "6"), range("6", ""));
+        testGRR(tokenRange("0", "0"), tokenRange("0", "1"), tokenRange("1", "6"), tokenRange("6", ""), tokenRange("", "0"));
+        testGRR(tokenRange("", ""), tokenRange("", "1"), tokenRange("1", "6"), tokenRange("6", ""));
         // wrap on member tokens
-        testGRR(range("6", "6"), range("6", ""), range("", "1"), range("1", "6"));
-        testGRR(range("6", "1"), range("6", ""), range("", "1"));
+        testGRR(tokenRange("6", "6"), tokenRange("6", ""), tokenRange("", "1"), tokenRange("1", "6"));
+        testGRR(tokenRange("6", "1"), tokenRange("6", ""), tokenRange("", "1"));
         // end wrapped
-        testGRR(range("5", ""), range("5", "6"), range("6", ""));
+        testGRR(tokenRange("5", ""), tokenRange("5", "6"), tokenRange("6", ""));
+
+        // Keys
+        // one token in wrapped range
+        testGRRKeys(range(rp("7"), rp("0")), range(rp("7"), rp("")), range(rp(""), rp("0")));
+        // two tokens in wrapped range
+        testGRRKeys(range(rp("5"), rp("0")), range(rp("5"), endOf("6")), range(endOf("6"), rp("")), range(rp(""), rp("0")));
+        testGRRKeys(range(rp("7"), rp("2")), range(rp("7"), rp("")), range(rp(""), endOf("1")), range(endOf("1"), rp("2")));
+        // full wraps
+        testGRRKeys(range(rp("0"), rp("0")), range(rp("0"), endOf("1")), range(endOf("1"), endOf("6")), range(endOf("6"), rp("")), range(rp(""), rp("0")));
+        testGRRKeys(range(rp(""), rp("")), range(rp(""), endOf("1")), range(endOf("1"), endOf("6")), range(endOf("6"), rp("")));
+        // wrap on member tokens
+        testGRRKeys(range(rp("6"), rp("6")), range(rp("6"), endOf("6")), range(endOf("6"), rp("")), range(rp(""), endOf("1")), range(endOf("1"), rp("6")));
+        testGRRKeys(range(rp("6"), rp("1")), range(rp("6"), endOf("6")), range(endOf("6"), rp("")), range(rp(""), rp("1")));
+        // end wrapped
+        testGRRKeys(range(rp("5"), rp("")), range(rp("5"), endOf("6")), range(endOf("6"), rp("")));
     }
 
     @Test
     public void testGRRExactBounds() throws Throwable
     {
         // equal tokens are special cased as non-wrapping for bounds
-        testGRR(bounds("0", "0"), bounds("0", "0"));
+        testGRR(tokenBounds("0", "0"), tokenBounds("0", "0"));
+        // completely empty bounds match everything
+        testGRR(tokenBounds("", ""), tokenBounds("", "1"), tokenRange("1", "6"), tokenRange("6", ""));
+
+        // Keys
+        // equal tokens are special cased as non-wrapping for bounds
+        testGRRKeys(bounds(rp("0"), rp("0")), bounds(rp("0"), rp("0")));
         // completely empty bounds match everything
-        testGRR(bounds("", ""), bounds("", "1"), range("1", "6"), range("6", ""));
+        testGRRKeys(bounds(rp(""), rp("")), bounds(rp(""), endOf("1")), range(endOf("1"), endOf("6")), range(endOf("6"), rp("")));
     }
 }
diff --git a/test/unit/org/apache/cassandra/streaming/SerializationsTest.java b/test/unit/org/apache/cassandra/streaming/SerializationsTest.java
index 61d12af9e9..fe6becfe87 100644
--- a/test/unit/org/apache/cassandra/streaming/SerializationsTest.java
+++ b/test/unit/org/apache/cassandra/streaming/SerializationsTest.java
@@ -28,6 +28,7 @@ import org.apache.cassandra.db.Table;
 import org.apache.cassandra.db.filter.QueryPath;
 import org.apache.cassandra.dht.BytesToken;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SSTable;
 import org.apache.cassandra.io.sstable.SSTableReader;
@@ -146,9 +147,9 @@ public class SerializationsTest extends AbstractSerializationsTester
     
     private void testStreamRequestMessageWrite() throws IOException
     {
-        Collection<Range> ranges = new ArrayList<Range>();
+        Collection<Range<Token>> ranges = new ArrayList<Range<Token>>();
         for (int i = 0; i < 5; i++)
-            ranges.add(new Range(new BytesToken(ByteBufferUtil.bytes(Integer.toString(10*i))), new BytesToken(ByteBufferUtil.bytes(Integer.toString(10*i+5)))));
+            ranges.add(new Range<Token>(new BytesToken(ByteBufferUtil.bytes(Integer.toString(10*i))), new BytesToken(ByteBufferUtil.bytes(Integer.toString(10*i+5)))));
         List<ColumnFamilyStore> stores = Collections.singletonList(Table.open("Keyspace1").getColumnFamilyStore("Standard1"));
         StreamRequestMessage msg0 = new StreamRequestMessage(FBUtilities.getBroadcastAddress(), ranges, "Keyspace1", stores, 123L, OperationType.RESTORE_REPLICA_COUNT);
         StreamRequestMessage msg1 = new StreamRequestMessage(FBUtilities.getBroadcastAddress(), makePendingFile(true, 100, OperationType.BOOTSTRAP), 124L);
diff --git a/test/unit/org/apache/cassandra/streaming/StreamingTransferTest.java b/test/unit/org/apache/cassandra/streaming/StreamingTransferTest.java
index ca0c5b3958..4a245c28bd 100644
--- a/test/unit/org/apache/cassandra/streaming/StreamingTransferTest.java
+++ b/test/unit/org/apache/cassandra/streaming/StreamingTransferTest.java
@@ -36,6 +36,7 @@ import org.apache.cassandra.db.filter.QueryFilter;
 import org.apache.cassandra.db.filter.QueryPath;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.io.sstable.SSTableUtils;
 import org.apache.cassandra.io.sstable.SSTableReader;
 import org.apache.cassandra.service.StorageService;
@@ -116,9 +117,9 @@ public class StreamingTransferTest extends CleanupHelper
     private void transfer(Table table, SSTableReader sstable) throws Exception
     {
         IPartitioner p = StorageService.getPartitioner();
-        List<Range> ranges = new ArrayList<Range>();
-        ranges.add(new Range(p.getMinimumToken(), p.getToken(ByteBufferUtil.bytes("key1"))));
-        ranges.add(new Range(p.getToken(ByteBufferUtil.bytes("key2")), p.getMinimumToken()));
+        List<Range<Token>> ranges = new ArrayList<Range<Token>>();
+        ranges.add(new Range<Token>(p.getMinimumToken(), p.getToken(ByteBufferUtil.bytes("key1"))));
+        ranges.add(new Range<Token>(p.getToken(ByteBufferUtil.bytes("key2")), p.getMinimumToken()));
         StreamOutSession session = StreamOutSession.create(table.name, LOCAL, null);
         StreamOut.transferSSTables(session, Arrays.asList(sstable), ranges, OperationType.BOOTSTRAP);
         session.await();
@@ -155,7 +156,7 @@ public class StreamingTransferTest extends CleanupHelper
                                                        ByteBufferUtil.bytes(val));
             IndexClause clause = new IndexClause(Arrays.asList(expr), ByteBufferUtil.EMPTY_BYTE_BUFFER, 100);
             IFilter filter = new IdentityQueryFilter();
-            Range range = new Range(p.getMinimumToken(), p.getMinimumToken());
+            Range<RowPosition> range = Util.range("", "");
             List<Row> rows = cfs.search(clause, range, filter);
             assertEquals(1, rows.size());
             assert rows.get(0).key.key.equals(ByteBufferUtil.bytes(key));
@@ -255,9 +256,9 @@ public class StreamingTransferTest extends CleanupHelper
 
         // transfer the first and last key
         IPartitioner p = StorageService.getPartitioner();
-        List<Range> ranges = new ArrayList<Range>();
-        ranges.add(new Range(p.getMinimumToken(), p.getToken(ByteBufferUtil.bytes("test"))));
-        ranges.add(new Range(p.getToken(ByteBufferUtil.bytes("transfer2")), p.getMinimumToken()));
+        List<Range<Token>> ranges = new ArrayList<Range<Token>>();
+        ranges.add(new Range<Token>(p.getMinimumToken(), p.getToken(ByteBufferUtil.bytes("test"))));
+        ranges.add(new Range<Token>(p.getToken(ByteBufferUtil.bytes("transfer2")), p.getMinimumToken()));
         // Acquiring references, transferSSTables needs it
         sstable.acquireReference();
         sstable2.acquireReference();
@@ -308,10 +309,10 @@ public class StreamingTransferTest extends CleanupHelper
         Map.Entry<DecoratedKey,String> first = keys.firstEntry();
         Map.Entry<DecoratedKey,String> last = keys.lastEntry();
         Map.Entry<DecoratedKey,String> secondtolast = keys.lowerEntry(last.getKey());
-        List<Range> ranges = new ArrayList<Range>();
-        ranges.add(new Range(p.getMinimumToken(), first.getKey().token));
+        List<Range<Token>> ranges = new ArrayList<Range<Token>>();
+        ranges.add(new Range<Token>(p.getMinimumToken(), first.getKey().token));
         // the left hand side of the range is exclusive, so we transfer from the second-to-last token
-        ranges.add(new Range(secondtolast.getKey().token, p.getMinimumToken()));
+        ranges.add(new Range<Token>(secondtolast.getKey().token, p.getMinimumToken()));
 
         // Acquiring references, transferSSTables needs it
         if (!SSTableReader.acquireReferences(ssTableReaders))
