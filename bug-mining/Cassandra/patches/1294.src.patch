diff --git a/CHANGES.txt b/CHANGES.txt
index 25b32c4153..c307e313a7 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -6,6 +6,7 @@
  * record partitioner in sstable metadata component (CASSANDRA-3407)
  * add new upgradesstables nodetool command (CASSANDRA-3406)
  * skip --debug requirement to see common exceptions in CLI (CASSANDRA-3508)
+ * fix incorrect query results due to invalid max timestamp (CASSANDRA-3510)
 
 1.0.3
  * revert name-based query defragmentation aka CASSANDRA-2503 (CASSANDRA-3491)
diff --git a/src/java/org/apache/cassandra/db/CollationController.java b/src/java/org/apache/cassandra/db/CollationController.java
index dd685afa4f..0d14508006 100644
--- a/src/java/org/apache/cassandra/db/CollationController.java
+++ b/src/java/org/apache/cassandra/db/CollationController.java
@@ -170,7 +170,8 @@ public class CollationController
         AbstractColumnContainer container = filter.path.superColumnName == null
                                           ? returnCF
                                           : (SuperColumn) returnCF.getColumn(filter.path.superColumnName);
-        if (container == null)
+        // MIN_VALUE means we don't know any information
+        if (container == null || sstableTimestamp == Long.MIN_VALUE)
             return;
 
         for (Iterator<ByteBuffer> iterator = ((NamesQueryFilter) filter.filter).columns.iterator(); iterator.hasNext(); )
diff --git a/src/java/org/apache/cassandra/db/EchoedRow.java b/src/java/org/apache/cassandra/db/EchoedRow.java
index b01f0a21da..09312dcfd7 100644
--- a/src/java/org/apache/cassandra/db/EchoedRow.java
+++ b/src/java/org/apache/cassandra/db/EchoedRow.java
@@ -73,6 +73,6 @@ public class EchoedRow extends AbstractCompactedRow
 
     public long maxTimestamp()
     {
-        throw new UnsupportedOperationException();
+        return Long.MIN_VALUE;
     }
 }
diff --git a/src/java/org/apache/cassandra/db/compaction/AbstractCompactedRow.java b/src/java/org/apache/cassandra/db/compaction/AbstractCompactedRow.java
index 9c730708c9..1499e448be 100644
--- a/src/java/org/apache/cassandra/db/compaction/AbstractCompactedRow.java
+++ b/src/java/org/apache/cassandra/db/compaction/AbstractCompactedRow.java
@@ -69,7 +69,9 @@ public abstract class AbstractCompactedRow
     public abstract int columnCount();
 
     /**
-     * @return the max column timestamp in the row
+     * @return the max column timestamp in the row or Long.MIN_VALUE if
+     * computing this value would require extra effort we're not willing to
+     * make.
      */
     public abstract long maxTimestamp();
 }
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java b/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java
index d785765852..22e8ac4e46 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java
@@ -160,8 +160,14 @@ public class SSTableWriter extends SSTable
         long dataSize = row.write(dataFile.stream);
         assert dataSize == dataFile.getFilePointer() - (dataStart + 8)
                 : "incorrect row data size " + dataSize + " written to " + dataFile.getPath() + "; correct is " + (dataFile.getFilePointer() - (dataStart + 8));
-        // max timestamp is not collected here, because we want to avoid deserializing an EchoedRow
-        // instead, it is collected when calling ColumnFamilyStore.createCompactionWriter
+        /*
+         * The max timestamp is not always collected here (more precisely, row.maxTimestamp() may return Long.MIN_VALUE),
+         * to avoid deserializing an EchoedRow.
+         * This is the reason why it is collected first when calling ColumnFamilyStore.createCompactionWriter
+         * However, for old sstables without timestamp, we still want to update the timestamp (and we know
+         * that in this case we will not use EchoedRow, since CompactionControler.needsDeserialize() will be true).
+        */
+        sstableMetadataCollector.updateMaxTimestamp(row.maxTimestamp());
         sstableMetadataCollector.addRowSize(dataFile.getFilePointer() - currentPosition);
         sstableMetadataCollector.addColumnCount(row.columnCount());
         afterAppend(row.key, currentPosition);
diff --git a/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java b/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
index 43e1631dde..a0af4e0042 100644
--- a/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
+++ b/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
@@ -41,6 +41,7 @@ import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SSTableReader;
+import org.apache.cassandra.io.sstable.SSTable;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.thrift.*;
 import org.apache.cassandra.utils.ByteBufferUtil;
@@ -737,4 +738,38 @@ public class ColumnFamilyStoreTest extends CleanupHelper
         assertEquals(ByteBufferUtil.bytes("A"), columnSliced.getSubColumn(ByteBufferUtil.bytes("a")).value());
         assertEquals(ByteBufferUtil.bytes("B"), columnSliced.getSubColumn(ByteBufferUtil.bytes("b")).value());
     }
+
+    @Test
+    public void testSliceByNamesCommandOldMetatada() throws Throwable
+    {
+        String tableName = "Keyspace1";
+        String cfName= "Standard1";
+        DecoratedKey key = Util.dk("slice-name-old-metadata");
+        ByteBuffer cname = ByteBufferUtil.bytes("c1");
+        Table table = Table.open(tableName);
+        ColumnFamilyStore cfs = table.getColumnFamilyStore(cfName);
+        cfs.clearUnsafe();
+
+        // Create a column a 'high timestamp'
+        putColsStandard(cfs, key, new Column(cname, ByteBufferUtil.bytes("a"), 2));
+        cfs.forceBlockingFlush();
+
+        // Nuke the metadata and reload that sstable
+        Collection<SSTableReader> ssTables = cfs.getSSTables();
+        assertEquals(1, ssTables.size());
+        cfs.clearUnsafe();
+        assertEquals(0, cfs.getSSTables().size());
+
+        new File(ssTables.iterator().next().descriptor.filenameFor(SSTable.COMPONENT_STATS)).delete();
+        cfs.loadNewSSTables();
+
+        // Add another column with a lower timestamp
+        putColsStandard(cfs, key, new Column(cname, ByteBufferUtil.bytes("b"), 1));
+
+        // Test fetching the column by name returns the first column
+        SliceByNamesReadCommand cmd = new SliceByNamesReadCommand(tableName, key.key, new QueryPath(cfName), Collections.singletonList(cname));
+        ColumnFamily cf = cmd.getRow(table).cf;
+        Column column = (Column) cf.getColumn(cname);
+        assert column.value().equals(ByteBufferUtil.bytes("a")) : "expecting a, got " + ByteBufferUtil.string(column.value());
+    }
 }
