diff --git a/CHANGES.txt b/CHANGES.txt
index 29d6b9fec9..0993ba5ab6 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,4 +1,5 @@
 3.11.10
+ * Fix digest computation for queries with fetched but non queried columns (CASSANDRA-15962)
  * Reduce amount of allocations during batch statement execution (CASSANDRA-16201)
  * Update jflex-1.6.0.jar to match upstream (CASSANDRA-16393)
  * Fix DecimalDeserializer#toString OOM (CASSANDRA-14925)
diff --git a/src/java/org/apache/cassandra/db/rows/BTreeRow.java b/src/java/org/apache/cassandra/db/rows/BTreeRow.java
index ba81a4eb72..7540c110d8 100644
--- a/src/java/org/apache/cassandra/db/rows/BTreeRow.java
+++ b/src/java/org/apache/cassandra/db/rows/BTreeRow.java
@@ -311,8 +311,14 @@ public class BTreeRow extends AbstractRow
             // is lower than the row timestamp (see #10657 or SerializationHelper.includes() for details).
             boolean isForDropped = dropped != null && cell.timestamp() <= dropped.droppedTime;
             boolean isShadowed = mayHaveShadowed && activeDeletion.deletes(cell);
-            boolean isSkippable = !queriedByUserTester.test(column) && cell.timestamp() < rowLiveness.timestamp();
-            return isForDropped || isShadowed || isSkippable ? null : cell;
+            boolean isSkippable = !queriedByUserTester.test(column);
+
+            if (isForDropped || isShadowed || (isSkippable && cell.timestamp() < rowLiveness.timestamp()))
+                return null;
+
+            // We should apply the same "optimization" as in Cell.deserialize to avoid discrepances
+            // between sstables and memtables data, i.e resulting in a digest mismatch.
+            return isSkippable ? cell.withSkippedValue() : cell;
         });
     }
 
diff --git a/src/java/org/apache/cassandra/db/rows/BufferCell.java b/src/java/org/apache/cassandra/db/rows/BufferCell.java
index b62d95aaec..e445049188 100644
--- a/src/java/org/apache/cassandra/db/rows/BufferCell.java
+++ b/src/java/org/apache/cassandra/db/rows/BufferCell.java
@@ -120,6 +120,11 @@ public class BufferCell extends AbstractCell
         return new BufferCell(column, newTimestamp, ttl, newLocalDeletionTime, value, path);
     }
 
+    public Cell withSkippedValue()
+    {
+        return withUpdatedValue(ByteBufferUtil.EMPTY_BYTE_BUFFER);
+    }
+
     public Cell copy(AbstractAllocator allocator)
     {
         if (!value.hasRemaining())
diff --git a/src/java/org/apache/cassandra/db/rows/Cell.java b/src/java/org/apache/cassandra/db/rows/Cell.java
index 1205b7d801..9e59246d7c 100644
--- a/src/java/org/apache/cassandra/db/rows/Cell.java
+++ b/src/java/org/apache/cassandra/db/rows/Cell.java
@@ -144,6 +144,13 @@ public abstract class Cell extends ColumnData
 
     public abstract Cell withUpdatedTimestampAndLocalDeletionTime(long newTimestamp, int newLocalDeletionTime);
 
+    /**
+     * Used to apply the same optimization as in {@link Cell.Serializer#deserialize} when
+     * the column is not queried but eventhough it's used for digest calculation.
+     * @return a cell with an empty buffer as value
+     */
+    public abstract Cell withSkippedValue();
+
     public abstract Cell copy(AbstractAllocator allocator);
 
     @Override
diff --git a/src/java/org/apache/cassandra/db/rows/ComplexColumnData.java b/src/java/org/apache/cassandra/db/rows/ComplexColumnData.java
index 1395782c9a..2dea16292f 100644
--- a/src/java/org/apache/cassandra/db/rows/ComplexColumnData.java
+++ b/src/java/org/apache/cassandra/db/rows/ComplexColumnData.java
@@ -146,17 +146,24 @@ public class ComplexColumnData extends ColumnData implements Iterable<Cell>
     public ComplexColumnData filter(ColumnFilter filter, DeletionTime activeDeletion, CFMetaData.DroppedColumn dropped, LivenessInfo rowLiveness)
     {
         ColumnFilter.Tester cellTester = filter.newTester(column);
-        if (cellTester == null && activeDeletion.isLive() && dropped == null)
+        boolean isQueriedColumn = filter.fetchedColumnIsQueried(column);
+        if (cellTester == null && activeDeletion.isLive() && dropped == null && isQueriedColumn)
             return this;
 
         DeletionTime newDeletion = activeDeletion.supersedes(complexDeletion) ? DeletionTime.LIVE : complexDeletion;
         return transformAndFilter(newDeletion, (cell) ->
         {
+            CellPath path = cell.path();
             boolean isForDropped = dropped != null && cell.timestamp() <= dropped.droppedTime;
             boolean isShadowed = activeDeletion.deletes(cell);
-            boolean isSkippable = cellTester != null && (!cellTester.fetches(cell.path())
-                                                         || (!cellTester.fetchedCellIsQueried(cell.path()) && cell.timestamp() < rowLiveness.timestamp()));
-            return isForDropped || isShadowed || isSkippable ? null : cell;
+            boolean isFetchedCell = cellTester == null || cellTester.fetches(path);
+            boolean isQueriedCell = isQueriedColumn && isFetchedCell && (cellTester == null || cellTester.fetchedCellIsQueried(path));
+            boolean isSkippableCell = !isFetchedCell || (!isQueriedCell && cell.timestamp() < rowLiveness.timestamp());
+            if (isForDropped || isShadowed || isSkippableCell)
+                return null;
+            // We should apply the same "optimization" as in Cell.deserialize to avoid discrepances
+            // between sstables and memtables data, i.e resulting in a digest mismatch.
+            return isQueriedCell ? cell : cell.withSkippedValue();
         });
     }
 
diff --git a/src/java/org/apache/cassandra/db/rows/NativeCell.java b/src/java/org/apache/cassandra/db/rows/NativeCell.java
index 31ce0b7700..1f8c258785 100644
--- a/src/java/org/apache/cassandra/db/rows/NativeCell.java
+++ b/src/java/org/apache/cassandra/db/rows/NativeCell.java
@@ -21,6 +21,7 @@ import java.nio.ByteBuffer;
 import java.nio.ByteOrder;
 
 import org.apache.cassandra.config.ColumnDefinition;
+import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.ObjectSizes;
 import org.apache.cassandra.utils.concurrent.OpOrder;
 import org.apache.cassandra.utils.memory.MemoryUtil;
@@ -153,6 +154,11 @@ public class NativeCell extends AbstractCell
         return new BufferCell(column, timestamp(), ttl(), localDeletionTime(), value(), path());
     }
 
+    public Cell withSkippedValue()
+    {
+        return new BufferCell(column, timestamp(), ttl(), localDeletionTime(), ByteBufferUtil.EMPTY_BYTE_BUFFER, path());
+    }
+
     public long unsharedHeapSizeExcludingData()
     {
         return EMPTY_SIZE;
diff --git a/test/unit/org/apache/cassandra/db/SSTableAndMemTableDigestMatchTest.java b/test/unit/org/apache/cassandra/db/SSTableAndMemTableDigestMatchTest.java
new file mode 100644
index 0000000000..54ed80b800
--- /dev/null
+++ b/test/unit/org/apache/cassandra/db/SSTableAndMemTableDigestMatchTest.java
@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.db;
+
+import java.nio.ByteBuffer;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.NavigableSet;
+import java.util.function.Function;
+
+import com.google.common.collect.Sets;
+import org.junit.Test;
+
+import com.sun.xml.internal.xsom.impl.scd.Iterators;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.cql3.ColumnIdentifier;
+import org.apache.cassandra.db.filter.ClusteringIndexNamesFilter;
+import org.apache.cassandra.db.filter.ColumnFilter;
+import org.apache.cassandra.db.marshal.Int32Type;
+import org.apache.cassandra.db.marshal.IntegerType;
+import org.apache.cassandra.db.partitions.SingletonUnfilteredPartitionIterator;
+import org.apache.cassandra.db.rows.CellPath;
+import org.apache.cassandra.db.rows.UnfilteredRowIterator;
+import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.utils.ByteBufferUtil;
+
+import static org.junit.Assert.assertEquals;
+
+public class SSTableAndMemTableDigestMatchTest extends CQLTester
+{
+    private final static long writeTime = System.currentTimeMillis() * 1000L;
+
+    @Test
+    public void testSelectAllColumns() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.all(cfs.metadata));
+    }
+
+    @Test
+    public void testSelectNoColumns() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selection(cfs.metadata, PartitionColumns.NONE));
+    }
+
+    @Test
+    public void testSelectEmptyColumn() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selection(cfs.metadata, PartitionColumns.of(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("e", false)))));
+    }
+
+    @Test
+    public void testSelectNonEmptyColumn() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selection(cfs.metadata, PartitionColumns.of(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("v1", false)))));
+    }
+
+    @Test
+    public void testSelectEachNonEmptyColumn() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selection(cfs.metadata,
+                                                     PartitionColumns.builder()
+                                                                     .add(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("v1", false)))
+                                                                     .add(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("v2", false)))
+                                                                     .add(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("m", false)))
+                                                                     .build()));
+    }
+
+    @Test
+    public void testSelectEmptyComplexColumn() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selection(cfs.metadata,
+                                                     PartitionColumns.builder()
+                                                                     .add(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("em", false)))
+                                                                     .build()));
+    }
+
+    @Test
+    public void testSelectCellsFromEmptyComplexColumn() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selectionBuilder()
+                                          .select(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("em", false)),
+                                                  CellPath.create(Int32Type.instance.decompose(5))).build());
+    }
+
+    @Test
+    public void testSelectNonEmptyCellsFromComplexColumn() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selectionBuilder()
+                                          .select(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("m", false)),
+                                                  CellPath.create(Int32Type.instance.decompose(1))).build());
+    }
+
+    @Test
+    public void testSelectEmptyCellsFromNonEmptyComplexColumn() throws Throwable
+    {
+        testWithFilter(cfs -> ColumnFilter.selectionBuilder()
+                                          .select(cfs.metadata.getColumnDefinition(ColumnIdentifier.getInterned("m", false)),
+                                                  CellPath.create(Int32Type.instance.decompose(5))).build());
+    }
+
+    private void testWithFilter(Function<ColumnFamilyStore, ColumnFilter> filterFactory) throws Throwable
+    {
+        Map<Integer, Integer> m = new HashMap<>();
+        m.put(1, 10);
+        createTable("CREATE TABLE %s (k int PRIMARY KEY, v1 int, v2 int, e text, m map<int, int>, em map<int, int>)");
+        execute("INSERT INTO %s (k, v1, v2, m) values (?, ?, ?, ?) USING TIMESTAMP ?", 1, 2, 3, m, writeTime);
+
+        ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
+        ColumnFilter filter = filterFactory.apply(cfs);
+        String digest1 = getDigest(filter);
+        flush();
+        String digest2 = getDigest(filter);
+
+        assertEquals(digest1, digest2);
+    }
+
+    private String getDigest(ColumnFilter filter)
+    {
+        ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
+        NavigableSet<Clustering> clusterings = Sets.newTreeSet(new ClusteringComparator());
+        clusterings.add(Clustering.EMPTY);
+        BufferDecoratedKey key = new BufferDecoratedKey(DatabaseDescriptor.getPartitioner().getToken(Int32Type.instance.decompose(1)),
+                                                        Int32Type.instance.decompose(1));
+        SinglePartitionReadCommand cmd = SinglePartitionReadCommand
+                                         .create(cfs.metadata,
+                                                 (int) (System.currentTimeMillis() / 1000),
+                                                 key,
+                                                 filter,
+                                                 new ClusteringIndexNamesFilter(clusterings, false)).copyAsDigestQuery();
+        cmd.setDigestVersion(MessagingService.current_version);
+        ReadResponse resp;
+        try (ReadExecutionController ctrl = ReadExecutionController.forCommand(cmd); UnfilteredRowIterator iterator = cmd.queryMemtableAndDisk(cfs, ctrl))
+        {
+            resp = ReadResponse.createDataResponse(new SingletonUnfilteredPartitionIterator(iterator, false), cmd);
+            logger.info("Response is: {}", resp.toDebugString(cmd, key));
+            ByteBuffer digest = resp.digest(cmd);
+            return ByteBufferUtil.bytesToHex(digest);
+        }
+    }
+}
\ No newline at end of file
