diff --git a/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java b/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java
index eee992ef75..4f567cb95f 100644
--- a/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java
@@ -38,8 +38,6 @@ import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Iterables;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
 
 import accord.api.Key;
 import accord.primitives.Keys;
@@ -96,8 +94,6 @@ import static org.apache.cassandra.service.accord.txn.TxnResult.Kind.retry_new_p
 
 public class TransactionStatement implements CQLStatement.CompositeCQLStatement, CQLStatement.ReturningCQLStatement
 {
-    private static final Logger logger = LoggerFactory.getLogger(TransactionStatement.class);
-
     public static final String DUPLICATE_TUPLE_NAME_MESSAGE = "The name '%s' has already been used by a LET assignment.";
     public static final String INCOMPLETE_PARTITION_KEY_SELECT_MESSAGE = "SELECT must specify either all partition key elements. Partition key elements must be always specified with equality operators; %s %s";
     public static final String INCOMPLETE_PRIMARY_KEY_SELECT_MESSAGE = "SELECT must specify either all primary key elements or all partition key elements and LIMIT 1. In both cases partition key elements must be always specified with equality operators; %s %s";
@@ -381,82 +377,73 @@ public class TransactionStatement implements CQLStatement.CompositeCQLStatement,
     {
         checkTrue(DatabaseDescriptor.getAccordTransactionsEnabled(), TRANSACTIONS_DISABLED_MESSAGE);
 
-        try
-        {
-            // check again since now we have query options; note that statements are quaranted to be single partition reads at this point
-            for (NamedSelect assignment : assignments)
-                checkFalse(isSelectingMultipleClusterings(assignment.select, options), INCOMPLETE_PRIMARY_KEY_SELECT_MESSAGE, "LET assignment", assignment.select.source);
+        // check again since now we have query options; note that statements are quaranted to be single partition reads at this point
+        for (NamedSelect assignment : assignments)
+            checkFalse(isSelectingMultipleClusterings(assignment.select, options), INCOMPLETE_PRIMARY_KEY_SELECT_MESSAGE, "LET assignment", assignment.select.source);
 
-            Txn txn = createTxn(state.getClientState(), options);
+        Txn txn = createTxn(state.getClientState(), options);
 
-            TxnResult txnResult = AccordService.instance().coordinate(txn, options.getConsistency(), requestTime);
-            if (txnResult.kind() == retry_new_protocol)
-                throw new InvalidRequestException(UNSUPPORTED_MIGRATION);
-            TxnData data = (TxnData)txnResult;
+        TxnResult txnResult = AccordService.instance().coordinate(txn, options.getConsistency(), requestTime);
+        if (txnResult.kind() == retry_new_protocol)
+            throw new InvalidRequestException(UNSUPPORTED_MIGRATION);
+        TxnData data = (TxnData)txnResult;
 
-            if (returningSelect != null)
+        if (returningSelect != null)
+        {
+            @SuppressWarnings("unchecked")
+            SinglePartitionReadQuery.Group<SinglePartitionReadCommand> selectQuery = (SinglePartitionReadQuery.Group<SinglePartitionReadCommand>) returningSelect.select.getQuery(options, 0);
+            Selection.Selectors selectors = returningSelect.select.getSelection().newSelectors(options);
+            ResultSetBuilder result = new ResultSetBuilder(resultMetadata, selectors, false);
+            if (selectQuery.queries.size() == 1)
+            {
+                FilteredPartition partition = data.get(TxnDataName.returning());
+                boolean reversed = selectQuery.queries.get(0).isReversed();
+                if (partition != null)
+                    returningSelect.select.processPartition(partition.rowIterator(reversed), options, result, FBUtilities.nowInSeconds());
+            }
+            else
             {
-                @SuppressWarnings("unchecked")
-                SinglePartitionReadQuery.Group<SinglePartitionReadCommand> selectQuery = (SinglePartitionReadQuery.Group<SinglePartitionReadCommand>) returningSelect.select.getQuery(options, 0);
-                Selection.Selectors selectors = returningSelect.select.getSelection().newSelectors(options);
-                ResultSetBuilder result = new ResultSetBuilder(resultMetadata, selectors, false);
-                if (selectQuery.queries.size() == 1)
+                long nowInSec = FBUtilities.nowInSeconds();
+                for (int i = 0; i < selectQuery.queries.size(); i++)
                 {
-                    FilteredPartition partition = data.get(TxnDataName.returning());
-                    boolean reversed = selectQuery.queries.get(0).isReversed();
+                    FilteredPartition partition = data.get(TxnDataName.returning(i));
+                    boolean reversed = selectQuery.queries.get(i).isReversed();
                     if (partition != null)
-                        returningSelect.select.processPartition(partition.rowIterator(reversed), options, result, FBUtilities.nowInSeconds());
-                }
-                else
-                {
-                    long nowInSec = FBUtilities.nowInSeconds();
-                    for (int i = 0; i < selectQuery.queries.size(); i++)
-                    {
-                        FilteredPartition partition = data.get(TxnDataName.returning(i));
-                        boolean reversed = selectQuery.queries.get(i).isReversed();
-                        if (partition != null)
-                            returningSelect.select.processPartition(partition.rowIterator(reversed), options, result, nowInSec);
-                    }
+                        returningSelect.select.processPartition(partition.rowIterator(reversed), options, result, nowInSec);
                 }
-                return new ResultMessage.Rows(result.build());
             }
+            return new ResultMessage.Rows(result.build());
+        }
 
-            if (returningReferences != null)
-            {
-                List<AbstractType<?>> resultType = new ArrayList<>(returningReferences.size());
-                List<ColumnMetadata> columns = new ArrayList<>(returningReferences.size());
-
-                for (RowDataReference reference : returningReferences)
-                {
-                    ColumnMetadata forMetadata = reference.toResultMetadata();
-                    resultType.add(forMetadata.type);
-                    columns.add(reference.column());
-                }
+        if (returningReferences != null)
+        {
+            List<AbstractType<?>> resultType = new ArrayList<>(returningReferences.size());
+            List<ColumnMetadata> columns = new ArrayList<>(returningReferences.size());
 
-                ResultSetBuilder result = new ResultSetBuilder(resultMetadata, Selection.noopSelector(), false);
-                result.newRow(options.getProtocolVersion(), null, null, columns);
+            for (RowDataReference reference : returningReferences)
+            {
+                ColumnMetadata forMetadata = reference.toResultMetadata();
+                resultType.add(forMetadata.type);
+                columns.add(reference.column());
+            }
 
-                for (int i = 0; i < returningReferences.size(); i++)
-                {
-                    RowDataReference reference = returningReferences.get(i);
-                    TxnReference txnReference = reference.toTxnReference(options);
-                    ByteBuffer buffer = txnReference.toByteBuffer(data, resultType.get(i));
-                    result.add(buffer);
-                }
+            ResultSetBuilder result = new ResultSetBuilder(resultMetadata, Selection.noopSelector(), false);
+            result.newRow(options.getProtocolVersion(), null, null, columns);
 
-                return new ResultMessage.Rows(result.build());
+            for (int i = 0; i < returningReferences.size(); i++)
+            {
+                RowDataReference reference = returningReferences.get(i);
+                TxnReference txnReference = reference.toTxnReference(options);
+                ByteBuffer buffer = txnReference.toByteBuffer(data, resultType.get(i));
+                result.add(buffer);
             }
 
-            // In the case of a write-only transaction, just return and empty result.
-            // TODO: This could be modified to return an indication of whether a condition (if present) succeeds.
-            return new ResultMessage.Void();
-        }
-        catch (Throwable t)
-        {
-            //TODO remove before merge to trunk
-           logger.error("Unexpected error with transaction: {}", t.toString());
-           throw t;
+            return new ResultMessage.Rows(result.build());
         }
+
+        // In the case of a write-only transaction, just return and empty result.
+        // TODO: This could be modified to return an indication of whether a condition (if present) succeeds.
+        return new ResultMessage.Void();
     }
 
     @Override
diff --git a/src/java/org/apache/cassandra/service/accord/AccordService.java b/src/java/org/apache/cassandra/service/accord/AccordService.java
index 85f491f0f4..167428a759 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordService.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordService.java
@@ -128,6 +128,8 @@ import org.apache.cassandra.journal.Params;
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.metrics.AccordClientRequestMetrics;
 import org.apache.cassandra.metrics.TCMMetrics;
+import org.apache.cassandra.metrics.ClientRequestMetrics;
+import org.apache.cassandra.metrics.ClientRequestsMetricsHolder;
 import org.apache.cassandra.net.IVerbHandler;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.MessageDelivery;
@@ -874,12 +876,24 @@ public class AccordService implements IAccordService, Shutdownable
     public @Nonnull AsyncTxnResult coordinateAsync(Txn txn, ConsistencyLevel consistencyLevel, Dispatcher.RequestTime requestTime)
     {
         TxnId txnId = node.nextTxnId(txn.kind(), txn.keys().domain());
-        AccordClientRequestMetrics metrics = txn.isWrite() ? accordWriteMetrics : accordReadMetrics;
+        ClientRequestMetrics sharedMetrics;
+        AccordClientRequestMetrics metrics;
+        if (txn.isWrite())
+        {
+            sharedMetrics = ClientRequestsMetricsHolder.writeMetrics;
+            metrics = accordWriteMetrics;
+        }
+        else
+        {
+            sharedMetrics = ClientRequestsMetricsHolder.readMetrics;
+            metrics = accordReadMetrics;
+        }
         metrics.keySize.update(txn.keys().size());
         AsyncResult<Result> asyncResult = node.coordinate(txnId, txn);
         AsyncTxnResult asyncTxnResult = new AsyncTxnResult(txnId);
         asyncResult.addCallback((success, failure) -> {
             long durationNanos = nanoTime() - requestTime.startedAtNanos();
+            sharedMetrics.addNano(durationNanos);
             metrics.addNano(durationNanos);
             Throwable cause = failure != null ? Throwables.getRootCause(failure) : null;
             if (success != null)
@@ -902,6 +916,7 @@ public class AccordService implements IAccordService, Shutdownable
             }
             if (cause instanceof Preempted || cause instanceof Invalidated)
             {
+                sharedMetrics.timeouts.mark();
                 metrics.preempted.mark();
                 //TODO need to improve
                 // Coordinator "could" query the accord state to see whats going on but that doesn't exist yet.
@@ -909,6 +924,7 @@ public class AccordService implements IAccordService, Shutdownable
                 asyncTxnResult.tryFailure(newPreempted(txnId, txn.isWrite(), consistencyLevel));
                 return;
             }
+            sharedMetrics.failures.mark();
             if (cause instanceof TopologyMismatch)
             {
                 metrics.topologyMismatches.mark();
@@ -924,7 +940,18 @@ public class AccordService implements IAccordService, Shutdownable
     @Override
     public TxnResult getTxnResult(AsyncTxnResult asyncTxnResult, boolean isWrite, @Nullable ConsistencyLevel consistencyLevel, Dispatcher.RequestTime requestTime)
     {
-        AccordClientRequestMetrics metrics = isWrite ? accordWriteMetrics : accordReadMetrics;
+        ClientRequestMetrics sharedMetrics;
+        AccordClientRequestMetrics metrics;
+        if (isWrite)
+        {
+            sharedMetrics = ClientRequestsMetricsHolder.writeMetrics;
+            metrics = accordWriteMetrics;
+        }
+        else
+        {
+            sharedMetrics = ClientRequestsMetricsHolder.readMetrics;
+            metrics = accordReadMetrics;
+        }
         try
         {
             long deadlineNanos = requestTime.computeDeadline(DatabaseDescriptor.getTransactionTimeout(NANOSECONDS));
@@ -939,6 +966,7 @@ public class AccordService implements IAccordService, Shutdownable
             {
                 // Mark here instead of in coordinate async since this is where the request timeout actually occurs
                 metrics.timeouts.mark();
+                sharedMetrics.timeouts.mark();
                 cause.addSuppressed(e);
                 throw (RequestTimeoutException) cause;
             }
@@ -950,11 +978,13 @@ public class AccordService implements IAccordService, Shutdownable
         catch (InterruptedException e)
         {
             metrics.failures.mark();
+            sharedMetrics.failures.mark();
             throw new UncheckedInterruptedException(e);
         }
         catch (TimeoutException e)
         {
             metrics.timeouts.mark();
+            sharedMetrics.timeouts.mark();
             throw newTimeout(asyncTxnResult.txnId, isWrite, consistencyLevel);
         }
     }
diff --git a/test/distributed/org/apache/cassandra/distributed/test/metrics/CoordinatorReadLatencyMetricTest.java b/test/distributed/org/apache/cassandra/distributed/test/metrics/CoordinatorReadLatencyMetricTest.java
index ab3de57cb6..31de169030 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/metrics/CoordinatorReadLatencyMetricTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/metrics/CoordinatorReadLatencyMetricTest.java
@@ -18,23 +18,67 @@
 
 package org.apache.cassandra.distributed.test.metrics;
 
+import java.io.IOException;
 import java.util.concurrent.TimeUnit;
+import java.util.function.LongSupplier;
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 
+import org.assertj.core.api.Assertions;
 import org.junit.Test;
 
 import org.apache.cassandra.config.Config;
+import org.apache.cassandra.cql3.ast.Conditional;
+import org.apache.cassandra.cql3.ast.Select;
+import org.apache.cassandra.cql3.ast.Txn;
+import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.distributed.Cluster;
 import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
 import org.apache.cassandra.distributed.test.TestBaseImpl;
 import org.apache.cassandra.metrics.ClientRequestsMetricsHolder;
+import org.apache.cassandra.service.consensus.TransactionalMode;
 import org.apache.cassandra.service.paxos.Paxos;
 
 import static org.junit.Assert.assertTrue;
 
 public class CoordinatorReadLatencyMetricTest extends TestBaseImpl
 {
+    @Test
+    public void singleRowTest() throws IOException
+    {
+        try (Cluster cluster = init(builder().withNodes(1).start()))
+        {
+            cluster.schemaChange(withKeyspace("CREATE TABLE %s.tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"));
+            for (int i = 0; i < 100; i++)
+                cluster.coordinator(1).execute(withKeyspace("insert into %s.tbl (pk, ck ,v) values (0, ?, 1)"), ConsistencyLevel.ALL, i);
+
+            var select = Select.builder()
+                               //TODO (now, correctness, coverage): count(v) breaks accord as we get mutliple rows rather than the count of rows...
+//                               .withSelection(FunctionCall.count("v"))
+                               .table(KEYSPACE, "tbl")
+                               .value("pk", 0)
+                               .where("ck", Conditional.Where.Inequality.LESS_THAN, 42)
+                               .limit(1)
+                               .build();
+
+            verifyTableLatency(cluster, 1, () -> verifyLatencyMetrics(cluster, select.toCQL(), ConsistencyLevel.QUORUM));
+            cluster.get(1).runOnInstance(() -> Paxos.setPaxosVariant(Config.PaxosVariant.v1));
+            verifyTableLatency(cluster, 1, () -> verifyLatencyMetrics(cluster, select.toCQL(), ConsistencyLevel.SERIAL));
+            cluster.get(1).runOnInstance(() -> Paxos.setPaxosVariant(Config.PaxosVariant.v2));
+            verifyTableLatency(cluster, 1, () -> verifyLatencyMetrics(cluster, select.toCQL(), ConsistencyLevel.SERIAL));
+
+            cluster.schemaChange(withKeyspace("ALTER TABLE %s.tbl WITH " + TransactionalMode.full.asCqlParam()));
+            verifyTableLatency(cluster, 1, () -> verifyLatencyMetrics(cluster, Txn.wrap(select).toCQL(), ConsistencyLevel.QUORUM));
+
+            var let = Txn.builder()
+                         .addLet("a", select)
+                         .addReturnReferences("a.v")
+                         .build();
+            verifyTableLatency(cluster, 1, () -> verifyLatencyMetrics(cluster, let.toCQL(), ConsistencyLevel.QUORUM));
+        }
+    }
+
     @Test
     public void internalPagingWithAggregateTest() throws Throwable
     {
@@ -91,16 +135,26 @@ public class CoordinatorReadLatencyMetricTest extends TestBaseImpl
         }
     }
 
-    private void verifyLatencyMetricsWhenPaging(Cluster cluster,
-                                                int pagesize,
-                                                int expectedQueries,
-                                                String query,
-                                                ConsistencyLevel consistencyLevel)
+    private static void verifyLatencyMetricsWhenPaging(Cluster cluster,
+                                                       int pagesize,
+                                                       int expectedQueries,
+                                                       String query,
+                                                       ConsistencyLevel consistencyLevel)
+    {
+        verifyLatencyMetrics(cluster, expectedQueries, () -> cluster.coordinator(1).executeWithPaging(query, consistencyLevel, pagesize));
+    }
+
+    private static void verifyLatencyMetrics(Cluster cluster, String query, ConsistencyLevel consistencyLevel)
+    {
+        verifyLatencyMetrics(cluster, 1, () -> cluster.coordinator(1).execute(query, consistencyLevel));
+    }
+
+    private static void verifyLatencyMetrics(Cluster cluster, int expectedQueries, Runnable query)
     {
         long countBefore = cluster.get(1).callOnInstance(() -> ClientRequestsMetricsHolder.readMetrics.latency.getCount());
         long totalLatencyBefore = cluster.get(1).callOnInstance(() -> ClientRequestsMetricsHolder.readMetrics.totalLatency.getCount());
         long startTime = System.nanoTime();
-        cluster.coordinator(1).executeWithPaging(query, consistencyLevel, pagesize);
+        query.run();
         long elapsedTime = System.nanoTime() - startTime;
         long countAfter = cluster.get(1).callOnInstance(() -> ClientRequestsMetricsHolder.readMetrics.latency.getCount());
         long totalLatencyAfter = cluster.get(1).callOnInstance(() -> ClientRequestsMetricsHolder.readMetrics.totalLatency.getCount());
@@ -113,4 +167,16 @@ public class CoordinatorReadLatencyMetricTest extends TestBaseImpl
                    totalLatencyRecorded <= elapsedTime);
     }
 
+    private static void verifyTableLatency(Cluster cluster, int expectedQueries, Runnable query)
+    {
+        IInvokableInstance inst = cluster.get(1);
+        LongSupplier tableMetric = () -> inst.callOnInstance(() -> Keyspace.open("distributed_test_keyspace").getColumnFamilyStore("tbl").getMetrics().readLatency.latency.getCount());
+
+        long tableBefore = tableMetric.getAsLong();
+        query.run();
+        long tableAfter = tableMetric.getAsLong();
+
+        Assertions.assertThat(tableAfter - tableBefore).isEqualTo(expectedQueries);
+    }
+
 }
