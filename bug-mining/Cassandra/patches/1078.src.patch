diff --git a/build.xml b/build.xml
index 8df98df1ab..4b5d3ca2e2 100644
--- a/build.xml
+++ b/build.xml
@@ -36,6 +36,7 @@
     <property name="build.src" value="${basedir}/src"/>
     <property name="build.src.java" value="${basedir}/src/java"/>
     <property name="build.src.resources" value="${basedir}/src/resources"/>
+    <property name="build.src.driver" value="${basedir}/drivers/java/src" />
     <property name="avro.src" value="${basedir}/src/avro"/>
     <property name="build.src.gen-java" value="${basedir}/src/gen-java"/>
     <property name="build.lib" value="${basedir}/lib"/>
@@ -45,6 +46,7 @@
     <property name="build.classes" value="${build.dir}/classes"/>
     <property name="build.classes.main" value="${build.classes}/main" />
     <property name="build.classes.thrift" value="${build.classes}/thrift" />
+    <property name="build.classes.cql" value="${build.classes}/cql" />
     <property name="javadoc.dir" value="${build.dir}/javadoc"/>
     <property name="javadoc.jars.dir" value="${build.dir}/javadocs"/>
     <property name="interface.dir" value="${basedir}/interface"/>
@@ -58,9 +60,11 @@
     <property name="test.data" value="${test.dir}/data"/>
     <property name="test.name" value="*Test"/>
     <property name="test.unit.src" value="${test.dir}/unit"/>
+    <property name="test.src.driver" value="${basedir}/drivers/java/test"/>
     <property name="test.long.src" value="${test.dir}/long"/>
     <property name="test.distributed.src" value="${test.dir}/distributed"/>
     <property name="dist.dir" value="${build.dir}/dist"/>
+    <property name="cql.driver.version" value="1.0.4" />
     <condition property="version" value="${base.version}">
       <isset property="release"/>
     </condition>
@@ -157,6 +161,7 @@
             message="Not a source artifact, stopping here." />
         <mkdir dir="${build.classes.main}"/>
         <mkdir dir="${build.classes.thrift}"/>
+        <mkdir dir="${build.classes.cql}"/>
         <mkdir dir="${test.lib}"/>
         <mkdir dir="${test.classes}"/>
         <mkdir dir="${build.src.gen-java}"/>
@@ -391,6 +396,7 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
           <dependency groupId="log4j" artifactId="log4j" version="1.2.16" />
           <dependency groupId="org.apache.cassandra" artifactId="cassandra-all" version="${version}" />
           <dependency groupId="org.apache.cassandra" artifactId="cassandra-thrift" version="${version}" />
+          <dependency groupId="org.apache.cassandra" artifactId="cassandra-cql" version="${version}" />
         </dependencyManagement>
         <developer id="alakshman" name="Avinash Lakshman"/>
         <developer id="antelder" name="Anthony Elder"/>
@@ -478,7 +484,7 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
         
         <!-- don't need hadoop classes to run, but if you use the hadoop stuff -->
         <dependency groupId="org.apache.hadoop" artifactId="hadoop-core" optional="true"/>
-        
+
         <!-- don't need jna to run, but nice to have -->
         <dependency groupId="net.java.dev.jna" artifactId="jna" optional="true"/>
         
@@ -497,6 +503,22 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
         <dependency groupId="org.slf4j" artifactId="slf4j-api"/>
         <dependency groupId="org.apache.thrift" artifactId="libthrift"/>
       </artifact:pom>
+      <artifact:pom id="cql-pom"
+                    artifactId="cassandra-cql"
+                    url="http://cassandra.apache.org"
+                    name="Apache Cassandra">
+        <parent groupId="org.apache.cassandra"
+                artifactId="cassandra-parent"
+                version="${version}"/>
+        <scm connection="${scm.connection}" developerConnection="${scm.developerConnection}" url="${scm.url}"/>
+        <dependency groupId="com.google.guava" artifactId="guava"/>
+        <dependency groupId="org.slf4j" artifactId="slf4j-api"/>
+        <dependency groupId="org.apache.thrift" artifactId="libthrift"/>
+        <dependency groupId="org.apache.cassandra" artifactId="cassandra-thrift"/>
+        <dependency groupId="org.apache.cassandra" artifactId="cassandra-all"/>
+        <!-- because cassandra-all uses log4j, and we need cassandra-all, consumers must use log4j, so force log4j version of slf4j -->
+        <dependency groupId="org.slf4j" artifactId="slf4j-log4j12" scope="runtime"/>
+      </artifact:pom>
 
       <artifact:pom id="dist-pom"
                     artifactId="apache-cassandra"
@@ -666,6 +688,11 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
             <src path="${build.src.gen-java}"/>
             <classpath refid="cassandra.classpath"/>
         </javac>
+        <javac debug="true" debuglevel="${debuglevel}"
+               destdir="${build.classes.cql}" includeantruntime="false">
+            <src path="${build.src.driver}" />
+            <classpath refid="cassandra.classpath"/>
+        </javac>
         <copy todir="${build.classes.main}">
             <fileset dir="${build.src.resources}" />
         </copy>
@@ -723,6 +750,20 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
         <!-- </section> -->
         </manifest>
       </jar>
+
+      <!-- CQL driver Jar -->
+      <artifact:writepom pomRefId="cql-pom" 
+              file="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.pom"/>
+      <jar jarfile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.jar"
+           basedir="${build.classes.cql}">
+        <manifest>
+          <attribute name="Implementation-Title" value="Cassandra"/>
+          <attribute name="Implementation-Version" value="${version}"/>
+          <attribute name="Implementation-Vendor" value="Apache"/>
+          <attribute name="Class-Path"
+                     value="${ant.project.name}-thrift-${version}.jar" />
+        </manifest>
+      </jar>
     </target>
 
     <!--
@@ -748,11 +789,23 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
         <fileset dir="${build.src.gen-java}" defaultexcludes="yes">
           <include name="org/apache/**/*.java"/>
         </fileset>
+        <fileset dir="${build.src.driver}" defaultexcludes="yes">
+          <include name="org/apache/**/*.java"/>
+        </fileset>
         </filesets>
       </create-javadoc>
       <jar jarfile="${build.dir}/${final.name}-javadoc.jar"
            basedir="${javadoc.jars.dir}/main"/>
 
+      <create-javadoc destdir="${javadoc.jars.dir}/cql">
+        <filesets>
+        <fileset dir="${build.src.driver}" defaultexcludes="yes">
+          <include name="org/apache/**/*.java"/>
+        </fileset>
+        </filesets>
+      </create-javadoc>
+      <jar jarfile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}-javadoc.jar"
+           basedir="${javadoc.jars.dir}/cql"/>
       <!-- javadoc task always rebuilds so might as well remove the generated docs to prevent 
            being pulled into the distribution by accident -->
       <delete quiet="true" dir="${javadoc.jars.dir}"/>
@@ -774,11 +827,19 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
         <fileset dir="${build.src.gen-java}" defaultexcludes="yes">
           <include name="org/apache/**/*.java"/>
         </fileset>
+        <fileset dir="${build.src.driver}" defaultexcludes="yes">
+          <include name="org/apache/**/*.java"/>
+        </fileset>
+      </jar>
+      <jar jarfile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}-sources.jar">
+        <fileset dir="${build.src.driver}" defaultexcludes="yes">
+          <include name="org/apache/**/*.java"/>
+        </fileset>
       </jar>
     </target>
 
     <!-- creates release tarballs -->
-    <target name="artifacts" depends="jar,javadoc"
+    <target name="artifacts" depends="jar,javadoc,py-cql-driver"
             description="Create Cassandra release artifacts">
       <mkdir dir="${dist.dir}"/>
       <copy todir="${dist.dir}/lib">
@@ -868,12 +929,14 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
                 algorithm="MD5">
         <fileset dir="${build.dir}">
           <include name="*.tar.gz" />
+          <include name="${ant.project.name}-cql-${cql.driver.version}.jar" />
         </fileset>
       </checksum>
       <checksum forceOverwrite="yes" todir="${build.dir}" fileext=".sha"
                 algorithm="SHA">
         <fileset dir="${build.dir}">
           <include name="*.tar.gz" />
+          <include name="${ant.project.name}-cql-${cql.driver.version}.jar" />
         </fileset>
       </checksum>
 
@@ -903,9 +966,11 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
      destdir="${test.classes}">
       <classpath>
         <path refid="cassandra.classpath"/>
+        <pathelement location="${build.classes.cql}"/>
       </classpath>
       <src path="${test.unit.src}"/>
       <src path="${test.long.src}"/>
+      <src path="${test.src.driver}"/>
     </javac>
 
     <!-- Non-java resources needed by the test suite -->
@@ -954,6 +1019,7 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
         <classpath>
           <path refid="cassandra.classpath" />
           <pathelement location="${test.classes}"/>
+          <pathelement location="${build.classes.cql}"/>
           <path refid="cobertura.classpath"/>
           <pathelement location="${test.conf}"/>
           <fileset dir="${test.lib}">
@@ -982,8 +1048,11 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
       <jvmarg value="-Dlegacy-sstable-root=${test.data}/legacy-sstables"/>
       <jvmarg value="-Dcorrupt-sstable-root=${test.data}/corrupt-sstables"/>
     </testmacro>
+    <testmacro suitename="driverunit" inputdir="${test.src.driver}" timeout="60000">
+      <jvmarg value="-Dlegacy-sstable-root=${test.data}/legacy-sstables"/>
+    </testmacro>
   </target>
-
+    
   <target name="test-compression" depends="build-test" description="Execute unit tests with sstable compression enabled">
     <testmacro suitename="unit" inputdir="${test.unit.src}" timeout="60000">
       <jvmarg value="-Dlegacy-sstable-root=${test.data}/legacy-sstables"/>
@@ -991,7 +1060,7 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
       <jvmarg value="-Dcassandra.test.compression=true"/>
     </testmacro>
   </target>
-    
+
   <target name="msg-ser-gen-test" depends="build-test" description="Generates message serializations">
     <testmacro suitename="unit" inputdir="${test.unit.src}" 
                timeout="60000" filter="**/SerializationsTest.java">
@@ -1136,6 +1205,8 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
   <classpathentry kind="src" path="src/java"/>
   <classpathentry kind="src" path="src/gen-java"/>
   <classpathentry kind="src" path="interface/thrift/gen-java"/>
+  <classpathentry kind="src" path="drivers/java/src"/>
+  <classpathentry kind="src" path="drivers/java/test"/>
   <classpathentry kind="src" path="test/unit"/>
   <classpathentry kind="src" path="test/long"/>
   <classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER"/>
@@ -1213,6 +1284,17 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
   	<delete dir="build/eclipse-classes" />
   </target>
 
+  <target name="py-cql-driver"
+          description="Generate Python CQL driver artifact">
+    <echo>Creating Python CQL driver artifact...</echo>
+    <exec executable="python" dir="${basedir}/drivers/py" failonerror="true">
+      <arg line="setup.py" />
+      <arg line="sdist" />
+      <arg line="--dist-dir" />
+      <arg line="${build.dir}" />
+    </exec>
+  </target>
+
   <!-- Publish artifacts to Maven repositories -->
   <target name="mvn-install"
           depends="maven-declare-dependencies,artifacts,jar,sources-jar,javadoc-jar"
@@ -1255,6 +1337,16 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
     <install pomFile="${build.dir}/${final.name}.pom"
              file="${build.dir}/${final.name}-javadoc.jar"
              classifier="javadoc"/>
+
+    <!-- the cassandra-cql jar -->
+    <install pomFile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.pom"
+             file="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.jar"/>
+    <install pomFile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.pom"
+             file="${build.dir}/${ant.project.name}-cql-${cql.driver.version}-sources.jar"
+             classifier="sources"/>
+    <install pomFile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.pom"
+             file="${build.dir}/${ant.project.name}-cql-${cql.driver.version}-javadoc.jar"
+             classifier="javadoc"/>
   </target>
 
   <target name="publish"
@@ -1299,6 +1391,16 @@ url=${svn.entry.url}?pathrev=${svn.entry.commit.revision}
     <deploy pomFile="${build.dir}/${final.name}.pom"
             file="${build.dir}/${final.name}-javadoc.jar"
             classifier="javadoc"/>
+
+    <!-- the cassandra-cql jar -->
+    <deploy pomFile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.pom"
+            file="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.jar"/>
+    <deploy pomFile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.pom"
+            file="${build.dir}/${ant.project.name}-cql-${cql.driver.version}-sources.jar"
+            classifier="sources"/>
+    <deploy pomFile="${build.dir}/${ant.project.name}-cql-${cql.driver.version}.pom"
+            file="${build.dir}/${ant.project.name}-cql-${cql.driver.version}-javadoc.jar"
+            classifier="javadoc"/>
   </target>
 
 </project>
diff --git a/drivers/java/CHANGES.txt b/drivers/java/CHANGES.txt
new file mode 100644
index 0000000000..6a0616d6c2
--- /dev/null
+++ b/drivers/java/CHANGES.txt
@@ -0,0 +1,4 @@
+1.0.4
+ * improve JDBC spec compliance (CASSANDRA-2720, 2754, 3052)
+ * cooperate with other jdbc drivers (CASSANDRA-2842)
+ * fix unbox-to-NPE with null primitives (CASSANDRA-2956)
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractCassandraConnection.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractCassandraConnection.java
new file mode 100644
index 0000000000..99d982bb38
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractCassandraConnection.java
@@ -0,0 +1,129 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import java.sql.Array;
+import java.sql.Blob;
+import java.sql.CallableStatement;
+import java.sql.Clob;
+import java.sql.NClob;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.sql.SQLFeatureNotSupportedException;
+import java.sql.SQLXML;
+import java.sql.Savepoint;
+import java.sql.Struct;
+import java.util.Map;
+
+public class AbstractCassandraConnection
+{
+    protected static final String NOT_SUPPORTED = "the Cassandra implementation does not support this method";
+
+    public Array createArrayOf(String arg0, Object[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Blob createBlob() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Clob createClob() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public NClob createNClob() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public SQLXML createSQLXML() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Struct createStruct(String arg0, Object[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Map<String, Class<?>> getTypeMap() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+    
+    public CallableStatement prepareCall(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+    
+    public CallableStatement prepareCall(String arg0, int arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public CallableStatement prepareCall(String arg0, int arg1, int arg2, int arg3) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public PreparedStatement prepareStatement(String arg0, int arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public PreparedStatement prepareStatement(String arg0, int[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public PreparedStatement prepareStatement(String arg0, String[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void releaseSavepoint(Savepoint arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void rollback(Savepoint arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Savepoint setSavepoint() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+    public Savepoint setSavepoint(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+    
+    public void setTypeMap(Map<String, Class<?>> arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractResultSet.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractResultSet.java
new file mode 100644
index 0000000000..de16e64fe0
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractResultSet.java
@@ -0,0 +1,636 @@
+package org.apache.cassandra.cql.jdbc;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+import java.io.InputStream;
+import java.io.Reader;
+import java.math.BigDecimal;
+import java.sql.*;
+import java.util.Map;
+
+/** a class to hold all the unimplemented crap */
+class AbstractResultSet
+{
+    protected static final String NOT_SUPPORTED = "the Cassandra implementation does not support this method";
+
+    public void cancelRowUpdates() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void deleteRow() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Array getArray(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Array getArray(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public InputStream getAsciiStream(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public InputStream getAsciiStream(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public InputStream getBinaryStream(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public InputStream getBinaryStream(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Blob getBlob(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Blob getBlob(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Reader getCharacterStream(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Reader getCharacterStream(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Clob getClob(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Clob getClob(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public String getCursorName() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Reader getNCharacterStream(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Reader getNCharacterStream(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public NClob getNClob(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public NClob getNClob(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public String getNString(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public String getNString(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Object getObject(int arg0, Map<String, Class<?>> arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Object getObject(String arg0, Map<String, Class<?>> arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Ref getRef(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public Ref getRef(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public RowId getRowId(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public SQLXML getSQLXML(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public SQLXML getSQLXML(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public InputStream getUnicodeStream(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public InputStream getUnicodeStream(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void insertRow() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void moveToCurrentRow() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void moveToInsertRow() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void refreshRow() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public boolean rowDeleted() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public boolean rowInserted() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public boolean rowUpdated() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    //
+    // all the update methods are unsupported, requires a separate statement in Cassandra
+    //
+
+    public void updateArray(int arg0, Array arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateArray(String arg0, Array arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateAsciiStream(int arg0, InputStream arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateAsciiStream(int arg0, InputStream arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateAsciiStream(int arg0, InputStream arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateAsciiStream(String arg0, InputStream arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateAsciiStream(String arg0, InputStream arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateAsciiStream(String arg0, InputStream arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBigDecimal(int arg0, BigDecimal arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBigDecimal(String arg0, BigDecimal arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBinaryStream(int arg0, InputStream arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBinaryStream(int arg0, InputStream arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBinaryStream(int arg0, InputStream arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBinaryStream(String arg0, InputStream arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBinaryStream(String arg0, InputStream arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBinaryStream(String arg0, InputStream arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBlob(int arg0, Blob arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBlob(int arg0, InputStream arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBlob(int arg0, InputStream arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBlob(String arg0, Blob arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBlob(String arg0, InputStream arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBlob(String arg0, InputStream arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBoolean(int arg0, boolean arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBoolean(String arg0, boolean arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateByte(int arg0, byte arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateByte(String arg0, byte arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBytes(int arg0, byte[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateBytes(String arg0, byte[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateCharacterStream(int arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateCharacterStream(int arg0, Reader arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateCharacterStream(int arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateCharacterStream(String arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateCharacterStream(String arg0, Reader arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateCharacterStream(String arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateClob(int arg0, Clob arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateClob(int arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateClob(int arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateClob(String arg0, Clob arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateClob(String arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateClob(String arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateDate(int arg0, Date arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateDate(String arg0, Date arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateDouble(int arg0, double arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateDouble(String arg0, double arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateFloat(int arg0, float arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateFloat(String arg0, float arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateInt(int arg0, int arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateInt(String arg0, int arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateLong(int arg0, long arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateLong(String arg0, long arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNCharacterStream(int arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNCharacterStream(int arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNCharacterStream(String arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNCharacterStream(String arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNClob(int arg0, NClob arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNClob(int arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNClob(int arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNClob(String arg0, NClob arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNClob(String arg0, Reader arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNClob(String arg0, Reader arg1, long arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNString(int arg0, String arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNString(String arg0, String arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNull(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateNull(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateObject(int arg0, Object arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateObject(int arg0, Object arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateObject(String arg0, Object arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateObject(String arg0, Object arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateRef(int arg0, Ref arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateRef(String arg0, Ref arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateRow() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateRowId(int arg0, RowId arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateRowId(String arg0, RowId arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateShort(int arg0, short arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateShort(String arg0, short arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateSQLXML(int arg0, SQLXML arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateSQLXML(String arg0, SQLXML arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateString(int arg0, String arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateString(String arg0, String arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateTime(int arg0, Time arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateTime(String arg0, Time arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateTimestamp(int arg0, Timestamp arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void updateTimestamp(String arg0, Timestamp arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractStatement.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractStatement.java
new file mode 100644
index 0000000000..12cc1c1194
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/AbstractStatement.java
@@ -0,0 +1,64 @@
+/*
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.SQLFeatureNotSupportedException;
+
+public class AbstractStatement
+{
+    protected static final String NOT_SUPPORTED = "the Cassandra implementation does not support this method";
+
+    public void cancel() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+    
+    public boolean execute(String arg0, int[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public boolean execute(String arg0, String[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public int executeUpdate(String arg0, int[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+    
+    public int executeUpdate(String arg0, String[] arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+    public ResultSet getGeneratedKeys() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+   
+    public void setCursorName(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CResultSet.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CResultSet.java
new file mode 100644
index 0000000000..c5c8bb8594
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CResultSet.java
@@ -0,0 +1,1069 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import static org.apache.cassandra.cql.jdbc.Utils.*;
+
+import java.math.BigDecimal;
+import java.math.BigInteger;
+import java.net.URL;
+import java.nio.ByteBuffer;
+import java.sql.*;
+import java.sql.Date;
+import java.util.*;
+
+import org.apache.cassandra.db.marshal.CounterColumnType;
+import org.apache.cassandra.thrift.Column;
+import org.apache.cassandra.thrift.CqlResult;
+import org.apache.cassandra.thrift.CqlRow;
+import org.apache.cassandra.utils.ByteBufferUtil;
+
+public class CResultSet extends AbstractResultSet implements CassandraResultSet
+{
+    public static final int DEFAULT_TYPE = ResultSet.TYPE_FORWARD_ONLY;
+    public static final int DEFAULT_CONCURRENCY = ResultSet.CONCUR_READ_ONLY;
+    public static final int DEFAULT_HOLDABILITY = ResultSet.HOLD_CURSORS_OVER_COMMIT;
+
+    private final ColumnDecoder decoder;
+    private final String keyspace;
+
+    private final String columnFamily;
+
+    /**
+     * The r set iter.
+     */
+    private Iterator<CqlRow> rSetIter;
+
+    int rowNumber = 0;
+    // the current row key when iterating through results.
+    private byte[] curRowKey = null;
+
+    private TypedColumn typedCurRowKey = null;
+
+    /**
+     * The values.
+     */
+    private List<TypedColumn> values = new ArrayList<TypedColumn>();
+
+    /**
+     * The value map.
+     */
+    private Map<String, TypedColumn> valueMap = new HashMap<String, TypedColumn>();
+
+    /**
+     * The index map.
+     */
+    private Map<String, Integer> indexMap = new HashMap<String, Integer>();
+
+    private final CResultSetMetaData meta;
+
+    private final Statement statement;
+
+    private int resultSetType;
+
+    private int fetchDirection;
+
+    private int fetchSize;
+
+    private boolean wasNull;
+
+    /**
+     * no argument constructor.
+     */
+    CResultSet()
+    {
+        keyspace = null;
+        columnFamily = null;
+        decoder = null;
+        statement = null;
+        meta = new CResultSetMetaData();
+    }
+
+    /**
+     * Instantiates a new cassandra result set.
+     */
+    CResultSet(Statement statement, CqlResult resultSet, ColumnDecoder decoder, String keyspace, String columnFamily) throws SQLException
+    {
+        this.statement = statement;
+        this.resultSetType = statement.getResultSetType();
+        this.fetchDirection = statement.getFetchDirection();
+        this.fetchSize = statement.getFetchSize();
+
+        this.decoder = decoder;
+        this.keyspace = keyspace;
+        this.columnFamily = columnFamily;
+        rSetIter = resultSet.getRowsIterator();
+        meta = new CResultSetMetaData();
+    }
+
+    public boolean absolute(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void afterLast() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void beforeFirst() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    private final void checkIndex(int index) throws SQLException
+    {
+        // 1 <= index <= size()
+        if (index < 1 || index > values.size())
+            throw new SQLSyntaxErrorException(String.format(MUST_BE_POSITIVE, String.valueOf(index)));
+    }
+
+    private final void checkName(String name) throws SQLException
+    {
+        if (valueMap.get(name) == null) throw new SQLSyntaxErrorException(String.format(VALID_LABELS, name));
+    }
+
+    private final void checkNotClosed() throws SQLException
+    {
+        if (isClosed()) throw new SQLRecoverableException(WAS_CLOSED_RSLT);
+    }
+
+    public void clearWarnings() throws SQLException
+    {
+        // This implementation does not support the collection of warnings so clearing is a no-op
+        // but it is still an exception to call this on a closed connection.
+        checkNotClosed();
+    }
+
+    public void close() throws SQLException
+    {
+        valueMap = null;
+        values = null;
+    }
+
+    public int findColumn(String name) throws SQLException
+    {
+        checkNotClosed();
+        checkName(name);
+        return indexMap.get(name).intValue();
+    }
+
+    public boolean first() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    // Big Decimal (awaiting a new AbstractType implementation)
+
+    public BigDecimal getBigDecimal(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public BigDecimal getBigDecimal(int arg0, int arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public BigDecimal getBigDecimal(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public BigDecimal getBigDecimal(String arg0, int arg1) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public BigInteger getBigInteger(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getBigInteger(values.get(index - 1));
+    }
+
+    public BigInteger getBigInteger(String name) throws SQLException
+    {
+        checkName(name);
+        return getBigInteger(valueMap.get(name));
+    }
+
+    private BigInteger getBigInteger(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return BigInteger.ZERO;
+
+        if (value instanceof Long) return BigInteger.valueOf((Long) value);
+
+        if (value instanceof BigInteger) return (BigInteger) value;
+
+        try
+        {
+            if (value instanceof String) return (new BigInteger((String) value));
+        }
+        catch (NumberFormatException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "BigInteger"));
+    }
+
+    public boolean getBoolean(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getBoolean(values.get(index - 1));
+    }
+
+    public boolean getBoolean(String name) throws SQLException
+    {
+        checkName(name);
+        return getBoolean(valueMap.get(name));
+    }
+
+    private final Boolean getBoolean(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return false;
+
+        if (value instanceof Long) return Boolean.valueOf(((Long) value) == 0 ? false : true);
+
+        if (value instanceof BigInteger) return Boolean.valueOf(((BigInteger) value).intValue() == 0 ? false : true);
+
+        if (value instanceof String)
+        {
+            String str = (String) value;
+            if (str.equalsIgnoreCase("true")) return true;
+            if (str.equalsIgnoreCase("false")) return false;
+
+            throw new SQLSyntaxErrorException(String.format(NOT_BOOLEAN, str));
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "Boolean"));
+    }
+
+    public byte getByte(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getByte(values.get(index - 1));
+    }
+
+    public byte getByte(String name) throws SQLException
+    {
+        checkName(name);
+        return getByte(valueMap.get(name));
+    }
+
+    private final Byte getByte(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return 0;
+
+        if (value instanceof Long) return ((Long) value).byteValue();
+
+        if (value instanceof BigInteger) return ((BigInteger) value).byteValue();
+
+        try
+        {
+            if (value instanceof String) return (new Byte((String) value));
+        }
+        catch (NumberFormatException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "Byte"));
+    }
+
+    public byte[] getBytes(int index) throws SQLException
+    {
+        return getBytes(values.get(index - 1));
+    }
+
+    public byte[] getBytes(String name) throws SQLException
+    {
+        return getBytes(valueMap.get(name));
+    }
+
+    private byte[] getBytes(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        ByteBuffer value = (ByteBuffer) column.getValue();
+        wasNull = value == null;
+        return value == null ? null : ByteBufferUtil.clone(value).array();
+    }
+
+    public TypedColumn getColumn(int index) throws SQLException
+    {
+        checkIndex(index);
+        checkNotClosed();
+        return values.get(index);
+    }
+
+    public TypedColumn getColumn(String name) throws SQLException
+    {
+        checkName(name);
+        checkNotClosed();
+        return valueMap.get(name);
+    }
+
+    public int getConcurrency() throws SQLException
+    {
+        checkNotClosed();
+        return statement.getResultSetConcurrency();
+    }
+
+    public Date getDate(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getDate(values.get(index - 1));
+    }
+
+    public Date getDate(int index, Calendar calendar) throws SQLException
+    {
+        checkIndex(index);
+        // silently ignore the Calendar argument; its a hint we do not need
+        return getDate(index);
+    }
+
+    public Date getDate(String name) throws SQLException
+    {
+        checkName(name);
+        return getDate(valueMap.get(name));
+    }
+
+    public Date getDate(String name, Calendar calendar) throws SQLException
+    {
+        checkName(name);
+        // silently ignore the Calendar argument; its a hint we do not need
+        return getDate(name);
+    }
+
+    private Date getDate(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return null;
+
+        if (value instanceof Long) return new Date((Long) value);
+
+        if (value instanceof java.util.Date) return new Date(((java.util.Date) value).getTime());
+
+        try
+        {
+            if (value instanceof String) return Date.valueOf((String) value);
+        }
+        catch (IllegalArgumentException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "SQL Date"));
+    }
+
+    public double getDouble(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getDouble(values.get(index - 1));
+    }
+
+    public double getDouble(String name) throws SQLException
+    {
+        checkName(name);
+        return getDouble(valueMap.get(name));
+    }
+
+    private final Double getDouble(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return 0.0;
+
+        if (value instanceof Long) return new Double((Long) value);
+
+        if (value instanceof BigInteger) return new Double(((BigInteger) value).doubleValue());
+
+        if (value instanceof Double) return ((Double) value);
+
+        if (value instanceof Float) return ((Float) value).doubleValue();
+
+        try
+        {
+            if (value instanceof String) return new Double((String) value);
+        }
+        catch (NumberFormatException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "Double"));
+    }
+
+    public int getFetchDirection() throws SQLException
+    {
+        checkNotClosed();
+        return fetchDirection;
+    }
+
+    public int getFetchSize() throws SQLException
+    {
+        checkNotClosed();
+        return fetchSize;
+    }
+
+    public float getFloat(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getFloat(values.get(index - 1));
+    }
+
+    public float getFloat(String name) throws SQLException
+    {
+        checkName(name);
+        return getFloat(valueMap.get(name));
+    }
+
+    private final Float getFloat(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return (float) 0.0;
+
+        if (value instanceof Long) return new Float((Long) value);
+
+        if (value instanceof BigInteger) return new Float(((BigInteger) value).floatValue());
+
+        if (value instanceof Float) return ((Float) value);
+
+        if (value instanceof Double) return ((Double) value).floatValue();
+
+        try
+        {
+            if (value instanceof String) return new Float((String) value);
+        }
+        catch (NumberFormatException e)
+        {
+            throw new SQLException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "Float"));
+    }
+
+    public int getHoldability() throws SQLException
+    {
+        checkNotClosed();
+        return statement.getResultSetHoldability();
+    }
+
+    public int getInt(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getInt(values.get(index - 1));
+    }
+
+    public int getInt(String name) throws SQLException
+    {
+        checkName(name);
+        return getInt(valueMap.get(name));
+    }
+
+    private int getInt(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return 0;
+
+        // bit of a hack, this, but asking for getInt seems so common that we should accommodate it
+        if (value instanceof BigInteger) return ((BigInteger) value).intValue();
+
+        if (value instanceof Long) return ((Long) value).intValue();
+
+        try
+        {
+            if (value instanceof String) return (Integer.parseInt((String) value));
+        }
+        catch (NumberFormatException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "int"));
+    }
+
+    public byte[] getKey() throws SQLException
+    {
+        return curRowKey;
+    }
+
+    public long getLong(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getLong(values.get(index - 1));
+    }
+
+    public long getLong(String name) throws SQLException
+    {
+        checkName(name);
+        return getLong(valueMap.get(name));
+    }
+
+    private Long getLong(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return 0L;
+
+        if (value instanceof BigInteger) return getBigInteger(column).longValue();
+
+        if (value instanceof Long) return (Long) value;
+
+        try
+        {
+            if (value instanceof String) return (Long.parseLong((String) value));
+        }
+        catch (NumberFormatException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "Long"));
+    }
+
+    public ResultSetMetaData getMetaData() throws SQLException
+    {
+        checkNotClosed();
+        return meta;
+    }
+
+    public Object getObject(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getObject(values.get(index - 1));
+    }
+
+    public Object getObject(String name) throws SQLException
+    {
+        checkName(name);
+        return getObject(valueMap.get(name));
+    }
+
+
+    private Object getObject(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+        return (wasNull) ? null : value;
+    }
+
+    public int getRow() throws SQLException
+    {
+        checkNotClosed();
+        return rowNumber;
+    }
+
+    // RowId (shall we just store the raw bytes as it is kept in C* ? Probably...
+    public RowId getRowId(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public short getShort(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getShort(values.get(index - 1));
+    }
+
+    public short getShort(String name) throws SQLException
+    {
+        checkName(name);
+        return getShort(valueMap.get(name));
+    }
+
+    private final Short getShort(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return 0;
+
+        if (value instanceof Long) return ((Long) value).shortValue();
+
+        if (value instanceof BigInteger) return ((BigInteger) value).shortValue();
+
+        try
+        {
+            if (value instanceof String) return (new Short((String) value));
+        }
+        catch (NumberFormatException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "Short"));
+    }
+
+    public Statement getStatement() throws SQLException
+    {
+        checkNotClosed();
+        return statement;
+    }
+
+    public String getString(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getString(values.get(index - 1));
+    }
+
+    public String getString(String name) throws SQLException
+    {
+        checkName(name);
+        return getString(valueMap.get(name));
+    }
+
+    private String getString(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+        return (wasNull) ? null : value.toString();
+    }
+
+    public Time getTime(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getTime(values.get(index - 1));
+    }
+
+    public Time getTime(int index, Calendar calendar) throws SQLException
+    {
+        checkIndex(index);
+        // silently ignore the Calendar argument; its a hint we do not need
+        return getTime(index);
+    }
+
+    public Time getTime(String name) throws SQLException
+    {
+        checkName(name);
+        return getTime(valueMap.get(name));
+    }
+
+    public Time getTime(String name, Calendar calendar) throws SQLException
+    {
+        checkName(name);
+        // silently ignore the Calendar argument; its a hint we do not need
+        return getTime(name);
+    }
+
+    private Time getTime(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return null;
+
+        if (value instanceof Long) return new Time((Long) value);
+
+        if (value instanceof java.util.Date) return new Time(((java.util.Date) value).getTime());
+
+        try
+        {
+            if (value instanceof String) return Time.valueOf((String) value);
+        }
+        catch (IllegalArgumentException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "SQL Time"));
+    }
+
+    public Timestamp getTimestamp(int index) throws SQLException
+    {
+        checkIndex(index);
+        return getTimestamp(values.get(index - 1));
+    }
+
+    public Timestamp getTimestamp(int index, Calendar calendar) throws SQLException
+    {
+        checkIndex(index);
+        // silently ignore the Calendar argument; its a hint we do not need
+        return getTimestamp(index);
+    }
+
+    public Timestamp getTimestamp(String name) throws SQLException
+    {
+        checkName(name);
+        return getTimestamp(valueMap.get(name));
+    }
+
+    public Timestamp getTimestamp(String name, Calendar calendar) throws SQLException
+    {
+        checkName(name);
+        // silently ignore the Calendar argument; its a hint we do not need
+        return getTimestamp(name);
+    }
+
+    private Timestamp getTimestamp(TypedColumn column) throws SQLException
+    {
+        checkNotClosed();
+        Object value = column.getValue();
+        wasNull = value == null;
+
+        if (wasNull) return null;
+
+        if (value instanceof Long) return new Timestamp((Long) value);
+
+        if (value instanceof java.util.Date) return new Timestamp(((java.util.Date) value).getTime());
+
+        try
+        {
+            if (value instanceof String) return Timestamp.valueOf((String) value);
+        }
+        catch (IllegalArgumentException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+
+        throw new SQLSyntaxErrorException(String.format(NOT_TRANSLATABLE, value.getClass().getSimpleName(), "SQL Timestamp"));
+    }
+
+    public int getType() throws SQLException
+    {
+        checkNotClosed();
+        return resultSetType;
+    }
+
+    public TypedColumn getTypedKey() throws SQLException
+    {
+        return typedCurRowKey;
+    }
+
+    // URL (awaiting some clarifications as to how it is stored in C* ... just a validated Sting in URL format?
+    public URL getURL(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public URL getURL(String arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    // These Methods are planned to be  implemented soon; but not right now...
+    // Each set of methods has a more detailed set of issues that should be considered fully...
+
+
+    public SQLWarning getWarnings() throws SQLException
+    {
+        checkNotClosed();
+        // the rationale is there are no warnings to return in this implementation...
+        return null;
+    }
+
+
+    public boolean isAfterLast() throws SQLException
+    {
+        checkNotClosed();
+        return rowNumber == Integer.MAX_VALUE;
+    }
+
+    public boolean isBeforeFirst() throws SQLException
+    {
+        checkNotClosed();
+        return rowNumber == 0;
+    }
+
+    public boolean isClosed() throws SQLException
+    {
+        return valueMap == null;
+    }
+
+    public boolean isFirst() throws SQLException
+    {
+        checkNotClosed();
+        return rowNumber == 1;
+    }
+
+    public boolean isLast() throws SQLException
+    {
+        checkNotClosed();
+        return !rSetIter.hasNext();
+    }
+
+    public boolean isWrapperFor(Class<?> iface) throws SQLException
+    {
+        return CassandraResultSet.class.isAssignableFrom(iface);
+    }
+
+    // Navigation between rows within the returned set of rows
+    // Need to use a list iterator so next() needs completely re-thought
+
+    public boolean last() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public synchronized boolean next() throws SQLException
+    {
+        if (!values.isEmpty() || !valueMap.isEmpty())
+        {
+            values.clear();
+            valueMap.clear();
+        }
+        if (rSetIter != null && rSetIter.hasNext())
+        {
+            CqlRow row = rSetIter.next();
+            rowNumber++;
+            curRowKey = row.getKey();
+            typedCurRowKey = decoder.makeKeyColumn(keyspace, columnFamily, curRowKey);
+            List<Column> cols = row.getColumns();
+            for (Column col : cols)
+            {
+
+                TypedColumn c = decoder.makeCol(keyspace, columnFamily, col);
+                String columnName = decoder.colNameAsString(keyspace, columnFamily, col.name);
+                values.add(c);
+                indexMap.put(columnName, values.size()); // one greater than 0 based index of a list
+                valueMap.put(columnName, c);
+            }
+            return !(values.isEmpty() || valueMap.isEmpty());
+        }
+        else
+        {
+            rowNumber = Integer.MAX_VALUE;
+            return false;
+        }
+    }
+
+    public boolean previous() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public boolean relative(int arg0) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setFetchDirection(int direction) throws SQLException
+    {
+        checkNotClosed();
+
+        if (direction == FETCH_FORWARD || direction == FETCH_REVERSE || direction == FETCH_UNKNOWN)
+        {
+            if ((getType() == TYPE_FORWARD_ONLY) && (direction != FETCH_FORWARD))
+                throw new SQLSyntaxErrorException("attempt to set an illegal direction : " + direction);
+            fetchDirection = direction;
+        }
+        throw new SQLSyntaxErrorException(String.format(BAD_FETCH_DIR, direction));
+    }
+
+    public void setFetchSize(int size) throws SQLException
+    {
+        checkNotClosed();
+        if (size < 0) throw new SQLException(String.format(BAD_FETCH_SIZE, size));
+        fetchSize = size;
+    }
+
+    public <T> T unwrap(Class<T> iface) throws SQLException
+    {
+        if (iface.equals(CassandraResultSet.class)) return (T) this;
+
+        throw new SQLFeatureNotSupportedException(String.format(NO_INTERFACE, iface.getSimpleName()));
+    }
+
+    public boolean wasNull() throws SQLException
+    {
+        return wasNull;
+    }
+
+    /**
+     * RSMD implementation.  The metadata returned refers to the column
+     * values, not the column names.
+     */
+    class CResultSetMetaData implements ResultSetMetaData
+    {
+        public String getCatalogName(int column) throws SQLException
+        {
+            checkIndex(column);
+            return "";
+        }
+
+        public String getColumnClassName(int column) throws SQLException
+        {
+            checkIndex(column);
+            return values.get(column - 1).getValueType().getType().getName();
+        }
+
+        public int getColumnCount() throws SQLException
+        {
+            return values.size();
+        }
+
+        public int getColumnDisplaySize(int column) throws SQLException
+        {
+            checkIndex(column);
+            return values.get(column - 1).getValueString().length();
+        }
+
+        public String getColumnLabel(int column) throws SQLException
+        {
+            checkIndex(column);
+            return getColumnName(column);
+        }
+
+        public String getColumnName(int column) throws SQLException
+        {
+            checkIndex(column);
+            return values.get(column - 1).getNameString();
+        }
+
+        public int getColumnType(int column) throws SQLException
+        {
+            checkIndex(column);
+            return values.get(column - 1).getValueType().getJdbcType();
+        }
+
+        // Spec says "database specific type name". For Cassandra this means the abstract type.
+        public String getColumnTypeName(int column) throws SQLException
+        {
+            checkIndex(column);
+            return values.get(column - 1).getValueType().getClass().getSimpleName();
+        }
+
+        public int getPrecision(int column) throws SQLException
+        {
+            checkIndex(column);
+            TypedColumn col = values.get(column - 1);
+            return col.getValueType().getPrecision(col.getValue());
+        }
+
+        public int getScale(int column) throws SQLException
+        {
+            checkIndex(column);
+            TypedColumn tc = values.get(column - 1);
+            return tc.getValueType().getScale(tc.getValue());
+        }
+
+        public String getSchemaName(int column) throws SQLException
+        {
+            checkIndex(column);
+            return keyspace;
+        }
+
+        public String getTableName(int column) throws SQLException
+        {
+            checkIndex(column);
+            return columnFamily;
+        }
+
+        public boolean isAutoIncrement(int column) throws SQLException
+        {
+            checkIndex(column);
+            return values.get(column - 1).getValueType() instanceof CounterColumnType; // todo: check Value is correct.
+        }
+
+        public boolean isCaseSensitive(int column) throws SQLException
+        {
+            checkIndex(column);
+            TypedColumn tc = values.get(column - 1);
+            return tc.getValueType().isCaseSensitive();
+        }
+
+        public boolean isCurrency(int column) throws SQLException
+        {
+            checkIndex(column);
+            TypedColumn tc = values.get(column - 1);
+            return tc.getValueType().isCurrency();
+        }
+
+        public boolean isDefinitelyWritable(int column) throws SQLException
+        {
+            checkIndex(column);
+            return isWritable(column);
+        }
+
+        /**
+         * absence is the equivalent of null in Cassandra
+         */
+        public int isNullable(int column) throws SQLException
+        {
+            checkIndex(column);
+            return ResultSetMetaData.columnNullable;
+        }
+
+        public boolean isReadOnly(int column) throws SQLException
+        {
+            checkIndex(column);
+            return column == 0;
+        }
+
+        public boolean isSearchable(int column) throws SQLException
+        {
+            checkIndex(column);
+            return false;
+        }
+
+        public boolean isSigned(int column) throws SQLException
+        {
+            checkIndex(column);
+            TypedColumn tc = values.get(column - 1);
+            return tc.getValueType().isSigned();
+        }
+
+        public boolean isWrapperFor(Class<?> iface) throws SQLException
+        {
+            return false;
+        }
+
+        public boolean isWritable(int column) throws SQLException
+        {
+            checkIndex(column);
+            return column > 0;
+        }
+
+        public <T> T unwrap(Class<T> iface) throws SQLException
+        {
+            throw new SQLFeatureNotSupportedException(String.format(NO_INTERFACE, iface.getSimpleName()));
+        }
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraConnection.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraConnection.java
new file mode 100644
index 0000000000..c34801b53c
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraConnection.java
@@ -0,0 +1,459 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import static org.apache.cassandra.cql.jdbc.Utils.ALWAYS_AUTOCOMMIT;
+import static org.apache.cassandra.cql.jdbc.Utils.BAD_TIMEOUT;
+import static org.apache.cassandra.cql.jdbc.Utils.NO_INTERFACE;
+import static org.apache.cassandra.cql.jdbc.Utils.NO_TRANSACTIONS;
+import static org.apache.cassandra.cql.jdbc.Utils.PROTOCOL;
+import static org.apache.cassandra.cql.jdbc.Utils.SCHEMA_MISMATCH;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_SERVER_NAME;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_DATABASE_NAME;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_PASSWORD;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_PORT_NUMBER;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_USER;
+import static org.apache.cassandra.cql.jdbc.Utils.WAS_CLOSED_CON;
+import static org.apache.cassandra.cql.jdbc.Utils.createSubName;
+import static org.apache.cassandra.cql.jdbc.Utils.determineCurrentKeyspace;
+
+import java.sql.Connection;
+import java.sql.DatabaseMetaData;
+import java.sql.PreparedStatement;
+import java.sql.SQLClientInfoException;
+import java.sql.SQLException;
+import java.sql.SQLFeatureNotSupportedException;
+import java.sql.SQLInvalidAuthorizationSpecException;
+import java.sql.SQLNonTransientConnectionException;
+import java.sql.SQLRecoverableException;
+import java.sql.SQLSyntaxErrorException;
+import java.sql.SQLTimeoutException;
+import java.sql.SQLTransientConnectionException;
+import java.sql.SQLWarning;
+import java.sql.Statement;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Properties;
+
+import org.apache.cassandra.thrift.AuthenticationException;
+import org.apache.cassandra.thrift.AuthenticationRequest;
+import org.apache.cassandra.thrift.AuthorizationException;
+import org.apache.cassandra.thrift.Cassandra;
+import org.apache.cassandra.thrift.Compression;
+import org.apache.cassandra.thrift.CqlResult;
+import org.apache.cassandra.thrift.InvalidRequestException;
+import org.apache.cassandra.thrift.SchemaDisagreementException;
+import org.apache.cassandra.thrift.TimedOutException;
+import org.apache.cassandra.thrift.UnavailableException;
+import org.apache.thrift.TException;
+import org.apache.thrift.protocol.TBinaryProtocol;
+import org.apache.thrift.protocol.TProtocol;
+import org.apache.thrift.transport.TFramedTransport;
+import org.apache.thrift.transport.TSocket;
+import org.apache.thrift.transport.TTransport;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Implementation class for {@link Connection}.
+ */
+class CassandraConnection extends AbstractCassandraConnection implements Connection
+{
+
+    private static final Logger logger = LoggerFactory.getLogger(CassandraConnection.class);
+
+    public static final int DB_MAJOR_VERSION = 0;
+    public static final int DB_MINOR_VERSION = 8;
+    public static final String DB_PRODUCT_NAME = "Cassandra";
+
+    public static Compression defaultCompression = Compression.GZIP;
+
+    private final boolean autoCommit = true;
+
+    private final int transactionIsolation = Connection.TRANSACTION_NONE;
+
+    /**
+     * Client Info Properties (currently unused)
+     */
+    private Properties clientInfo = new Properties();
+
+    /**
+     * List of all Statements that have been created by this connection
+     */
+    private List<Statement> statements;
+
+    private Cassandra.Client client;
+    private TTransport transport;
+
+    protected long timeOfLastFailure = 0;
+    protected int numFailures = 0;
+    protected String username = null;
+    protected String url = null;
+    String currentKeyspace;
+    ColumnDecoder decoder;
+
+
+    /**
+     * Instantiates a new CassandraConnection.
+     */
+    public CassandraConnection(Properties props) throws SQLException
+    {
+        statements = new ArrayList<Statement>();
+        clientInfo = new Properties();
+        url = PROTOCOL + createSubName(props);
+        try
+        {
+            String host = props.getProperty(TAG_SERVER_NAME);
+            int port = Integer.parseInt(props.getProperty(TAG_PORT_NUMBER));
+            String keyspace = props.getProperty(TAG_DATABASE_NAME);
+            username = props.getProperty(TAG_USER);
+            String password = props.getProperty(TAG_PASSWORD);
+
+            TSocket socket = new TSocket(host, port);
+            transport = new TFramedTransport(socket);
+            TProtocol protocol = new TBinaryProtocol(transport);
+            client = new Cassandra.Client(protocol);
+            socket.open();
+            decoder = new ColumnDecoder(client.describe_keyspaces());
+
+            if (username != null)
+            {
+                Map<String, String> credentials = new HashMap<String, String>();
+                credentials.put("username", username);
+                if (password != null) credentials.put("password", password);
+                AuthenticationRequest areq = new AuthenticationRequest(credentials);
+                client.login(areq);
+
+            }
+
+            logger.info("Connected to {}:{}", host, port);
+
+
+            if (keyspace != null)
+            {
+                execute("USE " + keyspace);
+            }
+        }
+        catch (SchemaDisagreementException e)
+        {
+            throw new SQLRecoverableException(SCHEMA_MISMATCH);
+        }
+        catch (InvalidRequestException e)
+        {
+            throw new SQLSyntaxErrorException(e);
+        }
+        catch (UnavailableException e)
+        {
+            throw new SQLNonTransientConnectionException(e);
+        }
+        catch (TimedOutException e)
+        {
+            throw new SQLTransientConnectionException(e);
+        }
+        catch (TException e)
+        {
+            throw new SQLNonTransientConnectionException(e);
+        }
+        catch (AuthenticationException e)
+        {
+            throw new SQLInvalidAuthorizationSpecException(e);
+        }
+        catch (AuthorizationException e)
+        {
+            throw new SQLInvalidAuthorizationSpecException(e);
+        }
+    }
+
+    private final void checkNotClosed() throws SQLException
+    {
+        if (isClosed()) throw new SQLNonTransientConnectionException(WAS_CLOSED_CON);
+    }
+
+    public void clearWarnings() throws SQLException
+    {
+        // This implementation does not support the collection of warnings so clearing is a no-op
+        // but it is still an exception to call this on a closed connection.
+        checkNotClosed();
+    }
+
+    /**
+     * On close of connection.
+     */
+    public synchronized void close() throws SQLException
+    {
+        if (isConnected())
+        {
+            // spec says to close all statements associated with this connection upon close
+            for (Statement statement : statements) statement.close();
+            // then disconnect from the transport                
+            disconnect();
+        }
+    }
+
+    public void commit() throws SQLException
+    {
+        checkNotClosed();
+        throw new SQLFeatureNotSupportedException(ALWAYS_AUTOCOMMIT);
+    }
+
+    public Statement createStatement() throws SQLException
+    {
+        checkNotClosed();
+        statements.add(new CassandraStatement(this));
+        return statements.get(statements.size() - 1);
+    }
+
+    public Statement createStatement(int resultSetType, int resultSetConcurrency) throws SQLException
+    {
+        checkNotClosed();
+        statements.add(new CassandraStatement(this, null, resultSetType, resultSetConcurrency));
+        return statements.get(statements.size() - 1);
+    }
+
+    public Statement createStatement(int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException
+    {
+        checkNotClosed();
+        statements.add(new CassandraStatement(this, null, resultSetType, resultSetConcurrency, resultSetHoldability));
+        return statements.get(statements.size() - 1);
+    }
+
+    public boolean getAutoCommit() throws SQLException
+    {
+        checkNotClosed();
+        return autoCommit;
+    }
+
+    public String getCatalog() throws SQLException
+    {
+        // This implementation does not support the catalog names so null is always returned if the connection is open.
+        // but it is still an exception to call this on a closed connection.
+        checkNotClosed();
+        return null;
+    }
+
+    public Properties getClientInfo() throws SQLException
+    {
+        checkNotClosed();
+        return clientInfo;
+    }
+
+    public String getClientInfo(String label) throws SQLException
+    {
+        checkNotClosed();
+        return clientInfo.getProperty(label);
+    }
+
+    public int getHoldability() throws SQLException
+    {
+        checkNotClosed();
+        // the rationale is there are really no commits in Cassandra so no boundary...
+        return CResultSet.DEFAULT_HOLDABILITY;
+    }
+
+    public DatabaseMetaData getMetaData() throws SQLException
+    {
+        checkNotClosed();
+        return new CassandraDatabaseMetaData(this);
+    }
+
+    public int getTransactionIsolation() throws SQLException
+    {
+        checkNotClosed();
+        return transactionIsolation;
+    }
+
+    public SQLWarning getWarnings() throws SQLException
+    {
+        checkNotClosed();
+        // the rationale is there are no warnings to return in this implementation...
+        return null;
+    }
+
+    public synchronized boolean isClosed() throws SQLException
+    {
+
+        return !isConnected();
+    }
+
+    public boolean isReadOnly() throws SQLException
+    {
+        checkNotClosed();
+        return false;
+    }
+
+    public boolean isValid(int timeout) throws SQLException
+    {
+        checkNotClosed();
+        if (timeout < 0) throw new SQLTimeoutException(BAD_TIMEOUT);
+
+        // this needs to be more robust. Some query needs to be made to verify connection is really up.
+        return !isClosed();
+    }
+
+    public boolean isWrapperFor(Class<?> arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public String nativeSQL(String sql) throws SQLException
+    {
+        checkNotClosed();
+        // the rationale is there are no distinction between grammars in this implementation...
+        // so we are just return the input argument
+        return sql;
+    }
+
+    public PreparedStatement prepareStatement(String sql) throws SQLException
+    {
+        checkNotClosed();
+        statements.add(new CassandraPreparedStatement(this, sql));
+        return (PreparedStatement) statements.get(statements.size() - 1);
+    }
+
+    public PreparedStatement prepareStatement(String arg0, int arg1, int arg2) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public PreparedStatement prepareStatement(String arg0, int arg1, int arg2, int arg3) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void rollback() throws SQLException
+    {
+        checkNotClosed();
+        throw new SQLFeatureNotSupportedException(ALWAYS_AUTOCOMMIT);
+    }
+
+    public void setAutoCommit(boolean autoCommit) throws SQLException
+    {
+        checkNotClosed();
+        if (!autoCommit) throw new SQLFeatureNotSupportedException(ALWAYS_AUTOCOMMIT);
+    }
+
+    public void setCatalog(String arg0) throws SQLException
+    {
+        checkNotClosed();
+        // the rationale is there are no catalog name to set in this implementation...
+        // so we are "silently ignoring" the request
+    }
+
+    public void setClientInfo(Properties props) throws SQLClientInfoException
+    {
+        // we don't use them but we will happily collect them for now...
+        if (props != null) clientInfo = props;
+    }
+
+    public void setClientInfo(String key, String value) throws SQLClientInfoException
+    {
+        // we don't use them but we will happily collect them for now...
+        clientInfo.setProperty(key, value);
+    }
+
+    public void setHoldability(int arg0) throws SQLException
+    {
+        checkNotClosed();
+        // the rationale is there are no holdability to set in this implementation...
+        // so we are "silently ignoring" the request
+    }
+
+    public void setReadOnly(boolean arg0) throws SQLException
+    {
+        checkNotClosed();
+        // the rationale is all connections are read/write in the Cassandra implementation...
+        // so we are "silently ignoring" the request
+    }
+
+    public void setTransactionIsolation(int level) throws SQLException
+    {
+        checkNotClosed();
+        if (level != Connection.TRANSACTION_NONE) throw new SQLFeatureNotSupportedException(NO_TRANSACTIONS);
+    }
+
+    public <T> T unwrap(Class<T> iface) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(String.format(NO_INTERFACE, iface.getSimpleName()));
+    }
+
+    /**
+     * Execute a CQL query.
+     *
+     * @param queryStr    a CQL query string
+     * @param compression query compression to use
+     * @return the query results encoded as a CqlResult structure
+     * @throws InvalidRequestException     on poorly constructed or illegal requests
+     * @throws UnavailableException        when not all required replicas could be created/read
+     * @throws TimedOutException           when a cluster operation timed out
+     * @throws SchemaDisagreementException when the client side and server side are at different versions of schema (Thrift)
+     * @throws TException                  when there is a error in Thrift processing
+     */
+    public CqlResult execute(String queryStr, Compression compression) throws InvalidRequestException, UnavailableException, TimedOutException, SchemaDisagreementException, TException
+    {
+        currentKeyspace = determineCurrentKeyspace(queryStr, currentKeyspace);
+
+        try
+        {
+            return client.execute_cql_query(Utils.compressQuery(queryStr, compression), compression);
+        }
+        catch (TException error)
+        {
+            numFailures++;
+            timeOfLastFailure = System.currentTimeMillis();
+            throw error;
+        }
+    }
+
+    /**
+     * Execute a CQL query using the default compression methodology.
+     *
+     * @param queryStr a CQL query string
+     * @return the query results encoded as a CqlResult structure
+     * @throws InvalidRequestException     on poorly constructed or illegal requests
+     * @throws UnavailableException        when not all required replicas could be created/read
+     * @throws TimedOutException           when a cluster operation timed out
+     * @throws SchemaDisagreementException when the client side and server side are at different versions of schema (Thrift)
+     * @throws TException                  when there is a error in Thrift processing
+     */
+    public CqlResult execute(String queryStr) throws InvalidRequestException, UnavailableException, TimedOutException, SchemaDisagreementException, TException
+    {
+        return execute(queryStr, defaultCompression);
+    }
+
+    /**
+     * Shutdown the remote connection
+     */
+    public void disconnect()
+    {
+        transport.close();
+    }
+
+    /**
+     * Connection state.
+     */
+    public boolean isConnected()
+    {
+        return transport.isOpen();
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDataSource.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDataSource.java
new file mode 100644
index 0000000000..cdb42a270d
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDataSource.java
@@ -0,0 +1,168 @@
+
+package org.apache.cassandra.cql.jdbc;
+
+import static org.apache.cassandra.cql.jdbc.Utils.HOST_REQUIRED;
+import static org.apache.cassandra.cql.jdbc.Utils.NO_INTERFACE;
+import static org.apache.cassandra.cql.jdbc.Utils.PROTOCOL;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_SERVER_NAME;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_DATABASE_NAME;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_PASSWORD;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_PORT_NUMBER;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_USER;
+import static org.apache.cassandra.cql.jdbc.Utils.createSubName;
+
+import java.io.PrintWriter;
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.SQLException;
+import java.sql.SQLFeatureNotSupportedException;
+import java.sql.SQLNonTransientConnectionException;
+import java.util.Properties;
+
+import javax.sql.DataSource;
+
+public class CassandraDataSource implements DataSource
+{
+
+    static
+    {
+        try
+        {
+            Class.forName("org.apache.cassandra.cql.jdbc.CassandraDriver");
+        }
+        catch (ClassNotFoundException e)
+        {
+            throw new RuntimeException(e);
+        }
+    }
+
+    protected static final String description = "Cassandra Data Source";
+
+    protected String serverName;
+
+    protected int    portNumber = 9160;
+
+    protected String databaseName;
+
+    protected String user;
+
+    protected String password;
+
+    public CassandraDataSource(String host, int port, String keyspace, String user, String password)
+    {
+        if (host != null) setServerName(host);
+        if (port != -1) setPortNumber(port);
+        setDatabaseName(keyspace);
+        setUser(user);
+        setPassword(password);
+    }
+
+    public String getDescription()
+    {
+        return description;
+    }
+
+    public String getServerName()
+    {
+        return serverName;
+    }
+
+    public void setServerName(String serverName)
+    {
+        this.serverName = serverName;
+    }
+
+    public int getPortNumber()
+    {
+        return portNumber;
+    }
+
+    public void setPortNumber(int portNumber)
+    {
+        this.portNumber = portNumber;
+    }
+
+    public String getDatabaseName()
+    {
+        return databaseName;
+    }
+
+    public void setDatabaseName(String databaseName)
+    {
+        this.databaseName = databaseName;
+    }
+
+    public String getUser()
+    {
+        return user;
+    }
+
+    public void setUser(String user)
+    {
+        this.user = user;
+    }
+
+    public String getPassword()
+    {
+        return password;
+    }
+
+    public void setPassword(String password)
+    {
+        this.password = password;
+    }
+
+    public Connection getConnection() throws SQLException
+    {
+        return getConnection(null, null);
+    }
+
+    public Connection getConnection(String user, String password) throws SQLException
+    {
+        Properties props = new Properties();
+        
+        this.user = user;
+        this.password = password;
+        
+        if (this.serverName!=null) props.setProperty(TAG_SERVER_NAME, this.serverName);
+        else throw new SQLNonTransientConnectionException(HOST_REQUIRED);
+        props.setProperty(TAG_PORT_NUMBER, ""+this.portNumber);
+        if (this.databaseName!=null) props.setProperty(TAG_DATABASE_NAME, this.databaseName);
+        if (user!=null) props.setProperty(TAG_USER, user);
+        if (password!=null) props.setProperty(TAG_PASSWORD, password);
+
+        String url = PROTOCOL+createSubName(props);
+        return DriverManager.getConnection(url, props);
+    }
+
+    public int getLoginTimeout() throws SQLException
+    {
+        return DriverManager.getLoginTimeout();
+    }
+
+    public PrintWriter getLogWriter() throws SQLException
+    {
+        return DriverManager.getLogWriter();
+    }
+
+    public void setLoginTimeout(int timeout) throws SQLException
+    {
+        DriverManager.setLoginTimeout(timeout);
+    }
+
+    public void setLogWriter(PrintWriter writer) throws SQLException
+    {
+        DriverManager.setLogWriter(writer);
+    }
+
+    public boolean isWrapperFor(Class<?> iface) throws SQLException
+    {
+        return iface.isAssignableFrom(getClass());
+    }
+
+    public <T> T unwrap(Class<T> iface) throws SQLException
+    {
+        if (iface.isAssignableFrom(getClass())) return iface.cast(this);
+        throw new SQLFeatureNotSupportedException(String.format(NO_INTERFACE, iface.getSimpleName()));
+    }      
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDatabaseMetaData.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDatabaseMetaData.java
new file mode 100644
index 0000000000..502a9b15e2
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDatabaseMetaData.java
@@ -0,0 +1,922 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import static org.apache.cassandra.cql.jdbc.Utils.NO_INTERFACE;
+
+import java.sql.Connection;
+import java.sql.DatabaseMetaData;
+import java.sql.ResultSet;
+import java.sql.RowIdLifetime;
+import java.sql.SQLException;
+import java.sql.SQLFeatureNotSupportedException;
+
+import org.apache.cassandra.db.DBConstants;
+import org.apache.cassandra.utils.FBUtilities;
+
+public class CassandraDatabaseMetaData implements DatabaseMetaData
+{
+    private CassandraConnection connection;
+    
+    public CassandraDatabaseMetaData(CassandraConnection connection)
+    {
+        this.connection = connection;
+    }
+    
+    public boolean isWrapperFor(Class<?> iface) throws SQLException
+    {
+        return iface.isAssignableFrom(getClass());
+    }
+
+    public <T> T unwrap(Class<T> iface) throws SQLException
+    {
+        if (iface.isAssignableFrom(getClass())) return iface.cast(this);
+        throw new SQLFeatureNotSupportedException(String.format(NO_INTERFACE, iface.getSimpleName()));
+    }      
+
+    public boolean allProceduresAreCallable() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean allTablesAreSelectable() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean autoCommitFailureClosesAllResultSets() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean dataDefinitionCausesTransactionCommit() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean dataDefinitionIgnoredInTransactions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean deletesAreDetected(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean doesMaxRowSizeIncludeBlobs() throws SQLException
+    {
+        return false;
+    }
+
+    public ResultSet getAttributes(String arg0, String arg1, String arg2, String arg3) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getBestRowIdentifier(String arg0, String arg1, String arg2, int arg3, boolean arg4) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getCatalogSeparator() throws SQLException
+    {
+        return "";
+    }
+
+    public String getCatalogTerm() throws SQLException
+    {
+        return "";
+    }
+
+    public ResultSet getCatalogs() throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getClientInfoProperties() throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getColumnPrivileges(String arg0, String arg1, String arg2, String arg3) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getColumns(String arg0, String arg1, String arg2, String arg3) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public Connection getConnection() throws SQLException
+    {
+        return connection;
+    }
+
+    public ResultSet getCrossReference(String arg0, String arg1, String arg2, String arg3, String arg4, String arg5) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public int getDatabaseMajorVersion() throws SQLException
+    {
+        return CassandraConnection.DB_MAJOR_VERSION;
+    }
+
+    public int getDatabaseMinorVersion() throws SQLException
+    {
+        return CassandraConnection.DB_MINOR_VERSION;
+    }
+
+    public String getDatabaseProductName() throws SQLException
+    {
+        return CassandraConnection.DB_PRODUCT_NAME;
+    }
+
+    public String getDatabaseProductVersion() throws SQLException
+    {
+        return String.format("%d.%d", CassandraConnection.DB_MAJOR_VERSION,CassandraConnection.DB_MINOR_VERSION);
+    }
+
+    public int getDefaultTransactionIsolation() throws SQLException
+    {
+        return Connection.TRANSACTION_NONE;
+    }
+
+    public int getDriverMajorVersion()
+    {
+        return CassandraDriver.DVR_MAJOR_VERSION;
+    }
+
+    public int getDriverMinorVersion()
+    {
+        return CassandraDriver.DVR_MINOR_VERSION;
+    }
+
+    public String getDriverName() throws SQLException
+    {
+        return CassandraDriver.DVR_NAME;
+    }
+
+    public String getDriverVersion() throws SQLException
+    {
+        return String.format("%d.%d.%d", CassandraDriver.DVR_MAJOR_VERSION,CassandraDriver.DVR_MINOR_VERSION,CassandraDriver.DVR_PATCH_VERSION);
+    }
+
+    public ResultSet getExportedKeys(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getExtraNameCharacters() throws SQLException
+    {
+        return "";
+    }
+
+    public ResultSet getFunctionColumns(String arg0, String arg1, String arg2, String arg3) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getFunctions(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getIdentifierQuoteString() throws SQLException
+    {
+        return "'";
+    }
+
+    public ResultSet getImportedKeys(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getIndexInfo(String arg0, String arg1, String arg2, boolean arg3, boolean arg4) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public int getJDBCMajorVersion() throws SQLException
+    {
+        return 4;
+    }
+
+    public int getJDBCMinorVersion() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxBinaryLiteralLength() throws SQLException
+    {
+        // Cassandra can represent a 2GB value, but CQL has to encode it in hex
+        return Integer.MAX_VALUE / 2;
+    }
+
+    public int getMaxCatalogNameLength() throws SQLException
+    {
+        return Short.MAX_VALUE;
+    }
+
+    public int getMaxCharLiteralLength() throws SQLException
+    {
+        return Integer.MAX_VALUE;
+    }
+
+    public int getMaxColumnNameLength() throws SQLException
+    {
+        return Short.MAX_VALUE;
+    }
+
+    public int getMaxColumnsInGroupBy() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxColumnsInIndex() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxColumnsInOrderBy() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxColumnsInSelect() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxColumnsInTable() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxConnections() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxCursorNameLength() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxIndexLength() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxProcedureNameLength() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxRowSize() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxSchemaNameLength() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxStatementLength() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxStatements() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxTableNameLength() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxTablesInSelect() throws SQLException
+    {
+        return 0;
+    }
+
+    public int getMaxUserNameLength() throws SQLException
+    {
+        return 0;
+    }
+
+    public String getNumericFunctions() throws SQLException
+    {
+        return null;
+    }
+
+    public ResultSet getPrimaryKeys(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getProcedureColumns(String arg0, String arg1, String arg2, String arg3) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getProcedureTerm() throws SQLException
+    {
+        return "";
+    }
+
+    public ResultSet getProcedures(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public int getResultSetHoldability() throws SQLException
+    {
+        return CResultSet.DEFAULT_HOLDABILITY;
+    }
+
+    public RowIdLifetime getRowIdLifetime() throws SQLException
+    {
+        return RowIdLifetime.ROWID_UNSUPPORTED;
+    }
+
+    public String getSQLKeywords() throws SQLException
+    {
+        return "";
+    }
+
+    public int getSQLStateType() throws SQLException
+    {
+        return sqlStateSQL;
+    }
+
+    public String getSchemaTerm() throws SQLException
+    {
+        return "";
+    }
+
+    public ResultSet getSchemas() throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getSchemas(String arg0, String arg1) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getSearchStringEscape() throws SQLException
+    {
+        return "\\";
+    }
+
+    public String getStringFunctions() throws SQLException
+    {
+        return "";
+    }
+
+    public ResultSet getSuperTables(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getSuperTypes(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getSystemFunctions() throws SQLException
+    {
+        return "";
+    }
+
+    public ResultSet getTablePrivileges(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getTableTypes() throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getTables(String arg0, String arg1, String arg2, String[] arg3) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getTimeDateFunctions() throws SQLException
+    {
+        return "";
+    }
+
+    public ResultSet getTypeInfo() throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public ResultSet getUDTs(String arg0, String arg1, String arg2, int[] arg3) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public String getURL() throws SQLException
+    {
+        return connection.url;
+    }
+
+    public String getUserName() throws SQLException
+    {
+        return (connection.username==null) ? "" : connection.username;
+    }
+
+    public ResultSet getVersionColumns(String arg0, String arg1, String arg2) throws SQLException
+    {
+        return new CResultSet();
+    }
+
+    public boolean insertsAreDetected(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean isCatalogAtStart() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean isReadOnly() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean locatorsUpdateCopy() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean nullPlusNonNullIsNull() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean nullsAreSortedAtEnd() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean nullsAreSortedAtStart() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean nullsAreSortedHigh() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean nullsAreSortedLow() throws SQLException
+    {
+
+        return false;
+    }
+
+    public boolean othersDeletesAreVisible(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean othersInsertsAreVisible(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean othersUpdatesAreVisible(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean ownDeletesAreVisible(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean ownInsertsAreVisible(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean ownUpdatesAreVisible(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean storesLowerCaseIdentifiers() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean storesLowerCaseQuotedIdentifiers() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean storesMixedCaseIdentifiers() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean storesMixedCaseQuotedIdentifiers() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean storesUpperCaseIdentifiers() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean storesUpperCaseQuotedIdentifiers() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsANSI92EntryLevelSQL() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsANSI92FullSQL() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsANSI92IntermediateSQL() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsAlterTableWithAddColumn() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean supportsAlterTableWithDropColumn() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean supportsBatchUpdates() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsCatalogsInDataManipulation() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsCatalogsInIndexDefinitions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsCatalogsInPrivilegeDefinitions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsCatalogsInProcedureCalls() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsCatalogsInTableDefinitions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsColumnAliasing() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsConvert() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsConvert(int arg0, int arg1) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsCoreSQLGrammar() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsCorrelatedSubqueries() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsDataDefinitionAndDataManipulationTransactions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsDataManipulationTransactionsOnly() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsDifferentTableCorrelationNames() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsExpressionsInOrderBy() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsExtendedSQLGrammar() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsFullOuterJoins() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsGetGeneratedKeys() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsGroupBy() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsGroupByBeyondSelect() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsGroupByUnrelated() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsIntegrityEnhancementFacility() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsLikeEscapeClause() throws SQLException
+    {
+
+        return false;
+    }
+
+    public boolean supportsLimitedOuterJoins() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsMinimumSQLGrammar() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsMixedCaseIdentifiers() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean supportsMixedCaseQuotedIdentifiers() throws SQLException
+    {
+        return true;
+    }
+
+    public boolean supportsMultipleOpenResults() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsMultipleResultSets() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsMultipleTransactions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsNamedParameters() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsNonNullableColumns() throws SQLException
+    {
+
+        return false;
+    }
+
+    public boolean supportsOpenCursorsAcrossCommit() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsOpenCursorsAcrossRollback() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsOpenStatementsAcrossCommit() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsOpenStatementsAcrossRollback() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsOrderByUnrelated() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsOuterJoins() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsPositionedDelete() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsPositionedUpdate() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsResultSetConcurrency(int arg0, int arg1) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsResultSetHoldability(int holdability) throws SQLException
+    {
+
+        return ResultSet.HOLD_CURSORS_OVER_COMMIT==holdability;
+    }
+
+    public boolean supportsResultSetType(int type) throws SQLException
+    {
+
+        return ResultSet.TYPE_FORWARD_ONLY==type;
+    }
+
+    public boolean supportsSavepoints() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSchemasInDataManipulation() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSchemasInIndexDefinitions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSchemasInPrivilegeDefinitions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSchemasInProcedureCalls() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSchemasInTableDefinitions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSelectForUpdate() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsStatementPooling() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsStoredFunctionsUsingCallSyntax() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsStoredProcedures() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSubqueriesInComparisons() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSubqueriesInExists() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSubqueriesInIns() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsSubqueriesInQuantifieds() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsTableCorrelationNames() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsTransactionIsolationLevel(int level) throws SQLException
+    {
+
+        return Connection.TRANSACTION_NONE==level;
+    }
+
+    public boolean supportsTransactions() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsUnion() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean supportsUnionAll() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean updatesAreDetected(int arg0) throws SQLException
+    {
+        return false;
+    }
+
+    public boolean usesLocalFilePerTable() throws SQLException
+    {
+        return false;
+    }
+
+    public boolean usesLocalFiles() throws SQLException
+    {
+        return false;
+    }
+
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDriver.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDriver.java
new file mode 100644
index 0000000000..31edfd7e36
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraDriver.java
@@ -0,0 +1,139 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import static org.apache.cassandra.cql.jdbc.Utils.PROTOCOL;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_PASSWORD;
+import static org.apache.cassandra.cql.jdbc.Utils.TAG_USER;
+
+import java.sql.Connection;
+import java.sql.Driver;
+import java.sql.DriverManager;
+import java.sql.DriverPropertyInfo;
+import java.sql.SQLException;
+import java.util.Properties;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * The Class CassandraDriver.
+ */
+public class CassandraDriver implements Driver
+{
+    public static final int DVR_MAJOR_VERSION = 1;
+
+    public static final int DVR_MINOR_VERSION = 0;
+
+    public static final int DVR_PATCH_VERSION = 4;
+
+    public static final String DVR_NAME = "Cassandra JDBC Driver";
+
+    private static final Logger logger = LoggerFactory.getLogger(CassandraDriver.class);
+
+    static
+    {
+        // Register the CassandraDriver with DriverManager
+        try
+        {
+            CassandraDriver driverInst = new CassandraDriver();
+            DriverManager.registerDriver(driverInst);
+        }
+        catch (SQLException e)
+        {
+            throw new RuntimeException(e.getMessage());
+        }
+    }
+
+    /**
+     * Method to validate whether provided connection url matches with pattern or not.
+     */
+    public boolean acceptsURL(String url) throws SQLException
+    {
+        return url.startsWith(PROTOCOL);
+    }
+
+    /**
+     * Method to return connection instance for given connection url and connection props.
+     */
+    public Connection connect(String url, Properties props) throws SQLException
+    {
+        Properties finalProps;
+        if (acceptsURL(url))
+        {
+            // parse the URL into a set of Properties
+            finalProps = Utils.parseURL(url);
+
+            // override any matching values in finalProps with values from props
+            finalProps.putAll(props);
+
+            if (logger.isDebugEnabled()) logger.debug("Final Properties to Connection: {}", finalProps);
+
+            return new CassandraConnection(finalProps);
+        }
+        else
+        {
+            return null; // signal it is the wrong driver for this protocol:subprotocol
+        }
+    }
+
+    /**
+     * Returns default major version.
+     */
+    public int getMajorVersion()
+    {
+        return DVR_MAJOR_VERSION;
+    }
+
+    /**
+     * Returns default minor version.
+     */
+    public int getMinorVersion()
+    {
+        return DVR_MINOR_VERSION;
+    }
+
+    /**
+     * Returns default driver property info object.
+     */
+    public DriverPropertyInfo[] getPropertyInfo(String url, Properties props) throws SQLException
+    {
+        if (props == null) props = new Properties();
+
+        DriverPropertyInfo[] info = new DriverPropertyInfo[2];
+
+        info[0] = new DriverPropertyInfo(TAG_USER, props.getProperty(TAG_USER));
+        info[0].description = "The 'user' property";
+
+        info[1] = new DriverPropertyInfo(TAG_PASSWORD, props.getProperty(TAG_PASSWORD));
+        info[1].description = "The 'password' property";
+
+        return info;
+    }
+
+    /**
+     * Returns true, if it is jdbc compliant.
+     */
+    public boolean jdbcCompliant()
+    {
+        return false;
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraPreparedStatement.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraPreparedStatement.java
new file mode 100644
index 0000000000..348dfc652e
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraPreparedStatement.java
@@ -0,0 +1,556 @@
+package org.apache.cassandra.cql.jdbc;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+import static org.apache.cassandra.cql.jdbc.Utils.determineCurrentKeyspace;
+import static org.apache.cassandra.cql.jdbc.Utils.determineCurrentColumnFamily;
+import static org.apache.cassandra.cql.jdbc.Utils.NO_CF;
+import static org.apache.cassandra.cql.jdbc.Utils.NO_COMPARATOR;
+import static org.apache.cassandra.cql.jdbc.Utils.NO_VALIDATOR;
+
+import org.apache.cassandra.db.marshal.*;
+
+import java.io.InputStream;
+import java.io.Reader;
+import java.math.BigDecimal;
+import java.math.BigInteger;
+import java.net.URL;
+import java.nio.ByteBuffer;
+import java.sql.Array;
+import java.sql.Blob;
+import java.sql.Clob;
+import java.sql.Date;
+import java.sql.NClob;
+import java.sql.ParameterMetaData;
+import java.sql.PreparedStatement;
+import java.sql.Ref;
+import java.sql.ResultSet;
+import java.sql.ResultSetMetaData;
+import java.sql.RowId;
+import java.sql.SQLDataException;
+import java.sql.SQLException;
+import java.sql.SQLFeatureNotSupportedException;
+import java.sql.SQLTransientException;
+import java.sql.SQLXML;
+import java.sql.Time;
+import java.sql.Timestamp;
+import java.util.ArrayList;
+import java.util.Calendar;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+public class CassandraPreparedStatement extends CassandraStatement implements PreparedStatement
+{
+    //    private static final Pattern Parameterizable = Pattern.compile("(SELECT|DELETE|UPDATE)\\s+.*", Pattern.CASE_INSENSITIVE);
+    private static final Pattern Select = Pattern.compile("SELECT[\\s+FIRST\\s+\\d+]?[\\s+REVERSED]?\\s+(.*)WHERE\\s+(.*)", Pattern.CASE_INSENSITIVE);
+    private static final Pattern Update = Pattern.compile("UPDATE\\s+\\w+.*\\s+SET\\s+(.*)\\s+WHERE KEY(.*)", Pattern.CASE_INSENSITIVE);
+    private static final Pattern Delete = Pattern.compile("DELETE\\s+(.*)\\s+FROM\\s+\\w+\\s+WHERE KEY(.*)", Pattern.CASE_INSENSITIVE);
+
+    // current set of bound variables.
+    private final Map<Integer, Object> variables = new HashMap<Integer, Object>();
+
+    // for batching. These are the queries that have been batched and not executed.
+    private final List<String> queries = new ArrayList<String>();
+
+    CassandraPreparedStatement(CassandraConnection con, String cql) throws SQLException
+    {
+        super(con, cql);
+    }
+
+    // impl specific methods start here.
+
+    // double quotes strings (in parameters)
+    private static String makeCqlString(String s)
+    {
+        // escape any single-quotes with double single-quotes.
+        return s.replaceAll("\'", "\'\'");
+    }
+
+    // null type means just call param.toString() and quote it (default for keys).
+    private static String applySimpleBindings(String q, AbstractType type, ParameterIterator params) throws SQLException
+    {
+        assert type != null;
+        // we need to keep track of whether or not we are between quotes and ignore any question marks within them
+        // so that they are not substituted.  
+        StringBuffer sb = new StringBuffer();
+        boolean between = false;
+        for (char c : q.toCharArray())
+        {
+            if (c == '\'')
+                between = !between;
+            if (between)
+                sb.append(c);
+            else if (c == '?') // !between if we got here.
+            {
+                try
+                {
+                    // perform substitution!
+                    Object param = params.nextParam();
+                    String stringParam = type == null ? param.toString() : type.toString(param);
+                    stringParam = makeCqlString(stringParam);
+                    if (type == null || type.needsQuotes())
+                        stringParam = "'" + stringParam + "'";
+                    sb.append(stringParam);
+                }
+                catch (ClassCastException ex)
+                {
+                    throw new SQLException("Mismatched types: " + ex.getLocalizedMessage());
+                }
+            }
+            else
+                sb.append(c);
+
+        }
+        return sb.toString();
+    }
+
+    private static String applyDualBindings(String q, AbstractType ltype, AbstractType rtype, ParameterIterator params) throws SQLException
+    {
+        StringBuffer sb = new StringBuffer();
+        boolean between = false;
+        boolean left = true; // we always start on the left-hand side of a statement. we switch state if we reach a comma and we are not between.
+        for (char c : q.toCharArray())
+        {
+            if (c == '\'')
+                between = !between;
+            if (c == '=' && !between)
+                left = false;
+            if (c == ',' && !between)
+                left = true;
+
+            if (c == '?' && !between)
+            {
+                try
+                {
+                    Object param = params.nextParam();
+                    AbstractType type = left ? ltype : rtype;
+                    String stringParam = makeCqlString(type.toString(param));
+                    if (type.needsQuotes())
+                        stringParam = "'" + stringParam + "'";
+                    sb.append(stringParam);
+                }
+                catch (ClassCastException ex)
+                {
+                    throw new SQLException("Mismatched types: " + ex.getLocalizedMessage());
+                }
+            }
+            else
+                sb.append(c);
+        }
+        return sb.toString();
+    }
+
+    /**
+     * applies current bindings to produce a string that can be sent to the server.
+     */
+    public synchronized String makeCql() throws SQLException
+    {
+        // break cql up
+        Matcher m;
+        m = Delete.matcher(cql);
+        if (m.matches())
+            return makeDelete(m.end(1));
+        m = Update.matcher(cql);
+        if (m.matches())
+            return makeUpdate(m.end(1));
+        m = Select.matcher(cql);
+        if (m.matches())
+            return makeSelect(m.end(1));
+
+        // if we made it this far, cql is not parameterizable. this isn't bad, there is just nothing to be done.
+        return cql;
+    }
+
+    // subs parameters into a delete statement.
+    private String makeDelete(int pivot) throws SQLException
+    {
+        String keyspace = determineCurrentKeyspace(cql, connection.currentKeyspace);
+        String columnFamily = determineCurrentColumnFamily(cql);
+        if (columnFamily == null) throw new SQLTransientException(NO_CF);
+
+        ParameterIterator params = new ParameterIterator();
+        String left = cql.substring(0, pivot);
+        AbstractType leftType = connection.decoder.getComparator(keyspace, columnFamily);
+        if (leftType == null) throw new SQLDataException(String.format(NO_COMPARATOR, keyspace, columnFamily));
+        left = applySimpleBindings(left, leftType, params);
+
+        String right = cql.substring(pivot);
+        AbstractType keyVald = connection.decoder.getKeyValidator(keyspace, columnFamily);
+        if (keyVald == null) throw new SQLDataException(String.format(NO_VALIDATOR, keyspace, columnFamily));
+        right = applySimpleBindings(right, keyVald, params);
+        return left + right;
+    }
+
+    // subs parameters into a select statement.
+    private String makeSelect(int pivot) throws SQLException
+    {
+        String keyspace = determineCurrentKeyspace(cql, connection.currentKeyspace);
+        String columnFamily = determineCurrentColumnFamily(cql);
+        if (columnFamily == null) throw new SQLTransientException(NO_CF);
+
+        ParameterIterator params = new ParameterIterator();
+        String left = cql.substring(0, pivot);
+        AbstractType leftType = connection.decoder.getComparator(keyspace, columnFamily);
+        if (leftType == null) throw new SQLDataException(String.format(NO_COMPARATOR, keyspace, columnFamily));
+        left = applySimpleBindings(left, leftType, params);
+
+        String right = cql.substring(pivot);
+        AbstractType keyVald = connection.decoder.getKeyValidator(keyspace, columnFamily);
+        if (keyVald == null) throw new SQLDataException(String.format(NO_VALIDATOR, keyspace, columnFamily));
+        right = applySimpleBindings(right, keyVald, params);
+        return left + right;
+    }
+
+    // subs parameters into an update statement.
+    private String makeUpdate(int pivot) throws SQLException
+    {
+        // this one is a little bit different. left contains key=value pairs. we use the comparator for the left side,
+        // the validator for the right side.  right side is treated as a key.
+        String keyspace = determineCurrentKeyspace(cql, connection.currentKeyspace);
+        String columnFamily = determineCurrentColumnFamily(cql);
+        if (columnFamily == null) throw new SQLTransientException(NO_CF);
+
+        ParameterIterator params = new ParameterIterator();
+        String left = cql.substring(0, pivot);
+        AbstractType leftComp = connection.decoder.getComparator(keyspace, columnFamily);
+        if (leftComp == null) throw new SQLDataException(String.format(NO_COMPARATOR, keyspace, columnFamily));
+
+        AbstractType leftVald = connection.decoder.getComparator(keyspace, columnFamily);
+        if (leftVald == null) throw new SQLDataException(String.format(NO_VALIDATOR, keyspace, columnFamily));
+        left = applyDualBindings(left, leftComp, leftVald, params);
+
+        String right = cql.substring(pivot);
+        AbstractType keyVald = connection.decoder.getKeyValidator(keyspace, columnFamily);
+        if (keyVald == null) throw new SQLDataException(String.format(NO_VALIDATOR, keyspace, columnFamily));
+        right = applySimpleBindings(right, keyVald, params);
+        return left + right;
+    }
+
+
+    // standard API methods follow.
+
+    public void addBatch() throws SQLException
+    {
+        queries.add(makeCql());
+    }
+
+    public synchronized void clearParameters() throws SQLException
+    {
+        variables.clear();
+    }
+
+    public boolean execute() throws SQLException
+    {
+        return this.cql != null && super.execute(makeCql());
+    }
+
+    public ResultSet executeQuery() throws SQLException
+    {
+        return this.cql == null ? null : super.executeQuery(makeCql());
+    }
+
+    public int executeUpdate() throws SQLException
+    {
+        return this.cql == null ? 0 : super.executeUpdate(makeCql());
+    }
+
+    public ResultSetMetaData getMetaData() throws SQLException
+    {
+        // todo: current impl of RSMD relies on knowing the results. implementing this will require refactoring CRSMD into 
+        // two classes: the first will be an implementation whose methods don't rely on knowing the results, the second
+        // will implement the full CRSMD interface and extend or compose the first.
+        throw new SQLFeatureNotSupportedException("PreparedStatement.getMetaData() hasn't been implemented yet.");
+    }
+
+    public void setByte(int parameterIndex, byte x) throws SQLException
+    {
+        setObject(parameterIndex, new byte[]{ x });
+    }
+
+    public void setBytes(int parameterIndex, byte[] x) throws SQLException
+    {
+        setObject(parameterIndex, ByteBuffer.wrap(x));
+    }
+
+    public void setInt(int parameterIndex, int x) throws SQLException
+    {
+        setObject(parameterIndex, new BigInteger(Integer.toString(x)));
+    }
+
+    public void setLong(int parameterIndex, long x) throws SQLException
+    {
+        setObject(parameterIndex, x);
+    }
+
+    public void setNString(int parameterIndex, String value) throws SQLException
+    {
+        setString(parameterIndex, value);
+    }
+
+    public void setObject(int parameterIndex, Object x) throws SQLException
+    {
+        variables.put(parameterIndex, x);
+    }
+
+    public void setShort(int parameterIndex, short x) throws SQLException
+    {
+        setInt(parameterIndex, x);
+    }
+
+    public void setString(int parameterIndex, String x) throws SQLException
+    {
+        setObject(parameterIndex, x);
+    }
+
+
+    // everything below here is not implemented and will let you know about it.
+
+
+    public ParameterMetaData getParameterMetaData() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException("PreparedStatement.getParameterMetaData() hasn't been implemented yet.");
+    }
+
+    public void setArray(int parameterIndex, Array x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setAsciiStream(int parameterIndex, InputStream x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setAsciiStream(int parameterIndex, InputStream x, int length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setAsciiStream(int parameterIndex, InputStream x, long length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBigDecimal(int parameterIndex, BigDecimal x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBinaryStream(int parameterIndex, InputStream x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBinaryStream(int parameterIndex, InputStream x, int length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBinaryStream(int parameterIndex, InputStream x, long length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBlob(int parameterIndex, Blob x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBlob(int parameterIndex, InputStream inputStream) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBlob(int parameterIndex, InputStream inputStream, long length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setBoolean(int parameterIndex, boolean x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setCharacterStream(int parameterIndex, Reader reader) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setCharacterStream(int parameterIndex, Reader reader, int length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setCharacterStream(int parameterIndex, Reader reader, long length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setClob(int parameterIndex, Clob x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException("method not supported");
+    }
+
+    public void setClob(int parameterIndex, Reader reader) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setClob(int parameterIndex, Reader reader, long length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setDate(int parameterIndex, Date x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setDate(int parameterIndex, Date x, Calendar cal) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setDouble(int parameterIndex, double x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setFloat(int parameterIndex, float x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setNCharacterStream(int parameterIndex, Reader value) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setNCharacterStream(int parameterIndex, Reader value, long length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setNClob(int parameterIndex, NClob value) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setNClob(int parameterIndex, Reader reader) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setNClob(int parameterIndex, Reader reader, long length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setNull(int parameterIndex, int sqlType) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setNull(int parameterIndex, int sqlType, String typeName) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setObject(int parameterIndex, Object x, int targetSqlType) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setObject(int parameterIndex, Object x, int targetSqlType, int scaleOrLength) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setRef(int parameterIndex, Ref x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setRowId(int parameterIndex, RowId x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setSQLXML(int parameterIndex, SQLXML xmlObject) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setTime(int parameterIndex, Time x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setTime(int parameterIndex, Time x, Calendar cal) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setTimestamp(int parameterIndex, Timestamp x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setTimestamp(int parameterIndex, Timestamp x, Calendar cal) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setURL(int parameterIndex, URL x) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+    public void setUnicodeStream(int parameterIndex, InputStream x, int length) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NOT_SUPPORTED);
+    }
+
+
+    // done with API methods.
+
+
+    // provides a way to iterate through the parameters. it will blow up if it discovers any missing parameters.
+    // not thread-safe.
+    private class ParameterIterator
+    {
+        private Map<Integer, Object> params = new HashMap<Integer, Object>(variables);
+        private int index = 1;
+
+        // throws SQLException if a parameter is not specified.
+        private Object nextParam() throws SQLException
+        {
+            Object p = params.get(index++);
+            if (p == null)
+                throw new SQLException("No parameter bound to " + (index - 1));
+            return p;
+        }
+
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraResultSet.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraResultSet.java
new file mode 100644
index 0000000000..1ac806e2c3
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraResultSet.java
@@ -0,0 +1,45 @@
+package org.apache.cassandra.cql.jdbc;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+import java.math.BigInteger;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+public interface CassandraResultSet extends ResultSet
+{
+    /**
+     * @return the current row key
+     */
+    public byte[] getKey()throws SQLException;;
+    
+    public TypedColumn getTypedKey()throws SQLException;;
+
+    /** @return a BigInteger value for the given column offset*/
+    public BigInteger getBigInteger(int i) throws SQLException;
+    /** @return a BigInteger value for the given column name */
+    public BigInteger getBigInteger(String name) throws SQLException;
+
+    /** @return the raw column data for the given column offset */
+    public TypedColumn getColumn(int i) throws SQLException;
+    /** @return the raw column data for the given column name */
+    public TypedColumn getColumn(String name) throws SQLException;
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraStatement.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraStatement.java
new file mode 100644
index 0000000000..4e97488435
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/CassandraStatement.java
@@ -0,0 +1,427 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import static org.apache.cassandra.cql.jdbc.Utils.*;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.SQLFeatureNotSupportedException;
+import java.sql.SQLNonTransientConnectionException;
+import java.sql.SQLNonTransientException;
+import java.sql.SQLRecoverableException;
+import java.sql.SQLSyntaxErrorException;
+import java.sql.SQLTransientConnectionException;
+import java.sql.SQLWarning;
+import java.sql.Statement;
+import java.util.regex.Pattern;
+
+import org.apache.cassandra.thrift.CqlResult;
+import org.apache.cassandra.thrift.InvalidRequestException;
+import org.apache.cassandra.thrift.SchemaDisagreementException;
+import org.apache.cassandra.thrift.TimedOutException;
+import org.apache.cassandra.thrift.UnavailableException;
+import org.apache.thrift.TException;
+
+/**
+ * Cassandra statement: implementation class for {@link PreparedStatement}.
+ */
+
+class CassandraStatement extends AbstractStatement implements Statement
+{
+    /**
+     * The connection.
+     */
+    protected CassandraConnection connection;
+
+    /**
+     * The cql.
+     */
+    protected String cql;
+
+    protected int fetchDirection = ResultSet.FETCH_FORWARD;
+
+    protected int fetchSize = 0;
+
+    protected int maxFieldSize = 0;
+
+    protected int maxRows = 0;
+
+    protected int resultSetType = CResultSet.DEFAULT_TYPE;
+
+    protected int resultSetConcurrency = CResultSet.DEFAULT_CONCURRENCY;
+
+    protected int resultSetHoldability = CResultSet.DEFAULT_HOLDABILITY;
+
+    protected ResultSet currentResultSet = null;
+
+    protected int updateCount = -1;
+
+    protected boolean escapeProcessing = true;
+
+    CassandraStatement(CassandraConnection con) throws SQLException
+    {
+        this(con, null);
+    }
+
+    CassandraStatement(CassandraConnection con, String cql) throws SQLException
+    {
+        this.connection = con;
+        this.cql = cql;
+    }
+
+    CassandraStatement(CassandraConnection con, String cql, int resultSetType, int resultSetConcurrency) throws SQLException
+    {
+        this(con, cql, resultSetType, resultSetConcurrency, ResultSet.HOLD_CURSORS_OVER_COMMIT);
+    }
+
+    CassandraStatement(CassandraConnection con, String cql, int resultSetType, int resultSetConcurrency,
+                       int resultSetHoldability) throws SQLException
+    {
+        this.connection = con;
+        this.cql = cql;
+
+        if (!(resultSetType == ResultSet.TYPE_FORWARD_ONLY
+              || resultSetType == ResultSet.TYPE_SCROLL_INSENSITIVE
+              || resultSetType == ResultSet.TYPE_SCROLL_SENSITIVE)) throw new SQLSyntaxErrorException(BAD_TYPE_RSET);
+        this.resultSetType = resultSetType;
+
+        if (!(resultSetConcurrency == ResultSet.CONCUR_READ_ONLY
+              || resultSetConcurrency == ResultSet.CONCUR_UPDATABLE)) throw new SQLSyntaxErrorException(BAD_TYPE_RSET);
+        this.resultSetConcurrency = resultSetConcurrency;
+
+
+        if (!(resultSetHoldability == ResultSet.HOLD_CURSORS_OVER_COMMIT
+              || resultSetHoldability == ResultSet.CLOSE_CURSORS_AT_COMMIT))
+            throw new SQLSyntaxErrorException(BAD_HOLD_RSET);
+        this.resultSetHoldability = resultSetHoldability;
+    }
+
+    public void addBatch(String arg0) throws SQLException
+    {
+        checkNotClosed();
+        throw new SQLFeatureNotSupportedException(NO_BATCH);
+    }
+
+    private final void checkNotClosed() throws SQLException
+    {
+        if (isClosed()) throw new SQLRecoverableException(WAS_CLOSED_STMT);
+    }
+
+    public void clearBatch() throws SQLException
+    {
+        checkNotClosed();
+        throw new SQLFeatureNotSupportedException(NO_BATCH);
+    }
+
+    public void clearWarnings() throws SQLException
+    {
+        // This implementation does not support the collection of warnings so clearing is a no-op
+        // but it is still an exception to call this on a closed connection.
+        checkNotClosed();
+    }
+
+    public void close() throws SQLException
+    {
+        connection = null;
+        cql = null;
+    }
+
+    private void doExecute(String sql) throws SQLException
+    {
+        try
+        {
+            resetResults();
+            CqlResult rSet = connection.execute(sql);
+            String keyspace = connection.currentKeyspace;
+            String columnfamily = determineCurrentColumnFamily(sql);
+
+            switch (rSet.getType())
+            {
+                case ROWS:
+                    currentResultSet = new CResultSet(this, rSet, connection.decoder, keyspace, columnfamily);
+                    break;
+                case INT:
+                    updateCount = rSet.getNum();
+                    break;
+                case VOID:
+                    updateCount = 0;
+                    break;
+            }
+        }
+        catch (InvalidRequestException e)
+        {
+            throw new SQLSyntaxErrorException(e.getWhy());
+        }
+        catch (UnavailableException e)
+        {
+            throw new SQLNonTransientConnectionException(NO_SERVER, e);
+        }
+        catch (TimedOutException e)
+        {
+            throw new SQLTransientConnectionException(e.getMessage());
+        }
+        catch (SchemaDisagreementException e)
+        {
+            throw new SQLRecoverableException(SCHEMA_MISMATCH);
+        }
+        catch (TException e)
+        {
+            throw new SQLNonTransientConnectionException(e.getMessage());
+        }
+
+    }
+
+    public boolean execute(String query) throws SQLException
+    {
+        checkNotClosed();
+        doExecute(query);
+        return !(currentResultSet == null);
+    }
+
+    public boolean execute(String sql, int autoGeneratedKeys) throws SQLException
+    {
+        checkNotClosed();
+
+        if (!(autoGeneratedKeys == RETURN_GENERATED_KEYS || autoGeneratedKeys == NO_GENERATED_KEYS))
+            throw new SQLSyntaxErrorException(BAD_AUTO_GEN);
+
+        if (autoGeneratedKeys == RETURN_GENERATED_KEYS) throw new SQLFeatureNotSupportedException(NO_GEN_KEYS);
+
+        return execute(sql);
+    }
+
+    public int[] executeBatch() throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(NO_BATCH);
+    }
+
+    public ResultSet executeQuery(String query) throws SQLException
+    {
+        checkNotClosed();
+        doExecute(query);
+        if (currentResultSet == null)
+            throw new SQLNonTransientException(NO_RESULTSET);
+        return currentResultSet;
+    }
+
+    public int executeUpdate(String query) throws SQLException
+    {
+        checkNotClosed();
+        doExecute(query);
+        if (currentResultSet != null)
+            throw new SQLNonTransientException(NO_UPDATE_COUNT);
+        return updateCount;
+    }
+
+    public int executeUpdate(String sql, int autoGeneratedKeys) throws SQLException
+    {
+        checkNotClosed();
+
+        if (!(autoGeneratedKeys == RETURN_GENERATED_KEYS || autoGeneratedKeys == NO_GENERATED_KEYS))
+            throw new SQLFeatureNotSupportedException(BAD_AUTO_GEN);
+
+        return executeUpdate(sql);
+    }
+
+    public Connection getConnection() throws SQLException
+    {
+        checkNotClosed();
+        return (Connection) connection;
+    }
+
+    public int getFetchDirection() throws SQLException
+    {
+        checkNotClosed();
+        return fetchDirection;
+    }
+
+    public int getFetchSize() throws SQLException
+    {
+        checkNotClosed();
+        return fetchSize;
+    }
+
+    public int getMaxFieldSize() throws SQLException
+    {
+        checkNotClosed();
+        return maxFieldSize;
+    }
+
+    public int getMaxRows() throws SQLException
+    {
+        checkNotClosed();
+        return maxRows;
+    }
+
+    public boolean getMoreResults() throws SQLException
+    {
+        checkNotClosed();
+        resetResults();
+        // in the current Cassandra implementation there are never MORE results
+        return false;
+    }
+
+    public boolean getMoreResults(int current) throws SQLException
+    {
+        checkNotClosed();
+
+        switch (current)
+        {
+            case CLOSE_CURRENT_RESULT:
+                resetResults();
+                break;
+
+            case CLOSE_ALL_RESULTS:
+            case KEEP_CURRENT_RESULT:
+                throw new SQLFeatureNotSupportedException(NO_MULTIPLE);
+
+            default:
+                throw new SQLSyntaxErrorException(String.format(BAD_KEEP_RSET, current));
+        }
+        // in the current Cassandra implementation there are never MORE results
+        return false;
+    }
+
+    public int getQueryTimeout() throws SQLException
+    {
+        // the Cassandra implementation does not support timeouts on queries
+        return 0;
+    }
+
+    public ResultSet getResultSet() throws SQLException
+    {
+        checkNotClosed();
+        return currentResultSet;
+    }
+
+    public int getResultSetConcurrency() throws SQLException
+    {
+        checkNotClosed();
+        return ResultSet.CONCUR_READ_ONLY;
+    }
+
+    public int getResultSetHoldability() throws SQLException
+    {
+        checkNotClosed();
+        // the Cassandra implementations does not support commits so this is the closest match
+        return ResultSet.HOLD_CURSORS_OVER_COMMIT;
+    }
+
+    public int getResultSetType() throws SQLException
+    {
+        checkNotClosed();
+        return ResultSet.TYPE_FORWARD_ONLY;
+    }
+
+    public int getUpdateCount() throws SQLException
+    {
+        checkNotClosed();
+        return updateCount;
+    }
+
+    public SQLWarning getWarnings() throws SQLException
+    {
+        checkNotClosed();
+        return null;
+    }
+
+    public boolean isClosed() throws SQLException
+    {
+        return connection == null;
+    }
+
+    public boolean isPoolable() throws SQLException
+    {
+        checkNotClosed();
+        return false;
+    }
+
+    public boolean isWrapperFor(Class<?> iface) throws SQLException
+    {
+        return false;
+    }
+
+    private final void resetResults()
+    {
+        currentResultSet = null;
+        updateCount = -1;
+    }
+
+    public void setEscapeProcessing(boolean enable) throws SQLException
+    {
+        checkNotClosed();
+        // the Cassandra implementation does not currently look at this
+        escapeProcessing = enable;
+    }
+
+    public void setFetchDirection(int direction) throws SQLException
+    {
+        checkNotClosed();
+
+        if (direction == ResultSet.FETCH_FORWARD || direction == ResultSet.FETCH_REVERSE || direction == ResultSet.FETCH_UNKNOWN)
+        {
+            if ((getResultSetType() == ResultSet.TYPE_FORWARD_ONLY) && (direction != ResultSet.FETCH_FORWARD))
+                throw new SQLSyntaxErrorException(String.format(BAD_FETCH_DIR, direction));
+            fetchDirection = direction;
+        }
+        else throw new SQLSyntaxErrorException(String.format(BAD_FETCH_DIR, direction));
+    }
+
+
+    public void setFetchSize(int size) throws SQLException
+    {
+        checkNotClosed();
+        if (size < 0) throw new SQLSyntaxErrorException(String.format(BAD_FETCH_SIZE, size));
+        fetchSize = size;
+    }
+
+    public void setMaxFieldSize(int arg0) throws SQLException
+    {
+        checkNotClosed();
+        // silently ignore this setting. always use default 0 (unlimited)
+    }
+
+    public void setMaxRows(int arg0) throws SQLException
+    {
+        checkNotClosed();
+        // silently ignore this setting. always use default 0 (unlimited)
+    }
+
+    public void setPoolable(boolean poolable) throws SQLException
+    {
+        checkNotClosed();
+        // silently ignore any attempt to set this away from the current default (false)
+    }
+
+    public void setQueryTimeout(int arg0) throws SQLException
+    {
+        checkNotClosed();
+        // silently ignore any attempt to set this away from the current default (0)
+    }
+
+    public <T> T unwrap(Class<T> iface) throws SQLException
+    {
+        throw new SQLFeatureNotSupportedException(String.format(NO_INTERFACE, iface.getSimpleName()));
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/ColumnDecoder.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/ColumnDecoder.java
new file mode 100644
index 0000000000..1de564fa70
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/ColumnDecoder.java
@@ -0,0 +1,142 @@
+package org.apache.cassandra.cql.jdbc;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+
+import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.config.ColumnDefinition;
+import org.apache.cassandra.config.ConfigurationException;
+import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.db.marshal.AsciiType;
+import org.apache.cassandra.thrift.*;
+import org.apache.cassandra.utils.ByteBufferUtil;
+
+//import org.slf4j.Logger;
+//import org.slf4j.LoggerFactory;
+
+import java.nio.ByteBuffer;
+import java.nio.charset.CharacterCodingException;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * Decodes columns from bytes into instances of their respective expected types.
+ */
+class ColumnDecoder
+{
+//    private static final Logger logger = LoggerFactory.getLogger(ColumnDecoder.class);
+
+    private final Map<String, CFMetaData> metadata = new HashMap<String, CFMetaData>();
+
+    /**
+     * is specific per set of keyspace definitions.
+     */
+    public ColumnDecoder(List<KsDef> defs)
+    {
+        for (KsDef ks : defs)
+        {
+            for (CfDef cf : ks.getCf_defs())
+            {
+                try
+                {
+                    metadata.put(String.format("%s.%s", ks.getName(), cf.getName()), CFMetaData.fromThrift(cf));
+                }
+                catch (InvalidRequestException e)
+                {
+                    throw new RuntimeException(e);
+                }
+                catch (ConfigurationException e)
+                {
+                    throw new RuntimeException(e);
+                }
+            }
+        }
+    }
+
+    AbstractType<?> getComparator(String keyspace, String columnFamily)
+    {
+        CFMetaData md = metadata.get(String.format("%s.%s", keyspace, columnFamily));
+        return (md == null) ? null : md.comparator;
+    }
+
+    AbstractType<?> getNameType(String keyspace, String columnFamily, ByteBuffer name)
+    {
+        CFMetaData md = metadata.get(String.format("%s.%s", keyspace, columnFamily));
+        try
+        {
+            if (ByteBufferUtil.string(name).equalsIgnoreCase(ByteBufferUtil.string(md.getKeyName())))
+                return AsciiType.instance;
+        }
+        catch (CharacterCodingException e)
+        {
+            // not be the key name
+        }
+        return md.comparator;
+    }
+
+    AbstractType<?> getValueType(String keyspace, String columnFamily, ByteBuffer name)
+    {
+        CFMetaData md = metadata.get(String.format("%s.%s", keyspace, columnFamily));
+        try
+        {
+            if (ByteBufferUtil.string(name).equalsIgnoreCase(ByteBufferUtil.string(md.getKeyName())))
+                return md.getKeyValidator();
+        }
+        catch (CharacterCodingException e)
+        {
+            // not be the key name
+        }
+        ColumnDefinition cd = md.getColumnDefinition(name);
+        return cd == null ? md.getDefaultValidator() : cd.getValidator();
+    }
+
+    public AbstractType<?> getKeyValidator(String keyspace, String columnFamily)
+    {
+        CFMetaData md = metadata.get(String.format("%s.%s", keyspace, columnFamily));
+        return (md == null) ? null : md.getKeyValidator();
+    }
+
+    /** uses the AbstractType to map a column name to a string. */
+    public String colNameAsString(String keyspace, String columnFamily, ByteBuffer name)
+    {
+        AbstractType<?> comparator = getNameType(keyspace, columnFamily, name);
+        return comparator.getString(name);
+    }
+
+    /** constructs a typed column */
+    public TypedColumn makeCol(String keyspace, String columnFamily, Column column)
+    {
+        return new TypedColumn(column,
+                               getNameType(keyspace, columnFamily, column.name),
+                               getValueType(keyspace, columnFamily, column.name));
+    }
+
+    /** constructs a typed column to hold the key */
+    public TypedColumn makeKeyColumn(String keyspace, String columnFamily, byte[] key)
+    {
+        CFMetaData md = metadata.get(String.format("%s.%s", keyspace, columnFamily));
+        Column column = new Column(md.getKeyName()).setValue(key).setTimestamp(-1);
+        return new TypedColumn(column,
+                               getNameType(keyspace, columnFamily, md.getKeyName()),
+                               getValueType(keyspace, columnFamily, md.getKeyName()));
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/DriverResolverException.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/DriverResolverException.java
new file mode 100644
index 0000000000..d07507efe2
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/DriverResolverException.java
@@ -0,0 +1,39 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+/**
+ * Runtime exception handling in case of runtime error during Driver resolving. 
+ */
+public class DriverResolverException extends RuntimeException {
+
+	/**
+	 * Default serial version UID. 
+	 */
+	private static final long serialVersionUID = 1L;
+
+	/**
+	 * Constructor using fields.
+	 * @param errMsg error message.
+	 */
+	public DriverResolverException(String errMsg) {
+		super(errMsg);
+	}
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/InvalidUrlException.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/InvalidUrlException.java
new file mode 100644
index 0000000000..5b9fd222e3
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/InvalidUrlException.java
@@ -0,0 +1,41 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+/**
+ * Runtime exception handling during incorrect connection url provided.
+ */
+public class InvalidUrlException extends RuntimeException {
+	
+	/**
+	 *  Default serial version UID
+	 */
+	private static final long serialVersionUID = 1L;
+
+	/**
+	 * Constructor using fields.
+	 * @param errMsg error message.
+	 */
+	public InvalidUrlException(String errMsg) {
+		super(errMsg);
+	}
+
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/TypedColumn.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/TypedColumn.java
new file mode 100644
index 0000000000..9c8df80f48
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/TypedColumn.java
@@ -0,0 +1,77 @@
+package org.apache.cassandra.cql.jdbc;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+
+import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.thrift.Column;
+
+
+public class TypedColumn
+{
+    private final Column rawColumn;
+
+    // we cache the frequently-accessed forms: java object for value, String for name.
+    // Note that {N|V}.toString() isn't always the same as Type.getString
+    // (a good example is byte buffers).
+    private final Object value;
+    private final String nameString;
+    private final AbstractType<?> nameType, valueType;
+
+    public TypedColumn(Column column, AbstractType<?> comparator, AbstractType<?> validator)
+    {
+        rawColumn = column;
+        this.value = column.value == null ? null : validator.compose(column.value);
+        nameString = comparator.getString(column.name);
+        nameType = comparator;
+        valueType = validator;
+    }
+
+    public Column getRawColumn()
+    {
+        return rawColumn;
+    }
+    
+    public Object getValue()
+    {
+        return value;
+    }
+    
+    public String getNameString()
+    {
+        return nameString;
+    }
+    
+    public String getValueString()
+    {
+        return valueType.getString(rawColumn.value);
+    }
+    
+    public AbstractType getNameType()
+    {
+        return nameType;
+    }
+
+    public AbstractType getValueType()
+    {
+        return valueType;
+    }
+}
diff --git a/drivers/java/src/org/apache/cassandra/cql/jdbc/Utils.java b/drivers/java/src/org/apache/cassandra/cql/jdbc/Utils.java
new file mode 100644
index 0000000000..376f4fdd6e
--- /dev/null
+++ b/drivers/java/src/org/apache/cassandra/cql/jdbc/Utils.java
@@ -0,0 +1,254 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+package org.apache.cassandra.cql.jdbc;
+
+import java.io.ByteArrayOutputStream;
+import java.net.URI;
+import java.net.URISyntaxException;
+import java.nio.ByteBuffer;
+import java.sql.SQLException;
+import java.sql.SQLNonTransientConnectionException;
+import java.sql.SQLSyntaxErrorException;
+import java.util.Properties;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.zip.Deflater;
+
+import org.apache.cassandra.thrift.Compression;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.base.Charsets;
+
+/**
+ * A set of static utility methods used by the JDBC Suite, and various default values and error message strings
+ * that can be shared across classes.
+ */
+class Utils
+{
+    private static final Pattern KEYSPACE_PATTERN = Pattern.compile("USE (\\w+);?", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE);
+    private static final Pattern SELECT_PATTERN = Pattern.compile("(?:SELECT|DELETE)\\s+.+\\s+FROM\\s+(\\w+).*", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE);
+    private static final Pattern UPDATE_PATTERN = Pattern.compile("UPDATE\\s+(\\w+)\\s+.*", Pattern.CASE_INSENSITIVE);
+
+    public static final String PROTOCOL = "jdbc:cassandra:";
+    public static final String DEFAULT_HOST = "localhost";
+    public static final int DEFAULT_PORT = 9160;
+
+    public static final String TAG_DESCRIPTION = "description";
+    public static final String TAG_USER = "user";
+    public static final String TAG_PASSWORD = "password";
+    public static final String TAG_DATABASE_NAME = "databaseName";
+    public static final String TAG_SERVER_NAME = "serverName";
+    public static final String TAG_PORT_NUMBER = "portNumber";
+
+    protected static final String WAS_CLOSED_CON = "method was called on a closed Connection";
+    protected static final String WAS_CLOSED_STMT = "method was called on a closed Statement";
+    protected static final String WAS_CLOSED_RSLT = "method was called on a closed ResultSet";
+    protected static final String NO_INTERFACE = "no object was found that matched the provided interface: %s";
+    protected static final String NO_TRANSACTIONS = "the Cassandra implementation does not support transactions";
+    protected static final String NO_SERVER = "no Cassandra server is available";
+    protected static final String ALWAYS_AUTOCOMMIT = "the Cassandra implementation is always in auto-commit mode";
+    protected static final String BAD_TIMEOUT = "the timeout value was less than zero";
+    protected static final String SCHEMA_MISMATCH = "schema does not match across nodes, (try again later)";
+    protected static final String NOT_SUPPORTED = "the Cassandra implementation does not support this method";
+    protected static final String NO_GEN_KEYS = "the Cassandra implementation does not currently support returning generated  keys";
+    protected static final String NO_BATCH = "the Cassandra implementation does not currently support this batch in Statement";
+    protected static final String NO_MULTIPLE = "the Cassandra implementation does not currently support multiple open Result Sets";
+    protected static final String NO_VALIDATOR = "Could not find key validator for: %s.%s";
+    protected static final String NO_COMPARATOR = "Could not find key comparator for: %s.%s";
+    protected static final String NO_RESULTSET = "No ResultSet returned from the CQL statement passed in an 'executeQuery()' method";
+    protected static final String NO_UPDATE_COUNT = "No Update Count was returned from the CQL statement passed in an 'executeUpdate()' method";
+    protected static final String NO_CF = "no column family reference could be extracted from the provided CQL statement";
+    protected static final String BAD_KEEP_RSET = "the argument for keeping the current result set : %s is not a valid value";
+    protected static final String BAD_TYPE_RSET = "the argument for result set type : %s is not a valid value";
+    protected static final String BAD_CONCUR_RSET = "the argument for result set concurrency : %s is not a valid value";
+    protected static final String BAD_HOLD_RSET = "the argument for result set holdability : %s is not a valid value";
+    protected static final String BAD_FETCH_DIR = "fetch direction value of : %s is illegal";
+    protected static final String BAD_AUTO_GEN = "auto key generation value of : %s is illegal";
+    protected static final String BAD_FETCH_SIZE = "fetch size of : %s rows may not be negative";
+    protected static final String MUST_BE_POSITIVE = "index must be a positive number less or equal the count of returned columns: %s";
+    protected static final String VALID_LABELS = "name provided was not in the list of valid column labels: %s";
+    protected static final String NOT_TRANSLATABLE = "column was stored in %s format which is not translatable to %s";
+    protected static final String NOT_BOOLEAN = "string value was neither 'true' nor 'false' :  %s";
+    protected static final String HOST_IN_URL = "Connection url must specify a host, e.g., jdbc:cassandra://localhost:9170/Keyspace1";
+    protected static final String HOST_REQUIRED = "a 'host' name is required to build a Connection";
+    protected static final String BAD_KEYSPACE = "Keyspace names must be composed of alphanumerics and underscores (parsed: '%s')";
+    protected static final String URI_IS_SIMPLE = "Connection url may only include host, port, and keyspace, e.g., jdbc:cassandra://localhost:9170/Keyspace1";
+
+    protected static final Logger logger = LoggerFactory.getLogger(Utils.class);
+
+    /**
+     * Use the Compression object method to deflate the query string
+     *
+     * @param queryStr An un-compressed CQL query string
+     * @param compression The compression object
+     * @return A compressed string
+     */
+    public static ByteBuffer compressQuery(String queryStr, Compression compression)
+    {
+        byte[] data = queryStr.getBytes(Charsets.UTF_8);
+        Deflater compressor = new Deflater();
+        compressor.setInput(data);
+        compressor.finish();
+
+        ByteArrayOutputStream byteArray = new ByteArrayOutputStream();
+        byte[] buffer = new byte[1024];
+
+        while (!compressor.finished())
+        {
+            int size = compressor.deflate(buffer);
+            byteArray.write(buffer, 0, size);
+        }
+
+        logger.trace("Compressed query statement {} bytes in length to {} bytes", data.length, byteArray.size());
+
+        return ByteBuffer.wrap(byteArray.toByteArray());
+    }
+
+    /**
+     * Parse a URL for the Cassandra JDBC Driver
+     * <p/>
+     * The URL must start with the Protocol: "jdbc:cassandra:"
+     * The URI part(the "Subname") must contain a host and an optional port and optional keyspace name
+     * ie. "//localhost:9160/Test1"
+     *
+     * @param url The full JDBC URL to be parsed
+     * @return A list of properties that were parsed from the Subname
+     * @throws SQLException
+     */
+    public static final Properties parseURL(String url) throws SQLException
+    {
+        Properties props = new Properties();
+
+        if (!(url == null))
+        {
+            props.setProperty(TAG_PORT_NUMBER, "" + DEFAULT_PORT);
+            String rawUri = url.substring(PROTOCOL.length());
+            URI uri = null;
+            try
+            {
+                uri = new URI(rawUri);
+            }
+            catch (URISyntaxException e)
+            {
+                throw new SQLSyntaxErrorException(e);
+            }
+
+            String host = uri.getHost();
+            if (host == null) throw new SQLNonTransientConnectionException(HOST_IN_URL);
+            props.setProperty(TAG_SERVER_NAME, host);
+
+            int port = uri.getPort() >= 0 ? uri.getPort() : DEFAULT_PORT;
+            props.setProperty(TAG_PORT_NUMBER, "" + port);
+
+            String keyspace = uri.getPath();
+            if ((keyspace != null) && (!keyspace.isEmpty()))
+            {
+                if (keyspace.startsWith("/")) keyspace = keyspace.substring(1);
+                if (!keyspace.matches("[a-zA-Z]\\w+"))
+                    throw new SQLNonTransientConnectionException(String.format(BAD_KEYSPACE, keyspace));
+                props.setProperty(TAG_DATABASE_NAME, keyspace);
+            }
+
+            if (uri.getUserInfo() != null)
+                throw new SQLNonTransientConnectionException(URI_IS_SIMPLE);
+        }
+
+        if (logger.isTraceEnabled()) logger.trace("URL : '{}' parses to: {}", url, props);
+
+        return props;
+    }
+
+    /**
+     * Create a "Subname" portion of a JDBC URL from properties.
+     * 
+     * @param props A Properties file containing all the properties to be considered.
+     * @return A constructed "Subname" portion of a JDBC URL in the form of a CLI (ie: //myhost:9160/Test1 )
+     * @throws SQLException
+     */
+    public static final String createSubName(Properties props)throws SQLException
+    {
+        // make keyspace always start with a "/" for URI
+        String keyspace = props.getProperty(TAG_DATABASE_NAME);
+     
+        // if keyspace is null then do not bother ...
+        if (keyspace != null) 
+            if (!keyspace.startsWith("/")) keyspace = "/"  + keyspace;
+        
+        String host = props.getProperty(TAG_SERVER_NAME);
+        if (host==null)throw new SQLNonTransientConnectionException(HOST_REQUIRED);
+        
+        // construct a valid URI from parts... 
+        URI uri;
+        try
+        {
+            uri = new URI(
+                null,
+                null,
+                host,
+                props.getProperty(TAG_PORT_NUMBER)==null ? DEFAULT_PORT : Integer.parseInt(props.getProperty(TAG_PORT_NUMBER)),
+                keyspace,
+                null,
+                null);
+        }
+        catch (Exception e)
+        {
+            throw new SQLNonTransientConnectionException(e);
+        }
+        
+        if (logger.isTraceEnabled()) logger.trace("Subname : '{}' created from : {}",uri.toString(), props);
+        
+        return uri.toString();
+    }
+    
+    /**
+     * Determine the current keyspace by inspecting the CQL string to see if a USE statement is provided; which would change the keyspace.
+     *
+     * @param cql     A CQL query string
+     * @param current The current keyspace stored as state in the connection
+     * @return the provided keyspace name or the keyspace from the contents of the CQL string
+     */
+    public static String determineCurrentKeyspace(String cql, String current)
+    {
+        String ks = current;
+        Matcher isKeyspace = KEYSPACE_PATTERN.matcher(cql);
+        if (isKeyspace.matches()) ks = isKeyspace.group(1);
+        return ks;
+    }
+
+    /**
+     * Determine the current column family by inspecting the CQL to find a CF reference.
+     *
+     * @param cql A CQL query string
+     * @return The column family name from the contents of the CQL string or null in none was found
+     */
+    public static String determineCurrentColumnFamily(String cql)
+    {
+        String cf = null;
+        Matcher isSelect = SELECT_PATTERN.matcher(cql);
+        if (isSelect.matches()) cf = isSelect.group(1);
+        Matcher isUpdate = UPDATE_PATTERN.matcher(cql);
+        if (isUpdate.matches()) cf = isUpdate.group(1);
+        return cf;
+    }
+}
diff --git a/drivers/java/test/conf/cassandra.yaml b/drivers/java/test/conf/cassandra.yaml
new file mode 100644
index 0000000000..1df250195d
--- /dev/null
+++ b/drivers/java/test/conf/cassandra.yaml
@@ -0,0 +1,35 @@
+#
+# Warning!
+# Consider the effects on 'o.a.c.i.s.LegacySSTableTest' before changing schemas in this file.
+#
+cluster_name: Test Cluster
+in_memory_compaction_limit_in_mb: 1
+commitlog_sync: batch
+commitlog_sync_batch_window_in_ms: 1.0
+partitioner: org.apache.cassandra.dht.CollatingOrderPreservingPartitioner
+rpc_timeout_in_ms: 5000
+listen_address: 127.0.0.1
+storage_port: 7010
+rpc_port: 9170
+column_index_size_in_kb: 4
+commitlog_directory: build/test/cassandra/commitlog
+saved_caches_directory: build/test/cassandra/saved_caches
+data_file_directories:
+    - build/test/cassandra/data
+disk_access_mode: mmap
+seed_provider:
+    - class_name: org.apache.cassandra.locator.SimpleSeedProvider
+      parameters:
+          - seeds: "127.0.0.2"
+endpoint_snitch: org.apache.cassandra.locator.SimpleSnitch
+dynamic_snitch: true
+request_scheduler: org.apache.cassandra.scheduler.RoundRobinScheduler
+request_scheduler_id: keyspace
+encryption_options:
+    internode_encryption: none
+    keystore: conf/.keystore
+    keystore_password: cassandra
+    truststore: conf/.truststore
+    truststore_password: cassandra
+incremental_backups: true
+flush_largest_memtables_at: 1.0
diff --git a/drivers/java/test/conf/log4j-junit.properties b/drivers/java/test/conf/log4j-junit.properties
new file mode 100644
index 0000000000..7c73c54d18
--- /dev/null
+++ b/drivers/java/test/conf/log4j-junit.properties
@@ -0,0 +1,37 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# for production, you should probably set the root to INFO
+# and the pattern to %c instead of %l.  (%l is slower.)
+
+# output messages into a rolling log file as well as stdout
+log4j.rootLogger=DEBUG,stderr,R
+
+# stderr
+log4j.appender.stderr=org.apache.log4j.ConsoleAppender
+log4j.appender.stderr.target=System.err
+log4j.appender.stderr.layout=org.apache.log4j.PatternLayout
+log4j.appender.stderr.layout.ConversionPattern=%5p %d{HH:mm:ss,SSS} %m%n
+log4j.appender.stderr.threshold=WARN
+
+# rolling log file
+log4j.appender.R=org.apache.log4j.RollingFileAppender
+log4j.appender.file.maxFileSize=20MB
+log4j.appender.file.maxBackupIndex=50
+log4j.appender.R.layout=org.apache.log4j.PatternLayout
+log4j.appender.R.layout.ConversionPattern=%5p [%t] %d{ISO8601} %F (line %L) %m%n
+# Edit the next line to point to your logs directory
+log4j.appender.R.File=build/test/logs/system.log
diff --git a/drivers/java/test/org/apache/cassandra/cql/EmbeddedServiceBase.java b/drivers/java/test/org/apache/cassandra/cql/EmbeddedServiceBase.java
new file mode 100644
index 0000000000..b61bfd1a71
--- /dev/null
+++ b/drivers/java/test/org/apache/cassandra/cql/EmbeddedServiceBase.java
@@ -0,0 +1,106 @@
+package org.apache.cassandra.cql;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+
+import java.io.IOException;
+import java.net.Socket;
+import java.net.UnknownHostException;
+
+import org.apache.cassandra.CleanupHelper;
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.config.ConfigurationException;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.config.KSMetaData;
+import org.apache.cassandra.service.EmbeddedCassandraService;
+import org.junit.BeforeClass;
+
+/**
+ * The abstract BaseClass.
+ */
+public abstract class EmbeddedServiceBase
+{
+
+    /** The embedded server cassandra. */
+    private static EmbeddedCassandraService cassandra;
+    
+    @BeforeClass 
+    public static void cleanUpOldStuff() throws IOException
+    {
+        CleanupHelper.cleanupAndLeaveDirs();
+    }
+    
+    /**
+     * Start cassandra server.
+     * @throws ConfigurationException 
+     *
+     * @throws Exception the exception
+     */
+    public static void startCassandraServer() throws IOException, ConfigurationException
+    {
+        if (!checkIfServerRunning())
+        {
+            loadData();
+            cassandra = new EmbeddedCassandraService();
+            cassandra.start();
+        }
+    }
+
+    
+    /**
+     * Load yaml tables.
+     *
+     * @throws ConfigurationException the configuration exception
+     */
+    static void loadData() throws ConfigurationException
+    {
+        for (KSMetaData table : SchemaLoader.schemaDefinition())
+        {
+            for (CFMetaData cfm : table.cfMetaData().values())
+            {
+                CFMetaData.map(cfm);
+            }
+            DatabaseDescriptor.setTableDefinition(table, DatabaseDescriptor.getDefsVersion());
+        }
+    }
+    /**
+     * Check if server running.
+     *
+     * @return true, if successful
+     */
+    static boolean checkIfServerRunning()
+    {
+        try
+        {
+            Socket socket = new Socket("127.0.0.1", 9170);
+            return socket.getInetAddress() != null;
+        } 
+        catch (UnknownHostException e)
+        {
+            return false;
+        }
+        catch (IOException e)
+        {
+            return false;
+        }
+    }
+}
diff --git a/drivers/java/test/org/apache/cassandra/cql/JdbcDriverTest.java b/drivers/java/test/org/apache/cassandra/cql/JdbcDriverTest.java
new file mode 100644
index 0000000000..f5811caa5c
--- /dev/null
+++ b/drivers/java/test/org/apache/cassandra/cql/JdbcDriverTest.java
@@ -0,0 +1,511 @@
+package org.apache.cassandra.cql;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+import java.io.File;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.math.BigInteger;
+import java.nio.ByteBuffer;
+import java.sql.*;
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+
+import org.apache.cassandra.cql.jdbc.CassandraResultSet;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.apache.cassandra.db.marshal.*;
+import org.apache.cassandra.utils.ByteBufferUtil;
+import org.apache.cassandra.utils.FBUtilities;
+
+import static junit.framework.Assert.assertEquals;
+
+/**
+ * Test case for unit test of various methods of JDBC implementation.
+ */
+public class JdbcDriverTest extends EmbeddedServiceBase
+{
+    private static java.sql.Connection con = null;
+    private static final String first = FBUtilities.bytesToHex("first".getBytes());
+    private static final String firstrec = FBUtilities.bytesToHex("firstrec".getBytes());
+    private static final String last = FBUtilities.bytesToHex("last".getBytes());
+    private static final String lastrec = FBUtilities.bytesToHex("lastrec".getBytes());
+    private static final String jsmith = FBUtilities.bytesToHex("jsmith".getBytes());
+
+    /** SetUp */
+    @BeforeClass
+    public static void startServer() throws Exception
+    {
+        startCassandraServer();
+        Class.forName("org.apache.cassandra.cql.jdbc.CassandraDriver");
+        con = DriverManager.getConnection("jdbc:cassandra://localhost:9170/Keyspace1");
+        String[] inserts = 
+        {
+            String.format("UPDATE Standard1 SET '%s' = '%s', '%s' = '%s' WHERE KEY = '%s'", first, firstrec, last, lastrec, jsmith),    
+            "UPDATE JdbcInteger SET 1 = 11, 2 = 22, 42='fortytwo' WHERE KEY = '" + jsmith + "'",
+            "UPDATE JdbcInteger SET 3 = 33, 4 = 44 WHERE KEY = '" + jsmith + "'",
+            "UPDATE JdbcLong SET 1 = 11, 2 = 22 WHERE KEY = '" + jsmith + "'",
+            "UPDATE JdbcAscii SET 'first' = 'firstrec', last = 'lastrec' WHERE key = '" + jsmith + "'",
+            String.format("UPDATE JdbcBytes SET '%s' = '%s', '%s' = '%s' WHERE key = '%s'", first, firstrec, last, lastrec, jsmith),
+            "UPDATE JdbcUtf8 SET 'first' = 'firstrec', fortytwo = '42', last = 'lastrec' WHERE key = '" + jsmith + "'",
+        };
+        for (String q : inserts)
+        {
+            try 
+            {
+                executeNoResults(con, q);
+            }
+            catch (SQLException ex)
+            {
+                throw new AssertionError(ex.getMessage() + ", query:" + q);
+            }
+        }
+    }
+
+    private static void expectedMetaData(ResultSetMetaData md, int col, String colClass, String table, String schema,
+                                  String label, int type, String typeName, boolean signed, boolean caseSensitive) throws SQLException
+    {
+        assertEquals(colClass, md.getColumnClassName(col)); // full class name of type<T>
+        assertEquals(table, md.getTableName(col));
+        assertEquals(schema, md.getSchemaName(col));
+        assertEquals(label, md.getColumnLabel(col));
+        assertEquals(label, md.getColumnName(col));
+        assertEquals(type, md.getColumnType(col));
+        assertEquals(typeName, md.getColumnTypeName(col));
+        assertEquals(signed, md.isSigned(col));
+        assertEquals(caseSensitive, md.isCaseSensitive(col));
+    }
+    
+    private static void expectedMetaData(ResultSetMetaData md, int col,
+                                         String valuClass, int valuType, String valuTypeName, boolean valuSigned, boolean valuCaseSense) throws SQLException
+    {
+        assertEquals(valuClass, md.getColumnClassName(col));
+        assertEquals(valuType, md.getColumnType(col));
+        assertEquals(valuTypeName, md.getColumnTypeName(col));
+        assertEquals(valuSigned, md.isSigned(col));
+        assertEquals(valuCaseSense, md.isCaseSensitive(col));
+    }
+
+    @Test(expected=SQLNonTransientConnectionException.class)
+    public void testNoHost() throws SQLException
+    {
+        DriverManager.getConnection("jdbc:cassandra:localhost");
+    }
+
+    @Test(expected=SQLNonTransientConnectionException.class)
+    public void testBadKeyspace() throws SQLException
+    {
+        DriverManager.getConnection("jdbc:cassandra://localhost/Keysp@ce");
+    }
+
+    @Test(expected=SQLNonTransientConnectionException.class)
+    public void testBadUserinfo() throws SQLException
+    {
+        DriverManager.getConnection("jdbc:cassandra://root;root@localhost");
+    }
+
+    @Test
+    public void testNonDefaultColumnValidators() throws SQLException
+    {
+        String key = FBUtilities.bytesToHex("Integer".getBytes());
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("update JdbcInteger set 1=36893488147419103232, 42='fortytwofortytwo' where key='" + key + "'");
+        ResultSet rs = stmt.executeQuery("select 1, 2, 42 from JdbcInteger where key='" + key + "'");
+        assert rs.next();
+        assert rs.getObject("1").equals(new BigInteger("36893488147419103232"));
+        assert rs.getString("42").equals("fortytwofortytwo") : rs.getString("42");
+        
+        ResultSetMetaData md = rs.getMetaData();
+        assert md.getColumnCount() == 3;
+        expectedMetaData(md, 1, BigInteger.class.getName(), "JdbcInteger", "Keyspace1", "1", Types.BIGINT, IntegerType.class.getSimpleName(), true, false);
+        expectedMetaData(md, 2, BigInteger.class.getName(), "JdbcInteger", "Keyspace1", "2", Types.BIGINT, IntegerType.class.getSimpleName(), true, false);
+        expectedMetaData(md, 3, String.class.getName(), "JdbcInteger", "Keyspace1", "42", Types.VARCHAR, UTF8Type.class.getSimpleName(), false, true);
+        
+        rs = stmt.executeQuery("select key, 1, 2, 42 from JdbcInteger where key='" + key + "'");
+        assert rs.next();
+        assert Arrays.equals(rs.getBytes("key"), FBUtilities.hexToBytes(key));
+        assert rs.getObject("1").equals(new BigInteger("36893488147419103232"));
+        assert rs.getString("42").equals("fortytwofortytwo") : rs.getString("42");
+
+        stmt.executeUpdate("update JdbcUtf8 set a='aa', b='bb', fortytwo='4242' where key='" + key + "'");
+        rs = stmt.executeQuery("select a, b, fortytwo from JdbcUtf8 where key='" + key + "'");
+        assert rs.next();
+        assert rs.getString("a").equals("aa");
+        assert rs.getString("b").equals("bb");
+        assert rs.getInt("fortytwo") == 4242L;
+        
+        md = rs.getMetaData();
+        expectedMetaData(md, 1, String.class.getName(), "JdbcUtf8", "Keyspace1", "a", Types.VARCHAR, UTF8Type.class.getSimpleName(), false, true);
+        expectedMetaData(md, 2, String.class.getName(), "JdbcUtf8", "Keyspace1", "b", Types.VARCHAR, UTF8Type.class.getSimpleName(), false, true);
+        expectedMetaData(md, 3, BigInteger.class.getName(), "JdbcUtf8", "Keyspace1", "fortytwo", Types.BIGINT, IntegerType.class.getSimpleName(), true, false);
+    }
+        
+    @Test
+    public void testLongMetadata() throws SQLException
+    {
+        String key = FBUtilities.bytesToHex("Long".getBytes());
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("UPDATE JdbcLong SET 1=111, 2=222 WHERE KEY = '" + key + "'");
+        ResultSet rs = stmt.executeQuery("SELECT 1, 2 from JdbcLong WHERE KEY = '" + key + "'");
+        assert rs.next();
+        assert rs.getLong("1") == 111;
+        assert rs.getLong("2") == 222;
+        
+        ResultSetMetaData md = rs.getMetaData();
+        assert md.getColumnCount() == 2;
+        expectedMetaData(md, 1, Long.class.getName(), "JdbcLong", "Keyspace1", "1", Types.INTEGER, LongType.class.getSimpleName(), true, false);
+        expectedMetaData(md, 2, Long.class.getName(), "JdbcLong", "Keyspace1", "2", Types.INTEGER, LongType.class.getSimpleName(), true, false);
+        
+        for (int i = 0; i < md.getColumnCount(); i++)
+            expectedMetaData(md, i + 1, Long.class.getName(), Types.INTEGER, LongType.class.getSimpleName(), true, false);
+    }
+
+    @Test
+    public void testStringMetadata() throws SQLException
+    {
+        String aKey = FBUtilities.bytesToHex("ascii".getBytes());
+        String uKey = FBUtilities.bytesToHex("utf8".getBytes());
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("UPDATE JdbcAscii SET a='aa', b='bb' WHERE KEY = '" + aKey + "'");
+        stmt.executeUpdate("UPDATE JdbcUtf8 SET a='aa', b='bb' WHERE KEY = '" + uKey + "'");
+        ResultSet rs0 = stmt.executeQuery("SELECT a, b FROM JdbcAscii WHERE KEY = '" + aKey + "'");
+        ResultSet rs1 = stmt.executeQuery("SELECT a, b FROM JdbcUtf8 WHERE KEY = '" + uKey + "'");
+        for (ResultSet rs : new ResultSet[] { rs0, rs1 }) 
+        {
+            assert rs.next();
+            assert rs.getString("a").equals("aa");
+            assert rs.getString("b").equals("bb");
+        }
+        
+        ResultSetMetaData md = rs0.getMetaData();
+        assert md.getColumnCount() == 2;
+        expectedMetaData(md, 1, String.class.getName(), "JdbcAscii", "Keyspace1", "a", Types.VARCHAR, AsciiType.class.getSimpleName(), false, true);
+        expectedMetaData(md, 2, String.class.getName(), "JdbcAscii", "Keyspace1", "b", Types.VARCHAR, AsciiType.class.getSimpleName(), false, true);
+        md = rs1.getMetaData();
+        assert md.getColumnCount() == 2;
+        expectedMetaData(md, 1, String.class.getName(), "JdbcUtf8", "Keyspace1", "a", Types.VARCHAR, UTF8Type.class.getSimpleName(), false, true);
+        expectedMetaData(md, 2, String.class.getName(), "JdbcUtf8", "Keyspace1", "b", Types.VARCHAR, UTF8Type.class.getSimpleName(), false, true);
+
+        for (int i = 0; i < 2; i++)
+        {
+            expectedMetaData(rs0.getMetaData(),
+                             i + 1,
+                             String.class.getName(),
+                             Types.VARCHAR,
+                             AsciiType.class.getSimpleName(),
+                             false,
+                             true);
+            expectedMetaData(rs1.getMetaData(),
+                             i + 1,
+                             String.class.getName(),
+                             Types.VARCHAR,
+                             UTF8Type.class.getSimpleName(),
+                             false,
+                             true);
+
+        }
+    }
+    
+    @Test
+    public void testBytesMetadata() throws SQLException 
+    {
+        String key = FBUtilities.bytesToHex("bytes".getBytes());
+        Statement stmt = con.createStatement();
+        byte[] a = "a_".getBytes();
+        byte[] b = "b_".getBytes();
+        byte[] aa = "_aa_".getBytes();
+        byte[] bb = "_bb_".getBytes();
+        stmt.executeUpdate(String.format(
+                "UPDATE JdbcBytes set '%s'='%s', '%s'='%s' WHERE KEY = '" + key + "'",
+                FBUtilities.bytesToHex(a),
+                FBUtilities.bytesToHex(aa),
+                FBUtilities.bytesToHex(b),
+                FBUtilities.bytesToHex(bb)));
+        ResultSet rs = stmt.executeQuery(String.format(
+                "SELECT '%s', '%s' from JdbcBytes WHERE KEY = '" + key + "'",
+                FBUtilities.bytesToHex(a),
+                FBUtilities.bytesToHex(b)));
+        assert rs.next();
+        assert Arrays.equals(aa, rs.getBytes(1));
+        assert Arrays.equals(bb, rs.getBytes(2));
+        assert Arrays.equals(aa, rs.getBytes(FBUtilities.bytesToHex(a)));
+        assert Arrays.equals(bb, rs.getBytes(FBUtilities.bytesToHex(b)));
+        ResultSetMetaData md = rs.getMetaData();
+        assert md.getColumnCount() == 2;
+        expectedMetaData(md, 1, ByteBuffer.class.getName(), "JdbcBytes", "Keyspace1", FBUtilities.bytesToHex(a), Types.BINARY, BytesType.class.getSimpleName(), false, false);
+        expectedMetaData(md, 2, ByteBuffer.class.getName(), "JdbcBytes", "Keyspace1", FBUtilities.bytesToHex(b), Types.BINARY, BytesType.class.getSimpleName(), false, false);
+        
+        for (int i = 0; i < md.getColumnCount(); i++)
+            expectedMetaData(md, i + 1, ByteBuffer.class.getName(), Types.BINARY, BytesType.class.getSimpleName(), false, false);
+    }
+
+    @Test
+    public void testWithStatementBytesType() throws SQLException
+    {
+        Statement stmt = con.createStatement();
+        
+        String selectQ = String.format("SELECT '%s', '%s' FROM Standard1 WHERE KEY='%s'", first, last, jsmith);
+        checkResultSet(stmt.executeQuery(selectQ), "Bytes", 1, first, last);
+        
+        selectQ = String.format("SELECT '%s', '%s' FROM JdbcBytes WHERE KEY='%s'", first, last, jsmith);
+        checkResultSet(stmt.executeQuery(selectQ), "Bytes", 1, first, last);
+    }
+    
+    /** Method to test statement. */
+    @Test
+    public void testWithStatement() throws SQLException
+    {
+        Statement stmt = con.createStatement();
+        List<String> keys = Arrays.asList(jsmith);
+        String selectQ = "SELECT 1, 2 FROM JdbcInteger WHERE KEY='" + jsmith + "'";
+        checkResultSet(stmt.executeQuery(selectQ), "Int", 1, keys, "1", "2");
+        
+        selectQ = "SELECT 3, 4 FROM JdbcInteger WHERE KEY='" + jsmith + "'";
+        checkResultSet(stmt.executeQuery(selectQ), "Int", 1, keys, "3", "4");
+        
+        selectQ = "SELECT 1, 2, 3, 4 FROM JdbcInteger WHERE KEY='" + jsmith + "'";
+        checkResultSet(stmt.executeQuery(selectQ), "Int", 1, keys, "1", "2", "3", "4");
+        
+        selectQ = "SELECT 1, 2 FROM JdbcLong WHERE KEY='" + jsmith + "'";
+        checkResultSet(stmt.executeQuery(selectQ), "Long", 1, keys, "1", "2");
+        
+        selectQ = "SELECT 'first', last FROM JdbcAscii WHERE KEY='" + jsmith + "'";
+        checkResultSet(stmt.executeQuery(selectQ), "String", 1, keys, "first", "last");
+        
+        selectQ = String.format("SELECT '%s', '%s' FROM JdbcBytes WHERE KEY='%s'", first, last, jsmith);
+        checkResultSet(stmt.executeQuery(selectQ), "Bytes", 1, keys, first, last);
+        
+        selectQ = "SELECT 'first', last FROM JdbcUtf8 WHERE KEY='" + jsmith + "'";
+        checkResultSet(stmt.executeQuery(selectQ), "String", 1, keys, "first", "last");
+
+        String badKey = FBUtilities.bytesToHex(String.format("jsmith-%s", System.currentTimeMillis()).getBytes());
+        selectQ = "SELECT 1, 2 FROM JdbcInteger WHERE KEY IN ('" + badKey + "', '" + jsmith + "')";
+        checkResultSet(stmt.executeQuery(selectQ), "Int", 1, keys, "1", "2");
+    }
+    
+    @Test
+    public void testWithPreparedStatementBytesType() throws SQLException
+    {
+        String selectQ = String.format("SELECT '%s', '%s' FROM Standard1 WHERE KEY='%s'", first, last, jsmith);
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Bytes", 1, first, last);
+        
+        selectQ = String.format("SELECT '%s', '%s' FROM JdbcBytes WHERE KEY='%s'", first, last, jsmith);
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Bytes", 1, first, last);
+    }
+
+   /** Method to test with prepared statement.*/
+   @Test
+    public void testWithPreparedStatement() throws SQLException
+    {
+        List<String> keys = Arrays.asList(jsmith);
+
+        String selectQ = String.format("SELECT '%s', '%s' FROM Standard1 WHERE KEY='%s'", first, last, jsmith);
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Bytes", 1, keys, first, last);
+        
+        selectQ = "SELECT 1, 2 FROM JdbcInteger WHERE KEY='" + jsmith + "'";
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Int", 1, keys, "1", "2");
+        
+        selectQ = "SELECT 3, 4 FROM JdbcInteger WHERE KEY='" + jsmith + "'";
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Int", 1, keys, "3", "4");
+        
+        selectQ = "SELECT 1, 2, 3, 4 FROM JdbcInteger WHERE KEY='" + jsmith + "'";
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Int", 1, keys, "1", "2", "3", "4");
+        
+        selectQ = "SELECT 1, 2 FROM JdbcLong WHERE KEY='" + jsmith + "'";
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Long", 1, keys, "1", "2");
+        
+        selectQ = "SELECT 'first', last FROM JdbcAscii WHERE KEY='" + jsmith + "'";
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "String", 1, keys, "first", "last");
+        
+        selectQ = String.format("SELECT '%s', '%s' FROM JdbcBytes WHERE KEY='%s'", first, last, jsmith);
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Bytes", 1, keys, first, last);
+        
+        selectQ = "SELECT 'first', last FROM JdbcUtf8 WHERE KEY='" + jsmith + "'";
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "String", 1, keys, "first", "last");
+
+        String badKey = FBUtilities.bytesToHex(String.format("jsmith-%s", System.currentTimeMillis()).getBytes());
+        selectQ = "SELECT 1, 2 FROM JdbcInteger WHERE KEY IN ('" + badKey + "', '" + jsmith + "')";
+        checkResultSet(executePreparedStatementWithResults(con, selectQ), "Int", 1, keys, "1", "2");
+    }
+
+    /* Method to test with Delete statement. */
+    @Test
+    public void testWithDeleteStatement() throws SQLException
+    {
+        // the pattern: 0) a deltion, 1) ensure deletion 2) ensure deletion wasn't over-eager.
+        String[] statements = 
+        {
+                String.format("DELETE '%s', '%s' FROM Standard1 WHERE KEY='%s'",
+                              FBUtilities.bytesToHex("firstN".getBytes()),
+                              FBUtilities.bytesToHex("lastN".getBytes()),
+                              jsmith),
+                String.format("SELECT '%s', '%s' FROM Standard1 WHERE KEY='%s'",
+                              FBUtilities.bytesToHex("firstN".getBytes()),
+                              FBUtilities.bytesToHex("lastN".getBytes()),
+                              jsmith),
+                String.format("SELECT '%s' FROM Standard1 WHERE KEY='%s'",
+                              first,
+                              jsmith),
+                
+                "DELETE 1, 3 FROM JdbcInteger WHERE KEY='" + jsmith + "'",
+                "SELECT 1, 3 FROM JdbcInteger WHERE KEY='" + jsmith + "'",
+                "SELECT 2, 4 FROM JdbcInteger WHERE KEY='" + jsmith + "'",
+                
+                "DELETE 1 FROM JdbcLong WHERE KEY='" + jsmith + "'",
+                "SELECT 1 FROM JdbcLong WHERE KEY='" + jsmith + "'",
+                "SELECT 2 FROM JdbcLong WHERE KEY='" + jsmith + "'",
+                
+                "DELETE 'first' FROM JdbcAscii WHERE KEY='" + jsmith + "'",
+                "SELECT 'first' FROM JdbcAscii WHERE KEY='" + jsmith + "'",
+                "SELECT last FROM JdbcAscii WHERE KEY='" + jsmith + "'",
+                
+                String.format("DELETE '%s' FROM JdbcBytes WHERE KEY='%s'", first, jsmith),
+                String.format("SELECT '%s' FROM JdbcBytes WHERE KEY='%s'", first, jsmith),
+                String.format("SELECT '%s' FROM JdbcBytes WHERE KEY='%s'", last, jsmith),
+                
+                "DELETE 'first' FROM JdbcUtf8 WHERE KEY='" + jsmith + "'",
+                "SELECT 'first' FROM JdbcUtf8 WHERE KEY='" + jsmith + "'",
+                "SELECT last FROM JdbcUtf8 WHERE KEY='" + jsmith + "'",
+        };
+        
+        for (int i = 0; i < statements.length/3; i++) 
+        {
+            executeNoResults(con, statements[3*i]);
+            ResultSet rs = executePreparedStatementWithResults(con, statements[3*i+1]);
+            rs.next();
+            rs.getObject(1);
+            assert rs.wasNull();
+            rs.close();
+
+            rs = executePreparedStatementWithResults(con, statements[3*i+2]);
+            assert rs.next() : statements[3*i+2];
+        }
+    }
+
+    @AfterClass
+    public static void stopServer() throws SQLException
+    {
+        if (con != null)
+        {
+            String[] stmts = 
+            {
+                "TRUNCATE Standard1",
+                "TRUNCATE JdbcAscii", // todo: this one is broken for some reason.
+                "TRUNCATE JdbcInteger",
+                "TRUNCATE JdbcLong",
+                "TRUNCATE JdbcBytes",
+                "TRUNCATE JdbcUtf8",
+            };
+            for (String stmt : stmts)
+            {
+                try 
+                {
+                    executeNoResults(con, stmt);
+                }
+                catch (SQLException ex)
+                {
+                    throw new SQLException(stmt, ex);
+                }
+            }
+            con.close();
+            con = null;
+        }
+        
+        // Cleanup backup links
+        File backups = new File("build/test/cassandra/data/Keyspace1/backups");
+        if (backups.exists())
+            for (String fname : backups.list())
+                new File("build/test/cassandra/data/Keyspace1/backups" + File.separator + fname).delete();
+    }
+    
+    // todo: check expected values as well.
+    /** iterates over a result set checking columns */
+    private static void checkResultSet(ResultSet rs, String accessor, int expectedRows, String... cols) throws SQLException
+    {
+        checkResultSet(rs, accessor, expectedRows, null, cols);
+    }
+
+    private static void checkResultSet(ResultSet rs, String accessor, int expectedRows, List<String> keys,  String... cols) throws SQLException
+    {
+        int actualRows = 0;
+        assert rs != null;
+        Iterator<String> keyIter = (keys == null) ? null : keys.iterator();
+        CassandraResultSet cassandraRs = (CassandraResultSet)rs;
+        while (rs.next())
+        {
+            actualRows++;
+            if (keyIter != null)
+            {
+                assert cassandraRs.getTypedKey().getValueString().equals(keyIter.next());
+            }
+
+            for (int c = 0; c < cols.length; c++)
+            {
+                // getObject should always work.
+                assert rs.getObject(cols[c]) != null;
+                assert rs.getObject(c+1) != null;
+                
+                // now call the accessor.
+                try
+                {
+                    Method byInt = rs.getClass().getDeclaredMethod("get" + accessor, int.class);
+                    byInt.setAccessible(true);
+                    assert byInt.invoke(rs, c+1) != null;
+                    
+                    Method byString = rs.getClass().getDeclaredMethod("get" + accessor, String.class);
+                    byString.setAccessible(true);
+                    assert byString.invoke(rs, cols[c]) != null;
+                }
+                catch (NoSuchMethodException ex)
+                {
+                    throw new RuntimeException(ex);
+                }
+                catch (IllegalAccessException ex)
+                {
+                    throw new RuntimeException(ex);
+                }
+                catch (InvocationTargetException ex) 
+                {
+                    throw new RuntimeException(ex);
+                }
+            }
+        }
+        
+        assert actualRows == expectedRows : String.format("expected %d rows, got %d", expectedRows, actualRows);
+    }
+    
+    /** executes a prepared statement */
+    private static ResultSet executePreparedStatementWithResults(final Connection con, final String selectQ) throws SQLException
+    {
+        PreparedStatement statement = con.prepareStatement(selectQ);
+        return statement.executeQuery();
+    }
+
+    /** executes an prepared statement */
+    private static void executeNoResults(final Connection con, final String cql) throws SQLException
+    {
+        PreparedStatement statement = con.prepareStatement(cql);
+        statement.execute();
+    }
+}
diff --git a/drivers/java/test/org/apache/cassandra/cql/jdbc/DataSourceTest.java b/drivers/java/test/org/apache/cassandra/cql/jdbc/DataSourceTest.java
new file mode 100644
index 0000000000..0c16cce6fe
--- /dev/null
+++ b/drivers/java/test/org/apache/cassandra/cql/jdbc/DataSourceTest.java
@@ -0,0 +1,111 @@
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+package org.apache.cassandra.cql.jdbc;
+
+import static org.junit.Assert.*;
+
+import java.io.PrintWriter;
+import java.sql.SQLFeatureNotSupportedException;
+
+import javax.sql.DataSource;
+
+import org.apache.cassandra.cql.EmbeddedServiceBase;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+public class DataSourceTest extends EmbeddedServiceBase
+{
+    private static final String HOST = "localhost";
+    private static final int PORT = 9170;
+    private static final String KEYSPACE = "Test";
+    private static final String USER = "JohnDoe";
+    private static final String PASSWORD = "secret";
+
+
+    @BeforeClass
+    public static void setUpBeforeClass() throws Exception
+    {
+        startCassandraServer();
+    }
+
+    @Test
+    public void testConstructor() throws Exception
+    {
+        CassandraDataSource cds = new CassandraDataSource(HOST,PORT,KEYSPACE,USER,PASSWORD);
+        assertEquals(HOST,cds.getServerName());
+        assertEquals(PORT,cds.getPortNumber());
+        assertEquals(KEYSPACE,cds.getDatabaseName());
+        assertEquals(USER,cds.getUser());
+        assertEquals(PASSWORD,cds.getPassword());
+        
+        DataSource ds = new CassandraDataSource(HOST,PORT,KEYSPACE,USER,PASSWORD);
+        assertNotNull(ds);
+        
+        PrintWriter pw = new PrintWriter(System.err);
+        
+        // null username and password
+        java.sql.Connection cnx = ds.getConnection(null, null);
+        assertFalse(cnx.isClosed());
+        ds.setLoginTimeout(5);
+        assertEquals(5, ds.getLoginTimeout());
+        ds.setLogWriter(pw);
+        assertNotNull(ds.getLogWriter());
+        
+        // no username and password
+        cnx = ds.getConnection();
+        assertFalse(cnx.isClosed());
+        ds.setLoginTimeout(5);
+        assertEquals(5, ds.getLoginTimeout());
+        ds.setLogWriter(pw);
+        assertNotNull(ds.getLogWriter());
+    }
+
+    
+    @Test
+    public void testIsWrapperFor() throws Exception
+    {
+        DataSource ds = new CassandraDataSource(HOST,PORT,KEYSPACE,USER,PASSWORD);
+        
+        boolean isIt = false;
+                
+        // it is a wrapper for DataSource
+        isIt = ds.isWrapperFor(DataSource.class);        
+        assertTrue(isIt);
+        
+        // it is not a wrapper for this test class
+        isIt = ds.isWrapperFor(this.getClass());        
+        assertFalse(isIt);
+    }
+ 
+    @Test(expected=SQLFeatureNotSupportedException.class)
+    public void testUnwrap() throws Exception
+    {
+        DataSource ds = new CassandraDataSource(HOST,PORT,KEYSPACE,USER,PASSWORD);
+
+        // it is a wrapper for DataSource
+        DataSource newds = ds.unwrap(DataSource.class);        
+        assertNotNull(newds);
+        
+        // it is not a wrapper for this test class
+        newds = (DataSource) ds.unwrap(this.getClass());        
+        assertNotNull(newds);
+    }
+}
diff --git a/drivers/java/test/org/apache/cassandra/cql/jdbc/PreparedStatementTest.java b/drivers/java/test/org/apache/cassandra/cql/jdbc/PreparedStatementTest.java
new file mode 100644
index 0000000000..d0d8741a95
--- /dev/null
+++ b/drivers/java/test/org/apache/cassandra/cql/jdbc/PreparedStatementTest.java
@@ -0,0 +1,384 @@
+package org.apache.cassandra.cql.jdbc;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+
+import org.apache.cassandra.cql.EmbeddedServiceBase;
+import org.apache.cassandra.utils.FBUtilities;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import java.sql.DriverManager;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+
+public class PreparedStatementTest extends EmbeddedServiceBase
+{ 
+    private static java.sql.Connection con = null;
+    
+    @BeforeClass
+    public static void waxOn() throws Exception
+    {
+        startCassandraServer();
+        Class.forName("org.apache.cassandra.cql.jdbc.CassandraDriver");
+        con = DriverManager.getConnection("jdbc:cassandra://localhost:9170/Keyspace1");
+    }
+    
+    @Test
+    public void testBytes() throws SQLException
+    {
+        // insert
+        PreparedStatement stmt = con.prepareStatement("update JdbcBytes set ?=?, ?=? where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setBytes(1, FBUtilities.toByteArray(i));
+            stmt.setBytes(2, FBUtilities.toByteArray((i+1)*10));
+            stmt.setBytes(3, FBUtilities.toByteArray(i+100));
+            stmt.setBytes(4, FBUtilities.toByteArray((i+1)*10+1));
+            stmt.setBytes(5, key);
+            stmt.executeUpdate();
+        }
+        
+        // verify
+        stmt = con.prepareStatement("select ?, ? from JdbcBytes where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setBytes(1, FBUtilities.toByteArray(i));
+            stmt.setBytes(2, FBUtilities.toByteArray(i+100));
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            assert rs.next();
+            assert Arrays.equals(rs.getBytes(FBUtilities.bytesToHex(FBUtilities.toByteArray(i))), FBUtilities.toByteArray((i+1)*10));
+            assert Arrays.equals(rs.getBytes(FBUtilities.bytesToHex(FBUtilities.toByteArray(i+100))), FBUtilities.toByteArray((i+1)*10+1));
+            assert Arrays.equals(rs.getBytes(1), FBUtilities.toByteArray((i+1)*10));
+            assert Arrays.equals(rs.getBytes(2), FBUtilities.toByteArray((i+1)*10+1));
+            assert !rs.next();
+            rs.close();
+        }
+        
+        // delete
+        stmt = con.prepareStatement("delete ?, ? from JdbcBytes where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setBytes(1, FBUtilities.toByteArray(i));
+            stmt.setBytes(2, FBUtilities.toByteArray(i+100));
+            stmt.setBytes(3, key);
+            stmt.execute();
+        }
+        
+        // verify
+        stmt = con.prepareStatement("select ?, ? from JdbcBytes where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setBytes(1, FBUtilities.toByteArray(i));
+            stmt.setBytes(2, FBUtilities.toByteArray(i+100));
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            rs.next();
+            assert rs.getString(1) == null;  assert rs.getString(2) == null;
+            rs.close();
+        }
+    }
+    
+    @Test
+    public void testUtf8() throws SQLException
+    {
+        // insert.
+        PreparedStatement stmt = con.prepareStatement("update JdbcUtf8 set ?=?, ?=? where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1\u6543\u3435\u6554");
+            stmt.setString(2, "abc\u6543\u3435\u6554");
+            stmt.setString(3, "2\u6543\u3435\u6554");
+            stmt.setString(4, "def\u6543\u3435\u6554");
+            stmt.setBytes(5, key);
+            stmt.executeUpdate();
+        }
+        
+        // verify
+        stmt = con.prepareStatement("select ?, ? from JdbcUtf8 where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1\u6543\u3435\u6554");
+            stmt.setString(2, "2\u6543\u3435\u6554");
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            assert rs.next();
+            assert rs.getString("1\u6543\u3435\u6554").equals("abc\u6543\u3435\u6554");
+            assert rs.getString("2\u6543\u3435\u6554").equals("def\u6543\u3435\u6554");
+            assert rs.getString(1).equals("abc\u6543\u3435\u6554");
+            assert rs.getString(2).equals("def\u6543\u3435\u6554");
+            assert !rs.next();
+            rs.close();
+        }
+        
+        // delete
+        stmt = con.prepareStatement("delete ?, ? from JdbcUtf8 where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1\u6543\u3435\u6554");
+            stmt.setString(2, "2\u6543\u3435\u6554");
+            stmt.setBytes(3, key);
+            stmt.execute();
+        }
+        
+        // verify
+        stmt = con.prepareStatement("select ?, ? from JdbcUtf8 where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1\u6543\u3435\u6554");
+            stmt.setString(2, "2\u6543\u3435\u6554");
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            rs.next();
+            assert rs.getString(1) == null;  assert rs.getString(2) == null;
+            rs.close();
+        }
+    }
+    
+    @Test
+    public void testAscii() throws SQLException
+    {
+        // insert.
+        PreparedStatement stmt = con.prepareStatement("update JdbcAscii set ?=?, ?=? where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1");
+            stmt.setString(2, "abc");
+            stmt.setString(3, "2");
+            stmt.setString(4, "def");
+            stmt.setBytes(5, key);
+            stmt.executeUpdate();
+        }
+        
+        // verify
+        stmt = con.prepareStatement("select ?, ? from JdbcAscii where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1");
+            stmt.setString(2, "2");
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            assert rs.next();
+            assert rs.getString("1").equals("abc");
+            assert rs.getString("2").equals("def");
+            assert rs.getString(1).equals("abc");
+            assert rs.getString(2).equals("def");
+            assert !rs.next();
+            rs.close();
+        }
+        
+        // delete
+        stmt = con.prepareStatement("delete ?, ? from JdbcAscii where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1");
+            stmt.setString(2, "2");
+            stmt.setBytes(3, key);
+            stmt.execute();
+        }
+        
+        // verify
+        stmt = con.prepareStatement("select ?, ? from JdbcAscii where key=?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setString(1, "1");
+            stmt.setString(2, "2");
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            rs.next();
+            assert rs.getString(1) == null;  assert rs.getString(2) == null;
+            rs.close();
+        }
+    }
+    
+    @Test
+    public void testLong() throws SQLException
+    {
+        PreparedStatement stmt = con.prepareStatement("update JdbcLong set ?=?, ?=? where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setLong(1, 1);
+            stmt.setLong(2, (i+1)*10);
+            stmt.setLong(3, 2);
+            stmt.setLong(4, (i+1)*10+1);
+            stmt.setBytes(5, key);
+            stmt.executeUpdate();
+        }
+        stmt.close();
+        
+        // verify.
+        stmt = con.prepareStatement("select ?, ? from JdbcLong where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setLong(1, 1);
+            stmt.setLong(2, 2);
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            assert rs.next();
+            assert rs.getLong("1") == (i+1)*10;
+            assert rs.getLong("2") == (i+1)*10+1;
+            assert rs.getLong(1) == (i+1)*10;
+            assert rs.getLong(2) == (i+1)*10+1;
+            assert !rs.next();
+            rs.close();
+        }
+        
+        // delete
+        stmt = con.prepareStatement("delete ?, ? from JdbcLong where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setLong(1, 1);
+            stmt.setLong(2, 2);
+            stmt.setBytes(3, key);
+            stmt.execute();
+        }
+        
+        // verify.
+        stmt = con.prepareStatement("select ?, ? from JdbcLong where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setLong(1, 1);
+            stmt.setLong(2, 2);
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            rs.next();
+            rs.getLong(1);
+            assert rs.wasNull();
+            rs.close();
+        }
+    }
+    
+    @Test
+    public void testInteger() throws SQLException
+    {
+        PreparedStatement stmt = con.prepareStatement("update JdbcInteger set ?=?, ?=? where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setInt(1, 1);
+            stmt.setInt(2, (i+1)*10);
+            stmt.setInt(3, 2);
+            stmt.setInt(4, (i+1)*10+1);
+            stmt.setBytes(5, key);
+            stmt.executeUpdate();
+        }
+        stmt.close();
+        
+        // verify.
+        stmt = con.prepareStatement("select ?, ? from JdbcInteger where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setInt(1, 1);
+            stmt.setInt(2, 2);
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            assert rs.next();
+            assert rs.getInt("1") == (i+1)*10;
+            assert rs.getInt("2") == (i+1)*10+1;
+            assert rs.getInt(1) == (i+1)*10;
+            assert rs.getInt(2) == (i+1)*10+1;
+            assert !rs.next();
+            rs.close();
+        }
+        
+        // delete
+        stmt = con.prepareStatement("delete ?, ? from JdbcInteger where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setInt(1, 1);
+            stmt.setInt(2, 2);
+            stmt.setBytes(3, key);
+            stmt.execute();
+        }
+        
+        // verify.
+        stmt = con.prepareStatement("select ?, ? from JdbcInteger where key = ?");
+        for (int i = 0; i < 5; i++)
+        {
+            byte[] key = Integer.toString(i).getBytes();
+            stmt.setInt(1, 1);
+            stmt.setInt(2, 2);
+            stmt.setBytes(3, key);
+            ResultSet rs = stmt.executeQuery();
+            rs.next();
+            rs.getInt(1);
+            assert rs.wasNull();
+            rs.close();
+        }
+    }
+    
+    @Test
+    public void testParamSubstitution() throws SQLException
+    {
+        byte[] key = "key".getBytes();
+        String q = "SELECT 'fo??est', ?, ? from JdbcUtf8 WHERE KEY = ?";
+        CassandraPreparedStatement stmt = (CassandraPreparedStatement)con.prepareStatement(q);
+        stmt.setString(1, "pathological param: ?'make it?? '' sto'p?'");
+        stmt.setString(2, "simple");
+        stmt.setBytes(3, key);
+        String qq = stmt.makeCql();
+        assert qq.equals("SELECT 'fo??est', 'pathological param: ?''make it?? '''' sto''p?''', 'simple' from JdbcUtf8 WHERE KEY = '6b6579'");
+        
+        q = "UPDATE JdbcUtf8 USING CONSISTENCY ONE SET 'fru??us'=?, ?='gr''d?', ?=?, ?=? WHERE key=?";
+        stmt = (CassandraPreparedStatement)con.prepareStatement(q);
+        stmt.setString(1, "o?e");
+        stmt.setString(2, "tw'o");
+        stmt.setString(3, "thr'?'ee");
+        stmt.setString(4, "fo''?'ur");
+        stmt.setString(5, "five");
+        stmt.setString(6, "six");
+        stmt.setBytes(7, key);
+        qq = stmt.makeCql();
+        assert qq.equals("UPDATE JdbcUtf8 USING CONSISTENCY ONE SET 'fru??us'='o?e', 'tw''o'='gr''d?', 'thr''?''ee'='fo''''?''ur', 'five'='six' WHERE key='6b6579'");
+        
+        q = "DELETE ?, ? FROM JdbcUtf8 WHERE KEY=?";
+        stmt = (CassandraPreparedStatement)con.prepareStatement(q);
+        stmt.setString(1, "on'?'");
+        stmt.setString(2, "two");
+        stmt.setBytes(3, key);
+        qq = stmt.makeCql();
+        assert qq.equals("DELETE 'on''?''', 'two' FROM JdbcUtf8 WHERE KEY='6b6579'");
+    }
+}
diff --git a/drivers/py/CHANGES.txt b/drivers/py/CHANGES.txt
new file mode 100644
index 0000000000..866c97565e
--- /dev/null
+++ b/drivers/py/CHANGES.txt
@@ -0,0 +1,2 @@
+1.0.4
+ * fix issues with parameters being escaped incorrectly in Python CQL (CASSANDRA-2993)
diff --git a/drivers/py/README b/drivers/py/README
new file mode 100644
index 0000000000..8beb9f06f1
--- /dev/null
+++ b/drivers/py/README
@@ -0,0 +1,28 @@
+A Python driver for CQL that adheres to py-dbapi v2
+ (PEP249, Python Database API Specification v2.0:  http://www.python.org/dev/peps/pep-0249/).
+
+Standard use:
+ >> import cql
+ >> con = cql.connect(host, port, keyspace)
+ >> cursor = con.cursor()
+ >> cursor.execute("CQL QUERY", {kw=Foo, kw2=Bar, etc...})
+
+    - cursor.description  # None initially, list of N tuples that represent
+                              the N columns in a row after an execute. Only 
+                              contains type and name info, not values.
+    - cursor.rowcount     # -1 initially, N after an execute
+    - cursor.arraysize    # variable size of a fetchmany call
+    - cursor.fetchone()   # returns  a single row
+    - cursor.fetchmany()  # returns  self.arraysize # of rows
+    - cursor.fetchall()   # returns  all rows, don't do this.
+
+ >> cursor.execute("ANOTHER QUERY", **more_kwargs)
+ >> for row in cursor:  # Iteration is equivalent to lots of fetchone() calls
+ >>     doRowMagic(row)
+
+ >> cursor.close()
+ >> con.close()
+
+Query substitution:
+ - Use named parameters and a dictionary of names and values. 
+    e.g. execute("SELECT * FROM CF WHERE name=:name", name="Foo")
diff --git a/drivers/py/cql/__init__.py b/drivers/py/cql/__init__.py
new file mode 100644
index 0000000000..de0087699b
--- /dev/null
+++ b/drivers/py/cql/__init__.py
@@ -0,0 +1,95 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import exceptions
+import datetime
+import time
+
+import connection
+import marshal
+
+
+# dbapi Error hierarchy
+
+class Warning(exceptions.StandardError): pass
+class Error  (exceptions.StandardError): pass
+
+class InterfaceError(Error): pass
+class DatabaseError (Error): pass
+
+class DataError        (DatabaseError): pass
+class OperationalError (DatabaseError): pass
+class IntegrityError   (DatabaseError): pass
+class InternalError    (DatabaseError): pass
+class ProgrammingError (DatabaseError): pass
+class NotSupportedError(DatabaseError): pass
+
+
+# Module constants
+
+apilevel = 1.0
+threadsafety = 1 # Threads may share the module, but not connections/cursors.
+paramstyle = 'named'
+
+# TODO: Pull connections out of a pool instead.
+def connect(host, port=9160, keyspace='system', user=None, password=None):
+    return connection.Connection(host, port, keyspace, user, password)
+
+# Module Type Objects and Constructors
+
+Date = datetime.date
+
+Time = datetime.time
+
+Timestamp = datetime.datetime
+
+Binary = buffer
+
+def DateFromTicks(ticks):
+    return Date(*time.localtime(ticks)[:3])
+
+def TimeFromTicks(ticks):
+    return Time(*time.localtime(ticks)[3:6])
+
+def TimestampFromTicks(ticks):
+    return Timestamp(*time.localtime(ticks)[:6])
+
+class DBAPITypeObject:
+
+    def __init__(self, *values):
+        self.values = values
+
+    def __cmp__(self,other):
+        if other in self.values:
+            return 0
+        if other < self.values:
+            return 1
+        else:
+            return -1
+
+STRING = DBAPITypeObject(marshal.BYTES_TYPE, marshal.ASCII_TYPE, marshal.UTF8_TYPE)
+
+BINARY = DBAPITypeObject(marshal.BYTES_TYPE, marshal.UUID_TYPE, marshal.LEXICAL_UUID_TYPE)
+
+NUMBER = DBAPITypeObject(marshal.LONG_TYPE, marshal.INTEGER_TYPE)
+
+DATETIME = DBAPITypeObject(marshal.TIME_UUID_TYPE)
+
+ROWID = DBAPITypeObject(marshal.BYTES_TYPE, marshal.ASCII_TYPE, marshal.UTF8_TYPE,
+                        marshal.INTEGER_TYPE, marshal.LONG_TYPE, marshal.UUID_TYPE,
+                        marshal.LEXICAL_UUID_TYPE, marshal.TIME_UUID_TYPE)
+
diff --git a/drivers/py/cql/cassandra/Cassandra.py b/drivers/py/cql/cassandra/Cassandra.py
new file mode 100644
index 0000000000..dbe9ff508a
--- /dev/null
+++ b/drivers/py/cql/cassandra/Cassandra.py
@@ -0,0 +1,7064 @@
+#
+# Autogenerated by Thrift
+#
+# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
+#
+
+from thrift.Thrift import *
+from ttypes import *
+from thrift.Thrift import TProcessor
+from thrift.transport import TTransport
+from thrift.protocol import TBinaryProtocol, TProtocol
+try:
+  from thrift.protocol import fastbinary
+except:
+  fastbinary = None
+
+
+class Iface:
+  def login(self, auth_request):
+    """
+    Parameters:
+     - auth_request
+    """
+    pass
+
+  def set_keyspace(self, keyspace):
+    """
+    Parameters:
+     - keyspace
+    """
+    pass
+
+  def get(self, key, column_path, consistency_level):
+    """
+    Get the Column or SuperColumn at the given column_path. If no value is present, NotFoundException is thrown. (This is
+    the only method that can throw an exception under non-failure conditions.)
+
+    Parameters:
+     - key
+     - column_path
+     - consistency_level
+    """
+    pass
+
+  def get_slice(self, key, column_parent, predicate, consistency_level):
+    """
+    Get the group of columns contained by column_parent (either a ColumnFamily name or a ColumnFamily/SuperColumn name
+    pair) specified by the given SlicePredicate. If no matching values are found, an empty list is returned.
+
+    Parameters:
+     - key
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    pass
+
+  def get_count(self, key, column_parent, predicate, consistency_level):
+    """
+    returns the number of columns matching <code>predicate</code> for a particular <code>key</code>,
+    <code>ColumnFamily</code> and optionally <code>SuperColumn</code>.
+
+    Parameters:
+     - key
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    pass
+
+  def multiget_slice(self, keys, column_parent, predicate, consistency_level):
+    """
+    Performs a get_slice for column_parent and predicate for the given keys in parallel.
+
+    Parameters:
+     - keys
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    pass
+
+  def multiget_count(self, keys, column_parent, predicate, consistency_level):
+    """
+    Perform a get_count in parallel on the given list<binary> keys. The return value maps keys to the count found.
+
+    Parameters:
+     - keys
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    pass
+
+  def get_range_slices(self, column_parent, predicate, range, consistency_level):
+    """
+    returns a subset of columns for a contiguous range of keys.
+
+    Parameters:
+     - column_parent
+     - predicate
+     - range
+     - consistency_level
+    """
+    pass
+
+  def get_indexed_slices(self, column_parent, index_clause, column_predicate, consistency_level):
+    """
+    Returns the subset of columns specified in SlicePredicate for the rows matching the IndexClause
+
+    Parameters:
+     - column_parent
+     - index_clause
+     - column_predicate
+     - consistency_level
+    """
+    pass
+
+  def insert(self, key, column_parent, column, consistency_level):
+    """
+    Insert a Column at the given column_parent.column_family and optional column_parent.super_column.
+
+    Parameters:
+     - key
+     - column_parent
+     - column
+     - consistency_level
+    """
+    pass
+
+  def add(self, key, column_parent, column, consistency_level):
+    """
+    Increment or decrement a counter.
+
+    Parameters:
+     - key
+     - column_parent
+     - column
+     - consistency_level
+    """
+    pass
+
+  def remove(self, key, column_path, timestamp, consistency_level):
+    """
+    Remove data from the row specified by key at the granularity specified by column_path, and the given timestamp. Note
+    that all the values in column_path besides column_path.column_family are truly optional: you can remove the entire
+    row by just specifying the ColumnFamily, or you can remove a SuperColumn or a single Column by specifying those levels too.
+
+    Parameters:
+     - key
+     - column_path
+     - timestamp
+     - consistency_level
+    """
+    pass
+
+  def remove_counter(self, key, path, consistency_level):
+    """
+    Remove a counter at the specified location.
+    Note that counters have limited support for deletes: if you remove a counter, you must wait to issue any following update
+    until the delete has reached all the nodes and all of them have been fully compacted.
+
+    Parameters:
+     - key
+     - path
+     - consistency_level
+    """
+    pass
+
+  def batch_mutate(self, mutation_map, consistency_level):
+    """
+      Mutate many columns or super columns for many row keys. See also: Mutation.
+
+      mutation_map maps key to column family to a list of Mutation objects to take place at that scope.
+    *
+
+    Parameters:
+     - mutation_map
+     - consistency_level
+    """
+    pass
+
+  def truncate(self, cfname):
+    """
+    Truncate will mark and entire column family as deleted.
+    From the user's perspective a successful call to truncate will result complete data deletion from cfname.
+    Internally, however, disk space will not be immediatily released, as with all deletes in cassandra, this one
+    only marks the data as deleted.
+    The operation succeeds only if all hosts in the cluster at available and will throw an UnavailableException if
+    some hosts are down.
+
+    Parameters:
+     - cfname
+    """
+    pass
+
+  def describe_schema_versions(self, ):
+    """
+    for each schema version present in the cluster, returns a list of nodes at that version.
+    hosts that do not respond will be under the key DatabaseDescriptor.INITIAL_VERSION.
+    the cluster is all on the same version if the size of the map is 1.
+    """
+    pass
+
+  def describe_keyspaces(self, ):
+    """
+    list the defined keyspaces in this cluster
+    """
+    pass
+
+  def describe_cluster_name(self, ):
+    """
+    get the cluster name
+    """
+    pass
+
+  def describe_version(self, ):
+    """
+    get the thrift api version
+    """
+    pass
+
+  def describe_ring(self, keyspace):
+    """
+    get the token ring: a map of ranges to host addresses,
+    represented as a set of TokenRange instead of a map from range
+    to list of endpoints, because you can't use Thrift structs as
+    map keys:
+    https://issues.apache.org/jira/browse/THRIFT-162
+
+    for the same reason, we can't return a set here, even though
+    order is neither important nor predictable.
+
+    Parameters:
+     - keyspace
+    """
+    pass
+
+  def describe_partitioner(self, ):
+    """
+    returns the partitioner used by this cluster
+    """
+    pass
+
+  def describe_snitch(self, ):
+    """
+    returns the snitch used by this cluster
+    """
+    pass
+
+  def describe_keyspace(self, keyspace):
+    """
+    describe specified keyspace
+
+    Parameters:
+     - keyspace
+    """
+    pass
+
+  def describe_splits(self, cfName, start_token, end_token, keys_per_split):
+    """
+    experimental API for hadoop/parallel query support.
+    may change violently and without warning.
+
+    returns list of token strings such that first subrange is (list[0], list[1]],
+    next is (list[1], list[2]], etc.
+
+    Parameters:
+     - cfName
+     - start_token
+     - end_token
+     - keys_per_split
+    """
+    pass
+
+  def system_add_column_family(self, cf_def):
+    """
+    adds a column family. returns the new schema id.
+
+    Parameters:
+     - cf_def
+    """
+    pass
+
+  def system_drop_column_family(self, column_family):
+    """
+    drops a column family. returns the new schema id.
+
+    Parameters:
+     - column_family
+    """
+    pass
+
+  def system_add_keyspace(self, ks_def):
+    """
+    adds a keyspace and any column families that are part of it. returns the new schema id.
+
+    Parameters:
+     - ks_def
+    """
+    pass
+
+  def system_drop_keyspace(self, keyspace):
+    """
+    drops a keyspace and any column families that are part of it. returns the new schema id.
+
+    Parameters:
+     - keyspace
+    """
+    pass
+
+  def system_update_keyspace(self, ks_def):
+    """
+    updates properties of a keyspace. returns the new schema id.
+
+    Parameters:
+     - ks_def
+    """
+    pass
+
+  def system_update_column_family(self, cf_def):
+    """
+    updates properties of a column family. returns the new schema id.
+
+    Parameters:
+     - cf_def
+    """
+    pass
+
+  def execute_cql_query(self, query, compression):
+    """
+    Executes a CQL (Cassandra Query Language) statement and returns a
+    CqlResult containing the results.
+
+    Parameters:
+     - query
+     - compression
+    """
+    pass
+
+
+class Client(Iface):
+  def __init__(self, iprot, oprot=None):
+    self._iprot = self._oprot = iprot
+    if oprot != None:
+      self._oprot = oprot
+    self._seqid = 0
+
+  def login(self, auth_request):
+    """
+    Parameters:
+     - auth_request
+    """
+    self.send_login(auth_request)
+    self.recv_login()
+
+  def send_login(self, auth_request):
+    self._oprot.writeMessageBegin('login', TMessageType.CALL, self._seqid)
+    args = login_args()
+    args.auth_request = auth_request
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_login(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = login_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.authnx != None:
+      raise result.authnx
+    if result.authzx != None:
+      raise result.authzx
+    return
+
+  def set_keyspace(self, keyspace):
+    """
+    Parameters:
+     - keyspace
+    """
+    self.send_set_keyspace(keyspace)
+    self.recv_set_keyspace()
+
+  def send_set_keyspace(self, keyspace):
+    self._oprot.writeMessageBegin('set_keyspace', TMessageType.CALL, self._seqid)
+    args = set_keyspace_args()
+    args.keyspace = keyspace
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_set_keyspace(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = set_keyspace_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.ire != None:
+      raise result.ire
+    return
+
+  def get(self, key, column_path, consistency_level):
+    """
+    Get the Column or SuperColumn at the given column_path. If no value is present, NotFoundException is thrown. (This is
+    the only method that can throw an exception under non-failure conditions.)
+
+    Parameters:
+     - key
+     - column_path
+     - consistency_level
+    """
+    self.send_get(key, column_path, consistency_level)
+    return self.recv_get()
+
+  def send_get(self, key, column_path, consistency_level):
+    self._oprot.writeMessageBegin('get', TMessageType.CALL, self._seqid)
+    args = get_args()
+    args.key = key
+    args.column_path = column_path
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_get(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = get_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.nfe != None:
+      raise result.nfe
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "get failed: unknown result");
+
+  def get_slice(self, key, column_parent, predicate, consistency_level):
+    """
+    Get the group of columns contained by column_parent (either a ColumnFamily name or a ColumnFamily/SuperColumn name
+    pair) specified by the given SlicePredicate. If no matching values are found, an empty list is returned.
+
+    Parameters:
+     - key
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    self.send_get_slice(key, column_parent, predicate, consistency_level)
+    return self.recv_get_slice()
+
+  def send_get_slice(self, key, column_parent, predicate, consistency_level):
+    self._oprot.writeMessageBegin('get_slice', TMessageType.CALL, self._seqid)
+    args = get_slice_args()
+    args.key = key
+    args.column_parent = column_parent
+    args.predicate = predicate
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_get_slice(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = get_slice_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "get_slice failed: unknown result");
+
+  def get_count(self, key, column_parent, predicate, consistency_level):
+    """
+    returns the number of columns matching <code>predicate</code> for a particular <code>key</code>,
+    <code>ColumnFamily</code> and optionally <code>SuperColumn</code>.
+
+    Parameters:
+     - key
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    self.send_get_count(key, column_parent, predicate, consistency_level)
+    return self.recv_get_count()
+
+  def send_get_count(self, key, column_parent, predicate, consistency_level):
+    self._oprot.writeMessageBegin('get_count', TMessageType.CALL, self._seqid)
+    args = get_count_args()
+    args.key = key
+    args.column_parent = column_parent
+    args.predicate = predicate
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_get_count(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = get_count_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "get_count failed: unknown result");
+
+  def multiget_slice(self, keys, column_parent, predicate, consistency_level):
+    """
+    Performs a get_slice for column_parent and predicate for the given keys in parallel.
+
+    Parameters:
+     - keys
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    self.send_multiget_slice(keys, column_parent, predicate, consistency_level)
+    return self.recv_multiget_slice()
+
+  def send_multiget_slice(self, keys, column_parent, predicate, consistency_level):
+    self._oprot.writeMessageBegin('multiget_slice', TMessageType.CALL, self._seqid)
+    args = multiget_slice_args()
+    args.keys = keys
+    args.column_parent = column_parent
+    args.predicate = predicate
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_multiget_slice(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = multiget_slice_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "multiget_slice failed: unknown result");
+
+  def multiget_count(self, keys, column_parent, predicate, consistency_level):
+    """
+    Perform a get_count in parallel on the given list<binary> keys. The return value maps keys to the count found.
+
+    Parameters:
+     - keys
+     - column_parent
+     - predicate
+     - consistency_level
+    """
+    self.send_multiget_count(keys, column_parent, predicate, consistency_level)
+    return self.recv_multiget_count()
+
+  def send_multiget_count(self, keys, column_parent, predicate, consistency_level):
+    self._oprot.writeMessageBegin('multiget_count', TMessageType.CALL, self._seqid)
+    args = multiget_count_args()
+    args.keys = keys
+    args.column_parent = column_parent
+    args.predicate = predicate
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_multiget_count(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = multiget_count_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "multiget_count failed: unknown result");
+
+  def get_range_slices(self, column_parent, predicate, range, consistency_level):
+    """
+    returns a subset of columns for a contiguous range of keys.
+
+    Parameters:
+     - column_parent
+     - predicate
+     - range
+     - consistency_level
+    """
+    self.send_get_range_slices(column_parent, predicate, range, consistency_level)
+    return self.recv_get_range_slices()
+
+  def send_get_range_slices(self, column_parent, predicate, range, consistency_level):
+    self._oprot.writeMessageBegin('get_range_slices', TMessageType.CALL, self._seqid)
+    args = get_range_slices_args()
+    args.column_parent = column_parent
+    args.predicate = predicate
+    args.range = range
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_get_range_slices(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = get_range_slices_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "get_range_slices failed: unknown result");
+
+  def get_indexed_slices(self, column_parent, index_clause, column_predicate, consistency_level):
+    """
+    Returns the subset of columns specified in SlicePredicate for the rows matching the IndexClause
+
+    Parameters:
+     - column_parent
+     - index_clause
+     - column_predicate
+     - consistency_level
+    """
+    self.send_get_indexed_slices(column_parent, index_clause, column_predicate, consistency_level)
+    return self.recv_get_indexed_slices()
+
+  def send_get_indexed_slices(self, column_parent, index_clause, column_predicate, consistency_level):
+    self._oprot.writeMessageBegin('get_indexed_slices', TMessageType.CALL, self._seqid)
+    args = get_indexed_slices_args()
+    args.column_parent = column_parent
+    args.index_clause = index_clause
+    args.column_predicate = column_predicate
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_get_indexed_slices(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = get_indexed_slices_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "get_indexed_slices failed: unknown result");
+
+  def insert(self, key, column_parent, column, consistency_level):
+    """
+    Insert a Column at the given column_parent.column_family and optional column_parent.super_column.
+
+    Parameters:
+     - key
+     - column_parent
+     - column
+     - consistency_level
+    """
+    self.send_insert(key, column_parent, column, consistency_level)
+    self.recv_insert()
+
+  def send_insert(self, key, column_parent, column, consistency_level):
+    self._oprot.writeMessageBegin('insert', TMessageType.CALL, self._seqid)
+    args = insert_args()
+    args.key = key
+    args.column_parent = column_parent
+    args.column = column
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_insert(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = insert_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    return
+
+  def add(self, key, column_parent, column, consistency_level):
+    """
+    Increment or decrement a counter.
+
+    Parameters:
+     - key
+     - column_parent
+     - column
+     - consistency_level
+    """
+    self.send_add(key, column_parent, column, consistency_level)
+    self.recv_add()
+
+  def send_add(self, key, column_parent, column, consistency_level):
+    self._oprot.writeMessageBegin('add', TMessageType.CALL, self._seqid)
+    args = add_args()
+    args.key = key
+    args.column_parent = column_parent
+    args.column = column
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_add(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = add_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    return
+
+  def remove(self, key, column_path, timestamp, consistency_level):
+    """
+    Remove data from the row specified by key at the granularity specified by column_path, and the given timestamp. Note
+    that all the values in column_path besides column_path.column_family are truly optional: you can remove the entire
+    row by just specifying the ColumnFamily, or you can remove a SuperColumn or a single Column by specifying those levels too.
+
+    Parameters:
+     - key
+     - column_path
+     - timestamp
+     - consistency_level
+    """
+    self.send_remove(key, column_path, timestamp, consistency_level)
+    self.recv_remove()
+
+  def send_remove(self, key, column_path, timestamp, consistency_level):
+    self._oprot.writeMessageBegin('remove', TMessageType.CALL, self._seqid)
+    args = remove_args()
+    args.key = key
+    args.column_path = column_path
+    args.timestamp = timestamp
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_remove(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = remove_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    return
+
+  def remove_counter(self, key, path, consistency_level):
+    """
+    Remove a counter at the specified location.
+    Note that counters have limited support for deletes: if you remove a counter, you must wait to issue any following update
+    until the delete has reached all the nodes and all of them have been fully compacted.
+
+    Parameters:
+     - key
+     - path
+     - consistency_level
+    """
+    self.send_remove_counter(key, path, consistency_level)
+    self.recv_remove_counter()
+
+  def send_remove_counter(self, key, path, consistency_level):
+    self._oprot.writeMessageBegin('remove_counter', TMessageType.CALL, self._seqid)
+    args = remove_counter_args()
+    args.key = key
+    args.path = path
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_remove_counter(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = remove_counter_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    return
+
+  def batch_mutate(self, mutation_map, consistency_level):
+    """
+      Mutate many columns or super columns for many row keys. See also: Mutation.
+
+      mutation_map maps key to column family to a list of Mutation objects to take place at that scope.
+    *
+
+    Parameters:
+     - mutation_map
+     - consistency_level
+    """
+    self.send_batch_mutate(mutation_map, consistency_level)
+    self.recv_batch_mutate()
+
+  def send_batch_mutate(self, mutation_map, consistency_level):
+    self._oprot.writeMessageBegin('batch_mutate', TMessageType.CALL, self._seqid)
+    args = batch_mutate_args()
+    args.mutation_map = mutation_map
+    args.consistency_level = consistency_level
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_batch_mutate(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = batch_mutate_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    return
+
+  def truncate(self, cfname):
+    """
+    Truncate will mark and entire column family as deleted.
+    From the user's perspective a successful call to truncate will result complete data deletion from cfname.
+    Internally, however, disk space will not be immediatily released, as with all deletes in cassandra, this one
+    only marks the data as deleted.
+    The operation succeeds only if all hosts in the cluster at available and will throw an UnavailableException if
+    some hosts are down.
+
+    Parameters:
+     - cfname
+    """
+    self.send_truncate(cfname)
+    self.recv_truncate()
+
+  def send_truncate(self, cfname):
+    self._oprot.writeMessageBegin('truncate', TMessageType.CALL, self._seqid)
+    args = truncate_args()
+    args.cfname = cfname
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_truncate(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = truncate_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    return
+
+  def describe_schema_versions(self, ):
+    """
+    for each schema version present in the cluster, returns a list of nodes at that version.
+    hosts that do not respond will be under the key DatabaseDescriptor.INITIAL_VERSION.
+    the cluster is all on the same version if the size of the map is 1.
+    """
+    self.send_describe_schema_versions()
+    return self.recv_describe_schema_versions()
+
+  def send_describe_schema_versions(self, ):
+    self._oprot.writeMessageBegin('describe_schema_versions', TMessageType.CALL, self._seqid)
+    args = describe_schema_versions_args()
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_schema_versions(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_schema_versions_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_schema_versions failed: unknown result");
+
+  def describe_keyspaces(self, ):
+    """
+    list the defined keyspaces in this cluster
+    """
+    self.send_describe_keyspaces()
+    return self.recv_describe_keyspaces()
+
+  def send_describe_keyspaces(self, ):
+    self._oprot.writeMessageBegin('describe_keyspaces', TMessageType.CALL, self._seqid)
+    args = describe_keyspaces_args()
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_keyspaces(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_keyspaces_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_keyspaces failed: unknown result");
+
+  def describe_cluster_name(self, ):
+    """
+    get the cluster name
+    """
+    self.send_describe_cluster_name()
+    return self.recv_describe_cluster_name()
+
+  def send_describe_cluster_name(self, ):
+    self._oprot.writeMessageBegin('describe_cluster_name', TMessageType.CALL, self._seqid)
+    args = describe_cluster_name_args()
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_cluster_name(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_cluster_name_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_cluster_name failed: unknown result");
+
+  def describe_version(self, ):
+    """
+    get the thrift api version
+    """
+    self.send_describe_version()
+    return self.recv_describe_version()
+
+  def send_describe_version(self, ):
+    self._oprot.writeMessageBegin('describe_version', TMessageType.CALL, self._seqid)
+    args = describe_version_args()
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_version(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_version_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_version failed: unknown result");
+
+  def describe_ring(self, keyspace):
+    """
+    get the token ring: a map of ranges to host addresses,
+    represented as a set of TokenRange instead of a map from range
+    to list of endpoints, because you can't use Thrift structs as
+    map keys:
+    https://issues.apache.org/jira/browse/THRIFT-162
+
+    for the same reason, we can't return a set here, even though
+    order is neither important nor predictable.
+
+    Parameters:
+     - keyspace
+    """
+    self.send_describe_ring(keyspace)
+    return self.recv_describe_ring()
+
+  def send_describe_ring(self, keyspace):
+    self._oprot.writeMessageBegin('describe_ring', TMessageType.CALL, self._seqid)
+    args = describe_ring_args()
+    args.keyspace = keyspace
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_ring(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_ring_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_ring failed: unknown result");
+
+  def describe_partitioner(self, ):
+    """
+    returns the partitioner used by this cluster
+    """
+    self.send_describe_partitioner()
+    return self.recv_describe_partitioner()
+
+  def send_describe_partitioner(self, ):
+    self._oprot.writeMessageBegin('describe_partitioner', TMessageType.CALL, self._seqid)
+    args = describe_partitioner_args()
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_partitioner(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_partitioner_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_partitioner failed: unknown result");
+
+  def describe_snitch(self, ):
+    """
+    returns the snitch used by this cluster
+    """
+    self.send_describe_snitch()
+    return self.recv_describe_snitch()
+
+  def send_describe_snitch(self, ):
+    self._oprot.writeMessageBegin('describe_snitch', TMessageType.CALL, self._seqid)
+    args = describe_snitch_args()
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_snitch(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_snitch_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_snitch failed: unknown result");
+
+  def describe_keyspace(self, keyspace):
+    """
+    describe specified keyspace
+
+    Parameters:
+     - keyspace
+    """
+    self.send_describe_keyspace(keyspace)
+    return self.recv_describe_keyspace()
+
+  def send_describe_keyspace(self, keyspace):
+    self._oprot.writeMessageBegin('describe_keyspace', TMessageType.CALL, self._seqid)
+    args = describe_keyspace_args()
+    args.keyspace = keyspace
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_keyspace(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_keyspace_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.nfe != None:
+      raise result.nfe
+    if result.ire != None:
+      raise result.ire
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_keyspace failed: unknown result");
+
+  def describe_splits(self, cfName, start_token, end_token, keys_per_split):
+    """
+    experimental API for hadoop/parallel query support.
+    may change violently and without warning.
+
+    returns list of token strings such that first subrange is (list[0], list[1]],
+    next is (list[1], list[2]], etc.
+
+    Parameters:
+     - cfName
+     - start_token
+     - end_token
+     - keys_per_split
+    """
+    self.send_describe_splits(cfName, start_token, end_token, keys_per_split)
+    return self.recv_describe_splits()
+
+  def send_describe_splits(self, cfName, start_token, end_token, keys_per_split):
+    self._oprot.writeMessageBegin('describe_splits', TMessageType.CALL, self._seqid)
+    args = describe_splits_args()
+    args.cfName = cfName
+    args.start_token = start_token
+    args.end_token = end_token
+    args.keys_per_split = keys_per_split
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_describe_splits(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = describe_splits_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "describe_splits failed: unknown result");
+
+  def system_add_column_family(self, cf_def):
+    """
+    adds a column family. returns the new schema id.
+
+    Parameters:
+     - cf_def
+    """
+    self.send_system_add_column_family(cf_def)
+    return self.recv_system_add_column_family()
+
+  def send_system_add_column_family(self, cf_def):
+    self._oprot.writeMessageBegin('system_add_column_family', TMessageType.CALL, self._seqid)
+    args = system_add_column_family_args()
+    args.cf_def = cf_def
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_system_add_column_family(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = system_add_column_family_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.sde != None:
+      raise result.sde
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "system_add_column_family failed: unknown result");
+
+  def system_drop_column_family(self, column_family):
+    """
+    drops a column family. returns the new schema id.
+
+    Parameters:
+     - column_family
+    """
+    self.send_system_drop_column_family(column_family)
+    return self.recv_system_drop_column_family()
+
+  def send_system_drop_column_family(self, column_family):
+    self._oprot.writeMessageBegin('system_drop_column_family', TMessageType.CALL, self._seqid)
+    args = system_drop_column_family_args()
+    args.column_family = column_family
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_system_drop_column_family(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = system_drop_column_family_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.sde != None:
+      raise result.sde
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "system_drop_column_family failed: unknown result");
+
+  def system_add_keyspace(self, ks_def):
+    """
+    adds a keyspace and any column families that are part of it. returns the new schema id.
+
+    Parameters:
+     - ks_def
+    """
+    self.send_system_add_keyspace(ks_def)
+    return self.recv_system_add_keyspace()
+
+  def send_system_add_keyspace(self, ks_def):
+    self._oprot.writeMessageBegin('system_add_keyspace', TMessageType.CALL, self._seqid)
+    args = system_add_keyspace_args()
+    args.ks_def = ks_def
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_system_add_keyspace(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = system_add_keyspace_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.sde != None:
+      raise result.sde
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "system_add_keyspace failed: unknown result");
+
+  def system_drop_keyspace(self, keyspace):
+    """
+    drops a keyspace and any column families that are part of it. returns the new schema id.
+
+    Parameters:
+     - keyspace
+    """
+    self.send_system_drop_keyspace(keyspace)
+    return self.recv_system_drop_keyspace()
+
+  def send_system_drop_keyspace(self, keyspace):
+    self._oprot.writeMessageBegin('system_drop_keyspace', TMessageType.CALL, self._seqid)
+    args = system_drop_keyspace_args()
+    args.keyspace = keyspace
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_system_drop_keyspace(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = system_drop_keyspace_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.sde != None:
+      raise result.sde
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "system_drop_keyspace failed: unknown result");
+
+  def system_update_keyspace(self, ks_def):
+    """
+    updates properties of a keyspace. returns the new schema id.
+
+    Parameters:
+     - ks_def
+    """
+    self.send_system_update_keyspace(ks_def)
+    return self.recv_system_update_keyspace()
+
+  def send_system_update_keyspace(self, ks_def):
+    self._oprot.writeMessageBegin('system_update_keyspace', TMessageType.CALL, self._seqid)
+    args = system_update_keyspace_args()
+    args.ks_def = ks_def
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_system_update_keyspace(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = system_update_keyspace_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.sde != None:
+      raise result.sde
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "system_update_keyspace failed: unknown result");
+
+  def system_update_column_family(self, cf_def):
+    """
+    updates properties of a column family. returns the new schema id.
+
+    Parameters:
+     - cf_def
+    """
+    self.send_system_update_column_family(cf_def)
+    return self.recv_system_update_column_family()
+
+  def send_system_update_column_family(self, cf_def):
+    self._oprot.writeMessageBegin('system_update_column_family', TMessageType.CALL, self._seqid)
+    args = system_update_column_family_args()
+    args.cf_def = cf_def
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_system_update_column_family(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = system_update_column_family_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.sde != None:
+      raise result.sde
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "system_update_column_family failed: unknown result");
+
+  def execute_cql_query(self, query, compression):
+    """
+    Executes a CQL (Cassandra Query Language) statement and returns a
+    CqlResult containing the results.
+
+    Parameters:
+     - query
+     - compression
+    """
+    self.send_execute_cql_query(query, compression)
+    return self.recv_execute_cql_query()
+
+  def send_execute_cql_query(self, query, compression):
+    self._oprot.writeMessageBegin('execute_cql_query', TMessageType.CALL, self._seqid)
+    args = execute_cql_query_args()
+    args.query = query
+    args.compression = compression
+    args.write(self._oprot)
+    self._oprot.writeMessageEnd()
+    self._oprot.trans.flush()
+
+  def recv_execute_cql_query(self, ):
+    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
+    if mtype == TMessageType.EXCEPTION:
+      x = TApplicationException()
+      x.read(self._iprot)
+      self._iprot.readMessageEnd()
+      raise x
+    result = execute_cql_query_result()
+    result.read(self._iprot)
+    self._iprot.readMessageEnd()
+    if result.success != None:
+      return result.success
+    if result.ire != None:
+      raise result.ire
+    if result.ue != None:
+      raise result.ue
+    if result.te != None:
+      raise result.te
+    if result.sde != None:
+      raise result.sde
+    raise TApplicationException(TApplicationException.MISSING_RESULT, "execute_cql_query failed: unknown result");
+
+
+class Processor(Iface, TProcessor):
+  def __init__(self, handler):
+    self._handler = handler
+    self._processMap = {}
+    self._processMap["login"] = Processor.process_login
+    self._processMap["set_keyspace"] = Processor.process_set_keyspace
+    self._processMap["get"] = Processor.process_get
+    self._processMap["get_slice"] = Processor.process_get_slice
+    self._processMap["get_count"] = Processor.process_get_count
+    self._processMap["multiget_slice"] = Processor.process_multiget_slice
+    self._processMap["multiget_count"] = Processor.process_multiget_count
+    self._processMap["get_range_slices"] = Processor.process_get_range_slices
+    self._processMap["get_indexed_slices"] = Processor.process_get_indexed_slices
+    self._processMap["insert"] = Processor.process_insert
+    self._processMap["add"] = Processor.process_add
+    self._processMap["remove"] = Processor.process_remove
+    self._processMap["remove_counter"] = Processor.process_remove_counter
+    self._processMap["batch_mutate"] = Processor.process_batch_mutate
+    self._processMap["truncate"] = Processor.process_truncate
+    self._processMap["describe_schema_versions"] = Processor.process_describe_schema_versions
+    self._processMap["describe_keyspaces"] = Processor.process_describe_keyspaces
+    self._processMap["describe_cluster_name"] = Processor.process_describe_cluster_name
+    self._processMap["describe_version"] = Processor.process_describe_version
+    self._processMap["describe_ring"] = Processor.process_describe_ring
+    self._processMap["describe_partitioner"] = Processor.process_describe_partitioner
+    self._processMap["describe_snitch"] = Processor.process_describe_snitch
+    self._processMap["describe_keyspace"] = Processor.process_describe_keyspace
+    self._processMap["describe_splits"] = Processor.process_describe_splits
+    self._processMap["system_add_column_family"] = Processor.process_system_add_column_family
+    self._processMap["system_drop_column_family"] = Processor.process_system_drop_column_family
+    self._processMap["system_add_keyspace"] = Processor.process_system_add_keyspace
+    self._processMap["system_drop_keyspace"] = Processor.process_system_drop_keyspace
+    self._processMap["system_update_keyspace"] = Processor.process_system_update_keyspace
+    self._processMap["system_update_column_family"] = Processor.process_system_update_column_family
+    self._processMap["execute_cql_query"] = Processor.process_execute_cql_query
+
+  def process(self, iprot, oprot):
+    (name, type, seqid) = iprot.readMessageBegin()
+    if name not in self._processMap:
+      iprot.skip(TType.STRUCT)
+      iprot.readMessageEnd()
+      x = TApplicationException(TApplicationException.UNKNOWN_METHOD, 'Unknown function %s' % (name))
+      oprot.writeMessageBegin(name, TMessageType.EXCEPTION, seqid)
+      x.write(oprot)
+      oprot.writeMessageEnd()
+      oprot.trans.flush()
+      return
+    else:
+      self._processMap[name](self, seqid, iprot, oprot)
+    return True
+
+  def process_login(self, seqid, iprot, oprot):
+    args = login_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = login_result()
+    try:
+      self._handler.login(args.auth_request)
+    except AuthenticationException, authnx:
+      result.authnx = authnx
+    except AuthorizationException, authzx:
+      result.authzx = authzx
+    oprot.writeMessageBegin("login", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_set_keyspace(self, seqid, iprot, oprot):
+    args = set_keyspace_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = set_keyspace_result()
+    try:
+      self._handler.set_keyspace(args.keyspace)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    oprot.writeMessageBegin("set_keyspace", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_get(self, seqid, iprot, oprot):
+    args = get_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = get_result()
+    try:
+      result.success = self._handler.get(args.key, args.column_path, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except NotFoundException, nfe:
+      result.nfe = nfe
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("get", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_get_slice(self, seqid, iprot, oprot):
+    args = get_slice_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = get_slice_result()
+    try:
+      result.success = self._handler.get_slice(args.key, args.column_parent, args.predicate, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("get_slice", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_get_count(self, seqid, iprot, oprot):
+    args = get_count_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = get_count_result()
+    try:
+      result.success = self._handler.get_count(args.key, args.column_parent, args.predicate, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("get_count", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_multiget_slice(self, seqid, iprot, oprot):
+    args = multiget_slice_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = multiget_slice_result()
+    try:
+      result.success = self._handler.multiget_slice(args.keys, args.column_parent, args.predicate, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("multiget_slice", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_multiget_count(self, seqid, iprot, oprot):
+    args = multiget_count_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = multiget_count_result()
+    try:
+      result.success = self._handler.multiget_count(args.keys, args.column_parent, args.predicate, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("multiget_count", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_get_range_slices(self, seqid, iprot, oprot):
+    args = get_range_slices_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = get_range_slices_result()
+    try:
+      result.success = self._handler.get_range_slices(args.column_parent, args.predicate, args.range, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("get_range_slices", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_get_indexed_slices(self, seqid, iprot, oprot):
+    args = get_indexed_slices_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = get_indexed_slices_result()
+    try:
+      result.success = self._handler.get_indexed_slices(args.column_parent, args.index_clause, args.column_predicate, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("get_indexed_slices", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_insert(self, seqid, iprot, oprot):
+    args = insert_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = insert_result()
+    try:
+      self._handler.insert(args.key, args.column_parent, args.column, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("insert", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_add(self, seqid, iprot, oprot):
+    args = add_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = add_result()
+    try:
+      self._handler.add(args.key, args.column_parent, args.column, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("add", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_remove(self, seqid, iprot, oprot):
+    args = remove_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = remove_result()
+    try:
+      self._handler.remove(args.key, args.column_path, args.timestamp, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("remove", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_remove_counter(self, seqid, iprot, oprot):
+    args = remove_counter_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = remove_counter_result()
+    try:
+      self._handler.remove_counter(args.key, args.path, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("remove_counter", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_batch_mutate(self, seqid, iprot, oprot):
+    args = batch_mutate_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = batch_mutate_result()
+    try:
+      self._handler.batch_mutate(args.mutation_map, args.consistency_level)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    oprot.writeMessageBegin("batch_mutate", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_truncate(self, seqid, iprot, oprot):
+    args = truncate_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = truncate_result()
+    try:
+      self._handler.truncate(args.cfname)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    oprot.writeMessageBegin("truncate", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_schema_versions(self, seqid, iprot, oprot):
+    args = describe_schema_versions_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_schema_versions_result()
+    try:
+      result.success = self._handler.describe_schema_versions()
+    except InvalidRequestException, ire:
+      result.ire = ire
+    oprot.writeMessageBegin("describe_schema_versions", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_keyspaces(self, seqid, iprot, oprot):
+    args = describe_keyspaces_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_keyspaces_result()
+    try:
+      result.success = self._handler.describe_keyspaces()
+    except InvalidRequestException, ire:
+      result.ire = ire
+    oprot.writeMessageBegin("describe_keyspaces", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_cluster_name(self, seqid, iprot, oprot):
+    args = describe_cluster_name_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_cluster_name_result()
+    result.success = self._handler.describe_cluster_name()
+    oprot.writeMessageBegin("describe_cluster_name", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_version(self, seqid, iprot, oprot):
+    args = describe_version_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_version_result()
+    result.success = self._handler.describe_version()
+    oprot.writeMessageBegin("describe_version", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_ring(self, seqid, iprot, oprot):
+    args = describe_ring_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_ring_result()
+    try:
+      result.success = self._handler.describe_ring(args.keyspace)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    oprot.writeMessageBegin("describe_ring", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_partitioner(self, seqid, iprot, oprot):
+    args = describe_partitioner_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_partitioner_result()
+    result.success = self._handler.describe_partitioner()
+    oprot.writeMessageBegin("describe_partitioner", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_snitch(self, seqid, iprot, oprot):
+    args = describe_snitch_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_snitch_result()
+    result.success = self._handler.describe_snitch()
+    oprot.writeMessageBegin("describe_snitch", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_keyspace(self, seqid, iprot, oprot):
+    args = describe_keyspace_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_keyspace_result()
+    try:
+      result.success = self._handler.describe_keyspace(args.keyspace)
+    except NotFoundException, nfe:
+      result.nfe = nfe
+    except InvalidRequestException, ire:
+      result.ire = ire
+    oprot.writeMessageBegin("describe_keyspace", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_describe_splits(self, seqid, iprot, oprot):
+    args = describe_splits_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = describe_splits_result()
+    try:
+      result.success = self._handler.describe_splits(args.cfName, args.start_token, args.end_token, args.keys_per_split)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    oprot.writeMessageBegin("describe_splits", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_system_add_column_family(self, seqid, iprot, oprot):
+    args = system_add_column_family_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = system_add_column_family_result()
+    try:
+      result.success = self._handler.system_add_column_family(args.cf_def)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except SchemaDisagreementException, sde:
+      result.sde = sde
+    oprot.writeMessageBegin("system_add_column_family", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_system_drop_column_family(self, seqid, iprot, oprot):
+    args = system_drop_column_family_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = system_drop_column_family_result()
+    try:
+      result.success = self._handler.system_drop_column_family(args.column_family)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except SchemaDisagreementException, sde:
+      result.sde = sde
+    oprot.writeMessageBegin("system_drop_column_family", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_system_add_keyspace(self, seqid, iprot, oprot):
+    args = system_add_keyspace_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = system_add_keyspace_result()
+    try:
+      result.success = self._handler.system_add_keyspace(args.ks_def)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except SchemaDisagreementException, sde:
+      result.sde = sde
+    oprot.writeMessageBegin("system_add_keyspace", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_system_drop_keyspace(self, seqid, iprot, oprot):
+    args = system_drop_keyspace_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = system_drop_keyspace_result()
+    try:
+      result.success = self._handler.system_drop_keyspace(args.keyspace)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except SchemaDisagreementException, sde:
+      result.sde = sde
+    oprot.writeMessageBegin("system_drop_keyspace", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_system_update_keyspace(self, seqid, iprot, oprot):
+    args = system_update_keyspace_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = system_update_keyspace_result()
+    try:
+      result.success = self._handler.system_update_keyspace(args.ks_def)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except SchemaDisagreementException, sde:
+      result.sde = sde
+    oprot.writeMessageBegin("system_update_keyspace", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_system_update_column_family(self, seqid, iprot, oprot):
+    args = system_update_column_family_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = system_update_column_family_result()
+    try:
+      result.success = self._handler.system_update_column_family(args.cf_def)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except SchemaDisagreementException, sde:
+      result.sde = sde
+    oprot.writeMessageBegin("system_update_column_family", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+  def process_execute_cql_query(self, seqid, iprot, oprot):
+    args = execute_cql_query_args()
+    args.read(iprot)
+    iprot.readMessageEnd()
+    result = execute_cql_query_result()
+    try:
+      result.success = self._handler.execute_cql_query(args.query, args.compression)
+    except InvalidRequestException, ire:
+      result.ire = ire
+    except UnavailableException, ue:
+      result.ue = ue
+    except TimedOutException, te:
+      result.te = te
+    except SchemaDisagreementException, sde:
+      result.sde = sde
+    oprot.writeMessageBegin("execute_cql_query", TMessageType.REPLY, seqid)
+    result.write(oprot)
+    oprot.writeMessageEnd()
+    oprot.trans.flush()
+
+
+# HELPER FUNCTIONS AND STRUCTURES
+
+class login_args:
+  """
+  Attributes:
+   - auth_request
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'auth_request', (AuthenticationRequest, AuthenticationRequest.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, auth_request=None,):
+    self.auth_request = auth_request
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.auth_request = AuthenticationRequest()
+          self.auth_request.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('login_args')
+    if self.auth_request != None:
+      oprot.writeFieldBegin('auth_request', TType.STRUCT, 1)
+      self.auth_request.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.auth_request is None:
+        raise TProtocol.TProtocolException(message='Required field auth_request is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class login_result:
+  """
+  Attributes:
+   - authnx
+   - authzx
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'authnx', (AuthenticationException, AuthenticationException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'authzx', (AuthorizationException, AuthorizationException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, authnx=None, authzx=None,):
+    self.authnx = authnx
+    self.authzx = authzx
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.authnx = AuthenticationException()
+          self.authnx.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.authzx = AuthorizationException()
+          self.authzx.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('login_result')
+    if self.authnx != None:
+      oprot.writeFieldBegin('authnx', TType.STRUCT, 1)
+      self.authnx.write(oprot)
+      oprot.writeFieldEnd()
+    if self.authzx != None:
+      oprot.writeFieldBegin('authzx', TType.STRUCT, 2)
+      self.authzx.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class set_keyspace_args:
+  """
+  Attributes:
+   - keyspace
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'keyspace', None, None, ), # 1
+  )
+
+  def __init__(self, keyspace=None,):
+    self.keyspace = keyspace
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.keyspace = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('set_keyspace_args')
+    if self.keyspace != None:
+      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
+      oprot.writeString(self.keyspace)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.keyspace is None:
+        raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class set_keyspace_result:
+  """
+  Attributes:
+   - ire
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, ire=None,):
+    self.ire = ire
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('set_keyspace_result')
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_args:
+  """
+  Attributes:
+   - key
+   - column_path
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.STRUCT, 'column_path', (ColumnPath, ColumnPath.thrift_spec), None, ), # 2
+    (3, TType.I32, 'consistency_level', None,     1, ), # 3
+  )
+
+  def __init__(self, key=None, column_path=None, consistency_level=thrift_spec[3][4],):
+    self.key = key
+    self.column_path = column_path
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_path = ColumnPath()
+          self.column_path.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_args')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.column_path != None:
+      oprot.writeFieldBegin('column_path', TType.STRUCT, 2)
+      self.column_path.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 3)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.column_path is None:
+        raise TProtocol.TProtocolException(message='Required field column_path is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - nfe
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    (0, TType.STRUCT, 'success', (ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'nfe', (NotFoundException, NotFoundException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 3
+    (4, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 4
+  )
+
+  def __init__(self, success=None, ire=None, nfe=None, ue=None, te=None,):
+    self.success = success
+    self.ire = ire
+    self.nfe = nfe
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRUCT:
+          self.success = ColumnOrSuperColumn()
+          self.success.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.nfe = NotFoundException()
+          self.nfe.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRUCT, 0)
+      self.success.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.nfe != None:
+      oprot.writeFieldBegin('nfe', TType.STRUCT, 2)
+      self.nfe.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 3)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 4)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_slice_args:
+  """
+  Attributes:
+   - key
+   - column_parent
+   - predicate
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, key=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
+    self.key = key
+    self.column_parent = column_parent
+    self.predicate = predicate
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.predicate = SlicePredicate()
+          self.predicate.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_slice_args')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.predicate != None:
+      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
+      self.predicate.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.predicate is None:
+        raise TProtocol.TProtocolException(message='Required field predicate is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_slice_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    (0, TType.LIST, 'success', (TType.STRUCT,(ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec)), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, success=None, ire=None, ue=None, te=None,):
+    self.success = success
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.LIST:
+          self.success = []
+          (_etype91, _size88) = iprot.readListBegin()
+          for _i92 in xrange(_size88):
+            _elem93 = ColumnOrSuperColumn()
+            _elem93.read(iprot)
+            self.success.append(_elem93)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_slice_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.LIST, 0)
+      oprot.writeListBegin(TType.STRUCT, len(self.success))
+      for iter94 in self.success:
+        iter94.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_count_args:
+  """
+  Attributes:
+   - key
+   - column_parent
+   - predicate
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, key=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
+    self.key = key
+    self.column_parent = column_parent
+    self.predicate = predicate
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.predicate = SlicePredicate()
+          self.predicate.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_count_args')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.predicate != None:
+      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
+      self.predicate.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.predicate is None:
+        raise TProtocol.TProtocolException(message='Required field predicate is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_count_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    (0, TType.I32, 'success', None, None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, success=None, ire=None, ue=None, te=None,):
+    self.success = success
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.I32:
+          self.success = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_count_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.I32, 0)
+      oprot.writeI32(self.success)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class multiget_slice_args:
+  """
+  Attributes:
+   - keys
+   - column_parent
+   - predicate
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.LIST, 'keys', (TType.STRING,None), None, ), # 1
+    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, keys=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
+    self.keys = keys
+    self.column_parent = column_parent
+    self.predicate = predicate
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.LIST:
+          self.keys = []
+          (_etype98, _size95) = iprot.readListBegin()
+          for _i99 in xrange(_size95):
+            _elem100 = iprot.readString();
+            self.keys.append(_elem100)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.predicate = SlicePredicate()
+          self.predicate.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('multiget_slice_args')
+    if self.keys != None:
+      oprot.writeFieldBegin('keys', TType.LIST, 1)
+      oprot.writeListBegin(TType.STRING, len(self.keys))
+      for iter101 in self.keys:
+        oprot.writeString(iter101)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.predicate != None:
+      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
+      self.predicate.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.keys is None:
+        raise TProtocol.TProtocolException(message='Required field keys is unset!')
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.predicate is None:
+        raise TProtocol.TProtocolException(message='Required field predicate is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class multiget_slice_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    (0, TType.MAP, 'success', (TType.STRING,None,TType.LIST,(TType.STRUCT,(ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec))), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, success=None, ire=None, ue=None, te=None,):
+    self.success = success
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.MAP:
+          self.success = {}
+          (_ktype103, _vtype104, _size102 ) = iprot.readMapBegin() 
+          for _i106 in xrange(_size102):
+            _key107 = iprot.readString();
+            _val108 = []
+            (_etype112, _size109) = iprot.readListBegin()
+            for _i113 in xrange(_size109):
+              _elem114 = ColumnOrSuperColumn()
+              _elem114.read(iprot)
+              _val108.append(_elem114)
+            iprot.readListEnd()
+            self.success[_key107] = _val108
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('multiget_slice_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.MAP, 0)
+      oprot.writeMapBegin(TType.STRING, TType.LIST, len(self.success))
+      for kiter115,viter116 in self.success.items():
+        oprot.writeString(kiter115)
+        oprot.writeListBegin(TType.STRUCT, len(viter116))
+        for iter117 in viter116:
+          iter117.write(oprot)
+        oprot.writeListEnd()
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class multiget_count_args:
+  """
+  Attributes:
+   - keys
+   - column_parent
+   - predicate
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.LIST, 'keys', (TType.STRING,None), None, ), # 1
+    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, keys=None, column_parent=None, predicate=None, consistency_level=thrift_spec[4][4],):
+    self.keys = keys
+    self.column_parent = column_parent
+    self.predicate = predicate
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.LIST:
+          self.keys = []
+          (_etype121, _size118) = iprot.readListBegin()
+          for _i122 in xrange(_size118):
+            _elem123 = iprot.readString();
+            self.keys.append(_elem123)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.predicate = SlicePredicate()
+          self.predicate.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('multiget_count_args')
+    if self.keys != None:
+      oprot.writeFieldBegin('keys', TType.LIST, 1)
+      oprot.writeListBegin(TType.STRING, len(self.keys))
+      for iter124 in self.keys:
+        oprot.writeString(iter124)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.predicate != None:
+      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
+      self.predicate.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.keys is None:
+        raise TProtocol.TProtocolException(message='Required field keys is unset!')
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.predicate is None:
+        raise TProtocol.TProtocolException(message='Required field predicate is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class multiget_count_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    (0, TType.MAP, 'success', (TType.STRING,None,TType.I32,None), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, success=None, ire=None, ue=None, te=None,):
+    self.success = success
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.MAP:
+          self.success = {}
+          (_ktype126, _vtype127, _size125 ) = iprot.readMapBegin() 
+          for _i129 in xrange(_size125):
+            _key130 = iprot.readString();
+            _val131 = iprot.readI32();
+            self.success[_key130] = _val131
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('multiget_count_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.MAP, 0)
+      oprot.writeMapBegin(TType.STRING, TType.I32, len(self.success))
+      for kiter132,viter133 in self.success.items():
+        oprot.writeString(kiter132)
+        oprot.writeI32(viter133)
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_range_slices_args:
+  """
+  Attributes:
+   - column_parent
+   - predicate
+   - range
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'range', (KeyRange, KeyRange.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, column_parent=None, predicate=None, range=None, consistency_level=thrift_spec[4][4],):
+    self.column_parent = column_parent
+    self.predicate = predicate
+    self.range = range
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.predicate = SlicePredicate()
+          self.predicate.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.range = KeyRange()
+          self.range.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_range_slices_args')
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 1)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.predicate != None:
+      oprot.writeFieldBegin('predicate', TType.STRUCT, 2)
+      self.predicate.write(oprot)
+      oprot.writeFieldEnd()
+    if self.range != None:
+      oprot.writeFieldBegin('range', TType.STRUCT, 3)
+      self.range.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.predicate is None:
+        raise TProtocol.TProtocolException(message='Required field predicate is unset!')
+      if self.range is None:
+        raise TProtocol.TProtocolException(message='Required field range is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_range_slices_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    (0, TType.LIST, 'success', (TType.STRUCT,(KeySlice, KeySlice.thrift_spec)), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, success=None, ire=None, ue=None, te=None,):
+    self.success = success
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.LIST:
+          self.success = []
+          (_etype137, _size134) = iprot.readListBegin()
+          for _i138 in xrange(_size134):
+            _elem139 = KeySlice()
+            _elem139.read(iprot)
+            self.success.append(_elem139)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_range_slices_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.LIST, 0)
+      oprot.writeListBegin(TType.STRUCT, len(self.success))
+      for iter140 in self.success:
+        iter140.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_indexed_slices_args:
+  """
+  Attributes:
+   - column_parent
+   - index_clause
+   - column_predicate
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'index_clause', (IndexClause, IndexClause.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'column_predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, column_parent=None, index_clause=None, column_predicate=None, consistency_level=thrift_spec[4][4],):
+    self.column_parent = column_parent
+    self.index_clause = index_clause
+    self.column_predicate = column_predicate
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.index_clause = IndexClause()
+          self.index_clause.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.column_predicate = SlicePredicate()
+          self.column_predicate.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_indexed_slices_args')
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 1)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.index_clause != None:
+      oprot.writeFieldBegin('index_clause', TType.STRUCT, 2)
+      self.index_clause.write(oprot)
+      oprot.writeFieldEnd()
+    if self.column_predicate != None:
+      oprot.writeFieldBegin('column_predicate', TType.STRUCT, 3)
+      self.column_predicate.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.index_clause is None:
+        raise TProtocol.TProtocolException(message='Required field index_clause is unset!')
+      if self.column_predicate is None:
+        raise TProtocol.TProtocolException(message='Required field column_predicate is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class get_indexed_slices_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    (0, TType.LIST, 'success', (TType.STRUCT,(KeySlice, KeySlice.thrift_spec)), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, success=None, ire=None, ue=None, te=None,):
+    self.success = success
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.LIST:
+          self.success = []
+          (_etype144, _size141) = iprot.readListBegin()
+          for _i145 in xrange(_size141):
+            _elem146 = KeySlice()
+            _elem146.read(iprot)
+            self.success.append(_elem146)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('get_indexed_slices_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.LIST, 0)
+      oprot.writeListBegin(TType.STRUCT, len(self.success))
+      for iter147 in self.success:
+        iter147.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class insert_args:
+  """
+  Attributes:
+   - key
+   - column_parent
+   - column
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'column', (Column, Column.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, key=None, column_parent=None, column=None, consistency_level=thrift_spec[4][4],):
+    self.key = key
+    self.column_parent = column_parent
+    self.column = column
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.column = Column()
+          self.column.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('insert_args')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.column != None:
+      oprot.writeFieldBegin('column', TType.STRUCT, 3)
+      self.column.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.column is None:
+        raise TProtocol.TProtocolException(message='Required field column is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class insert_result:
+  """
+  Attributes:
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, ire=None, ue=None, te=None,):
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('insert_result')
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class add_args:
+  """
+  Attributes:
+   - key
+   - column_parent
+   - column
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.STRUCT, 'column_parent', (ColumnParent, ColumnParent.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'column', (CounterColumn, CounterColumn.thrift_spec), None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, key=None, column_parent=None, column=None, consistency_level=thrift_spec[4][4],):
+    self.key = key
+    self.column_parent = column_parent
+    self.column = column
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_parent = ColumnParent()
+          self.column_parent.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.column = CounterColumn()
+          self.column.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('add_args')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.column_parent != None:
+      oprot.writeFieldBegin('column_parent', TType.STRUCT, 2)
+      self.column_parent.write(oprot)
+      oprot.writeFieldEnd()
+    if self.column != None:
+      oprot.writeFieldBegin('column', TType.STRUCT, 3)
+      self.column.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.column_parent is None:
+        raise TProtocol.TProtocolException(message='Required field column_parent is unset!')
+      if self.column is None:
+        raise TProtocol.TProtocolException(message='Required field column is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class add_result:
+  """
+  Attributes:
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, ire=None, ue=None, te=None,):
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('add_result')
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class remove_args:
+  """
+  Attributes:
+   - key
+   - column_path
+   - timestamp
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.STRUCT, 'column_path', (ColumnPath, ColumnPath.thrift_spec), None, ), # 2
+    (3, TType.I64, 'timestamp', None, None, ), # 3
+    (4, TType.I32, 'consistency_level', None,     1, ), # 4
+  )
+
+  def __init__(self, key=None, column_path=None, timestamp=None, consistency_level=thrift_spec[4][4],):
+    self.key = key
+    self.column_path = column_path
+    self.timestamp = timestamp
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.column_path = ColumnPath()
+          self.column_path.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.I64:
+          self.timestamp = iprot.readI64();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('remove_args')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.column_path != None:
+      oprot.writeFieldBegin('column_path', TType.STRUCT, 2)
+      self.column_path.write(oprot)
+      oprot.writeFieldEnd()
+    if self.timestamp != None:
+      oprot.writeFieldBegin('timestamp', TType.I64, 3)
+      oprot.writeI64(self.timestamp)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 4)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.column_path is None:
+        raise TProtocol.TProtocolException(message='Required field column_path is unset!')
+      if self.timestamp is None:
+        raise TProtocol.TProtocolException(message='Required field timestamp is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class remove_result:
+  """
+  Attributes:
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, ire=None, ue=None, te=None,):
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('remove_result')
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class remove_counter_args:
+  """
+  Attributes:
+   - key
+   - path
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.STRUCT, 'path', (ColumnPath, ColumnPath.thrift_spec), None, ), # 2
+    (3, TType.I32, 'consistency_level', None,     1, ), # 3
+  )
+
+  def __init__(self, key=None, path=None, consistency_level=thrift_spec[3][4],):
+    self.key = key
+    self.path = path
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.path = ColumnPath()
+          self.path.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('remove_counter_args')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.path != None:
+      oprot.writeFieldBegin('path', TType.STRUCT, 2)
+      self.path.write(oprot)
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 3)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.path is None:
+        raise TProtocol.TProtocolException(message='Required field path is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class remove_counter_result:
+  """
+  Attributes:
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, ire=None, ue=None, te=None,):
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('remove_counter_result')
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class batch_mutate_args:
+  """
+  Attributes:
+   - mutation_map
+   - consistency_level
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.MAP, 'mutation_map', (TType.STRING,None,TType.MAP,(TType.STRING,None,TType.LIST,(TType.STRUCT,(Mutation, Mutation.thrift_spec)))), None, ), # 1
+    (2, TType.I32, 'consistency_level', None,     1, ), # 2
+  )
+
+  def __init__(self, mutation_map=None, consistency_level=thrift_spec[2][4],):
+    self.mutation_map = mutation_map
+    self.consistency_level = consistency_level
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.MAP:
+          self.mutation_map = {}
+          (_ktype149, _vtype150, _size148 ) = iprot.readMapBegin() 
+          for _i152 in xrange(_size148):
+            _key153 = iprot.readString();
+            _val154 = {}
+            (_ktype156, _vtype157, _size155 ) = iprot.readMapBegin() 
+            for _i159 in xrange(_size155):
+              _key160 = iprot.readString();
+              _val161 = []
+              (_etype165, _size162) = iprot.readListBegin()
+              for _i166 in xrange(_size162):
+                _elem167 = Mutation()
+                _elem167.read(iprot)
+                _val161.append(_elem167)
+              iprot.readListEnd()
+              _val154[_key160] = _val161
+            iprot.readMapEnd()
+            self.mutation_map[_key153] = _val154
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.I32:
+          self.consistency_level = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('batch_mutate_args')
+    if self.mutation_map != None:
+      oprot.writeFieldBegin('mutation_map', TType.MAP, 1)
+      oprot.writeMapBegin(TType.STRING, TType.MAP, len(self.mutation_map))
+      for kiter168,viter169 in self.mutation_map.items():
+        oprot.writeString(kiter168)
+        oprot.writeMapBegin(TType.STRING, TType.LIST, len(viter169))
+        for kiter170,viter171 in viter169.items():
+          oprot.writeString(kiter170)
+          oprot.writeListBegin(TType.STRUCT, len(viter171))
+          for iter172 in viter171:
+            iter172.write(oprot)
+          oprot.writeListEnd()
+        oprot.writeMapEnd()
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    if self.consistency_level != None:
+      oprot.writeFieldBegin('consistency_level', TType.I32, 2)
+      oprot.writeI32(self.consistency_level)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.mutation_map is None:
+        raise TProtocol.TProtocolException(message='Required field mutation_map is unset!')
+      if self.consistency_level is None:
+        raise TProtocol.TProtocolException(message='Required field consistency_level is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class batch_mutate_result:
+  """
+  Attributes:
+   - ire
+   - ue
+   - te
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, ire=None, ue=None, te=None,):
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('batch_mutate_result')
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class truncate_args:
+  """
+  Attributes:
+   - cfname
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'cfname', None, None, ), # 1
+  )
+
+  def __init__(self, cfname=None,):
+    self.cfname = cfname
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.cfname = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('truncate_args')
+    if self.cfname != None:
+      oprot.writeFieldBegin('cfname', TType.STRING, 1)
+      oprot.writeString(self.cfname)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.cfname is None:
+        raise TProtocol.TProtocolException(message='Required field cfname is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class truncate_result:
+  """
+  Attributes:
+   - ire
+   - ue
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, ire=None, ue=None,):
+    self.ire = ire
+    self.ue = ue
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('truncate_result')
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_schema_versions_args:
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_schema_versions_args')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_schema_versions_result:
+  """
+  Attributes:
+   - success
+   - ire
+  """
+
+  thrift_spec = (
+    (0, TType.MAP, 'success', (TType.STRING,None,TType.LIST,(TType.STRING,None)), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, success=None, ire=None,):
+    self.success = success
+    self.ire = ire
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.MAP:
+          self.success = {}
+          (_ktype174, _vtype175, _size173 ) = iprot.readMapBegin() 
+          for _i177 in xrange(_size173):
+            _key178 = iprot.readString();
+            _val179 = []
+            (_etype183, _size180) = iprot.readListBegin()
+            for _i184 in xrange(_size180):
+              _elem185 = iprot.readString();
+              _val179.append(_elem185)
+            iprot.readListEnd()
+            self.success[_key178] = _val179
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_schema_versions_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.MAP, 0)
+      oprot.writeMapBegin(TType.STRING, TType.LIST, len(self.success))
+      for kiter186,viter187 in self.success.items():
+        oprot.writeString(kiter186)
+        oprot.writeListBegin(TType.STRING, len(viter187))
+        for iter188 in viter187:
+          oprot.writeString(iter188)
+        oprot.writeListEnd()
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_keyspaces_args:
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_keyspaces_args')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_keyspaces_result:
+  """
+  Attributes:
+   - success
+   - ire
+  """
+
+  thrift_spec = (
+    (0, TType.LIST, 'success', (TType.STRUCT,(KsDef, KsDef.thrift_spec)), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, success=None, ire=None,):
+    self.success = success
+    self.ire = ire
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.LIST:
+          self.success = []
+          (_etype192, _size189) = iprot.readListBegin()
+          for _i193 in xrange(_size189):
+            _elem194 = KsDef()
+            _elem194.read(iprot)
+            self.success.append(_elem194)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_keyspaces_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.LIST, 0)
+      oprot.writeListBegin(TType.STRUCT, len(self.success))
+      for iter195 in self.success:
+        iter195.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_cluster_name_args:
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_cluster_name_args')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_cluster_name_result:
+  """
+  Attributes:
+   - success
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+  )
+
+  def __init__(self, success=None,):
+    self.success = success
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_cluster_name_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_version_args:
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_version_args')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_version_result:
+  """
+  Attributes:
+   - success
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+  )
+
+  def __init__(self, success=None,):
+    self.success = success
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_version_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_ring_args:
+  """
+  Attributes:
+   - keyspace
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'keyspace', None, None, ), # 1
+  )
+
+  def __init__(self, keyspace=None,):
+    self.keyspace = keyspace
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.keyspace = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_ring_args')
+    if self.keyspace != None:
+      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
+      oprot.writeString(self.keyspace)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.keyspace is None:
+        raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_ring_result:
+  """
+  Attributes:
+   - success
+   - ire
+  """
+
+  thrift_spec = (
+    (0, TType.LIST, 'success', (TType.STRUCT,(TokenRange, TokenRange.thrift_spec)), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, success=None, ire=None,):
+    self.success = success
+    self.ire = ire
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.LIST:
+          self.success = []
+          (_etype199, _size196) = iprot.readListBegin()
+          for _i200 in xrange(_size196):
+            _elem201 = TokenRange()
+            _elem201.read(iprot)
+            self.success.append(_elem201)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_ring_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.LIST, 0)
+      oprot.writeListBegin(TType.STRUCT, len(self.success))
+      for iter202 in self.success:
+        iter202.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_partitioner_args:
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_partitioner_args')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_partitioner_result:
+  """
+  Attributes:
+   - success
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+  )
+
+  def __init__(self, success=None,):
+    self.success = success
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_partitioner_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_snitch_args:
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_snitch_args')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_snitch_result:
+  """
+  Attributes:
+   - success
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+  )
+
+  def __init__(self, success=None,):
+    self.success = success
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_snitch_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_keyspace_args:
+  """
+  Attributes:
+   - keyspace
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'keyspace', None, None, ), # 1
+  )
+
+  def __init__(self, keyspace=None,):
+    self.keyspace = keyspace
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.keyspace = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_keyspace_args')
+    if self.keyspace != None:
+      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
+      oprot.writeString(self.keyspace)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.keyspace is None:
+        raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_keyspace_result:
+  """
+  Attributes:
+   - success
+   - nfe
+   - ire
+  """
+
+  thrift_spec = (
+    (0, TType.STRUCT, 'success', (KsDef, KsDef.thrift_spec), None, ), # 0
+    (1, TType.STRUCT, 'nfe', (NotFoundException, NotFoundException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, success=None, nfe=None, ire=None,):
+    self.success = success
+    self.nfe = nfe
+    self.ire = ire
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRUCT:
+          self.success = KsDef()
+          self.success.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.nfe = NotFoundException()
+          self.nfe.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_keyspace_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRUCT, 0)
+      self.success.write(oprot)
+      oprot.writeFieldEnd()
+    if self.nfe != None:
+      oprot.writeFieldBegin('nfe', TType.STRUCT, 1)
+      self.nfe.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 2)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_splits_args:
+  """
+  Attributes:
+   - cfName
+   - start_token
+   - end_token
+   - keys_per_split
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'cfName', None, None, ), # 1
+    (2, TType.STRING, 'start_token', None, None, ), # 2
+    (3, TType.STRING, 'end_token', None, None, ), # 3
+    (4, TType.I32, 'keys_per_split', None, None, ), # 4
+  )
+
+  def __init__(self, cfName=None, start_token=None, end_token=None, keys_per_split=None,):
+    self.cfName = cfName
+    self.start_token = start_token
+    self.end_token = end_token
+    self.keys_per_split = keys_per_split
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.cfName = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.start_token = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRING:
+          self.end_token = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.keys_per_split = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_splits_args')
+    if self.cfName != None:
+      oprot.writeFieldBegin('cfName', TType.STRING, 1)
+      oprot.writeString(self.cfName)
+      oprot.writeFieldEnd()
+    if self.start_token != None:
+      oprot.writeFieldBegin('start_token', TType.STRING, 2)
+      oprot.writeString(self.start_token)
+      oprot.writeFieldEnd()
+    if self.end_token != None:
+      oprot.writeFieldBegin('end_token', TType.STRING, 3)
+      oprot.writeString(self.end_token)
+      oprot.writeFieldEnd()
+    if self.keys_per_split != None:
+      oprot.writeFieldBegin('keys_per_split', TType.I32, 4)
+      oprot.writeI32(self.keys_per_split)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.cfName is None:
+        raise TProtocol.TProtocolException(message='Required field cfName is unset!')
+      if self.start_token is None:
+        raise TProtocol.TProtocolException(message='Required field start_token is unset!')
+      if self.end_token is None:
+        raise TProtocol.TProtocolException(message='Required field end_token is unset!')
+      if self.keys_per_split is None:
+        raise TProtocol.TProtocolException(message='Required field keys_per_split is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class describe_splits_result:
+  """
+  Attributes:
+   - success
+   - ire
+  """
+
+  thrift_spec = (
+    (0, TType.LIST, 'success', (TType.STRING,None), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, success=None, ire=None,):
+    self.success = success
+    self.ire = ire
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.LIST:
+          self.success = []
+          (_etype206, _size203) = iprot.readListBegin()
+          for _i207 in xrange(_size203):
+            _elem208 = iprot.readString();
+            self.success.append(_elem208)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('describe_splits_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.LIST, 0)
+      oprot.writeListBegin(TType.STRING, len(self.success))
+      for iter209 in self.success:
+        oprot.writeString(iter209)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_add_column_family_args:
+  """
+  Attributes:
+   - cf_def
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'cf_def', (CfDef, CfDef.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, cf_def=None,):
+    self.cf_def = cf_def
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.cf_def = CfDef()
+          self.cf_def.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_add_column_family_args')
+    if self.cf_def != None:
+      oprot.writeFieldBegin('cf_def', TType.STRUCT, 1)
+      self.cf_def.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.cf_def is None:
+        raise TProtocol.TProtocolException(message='Required field cf_def is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_add_column_family_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - sde
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, success=None, ire=None, sde=None,):
+    self.success = success
+    self.ire = ire
+    self.sde = sde
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.sde = SchemaDisagreementException()
+          self.sde.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_add_column_family_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.sde != None:
+      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
+      self.sde.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_drop_column_family_args:
+  """
+  Attributes:
+   - column_family
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'column_family', None, None, ), # 1
+  )
+
+  def __init__(self, column_family=None,):
+    self.column_family = column_family
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.column_family = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_drop_column_family_args')
+    if self.column_family != None:
+      oprot.writeFieldBegin('column_family', TType.STRING, 1)
+      oprot.writeString(self.column_family)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.column_family is None:
+        raise TProtocol.TProtocolException(message='Required field column_family is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_drop_column_family_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - sde
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, success=None, ire=None, sde=None,):
+    self.success = success
+    self.ire = ire
+    self.sde = sde
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.sde = SchemaDisagreementException()
+          self.sde.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_drop_column_family_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.sde != None:
+      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
+      self.sde.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_add_keyspace_args:
+  """
+  Attributes:
+   - ks_def
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ks_def', (KsDef, KsDef.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, ks_def=None,):
+    self.ks_def = ks_def
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ks_def = KsDef()
+          self.ks_def.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_add_keyspace_args')
+    if self.ks_def != None:
+      oprot.writeFieldBegin('ks_def', TType.STRUCT, 1)
+      self.ks_def.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.ks_def is None:
+        raise TProtocol.TProtocolException(message='Required field ks_def is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_add_keyspace_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - sde
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, success=None, ire=None, sde=None,):
+    self.success = success
+    self.ire = ire
+    self.sde = sde
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.sde = SchemaDisagreementException()
+          self.sde.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_add_keyspace_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.sde != None:
+      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
+      self.sde.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_drop_keyspace_args:
+  """
+  Attributes:
+   - keyspace
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'keyspace', None, None, ), # 1
+  )
+
+  def __init__(self, keyspace=None,):
+    self.keyspace = keyspace
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.keyspace = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_drop_keyspace_args')
+    if self.keyspace != None:
+      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
+      oprot.writeString(self.keyspace)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.keyspace is None:
+        raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_drop_keyspace_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - sde
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, success=None, ire=None, sde=None,):
+    self.success = success
+    self.ire = ire
+    self.sde = sde
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.sde = SchemaDisagreementException()
+          self.sde.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_drop_keyspace_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.sde != None:
+      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
+      self.sde.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_update_keyspace_args:
+  """
+  Attributes:
+   - ks_def
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'ks_def', (KsDef, KsDef.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, ks_def=None,):
+    self.ks_def = ks_def
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.ks_def = KsDef()
+          self.ks_def.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_update_keyspace_args')
+    if self.ks_def != None:
+      oprot.writeFieldBegin('ks_def', TType.STRUCT, 1)
+      self.ks_def.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.ks_def is None:
+        raise TProtocol.TProtocolException(message='Required field ks_def is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_update_keyspace_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - sde
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, success=None, ire=None, sde=None,):
+    self.success = success
+    self.ire = ire
+    self.sde = sde
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.sde = SchemaDisagreementException()
+          self.sde.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_update_keyspace_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.sde != None:
+      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
+      self.sde.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_update_column_family_args:
+  """
+  Attributes:
+   - cf_def
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'cf_def', (CfDef, CfDef.thrift_spec), None, ), # 1
+  )
+
+  def __init__(self, cf_def=None,):
+    self.cf_def = cf_def
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.cf_def = CfDef()
+          self.cf_def.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_update_column_family_args')
+    if self.cf_def != None:
+      oprot.writeFieldBegin('cf_def', TType.STRUCT, 1)
+      self.cf_def.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.cf_def is None:
+        raise TProtocol.TProtocolException(message='Required field cf_def is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class system_update_column_family_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - sde
+  """
+
+  thrift_spec = (
+    (0, TType.STRING, 'success', None, None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, success=None, ire=None, sde=None,):
+    self.success = success
+    self.ire = ire
+    self.sde = sde
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRING:
+          self.success = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.sde = SchemaDisagreementException()
+          self.sde.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('system_update_column_family_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRING, 0)
+      oprot.writeString(self.success)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.sde != None:
+      oprot.writeFieldBegin('sde', TType.STRUCT, 2)
+      self.sde.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class execute_cql_query_args:
+  """
+  Attributes:
+   - query
+   - compression
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'query', None, None, ), # 1
+    (2, TType.I32, 'compression', None, None, ), # 2
+  )
+
+  def __init__(self, query=None, compression=None,):
+    self.query = query
+    self.compression = compression
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.query = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.I32:
+          self.compression = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('execute_cql_query_args')
+    if self.query != None:
+      oprot.writeFieldBegin('query', TType.STRING, 1)
+      oprot.writeString(self.query)
+      oprot.writeFieldEnd()
+    if self.compression != None:
+      oprot.writeFieldBegin('compression', TType.I32, 2)
+      oprot.writeI32(self.compression)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.query is None:
+        raise TProtocol.TProtocolException(message='Required field query is unset!')
+      if self.compression is None:
+        raise TProtocol.TProtocolException(message='Required field compression is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class execute_cql_query_result:
+  """
+  Attributes:
+   - success
+   - ire
+   - ue
+   - te
+   - sde
+  """
+
+  thrift_spec = (
+    (0, TType.STRUCT, 'success', (CqlResult, CqlResult.thrift_spec), None, ), # 0
+    (1, TType.STRUCT, 'ire', (InvalidRequestException, InvalidRequestException.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'ue', (UnavailableException, UnavailableException.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'te', (TimedOutException, TimedOutException.thrift_spec), None, ), # 3
+    (4, TType.STRUCT, 'sde', (SchemaDisagreementException, SchemaDisagreementException.thrift_spec), None, ), # 4
+  )
+
+  def __init__(self, success=None, ire=None, ue=None, te=None, sde=None,):
+    self.success = success
+    self.ire = ire
+    self.ue = ue
+    self.te = te
+    self.sde = sde
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 0:
+        if ftype == TType.STRUCT:
+          self.success = CqlResult()
+          self.success.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 1:
+        if ftype == TType.STRUCT:
+          self.ire = InvalidRequestException()
+          self.ire.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.ue = UnavailableException()
+          self.ue.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.te = TimedOutException()
+          self.te.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.STRUCT:
+          self.sde = SchemaDisagreementException()
+          self.sde.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('execute_cql_query_result')
+    if self.success != None:
+      oprot.writeFieldBegin('success', TType.STRUCT, 0)
+      self.success.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ire != None:
+      oprot.writeFieldBegin('ire', TType.STRUCT, 1)
+      self.ire.write(oprot)
+      oprot.writeFieldEnd()
+    if self.ue != None:
+      oprot.writeFieldBegin('ue', TType.STRUCT, 2)
+      self.ue.write(oprot)
+      oprot.writeFieldEnd()
+    if self.te != None:
+      oprot.writeFieldBegin('te', TType.STRUCT, 3)
+      self.te.write(oprot)
+      oprot.writeFieldEnd()
+    if self.sde != None:
+      oprot.writeFieldBegin('sde', TType.STRUCT, 4)
+      self.sde.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
diff --git a/drivers/py/cql/cassandra/__init__.py b/drivers/py/cql/cassandra/__init__.py
new file mode 100644
index 0000000000..2132df03c7
--- /dev/null
+++ b/drivers/py/cql/cassandra/__init__.py
@@ -0,0 +1 @@
+__all__ = ['ttypes', 'constants', 'Cassandra']
diff --git a/drivers/py/cql/cassandra/constants.py b/drivers/py/cql/cassandra/constants.py
new file mode 100644
index 0000000000..ab365a6ddf
--- /dev/null
+++ b/drivers/py/cql/cassandra/constants.py
@@ -0,0 +1,10 @@
+#
+# Autogenerated by Thrift
+#
+# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
+#
+
+from thrift.Thrift import *
+from ttypes import *
+
+VERSION = "19.10.0"
diff --git a/drivers/py/cql/cassandra/ttypes.py b/drivers/py/cql/cassandra/ttypes.py
new file mode 100644
index 0000000000..cc69f46b93
--- /dev/null
+++ b/drivers/py/cql/cassandra/ttypes.py
@@ -0,0 +1,2969 @@
+#
+# Autogenerated by Thrift
+#
+# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
+#
+
+from thrift.Thrift import *
+
+from thrift.transport import TTransport
+from thrift.protocol import TBinaryProtocol, TProtocol
+try:
+  from thrift.protocol import fastbinary
+except:
+  fastbinary = None
+
+
+class ConsistencyLevel:
+  """
+  The ConsistencyLevel is an enum that controls both read and write
+  behavior based on the ReplicationFactor of the keyspace.  The
+  different consistency levels have different meanings, depending on
+  if you're doing a write or read operation.
+
+  If W + R > ReplicationFactor, where W is the number of nodes to
+  block for on write, and R the number to block for on reads, you
+  will have strongly consistent behavior; that is, readers will
+  always see the most recent write. Of these, the most interesting is
+  to do QUORUM reads and writes, which gives you consistency while
+  still allowing availability in the face of node failures up to half
+  of <ReplicationFactor>. Of course if latency is more important than
+  consistency then you can use lower values for either or both.
+
+  Some ConsistencyLevels (ONE, TWO, THREE) refer to a specific number
+  of replicas rather than a logical concept that adjusts
+  automatically with the replication factor.  Of these, only ONE is
+  commonly used; TWO and (even more rarely) THREE are only useful
+  when you care more about guaranteeing a certain level of
+  durability, than consistency.
+
+  Write consistency levels make the following guarantees before reporting success to the client:
+    ANY          Ensure that the write has been written once somewhere, including possibly being hinted in a non-target node.
+    ONE          Ensure that the write has been written to at least 1 node's commit log and memory table
+    TWO          Ensure that the write has been written to at least 2 node's commit log and memory table
+    THREE        Ensure that the write has been written to at least 3 node's commit log and memory table
+    QUORUM       Ensure that the write has been written to <ReplicationFactor> / 2 + 1 nodes
+    LOCAL_QUORUM Ensure that the write has been written to <ReplicationFactor> / 2 + 1 nodes, within the local datacenter (requires NetworkTopologyStrategy)
+    EACH_QUORUM  Ensure that the write has been written to <ReplicationFactor> / 2 + 1 nodes in each datacenter (requires NetworkTopologyStrategy)
+    ALL          Ensure that the write is written to <code>&lt;ReplicationFactor&gt;</code> nodes before responding to the client.
+
+  Read consistency levels make the following guarantees before returning successful results to the client:
+    ANY          Not supported. You probably want ONE instead.
+    ONE          Returns the record obtained from a single replica.
+    TWO          Returns the record with the most recent timestamp once two replicas have replied.
+    THREE        Returns the record with the most recent timestamp once three replicas have replied.
+    QUORUM       Returns the record with the most recent timestamp once a majority of replicas have replied.
+    LOCAL_QUORUM Returns the record with the most recent timestamp once a majority of replicas within the local datacenter have replied.
+    EACH_QUORUM  Returns the record with the most recent timestamp once a majority of replicas within each datacenter have replied.
+    ALL          Returns the record with the most recent timestamp once all replicas have replied (implies no replica may be down)..
+  """
+  ONE = 1
+  QUORUM = 2
+  LOCAL_QUORUM = 3
+  EACH_QUORUM = 4
+  ALL = 5
+  ANY = 6
+  TWO = 7
+  THREE = 8
+
+  _VALUES_TO_NAMES = {
+    1: "ONE",
+    2: "QUORUM",
+    3: "LOCAL_QUORUM",
+    4: "EACH_QUORUM",
+    5: "ALL",
+    6: "ANY",
+    7: "TWO",
+    8: "THREE",
+  }
+
+  _NAMES_TO_VALUES = {
+    "ONE": 1,
+    "QUORUM": 2,
+    "LOCAL_QUORUM": 3,
+    "EACH_QUORUM": 4,
+    "ALL": 5,
+    "ANY": 6,
+    "TWO": 7,
+    "THREE": 8,
+  }
+
+class IndexOperator:
+  EQ = 0
+  GTE = 1
+  GT = 2
+  LTE = 3
+  LT = 4
+
+  _VALUES_TO_NAMES = {
+    0: "EQ",
+    1: "GTE",
+    2: "GT",
+    3: "LTE",
+    4: "LT",
+  }
+
+  _NAMES_TO_VALUES = {
+    "EQ": 0,
+    "GTE": 1,
+    "GT": 2,
+    "LTE": 3,
+    "LT": 4,
+  }
+
+class IndexType:
+  KEYS = 0
+
+  _VALUES_TO_NAMES = {
+    0: "KEYS",
+  }
+
+  _NAMES_TO_VALUES = {
+    "KEYS": 0,
+  }
+
+class Compression:
+  """
+  CQL query compression
+  """
+  GZIP = 1
+  NONE = 2
+
+  _VALUES_TO_NAMES = {
+    1: "GZIP",
+    2: "NONE",
+  }
+
+  _NAMES_TO_VALUES = {
+    "GZIP": 1,
+    "NONE": 2,
+  }
+
+class CqlResultType:
+  ROWS = 1
+  VOID = 2
+  INT = 3
+
+  _VALUES_TO_NAMES = {
+    1: "ROWS",
+    2: "VOID",
+    3: "INT",
+  }
+
+  _NAMES_TO_VALUES = {
+    "ROWS": 1,
+    "VOID": 2,
+    "INT": 3,
+  }
+
+
+class Column:
+  """
+  Basic unit of data within a ColumnFamily.
+  @param name, the name by which this column is set and retrieved.  Maximum 64KB long.
+  @param value. The data associated with the name.  Maximum 2GB long, but in practice you should limit it to small numbers of MB (since Thrift must read the full value into memory to operate on it).
+  @param timestamp. The timestamp is used for conflict detection/resolution when two columns with same name need to be compared.
+  @param ttl. An optional, positive delay (in seconds) after which the column will be automatically deleted.
+
+  Attributes:
+   - name
+   - value
+   - timestamp
+   - ttl
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'name', None, None, ), # 1
+    (2, TType.STRING, 'value', None, None, ), # 2
+    (3, TType.I64, 'timestamp', None, None, ), # 3
+    (4, TType.I32, 'ttl', None, None, ), # 4
+  )
+
+  def __init__(self, name=None, value=None, timestamp=None, ttl=None,):
+    self.name = name
+    self.value = value
+    self.timestamp = timestamp
+    self.ttl = ttl
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.value = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.I64:
+          self.timestamp = iprot.readI64();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.ttl = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('Column')
+    if self.name != None:
+      oprot.writeFieldBegin('name', TType.STRING, 1)
+      oprot.writeString(self.name)
+      oprot.writeFieldEnd()
+    if self.value != None:
+      oprot.writeFieldBegin('value', TType.STRING, 2)
+      oprot.writeString(self.value)
+      oprot.writeFieldEnd()
+    if self.timestamp != None:
+      oprot.writeFieldBegin('timestamp', TType.I64, 3)
+      oprot.writeI64(self.timestamp)
+      oprot.writeFieldEnd()
+    if self.ttl != None:
+      oprot.writeFieldBegin('ttl', TType.I32, 4)
+      oprot.writeI32(self.ttl)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.name is None:
+        raise TProtocol.TProtocolException(message='Required field name is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class SuperColumn:
+  """
+  A named list of columns.
+  @param name. see Column.name.
+  @param columns. A collection of standard Columns.  The columns within a super column are defined in an adhoc manner.
+                  Columns within a super column do not have to have matching structures (similarly named child columns).
+
+  Attributes:
+   - name
+   - columns
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'name', None, None, ), # 1
+    (2, TType.LIST, 'columns', (TType.STRUCT,(Column, Column.thrift_spec)), None, ), # 2
+  )
+
+  def __init__(self, name=None, columns=None,):
+    self.name = name
+    self.columns = columns
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.LIST:
+          self.columns = []
+          (_etype3, _size0) = iprot.readListBegin()
+          for _i4 in xrange(_size0):
+            _elem5 = Column()
+            _elem5.read(iprot)
+            self.columns.append(_elem5)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('SuperColumn')
+    if self.name != None:
+      oprot.writeFieldBegin('name', TType.STRING, 1)
+      oprot.writeString(self.name)
+      oprot.writeFieldEnd()
+    if self.columns != None:
+      oprot.writeFieldBegin('columns', TType.LIST, 2)
+      oprot.writeListBegin(TType.STRUCT, len(self.columns))
+      for iter6 in self.columns:
+        iter6.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.name is None:
+        raise TProtocol.TProtocolException(message='Required field name is unset!')
+      if self.columns is None:
+        raise TProtocol.TProtocolException(message='Required field columns is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class CounterColumn:
+  """
+  Attributes:
+   - name
+   - value
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'name', None, None, ), # 1
+    (2, TType.I64, 'value', None, None, ), # 2
+  )
+
+  def __init__(self, name=None, value=None,):
+    self.name = name
+    self.value = value
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.I64:
+          self.value = iprot.readI64();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('CounterColumn')
+    if self.name != None:
+      oprot.writeFieldBegin('name', TType.STRING, 1)
+      oprot.writeString(self.name)
+      oprot.writeFieldEnd()
+    if self.value != None:
+      oprot.writeFieldBegin('value', TType.I64, 2)
+      oprot.writeI64(self.value)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.name is None:
+        raise TProtocol.TProtocolException(message='Required field name is unset!')
+      if self.value is None:
+        raise TProtocol.TProtocolException(message='Required field value is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class CounterSuperColumn:
+  """
+  Attributes:
+   - name
+   - columns
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'name', None, None, ), # 1
+    (2, TType.LIST, 'columns', (TType.STRUCT,(CounterColumn, CounterColumn.thrift_spec)), None, ), # 2
+  )
+
+  def __init__(self, name=None, columns=None,):
+    self.name = name
+    self.columns = columns
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.LIST:
+          self.columns = []
+          (_etype10, _size7) = iprot.readListBegin()
+          for _i11 in xrange(_size7):
+            _elem12 = CounterColumn()
+            _elem12.read(iprot)
+            self.columns.append(_elem12)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('CounterSuperColumn')
+    if self.name != None:
+      oprot.writeFieldBegin('name', TType.STRING, 1)
+      oprot.writeString(self.name)
+      oprot.writeFieldEnd()
+    if self.columns != None:
+      oprot.writeFieldBegin('columns', TType.LIST, 2)
+      oprot.writeListBegin(TType.STRUCT, len(self.columns))
+      for iter13 in self.columns:
+        iter13.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.name is None:
+        raise TProtocol.TProtocolException(message='Required field name is unset!')
+      if self.columns is None:
+        raise TProtocol.TProtocolException(message='Required field columns is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class ColumnOrSuperColumn:
+  """
+  Methods for fetching rows/records from Cassandra will return either a single instance of ColumnOrSuperColumn or a list
+  of ColumnOrSuperColumns (get_slice()). If you're looking up a SuperColumn (or list of SuperColumns) then the resulting
+  instances of ColumnOrSuperColumn will have the requested SuperColumn in the attribute super_column. For queries resulting
+  in Columns, those values will be in the attribute column. This change was made between 0.3 and 0.4 to standardize on
+  single query methods that may return either a SuperColumn or Column.
+
+  If the query was on a counter column family, you will either get a counter_column (instead of a column) or a
+  counter_super_column (instead of a super_column)
+
+  @param column. The Column returned by get() or get_slice().
+  @param super_column. The SuperColumn returned by get() or get_slice().
+  @param counter_column. The Counterolumn returned by get() or get_slice().
+  @param counter_super_column. The CounterSuperColumn returned by get() or get_slice().
+
+  Attributes:
+   - column
+   - super_column
+   - counter_column
+   - counter_super_column
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'column', (Column, Column.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'super_column', (SuperColumn, SuperColumn.thrift_spec), None, ), # 2
+    (3, TType.STRUCT, 'counter_column', (CounterColumn, CounterColumn.thrift_spec), None, ), # 3
+    (4, TType.STRUCT, 'counter_super_column', (CounterSuperColumn, CounterSuperColumn.thrift_spec), None, ), # 4
+  )
+
+  def __init__(self, column=None, super_column=None, counter_column=None, counter_super_column=None,):
+    self.column = column
+    self.super_column = super_column
+    self.counter_column = counter_column
+    self.counter_super_column = counter_super_column
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.column = Column()
+          self.column.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.super_column = SuperColumn()
+          self.super_column.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.counter_column = CounterColumn()
+          self.counter_column.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.STRUCT:
+          self.counter_super_column = CounterSuperColumn()
+          self.counter_super_column.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('ColumnOrSuperColumn')
+    if self.column != None:
+      oprot.writeFieldBegin('column', TType.STRUCT, 1)
+      self.column.write(oprot)
+      oprot.writeFieldEnd()
+    if self.super_column != None:
+      oprot.writeFieldBegin('super_column', TType.STRUCT, 2)
+      self.super_column.write(oprot)
+      oprot.writeFieldEnd()
+    if self.counter_column != None:
+      oprot.writeFieldBegin('counter_column', TType.STRUCT, 3)
+      self.counter_column.write(oprot)
+      oprot.writeFieldEnd()
+    if self.counter_super_column != None:
+      oprot.writeFieldBegin('counter_super_column', TType.STRUCT, 4)
+      self.counter_super_column.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class NotFoundException(Exception):
+  """
+  A specific column was requested that does not exist.
+  """
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('NotFoundException')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __str__(self):
+    return repr(self)
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class InvalidRequestException(Exception):
+  """
+  Invalid request could mean keyspace or column family does not exist, required parameters are missing, or a parameter is malformed.
+  why contains an associated error message.
+
+  Attributes:
+   - why
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'why', None, None, ), # 1
+  )
+
+  def __init__(self, why=None,):
+    self.why = why
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.why = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('InvalidRequestException')
+    if self.why != None:
+      oprot.writeFieldBegin('why', TType.STRING, 1)
+      oprot.writeString(self.why)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.why is None:
+        raise TProtocol.TProtocolException(message='Required field why is unset!')
+      return
+
+
+  def __str__(self):
+    return repr(self)
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class UnavailableException(Exception):
+  """
+  Not all the replicas required could be created and/or read.
+  """
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('UnavailableException')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __str__(self):
+    return repr(self)
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class TimedOutException(Exception):
+  """
+  RPC timeout was exceeded.  either a node failed mid-operation, or load was too high, or the requested op was too large.
+  """
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('TimedOutException')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __str__(self):
+    return repr(self)
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class AuthenticationException(Exception):
+  """
+  invalid authentication request (invalid keyspace, user does not exist, or credentials invalid)
+
+  Attributes:
+   - why
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'why', None, None, ), # 1
+  )
+
+  def __init__(self, why=None,):
+    self.why = why
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.why = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('AuthenticationException')
+    if self.why != None:
+      oprot.writeFieldBegin('why', TType.STRING, 1)
+      oprot.writeString(self.why)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.why is None:
+        raise TProtocol.TProtocolException(message='Required field why is unset!')
+      return
+
+
+  def __str__(self):
+    return repr(self)
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class AuthorizationException(Exception):
+  """
+  invalid authorization request (user does not have access to keyspace)
+
+  Attributes:
+   - why
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'why', None, None, ), # 1
+  )
+
+  def __init__(self, why=None,):
+    self.why = why
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.why = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('AuthorizationException')
+    if self.why != None:
+      oprot.writeFieldBegin('why', TType.STRING, 1)
+      oprot.writeString(self.why)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.why is None:
+        raise TProtocol.TProtocolException(message='Required field why is unset!')
+      return
+
+
+  def __str__(self):
+    return repr(self)
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class SchemaDisagreementException(Exception):
+  """
+  schemas are not in agreement across all nodes
+  """
+
+  thrift_spec = (
+  )
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('SchemaDisagreementException')
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __str__(self):
+    return repr(self)
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class ColumnParent:
+  """
+  ColumnParent is used when selecting groups of columns from the same ColumnFamily. In directory structure terms, imagine
+  ColumnParent as ColumnPath + '/../'.
+
+  See also <a href="cassandra.html#Struct_ColumnPath">ColumnPath</a>
+
+  Attributes:
+   - column_family
+   - super_column
+  """
+
+  thrift_spec = (
+    None, # 0
+    None, # 1
+    None, # 2
+    (3, TType.STRING, 'column_family', None, None, ), # 3
+    (4, TType.STRING, 'super_column', None, None, ), # 4
+  )
+
+  def __init__(self, column_family=None, super_column=None,):
+    self.column_family = column_family
+    self.super_column = super_column
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 3:
+        if ftype == TType.STRING:
+          self.column_family = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.STRING:
+          self.super_column = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('ColumnParent')
+    if self.column_family != None:
+      oprot.writeFieldBegin('column_family', TType.STRING, 3)
+      oprot.writeString(self.column_family)
+      oprot.writeFieldEnd()
+    if self.super_column != None:
+      oprot.writeFieldBegin('super_column', TType.STRING, 4)
+      oprot.writeString(self.super_column)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.column_family is None:
+        raise TProtocol.TProtocolException(message='Required field column_family is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class ColumnPath:
+  """
+  The ColumnPath is the path to a single column in Cassandra. It might make sense to think of ColumnPath and
+  ColumnParent in terms of a directory structure.
+
+  ColumnPath is used to looking up a single column.
+
+  @param column_family. The name of the CF of the column being looked up.
+  @param super_column. The super column name.
+  @param column. The column name.
+
+  Attributes:
+   - column_family
+   - super_column
+   - column
+  """
+
+  thrift_spec = (
+    None, # 0
+    None, # 1
+    None, # 2
+    (3, TType.STRING, 'column_family', None, None, ), # 3
+    (4, TType.STRING, 'super_column', None, None, ), # 4
+    (5, TType.STRING, 'column', None, None, ), # 5
+  )
+
+  def __init__(self, column_family=None, super_column=None, column=None,):
+    self.column_family = column_family
+    self.super_column = super_column
+    self.column = column
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 3:
+        if ftype == TType.STRING:
+          self.column_family = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.STRING:
+          self.super_column = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 5:
+        if ftype == TType.STRING:
+          self.column = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('ColumnPath')
+    if self.column_family != None:
+      oprot.writeFieldBegin('column_family', TType.STRING, 3)
+      oprot.writeString(self.column_family)
+      oprot.writeFieldEnd()
+    if self.super_column != None:
+      oprot.writeFieldBegin('super_column', TType.STRING, 4)
+      oprot.writeString(self.super_column)
+      oprot.writeFieldEnd()
+    if self.column != None:
+      oprot.writeFieldBegin('column', TType.STRING, 5)
+      oprot.writeString(self.column)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.column_family is None:
+        raise TProtocol.TProtocolException(message='Required field column_family is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class SliceRange:
+  """
+  A slice range is a structure that stores basic range, ordering and limit information for a query that will return
+  multiple columns. It could be thought of as Cassandra's version of LIMIT and ORDER BY
+
+  @param start. The column name to start the slice with. This attribute is not required, though there is no default value,
+                and can be safely set to '', i.e., an empty byte array, to start with the first column name. Otherwise, it
+                must a valid value under the rules of the Comparator defined for the given ColumnFamily.
+  @param finish. The column name to stop the slice at. This attribute is not required, though there is no default value,
+                 and can be safely set to an empty byte array to not stop until 'count' results are seen. Otherwise, it
+                 must also be a valid value to the ColumnFamily Comparator.
+  @param reversed. Whether the results should be ordered in reversed order. Similar to ORDER BY blah DESC in SQL.
+  @param count. How many columns to return. Similar to LIMIT in SQL. May be arbitrarily large, but Thrift will
+                materialize the whole result into memory before returning it to the client, so be aware that you may
+                be better served by iterating through slices by passing the last value of one call in as the 'start'
+                of the next instead of increasing 'count' arbitrarily large.
+
+  Attributes:
+   - start
+   - finish
+   - reversed
+   - count
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'start', None, None, ), # 1
+    (2, TType.STRING, 'finish', None, None, ), # 2
+    (3, TType.BOOL, 'reversed', None, False, ), # 3
+    (4, TType.I32, 'count', None, 100, ), # 4
+  )
+
+  def __init__(self, start=None, finish=None, reversed=thrift_spec[3][4], count=thrift_spec[4][4],):
+    self.start = start
+    self.finish = finish
+    self.reversed = reversed
+    self.count = count
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.start = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.finish = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.BOOL:
+          self.reversed = iprot.readBool();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.count = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('SliceRange')
+    if self.start != None:
+      oprot.writeFieldBegin('start', TType.STRING, 1)
+      oprot.writeString(self.start)
+      oprot.writeFieldEnd()
+    if self.finish != None:
+      oprot.writeFieldBegin('finish', TType.STRING, 2)
+      oprot.writeString(self.finish)
+      oprot.writeFieldEnd()
+    if self.reversed != None:
+      oprot.writeFieldBegin('reversed', TType.BOOL, 3)
+      oprot.writeBool(self.reversed)
+      oprot.writeFieldEnd()
+    if self.count != None:
+      oprot.writeFieldBegin('count', TType.I32, 4)
+      oprot.writeI32(self.count)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.start is None:
+        raise TProtocol.TProtocolException(message='Required field start is unset!')
+      if self.finish is None:
+        raise TProtocol.TProtocolException(message='Required field finish is unset!')
+      if self.reversed is None:
+        raise TProtocol.TProtocolException(message='Required field reversed is unset!')
+      if self.count is None:
+        raise TProtocol.TProtocolException(message='Required field count is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class SlicePredicate:
+  """
+  A SlicePredicate is similar to a mathematic predicate (see http://en.wikipedia.org/wiki/Predicate_(mathematical_logic)),
+  which is described as "a property that the elements of a set have in common."
+
+  SlicePredicate's in Cassandra are described with either a list of column_names or a SliceRange.  If column_names is
+  specified, slice_range is ignored.
+
+  @param column_name. A list of column names to retrieve. This can be used similar to Memcached's "multi-get" feature
+                      to fetch N known column names. For instance, if you know you wish to fetch columns 'Joe', 'Jack',
+                      and 'Jim' you can pass those column names as a list to fetch all three at once.
+  @param slice_range. A SliceRange describing how to range, order, and/or limit the slice.
+
+  Attributes:
+   - column_names
+   - slice_range
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.LIST, 'column_names', (TType.STRING,None), None, ), # 1
+    (2, TType.STRUCT, 'slice_range', (SliceRange, SliceRange.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, column_names=None, slice_range=None,):
+    self.column_names = column_names
+    self.slice_range = slice_range
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.LIST:
+          self.column_names = []
+          (_etype17, _size14) = iprot.readListBegin()
+          for _i18 in xrange(_size14):
+            _elem19 = iprot.readString();
+            self.column_names.append(_elem19)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.slice_range = SliceRange()
+          self.slice_range.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('SlicePredicate')
+    if self.column_names != None:
+      oprot.writeFieldBegin('column_names', TType.LIST, 1)
+      oprot.writeListBegin(TType.STRING, len(self.column_names))
+      for iter20 in self.column_names:
+        oprot.writeString(iter20)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.slice_range != None:
+      oprot.writeFieldBegin('slice_range', TType.STRUCT, 2)
+      self.slice_range.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class IndexExpression:
+  """
+  Attributes:
+   - column_name
+   - op
+   - value
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'column_name', None, None, ), # 1
+    (2, TType.I32, 'op', None, None, ), # 2
+    (3, TType.STRING, 'value', None, None, ), # 3
+  )
+
+  def __init__(self, column_name=None, op=None, value=None,):
+    self.column_name = column_name
+    self.op = op
+    self.value = value
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.column_name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.I32:
+          self.op = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRING:
+          self.value = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('IndexExpression')
+    if self.column_name != None:
+      oprot.writeFieldBegin('column_name', TType.STRING, 1)
+      oprot.writeString(self.column_name)
+      oprot.writeFieldEnd()
+    if self.op != None:
+      oprot.writeFieldBegin('op', TType.I32, 2)
+      oprot.writeI32(self.op)
+      oprot.writeFieldEnd()
+    if self.value != None:
+      oprot.writeFieldBegin('value', TType.STRING, 3)
+      oprot.writeString(self.value)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.column_name is None:
+        raise TProtocol.TProtocolException(message='Required field column_name is unset!')
+      if self.op is None:
+        raise TProtocol.TProtocolException(message='Required field op is unset!')
+      if self.value is None:
+        raise TProtocol.TProtocolException(message='Required field value is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class IndexClause:
+  """
+  Attributes:
+   - expressions
+   - start_key
+   - count
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.LIST, 'expressions', (TType.STRUCT,(IndexExpression, IndexExpression.thrift_spec)), None, ), # 1
+    (2, TType.STRING, 'start_key', None, None, ), # 2
+    (3, TType.I32, 'count', None, 100, ), # 3
+  )
+
+  def __init__(self, expressions=None, start_key=None, count=thrift_spec[3][4],):
+    self.expressions = expressions
+    self.start_key = start_key
+    self.count = count
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.LIST:
+          self.expressions = []
+          (_etype24, _size21) = iprot.readListBegin()
+          for _i25 in xrange(_size21):
+            _elem26 = IndexExpression()
+            _elem26.read(iprot)
+            self.expressions.append(_elem26)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.start_key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.I32:
+          self.count = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('IndexClause')
+    if self.expressions != None:
+      oprot.writeFieldBegin('expressions', TType.LIST, 1)
+      oprot.writeListBegin(TType.STRUCT, len(self.expressions))
+      for iter27 in self.expressions:
+        iter27.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.start_key != None:
+      oprot.writeFieldBegin('start_key', TType.STRING, 2)
+      oprot.writeString(self.start_key)
+      oprot.writeFieldEnd()
+    if self.count != None:
+      oprot.writeFieldBegin('count', TType.I32, 3)
+      oprot.writeI32(self.count)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.expressions is None:
+        raise TProtocol.TProtocolException(message='Required field expressions is unset!')
+      if self.start_key is None:
+        raise TProtocol.TProtocolException(message='Required field start_key is unset!')
+      if self.count is None:
+        raise TProtocol.TProtocolException(message='Required field count is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class KeyRange:
+  """
+  The semantics of start keys and tokens are slightly different.
+  Keys are start-inclusive; tokens are start-exclusive.  Token
+  ranges may also wrap -- that is, the end token may be less
+  than the start one.  Thus, a range from keyX to keyX is a
+  one-element range, but a range from tokenY to tokenY is the
+  full ring.
+
+  Attributes:
+   - start_key
+   - end_key
+   - start_token
+   - end_token
+   - count
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'start_key', None, None, ), # 1
+    (2, TType.STRING, 'end_key', None, None, ), # 2
+    (3, TType.STRING, 'start_token', None, None, ), # 3
+    (4, TType.STRING, 'end_token', None, None, ), # 4
+    (5, TType.I32, 'count', None, 100, ), # 5
+  )
+
+  def __init__(self, start_key=None, end_key=None, start_token=None, end_token=None, count=thrift_spec[5][4],):
+    self.start_key = start_key
+    self.end_key = end_key
+    self.start_token = start_token
+    self.end_token = end_token
+    self.count = count
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.start_key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.end_key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRING:
+          self.start_token = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.STRING:
+          self.end_token = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 5:
+        if ftype == TType.I32:
+          self.count = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('KeyRange')
+    if self.start_key != None:
+      oprot.writeFieldBegin('start_key', TType.STRING, 1)
+      oprot.writeString(self.start_key)
+      oprot.writeFieldEnd()
+    if self.end_key != None:
+      oprot.writeFieldBegin('end_key', TType.STRING, 2)
+      oprot.writeString(self.end_key)
+      oprot.writeFieldEnd()
+    if self.start_token != None:
+      oprot.writeFieldBegin('start_token', TType.STRING, 3)
+      oprot.writeString(self.start_token)
+      oprot.writeFieldEnd()
+    if self.end_token != None:
+      oprot.writeFieldBegin('end_token', TType.STRING, 4)
+      oprot.writeString(self.end_token)
+      oprot.writeFieldEnd()
+    if self.count != None:
+      oprot.writeFieldBegin('count', TType.I32, 5)
+      oprot.writeI32(self.count)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.count is None:
+        raise TProtocol.TProtocolException(message='Required field count is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class KeySlice:
+  """
+  A KeySlice is key followed by the data it maps to. A collection of KeySlice is returned by the get_range_slice operation.
+
+  @param key. a row key
+  @param columns. List of data represented by the key. Typically, the list is pared down to only the columns specified by
+                  a SlicePredicate.
+
+  Attributes:
+   - key
+   - columns
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.LIST, 'columns', (TType.STRUCT,(ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec)), None, ), # 2
+  )
+
+  def __init__(self, key=None, columns=None,):
+    self.key = key
+    self.columns = columns
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.LIST:
+          self.columns = []
+          (_etype31, _size28) = iprot.readListBegin()
+          for _i32 in xrange(_size28):
+            _elem33 = ColumnOrSuperColumn()
+            _elem33.read(iprot)
+            self.columns.append(_elem33)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('KeySlice')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.columns != None:
+      oprot.writeFieldBegin('columns', TType.LIST, 2)
+      oprot.writeListBegin(TType.STRUCT, len(self.columns))
+      for iter34 in self.columns:
+        iter34.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.columns is None:
+        raise TProtocol.TProtocolException(message='Required field columns is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class KeyCount:
+  """
+  Attributes:
+   - key
+   - count
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.I32, 'count', None, None, ), # 2
+  )
+
+  def __init__(self, key=None, count=None,):
+    self.key = key
+    self.count = count
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.I32:
+          self.count = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('KeyCount')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.count != None:
+      oprot.writeFieldBegin('count', TType.I32, 2)
+      oprot.writeI32(self.count)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.count is None:
+        raise TProtocol.TProtocolException(message='Required field count is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class Deletion:
+  """
+  Note that the timestamp is only optional in case of counter deletion.
+
+  Attributes:
+   - timestamp
+   - super_column
+   - predicate
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.I64, 'timestamp', None, None, ), # 1
+    (2, TType.STRING, 'super_column', None, None, ), # 2
+    (3, TType.STRUCT, 'predicate', (SlicePredicate, SlicePredicate.thrift_spec), None, ), # 3
+  )
+
+  def __init__(self, timestamp=None, super_column=None, predicate=None,):
+    self.timestamp = timestamp
+    self.super_column = super_column
+    self.predicate = predicate
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.I64:
+          self.timestamp = iprot.readI64();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.super_column = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRUCT:
+          self.predicate = SlicePredicate()
+          self.predicate.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('Deletion')
+    if self.timestamp != None:
+      oprot.writeFieldBegin('timestamp', TType.I64, 1)
+      oprot.writeI64(self.timestamp)
+      oprot.writeFieldEnd()
+    if self.super_column != None:
+      oprot.writeFieldBegin('super_column', TType.STRING, 2)
+      oprot.writeString(self.super_column)
+      oprot.writeFieldEnd()
+    if self.predicate != None:
+      oprot.writeFieldBegin('predicate', TType.STRUCT, 3)
+      self.predicate.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class Mutation:
+  """
+  A Mutation is either an insert (represented by filling column_or_supercolumn) or a deletion (represented by filling the deletion attribute).
+  @param column_or_supercolumn. An insert to a column or supercolumn (possibly counter column or supercolumn)
+  @param deletion. A deletion of a column or supercolumn
+
+  Attributes:
+   - column_or_supercolumn
+   - deletion
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRUCT, 'column_or_supercolumn', (ColumnOrSuperColumn, ColumnOrSuperColumn.thrift_spec), None, ), # 1
+    (2, TType.STRUCT, 'deletion', (Deletion, Deletion.thrift_spec), None, ), # 2
+  )
+
+  def __init__(self, column_or_supercolumn=None, deletion=None,):
+    self.column_or_supercolumn = column_or_supercolumn
+    self.deletion = deletion
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRUCT:
+          self.column_or_supercolumn = ColumnOrSuperColumn()
+          self.column_or_supercolumn.read(iprot)
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRUCT:
+          self.deletion = Deletion()
+          self.deletion.read(iprot)
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('Mutation')
+    if self.column_or_supercolumn != None:
+      oprot.writeFieldBegin('column_or_supercolumn', TType.STRUCT, 1)
+      self.column_or_supercolumn.write(oprot)
+      oprot.writeFieldEnd()
+    if self.deletion != None:
+      oprot.writeFieldBegin('deletion', TType.STRUCT, 2)
+      self.deletion.write(oprot)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class TokenRange:
+  """
+  Attributes:
+   - start_token
+   - end_token
+   - endpoints
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'start_token', None, None, ), # 1
+    (2, TType.STRING, 'end_token', None, None, ), # 2
+    (3, TType.LIST, 'endpoints', (TType.STRING,None), None, ), # 3
+  )
+
+  def __init__(self, start_token=None, end_token=None, endpoints=None,):
+    self.start_token = start_token
+    self.end_token = end_token
+    self.endpoints = endpoints
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.start_token = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.end_token = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.LIST:
+          self.endpoints = []
+          (_etype38, _size35) = iprot.readListBegin()
+          for _i39 in xrange(_size35):
+            _elem40 = iprot.readString();
+            self.endpoints.append(_elem40)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('TokenRange')
+    if self.start_token != None:
+      oprot.writeFieldBegin('start_token', TType.STRING, 1)
+      oprot.writeString(self.start_token)
+      oprot.writeFieldEnd()
+    if self.end_token != None:
+      oprot.writeFieldBegin('end_token', TType.STRING, 2)
+      oprot.writeString(self.end_token)
+      oprot.writeFieldEnd()
+    if self.endpoints != None:
+      oprot.writeFieldBegin('endpoints', TType.LIST, 3)
+      oprot.writeListBegin(TType.STRING, len(self.endpoints))
+      for iter41 in self.endpoints:
+        oprot.writeString(iter41)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.start_token is None:
+        raise TProtocol.TProtocolException(message='Required field start_token is unset!')
+      if self.end_token is None:
+        raise TProtocol.TProtocolException(message='Required field end_token is unset!')
+      if self.endpoints is None:
+        raise TProtocol.TProtocolException(message='Required field endpoints is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class AuthenticationRequest:
+  """
+  Authentication requests can contain any data, dependent on the IAuthenticator used
+
+  Attributes:
+   - credentials
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.MAP, 'credentials', (TType.STRING,None,TType.STRING,None), None, ), # 1
+  )
+
+  def __init__(self, credentials=None,):
+    self.credentials = credentials
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.MAP:
+          self.credentials = {}
+          (_ktype43, _vtype44, _size42 ) = iprot.readMapBegin() 
+          for _i46 in xrange(_size42):
+            _key47 = iprot.readString();
+            _val48 = iprot.readString();
+            self.credentials[_key47] = _val48
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('AuthenticationRequest')
+    if self.credentials != None:
+      oprot.writeFieldBegin('credentials', TType.MAP, 1)
+      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.credentials))
+      for kiter49,viter50 in self.credentials.items():
+        oprot.writeString(kiter49)
+        oprot.writeString(viter50)
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.credentials is None:
+        raise TProtocol.TProtocolException(message='Required field credentials is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class ColumnDef:
+  """
+  Attributes:
+   - name
+   - validation_class
+   - index_type
+   - index_name
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'name', None, None, ), # 1
+    (2, TType.STRING, 'validation_class', None, None, ), # 2
+    (3, TType.I32, 'index_type', None, None, ), # 3
+    (4, TType.STRING, 'index_name', None, None, ), # 4
+  )
+
+  def __init__(self, name=None, validation_class=None, index_type=None, index_name=None,):
+    self.name = name
+    self.validation_class = validation_class
+    self.index_type = index_type
+    self.index_name = index_name
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.validation_class = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.I32:
+          self.index_type = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.STRING:
+          self.index_name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('ColumnDef')
+    if self.name != None:
+      oprot.writeFieldBegin('name', TType.STRING, 1)
+      oprot.writeString(self.name)
+      oprot.writeFieldEnd()
+    if self.validation_class != None:
+      oprot.writeFieldBegin('validation_class', TType.STRING, 2)
+      oprot.writeString(self.validation_class)
+      oprot.writeFieldEnd()
+    if self.index_type != None:
+      oprot.writeFieldBegin('index_type', TType.I32, 3)
+      oprot.writeI32(self.index_type)
+      oprot.writeFieldEnd()
+    if self.index_name != None:
+      oprot.writeFieldBegin('index_name', TType.STRING, 4)
+      oprot.writeString(self.index_name)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.name is None:
+        raise TProtocol.TProtocolException(message='Required field name is unset!')
+      if self.validation_class is None:
+        raise TProtocol.TProtocolException(message='Required field validation_class is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class CfDef:
+  """
+  Attributes:
+   - keyspace
+   - name
+   - column_type
+   - comparator_type
+   - subcomparator_type
+   - comment
+   - row_cache_size
+   - key_cache_size
+   - read_repair_chance
+   - column_metadata
+   - gc_grace_seconds
+   - default_validation_class
+   - id
+   - min_compaction_threshold
+   - max_compaction_threshold
+   - row_cache_save_period_in_seconds
+   - key_cache_save_period_in_seconds
+   - memtable_flush_after_mins
+   - memtable_throughput_in_mb
+   - memtable_operations_in_millions
+   - replicate_on_write
+   - merge_shards_chance
+   - key_validation_class
+   - row_cache_provider
+   - key_alias
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'keyspace', None, None, ), # 1
+    (2, TType.STRING, 'name', None, None, ), # 2
+    (3, TType.STRING, 'column_type', None, "Standard", ), # 3
+    None, # 4
+    (5, TType.STRING, 'comparator_type', None, "BytesType", ), # 5
+    (6, TType.STRING, 'subcomparator_type', None, None, ), # 6
+    None, # 7
+    (8, TType.STRING, 'comment', None, None, ), # 8
+    (9, TType.DOUBLE, 'row_cache_size', None, 0, ), # 9
+    None, # 10
+    (11, TType.DOUBLE, 'key_cache_size', None, 200000, ), # 11
+    (12, TType.DOUBLE, 'read_repair_chance', None, 1, ), # 12
+    (13, TType.LIST, 'column_metadata', (TType.STRUCT,(ColumnDef, ColumnDef.thrift_spec)), None, ), # 13
+    (14, TType.I32, 'gc_grace_seconds', None, None, ), # 14
+    (15, TType.STRING, 'default_validation_class', None, None, ), # 15
+    (16, TType.I32, 'id', None, None, ), # 16
+    (17, TType.I32, 'min_compaction_threshold', None, None, ), # 17
+    (18, TType.I32, 'max_compaction_threshold', None, None, ), # 18
+    (19, TType.I32, 'row_cache_save_period_in_seconds', None, None, ), # 19
+    (20, TType.I32, 'key_cache_save_period_in_seconds', None, None, ), # 20
+    (21, TType.I32, 'memtable_flush_after_mins', None, None, ), # 21
+    (22, TType.I32, 'memtable_throughput_in_mb', None, None, ), # 22
+    (23, TType.DOUBLE, 'memtable_operations_in_millions', None, None, ), # 23
+    (24, TType.BOOL, 'replicate_on_write', None, None, ), # 24
+    (25, TType.DOUBLE, 'merge_shards_chance', None, None, ), # 25
+    (26, TType.STRING, 'key_validation_class', None, None, ), # 26
+    (27, TType.STRING, 'row_cache_provider', None, "org.apache.cassandra.cache.ConcurrentLinkedHashCacheProvider", ), # 27
+    (28, TType.STRING, 'key_alias', None, None, ), # 28
+  )
+
+  def __init__(self, keyspace=None, name=None, column_type=thrift_spec[3][4], comparator_type=thrift_spec[5][4], subcomparator_type=None, comment=None, row_cache_size=thrift_spec[9][4], key_cache_size=thrift_spec[11][4], read_repair_chance=thrift_spec[12][4], column_metadata=None, gc_grace_seconds=None, default_validation_class=None, id=None, min_compaction_threshold=None, max_compaction_threshold=None, row_cache_save_period_in_seconds=None, key_cache_save_period_in_seconds=None, memtable_flush_after_mins=None, memtable_throughput_in_mb=None, memtable_operations_in_millions=None, replicate_on_write=None, merge_shards_chance=None, key_validation_class=None, row_cache_provider=thrift_spec[27][4], key_alias=None,):
+    self.keyspace = keyspace
+    self.name = name
+    self.column_type = column_type
+    self.comparator_type = comparator_type
+    self.subcomparator_type = subcomparator_type
+    self.comment = comment
+    self.row_cache_size = row_cache_size
+    self.key_cache_size = key_cache_size
+    self.read_repair_chance = read_repair_chance
+    self.column_metadata = column_metadata
+    self.gc_grace_seconds = gc_grace_seconds
+    self.default_validation_class = default_validation_class
+    self.id = id
+    self.min_compaction_threshold = min_compaction_threshold
+    self.max_compaction_threshold = max_compaction_threshold
+    self.row_cache_save_period_in_seconds = row_cache_save_period_in_seconds
+    self.key_cache_save_period_in_seconds = key_cache_save_period_in_seconds
+    self.memtable_flush_after_mins = memtable_flush_after_mins
+    self.memtable_throughput_in_mb = memtable_throughput_in_mb
+    self.memtable_operations_in_millions = memtable_operations_in_millions
+    self.replicate_on_write = replicate_on_write
+    self.merge_shards_chance = merge_shards_chance
+    self.key_validation_class = key_validation_class
+    self.row_cache_provider = row_cache_provider
+    self.key_alias = key_alias
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.keyspace = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.STRING:
+          self.column_type = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 5:
+        if ftype == TType.STRING:
+          self.comparator_type = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 6:
+        if ftype == TType.STRING:
+          self.subcomparator_type = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 8:
+        if ftype == TType.STRING:
+          self.comment = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 9:
+        if ftype == TType.DOUBLE:
+          self.row_cache_size = iprot.readDouble();
+        else:
+          iprot.skip(ftype)
+      elif fid == 11:
+        if ftype == TType.DOUBLE:
+          self.key_cache_size = iprot.readDouble();
+        else:
+          iprot.skip(ftype)
+      elif fid == 12:
+        if ftype == TType.DOUBLE:
+          self.read_repair_chance = iprot.readDouble();
+        else:
+          iprot.skip(ftype)
+      elif fid == 13:
+        if ftype == TType.LIST:
+          self.column_metadata = []
+          (_etype54, _size51) = iprot.readListBegin()
+          for _i55 in xrange(_size51):
+            _elem56 = ColumnDef()
+            _elem56.read(iprot)
+            self.column_metadata.append(_elem56)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 14:
+        if ftype == TType.I32:
+          self.gc_grace_seconds = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 15:
+        if ftype == TType.STRING:
+          self.default_validation_class = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 16:
+        if ftype == TType.I32:
+          self.id = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 17:
+        if ftype == TType.I32:
+          self.min_compaction_threshold = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 18:
+        if ftype == TType.I32:
+          self.max_compaction_threshold = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 19:
+        if ftype == TType.I32:
+          self.row_cache_save_period_in_seconds = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 20:
+        if ftype == TType.I32:
+          self.key_cache_save_period_in_seconds = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 21:
+        if ftype == TType.I32:
+          self.memtable_flush_after_mins = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 22:
+        if ftype == TType.I32:
+          self.memtable_throughput_in_mb = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 23:
+        if ftype == TType.DOUBLE:
+          self.memtable_operations_in_millions = iprot.readDouble();
+        else:
+          iprot.skip(ftype)
+      elif fid == 24:
+        if ftype == TType.BOOL:
+          self.replicate_on_write = iprot.readBool();
+        else:
+          iprot.skip(ftype)
+      elif fid == 25:
+        if ftype == TType.DOUBLE:
+          self.merge_shards_chance = iprot.readDouble();
+        else:
+          iprot.skip(ftype)
+      elif fid == 26:
+        if ftype == TType.STRING:
+          self.key_validation_class = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 27:
+        if ftype == TType.STRING:
+          self.row_cache_provider = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 28:
+        if ftype == TType.STRING:
+          self.key_alias = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('CfDef')
+    if self.keyspace != None:
+      oprot.writeFieldBegin('keyspace', TType.STRING, 1)
+      oprot.writeString(self.keyspace)
+      oprot.writeFieldEnd()
+    if self.name != None:
+      oprot.writeFieldBegin('name', TType.STRING, 2)
+      oprot.writeString(self.name)
+      oprot.writeFieldEnd()
+    if self.column_type != None:
+      oprot.writeFieldBegin('column_type', TType.STRING, 3)
+      oprot.writeString(self.column_type)
+      oprot.writeFieldEnd()
+    if self.comparator_type != None:
+      oprot.writeFieldBegin('comparator_type', TType.STRING, 5)
+      oprot.writeString(self.comparator_type)
+      oprot.writeFieldEnd()
+    if self.subcomparator_type != None:
+      oprot.writeFieldBegin('subcomparator_type', TType.STRING, 6)
+      oprot.writeString(self.subcomparator_type)
+      oprot.writeFieldEnd()
+    if self.comment != None:
+      oprot.writeFieldBegin('comment', TType.STRING, 8)
+      oprot.writeString(self.comment)
+      oprot.writeFieldEnd()
+    if self.row_cache_size != None:
+      oprot.writeFieldBegin('row_cache_size', TType.DOUBLE, 9)
+      oprot.writeDouble(self.row_cache_size)
+      oprot.writeFieldEnd()
+    if self.key_cache_size != None:
+      oprot.writeFieldBegin('key_cache_size', TType.DOUBLE, 11)
+      oprot.writeDouble(self.key_cache_size)
+      oprot.writeFieldEnd()
+    if self.read_repair_chance != None:
+      oprot.writeFieldBegin('read_repair_chance', TType.DOUBLE, 12)
+      oprot.writeDouble(self.read_repair_chance)
+      oprot.writeFieldEnd()
+    if self.column_metadata != None:
+      oprot.writeFieldBegin('column_metadata', TType.LIST, 13)
+      oprot.writeListBegin(TType.STRUCT, len(self.column_metadata))
+      for iter57 in self.column_metadata:
+        iter57.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.gc_grace_seconds != None:
+      oprot.writeFieldBegin('gc_grace_seconds', TType.I32, 14)
+      oprot.writeI32(self.gc_grace_seconds)
+      oprot.writeFieldEnd()
+    if self.default_validation_class != None:
+      oprot.writeFieldBegin('default_validation_class', TType.STRING, 15)
+      oprot.writeString(self.default_validation_class)
+      oprot.writeFieldEnd()
+    if self.id != None:
+      oprot.writeFieldBegin('id', TType.I32, 16)
+      oprot.writeI32(self.id)
+      oprot.writeFieldEnd()
+    if self.min_compaction_threshold != None:
+      oprot.writeFieldBegin('min_compaction_threshold', TType.I32, 17)
+      oprot.writeI32(self.min_compaction_threshold)
+      oprot.writeFieldEnd()
+    if self.max_compaction_threshold != None:
+      oprot.writeFieldBegin('max_compaction_threshold', TType.I32, 18)
+      oprot.writeI32(self.max_compaction_threshold)
+      oprot.writeFieldEnd()
+    if self.row_cache_save_period_in_seconds != None:
+      oprot.writeFieldBegin('row_cache_save_period_in_seconds', TType.I32, 19)
+      oprot.writeI32(self.row_cache_save_period_in_seconds)
+      oprot.writeFieldEnd()
+    if self.key_cache_save_period_in_seconds != None:
+      oprot.writeFieldBegin('key_cache_save_period_in_seconds', TType.I32, 20)
+      oprot.writeI32(self.key_cache_save_period_in_seconds)
+      oprot.writeFieldEnd()
+    if self.memtable_flush_after_mins != None:
+      oprot.writeFieldBegin('memtable_flush_after_mins', TType.I32, 21)
+      oprot.writeI32(self.memtable_flush_after_mins)
+      oprot.writeFieldEnd()
+    if self.memtable_throughput_in_mb != None:
+      oprot.writeFieldBegin('memtable_throughput_in_mb', TType.I32, 22)
+      oprot.writeI32(self.memtable_throughput_in_mb)
+      oprot.writeFieldEnd()
+    if self.memtable_operations_in_millions != None:
+      oprot.writeFieldBegin('memtable_operations_in_millions', TType.DOUBLE, 23)
+      oprot.writeDouble(self.memtable_operations_in_millions)
+      oprot.writeFieldEnd()
+    if self.replicate_on_write != None:
+      oprot.writeFieldBegin('replicate_on_write', TType.BOOL, 24)
+      oprot.writeBool(self.replicate_on_write)
+      oprot.writeFieldEnd()
+    if self.merge_shards_chance != None:
+      oprot.writeFieldBegin('merge_shards_chance', TType.DOUBLE, 25)
+      oprot.writeDouble(self.merge_shards_chance)
+      oprot.writeFieldEnd()
+    if self.key_validation_class != None:
+      oprot.writeFieldBegin('key_validation_class', TType.STRING, 26)
+      oprot.writeString(self.key_validation_class)
+      oprot.writeFieldEnd()
+    if self.row_cache_provider != None:
+      oprot.writeFieldBegin('row_cache_provider', TType.STRING, 27)
+      oprot.writeString(self.row_cache_provider)
+      oprot.writeFieldEnd()
+    if self.key_alias != None:
+      oprot.writeFieldBegin('key_alias', TType.STRING, 28)
+      oprot.writeString(self.key_alias)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.keyspace is None:
+        raise TProtocol.TProtocolException(message='Required field keyspace is unset!')
+      if self.name is None:
+        raise TProtocol.TProtocolException(message='Required field name is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class KsDef:
+  """
+  Attributes:
+   - name
+   - strategy_class
+   - strategy_options
+   - replication_factor: deprecated
+   - cf_defs
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'name', None, None, ), # 1
+    (2, TType.STRING, 'strategy_class', None, None, ), # 2
+    (3, TType.MAP, 'strategy_options', (TType.STRING,None,TType.STRING,None), None, ), # 3
+    (4, TType.I32, 'replication_factor', None, None, ), # 4
+    (5, TType.LIST, 'cf_defs', (TType.STRUCT,(CfDef, CfDef.thrift_spec)), None, ), # 5
+  )
+
+  def __init__(self, name=None, strategy_class=None, strategy_options=None, replication_factor=None, cf_defs=None,):
+    self.name = name
+    self.strategy_class = strategy_class
+    self.strategy_options = strategy_options
+    self.replication_factor = replication_factor
+    self.cf_defs = cf_defs
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.name = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.STRING:
+          self.strategy_class = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.MAP:
+          self.strategy_options = {}
+          (_ktype59, _vtype60, _size58 ) = iprot.readMapBegin() 
+          for _i62 in xrange(_size58):
+            _key63 = iprot.readString();
+            _val64 = iprot.readString();
+            self.strategy_options[_key63] = _val64
+          iprot.readMapEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 4:
+        if ftype == TType.I32:
+          self.replication_factor = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 5:
+        if ftype == TType.LIST:
+          self.cf_defs = []
+          (_etype68, _size65) = iprot.readListBegin()
+          for _i69 in xrange(_size65):
+            _elem70 = CfDef()
+            _elem70.read(iprot)
+            self.cf_defs.append(_elem70)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('KsDef')
+    if self.name != None:
+      oprot.writeFieldBegin('name', TType.STRING, 1)
+      oprot.writeString(self.name)
+      oprot.writeFieldEnd()
+    if self.strategy_class != None:
+      oprot.writeFieldBegin('strategy_class', TType.STRING, 2)
+      oprot.writeString(self.strategy_class)
+      oprot.writeFieldEnd()
+    if self.strategy_options != None:
+      oprot.writeFieldBegin('strategy_options', TType.MAP, 3)
+      oprot.writeMapBegin(TType.STRING, TType.STRING, len(self.strategy_options))
+      for kiter71,viter72 in self.strategy_options.items():
+        oprot.writeString(kiter71)
+        oprot.writeString(viter72)
+      oprot.writeMapEnd()
+      oprot.writeFieldEnd()
+    if self.replication_factor != None:
+      oprot.writeFieldBegin('replication_factor', TType.I32, 4)
+      oprot.writeI32(self.replication_factor)
+      oprot.writeFieldEnd()
+    if self.cf_defs != None:
+      oprot.writeFieldBegin('cf_defs', TType.LIST, 5)
+      oprot.writeListBegin(TType.STRUCT, len(self.cf_defs))
+      for iter73 in self.cf_defs:
+        iter73.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.name is None:
+        raise TProtocol.TProtocolException(message='Required field name is unset!')
+      if self.strategy_class is None:
+        raise TProtocol.TProtocolException(message='Required field strategy_class is unset!')
+      if self.cf_defs is None:
+        raise TProtocol.TProtocolException(message='Required field cf_defs is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class CqlRow:
+  """
+  Row returned from a CQL query
+
+  Attributes:
+   - key
+   - columns
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.STRING, 'key', None, None, ), # 1
+    (2, TType.LIST, 'columns', (TType.STRUCT,(Column, Column.thrift_spec)), None, ), # 2
+  )
+
+  def __init__(self, key=None, columns=None,):
+    self.key = key
+    self.columns = columns
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.STRING:
+          self.key = iprot.readString();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.LIST:
+          self.columns = []
+          (_etype77, _size74) = iprot.readListBegin()
+          for _i78 in xrange(_size74):
+            _elem79 = Column()
+            _elem79.read(iprot)
+            self.columns.append(_elem79)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('CqlRow')
+    if self.key != None:
+      oprot.writeFieldBegin('key', TType.STRING, 1)
+      oprot.writeString(self.key)
+      oprot.writeFieldEnd()
+    if self.columns != None:
+      oprot.writeFieldBegin('columns', TType.LIST, 2)
+      oprot.writeListBegin(TType.STRUCT, len(self.columns))
+      for iter80 in self.columns:
+        iter80.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.key is None:
+        raise TProtocol.TProtocolException(message='Required field key is unset!')
+      if self.columns is None:
+        raise TProtocol.TProtocolException(message='Required field columns is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
+
+class CqlResult:
+  """
+  Attributes:
+   - type
+   - rows
+   - num
+  """
+
+  thrift_spec = (
+    None, # 0
+    (1, TType.I32, 'type', None, None, ), # 1
+    (2, TType.LIST, 'rows', (TType.STRUCT,(CqlRow, CqlRow.thrift_spec)), None, ), # 2
+    (3, TType.I32, 'num', None, None, ), # 3
+  )
+
+  def __init__(self, type=None, rows=None, num=None,):
+    self.type = type
+    self.rows = rows
+    self.num = num
+
+  def read(self, iprot):
+    if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
+      fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
+      return
+    iprot.readStructBegin()
+    while True:
+      (fname, ftype, fid) = iprot.readFieldBegin()
+      if ftype == TType.STOP:
+        break
+      if fid == 1:
+        if ftype == TType.I32:
+          self.type = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      elif fid == 2:
+        if ftype == TType.LIST:
+          self.rows = []
+          (_etype84, _size81) = iprot.readListBegin()
+          for _i85 in xrange(_size81):
+            _elem86 = CqlRow()
+            _elem86.read(iprot)
+            self.rows.append(_elem86)
+          iprot.readListEnd()
+        else:
+          iprot.skip(ftype)
+      elif fid == 3:
+        if ftype == TType.I32:
+          self.num = iprot.readI32();
+        else:
+          iprot.skip(ftype)
+      else:
+        iprot.skip(ftype)
+      iprot.readFieldEnd()
+    iprot.readStructEnd()
+
+  def write(self, oprot):
+    if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
+      oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
+      return
+    oprot.writeStructBegin('CqlResult')
+    if self.type != None:
+      oprot.writeFieldBegin('type', TType.I32, 1)
+      oprot.writeI32(self.type)
+      oprot.writeFieldEnd()
+    if self.rows != None:
+      oprot.writeFieldBegin('rows', TType.LIST, 2)
+      oprot.writeListBegin(TType.STRUCT, len(self.rows))
+      for iter87 in self.rows:
+        iter87.write(oprot)
+      oprot.writeListEnd()
+      oprot.writeFieldEnd()
+    if self.num != None:
+      oprot.writeFieldBegin('num', TType.I32, 3)
+      oprot.writeI32(self.num)
+      oprot.writeFieldEnd()
+    oprot.writeFieldStop()
+    oprot.writeStructEnd()
+    def validate(self):
+      if self.type is None:
+        raise TProtocol.TProtocolException(message='Required field type is unset!')
+      return
+
+
+  def __repr__(self):
+    L = ['%s=%r' % (key, value)
+      for key, value in self.__dict__.iteritems()]
+    return '%s(%s)' % (self.__class__.__name__, ', '.join(L))
+
+  def __eq__(self, other):
+    return isinstance(other, self.__class__) and self.__dict__ == other.__dict__
+
+  def __ne__(self, other):
+    return not (self == other)
diff --git a/drivers/py/cql/connection.py b/drivers/py/cql/connection.py
new file mode 100644
index 0000000000..702dcec09c
--- /dev/null
+++ b/drivers/py/cql/connection.py
@@ -0,0 +1,85 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from cursor import Cursor
+from cassandra import Cassandra
+from thrift.transport import TTransport, TSocket
+from thrift.protocol import TBinaryProtocol
+from cql.cassandra.ttypes import AuthenticationRequest
+
+
+class Connection(object):
+    def __init__(self, host, port, keyspace, user=None, password=None):
+        """
+        Params:
+        * host .........: hostname of Cassandra node.
+        * port .........: port number to connect to.
+        * keyspace .....: keyspace to connect to.
+        * user .........: username used in authentication (optional).
+        * password .....: password used in authentication (optional).
+        """
+        self.host = host
+        self.port = port
+        self.keyspace = keyspace
+
+        socket = TSocket.TSocket(host, port)
+        self.transport = TTransport.TFramedTransport(socket)
+        protocol = TBinaryProtocol.TBinaryProtocolAccelerated(self.transport)
+        self.client = Cassandra.Client(protocol)
+
+        socket.open()
+        self.open_socket = True
+
+        if user and password:
+            credentials = {"username": user, "password": password}
+            self.client.login(AuthenticationRequest(credentials=credentials))
+
+        if keyspace:
+            c = self.cursor()
+            c.execute('USE %s;' % keyspace)
+            c.close()
+
+    def __str__(self):
+        return "{host: '%s:%s', keyspace: '%s'}"%(self.host,self.port,self.keyspace)
+
+    ###
+    # Connection API
+    ###
+
+    def close(self):
+        if not self.open_socket:
+            return
+
+        self.transport.close()
+        self.open_socket = False
+
+    def commit(self):
+        """
+        'Database modules that do not support transactions should
+          implement this method with void functionality.'
+        """
+        return
+
+    def rollback(self):
+        from cql import NotSupportedError
+        raise NotSupportedError("Rollback functionality not present in Cassandra.")
+
+    def cursor(self):
+        from cql import ProgrammingError
+        if not self.open_socket:
+            raise ProgrammingError("Connection has been closed.")
+        return Cursor(self)
diff --git a/drivers/py/cql/connection_pool.py b/drivers/py/cql/connection_pool.py
new file mode 100644
index 0000000000..a5a31ee056
--- /dev/null
+++ b/drivers/py/cql/connection_pool.py
@@ -0,0 +1,104 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from Queue import Queue, Empty
+from threading import Thread
+from time import sleep
+from connection import Connection
+
+__all__ = ['ConnectionPool']
+
+class ConnectionPool(object):
+    """
+    Simple connection-caching pool implementation.
+
+    ConnectionPool provides the simplest possible connection pooling,
+    lazily creating new connections if needed as `borrow_connection' is
+    called.  Connections are re-added to the pool by `return_connection',
+    unless doing so would exceed the maximum pool size.
+    
+    Example usage:
+    >>> pool = ConnectionPool("localhost", 9160, "Keyspace1")
+    >>> conn = pool.borrow_connection()
+    >>> conn.execute(...)
+    >>> pool.return_connection(conn)
+    """
+    def __init__(self, hostname, port=9160, keyspace=None, username=None,
+                 password=None, decoder=None, max_conns=25, max_idle=5,
+                 eviction_delay=10000):
+        self.hostname = hostname
+        self.port = port
+        self.keyspace = keyspace
+        self.username = username
+        self.password = password
+        self.decoder = decoder
+        self.max_conns = max_conns
+        self.max_idle = max_idle
+        self.eviction_delay = eviction_delay
+        
+        self.connections = Queue()
+        self.connections.put(self.__create_connection())
+        self.eviction = Eviction(self.connections,
+                                 self.max_idle,
+                                 self.eviction_delay)
+    
+    def __create_connection(self):
+        return Connection(self.hostname,
+                          port=self.port,
+                          keyspace=self.keyspace,
+                          username=self.username,
+                          password=self.password,
+                          decoder=self.decoder)
+        
+    def borrow_connection(self):
+        try:
+            connection = self.connections.get(block=False)
+        except Empty:
+            connection = self.__create_connection()
+        return connection
+    
+    def return_connection(self, connection):
+        if self.connections.qsize() > self.max_conns:
+            connection.close()
+            return
+        if not connection.is_open():
+            return
+        self.connections.put(connection)
+
+class Eviction(Thread):
+    def __init__(self, connections, max_idle, eviction_delay):
+        Thread.__init__(self)
+        
+        self.connections = connections
+        self.max_idle = max_idle
+        self.eviction_delay = eviction_delay
+        
+        self.setDaemon(True)
+        self.setName("EVICTION-THREAD")
+        self.start()
+        
+    def run(self):
+        while(True):
+            while(self.connections.qsize() > self.max_idle):
+                connection = self.connections.get(block=False)
+                if connection:
+                    if connection.is_open():
+                        connection.close()
+            sleep(self.eviction_delay/1000)
+        
+        
+        
diff --git a/drivers/py/cql/cursor.py b/drivers/py/cql/cursor.py
new file mode 100644
index 0000000000..0b8b22aa67
--- /dev/null
+++ b/drivers/py/cql/cursor.py
@@ -0,0 +1,254 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import re
+import zlib
+
+import cql
+from cql.marshal import prepare
+from cql.decoders import SchemaDecoder
+from cql.cassandra.ttypes import (
+    Compression, 
+    CqlResultType, 
+    InvalidRequestException,
+    UnavailableException,
+    TimedOutException,
+    TApplicationException,
+    SchemaDisagreementException)
+
+_COUNT_DESCRIPTION = (None, None, None, None, None, None, None)
+_VOID_DESCRIPTION = (None)
+
+class Cursor:
+    _keyspace_re = re.compile("USE (\w+);?",
+                              re.IGNORECASE | re.MULTILINE)
+    _cfamily_re = re.compile("\s*SELECT\s+.+?\s+FROM\s+[\']?(\w+)",
+                             re.IGNORECASE | re.MULTILINE | re.DOTALL)
+    _ddl_re = re.compile("\s*(CREATE|ALTER|DROP)\s+",
+                         re.IGNORECASE | re.MULTILINE)
+
+    def __init__(self, parent_connection):
+        self.open_socket = True
+        self._connection = parent_connection
+
+        self.description = None # A list of 7-tuples: 
+                                #  (column_name, type_code, none, none,
+                                #   none, none, nulls_ok=True)
+                                # Populate on execute()
+
+        self.arraysize = 1
+        self.rowcount = -1      # Populate on execute()
+        self.compression = 'GZIP'
+
+        self._query_ks = self._connection.keyspace
+        self._query_cf = None
+        self.decoder = SchemaDecoder(self.__get_schema())
+
+    ###
+    # Cursor API
+    ###
+
+    def close(self):
+        self.open_socket = False
+
+    def prepare(self, query, params):
+        prepared_query = prepare(query, params)
+        self._schema_update_needed = False
+
+        # Snag the keyspace or column family and stash it for later use in
+        # decoding columns.  These regexes don't match every query, but the
+        # current column family only needs to be current for SELECTs.
+        match = Cursor._cfamily_re.match(prepared_query)
+        if match:
+            self._query_cf = match.group(1)
+            return prepared_query
+        match = Cursor._keyspace_re.match(prepared_query)
+        if match:
+            self._query_ks = match.group(1)
+            return prepared_query
+
+        # If this is a CREATE, then refresh the schema for decoding purposes.
+        match = Cursor._ddl_re.match(prepared_query)
+        if match:
+            self._schema_update_needed = True
+        return prepared_query
+
+    def __get_schema(self):
+        def columns(metadata):
+            results = {}
+            for col in metadata:
+                results[col.name] = col.validation_class
+            return results
+
+        def column_families(cf_defs):
+            d = {}
+            for cf in cf_defs:
+                d[cf.name] = {'comparator': cf.comparator_type,
+                              'default_validation_class': cf.default_validation_class,
+                              'key_validation_class': cf.key_validation_class,
+                              'columns': columns(cf.column_metadata),
+                              'key_alias': cf.key_alias}
+            return d
+
+        schema = {}
+        client = self._connection.client
+        for ksdef in client.describe_keyspaces():
+            schema[ksdef.name] = column_families(ksdef.cf_defs)
+        return schema
+
+    def execute(self, cql_query, params={}):
+        self.__checksock()
+        self.rs_idx = 0
+        self.rowcount = 0
+        self.description = None
+        try:
+            prepared_q = self.prepare(cql_query, params)
+        except KeyError, e:
+            raise cql.ProgrammingError("Unmatched named substitution: " +
+                                       "%s not given for %s" % (e, cql_query))
+
+        if self.compression == 'GZIP':
+            compressed_q = zlib.compress(prepared_q)
+        else:
+            compressed_q = prepared_q
+        request_compression = getattr(Compression, self.compression)
+
+        try:
+            client = self._connection.client
+            response = client.execute_cql_query(compressed_q, request_compression)
+        except InvalidRequestException, ire:
+            raise cql.ProgrammingError("Bad Request: %s" % ire.why)
+        except SchemaDisagreementException, sde:
+            raise cql.IntegrityError("Schema versions disagree, (try again later).")
+        except UnavailableException:
+            raise cql.OperationalError("Unable to complete request: one or "
+                                       "more nodes were unavailable.")
+        except TimedOutException:
+            raise cql.OperationalError("Request did not complete within rpc_timeout.")
+        except TApplicationException, tapp:
+            raise cql.InternalError("Internal application error")
+
+        if self._schema_update_needed and isinstance(self.decoder, SchemaDecoder):
+            self.decoder.schema = self.__get_schema()
+
+        if response.type == CqlResultType.ROWS:
+            self.result = response.rows
+            self.rs_idx = 0
+            self.rowcount = len(self.result)
+            if self.result:
+                self.description = self.decoder.decode_description(self._query_ks, self._query_cf, self.result[0])
+        elif response.type == CqlResultType.INT:
+            self.result = [(response.num,)]
+            self.rs_idx = 0
+            self.rowcount = 1
+            # TODO: name could be the COUNT expression
+            self.description = _COUNT_DESCRIPTION
+        elif response.type == CqlResultType.VOID:
+            self.result = []
+            self.rs_idx = 0
+            self.rowcount = 0
+            self.description = _VOID_DESCRIPTION
+        else:
+            raise Exception('unknown result type ' + response.type)
+
+        # 'Return values are not defined.'
+        return True
+
+    def executemany(self, operation_list, argslist):
+        self.__checksock()
+        opssize = len(operation_list)
+        argsize = len(argslist)
+
+        if opssize > argsize:
+            raise cql.InterfaceError("Operations outnumber args for executemany().")
+        elif opssize < argsize:
+            raise cql.InterfaceError("Args outnumber operations for executemany().")
+
+        for idx in xrange(opssize):
+            self.execute(operation_list[idx], *argslist[idx])
+
+    def fetchone(self):
+        self.__checksock()
+        if self.rs_idx == len(self.result):
+            return None
+
+        row = self.result[self.rs_idx]
+        self.rs_idx += 1
+        if self.description == _COUNT_DESCRIPTION:
+            return row
+        else:
+            self.description = self.decoder.decode_description(self._query_ks, self._query_cf, row)
+            return self.decoder.decode_row(self._query_ks, self._query_cf, row)
+
+    def fetchmany(self, size=None):
+        self.__checksock()
+        if size is None:
+            size = self.arraysize
+        # we avoid leveraging fetchone here to avoid calling decode_description unnecessarily
+        L = []
+        while len(L) < size and self.rs_idx < len(self.result):
+            row = self.result[self.rs_idx]
+            self.rs_idx += 1
+            L.append(self.decoder.decode_row(self._query_ks, self._query_cf, row))
+        return L
+
+    def fetchall(self):
+        return self.fetchmany(len(self.result) - self.rs_idx)
+
+    ###
+    # extra, for cqlsh
+    ###
+    
+    def _reset(self):
+        self.rs_idx = 0
+
+    ###
+    # Iterator extension
+    ###
+
+    def next(self):
+        if self.rs_idx >= len(self.result):
+            raise StopIteration
+        return self.fetchone()
+
+    def __iter__(self):
+        return self
+
+    ###
+    # Unsupported, unimplemented optionally
+    ###
+
+    def setinputsizes(self, sizes):
+        pass # DO NOTHING
+
+    def setoutputsize(self, size, *columns):
+        pass # DO NOTHING
+
+    def callproc(self, procname, *args):
+        raise cql.NotSupportedError()
+
+    def nextset(self):
+        raise cql.NotSupportedError()
+
+    ###
+    # Helpers
+    ###
+
+    def __checksock(self):
+        if not self.open_socket:
+            raise cql.InternalError("Cursor belonging to %s has been closed." %
+                                    (self._connection, ))
diff --git a/drivers/py/cql/decoders.py b/drivers/py/cql/decoders.py
new file mode 100644
index 0000000000..b0adc1eaa4
--- /dev/null
+++ b/drivers/py/cql/decoders.py
@@ -0,0 +1,68 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import cql
+from marshal import (unmarshallers, unmarshal_noop)
+
+class SchemaDecoder(object):
+    """
+    Decode binary column names/values according to schema.
+    """
+    def __init__(self, schema={}):
+        self.schema = schema
+
+    def __get_column_family_def(self, keyspace, column_family):
+        if keyspace in self.schema and column_family in self.schema[keyspace]:
+            return self.schema[keyspace][column_family]
+        return None
+
+    def __comparator_for(self, keyspace, column_family):
+        cfam = self.__get_column_family_def(keyspace, column_family)
+        return cfam.get("comparator", None)
+
+    def decode_description(self, keyspace, column_family, row):
+        description = []
+        comparator = self.__comparator_for(keyspace, column_family)
+        unmarshal = unmarshallers.get(comparator, unmarshal_noop)
+        for column in row.columns:
+            if column.name == self.__get_column_family_def(keyspace, column_family)['key_alias']:
+                description.append((column.name, 'text', None, None, None, None, True))
+            else:
+                description.append((unmarshal(column.name), comparator, None, None, None, None, True))
+        return description
+
+    def decode_row(self, keyspace, column_family, row):
+        cfdef = self.__get_column_family_def(keyspace, column_family)
+        key_alias = cfdef['key_alias']
+        validators = cfdef['columns']
+        default_validator = cfdef['default_validation_class']
+        key_validator = cfdef.get("key_validation_class", None)
+
+        values = []
+        for column in row.columns:
+            name = column.name
+            if column.value is None:
+                values.append(None)
+                continue
+
+            if name == key_alias:
+                validator = key_validator
+            else:
+                validator = validators.get(name, default_validator)
+            values.append(unmarshallers.get(validator, unmarshal_noop)(column.value))
+
+        return values
diff --git a/drivers/py/cql/errors.py b/drivers/py/cql/errors.py
new file mode 100644
index 0000000000..fa87cd26c5
--- /dev/null
+++ b/drivers/py/cql/errors.py
@@ -0,0 +1,21 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+__all__ = ['InvalidCompressionScheme', 'InvalidQueryFormat']
+
+class InvalidCompressionScheme(Exception): pass
+class InvalidQueryFormat(Exception): pass
diff --git a/drivers/py/cql/marshal.py b/drivers/py/cql/marshal.py
new file mode 100644
index 0000000000..6e58c5bea9
--- /dev/null
+++ b/drivers/py/cql/marshal.py
@@ -0,0 +1,98 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import re
+import struct
+from uuid import UUID
+
+import cql
+
+__all__ = ['prepare', 'marshal', 'unmarshal_noop', 'unmarshallers']
+
+if hasattr(struct, 'Struct'): # new in Python 2.5
+   _have_struct = True
+   _long_packer = struct.Struct('>q')
+else:
+    _have_struct = False
+
+_param_re = re.compile(r"(?<!strategy_options)(?<!\\)(:[a-zA-Z_][a-zA-Z0-9_]*)", re.M)
+
+BYTES_TYPE = "org.apache.cassandra.db.marshal.BytesType"
+ASCII_TYPE = "org.apache.cassandra.db.marshal.AsciiType"
+UTF8_TYPE = "org.apache.cassandra.db.marshal.UTF8Type"
+INTEGER_TYPE = "org.apache.cassandra.db.marshal.IntegerType"
+LONG_TYPE = "org.apache.cassandra.db.marshal.LongType"
+UUID_TYPE = "org.apache.cassandra.db.marshal.UUIDType"
+LEXICAL_UUID_TYPE = "org.apache.cassandra.db.marshal.LexicalType"
+TIME_UUID_TYPE = "org.apache.cassandra.db.marshal.TimeUUIDType"
+COUNTER_COLUMN_TYPE = "org.apache.cassandra.db.marshal.CounterColumnType"
+
+def prepare(query, params):
+    # For every match of the form ":param_name", call marshal
+    # on kwargs['param_name'] and replace that section of the query
+    # with the result
+    new, count = re.subn(_param_re, lambda m: marshal(params[m.group(1)[1:]]), query)
+    if len(params) > count:
+        raise cql.ProgrammingError("More keywords were provided than parameters")
+    return new.replace("\:", ":")
+
+def marshal(term):
+    if isinstance(term, unicode):
+        return "'%s'" % __escape_quotes(term.encode('utf8'))
+    elif isinstance(term, str):
+        return "'%s'" % __escape_quotes(term)
+    else:
+        return str(term)
+
+def unmarshal_noop(bytestr):
+    return bytestr
+
+def unmarshal_utf8(bytestr):
+    return bytestr.decode("utf8")
+
+def unmarshal_int(bytestr):
+    return decode_bigint(bytestr)
+
+if _have_struct:
+    def unmarshal_long(bytestr):
+        return _long_packer.unpack(bytestr)[0]
+else:
+    def unmarshal_long(bytestr):
+        return struct.unpack(">q", bytestr)[0]
+
+def unmarshal_uuid(bytestr):
+    return UUID(bytes=bytestr)
+
+unmarshallers = {BYTES_TYPE:          unmarshal_noop,
+                 ASCII_TYPE:          unmarshal_noop,
+                 UTF8_TYPE:           unmarshal_utf8,
+                 INTEGER_TYPE:        unmarshal_int,
+                 LONG_TYPE:           unmarshal_long,
+                 UUID_TYPE:           unmarshal_uuid,
+                 LEXICAL_UUID_TYPE:   unmarshal_uuid,
+                 TIME_UUID_TYPE:      unmarshal_uuid,
+                 COUNTER_COLUMN_TYPE: unmarshal_long}
+
+def decode_bigint(term):
+    val = int(term.encode('hex'), 16)
+    if (ord(term[0]) & 128) != 0:
+        val = val - (1 << (len(term) * 8))
+    return val
+
+def __escape_quotes(term):
+    assert isinstance(term, (str, unicode))
+    return term.replace("\'", "''")
diff --git a/drivers/py/cqlsh b/drivers/py/cqlsh
new file mode 100755
index 0000000000..55e6282ef6
--- /dev/null
+++ b/drivers/py/cqlsh
@@ -0,0 +1,334 @@
+#!/usr/bin/env python
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from collections import defaultdict
+from optparse import OptionParser
+from StringIO import StringIO
+
+import cmd
+import sys
+import readline
+import os
+import re
+import string
+import time
+
+try:
+    import cql
+except ImportError:
+    sys.path.append(os.path.abspath(os.path.dirname(__file__)))
+    import cql
+from cql.cursor import _COUNT_DESCRIPTION, _VOID_DESCRIPTION
+
+HISTORY = os.path.join(os.path.expanduser('~'), '.cqlsh')
+CQLTYPES = ("bytes", "ascii", "utf8", "timeuuid", "uuid", "long", "int")
+
+RED = "\033[1;31m%s\033[0m"
+GREEN = "\033[1;32m%s\033[0m"
+BLUE = "\033[1;34m%s\033[0m"
+YELLOW = "\033[1;33m%s\033[0m"
+CYAN = "\033[1;36m%s\033[0m"
+MAGENTA = "\033[1;35m%s\033[0m"
+
+def startswith(words, text):
+    return [i for i in words if i.startswith(text)]
+
+class Shell(cmd.Cmd):
+    default_prompt  = "cqlsh> "
+    continue_prompt = "   ... "
+
+    def __init__(self, hostname, port, color=False, username=None,
+            password=None):
+        cmd.Cmd.__init__(self)
+        self.conn = cql.connect(hostname, port, user=username, password=password)
+        self.cursor = self.conn.cursor()
+
+        if os.path.exists(HISTORY):
+            readline.read_history_file(HISTORY)
+
+        if sys.stdin.isatty():
+            self.prompt = Shell.default_prompt
+        else:
+            self.prompt = ""
+        
+        self.statement = StringIO()
+        self.color = color
+        self.in_comment = False
+        self.in_batch = False
+    
+    def reset_statement(self):
+        self.set_prompt(Shell.default_prompt)
+        self.statement.truncate(0)
+        
+    def get_statement(self, line):
+        if self.in_comment:
+            if "*/" in line:
+                fragment = line[line.index("*/")+2:]
+                if fragment.strip():
+                    line = fragment
+                    self.in_comment = False
+                else:
+                    self.in_comment = False
+                    self.set_prompt(Shell.default_prompt)
+                    return None
+            else:
+                return None
+        
+        if "/*" in line and (not self.in_comment):
+            self.in_comment = True
+            self.set_prompt(Shell.continue_prompt)
+            if line.lstrip().index("/*") != 0:
+                self.statement.write(line[:line.lstrip().index("/*")])
+            return None
+        
+        if ["BEGIN", "BATCH"] == line.upper().split()[:2]:
+            self.set_prompt(Shell.continue_prompt)
+            self.in_batch = True
+            self.statement.write("%s\n" % line)
+            return None
+        elif (["APPLY", "BATCH"] == line.upper().split()) and self.in_batch:
+            self.in_batch = False
+            self.statement.write("%s\n" % line)
+            try:
+                return self.statement.getvalue()
+            finally:
+                self.reset_statement()
+        
+        self.statement.write("%s\n" % line)
+        
+        # The end of a statement    
+        if not line.endswith(";") or self.in_batch:
+            self.set_prompt(Shell.continue_prompt)
+            return None
+        
+        try:    
+            return self.statement.getvalue()
+        finally:
+            self.reset_statement()
+
+    def default(self, arg):
+        def scrub_oneline_comments(s):
+            res = re.sub(r'\/\*.*\*\/', '', s)
+            res = re.sub(r'--.*$', '', res)
+            return res
+        
+        input = scrub_oneline_comments(arg)
+        if not input.strip(): return
+        statement = self.get_statement(input)
+        if not statement: return
+
+        for i in range(1,4):
+            try:
+                self.cursor.execute(statement)
+                break
+            except cql.IntegrityError, err:
+                self.printerr("Attempt #%d: %s" % (i, str(err)))
+                time.sleep(1*i)
+
+        if self.cursor.description is _VOID_DESCRIPTION:
+            return
+        elif self.cursor.description is _COUNT_DESCRIPTION:
+            self.print_count_result()
+        else:
+            self.print_result()
+
+    def print_count_result(self):
+        if not self.cursor.result:
+            return
+        print 'count'
+        print '-----'
+        print self.cursor.result[0]
+        self.printout("")
+
+    def print_result(self):
+        # first pass: see if we have a static column set
+        last_description = None
+        for row in self.cursor:
+            if last_description is not None and self.cursor.description != last_description:
+                static = False
+                break
+        else:
+            static = True
+        self.cursor._reset()
+
+        if static:
+            self.print_static_result()
+        else:
+            self.print_dynamic_result()
+        self.printout("")
+
+    def print_static_result(self):
+        # first pass, get widths
+        widths = defaultdict(lambda: 0)
+        for row in self.cursor:
+            for desc, value in zip(self.cursor.description, row):
+                name = desc[0]
+                widths[name] = max(widths[name], len(str(name)), len(str(value)))
+        self.cursor._reset()
+                
+        # print header
+        for desc in self.cursor.description:
+            name = desc[0]
+            width = widths[name]
+            self.printout(" ", newline=False)
+            self.printout(string.rjust(str(name), width), MAGENTA, False)
+            self.printout(" |", newline=False)
+        self.printout("")
+
+        # print row data
+        for row in self.cursor:
+            for desc, value in zip(self.cursor.description, row):
+                name = desc[0]
+                width = widths[desc[0]]
+                self.printout(" ", newline=False)
+                self.printout(string.rjust(str(value), width), YELLOW, False)
+                self.printout(" |", newline=False)
+            self.printout("")
+
+    def print_dynamic_result(self):
+        for row in self.cursor:
+            self.printout(" ", newline=False)
+            for desc, value in zip(self.cursor.description, row):
+                name = desc[0]
+                self.printout(str(name), MAGENTA, False)
+                self.printout(",", newline=False)
+                self.printout(str(value), YELLOW, False)
+                self.printout(" | ", newline=False)
+            self.printout("")
+
+    def emptyline(self):
+        pass
+
+    def complete_select(self, text, line, begidx, endidx):
+        keywords = ('FIRST', 'REVERSED', 'FROM', 'WHERE', 'KEY')
+        return startswith(keywords, text.upper())
+    complete_SELECT = complete_select
+
+    def complete_update(self, text, line, begidx, endidx):
+        keywords = ('WHERE', 'KEY', 'SET')
+        return startswith(keywords, text.upper())
+    complete_UPDATE = complete_update
+
+    def complete_create(self, text, line, begidx, endidx):
+        words = line.split()
+        if len(words) < 3:
+            return startswith(['COLUMNFAMILY', 'KEYSPACE'], text.upper())
+
+        common = ['WITH', 'AND']
+
+        if words[1].upper() == 'COLUMNFAMILY':
+            types = startswith(CQLTYPES, text)
+            keywords = startswith(('KEY', 'PRIMARY'), text.upper())
+            props = startswith(("comparator",
+                                "comment",
+                                "row_cache_size",
+                                "key_cache_size",
+                                "read_repair_chance",
+                                "gc_grace_seconds",
+                                "default_validation",
+                                "min_compaction_threshold",
+                                "max_compaction_threshold",
+                                "row_cache_save_period_in_seconds",
+                                "key_cache_save_period_in_seconds",
+                                "memtable_flush_after_mins",
+                                "memtable_throughput_in_mb",
+                                "memtable_operations_in_millions",
+                                "replicate_on_write"), text)
+            return startswith(common, text.upper()) + types + keywords + props
+
+        if words[1].upper() == 'KEYSPACE':
+            props = ("replication_factor", "strategy_options", "strategy_class")
+            return startswith(common, text.upper()) + startswith(props, text)
+    complete_CREATE = complete_create
+
+    def complete_drop(self, text, line, begidx, endidx):
+        words = line.split()
+        if len(words) < 3:
+            return startswith(['COLUMNFAMILY', 'KEYSPACE'], text.upper())
+    complete_DROP = complete_drop
+
+    def completenames(self, text, *ignored):
+        cmds = startswith(('USE', 'SELECT', 'UPDATE', 'DELETE', 'CREATE', 'DROP'),
+                          text.upper())
+        return cmd.Cmd.completenames(self, text, ignored) + cmds
+
+    def set_prompt(self, prompt):
+        if sys.stdin.isatty():
+            self.prompt = prompt
+
+    def do_EOF(self, arg):
+        if sys.stdin.isatty(): print
+        self.do_exit(None)
+
+    def do_exit(self, arg):
+        sys.exit()
+    do_quit = do_exit
+
+    def printout(self, text, color=None, newline=True, out=sys.stdout):
+        if not color or not self.color:
+            out.write(text)
+        else:
+            out.write(color % text)
+
+        if newline:
+            out.write("\n");
+
+    def printerr(self, text, color=RED, newline=True):
+        self.printout(text, color, newline, sys.stderr)
+
+if __name__ == '__main__':
+    parser = OptionParser(usage = "Usage: %prog [host [port]]")
+    parser.add_option("-C",
+                      "--color",
+                      action="store_true",
+                      help="Enable color output.")
+    parser.add_option("-u", "--username", help="Authenticate as user.")
+    parser.add_option("-p", "--password", help="Authenticate using password.")
+    (options, arguments) = parser.parse_args()
+
+    hostname = len(arguments) > 0 and arguments[0] or "localhost"
+
+    if len(arguments) > 1:
+        try:
+            port = int(arguments[1])
+        except ValueError:
+            print >>sys.stderr, "%s is not a valid port number" % arguments[1]
+            parser.print_help(file=sys.stderr)
+            sys.exit(1)
+    else:
+        port = 9160
+
+
+    shell = Shell(hostname,
+                  port,
+                  color=options.color,
+                  username=options.username,
+                  password=options.password)
+    while True:
+        try:
+            shell.cmdloop()
+        except SystemExit:
+            readline.write_history_file(HISTORY)
+            break
+        except cql.Error, cqlerr:
+            shell.printerr(str(cqlerr))
+        except KeyboardInterrupt:
+            shell.reset_statement()
+            print
+        except Exception, err:
+            shell.printerr("Exception: %s" % err)
diff --git a/drivers/py/setup.py b/drivers/py/setup.py
new file mode 100755
index 0000000000..a89919b035
--- /dev/null
+++ b/drivers/py/setup.py
@@ -0,0 +1,40 @@
+#!/usr/bin/python
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from distutils.core import setup
+from os.path import abspath, join, dirname
+
+setup(
+    name="cql",
+    version="1.0.4",
+    description="Cassandra Query Language driver",
+    long_description=open(abspath(join(dirname(__file__), 'README'))).read(),
+    maintainer='Apache Cassandra development team',
+    maintainer_email='dev@cassandra.apache.org',
+    url="http://cassandra.apache.org",
+    packages=["cql", "cql.cassandra"],
+    scripts=["cqlsh"],
+    requires=["thrift"],
+    provides=["cql"],
+    classifiers=[
+        "Development Status :: 4 - Beta",
+        "License :: OSI Approved :: Apache Software License",
+        "Operating System :: OS Independent",
+        "Programming Language :: Python",
+        "Topic :: Database :: Front-Ends",
+    ],
+)
diff --git a/drivers/py/test/test_query_compression.py b/drivers/py/test/test_query_compression.py
new file mode 100644
index 0000000000..7d161c7a11
--- /dev/null
+++ b/drivers/py/test/test_query_compression.py
@@ -0,0 +1,26 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import unittest, zlib
+
+class TestCompression(unittest.TestCase):
+    def test_gzip(self):
+        "compressing a string w/ gzip"
+        query = "SELECT \"foo\" FROM Standard1 WHERE KEY = \"bar\";"
+        compressed = zlib.compress(query)
+        decompressed = zlib.decompress(compressed)
+        assert query == decompressed, "Decompressed query did not match"
diff --git a/drivers/py/test/test_query_preparation.py b/drivers/py/test/test_query_preparation.py
new file mode 100644
index 0000000000..72d6011ea9
--- /dev/null
+++ b/drivers/py/test/test_query_preparation.py
@@ -0,0 +1,65 @@
+
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+import unittest
+import cql
+from cql.marshal import prepare
+
+# TESTS[i] ARGUMENTS[i] -> STANDARDS[i]
+TESTS = (
+"""
+SELECT :a,:b,:c,:d FROM ColumnFamily WHERE KEY = :e AND 'col' = :f;
+""",
+"""
+USE Keyspace;
+""",
+"""
+SELECT :a..:b FROM ColumnFamily;
+""",
+)
+
+ARGUMENTS = (
+    {'a': 1, 'b': 3, 'c': long(1000), 'd': long(3000), 'e': "key", 'f': unicode("val")},
+    {},
+    {'a': "a'b", 'b': "c'd'e"},
+)
+
+STANDARDS = (
+"""
+SELECT 1,3,1000,3000 FROM ColumnFamily WHERE KEY = 'key' AND 'col' = 'val';
+""",
+"""
+USE Keyspace;
+""",
+"""
+SELECT 'a''b'..'c''d''e' FROM ColumnFamily;
+""",
+)
+
+class TestPrepare(unittest.TestCase):
+    def test_prepares(self):
+        "test prepared queries against known standards"
+        for (i, test) in enumerate(TESTS):
+            a = prepare(test, ARGUMENTS[i])
+            b = STANDARDS[i]
+            assert a == b, "\n%s !=\n%s" % (a, b)
+
+    def test_bad(self):
+        "ensure bad calls raise exceptions"
+        self.assertRaises(KeyError, prepare, ":a :b", {'a': 1})
+        self.assertRaises(cql.ProgrammingError, prepare, ":a :b", {'a': 1, 'b': 2, 'c': 3})
+        self.assertRaises(cql.ProgrammingError, prepare, "none", {'a': 1})
diff --git a/drivers/py/test/test_regex.py b/drivers/py/test/test_regex.py
new file mode 100644
index 0000000000..af7c609412
--- /dev/null
+++ b/drivers/py/test/test_regex.py
@@ -0,0 +1,26 @@
+import unittest
+from cql.cursor import Cursor
+
+class TestRegex(unittest.TestCase):
+
+    def single_match(self, match, string):
+        groups = match.groups()
+        self.assertEquals(groups, (string, ))
+
+    def test_cfamily_regex(self):
+        cf_re = Cursor._cfamily_re
+
+        m = cf_re.match("SELECT key FROM column_family WHERE key = 'foo'")
+        self.single_match(m, "column_family")
+
+        m = cf_re.match("SELECT key FROM 'column_family' WHERE key = 'foo'")
+        self.single_match(m, "column_family")
+
+        m = cf_re.match("SELECT key FROM column_family WHERE key = 'break from chores'")
+        self.single_match(m, "column_family")
+
+        m = cf_re.match("SELECT key FROM 'from_cf' WHERE key = 'break from chores'")
+        self.single_match(m, "from_cf")
+
+        m = cf_re.match("SELECT '\nkey' FROM 'column_family' WHERE key = 'break \nfrom chores'")
+        self.single_match(m, "column_family")
