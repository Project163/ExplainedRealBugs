diff --git a/NEWS.txt b/NEWS.txt
index 6abae2642b..fbc7001158 100644
--- a/NEWS.txt
+++ b/NEWS.txt
@@ -48,6 +48,12 @@ Thrift API
     - The get_string_property() method has been removed.
     - The get_string_list_property() method has been removed.
 
+Other
+-----
+    - If extending AbstractType, make sure you follow the singleton pattern
+      followed by Cassandra core AbstractType extensions.
+      e.g. BytesType has a variable called 'instance' and an empty constructor
+      with default access
 
 0.6.0
 =====
diff --git a/contrib/pig/README.txt b/contrib/pig/README.txt
index ca10adda77..34967c6d6c 100644
--- a/contrib/pig/README.txt
+++ b/contrib/pig/README.txt
@@ -4,14 +4,22 @@ Setup:
 
 First build and start a Cassandra server with the default
 configuration* and set the PIG_HOME and JAVA_HOME environment
-variables to the location of a Pig >= 0.7.0-dev install and your Java
+variables to the location of a Pig >= 0.7.0 install and your Java
 install. If you would like to run using the Hadoop backend, you should
 also set PIG_CONF_DIR to the location of your Hadoop config.
 
 Run:
 
 contrib/pig$ ant
-contrib/pig$ bin/pig_cassandra
+contrib/pig$ bin/pig_cassandra -x local example-script.pig
+
+This will run the test script against your Cassandra instance
+and will assume that there is a Keyspace1/Standard1 with some
+data in it. It will run in local mode (see pig docs for more info).
+
+If you'd like to get to a 'grunt>' shell prompt, run:
+
+contrib/pig$ bin/pig_cassandra -x local
 
 Once the 'grunt>' shell has loaded, try a simple program like the
 following, which will determine the top 50 column names:
@@ -26,4 +34,4 @@ grunt> topnames = LIMIT orderednames 50;
 grunt> dump topnames;
 
 *If you want to point Pig at a real cluster, modify the seed
-address in storage-conf.xml and re-run the build step.
+address in cassandra.yaml and re-run the build step.
diff --git a/contrib/pig/bin/pig_cassandra b/contrib/pig/bin/pig_cassandra
index 98b6015ca2..802f42f890 100644
--- a/contrib/pig/bin/pig_cassandra
+++ b/contrib/pig/bin/pig_cassandra
@@ -33,7 +33,7 @@ fi
 CLASSPATH=$CLASSPATH:$LOADFUNC_JAR
 
 if [ "x$PIG_HOME" = "x" ]; then
-    echo "PIG_HOME not set: requires Pig >= 0.7.0-dev" >&2
+    echo "PIG_HOME not set: requires Pig >= 0.7.0" >&2
     exit 1
 fi
 
diff --git a/contrib/pig/build.xml b/contrib/pig/build.xml
index 484464bc7e..68b39c37c6 100644
--- a/contrib/pig/build.xml
+++ b/contrib/pig/build.xml
@@ -49,7 +49,7 @@
     </target>
 
     <target depends="init" name="build">
-        <fail unless="env.PIG_HOME" message="Please set PIG_HOME to the location of a Pig >= 0.7.0-dev install." />
+        <fail unless="env.PIG_HOME" message="Please set PIG_HOME to the location of a Pig >= 0.7.0 install." />
         <javac destdir="${build.classes}">
             <src path="${build.src}" />
             <classpath refid="classpath" />
diff --git a/contrib/pig/cassandra.yaml b/contrib/pig/cassandra.yaml
new file mode 100644
index 0000000000..9e5806fe6b
--- /dev/null
+++ b/contrib/pig/cassandra.yaml
@@ -0,0 +1,236 @@
+# Cassandra storage config YAML 
+# See http://wiki.apache.org/cassandra/StorageConfiguration for
+# explanations of configuration directives.
+
+# name of the cluster
+cluster_name: 'Test Cluster'
+
+# Set to true to make new [non-seed] nodes automatically migrate data
+# to themselves from the pre-existing nodes in the cluster.  Defaults
+# to false because you can only bootstrap N machines at a time from
+# an existing cluster of N, so if you are bringing up a cluster of
+# 10 machines with 3 seeds you would have to do it in stages.  Leaving
+# this off for the initial start simplifies that.
+auto_bootstrap: false
+
+# See http://wiki.apache.org/cassandra/HintedHandoff
+hinted_handoff_enabled: true
+
+# authentication backend, implementing IAuthenticator; used to limit keyspace access
+authenticator: org.apache.cassandra.auth.AllowAllAuthenticator
+
+# any IPartitioner may be used, including your own as long as it is on
+# the classpath.  Out of the box, Cassandra provides
+# org.apache.cassandra.dht.RandomPartitioner
+# org.apache.cassandra.dht.OrderPreservingPartitioner, and
+# org.apache.cassandra.dht.CollatingOrderPreservingPartitioner.
+partitioner: org.apache.cassandra.dht.RandomPartitioner
+
+# directories where Cassandra should store data on disk.
+data_file_directories:
+    - /var/lib/cassandra/data
+
+# Addresses of hosts that are deemed contact points. 
+# Cassandra nodes use this list of hosts to find each other and learn
+# the topology of the ring.  You must change this if you are running
+# multiple nodes!
+seeds:
+    - 127.0.0.1
+
+# Access mode.  mmapped i/o is substantially faster, but only practical on
+# a 64bit machine (which notably does not include EC2 "small" instances)
+# or relatively small datasets.  "auto", the safe choice, will enable
+# mmapping on a 64bit JVM.  Other values are "mmap", "mmap_index_only"
+# (which may allow you to get part of the benefits of mmap on a 32bit
+# machine by mmapping only index files) and "standard".
+# (The buffer size settings that follow only apply to standard,
+# non-mmapped i/o.)
+disk_access_mode: auto
+
+# Unlike most systems, in Cassandra writes are faster than reads, so
+# you can afford more of those in parallel.  A good rule of thumb is 2
+# concurrent reads per processor core.  Increase ConcurrentWrites to
+# the number of clients writing at once if you enable CommitLogSync +
+# CommitLogSyncDelay. -->
+concurrent_reads: 8
+concurrent_writes: 32
+
+# This sets the amount of memtable flush writer threads.  These will
+# be blocked by disk io, and each one will hold a memtable in memory
+# while blocked. If you have a large heap and many data directories,
+# you can increase this value for better flush performance.
+# By default this will be set to the amount of data directories defined.
+#memtable_flush_writers: 1
+
+# Buffer size to use when performing contiguous column slices. 
+# Increase this to the size of the column slices you typically perform
+sliced_buffer_size_in_kb: 64
+
+# TCP port, for commands and data
+storage_port: 7000
+
+# Address to bind to and tell other nodes to connect to. You _must_
+# change this if you want multiple nodes to be able to communicate!
+listen_address: localhost
+
+# The address to bind the Thrift RPC service to
+rpc_address: localhost
+# port for Thrift to listen on
+rpc_port: 9160
+# Whether or not to use a framed transport for Thrift.
+thrift_framed_transport: false
+snapshot_before_compaction: false
+
+# The threshold size in megabytes the binary memtable must grow to,
+# before it's submitted for flushing to disk.
+binary_memtable_throughput_in_mb: 256
+# Number of minutes to keep a memtable in memory
+memtable_flush_after_mins: 60
+# Size of the memtable in memory before it is dumped
+memtable_throughput_in_mb: 64
+# Number of objects in millions in the memtable before it is dumped
+memtable_operations_in_millions: 0.3
+# Buffer size to use when flushing !memtables to disk.
+flush_data_buffer_size_in_mb: 32
+# Increase (decrease) the index buffer size relative to the data
+# buffer if you have few (many) columns per key.
+flush_index_buffer_size_in_mb: 8
+
+column_index_size_in_kb: 64
+row_warning_threshold_in_mb: 512
+
+# commit log
+commitlog_directory: /var/lib/cassandra/commitlog
+
+# Size to allow commitlog to grow to before creating a new segment 
+commitlog_rotation_threshold_in_mb: 128
+
+# commitlog_sync may be either "periodic" or "batch." 
+# When in batch mode, Cassandra won't ack writes until the commit log
+# has been fsynced to disk.  It will wait up to
+# CommitLogSyncBatchWindowInMS milliseconds for other writes, before
+# performing the sync.
+commitlog_sync: periodic
+
+# the other option is "timed," where writes may be acked immediately
+# and the CommitLog is simply synced every commitlog_sync_period_in_ms
+# milliseconds.
+commitlog_sync_period_in_ms: 10000
+
+# Time to wait for a reply from other nodes before failing the command 
+rpc_timeout_in_ms: 10000
+
+# phi value that must be reached for a host to be marked down.
+# most users should never need to adjust this.
+# phi_convict_threshold: 8
+
+# time to wait before garbage collecting tombstones (deletion markers)
+gc_grace_seconds: 864000
+
+# endpoint_snitch -- Set this to a class that implements
+# IEndpointSnitch, which will let Cassandra know enough
+# about your network topology to route requests efficiently.
+# Out of the box, Cassandra provides
+# org.apache.cassandra.locator.SimpleSnitch,
+# org.apache.cassandra.locator.RackInferringSnitch, and
+# org.apache.cassandra.locator.PropertyFileSnitch.
+endpoint_snitch: org.apache.cassandra.locator.SimpleSnitch
+
+# A ColumnFamily is the Cassandra concept closest to a relational table. 
+#
+# Keyspaces are separate groups of ColumnFamilies.  Except in very
+# unusual circumstances you will have one Keyspace per application.
+#
+# Keyspace required parameters:
+# - name: name of the keyspace; "system" and "definitions" are 
+#   reserved for Cassandra Internals.
+# - replica_placement_strategy: the class that determines how replicas
+#   are distributed among nodes.  Must implement IReplicaPlacementStrategy.
+#   Out of the box, Cassandra provides 
+#     * org.apache.cassandra.locator.RackUnawareStrategy 
+#     * org.apache.cassandra.locator.RackAwareStrategy
+#     * org.apache.cassandra.locator.DatacenterShardStrategy
+#
+#   RackUnawareStrategy is the simplest; it simply places the first
+#   replica at the node whose token is closest to the key (as determined
+#   by the Partitioner), and additional replicas on subsequent nodes
+#   along the ring in increasing Token order.
+# 
+#   RackAwareStrategy is special cased for replication_factor of 3.  It
+#   places one replica in each of two datacenters, and the third on a
+#   different rack in in the first.
+#
+#   DatacenterShardStrategy is a generalization of RackAwareStrategy.
+#   For each datacenter, you can specify (in `datacenter.properties`)
+#   how many replicas you want on a per-keyspace basis.  Replicas are
+#   placed on different racks within each DC, if possible.
+# 
+# - replication_factor: Number of replicas of each row
+# - column_families: column families associated with this keyspace
+#
+# ColumnFamily required parameters:
+# - name: name of the ColumnFamily.  Must not contain the character "-".
+# - compare_with: tells Cassandra how to sort the columns for slicing
+#   operations. The default is BytesType, which is a straightforward
+#   lexical comparison of the bytes in each column.  Other options are
+#   AsciiType, UTF8Type, LexicalUUIDType, TimeUUIDType, and LongType.
+#   You can also specify the fully-qualified class name to a class of
+#   your choice extending org.apache.cassandra.db.marshal.AbstractType.
+#
+# ColumnFamily optional parameters:
+# - keys_cached: specifies the number of keys per sstable whose
+#   locations we keep in memory in "mostly LRU" order.  (JUST the key
+#   locations, NOT any column values.) Specify a fraction (value less
+#   than 1) or an absolute number of keys to cache.  Defaults to 200000
+#   keys.
+# - rows_cached: specifies the number of rows whose entire contents we
+#   cache in memory. Do not use this on ColumnFamilies with large rows,
+#   or ColumnFamilies with high write:read ratios. Specify a fraction
+#   (value less than 1) or an absolute number of rows to cache.
+#   Defaults to 0. (i.e. row caching is off by default)
+# - comment: used to attach additional human-readable information about 
+#   the column family to its definition.
+# - read_repair_chance: specifies the probability with which read
+#   repairs should be invoked on non-quorum reads.  must be between 0
+#   and 1. defaults to 1.0 (always read repair).
+# - preload_row_cache: If true, will populate row cache on startup.
+#   Defaults to false.
+#
+# NOTE: this keyspace definition is for demonstration purposes only.
+#       Cassandra will not load these definitions during startup. See
+#       http://wiki.apache.org/cassandra/FAQ#no_keyspaces for an explanation.
+keyspaces:
+    - name: Keyspace1
+      replica_placement_strategy: org.apache.cassandra.locator.RackUnawareStrategy
+      replication_factor: 1
+      column_families:
+        - name: Standard1
+          compare_with: BytesType
+
+        - name: Standard2
+          compare_with: UTF8Type
+          read_repair_chance: 0.1
+          keys_cached: 100
+
+        - name: StandardByUUID1
+          compare_with: TimeUUIDType
+          clock_type: Timestamp
+          reconciler: TimestampReconciler          
+
+        - name: Super1
+          column_type: Super
+          compare_with: BytesType
+          compare_subcolumns_with: BytesType
+
+        - name: Super2
+          column_type: Super
+          compare_subcolumns_with: UTF8Type
+          preload_row_cache: true
+          rows_cached: 10000
+          keys_cached: 50
+          comment: 'A column family with supercolumns, whose column and subcolumn names are UTF8 strings'
+
+        - name: Super3
+          column_type: Super
+          compare_with: LongType
+          comment: 'A column family with supercolumns, whose column names are Longs (8 bytes)'
diff --git a/contrib/pig/example-script.pig b/contrib/pig/example-script.pig
new file mode 100644
index 0000000000..5b5c0329eb
--- /dev/null
+++ b/contrib/pig/example-script.pig
@@ -0,0 +1,8 @@
+rows = LOAD 'cassandra://Keyspace1/Standard1' USING CassandraStorage();
+cols = FOREACH rows GENERATE flatten($1);
+colnames = FOREACH cols GENERATE $0;
+namegroups = GROUP colnames BY $0;
+namecounts = FOREACH namegroups GENERATE COUNT($1), group;
+orderednames = ORDER namecounts BY $0;
+topnames = LIMIT orderednames 50;
+dump topnames;
\ No newline at end of file
diff --git a/contrib/pig/storage-conf.xml b/contrib/pig/storage-conf.xml
deleted file mode 100644
index 9303c4feba..0000000000
--- a/contrib/pig/storage-conf.xml
+++ /dev/null
@@ -1,369 +0,0 @@
-<!--
- ~ Licensed to the Apache Software Foundation (ASF) under one
- ~ or more contributor license agreements.  See the NOTICE file
- ~ distributed with this work for additional information
- ~ regarding copyright ownership.  The ASF licenses this file
- ~ to you under the Apache License, Version 2.0 (the
- ~ "License"); you may not use this file except in compliance
- ~ with the License.  You may obtain a copy of the License at
- ~
- ~    http://www.apache.org/licenses/LICENSE-2.0
- ~
- ~ Unless required by applicable law or agreed to in writing,
- ~ software distributed under the License is distributed on an
- ~ "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- ~ KIND, either express or implied.  See the License for the
- ~ specific language governing permissions and limitations
- ~ under the License.
--->
-<Storage>
-  <!--======================================================================-->
-  <!-- Basic Configuration                                                  -->
-  <!--======================================================================-->
-
-  <!-- 
-   ~ The name of this cluster.  This is mainly used to prevent machines in
-   ~ one logical cluster from joining another.
-  -->
-  <ClusterName>Test Cluster</ClusterName>
-
-  <!--
-   ~ Turn on to make new [non-seed] nodes automatically migrate the right data 
-   ~ to themselves.  (If no InitialToken is specified, they will pick one 
-   ~ such that they will get half the range of the most-loaded node.)
-   ~ If a node starts up without bootstrapping, it will mark itself bootstrapped
-   ~ so that you can't subsequently accidently bootstrap a node with
-   ~ data on it.  (You can reset this by wiping your data and commitlog
-   ~ directories.)
-   ~
-   ~ Off by default so that new clusters and upgraders from 0.4 don't
-   ~ bootstrap immediately.  You should turn this on when you start adding
-   ~ new nodes to a cluster that already has data on it.  (If you are upgrading
-   ~ from 0.4, start your cluster with it off once before changing it to true.
-   ~ Otherwise, no data will be lost but you will incur a lot of unnecessary
-   ~ I/O before your cluster starts up.)
-  -->
-  <AutoBootstrap>false</AutoBootstrap>
-
-  <!--
-   ~ Keyspaces and ColumnFamilies:
-   ~ A ColumnFamily is the Cassandra concept closest to a relational
-   ~ table.  Keyspaces are separate groups of ColumnFamilies.  Except in
-   ~ very unusual circumstances you will have one Keyspace per application.
-
-   ~ There is an implicit keyspace named 'system' for Cassandra internals.
-  -->
-  <Keyspaces>
-    <Keyspace Name="Keyspace1">
-      <!--
-       ~ ColumnFamily definitions have one required attribute (Name)
-       ~ and several optional ones.
-       ~
-       ~ The CompareWith attribute tells Cassandra how to sort the columns
-       ~ for slicing operations.  The default is BytesType, which is a
-       ~ straightforward lexical comparison of the bytes in each column.
-       ~ Other options are AsciiType, UTF8Type, LexicalUUIDType, TimeUUIDType,
-       ~ and LongType.  You can also specify the fully-qualified class
-       ~ name to a class of your choice extending
-       ~ org.apache.cassandra.db.marshal.AbstractType.
-       ~ 
-       ~ SuperColumns have a similar CompareSubcolumnsWith attribute.
-       ~ 
-       ~ BytesType: Simple sort by byte value.  No validation is performed.
-       ~ AsciiType: Like BytesType, but validates that the input can be 
-       ~            parsed as US-ASCII.
-       ~ UTF8Type: A string encoded as UTF8
-       ~ LongType: A 64bit long
-       ~ LexicalUUIDType: A 128bit UUID, compared lexically (by byte value)
-       ~ TimeUUIDType: a 128bit version 1 UUID, compared by timestamp
-       ~
-       ~ (To get the closest approximation to 0.3-style supercolumns, you
-       ~ would use CompareWith=UTF8Type CompareSubcolumnsWith=LongType.)
-       ~
-       ~ An optional `Comment` attribute may be used to attach additional
-       ~ human-readable information about the column family to its definition.
-       ~ 
-       ~ The optional KeysCachedFraction attribute specifies
-       ~ The fraction of keys per sstable whose locations we keep in
-       ~ memory in "mostly LRU" order.  (JUST the key locations, NOT any
-       ~ column values.) The amount of memory used by the default setting of 
-       ~ 0.01 is comparable to the amount used by the internal per-sstable key
-       ~ index. Consider increasing this if you have fewer, wider rows.
-       ~ Set to 0 to disable entirely.
-       ~
-       ~ The optional RowsCached attribute specifies the number of rows
-       ~ whose entire contents we cache in memory, either as a fixed number
-       ~ of rows or as a percent of rows in the ColumnFamily.  
-       ~ Do not use this on ColumnFamilies with large rows, or
-       ~ ColumnFamilies with high write:read ratios.  As with key caching,
-       ~ valid values are from 0 to 1.  The default 0 disables it entirely.
-      -->
-      <ColumnFamily CompareWith="BytesType" 
-                    Name="Standard1" 
-                    RowsCached="10%"
-                    KeysCachedFraction="0"/>
-      <ColumnFamily CompareWith="UTF8Type" Name="Standard2"/>
-      <ColumnFamily CompareWith="TimeUUIDType" Name="StandardByUUID1"/>
-      <ColumnFamily ColumnType="Super"
-                    CompareWith="UTF8Type"
-                    CompareSubcolumnsWith="UTF8Type"
-                    Name="Super1"
-                    RowsCached="1000"
-                    KeysCachedFraction="0"
-                    Comment="A column family with supercolumns, whose column and subcolumn names are UTF8 strings"/>
-
-      <!--
-       ~ Strategy: Setting this to the class that implements
-       ~ IReplicaPlacementStrategy will change the way the node picker works.
-       ~ Out of the box, Cassandra provides
-       ~ org.apache.cassandra.locator.RackUnawareStrategy and
-       ~ org.apache.cassandra.locator.RackAwareStrategy (place one replica in
-       ~ a different datacenter, and the others on different racks in the same
-       ~ one.)
-      -->
-      <ReplicaPlacementStrategy>org.apache.cassandra.locator.RackUnawareStrategy</ReplicaPlacementStrategy>
-
-      <!-- Number of replicas of the data -->
-      <ReplicationFactor>1</ReplicationFactor>
-
-      <!--
-       ~ EndpointSnitch: Setting this to the class that implements
-       ~ AbstractEndpointSnitch, which lets Cassandra know enough
-       ~ about your network topology to route requests efficiently.
-       ~ Out of the box, Cassandra provides org.apache.cassandra.locator.EndpointSnitch,
-       ~ and PropertyFileEndpointSnitch is available in contrib/.
-      -->
-      <EndpointSnitch>org.apache.cassandra.locator.EndpointSnitch</EndpointSnitch>
-    </Keyspace>
-  </Keyspaces>
-
-  <!--
-   ~ Authenticator: any IAuthenticator may be used, including your own as long
-   ~ as it is on the classpath.  Out of the box, Cassandra provides
-   ~ org.apache.cassandra.auth.AllowAllAuthenticator and,
-   ~ org.apache.cassandra.auth.SimpleAuthenticator 
-   ~ (SimpleAuthenticator uses access.properties and passwd.properties by
-   ~ default).
-   ~
-   ~ If you don't specify an authenticator, AllowAllAuthenticator is used.
-  -->
-  <Authenticator>org.apache.cassandra.auth.AllowAllAuthenticator</Authenticator>
-
-  <!--
-   ~ Partitioner: any IPartitioner may be used, including your own as long
-   ~ as it is on the classpath.  Out of the box, Cassandra provides
-   ~ org.apache.cassandra.dht.RandomPartitioner,
-   ~ org.apache.cassandra.dht.OrderPreservingPartitioner, and
-   ~ org.apache.cassandra.dht.CollatingOrderPreservingPartitioner.
-   ~ (CollatingOPP colates according to EN,US rules, not naive byte
-   ~ ordering.  Use this as an example if you need locale-aware collation.)
-   ~ Range queries require using an order-preserving partitioner.
-   ~
-   ~ Achtung!  Changing this parameter requires wiping your data
-   ~ directories, since the partitioner can modify the sstable on-disk
-   ~ format.
-  -->
-  <Partitioner>org.apache.cassandra.dht.RandomPartitioner</Partitioner>
-
-  <!--
-   ~ If you are using an order-preserving partitioner and you know your key
-   ~ distribution, you can specify the token for this node to use. (Keys
-   ~ are sent to the node with the "closest" token, so distributing your
-   ~ tokens equally along the key distribution space will spread keys
-   ~ evenly across your cluster.)  This setting is only checked the first
-   ~ time a node is started. 
-
-   ~ This can also be useful with RandomPartitioner to force equal spacing
-   ~ of tokens around the hash space, especially for clusters with a small
-   ~ number of nodes.
-  -->
-  <InitialToken></InitialToken>
-
-  <!--
-   ~ Directories: Specify where Cassandra should store different data on
-   ~ disk.  Keep the data disks and the CommitLog disks separate for best
-   ~ performance
-  -->
-  <CommitLogDirectory>/var/lib/cassandra/commitlog</CommitLogDirectory>
-  <DataFileDirectories>
-      <DataFileDirectory>/var/lib/cassandra/data</DataFileDirectory>
-  </DataFileDirectories>
-  <CalloutLocation>/var/lib/cassandra/callouts</CalloutLocation>
-  <StagingFileDirectory>/var/lib/cassandra/staging</StagingFileDirectory>
-
-
-  <!--
-   ~ Addresses of hosts that are deemed contact points. Cassandra nodes
-   ~ use this list of hosts to find each other and learn the topology of
-   ~ the ring. You must change this if you are running multiple nodes!
-  -->
-  <Seeds>
-      <Seed>127.0.0.1</Seed>
-  </Seeds>
-
-
-  <!-- Miscellaneous -->
-
-  <!-- Time to wait for a reply from other nodes before failing the command -->
-  <RpcTimeoutInMillis>5000</RpcTimeoutInMillis>
-  <!-- Size to allow commitlog to grow to before creating a new segment -->
-  <CommitLogRotationThresholdInMB>128</CommitLogRotationThresholdInMB>
-
-
-  <!-- Local hosts and ports -->
-
-  <!-- 
-   ~ Address to bind to and tell other nodes to connect to.  You _must_
-   ~ change this if you want multiple nodes to be able to communicate!  
-   ~
-   ~ Leaving it blank leaves it up to InetAddress.getLocalHost(). This
-   ~ will always do the Right Thing *if* the node is properly configured
-   ~ (hostname, name resolution, etc), and the Right Thing is to use the
-   ~ address associated with the hostname (it might not be).
-  -->
-  <ListenAddress>127.0.0.2</ListenAddress>
-  <!-- internal communications port -->
-  <StoragePort>7000</StoragePort>
-
-  <!--
-   ~ The address to bind the Thrift RPC service to. Unlike ListenAddress
-   ~ above, you *can* specify 0.0.0.0 here if you want Thrift to listen on
-   ~ all interfaces.
-   ~
-   ~ Leaving this blank has the same effect it does for ListenAddress,
-   ~ (i.e. it will be based on the configured hostname of the node).
-  -->
-  <ThriftAddress>127.0.0.2</ThriftAddress>
-  <!-- Thrift RPC port (the port clients connect to). -->
-  <ThriftPort>9160</ThriftPort>
-  <!-- 
-   ~ Whether or not to use a framed transport for Thrift. If this option
-   ~ is set to true then you must also use a framed transport on the 
-   ~ client-side, (framed and non-framed transports are not compatible).
-  -->
-  <ThriftFramedTransport>false</ThriftFramedTransport>
-
-
-  <!--======================================================================-->
-  <!-- Memory, Disk, and Performance                                        -->
-  <!--======================================================================-->
-
-  <!--
-   ~ Access mode.  mmapped i/o is substantially faster, but only practical on
-   ~ a 64bit machine (which notably does not include EC2 "small" instances)
-   ~ or relatively small datasets.  "auto", the safe choice, will enable
-   ~ mmapping on a 64bit JVM.  Other values are "mmap", "mmap_index_only"
-   ~ (which may allow you to get part of the benefits of mmap on a 32bit
-   ~ machine by mmapping only index files) and "standard".
-   ~ (The buffer size settings that follow only apply to standard,
-   ~ non-mmapped i/o.)
-   -->
-  <DiskAccessMode>auto</DiskAccessMode>
-
-  <!--
-   ~ Buffer size to use when performing contiguous column slices. Increase
-   ~ this to the size of the column slices you typically perform. 
-   ~ (Name-based queries are performed with a buffer size of 
-   ~ ColumnIndexSizeInKB.)
-  -->
-  <SlicedBufferSizeInKB>64</SlicedBufferSizeInKB>
-
-  <!--
-   ~ Buffer size to use when flushing memtables to disk. (Only one 
-   ~ memtable is ever flushed at a time.) Increase (decrease) the index
-   ~ buffer size relative to the data buffer if you have few (many) 
-   ~ columns per key.  Bigger is only better _if_ your memtables get large
-   ~ enough to use the space. (Check in your data directory after your
-   ~ app has been running long enough.) -->
-  <FlushDataBufferSizeInMB>32</FlushDataBufferSizeInMB>
-  <FlushIndexBufferSizeInMB>8</FlushIndexBufferSizeInMB>
-
-  <!--
-   ~ Add column indexes to a row after its contents reach this size.
-   ~ Increase if your column values are large, or if you have a very large
-   ~ number of columns.  The competing causes are, Cassandra has to
-   ~ deserialize this much of the row to read a single column, so you want
-   ~ it to be small - at least if you do many partial-row reads - but all
-   ~ the index data is read for each access, so you don't want to generate
-   ~ that wastefully either.
-  -->
-  <ColumnIndexSizeInKB>64</ColumnIndexSizeInKB>
-
-  <!--
-   ~ Flush memtable after this much data has been inserted, including
-   ~ overwritten data.  There is one memtable per column family, and 
-   ~ this threshold is based solely on the amount of data stored, not
-   ~ actual heap memory usage (there is some overhead in indexing the
-   ~ columns).
-  -->
-  <MemtableThroughputInMB>64</MemtableThroughputInMB>
-  <!--
-   ~ Throughput setting for Binary Memtables.  Typically these are
-   ~ used for bulk load so you want them to be larger.
-  -->
-  <BinaryMemtableThroughputInMB>256</BinaryMemtableThroughputInMB>
-  <!--
-   ~ The maximum number of columns in millions to store in memory per
-   ~ ColumnFamily before flushing to disk.  This is also a per-memtable
-   ~ setting.  Use with MemtableThroughputInMB to tune memory usage.
-  -->
-  <MemtableOperationsInMillions>0.1</MemtableOperationsInMillions>
-  <!--
-   ~ The maximum time to leave a dirty memtable unflushed.
-   ~ (While any affected columnfamilies have unflushed data from a
-   ~ commit log segment, that segment cannot be deleted.)
-   ~ This needs to be large enough that it won't cause a flush storm
-   ~ of all your memtables flushing at once because none has hit
-   ~ the size or count thresholds yet.  For production, a larger
-   ~ value such as 1440 is recommended.
-  -->
-  <MemtableFlushAfterMinutes>60</MemtableFlushAfterMinutes>
-
-  <!--
-   ~ Unlike most systems, in Cassandra writes are faster than reads, so
-   ~ you can afford more of those in parallel.  A good rule of thumb is 2
-   ~ concurrent reads per processor core.  Increase ConcurrentWrites to
-   ~ the number of clients writing at once if you enable CommitLogSync +
-   ~ CommitLogSyncDelay. -->
-  <ConcurrentReads>8</ConcurrentReads>
-  <ConcurrentWrites>32</ConcurrentWrites>
-
-  <!--
-   ~ CommitLogSync may be either "periodic" or "batch."  When in batch
-   ~ mode, Cassandra won't ack writes until the commit log has been
-   ~ fsynced to disk.  It will wait up to CommitLogSyncBatchWindowInMS
-   ~ milliseconds for other writes, before performing the sync.
-
-   ~ This is less necessary in Cassandra than in traditional databases
-   ~ since replication reduces the odds of losing data from a failure
-   ~ after writing the log entry but before it actually reaches the disk.
-   ~ So the other option is "timed," where writes may be acked immediately
-   ~ and the CommitLog is simply synced every CommitLogSyncPeriodInMS
-   ~ milliseconds.
-  -->
-  <CommitLogSync>periodic</CommitLogSync>
-  <!--
-   ~ Interval at which to perform syncs of the CommitLog in periodic mode.
-   ~ Usually the default of 10000ms is fine; increase it if your i/o
-   ~ load is such that syncs are taking excessively long times.
-  -->
-  <CommitLogSyncPeriodInMS>10000</CommitLogSyncPeriodInMS>
-  <!--
-   ~ Delay (in milliseconds) during which additional commit log entries
-   ~ may be written before fsync in batch mode.  This will increase
-   ~ latency slightly, but can vastly improve throughput where there are
-   ~ many writers.  Set to zero to disable (each entry will be synced
-   ~ individually).  Reasonable values range from a minimal 0.1 to 10 or
-   ~ even more if throughput matters more than latency.
-  -->
-  <!-- <CommitLogSyncBatchWindowInMS>1</CommitLogSyncBatchWindowInMS> --> 
-
-  <!--
-   ~ Time to wait before garbage-collection deletion markers.  Set this to
-   ~ a large enough value that you are confident that the deletion marker
-   ~ will be propagated to all replicas by the time this many seconds has
-   ~ elapsed, even in the face of hardware failures.  The default value is
-   ~ ten days.
-  -->
-  <GCGraceSeconds>864000</GCGraceSeconds>
-</Storage>
diff --git a/contrib/word_count/src/WordCountSetup.java b/contrib/word_count/src/WordCountSetup.java
index e8436cb887..aa55a511eb 100644
--- a/contrib/word_count/src/WordCountSetup.java
+++ b/contrib/word_count/src/WordCountSetup.java
@@ -46,6 +46,8 @@ public class WordCountSetup
         Map<byte[], Map<String,List<Mutation>>> mutationMap;
         Column c;
 
+        // text0: no rows
+
         // text1: 1 row, 1 word
         c = new Column("text1".getBytes(), "word1".getBytes(), new Clock(System.currentTimeMillis()));
         mutationMap = getMutationMap("key0".getBytes(), WordCount.COLUMN_FAMILY, c);
diff --git a/src/java/org/apache/cassandra/cli/CliClient.java b/src/java/org/apache/cassandra/cli/CliClient.java
index 3771d2caed..bed5272e98 100644
--- a/src/java/org/apache/cassandra/cli/CliClient.java
+++ b/src/java/org/apache/cassandra/cli/CliClient.java
@@ -47,7 +47,7 @@ public class CliClient
     }
 
     // Execute a CLI Statement 
-    public void executeCLIStmt(String stmt) throws TException, NotFoundException, InvalidRequestException, UnavailableException, TimedOutException, IllegalAccessException, ClassNotFoundException, InstantiationException
+    public void executeCLIStmt(String stmt) throws TException, NotFoundException, InvalidRequestException, UnavailableException, TimedOutException, IllegalAccessException, ClassNotFoundException, InstantiationException, NoSuchFieldException
     {
         CommonTree ast = null;
 
@@ -243,7 +243,7 @@ public class CliClient
     }
 
     private void doSlice(String keyspace, String key, String columnFamily, byte[] superColumnName)
-            throws InvalidRequestException, UnavailableException, TimedOutException, TException, UnsupportedEncodingException, IllegalAccessException, NotFoundException, InstantiationException, ClassNotFoundException
+            throws InvalidRequestException, UnavailableException, TimedOutException, TException, UnsupportedEncodingException, IllegalAccessException, NotFoundException, InstantiationException, NoSuchFieldException
     {
         SliceRange range = new SliceRange(ArrayUtils.EMPTY_BYTE_ARRAY, ArrayUtils.EMPTY_BYTE_ARRAY, true, 1000000);
         List<ColumnOrSuperColumn> columns = thriftClient_.get_slice(key.getBytes(),
@@ -276,34 +276,36 @@ public class CliClient
         css_.out.println("Returned " + size + " results.");
     }
  
-    private String formatSuperColumnName(String keyspace, String columnFamily, SuperColumn column) throws NotFoundException, TException, ClassNotFoundException, IllegalAccessException, InstantiationException
+    private String formatSuperColumnName(String keyspace, String columnFamily, SuperColumn column) throws NotFoundException, TException, IllegalAccessException, InstantiationException, NoSuchFieldException
     {
         return getFormatTypeForColumn(keyspacesMap.get(keyspace).get(columnFamily).get("CompareWith")).getString(column.name);
     }
 
-    private String formatSubcolumnName(String keyspace, String columnFamily, Column subcolumn) throws NotFoundException, TException, ClassNotFoundException, IllegalAccessException, InstantiationException
+    private String formatSubcolumnName(String keyspace, String columnFamily, Column subcolumn) throws NotFoundException, TException, IllegalAccessException, InstantiationException, NoSuchFieldException
     {
         return getFormatTypeForColumn(keyspacesMap.get(keyspace).get(columnFamily).get("CompareSubcolumnsWith")).getString(subcolumn.name);
     }
 
-    private String formatColumnName(String keyspace, String columnFamily, Column column) throws ClassNotFoundException, NotFoundException, TException, IllegalAccessException, InstantiationException
+    private String formatColumnName(String keyspace, String columnFamily, Column column) throws NotFoundException, TException, IllegalAccessException, InstantiationException, NoSuchFieldException
     {
         return getFormatTypeForColumn(keyspacesMap.get(keyspace).get(columnFamily).get("CompareWith")).getString(column.name);
     }
 
-    private AbstractType getFormatTypeForColumn(String compareWith) throws ClassNotFoundException, IllegalAccessException, InstantiationException
+    private AbstractType getFormatTypeForColumn(String compareWith) throws IllegalAccessException, InstantiationException, NoSuchFieldException
     {
         AbstractType type;
         try {
-            type = (AbstractType) Class.forName(compareWith).newInstance();
+            // Get the singleton instance of the AbstractType subclass
+            Class c = Class.forName(compareWith);
+            type = (AbstractType) c.getField("instance").get(c);
         } catch (ClassNotFoundException e) {
-            type = BytesType.class.newInstance();
+            type = BytesType.instance;
         }
         return type;
     }
 
     // Execute GET statement
-    private void executeGet(CommonTree ast) throws TException, NotFoundException, InvalidRequestException, UnavailableException, TimedOutException, UnsupportedEncodingException, IllegalAccessException, InstantiationException, ClassNotFoundException
+    private void executeGet(CommonTree ast) throws TException, NotFoundException, InvalidRequestException, UnavailableException, TimedOutException, UnsupportedEncodingException, IllegalAccessException, InstantiationException, ClassNotFoundException, NoSuchFieldException
     {
         if (!CliMain.isConnected() || !hasKeySpace())
             return;
diff --git a/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java b/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java
index 8e7facb0ad..57486fa150 100644
--- a/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java
+++ b/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java
@@ -128,7 +128,9 @@ public class ColumnFamilySerializer implements ICompactSerializer2<ColumnFamily>
 
         try
         {
-            return (AbstractType)Class.forName(className).getConstructor().newInstance();
+            // Get the singleton instance of the AbstractType subclass
+            Class c = Class.forName(className);
+            return (AbstractType) c.getField("instance").get(c);
         }
         catch (ClassNotFoundException e)
         {
diff --git a/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordReader.java b/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordReader.java
index 3ea8eff043..f5ca25f2f2 100644
--- a/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordReader.java
+++ b/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordReader.java
@@ -187,7 +187,7 @@ public class ColumnFamilyRecordReader extends RecordReader<byte[], SortedMap<byt
          */
         private void maybeConnect() throws InvalidRequestException, TException, AuthenticationException, 
             AuthorizationException, NotFoundException, InstantiationException, IllegalAccessException, 
-            ClassNotFoundException
+            ClassNotFoundException, NoSuchFieldException
         {
             // only need to connect once
             if (socket != null && socket.isOpen())
@@ -213,7 +213,9 @@ public class ColumnFamilyRecordReader extends RecordReader<byte[], SortedMap<byt
                 Map<String, Map<String,String>> desc = client.describe_keyspace(keyspace);
                 Map<String,String> ksProps = desc.get(cfName);
                 String compClass = ksProps.get("CompareWith");
-                comparator = (AbstractType) Class.forName(compClass).newInstance();
+                // Get the singleton instance of the AbstractType subclass
+                Class c = Class.forName(compClass);
+                comparator = (AbstractType) c.getField("instance").get(c);
             }
         }
 
