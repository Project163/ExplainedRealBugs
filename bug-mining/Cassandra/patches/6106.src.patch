diff --git a/CHANGES.txt b/CHANGES.txt
index 43b68541db..84975ef1b9 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,4 +1,5 @@
 4.2
+ * Fix potential out of range exception on column index downsampling (CASSANDRA-17839)
  * Introduce target directory to vtable output for sstable_tasks and for compactionstats (CASSANDRA-13010)
  * Read/Write/Truncate throw RequestFailure in a race condition with callback timeouts, should return Timeout instead (CASSANDRA-17828)
  * Add ability to log load profiles at fixed intervals (CASSANDRA-17821)
diff --git a/src/java/org/apache/cassandra/io/sstable/format/big/BigTableWriter.java b/src/java/org/apache/cassandra/io/sstable/format/big/BigTableWriter.java
index e8dff32fbc..0adb9df227 100644
--- a/src/java/org/apache/cassandra/io/sstable/format/big/BigTableWriter.java
+++ b/src/java/org/apache/cassandra/io/sstable/format/big/BigTableWriter.java
@@ -356,7 +356,19 @@ public class BigTableWriter extends SSTableWriter
             ifile = iwriter.builder.bufferSize(indexBufferSize).complete(boundary.indexLength);
             if (compression)
                 dbuilder.withCompressionMetadata(((CompressedSequentialWriter) dataFile).open(boundary.dataLength));
-            int dataBufferSize = optimizationStrategy.bufferSize(stats.estimatedPartitionSize.percentile(DatabaseDescriptor.getDiskOptimizationEstimatePercentile()));
+
+            EstimatedHistogram partitionSizeHistogram = stats.estimatedPartitionSize;
+
+            if (partitionSizeHistogram.isOverflowed())
+            {
+                logger.warn("Estimated partition size histogram for '{}' is overflowed ({} values greater than {}). " +
+                            "Clearing the overflow bucket to allow for degraded mean and percentile calculations...",
+                            descriptor, partitionSizeHistogram.overflowCount(), partitionSizeHistogram.getLargestBucketOffset());
+
+                partitionSizeHistogram.clearOverflow();
+            }
+
+            int dataBufferSize = optimizationStrategy.bufferSize(partitionSizeHistogram.percentile(DatabaseDescriptor.getDiskOptimizationEstimatePercentile()));
             dfile = dbuilder.bufferSize(dataBufferSize).complete(boundary.dataLength);
             invalidateCacheAtBoundary(dfile);
             sstable = SSTableReader.internalOpen(descriptor,
diff --git a/src/java/org/apache/cassandra/io/sstable/metadata/MetadataCollector.java b/src/java/org/apache/cassandra/io/sstable/metadata/MetadataCollector.java
index 1375331ce5..4786a1cbbc 100644
--- a/src/java/org/apache/cassandra/io/sstable/metadata/MetadataCollector.java
+++ b/src/java/org/apache/cassandra/io/sstable/metadata/MetadataCollector.java
@@ -58,8 +58,9 @@ public class MetadataCollector implements PartitionStatisticsCollector
 
     static EstimatedHistogram defaultPartitionSizeHistogram()
     {
-        // EH of 150 can track a max value of 1697806495183, i.e., > 1.5PB
-        return new EstimatedHistogram(150);
+        // EH of 155 can track a max value of 3520571548412 i.e. 3.5TB
+        return new EstimatedHistogram(155);
+
     }
 
     static TombstoneHistogram defaultTombstoneDropTimeHistogram()
