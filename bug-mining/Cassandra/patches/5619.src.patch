diff --git a/src/java/org/apache/cassandra/db/filter/DataLimits.java b/src/java/org/apache/cassandra/db/filter/DataLimits.java
index 2759932321..c4118cd7bd 100644
--- a/src/java/org/apache/cassandra/db/filter/DataLimits.java
+++ b/src/java/org/apache/cassandra/db/filter/DataLimits.java
@@ -861,7 +861,7 @@ public abstract class DataLimits
              */
             protected int groupInCurrentPartition;
 
-            protected boolean hasGroupStarted;
+            protected boolean hasUnfinishedGroup;
 
             protected boolean hasLiveStaticRow;
 
@@ -879,7 +879,7 @@ public abstract class DataLimits
                 // If the end of the partition was reached at the same time than the row limit, the last group might
                 // not have been counted yet. Due to that we need to guess, based on the state, if the previous group
                 // is still open.
-                hasGroupStarted = state.hasClustering();
+                hasUnfinishedGroup = state.hasClustering();
             }
 
             @Override
@@ -895,17 +895,17 @@ public abstract class DataLimits
                     // once more.
                     hasLiveStaticRow = false;
                     hasReturnedRowsFromCurrentPartition = true;
-                    hasGroupStarted = true;
+                    hasUnfinishedGroup = true;
                 }
                 else
                 {
                     // We need to increment our count of groups if we have reached a new one and unless we had no new
-                    // content added since we closed our last group (that is, if hasGroupStarted). Note that we may get
-                    // here with hasGroupStarted == false in the following cases:
+                    // content added since we closed our last group (that is, if hasUnfinishedGroup). Note that we may get
+                    // here with hasUnfinishedGroup == false in the following cases:
                     // * the partition limit was reached for the previous partition
                     // * the previous partition was containing only one static row
                     // * the rows of the last group of the previous partition were all marked as deleted
-                    if (hasGroupStarted && groupMaker.isNewGroup(partitionKey, Clustering.STATIC_CLUSTERING))
+                    if (hasUnfinishedGroup && groupMaker.isNewGroup(partitionKey, Clustering.STATIC_CLUSTERING))
                     {
                         incrementGroupCount();
                         // If we detect, before starting the new partition, that we are done, we need to increase
@@ -913,7 +913,7 @@ public abstract class DataLimits
                         // there.
                         if (isDone())
                             incrementGroupInCurrentPartitionCount();
-                        hasGroupStarted = false;
+                        hasUnfinishedGroup = false;
                     }
                     hasReturnedRowsFromCurrentPartition = false;
                     hasLiveStaticRow = !staticRow.isEmpty() && isLive(staticRow);
@@ -950,25 +950,25 @@ public abstract class DataLimits
                 // non deleted row that we have reached the limit.
                 if (groupMaker.isNewGroup(currentPartitionKey, row.clustering()))
                 {
-                    if (hasGroupStarted)
+                    if (hasUnfinishedGroup)
                     {
                         incrementGroupCount();
                         incrementGroupInCurrentPartitionCount();
                     }
-                    hasGroupStarted = false;
+                    hasUnfinishedGroup = false;
                 }
 
                 // That row may have made us increment the group count, which may mean we're done for this partition, in
                 // which case we shouldn't count this row (it won't be returned).
                 if (enforceLimits && isDoneForPartition())
                 {
-                    hasGroupStarted = false;
+                    hasUnfinishedGroup = false;
                     return null;
                 }
 
                 if (isLive(row))
                 {
-                    hasGroupStarted = true;
+                    hasUnfinishedGroup = true;
                     incrementRowCount();
                     hasReturnedRowsFromCurrentPartition = true;
                 }
@@ -1044,7 +1044,7 @@ public abstract class DataLimits
                     incrementRowCount();
                     incrementGroupCount();
                     incrementGroupInCurrentPartitionCount();
-                    hasGroupStarted = false;
+                    hasUnfinishedGroup = false;
                 }
                 super.onPartitionClose();
             }
@@ -1058,7 +1058,7 @@ public abstract class DataLimits
                 // 2) the end of the data is reached
                 // We know that the end of the data is reached if the group limit has not been reached
                 // and the number of rows counted is smaller than the internal page size.
-                if (hasGroupStarted && groupCounted < groupLimit && rowsCounted < rowLimit)
+                if (hasUnfinishedGroup && groupCounted < groupLimit && rowsCounted < rowLimit)
                 {
                     incrementGroupCount();
                     incrementGroupInCurrentPartitionCount();
@@ -1146,7 +1146,7 @@ public abstract class DataLimits
                     groupInCurrentPartition = groupPerPartitionLimit - lastReturnedKeyRemaining;
                     hasReturnedRowsFromCurrentPartition = true;
                     hasLiveStaticRow = false;
-                    hasGroupStarted = state.hasClustering();
+                    hasUnfinishedGroup = state.hasClustering();
                 }
                 else
                 {
diff --git a/src/java/org/apache/cassandra/service/DataResolver.java b/src/java/org/apache/cassandra/service/DataResolver.java
index 26dabe9f56..bab63f26af 100644
--- a/src/java/org/apache/cassandra/service/DataResolver.java
+++ b/src/java/org/apache/cassandra/service/DataResolver.java
@@ -746,7 +746,7 @@ public class DataResolver extends ResponseResolver
              * Can only take the short cut if there is no per partition limit set. Otherwise it's possible to hit false
              * positives due to some rows being uncounted for in certain scenarios (see CASSANDRA-13911).
              */
-            if (!singleResultCounter.isDone() && command.limits().perPartitionCount() == DataLimits.NO_LIMIT)
+            if (command.limits().isExhausted(singleResultCounter) && command.limits().perPartitionCount() == DataLimits.NO_LIMIT)
                 return null;
 
             /*
@@ -844,7 +844,7 @@ public class DataResolver extends ResponseResolver
                  * Can only take the short cut if there is no per partition limit set. Otherwise it's possible to hit false
                  * positives due to some rows being uncounted for in certain scenarios (see CASSANDRA-13911).
                  */
-                if (!singleResultCounter.isDoneForPartition() && command.limits().perPartitionCount() == DataLimits.NO_LIMIT)
+                if (command.limits().isExhausted(singleResultCounter) && command.limits().perPartitionCount() == DataLimits.NO_LIMIT)
                     return null;
 
                 /*
diff --git a/test/distributed/org/apache/cassandra/distributed/test/GroupByTest.java b/test/distributed/org/apache/cassandra/distributed/test/GroupByTest.java
index 1ffcb67e4f..26e3996732 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/GroupByTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/GroupByTest.java
@@ -39,6 +39,33 @@ import static org.apache.cassandra.distributed.shared.AssertUtils.row;
 
 public class GroupByTest extends TestBaseImpl
 {
+    @Test
+    public void groupByWithDeletesAndSrpOnPartitions() throws Throwable
+    {
+        try (Cluster cluster = init(builder().withNodes(2).withConfig((cfg) -> cfg.set("enable_user_defined_functions", "true")).start()))
+        {
+            cluster.schemaChange(withKeyspace("CREATE TABLE %s.tbl (pk int, ck text, PRIMARY KEY (pk, ck))"));
+            initFunctions(cluster);
+            cluster.get(1).executeInternal(withKeyspace("INSERT INTO %s.tbl (pk, ck) VALUES (1, '1') USING TIMESTAMP 0"));
+            cluster.get(1).executeInternal(withKeyspace("INSERT INTO %s.tbl (pk, ck) VALUES (2, '2') USING TIMESTAMP 0"));
+            cluster.get(1).executeInternal(withKeyspace("DELETE FROM %s.tbl WHERE pk=0 AND ck='0'"));
+
+            cluster.get(2).executeInternal(withKeyspace("INSERT INTO %s.tbl (pk, ck) VALUES (0, '0') USING TIMESTAMP 0"));
+            cluster.get(2).executeInternal(withKeyspace("DELETE FROM %s.tbl WHERE pk=1 AND ck='1'"));
+            cluster.get(2).executeInternal(withKeyspace("DELETE FROM %s.tbl WHERE pk=2 AND ck='2'"));
+
+            for (String limitClause : new String[]{ "", "LIMIT 1", "LIMIT 10", "PER PARTITION LIMIT 1", "PER PARTITION LIMIT 10" })
+            {
+                String query = withKeyspace("SELECT concat(ck) FROM %s.tbl GROUP BY pk " + limitClause);
+                for (int i = 1; i <= 4; i++)
+                {
+                    Iterator<Object[]> rows = cluster.coordinator(2).executeWithPaging(query, ConsistencyLevel.ALL, i);
+                    assertRows(Iterators.toArray(rows, Object[].class));
+                }
+            }
+        }
+    }
+
     @Test
     public void groupByWithDeletesAndSrpOnRows() throws Throwable
     {
@@ -54,9 +81,8 @@ public class GroupByTest extends TestBaseImpl
             cluster.get(2).executeInternal(withKeyspace("DELETE FROM %s.tbl WHERE pk=0 AND ck='1'"));
             cluster.get(2).executeInternal(withKeyspace("DELETE FROM %s.tbl WHERE pk=0 AND ck='2'"));
 
-            for (int limit : new int[]{ 0, 1, 10 })
+            for (String limitClause : new String[]{ "", "LIMIT 1", "LIMIT 10", "PER PARTITION LIMIT 1", "PER PARTITION LIMIT 10" })
             {
-                String limitClause = limit == 0 ? "" : "LIMIT " + limit;
                 String query = withKeyspace("SELECT concat(ck) FROM %s.tbl GROUP BY pk " + limitClause);
                 for (int i = 1; i <= 4; i++)
                 {
@@ -126,14 +152,14 @@ public class GroupByTest extends TestBaseImpl
     private static void initFunctions(Cluster cluster)
     {
         cluster.schemaChange(withKeyspace("CREATE FUNCTION %s.concat_strings_fn(a text, b text) " +
-                                          "RETURNS NULL ON NULL INPUT " +
-                                          "RETURNS text " +
-                                          "LANGUAGE java " +
-                                          "AS 'return a + \" \" + b;'"));
+                             "RETURNS NULL ON NULL INPUT " +
+                             "RETURNS text " +
+                             "LANGUAGE java " +
+                             "AS 'return a + \" \" + b;'"));
 
         cluster.schemaChange(withKeyspace("CREATE AGGREGATE %s.concat(text)" +
-                                          " SFUNC concat_strings_fn" +
-                                          " STYPE text" +
-                                          " INITCOND '_'"));
+                             " SFUNC concat_strings_fn" +
+                             " STYPE text" +
+                             " INITCOND '_'"));
     }
 }
\ No newline at end of file
