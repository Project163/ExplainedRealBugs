diff --git a/CHANGES.txt b/CHANGES.txt
index d2510b6bc1..4e64134fc8 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,4 +1,5 @@
 2.2.3
+ * cqlsh pg-style-strings broken (CASSANDRA-10484)
  * Make Hadoop CF splits more polite to custom orderered partitioners (CASSANDRA-10400)
 Merged from 2.1:
  * Update internal python driver used by cqlsh (CASSANDRA-10161)
diff --git a/pylib/cqlshlib/cql3handling.py b/pylib/cqlshlib/cql3handling.py
index dcae173610..40b7d6b0bc 100644
--- a/pylib/cqlshlib/cql3handling.py
+++ b/pylib/cqlshlib/cql3handling.py
@@ -135,7 +135,7 @@ JUNK ::= /([ \t\r\f\v]+|(--|[/][/])[^\n\r]*([\n\r]|$)|[/][*].*?[*][/])/ ;
 <stringLiteral> ::= <quotedStringLiteral>
                   | <pgStringLiteral> ;
 <quotedStringLiteral> ::= /'([^']|'')*'/ ;
-<pgStringLiteral> ::= /\$\$.*\$\$/;
+<pgStringLiteral> ::= /\$\$(?:(?!\$\$)|[^$])*\$\$/;
 <quotedName> ::=    /"([^"]|"")*"/ ;
 <float> ::=         /-?[0-9]+\.[0-9]+/ ;
 <uuid> ::=          /[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}/ ;
@@ -154,6 +154,7 @@ JUNK ::= /([ \t\r\f\v]+|(--|[/][/])[^\n\r]*([\n\r]|$)|[/][*].*?[*][/])/ ;
             | "false"
             ;
 
+<unclosedPgString>::= /\$\$(?:(?!\$\$)|[^$])*/ ;
 <unclosedString>  ::= /'([^']|'')*/ ;
 <unclosedName>    ::= /"([^"]|"")*/ ;
 <unclosedComment> ::= /[/][*].*$/ ;
diff --git a/pylib/cqlshlib/test/test_cql_parsing.py b/pylib/cqlshlib/test/test_cql_parsing.py
index cb8e3a6733..c011d94c70 100644
--- a/pylib/cqlshlib/test/test_cql_parsing.py
+++ b/pylib/cqlshlib/test/test_cql_parsing.py
@@ -31,6 +31,41 @@ class TestCqlParsing(TestCase):
         self.assertSequenceEqual(tokens_with_types(CqlRuleSet.lex("'eggs'")),
                                  [("'eggs'", 'quotedStringLiteral')])
 
+        tokens = CqlRuleSet.lex("'spam\nspam\n\tsausage'")
+        tokens = CqlRuleSet.cql_massage_tokens(tokens)
+        self.assertEqual(tokens[0][0], "quotedStringLiteral")
+
+        tokens = CqlRuleSet.lex("'spam\nspam\n")
+        tokens = CqlRuleSet.cql_massage_tokens(tokens)
+        self.assertEqual(tokens[0][0], "unclosedString")
+
+        tokens = CqlRuleSet.lex("'foo bar' 'spam\nspam\n")
+        tokens = CqlRuleSet.cql_massage_tokens(tokens)
+        self.assertEqual(tokens[1][0], "unclosedString")
+
+    def test_parse_pgstring_literals(self):
+        for n in ["$$eggs$$", "$$Sausage 1$$", "$$spam\nspam\n\tsausage$$", "$$$$"]:
+            self.assertSequenceEqual(tokens_with_types(CqlRuleSet.lex(n)),
+                                     [(n, 'pgStringLiteral')])
+        self.assertSequenceEqual(tokens_with_types(CqlRuleSet.lex("$$eggs$$")),
+                                 [("$$eggs$$", 'pgStringLiteral')])
+
+        tokens = CqlRuleSet.lex("$$spam\nspam\n\tsausage$$")
+        tokens = CqlRuleSet.cql_massage_tokens(tokens)
+        # [('pgStringLiteral', '$$spam\nspam\n\tsausage$$', (0, 22))]
+        self.assertEqual(tokens[0][0], "pgStringLiteral")
+
+        tokens = CqlRuleSet.lex("$$spam\nspam\n")
+        tokens = CqlRuleSet.cql_massage_tokens(tokens)
+        # [('unclosedPgString', '$$', (0, 2)), ('identifier', 'spam', (2, 6)), ('identifier', 'spam', (7, 11))]
+        self.assertEqual(tokens[0][0], "unclosedPgString")
+
+        tokens = CqlRuleSet.lex("$$foo bar$$ $$spam\nspam\n")
+        tokens = CqlRuleSet.cql_massage_tokens(tokens)
+        # [('pgStringLiteral', '$$foo bar$$', (0, 11)), ('unclosedPgString', '$$', (12, 14)), ('identifier', 'spam', (14, 18)), ('identifier', 'spam', (19, 23))]
+        self.assertEqual(tokens[0][0], "pgStringLiteral")
+        self.assertEqual(tokens[1][0], "unclosedPgString")
+
     def test_parse_numbers(self):
         for n in ['6', '398', '18018']:
             self.assertSequenceEqual(tokens_with_types(CqlRuleSet.lex(n)),
