diff --git a/src/java/org/apache/cassandra/db/ColumnFamilyStore.java b/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
index a41a4c814f..663773896d 100644
--- a/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
+++ b/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
@@ -245,38 +245,22 @@ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean
      * This method forces a compaction of the SSTables on disk. We wait
      * for the process to complete by waiting on a future pointer.
     */
-    boolean forceCompaction(List<Range> ranges, EndPoint target, long skip, List<String> fileList)
+    List<SSTableReader> forceAntiCompaction(List<Range> ranges, EndPoint target, long skip)
     {
-        Future<Boolean> futurePtr = null;
-        if (ranges != null)
-        {
-            futurePtr = MinorCompactionManager.instance().submit(ColumnFamilyStore.this, ranges, target, fileList);
-        }
-        else
-        {
-            MinorCompactionManager.instance().submitMajor(ColumnFamilyStore.this, skip);
-        }
+        assert ranges != null;
+        Future<List<SSTableReader>> futurePtr = MinorCompactionManager.instance().submit(ColumnFamilyStore.this, ranges, target);
 
-        boolean result = true;
+        List<SSTableReader> result;
         try
         {
             /* Waiting for the compaction to complete. */
-            if (futurePtr != null)
-            {
-                result = futurePtr.get();
-            }
+            result = futurePtr.get();
             if (logger_.isDebugEnabled())
               logger_.debug("Done forcing compaction ...");
         }
-        catch (ExecutionException ex)
-        {
-            if (logger_.isDebugEnabled())
-              logger_.debug(LogUtil.throwableToString(ex));
-        }
-        catch (InterruptedException ex2)
+        catch (Exception ex)
         {
-            if (logger_.isDebugEnabled())
-              logger_.debug(LogUtil.throwableToString(ex2));
+            throw new RuntimeException(ex);
         }
         return result;
     }
@@ -723,9 +707,9 @@ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean
         return maxFile;
     }
 
-    boolean doAntiCompaction(List<Range> ranges, EndPoint target, List<String> fileList) throws IOException
+    List<SSTableReader> doAntiCompaction(List<Range> ranges, EndPoint target) throws IOException
     {
-        return doFileAntiCompaction(ssTables_.getSSTables(), ranges, target, fileList);
+        return doFileAntiCompaction(ssTables_.getSSTables(), ranges, target);
     }
 
     void forceCleanup()
@@ -756,10 +740,14 @@ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean
     {
         assert sstable != null;
         List<Range> myRanges;
-        List<String> newFiles = new ArrayList<String>();
         Map<EndPoint, List<Range>> endPointtoRangeMap = StorageService.instance().constructEndPointToRangesMap();
         myRanges = endPointtoRangeMap.get(StorageService.getLocalStorageEndPoint());
-        doFileAntiCompaction(Arrays.asList(sstable), myRanges, null, newFiles);
+        List<SSTableReader> sstables = doFileAntiCompaction(Arrays.asList(sstable), myRanges, null);
+        if (!sstables.isEmpty())
+        {
+            assert sstables.size() == 1;
+            addSSTable(sstables.get(0));
+        }
         if (logger_.isDebugEnabled())
           logger_.debug("Original file : " + sstable + " of size " + sstable.length());
         ssTables_.markCompacted(Arrays.asList(sstable));
@@ -772,13 +760,12 @@ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean
      * @param sstables
      * @param ranges
      * @param target
-     * @param fileList
      * @return
      * @throws IOException
      */
-    boolean doFileAntiCompaction(Collection<SSTableReader> sstables, List<Range> ranges, EndPoint target, List<String> fileList) throws IOException
+    List<SSTableReader> doFileAntiCompaction(Collection<SSTableReader> sstables, List<Range> ranges, EndPoint target) throws IOException
     {
-        boolean result = false;
+        List<SSTableReader> results = new ArrayList<SSTableReader>();
         long startTime = System.currentTimeMillis();
         long totalBytesRead = 0;
         long totalBytesWritten = 0;
@@ -796,12 +783,12 @@ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean
         {
             logger_.error("Total bytes to be written for range compaction  ..."
                           + expectedRangeFileSize + "   is greater than the safe limit of the disk space available.");
-            return result;
+            return results;
         }
         PriorityQueue<FileStruct> pq = initializePriorityQueue(sstables, ranges);
         if (pq.isEmpty())
         {
-            return result;
+            return results;
         }
 
         mergedFileName = getTempSSTableFileName();
@@ -912,17 +899,7 @@ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean
 
         if (rangeWriter != null)
         {
-            rangeWriter.closeAndOpenReader();
-            if (fileList != null)
-            {
-                //Retain order. The -Data.db file needs to be last because 
-                //the receiving end checks for this file before opening the SSTable
-                //and adding this to the list of SSTables.
-                fileList.add(rangeWriter.indexFilename());
-                fileList.add(rangeWriter.filterFilename());
-                fileList.add(rangeWriter.getFilename());
-            }
-            result = true;
+            results.add(rangeWriter.closeAndOpenReader());
         }
 
         if (logger_.isDebugEnabled())
@@ -932,7 +909,7 @@ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean
             logger_.debug("Total bytes written for range split  ..."
                           + totalBytesWritten + "   Total keys read ..." + totalkeysRead);
         }
-        return result;
+        return results;
     }
 
     /*
diff --git a/src/java/org/apache/cassandra/db/HintedHandOffManager.java b/src/java/org/apache/cassandra/db/HintedHandOffManager.java
index 7898fe891f..80e2282893 100644
--- a/src/java/org/apache/cassandra/db/HintedHandOffManager.java
+++ b/src/java/org/apache/cassandra/db/HintedHandOffManager.java
@@ -19,7 +19,6 @@
 package org.apache.cassandra.db;
 
 import java.util.Collection;
-import java.util.Set;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
@@ -188,7 +187,7 @@ public class HintedHandOffManager
             }
         }
         hintStore.forceFlush();
-        hintStore.forceCompaction(null, null, 0, null);
+        hintStore.forceAntiCompaction(null, null, 0);
 
         if (logger_.isDebugEnabled())
           logger_.debug("Finished deliverAllHints");
diff --git a/src/java/org/apache/cassandra/db/MinorCompactionManager.java b/src/java/org/apache/cassandra/db/MinorCompactionManager.java
index 25d026e0c4..09089d1824 100644
--- a/src/java/org/apache/cassandra/db/MinorCompactionManager.java
+++ b/src/java/org/apache/cassandra/db/MinorCompactionManager.java
@@ -30,6 +30,7 @@ import org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor;
 import org.apache.cassandra.concurrent.ThreadFactoryImpl;
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.net.EndPoint;
+import org.apache.cassandra.io.SSTableReader;
 
 import org.apache.log4j.Logger;
 
@@ -60,29 +61,27 @@ class MinorCompactionManager
         return instance_;
     }
 
-    static class FileCompactor2 implements Callable<Boolean>
+    static class FileCompactor2 implements Callable<List<SSTableReader>>
     {
         private ColumnFamilyStore columnFamilyStore_;
         private List<Range> ranges_;
         private EndPoint target_;
-        private List<String> fileList_;
 
-        FileCompactor2(ColumnFamilyStore columnFamilyStore, List<Range> ranges, EndPoint target,List<String> fileList)
+        FileCompactor2(ColumnFamilyStore columnFamilyStore, List<Range> ranges, EndPoint target)
         {
             columnFamilyStore_ = columnFamilyStore;
             ranges_ = ranges;
             target_ = target;
-            fileList_ = fileList;
         }
 
-        public Boolean call()
+        public List<SSTableReader> call()
         {
-        	boolean result;
+        	List<SSTableReader> results;
             if (logger_.isDebugEnabled())
               logger_.debug("Started  compaction ..."+columnFamilyStore_.columnFamily_);
             try
             {
-                result = columnFamilyStore_.doAntiCompaction(ranges_, target_,fileList_);
+                results = columnFamilyStore_.doAntiCompaction(ranges_, target_);
             }
             catch (IOException e)
             {
@@ -90,7 +89,7 @@ class MinorCompactionManager
             }
             if (logger_.isDebugEnabled())
               logger_.debug("Finished compaction ..."+columnFamilyStore_.columnFamily_);
-            return result;
+            return results;
         }
     }
 
@@ -178,9 +177,9 @@ class MinorCompactionManager
         compactor_.submit(new CleanupCompactor(columnFamilyStore));
     }
 
-    public Future<Boolean> submit(ColumnFamilyStore columnFamilyStore, List<Range> ranges, EndPoint target, List<String> fileList)
+    public Future<List<SSTableReader>> submit(ColumnFamilyStore columnFamilyStore, List<Range> ranges, EndPoint target)
     {
-        return compactor_.submit( new FileCompactor2(columnFamilyStore, ranges, target, fileList) );
+        return compactor_.submit( new FileCompactor2(columnFamilyStore, ranges, target) );
     }
 
     public void  submitMajor(ColumnFamilyStore columnFamilyStore, long skip)
diff --git a/src/java/org/apache/cassandra/db/Table.java b/src/java/org/apache/cassandra/db/Table.java
index ab983a9d76..1b9eaa68d7 100644
--- a/src/java/org/apache/cassandra/db/Table.java
+++ b/src/java/org/apache/cassandra/db/Table.java
@@ -459,9 +459,9 @@ public class Table
      * do a complete compaction since we can figure out based on the ranges
      * whether the files need to be split.
     */
-    public boolean forceCompaction(List<Range> ranges, EndPoint target, List<String> fileList)
+    public List<SSTableReader> forceAntiCompaction(List<Range> ranges, EndPoint target)
     {
-        boolean result = true;
+        List<SSTableReader> allResults = new ArrayList<SSTableReader>();
         Set<String> columnFamilies = tableMetadata_.getColumnFamilies();
         for ( String columnFamily : columnFamilies )
         {
@@ -469,12 +469,9 @@ public class Table
                 continue;
             
             ColumnFamilyStore cfStore = columnFamilyStores_.get( columnFamily );
-            if ( cfStore != null )
-            {
-                cfStore.forceCompaction(ranges, target, 0, fileList);                
-            }
+            allResults.addAll(cfStore.forceAntiCompaction(ranges, target, 0));
         }
-        return result;
+        return allResults;
     }
     
     /*
diff --git a/src/java/org/apache/cassandra/dht/BootstrapMetadataVerbHandler.java b/src/java/org/apache/cassandra/dht/BootstrapMetadataVerbHandler.java
index 8b60bd64fc..67df99cb3e 100644
--- a/src/java/org/apache/cassandra/dht/BootstrapMetadataVerbHandler.java
+++ b/src/java/org/apache/cassandra/dht/BootstrapMetadataVerbHandler.java
@@ -26,6 +26,7 @@ import java.util.List;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.Table;
 import org.apache.cassandra.io.DataInputBuffer;
+import org.apache.cassandra.io.SSTableReader;
 import org.apache.cassandra.net.EndPoint;
 import org.apache.cassandra.net.IVerbHandler;
 import org.apache.cassandra.net.Message;
@@ -130,7 +131,12 @@ public class BootstrapMetadataVerbHandler implements IVerbHandler
               logger_.debug("Forcing compaction ...");
             /* Get the counting bloom filter for each endpoint and the list of files that need to be streamed */
             List<String> fileList = new ArrayList<String>();
-            table.forceCompaction(ranges, target, fileList);
+            for (SSTableReader sstable : table.forceAntiCompaction(ranges, target))
+            {
+                fileList.add(sstable.indexFilename());
+                fileList.add(sstable.filterFilename());
+                fileList.add(sstable.getFilename());
+            }
             doHandoff(target, fileList, tName);
             //In Handoff, Streaming the file also deletes the file, so no cleanup needed            
         }
diff --git a/test/unit/org/apache/cassandra/db/BootstrapTest.java b/test/unit/org/apache/cassandra/db/BootstrapTest.java
index 3c5aff3e3b..99407eac4f 100644
--- a/test/unit/org/apache/cassandra/db/BootstrapTest.java
+++ b/test/unit/org/apache/cassandra/db/BootstrapTest.java
@@ -32,6 +32,8 @@ import org.apache.cassandra.db.filter.QueryPath;
 import org.apache.cassandra.dht.*;
 import org.apache.cassandra.net.EndPoint;
 import org.apache.cassandra.net.io.StreamContextManager;
+import org.apache.cassandra.io.SSTableReader;
+
 import org.junit.Test;
 
 public class BootstrapTest
@@ -54,16 +56,13 @@ public class BootstrapTest
         }
         
         store.forceBlockingFlush();
-        List<String> fileList = new ArrayList<String>();
         List<Range> ranges  = new ArrayList<Range>();
         IPartitioner partitioner = new CollatingOrderPreservingPartitioner();
         Range r = new Range(partitioner.getToken("0"), partitioner.getToken("zzzzzzz"));
         ranges.add(r);
 
-        boolean result = store.forceCompaction(ranges, new EndPoint("127.0.0.1", 9150), 0, fileList);
-
-        assertEquals(true, result); // some keys should have qualified
-        assertEquals(true, fileList.size() >= 3); //Data, index, filter files
+        List<SSTableReader> fileList = store.forceAntiCompaction(ranges, new EndPoint("127.0.0.1", 9150), 0);
+        assert fileList.size() >= 1;
     }
 
     @Test
