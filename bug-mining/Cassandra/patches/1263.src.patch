diff --git a/CHANGES.txt b/CHANGES.txt
index 3fe79c4e15..1ca3bb782a 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -2,7 +2,7 @@
  * "defragment" rows for name-based queries under STCS (CASSANDRA-2503)
  * cleanup usage of StorageService.setMode() (CASANDRA-3388)
  * Add timing information to cassandra-cli GET/SET/LIST queries (CASSANDRA-3326)
- * Cache for CompressionMetadata objects (CASSANDRA-3427)
+ * Only create one CompressionMetadata object per sstable (CASSANDRA-3427)
  * synchronize BiMap of bootstrapping tokens (CASSANDRA-3417)
  * Avoid large array allocation for compressed chunk offsets (CASSANDRA-3432)
  * fix DecimalType bytebuffer marshalling (CASSANDRA-3421)
diff --git a/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java b/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java
index d3589cb1a3..3bed2c30ab 100644
--- a/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java
+++ b/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java
@@ -34,11 +34,6 @@ public class CompressedRandomAccessReader extends RandomAccessReader
 {
     private static final Logger logger = LoggerFactory.getLogger(CompressedRandomAccessReader.class);
 
-    public static RandomAccessReader open(String dataFilePath, boolean skipIOCache) throws IOException
-    {
-        return open(dataFilePath, CompressionMetadata.get(dataFilePath), skipIOCache);
-    }
-
     public static RandomAccessReader open(String dataFilePath, CompressionMetadata metadata) throws IOException
     {
         return open(dataFilePath, metadata, false);
diff --git a/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java b/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
index a96eb76568..064d247921 100644
--- a/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
+++ b/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
@@ -21,7 +21,6 @@ package org.apache.cassandra.io.compress;
 import java.io.*;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
 
 import org.apache.cassandra.config.ConfigurationException;
 import org.apache.cassandra.io.sstable.Component;
@@ -41,43 +40,23 @@ public class CompressionMetadata
     public final CompressionParameters parameters;
 
     /**
-     * Caches instances of CompressionMetadata.
-     * Each metada holds the chunk offsets index, which is reasonably big for
-     * enough data, so it's an expensive structure. We thus only want one
-     * CompressionMetadata created for each sstable.
-     * Note that we could have a compressionMetadata field in SSTableReader,
-     * but CompressedSegmentFile.Builder needs it before the reader is
-     * created, so it's easier that way.
-     */
-    private final static Map<String, CompressionMetadata> cache = new ConcurrentHashMap<String, CompressionMetadata>();
-
-    /**
-     * Get metadata about given compressed file including uncompressed data length, chunk size
+     * Create metadata about given compressed file including uncompressed data length, chunk size
      * and list of the chunk offsets of the compressed data.
      *
+     * This is an expensive operation! Don't create more than one for each
+     * sstable.
+     *
      * @param dataFilePath Path to the compressed file
      *
      * @return metadata about given compressed file.
      */
-    public static CompressionMetadata get(String dataFilePath)
+    public static CompressionMetadata create(String dataFilePath)
     {
-        CompressionMetadata metadata = cache.get(dataFilePath);
-        if (metadata != null)
-            return metadata;
-
-        // We want this to be relatively fast, because it's called often (for each
-        // range query). On the side, we don't care too much if the initial
-        // creation is no thread-safe, because we'll call this when the
-        // SSTableReader is loaded/created, so we're pretty sure there won't
-        // be any contention. Besides, if we really do create two
-        // CompressionMetadata, it's not the end of the world, so we don't
-        // bother with synchronization
         Descriptor desc = Descriptor.fromFilename(dataFilePath);
+
         try
         {
-            metadata = new CompressionMetadata(desc.filenameFor(Component.COMPRESSION_INFO), new File(dataFilePath).length());
-            cache.put(dataFilePath, metadata);
-            return metadata;
+            return new CompressionMetadata(desc.filenameFor(Component.COMPRESSION_INFO), new File(dataFilePath).length());
         }
         catch (IOException e)
         {
@@ -85,7 +64,7 @@ public class CompressionMetadata
         }
     }
 
-    // This is package protected because of the tests. Don't use, use get() instead.
+    // This is package protected because of the tests.
     CompressionMetadata(String indexFilePath, long compressedLength) throws IOException
     {
         this.indexFilePath = indexFilePath;
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableReader.java b/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
index de58f8a2a3..bc01d78494 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
@@ -44,6 +44,7 @@ import org.apache.cassandra.db.filter.QueryFilter;
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.io.compress.CompressionMetadata;
 import org.apache.cassandra.io.util.*;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.*;
@@ -312,7 +313,7 @@ public class SSTableReader extends SSTable
     {
         boolean cacheLoading = keyCache != null && !keysToLoadInCache.isEmpty();
         SegmentedFile.Builder ibuilder = SegmentedFile.getBuilder(DatabaseDescriptor.getIndexAccessMode());
-        SegmentedFile.Builder dbuilder = (components.contains(Component.COMPRESSION_INFO))
+        SegmentedFile.Builder dbuilder = compression
                                           ? SegmentedFile.getCompressedBuilder()
                                           : SegmentedFile.getBuilder(DatabaseDescriptor.getDiskAccessMode());
 
@@ -399,6 +400,18 @@ public class SSTableReader extends SSTable
         }
     }
 
+    /**
+     * Returns the compression metadata for this sstable.
+     * @throws IllegalStateException if the sstable is not compressed
+     */
+    public CompressionMetadata getCompressionMetadata()
+    {
+        if (!compression)
+            throw new IllegalStateException(this + " is not compressed");
+
+        return ((CompressedSegmentedFile)dfile).metadata;
+    }
+
     /**
      * For testing purposes only.
      */
@@ -894,7 +907,7 @@ public class SSTableReader extends SSTable
     public RandomAccessReader openDataReader(boolean skipIOCache) throws IOException
     {
         return compression
-               ? CompressedRandomAccessReader.open(getFilename(), skipIOCache)
+               ? CompressedRandomAccessReader.open(getFilename(), getCompressionMetadata(), skipIOCache)
                : RandomAccessReader.open(new File(getFilename()), skipIOCache);
     }
 
diff --git a/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java b/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java
index eadf7f218d..9d1345ac21 100644
--- a/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java
+++ b/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java
@@ -26,7 +26,7 @@ import org.apache.cassandra.io.compress.CompressionMetadata;
 
 public class CompressedSegmentedFile extends SegmentedFile
 {
-    private final CompressionMetadata metadata;
+    public final CompressionMetadata metadata;
 
     public CompressedSegmentedFile(String path, CompressionMetadata metadata)
     {
@@ -52,7 +52,7 @@ public class CompressedSegmentedFile extends SegmentedFile
          */
         public SegmentedFile complete(String path)
         {
-            return new CompressedSegmentedFile(path, CompressionMetadata.get(path));
+            return new CompressedSegmentedFile(path, CompressionMetadata.create(path));
         }
     }
 
diff --git a/src/java/org/apache/cassandra/io/util/SegmentedFile.java b/src/java/org/apache/cassandra/io/util/SegmentedFile.java
index 602909fb89..8a9682c697 100644
--- a/src/java/org/apache/cassandra/io/util/SegmentedFile.java
+++ b/src/java/org/apache/cassandra/io/util/SegmentedFile.java
@@ -26,6 +26,7 @@ import java.util.Iterator;
 import java.util.NoSuchElementException;
 
 import org.apache.cassandra.config.Config;
+import org.apache.cassandra.io.compress.CompressionMetadata;
 import org.apache.cassandra.utils.Pair;
 
 /**
diff --git a/src/java/org/apache/cassandra/streaming/FileStreamTask.java b/src/java/org/apache/cassandra/streaming/FileStreamTask.java
index 7c97b29b11..9411b16410 100644
--- a/src/java/org/apache/cassandra/streaming/FileStreamTask.java
+++ b/src/java/org/apache/cassandra/streaming/FileStreamTask.java
@@ -121,7 +121,7 @@ public class FileStreamTask extends WrappedRunnable
 
         // TODO just use a raw RandomAccessFile since we're managing our own buffer here
         RandomAccessReader file = (header.file.sstable.compression) // try to skip kernel page cache if possible
-                                ? CompressedRandomAccessReader.open(header.file.getFilename(), true)
+                                ? CompressedRandomAccessReader.open(header.file.getFilename(), header.file.sstable.getCompressionMetadata(), true)
                                 : RandomAccessReader.open(new File(header.file.getFilename()), true);
 
         // setting up data compression stream
