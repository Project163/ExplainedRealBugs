diff --git a/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java b/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
index e1177a3d37..84f348c4ae 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
@@ -257,7 +257,8 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
 
     private void checkIfNodesRemoved(Topology topology, Set<Node.Id> stillLiveNodes)
     {
-        if (epochs.minEpoch() == topology.epoch()) return;
+        long minEpoch = epochs.minEpoch();
+        if (minEpoch == 0 || topology.epoch() <= minEpoch) return;
         Topology previous = getTopologyForEpoch(topology.epoch() - 1);
         // for all nodes removed, or pending removal, mark them as removed so we don't wait on their replies
         Set<Node.Id> removedNodes = Sets.difference(previous.nodes(), topology.nodes());
@@ -265,7 +266,7 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
         // TODO (desired, efficiency): there should be no need to notify every epoch for every removed node
         for (Node.Id removedNode : removedNodes)
         {
-            if (topology.epoch() >= epochs.minEpoch())
+            if (topology.epoch() >= minEpoch)
                 onNodeRemoved(topology.epoch(), previous, removedNode);
         }
     }
diff --git a/src/java/org/apache/cassandra/service/accord/AccordService.java b/src/java/org/apache/cassandra/service/accord/AccordService.java
index be74ecc321..414f7b6d5a 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordService.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordService.java
@@ -391,20 +391,15 @@ public class AccordService implements IAccordService, Shutdownable
 
             if (remote != null)
                 remote.forEach(configService::reportTopology, highestKnown + 1, Integer.MAX_VALUE);
-            else if (images.isEmpty()) // First boot, single-node cluster
-                configService.reportTopology(AccordTopology.createAccordTopology(metadata));
 
+            // Subscribe to TCM events
             ClusterMetadataService.instance().log().addListener(configService.listener);
-            {
-                metadata = ClusterMetadata.current();
-                highestKnown = configService.currentEpoch();
-                if (metadata.epoch.getEpoch() > highestKnown)
-                {
-                    remote = fetchTopologies(highestKnown + 1);
-                    if (remote != null)
-                        remote.forEach(configService::reportTopology, highestKnown + 1, Integer.MAX_VALUE);
-                }
-            }
+
+            // We report current topology _after_ subscribing to TCM events since in a single-node cluster there
+            // will be no notification about the current epoch, since it's already reported. And in a multi-node cluster
+            // we do not want a race between addinga listener and reporting an epoch.
+            if (remote == null && images.isEmpty())
+                configService.reportTopology(AccordTopology.createAccordTopology(metadata));
 
             WatermarkCollector.fetchAndReportWatermarksAsync(configService());
             configService.unsafeMarkTruncated();
@@ -423,6 +418,15 @@ public class AccordService implements IAccordService, Shutdownable
                 catch (TimeoutException e)
                 {
                     logger.warn("Epoch {} is not ready after waiting for {} seconds", metadata.epoch, (++attempt) * waitSeconds);
+                    // In case there are any gaps, fetch unknown topologies.
+                    metadata = ClusterMetadata.current();
+                    highestKnown = configService.currentEpoch();
+                    if (metadata.epoch.getEpoch() > highestKnown)
+                    {
+                        remote = fetchTopologies(highestKnown + 1);
+                        if (remote != null)
+                            remote.forEach(configService::reportTopology, highestKnown + 1, Integer.MAX_VALUE);
+                    }
                 }
 
                 if (Clock.Global.nanoTime() > deadine)
