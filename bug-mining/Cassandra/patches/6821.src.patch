diff --git a/src/java/org/apache/cassandra/journal/ActiveSegment.java b/src/java/org/apache/cassandra/journal/ActiveSegment.java
index ed94b44c26..85035f4991 100644
--- a/src/java/org/apache/cassandra/journal/ActiveSegment.java
+++ b/src/java/org/apache/cassandra/journal/ActiveSegment.java
@@ -25,9 +25,11 @@ import java.nio.file.StandardOpenOption;
 import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
 import java.util.concurrent.atomic.AtomicLongFieldUpdater;
 import java.util.concurrent.locks.LockSupport;
+import java.util.function.Consumer;
 
 import accord.utils.Invariants;
 import com.codahale.metrics.Timer;
+import com.google.common.annotations.VisibleForTesting;
 import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.utils.*;
 import org.apache.cassandra.utils.concurrent.OpOrder;
@@ -458,6 +460,21 @@ public final class ActiveSegment<K, V> extends Segment<K, V>
             }
         }
 
+        // TODO (required): Find a better way to test unwritten allocations and/or corruption
+        @VisibleForTesting
+        void consumeBufferUnsafe(Consumer<ByteBuffer> fn)
+        {
+            try
+            {
+                fn.accept(buffer);
+            }
+            finally
+            {
+                appendOp.close();
+            }
+        }
+
+
         // Variant of write that does not allocate/return a record pointer
         void writeInternal(K id, ByteBuffer record)
         {
diff --git a/src/java/org/apache/cassandra/journal/EntrySerializer.java b/src/java/org/apache/cassandra/journal/EntrySerializer.java
index 2272188212..2ff680b150 100644
--- a/src/java/org/apache/cassandra/journal/EntrySerializer.java
+++ b/src/java/org/apache/cassandra/journal/EntrySerializer.java
@@ -29,8 +29,21 @@ import java.util.zip.CRC32;
 
 import static org.apache.cassandra.journal.Journal.validateCRC;
 
+/**
+ * Entry format:
+ *
+ *   [Total Size (4 bytes)]
+ *   [Header (variable size)]
+ *   [Header CRC (4 bytes)]
+ *   [Record Data (variable size)]
+ *   [Record CRC (4 bytes)]
+ */
 public final class EntrySerializer
 {
+    /**
+     * NOTE: out buffer already contains 4 bytes specifying the position of the next allocation, which
+     * can be used for determining current allocation size and reading / skipping unwritten allocations.
+     */
     static <K> void write(K key,
                           ByteBuffer record,
                           KeySupport<K> keySupport,
@@ -150,21 +163,27 @@ public final class EntrySerializer
             readValidated(into, from, start, keySupport, userVersion);
             return totalSize;
         }
-        catch (IOException e)
+        catch (Crc.InvalidCrc e)
         {
-            throw new RecoverableJournalError(totalSize, e);
+            throw new MaybeRecoverableJournalError(totalSize, e);
         }
     }
 
-    public static class RecoverableJournalError extends IOException
+    public static class MaybeRecoverableJournalError extends IOException
     {
         public final int knownLength;
 
-        public RecoverableJournalError(int knownLength, Throwable cause)
+        public MaybeRecoverableJournalError(int knownLength, Throwable cause)
         {
             super(cause);
             this.knownLength = knownLength;
         }
+
+        @Override
+        public String getMessage()
+        {
+            return String.format("%s knownLength %d", super.getMessage(), knownLength);
+        }
     }
 
     private static <K> void readValidated(EntryHolder<K> into, ByteBuffer from, int start, KeySupport<K> keySupport, int userVersion)
diff --git a/src/java/org/apache/cassandra/journal/Journal.java b/src/java/org/apache/cassandra/journal/Journal.java
index 68b13d0dc1..727360a3f0 100644
--- a/src/java/org/apache/cassandra/journal/Journal.java
+++ b/src/java/org/apache/cassandra/journal/Journal.java
@@ -18,6 +18,7 @@
 package org.apache.cassandra.journal;
 
 import java.io.IOException;
+import java.nio.ByteBuffer;
 import java.nio.channels.ClosedByInterruptException;
 import java.nio.file.FileStore;
 import java.util.ArrayList;
@@ -29,10 +30,7 @@ import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.concurrent.locks.LockSupport;
-import java.util.function.BooleanSupplier;
-import java.util.function.Function;
-import java.util.function.LongConsumer;
-import java.util.function.Predicate;
+import java.util.function.*;
 import java.util.zip.CRC32;
 
 import com.google.common.annotations.VisibleForTesting;
@@ -498,10 +496,17 @@ public class Journal<K, V> implements Shutdownable
         }
     }
 
+    // TODO (require): Find a better way to test unwritten allocations and/or corruption
+    @VisibleForTesting
+    public void unsafeConsumeBytesForTesting(int entrySize, Consumer<ByteBuffer> corrupt)
+    {
+        allocate(entrySize).consumeBufferUnsafe(corrupt);
+    }
+
     private ActiveSegment<K, V>.Allocation allocate(int entrySize)
     {
-        ActiveSegment<K, V> segment = currentSegment;
 
+        ActiveSegment<K, V> segment = currentSegment;
         ActiveSegment<K, V>.Allocation alloc;
         while (null == (alloc = segment.allocate(entrySize)))
         {
diff --git a/src/java/org/apache/cassandra/journal/StaticSegment.java b/src/java/org/apache/cassandra/journal/StaticSegment.java
index ffd2ed154d..b943ab8104 100644
--- a/src/java/org/apache/cassandra/journal/StaticSegment.java
+++ b/src/java/org/apache/cassandra/journal/StaticSegment.java
@@ -17,6 +17,14 @@
  */
 package org.apache.cassandra.journal;
 
+import org.apache.cassandra.io.util.File;
+import org.apache.cassandra.io.util.FileUtils;
+import org.apache.cassandra.utils.Closeable;
+import org.apache.cassandra.utils.Throwables;
+import org.apache.cassandra.utils.concurrent.Ref;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.MappedByteBuffer;
@@ -27,16 +35,6 @@ import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.cassandra.io.util.File;
-import org.apache.cassandra.io.util.FileUtils;
-import org.apache.cassandra.utils.Closeable;
-import org.apache.cassandra.utils.Throwables;
-import org.apache.cassandra.utils.concurrent.Ref;
-import org.apache.cassandra.utils.memory.MemoryUtil;
-
 /**
  * An immutable data segment that is no longer written to.
  * <p>
@@ -421,11 +419,18 @@ public final class StaticSegment<K, V> extends Segment<K, V>
                     return eof();
                 buffer.position(offset + length);
             }
-            catch (EntrySerializer.RecoverableJournalError e)
+            catch (EntrySerializer.MaybeRecoverableJournalError e)
             {
                 logger.warn("Caught a recoverable journal error, skipping bytes", e);
+                int sizeMarker = buffer.getInt(offset);
+                if (e.knownLength <= Integer.BYTES || sizeMarker != offset + e.knownLength)
+                    throw new JournalReadError(descriptor, file,  e.getCause());
+
+                if (!areAllBytesZero(buffer, offset + Integer.BYTES, e.knownLength - Integer.BYTES))
+                    throw new JournalReadError(descriptor, file, e.getCause());
+
                 buffer.position(offset + e.knownLength);
-                // Recur here, as we anticipate an corrupt or incompletely written entry to be a very rare case.
+                // Recur here, as we anticipate a corrupt or incompletely written entry to be a very rare case.
                 return doAdvance();
             }
             catch (IOException e)
@@ -445,6 +450,25 @@ public final class StaticSegment<K, V> extends Segment<K, V>
         }
     }
 
+    public static boolean areAllBytesZero(ByteBuffer buffer, int start, int length)
+    {
+        int mod8 = (length/8) * 8;
+        // Make sure all bytes are zero
+        for (int i = 0; i < mod8; i += Long.BYTES)
+        {
+            long v = buffer.getLong(start + i);
+            if (v != 0L)
+                return false;
+        }
+        for (int i = mod8; i < length; i++)
+        {
+            byte v = buffer.get(start + i);
+            if (v != 0)
+                return false;
+        }
+        return true;
+    }
+
     public StaticSegment.KeyOrderReader<K> keyOrderReader()
     {
         return new StaticSegment.KeyOrderReader<>(descriptor, keySupport, index.reader());
diff --git a/src/java/org/apache/cassandra/service/accord/AccordJournal.java b/src/java/org/apache/cassandra/service/accord/AccordJournal.java
index 4b8825eb4e..efbb39a0ce 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordJournal.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordJournal.java
@@ -497,6 +497,12 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
         status = Status.STARTED;
     }
 
+    @VisibleForTesting
+    public Journal<JournalKey, Object> unsafeGetJournal()
+    {
+        return journal;
+    }
+
     @Override
     public RangeSearcher rangeSearcher()
     {
diff --git a/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java b/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java
index 0404ea5ad3..b8f7afa725 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java
@@ -583,7 +583,7 @@ public class AccordJournalTable<K extends JournalKey, V> implements RangeSearche
         }
         catch (IOException e)
         {
-            // can only throw if serializer is buggy
+            // can only throw if serializer is buggy or bytes got corrupted
             throw new RuntimeException(e);
         }
     }
diff --git a/test/distributed/org/apache/cassandra/fuzz/topology/AccordBootstrapTest.java b/test/distributed/org/apache/cassandra/fuzz/topology/AccordBootstrapTest.java
index 77aaebfab7..4ddcd03d45 100644
--- a/test/distributed/org/apache/cassandra/fuzz/topology/AccordBootstrapTest.java
+++ b/test/distributed/org/apache/cassandra/fuzz/topology/AccordBootstrapTest.java
@@ -77,7 +77,7 @@ public class AccordBootstrapTest extends FuzzTestBase
 
             HashSet<Integer> downInstances = new HashSet<>();
             withRandom(rng -> {
-                Generator<SchemaSpec> schemaGen = SchemaGenerators.trivialSchema(KEYSPACE, "bootstrap_fuzz", POPULATION,
+                Generator<SchemaSpec> schemaGen = SchemaGenerators.trivialSchema(KEYSPACE, () -> "bootstrap_fuzz", POPULATION,
                                                                                  SchemaSpec.optionsBuilder()
                                                                                            .addWriteTimestamps(false)
                                                                                            .withTransactionalMode(TransactionalMode.full)
diff --git a/test/distributed/org/apache/cassandra/fuzz/topology/AccordBounceTest.java b/test/distributed/org/apache/cassandra/fuzz/topology/AccordBounceTest.java
new file mode 100644
index 0000000000..1e311bf8a5
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/fuzz/topology/AccordBounceTest.java
@@ -0,0 +1,200 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.fuzz.topology;
+
+import accord.primitives.Range;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.shared.ClusterUtils;
+import org.apache.cassandra.distributed.test.log.FuzzTestBase;
+import org.apache.cassandra.harry.SchemaSpec;
+import org.apache.cassandra.harry.dsl.HistoryBuilder;
+import org.apache.cassandra.harry.dsl.ReplayingHistoryBuilder;
+import org.apache.cassandra.harry.execution.InJvmDTestVisitExecutor;
+import org.apache.cassandra.harry.execution.QueryBuildingVisitExecutor;
+import org.apache.cassandra.harry.gen.Generator;
+import org.apache.cassandra.harry.gen.SchemaGenerators;
+import org.apache.cassandra.service.accord.AccordService;
+import org.apache.cassandra.service.consensus.TransactionalMode;
+import org.junit.Test;
+
+import java.util.*;
+import java.util.function.Supplier;
+
+import static org.apache.cassandra.harry.checker.TestHelper.withRandom;
+
+public class AccordBounceTest extends FuzzTestBase
+{
+    private static final int WRITES = 10;
+    private static final int POPULATION = 1000;
+
+    // Test bounce in presence of unwritten allocation.
+    @Test
+    public void emptyJournalAllocationBounceTest() throws Throwable
+    {
+        try (Cluster cluster = init(builder().withNodes(1).start()))
+        {
+            withRandom(rng -> {
+                Generator<SchemaSpec> schemaGen = SchemaGenerators.trivialSchema(KEYSPACE, new Supplier<String>()
+                                                                                 {
+                                                                                     int i = 0;
+
+                                                                                     @Override
+                                                                                     public String get()
+                                                                                     {
+                                                                                         return "bootstrap_fuzz" + (i++);
+                                                                                     }
+                                                                                 }, POPULATION,
+                                                                                 SchemaSpec.optionsBuilder()
+                                                                                         .addWriteTimestamps(false)
+                                                                                         .withTransactionalMode(TransactionalMode.full)
+                );
+
+                List<HistoryBuilder> historyBuilders = new ArrayList<>();
+                for (int i = 0; i < 10; i++)
+                {
+                    SchemaSpec schema = schemaGen.generate(rng);
+                    cluster.schemaChange(schema.compile());
+                    historyBuilders.add(new ReplayingHistoryBuilder(schema.valueGenerators,
+                                                                    hb -> InJvmDTestVisitExecutor.builder()
+                                                                            .consistencyLevel(ConsistencyLevel.QUORUM)
+                                                                            .wrapQueries(QueryBuildingVisitExecutor.WrapQueries.TRANSACTION)
+                                                                            .pageSizeSelector(p -> InJvmDTestVisitExecutor.PageSizeSelector.NO_PAGING)
+                                                                            .build(schema, hb, cluster)));
+                }
+
+                for (HistoryBuilder hb : historyBuilders)
+                    for (int pk = 0; pk < 5; pk++)
+                    {
+                        for (int i = 0; i < 5; i++)
+                            hb.insert(pk);
+                        cluster.get(1).runOnInstance(() -> {
+                            AccordService accordService = (AccordService) AccordService.instance();
+                            accordService.journal().unsafeGetJournal().unsafeConsumeBytesForTesting(200, bb -> {});
+                        });
+                    }
+
+                for (HistoryBuilder hb : historyBuilders)
+                    for (int pk = 0; pk < 5; pk++)
+                        hb.selectPartition(pk);
+
+                ClusterUtils.stopUnchecked(cluster.get(1));
+                cluster.get(1).startup();
+
+                for (HistoryBuilder hb : historyBuilders)
+                    for (int pk = 0; pk < 5; pk++)
+                        hb.selectPartition(pk);
+            });
+        }
+    }
+
+
+    @Test
+    public void commandStoresBounceTest() throws Throwable
+    {
+        try (Cluster cluster = init(builder().withNodes(1).start()))
+        {
+            withRandom(rng -> {
+                Generator<SchemaSpec> schemaGen = SchemaGenerators.trivialSchema(KEYSPACE, new Supplier<String>() {
+                                                                                     int i = 0;
+                                                                                     @Override
+                                                                                     public String get()
+                                                                                     {
+                                                                                         return  "bootstrap_fuzz" + (i++);
+                                                                                     }
+                                                                                 }, POPULATION,
+                                                                                 SchemaSpec.optionsBuilder()
+                                                                                         .addWriteTimestamps(false)
+                                                                                         .withTransactionalMode(TransactionalMode.full)
+                );
+
+                List<HistoryBuilder> historyBuilders = new ArrayList<>();
+                for (int i = 0; i < 10; i++)
+                {
+                    SchemaSpec schema = schemaGen.generate(rng);
+                    cluster.schemaChange(schema.compile());
+                    historyBuilders.add(new ReplayingHistoryBuilder(schema.valueGenerators,
+                                                                    hb -> InJvmDTestVisitExecutor.builder()
+                                                                            .consistencyLevel(ConsistencyLevel.QUORUM)
+                                                                            .wrapQueries(QueryBuildingVisitExecutor.WrapQueries.TRANSACTION)
+                                                                            .pageSizeSelector(p -> InJvmDTestVisitExecutor.PageSizeSelector.NO_PAGING)
+                                                                            .build(schema, hb, cluster)));
+                }
+
+                Runnable writeAndValidate = () -> {
+                    for (HistoryBuilder hb : historyBuilders)
+                        for (int pk = 0; pk < 10; pk++)
+                            for (int i = 0; i < 10; i++)
+                                hb.insert(pk);
+                    for (HistoryBuilder hb : historyBuilders)
+                        for (int pk = 0; pk < 10; pk++)
+                            hb.selectPartition(pk);
+                };
+
+                // Command Stores should not be lost on bounce
+                Map<Integer, Set<String>> before = cluster.get(1).callOnInstance(() -> {
+                    Map<Integer, Set<String>> m = new HashMap<>();
+                    AccordService.instance().node().commandStores().forEach((store, ranges) -> {
+                        Set<String> set = new HashSet<>();
+                        for (Range range : ranges.all())
+                            set.add(range.toString());
+                        m.put(store.id(), set);
+                    });
+                    return m;
+                });
+                for (int i = 0; i < 5; i++)
+                {
+                    writeAndValidate.run();
+                    ClusterUtils.stopUnchecked(cluster.get(1));
+                    cluster.get(1).startup();
+
+                    SchemaSpec schema = schemaGen.generate(rng);
+                    cluster.schemaChange(schema.compile());
+
+                    Map<Integer, Set<String>> after = cluster.get(1).callOnInstance(() -> {
+                        Map<Integer, Set<String>> m = new HashMap<>();
+                        AccordService.instance().node().commandStores().forEach((store, ranges) -> {
+                            Set<String> set = new HashSet<>();
+                            for (Range range : ranges.all())
+                                set.add(range.toString());
+                            m.put(store.id(), set);
+                        });
+                        return m;
+                    });
+                    if (!before.equals(after))
+                    {
+                        for (Integer k : before.keySet())
+                        {
+                            if (!after.containsKey(k))
+                                throw new AssertionError(String.format("%d is contained only in before set with %s", k, before.get(k)));
+
+                            for (String s : before.get(k))
+                            {
+                                if (!after.get(k).contains(s))
+                                    throw new AssertionError(String.format("%d is contained in before set with %s but in after set with %s", k, before.get(k), after.get(k)));
+                            }
+                        }
+                    }
+                    before = after;
+                }
+            });
+        }
+    }
+}
+
diff --git a/test/harry/main/org/apache/cassandra/harry/gen/SchemaGenerators.java b/test/harry/main/org/apache/cassandra/harry/gen/SchemaGenerators.java
index a3433c5b56..4feff7cf26 100644
--- a/test/harry/main/org/apache/cassandra/harry/gen/SchemaGenerators.java
+++ b/test/harry/main/org/apache/cassandra/harry/gen/SchemaGenerators.java
@@ -21,6 +21,7 @@ package org.apache.cassandra.harry.gen;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
+import java.util.function.Supplier;
 
 import org.apache.cassandra.harry.ColumnSpec;
 import org.apache.cassandra.harry.SchemaSpec;
@@ -98,15 +99,15 @@ public class SchemaGenerators
 
     public static Generator<SchemaSpec> trivialSchema(String ks, String table, int population)
     {
-        return trivialSchema(ks, table, population, SchemaSpec.optionsBuilder().build());
+        return trivialSchema(ks, () -> table, population, SchemaSpec.optionsBuilder().build());
     }
 
-    public static Generator<SchemaSpec> trivialSchema(String ks, String table, int population, SchemaSpec.Options options)
+    public static Generator<SchemaSpec> trivialSchema(String ks, Supplier<String> table, int population, SchemaSpec.Options options)
     {
         return (rng) -> {
             return new SchemaSpec(rng.next(),
                                   population,
-                                  ks, table,
+                                  ks, table.get(),
                                   Arrays.asList(ColumnSpec.pk("pk1", ColumnSpec.int64Type, Generators.int64())),
                                   Arrays.asList(ColumnSpec.ck("ck1", ColumnSpec.int64Type, Generators.int64(), false)),
                                   Arrays.asList(ColumnSpec.regularColumn("v1", ColumnSpec.int64Type)),
diff --git a/test/unit/org/apache/cassandra/journal/SegmentTest.java b/test/unit/org/apache/cassandra/journal/SegmentTest.java
index da366d3ea6..6eb8d53ec2 100644
--- a/test/unit/org/apache/cassandra/journal/SegmentTest.java
+++ b/test/unit/org/apache/cassandra/journal/SegmentTest.java
@@ -17,23 +17,22 @@
  */
 package org.apache.cassandra.journal;
 
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.nio.file.Files;
-
-import org.junit.Test;
-
 import org.apache.cassandra.concurrent.ImmediateExecutor;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.io.util.File;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.TimeUUID;
 import org.apache.cassandra.utils.concurrent.OpOrder;
+import org.junit.Assert;
+import org.junit.Test;
 
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+
+import static org.apache.cassandra.harry.checker.TestHelper.withRandom;
 import static org.apache.cassandra.utils.TimeUUID.Generator.nextTimeUUID;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.*;
 
 public class SegmentTest
 {
@@ -187,6 +186,19 @@ public class SegmentTest
         assertFalse(reader.advance());
     }
 
+    @Test
+    public void testAllZeroBytes()
+    {
+        for (int size = 1; size < 200; size++)
+        {
+            ByteBuffer buffer = ByteBuffer.allocate(size);
+            withRandom(rng -> {
+                buffer.put(rng.nextInt(buffer.limit()), (byte) 0xff);
+                Assert.assertFalse(StaticSegment.areAllBytesZero(buffer, 0, buffer.limit()));
+            });
+        }
+    }
+
     private static Params params()
     {
         return TestParams.INSTANCE;
