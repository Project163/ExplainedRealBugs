diff --git a/modules/accord b/modules/accord
index 486cd4bc15..4844e64945 160000
--- a/modules/accord
+++ b/modules/accord
@@ -1 +1 @@
-Subproject commit 486cd4bc15d33500b7b896f9e4691a38d946b679
+Subproject commit 4844e64945b720c802dce11d811e25665f9da826
diff --git a/src/java/org/apache/cassandra/config/AccordSpec.java b/src/java/org/apache/cassandra/config/AccordSpec.java
index 39fefbf187..0350e587c6 100644
--- a/src/java/org/apache/cassandra/config/AccordSpec.java
+++ b/src/java/org/apache/cassandra/config/AccordSpec.java
@@ -90,6 +90,15 @@ public class AccordSpec
     public boolean ephemeralReadEnabled = false;
     public boolean state_cache_listener_jfr_enabled = true;
     public final JournalSpec journal = new JournalSpec();
+    public final MinEpochRetrySpec minEpochSyncRetry = new MinEpochRetrySpec();
+
+    public static class MinEpochRetrySpec extends RetrySpec
+    {
+        public MinEpochRetrySpec()
+        {
+            maxAttempts = new MaxAttempt(3);
+        }
+    }
 
     public static class JournalSpec implements Params
     {
diff --git a/src/java/org/apache/cassandra/config/CassandraRelevantProperties.java b/src/java/org/apache/cassandra/config/CassandraRelevantProperties.java
index 10cf8d6b10..bb7dc7c551 100644
--- a/src/java/org/apache/cassandra/config/CassandraRelevantProperties.java
+++ b/src/java/org/apache/cassandra/config/CassandraRelevantProperties.java
@@ -25,6 +25,7 @@ import javax.annotation.Nullable;
 
 import com.google.common.primitives.Ints;
 
+import accord.utils.Invariants;
 import org.apache.cassandra.db.virtual.LogMessagesTable;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.utils.FBUtilities;
@@ -38,6 +39,9 @@ import static org.apache.cassandra.utils.LocalizeString.toUpperCaseLocalized;
 public enum CassandraRelevantProperties
 {
     ACCORD_AGENT_CLASS("cassandra.test.accord.agent"),
+    ACCORD_KEY_PARANOIA_COSTFACTOR(Invariants.KEY_PARANOIA_COSTFACTOR),
+    ACCORD_KEY_PARANOIA_CPU(Invariants.KEY_PARANOIA_CPU),
+    ACCORD_KEY_PARANOIA_MEMORY(Invariants.KEY_PARANOIA_MEMORY),
     ACCORD_REPAIR_RANGE_STEP_UPDATE_INTERVAL("cassandra.accord.repair.range_step_update_interval", "100"),
     ACQUIRE_RETRY_SECONDS("cassandra.acquire_retry_seconds", "60"),
     ACQUIRE_SLEEP_MS("cassandra.acquire_sleep_ms", "1000"),
diff --git a/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java b/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java
index 950eb8a6da..1320325c38 100644
--- a/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/TransactionStatement.java
@@ -102,6 +102,7 @@ public class TransactionStatement implements CQLStatement.CompositeCQLStatement,
     public static final String NO_CONDITIONS_IN_UPDATES_MESSAGE = "Updates within transactions may not specify their own conditions; %s statement %s";
     public static final String NO_TIMESTAMPS_IN_UPDATES_MESSAGE = "Updates within transactions may not specify custom timestamps; %s statement %s";
     public static final String TRANSACTIONS_DISABLED_ON_TABLE_MESSAGE = "Accord transactions are disabled on table (See transactional_mode in table options); %s statement %s";
+    public static final String TRANSACTIONS_DISABLED_ON_TABLE_BEING_DROPPED_MESSAGE = "Accord transactions are disabled on table (table is being dropped); %s statement %s";
     public static final String NO_COUNTERS_IN_TXNS_MESSAGE = "Counter columns cannot be accessed within a transaction; %s statement %s";
     public static final String EMPTY_TRANSACTION_MESSAGE = "Transaction contains no reads or writes";
     public static final String SELECT_REFS_NEED_COLUMN_MESSAGE = "SELECT references must specify a column.";
@@ -532,6 +533,8 @@ public class TransactionStatement implements CQLStatement.CompositeCQLStatement,
 
                 if (!prepared.table.isAccordEnabled())
                     throw invalidRequest(TRANSACTIONS_DISABLED_ON_TABLE_MESSAGE, "SELECT", prepared.source);
+                if (prepared.table.params.pendingDrop)
+                    throw invalidRequest(TRANSACTIONS_DISABLED_ON_TABLE_BEING_DROPPED_MESSAGE, "SELECT", prepared.source);
                 if (prepared.table.isCounter())
                     throw invalidRequest(NO_COUNTERS_IN_TXNS_MESSAGE, "SELECT", prepared.source);
 
@@ -552,6 +555,8 @@ public class TransactionStatement implements CQLStatement.CompositeCQLStatement,
 
                 if (!prepared.table.isAccordEnabled())
                     throw invalidRequest(TRANSACTIONS_DISABLED_ON_TABLE_MESSAGE, "SELECT", prepared.source);
+                if (prepared.table.params.pendingDrop)
+                    throw invalidRequest(TRANSACTIONS_DISABLED_ON_TABLE_BEING_DROPPED_MESSAGE, "SELECT", prepared.source);
                 if (prepared.table.isCounter())
                     throw invalidRequest(NO_COUNTERS_IN_TXNS_MESSAGE, "SELECT", prepared.source);
 
@@ -578,6 +583,7 @@ public class TransactionStatement implements CQLStatement.CompositeCQLStatement,
 
                 ModificationStatement prepared = parsed.prepare(state, bindVariables);
                 checkTrue(prepared.metadata().isAccordEnabled(), TRANSACTIONS_DISABLED_ON_TABLE_MESSAGE, prepared.type, prepared.source);
+                checkFalse(prepared.metadata().params.pendingDrop, TRANSACTIONS_DISABLED_ON_TABLE_BEING_DROPPED_MESSAGE, prepared.type, prepared.source);
                 checkFalse(prepared.hasConditions(), NO_CONDITIONS_IN_UPDATES_MESSAGE, prepared.type, prepared.source);
                 checkFalse(prepared.isTimestampSet(), NO_TIMESTAMPS_IN_UPDATES_MESSAGE, prepared.type, prepared.source);
 
diff --git a/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java b/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java
index 115a6a3374..3901e65cfb 100644
--- a/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java
@@ -181,7 +181,7 @@ abstract public class AlterSchemaStatement implements CQLStatement.SingleKeyspac
         // cluster, as config can be heterogenous falling back to safe defaults may occur on some nodes.
         ClusterMetadata metadata = ClusterMetadata.current();
         apply(metadata);
-        ClusterMetadata result = Schema.instance.submit(this);
+        ClusterMetadata result = commit(metadata);
 
         KeyspacesDiff diff = Keyspaces.diff(metadata.schema.getKeyspaces(), result.schema.getKeyspaces());
         clientWarnings(diff).forEach(ClientWarn.instance::warn);
@@ -206,6 +206,11 @@ abstract public class AlterSchemaStatement implements CQLStatement.SingleKeyspac
         return new ResultMessage.SchemaChange(schemaChangeEvent(diff));
     }
 
+    protected ClusterMetadata commit(ClusterMetadata metadata)
+    {
+        return Schema.instance.submit(this);
+    }
+
     private void validateKeyspaceName()
     {
         if (!SchemaConstants.isValidName(keyspaceName))
diff --git a/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java b/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
index a7abcbada0..f8a24b0724 100644
--- a/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
@@ -124,6 +124,9 @@ public abstract class AlterTableStatement extends AlterSchemaStatement
             return schema;
         }
 
+        if (table.params.pendingDrop)
+            throw ire("Cannot use ALTER TABLE on a table that is being dropped.");
+
         if (table.isView())
             throw ire("Cannot use ALTER TABLE on a materialized view; use ALTER MATERIALIZED VIEW instead");
 
diff --git a/src/java/org/apache/cassandra/cql3/statements/schema/CreateViewStatement.java b/src/java/org/apache/cassandra/cql3/statements/schema/CreateViewStatement.java
index 40cbee967b..e68e0c003d 100644
--- a/src/java/org/apache/cassandra/cql3/statements/schema/CreateViewStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/CreateViewStatement.java
@@ -173,6 +173,11 @@ public final class CreateViewStatement extends AlterSchemaStatement
                       viewName, tableName);
         }
 
+        if (table.params.pendingDrop)
+            throw ire("Cannot create materialized view '%s' for base table " +
+                      "'%s' as it is being dropped.",
+                      viewName, tableName);
+
         /*
          * Process SELECT clause
          */
diff --git a/src/java/org/apache/cassandra/cql3/statements/schema/DropKeyspaceStatement.java b/src/java/org/apache/cassandra/cql3/statements/schema/DropKeyspaceStatement.java
index e074da54a3..e7159cda8d 100644
--- a/src/java/org/apache/cassandra/cql3/statements/schema/DropKeyspaceStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/DropKeyspaceStatement.java
@@ -17,13 +17,18 @@
  */
 package org.apache.cassandra.cql3.statements.schema;
 
+import java.util.List;
+import java.util.stream.Collectors;
+
 import org.apache.cassandra.audit.AuditLogContext;
 import org.apache.cassandra.audit.AuditLogEntryType;
 import org.apache.cassandra.auth.Permission;
 import org.apache.cassandra.cql3.CQLStatement;
 import org.apache.cassandra.db.guardrails.Guardrails;
+import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.Keyspaces;
 import org.apache.cassandra.schema.Keyspaces.KeyspacesDiff;
+import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.tcm.ClusterMetadata;
 import org.apache.cassandra.transport.Event.SchemaChange;
@@ -45,8 +50,30 @@ public final class DropKeyspaceStatement extends AlterSchemaStatement
         Guardrails.dropKeyspaceEnabled.ensureEnabled(state);
 
         Keyspaces schema = metadata.schema.getKeyspaces();
-        if (schema.containsKeyspace(keyspaceName))
+        KeyspaceMetadata keyspace = schema.getNullable(keyspaceName);
+        if (keyspace != null)
+        {
+            // check that no accord tables in the keyspace are currently in the process of being dropped
+            List<TableMetadata> pendingDrop = keyspace.tables.stream()
+                                                             .filter(t -> t.params.pendingDrop)
+                                                             .collect(Collectors.toList());
+            if (!pendingDrop.isEmpty())
+                throw ire("Cannot drop keyspace '%s' as it contains accord tables which are currently being dropped. " +
+                          "Please wait for those operations to complete before dropping the keyspace. (%s)",
+                          keyspaceName, pendingDrop.stream()
+                                                   .map(Object::toString)
+                                                   .collect(Collectors.joining(",")));
+
+            List<TableMetadata> accordTables = keyspace.tables.stream()
+                                               .filter(TableMetadata::isAccordEnabled)
+                                               .collect(Collectors.toList());
+            if (!accordTables.isEmpty())
+                throw ire("Cannot drop keyspace '%s' as it contains accord tables. (%s)",
+                          keyspaceName, accordTables.stream()
+                                                   .map(Object::toString)
+                                                   .collect(Collectors.joining(",")));
             return schema.without(keyspaceName);
+        }
 
         if (ifExists)
             return schema;
diff --git a/src/java/org/apache/cassandra/cql3/statements/schema/DropTableStatement.java b/src/java/org/apache/cassandra/cql3/statements/schema/DropTableStatement.java
index 56848a8c22..a008b45488 100644
--- a/src/java/org/apache/cassandra/cql3/statements/schema/DropTableStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/DropTableStatement.java
@@ -27,6 +27,10 @@ import org.apache.cassandra.schema.*;
 import org.apache.cassandra.schema.Keyspaces.KeyspacesDiff;
 import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.tcm.ClusterMetadata;
+import org.apache.cassandra.tcm.ClusterMetadataService;
+import org.apache.cassandra.tcm.sequences.DropAccordTable.TableReference;
+import org.apache.cassandra.tcm.sequences.InProgressSequences;
+import org.apache.cassandra.tcm.transformations.PrepareDropAccordTable;
 import org.apache.cassandra.transport.Event.SchemaChange;
 import org.apache.cassandra.transport.Event.SchemaChange.Change;
 import org.apache.cassandra.transport.Event.SchemaChange.Target;
@@ -48,6 +52,26 @@ public final class DropTableStatement extends AlterSchemaStatement
         this.ifExists = ifExists;
     }
 
+    @Override
+    protected ClusterMetadata commit(ClusterMetadata metadata)
+    {
+        KeyspaceMetadata keyspace = metadata.schema.getKeyspaces().getNullable(keyspaceName);
+        TableMetadata table = null == keyspace
+                              ? null
+                              : keyspace.getTableOrViewNullable(tableName);
+        if (table == null // this can happen when ifExists=true... since its already been validated can skip
+            || !table.isAccordEnabled())
+            return super.commit(metadata);
+
+        // Multi-Step Operation
+        // 1) mark the table as pending delete
+        // 2) await for Accord to finish transactions
+        // 3) drop table
+        TableReference ref = TableReference.from(table);
+        ClusterMetadataService.instance().commit(new PrepareDropAccordTable(ref));
+        return InProgressSequences.finishInProgressSequences(ref);
+    }
+
     public Keyspaces apply(ClusterMetadata metadata)
     {
         Guardrails.dropTruncateTableEnabled.ensureEnabled(state);
@@ -70,6 +94,9 @@ public final class DropTableStatement extends AlterSchemaStatement
         if (table.isView())
             throw ire("Cannot use DROP TABLE on a materialized view. Please use DROP MATERIALIZED VIEW instead.");
 
+        if (table.isAccordEnabled() && table.params.pendingDrop)
+            throw ire("Table '%s.%s' is already being dropped", keyspaceName, tableName);
+
         Iterable<ViewMetadata> views = keyspace.views.forTable(table.id);
         if (!isEmpty(views))
         {
diff --git a/src/java/org/apache/cassandra/index/sai/utils/IndexTermType.java b/src/java/org/apache/cassandra/index/sai/utils/IndexTermType.java
index 2f07f76ad4..279f7441e4 100644
--- a/src/java/org/apache/cassandra/index/sai/utils/IndexTermType.java
+++ b/src/java/org/apache/cassandra/index/sai/utils/IndexTermType.java
@@ -788,7 +788,7 @@ public class IndexTermType
                         return CompositeType.getInstance(collection.nameComparator(), collection.valueComparator());
                 }
             default:
-                throw new IllegalArgumentException("Unsupported collection type: " + collection.kind);
+                throw new IllegalArgumentException("Unsupported collection type: " + collection.kind + "; index type: " + indexType.name());
         }
     }
 
diff --git a/src/java/org/apache/cassandra/net/Verb.java b/src/java/org/apache/cassandra/net/Verb.java
index e2d3696a62..42bce20c8c 100644
--- a/src/java/org/apache/cassandra/net/Verb.java
+++ b/src/java/org/apache/cassandra/net/Verb.java
@@ -81,6 +81,7 @@ import org.apache.cassandra.service.SnapshotVerbHandler;
 import org.apache.cassandra.service.accord.AccordService;
 import org.apache.cassandra.service.accord.AccordSyncPropagator;
 import org.apache.cassandra.service.accord.AccordSyncPropagator.Notification;
+import org.apache.cassandra.service.accord.FetchMinEpoch;
 import org.apache.cassandra.service.accord.interop.AccordInteropApply;
 import org.apache.cassandra.service.accord.interop.AccordInteropCommit;
 import org.apache.cassandra.service.accord.interop.AccordInteropRead;
@@ -356,6 +357,8 @@ public enum Verb
     ACCORD_INTEROP_READ_REPAIR_RSP  (157, P2, writeTimeout, IMMEDIATE,          () -> AccordInteropReadRepair.replySerializer,  RESPONSE_HANDLER),
     ACCORD_INTEROP_READ_REPAIR_REQ  (158, P2, writeTimeout, IMMEDIATE,          () -> AccordInteropReadRepair.requestSerializer, AccordService::verbHandlerOrNoop, ACCORD_INTEROP_READ_REPAIR_RSP),
     ACCORD_INTEROP_APPLY_REQ        (160, P2, writeTimeout, IMMEDIATE,          () -> AccordInteropApply.serializer,             AccordService::verbHandlerOrNoop,             ACCORD_APPLY_RSP),
+    ACCORD_FETCH_MIN_EPOCH_RSP      (166, P2, writeTimeout, IMMEDIATE,          () -> FetchMinEpoch.Response.serializer, RESPONSE_HANDLER),
+    ACCORD_FETCH_MIN_EPOCH_REQ      (165, P2, writeTimeout, IMMEDIATE,          () -> FetchMinEpoch.serializer, () -> FetchMinEpoch.handler, ACCORD_FETCH_MIN_EPOCH_RSP),
 
     // generic failure response
     FAILURE_RSP            (99,  P0, noTimeout,       REQUEST_RESPONSE,  () -> RequestFailure.serializer,            RESPONSE_HANDLER                             ),
diff --git a/src/java/org/apache/cassandra/schema/KeyspaceParams.java b/src/java/org/apache/cassandra/schema/KeyspaceParams.java
index fe05b10b5d..09afed84ba 100644
--- a/src/java/org/apache/cassandra/schema/KeyspaceParams.java
+++ b/src/java/org/apache/cassandra/schema/KeyspaceParams.java
@@ -33,7 +33,7 @@ import org.apache.cassandra.tcm.ClusterMetadata;
 import org.apache.cassandra.tcm.serialization.MetadataSerializer;
 import org.apache.cassandra.tcm.serialization.Version;
 
-import static org.apache.cassandra.tcm.serialization.Version.V2;
+import static org.apache.cassandra.tcm.serialization.Version.MIN_ACCORD_VERSION;
 import static org.apache.cassandra.utils.LocalizeString.toLowerCaseLocalized;
 
 /**
@@ -158,7 +158,7 @@ public final class KeyspaceParams
         {
             ReplicationParams.serializer.serialize(t.replication, out, version);
             out.writeBoolean(t.durableWrites);
-            if (version.isAtLeast(V2))
+            if (version.isAtLeast(MIN_ACCORD_VERSION))
                 FastPathStrategy.serializer.serialize(t.fastPath, out, version);
         }
 
@@ -166,7 +166,7 @@ public final class KeyspaceParams
         {
             ReplicationParams params = ReplicationParams.serializer.deserialize(in, version);
             boolean durableWrites = in.readBoolean();
-            FastPathStrategy fastPath = version.isAtLeast(V2)
+            FastPathStrategy fastPath = version.isAtLeast(MIN_ACCORD_VERSION)
                     ? FastPathStrategy.serializer.deserialize(in, version)
                     : FastPathStrategy.simple();
             return new KeyspaceParams(durableWrites, params, fastPath);
@@ -176,7 +176,7 @@ public final class KeyspaceParams
         {
             return ReplicationParams.serializer.serializedSize(t.replication, version) +
                    TypeSizes.sizeof(t.durableWrites) +
-                   (version.isAtLeast(V2) ? FastPathStrategy.serializer.serializedSize(t.fastPath, version) : 0);
+                   (version.isAtLeast(MIN_ACCORD_VERSION) ? FastPathStrategy.serializer.serializedSize(t.fastPath, version) : 0);
         }
     }
 }
diff --git a/src/java/org/apache/cassandra/schema/ReplicationParams.java b/src/java/org/apache/cassandra/schema/ReplicationParams.java
index da44292e0d..40a92c803f 100644
--- a/src/java/org/apache/cassandra/schema/ReplicationParams.java
+++ b/src/java/org/apache/cassandra/schema/ReplicationParams.java
@@ -70,6 +70,11 @@ public final class ReplicationParams
         return new ReplicationParams(strategy.getClass(), strategy.configOptions);
     }
 
+    public static ReplicationParams copy(AbstractReplicationStrategy strategy)
+    {
+        return new ReplicationParams(strategy.getClass(), strategy.configOptions);
+    }
+
     public static ReplicationParams local()
     {
         return new ReplicationParams(LocalStrategy.class, ImmutableMap.of());
diff --git a/src/java/org/apache/cassandra/schema/TableParams.java b/src/java/org/apache/cassandra/schema/TableParams.java
index 8cdc41f687..569fc27b1c 100644
--- a/src/java/org/apache/cassandra/schema/TableParams.java
+++ b/src/java/org/apache/cassandra/schema/TableParams.java
@@ -75,7 +75,8 @@ public final class TableParams
         READ_REPAIR,
         FAST_PATH,
         TRANSACTIONAL_MODE,
-        TRANSACTIONAL_MIGRATION_FROM;
+        TRANSACTIONAL_MIGRATION_FROM,
+        PENDING_DROP;
 
         @Override
         public String toString()
@@ -106,6 +107,7 @@ public final class TableParams
     public final FastPathStrategy fastPath;
     public final TransactionalMode transactionalMode;
     public final TransactionalMigrationFromMode transactionalMigrationFrom;
+    public final boolean pendingDrop;
 
     private TableParams(Builder builder)
     {
@@ -133,6 +135,7 @@ public final class TableParams
         fastPath = builder.fastPath;
         transactionalMode = builder.transactionalMode != null ? builder.transactionalMode : TransactionalMode.off;
         transactionalMigrationFrom = builder.transactionalMigrationFrom;
+        pendingDrop = builder.pendingDrop;
     }
 
     public static Builder builder()
@@ -163,7 +166,8 @@ public final class TableParams
                             .readRepair(params.readRepair)
                             .fastPath(params.fastPath)
                             .transactionalMode(params.transactionalMode)
-                            .transactionalMigrationFrom(params.transactionalMigrationFrom);
+                            .transactionalMigrationFrom(params.transactionalMigrationFrom)
+                            .pendingDrop(params.pendingDrop);
     }
 
     public Builder unbuild()
@@ -257,7 +261,8 @@ public final class TableParams
             && readRepair == p.readRepair
             && fastPath.equals(fastPath)
             && transactionalMode == p.transactionalMode
-            && transactionalMigrationFrom == p.transactionalMigrationFrom;
+            && transactionalMigrationFrom == p.transactionalMigrationFrom
+            && pendingDrop == p.pendingDrop;
     }
 
     @Override
@@ -284,7 +289,8 @@ public final class TableParams
                                 readRepair,
                                 fastPath,
                                 transactionalMode,
-                                transactionalMigrationFrom);
+                                transactionalMigrationFrom,
+                                pendingDrop);
     }
 
     @Override
@@ -314,6 +320,7 @@ public final class TableParams
                           .add(Option.FAST_PATH.toString(), fastPath)
                           .add(Option.TRANSACTIONAL_MODE.toString(), transactionalMode)
                           .add(Option.TRANSACTIONAL_MIGRATION_FROM.toString(), transactionalMigrationFrom)
+                          .add(PENDING_DROP.toString(), pendingDrop)
                           .toString();
     }
 
@@ -401,6 +408,7 @@ public final class TableParams
         private FastPathStrategy fastPath = FastPathStrategy.inheritKeyspace();
         private TransactionalMode transactionalMode = TransactionalMode.off;
         public TransactionalMigrationFromMode transactionalMigrationFrom = TransactionalMigrationFromMode.none;
+        public boolean pendingDrop = false;
 
         public Builder()
         {
@@ -542,6 +550,12 @@ public final class TableParams
             extensions = ImmutableMap.copyOf(val);
             return this;
         }
+
+        public Builder pendingDrop(boolean pendingDrop)
+        {
+            this.pendingDrop = pendingDrop;
+            return this;
+        }
     }
 
     public static class Serializer implements MetadataSerializer<TableParams>
@@ -559,10 +573,7 @@ public final class TableParams
             out.writeUTF(t.speculativeRetry.toString());
             out.writeUTF(t.additionalWritePolicy.toString());
             if (version.isAtLeast(Version.V2))
-            {
                 out.writeUTF(t.memtable.configurationKey());
-                FastPathStrategy.serializer.serialize(t.fastPath, out, version);
-            }
             serializeMap(t.caching.asMap(), out);
             serializeMap(t.compaction.asMap(), out);
             serializeMap(t.compression.asMap(), out);
@@ -573,8 +584,13 @@ public final class TableParams
             {
                 out.writeBoolean(t.allowAutoSnapshot);
                 out.writeBoolean(t.incrementalBackups);
+            }
+            if (version.isAtLeast(Version.MIN_ACCORD_VERSION))
+            {
+                FastPathStrategy.serializer.serialize(t.fastPath, out, version);
                 out.writeInt(t.transactionalMode.ordinal());
                 out.writeInt(t.transactionalMigrationFrom.ordinal());
+                out.writeBoolean(t.pendingDrop);
             }
         }
 
@@ -592,7 +608,6 @@ public final class TableParams
                    .speculativeRetry(SpeculativeRetryPolicy.fromString(in.readUTF()))
                    .additionalWritePolicy(SpeculativeRetryPolicy.fromString(in.readUTF()))
                    .memtable(version.isAtLeast(Version.V2) ? MemtableParams.get(in.readUTF()) : MemtableParams.DEFAULT)
-                   .fastPath(version.isAtLeast(Version.V2) ? FastPathStrategy.serializer.deserialize(in, version) : FastPathStrategy.simple())
                    .caching(CachingParams.fromMap(deserializeMap(in)))
                    .compaction(CompactionParams.fromMap(deserializeMap(in)))
                    .compression(CompressionParams.fromMap(deserializeMap(in)))
@@ -600,15 +615,20 @@ public final class TableParams
                    .cdc(in.readBoolean())
                    .readRepair(ReadRepairStrategy.fromString(in.readUTF()))
                    .allowAutoSnapshot(!version.isAtLeast(Version.V4) || in.readBoolean())
-                   .incrementalBackups(!version.isAtLeast(Version.V4) || in.readBoolean())
-                   .transactionalMode(version.isAtLeast(Version.V4) ? TransactionalMode.fromOrdinal(in.readInt()) : TransactionalMode.off)
-                   .transactionalMigrationFrom(version.isAtLeast(Version.V4) ? TransactionalMigrationFromMode.fromOrdinal(in.readInt()) : TransactionalMigrationFromMode.off);
+                   .incrementalBackups(!version.isAtLeast(Version.V4) || in.readBoolean());
+            if (version.isAtLeast(Version.MIN_ACCORD_VERSION))
+            {
+                builder.fastPath(FastPathStrategy.serializer.deserialize(in, version))
+                       .transactionalMode(TransactionalMode.fromOrdinal(in.readInt()))
+                       .transactionalMigrationFrom(TransactionalMigrationFromMode.fromOrdinal(in.readInt()))
+                       .pendingDrop(in.readBoolean());
+            }
             return builder.build();
         }
 
         public long serializedSize(TableParams t, Version version)
         {
-            return sizeof(t.comment) +
+            long size = sizeof(t.comment) +
                    sizeof(t.bloomFilterFpChance) +
                    sizeof(t.crcCheckChance) +
                    sizeof(t.gcGraceSeconds) +
@@ -619,7 +639,6 @@ public final class TableParams
                    sizeof(t.speculativeRetry.toString()) +
                    sizeof(t.additionalWritePolicy.toString()) +
                    (version.isAtLeast(Version.V2) ? sizeof(t.memtable.configurationKey()) : 0) +
-                   (version.isAtLeast(Version.V2) ? FastPathStrategy.serializer.serializedSize(t.fastPath, version) : 0) +
                    serializedSizeMap(t.caching.asMap()) +
                    serializedSizeMap(t.compaction.asMap()) +
                    serializedSizeMap(t.compression.asMap()) +
@@ -627,9 +646,15 @@ public final class TableParams
                    sizeof(t.cdc) +
                    sizeof(t.readRepair.name()) +
                    (version.isAtLeast(Version.V4) ? sizeof(t.allowAutoSnapshot) : 0) +
-                   (version.isAtLeast(Version.V4) ? sizeof(t.incrementalBackups) : 0) +
-                   (version.isAtLeast(Version.V4) ? sizeof(t.transactionalMode.ordinal()) : 0) +
-                   (version.isAtLeast(Version.V4) ? sizeof(t.transactionalMigrationFrom.ordinal()) : 0);
+                   (version.isAtLeast(Version.V4) ? sizeof(t.incrementalBackups) : 0);
+            if (version.isAtLeast(Version.MIN_ACCORD_VERSION))
+            {
+                size += FastPathStrategy.serializer.serializedSize(t.fastPath, version) +
+                        sizeof(t.transactionalMode.ordinal()) +
+                        sizeof(t.transactionalMigrationFrom.ordinal()) +
+                        sizeof(t.pendingDrop);
+            }
+            return size;
         }
 
         private void serializeMap(Map<String, String> map, DataOutputPlus out) throws IOException
diff --git a/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java b/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
index 1e6cb1d769..e0d1d84020 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
@@ -19,8 +19,10 @@
 package org.apache.cassandra.service.accord;
 
 import java.util.Objects;
+import java.util.OptionalLong;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
+import java.util.function.Consumer;
 import java.util.stream.Collectors;
 import javax.annotation.Nullable;
 
@@ -30,6 +32,7 @@ import com.google.common.collect.Sets;
 import accord.impl.AbstractConfigurationService;
 import accord.local.Node;
 import accord.primitives.Ranges;
+import accord.topology.Shard;
 import accord.topology.Topology;
 import accord.utils.Invariants;
 import accord.utils.async.AsyncResult;
@@ -207,12 +210,18 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
         return new EpochHistory();
     }
 
+    @VisibleForTesting
     public synchronized void start()
+    {
+        start(ignore -> {});
+    }
+
+    public synchronized void start(Consumer<OptionalLong> callback)
     {
         Invariants.checkState(state == State.INITIALIZED, "Expected state to be INITIALIZED but was %s", state);
         state = State.LOADING;
-        updateMapping(ClusterMetadata.current());
         EndpointMapping snapshot = mapping;
+        //TODO (restart): if there are topologies loaded then there is likely failures if reporting is needed, as mapping is not setup yet
         diskState = diskStateManager.loadTopologies(((epoch, topology, syncStatus, pendingSyncNotify, remoteSyncComplete, closed, redundant) -> {
             if (topology != null)
                 reportTopology(topology, syncStatus == SyncStatus.NOT_STARTED);
@@ -230,6 +239,7 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
             receiveRedundant(redundant, epoch);
         }));
         state = State.STARTED;
+        callback.accept(diskState.isEmpty() ? OptionalLong.empty() : OptionalLong.of(diskState.maxEpoch));
         ClusterMetadataService.instance().log().addListener(this);
     }
 
@@ -293,27 +303,54 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
 
     private void reportMetadata(ClusterMetadata metadata)
     {
-        Stage.MISC.submit(() -> {
-            synchronized (AccordConfigurationService.this)
+        Stage.MISC.submit(() -> reportMetadataInternal(metadata));
+    }
+
+    synchronized void reportMetadataInternal(ClusterMetadata metadata)
+    {
+        updateMapping(metadata);
+        Topology topology = AccordTopology.createAccordTopology(metadata);
+        if (Invariants.isParanoid())
+        {
+            for (Node.Id node : topology.nodes())
             {
-                updateMapping(metadata);
-                Topology topology = AccordTopology.createAccordTopology(metadata);
-                Topology current = isEmpty() ? Topology.EMPTY : currentTopology();
-                reportTopology(topology);
-                Sets.SetView<Node.Id> removedNodes = Sets.difference(current.nodes(), topology.nodes());
-                if (!removedNodes.isEmpty())
-                    onNodesRemoved(topology.epoch(), removedNodes);
+                if (mapping.mappedEndpointOrNull(node) == null)
+                    throw new IllegalStateException("Epoch " + topology.epoch() + " has node " + node + " but mapping does not!");
             }
-        });
+        }
+        Topology current = isEmpty() ? Topology.EMPTY : currentTopology();
+        reportTopology(topology);
+        // for all nodes removed, or pending removal, mark them as removed so we don't wait on their replies
+        Sets.SetView<Node.Id> removedNodes = Sets.difference(current.nodes(), topology.nodes());
+        if (!removedNodes.isEmpty())
+        {
+            onNodesRemoved(topology.epoch(), removedNodes);
+            for (Node.Id node : removedNodes)
+            {
+                if (shareShard(current, node, localId))
+                    AccordService.instance().tryMarkRemoved(current, node);
+            }
+        }
+    }
+
+    private static boolean shareShard(Topology current, Node.Id target, Node.Id self)
+    {
+        for (Shard shard : current.shards())
+        {
+            if (!shard.contains(target)) continue;
+            if (shard.contains(self)) return true;
+        }
+        return false;
     }
 
-    private synchronized void onNodesRemoved(long epoch, Set<Node.Id> removed)
+    public synchronized void onNodesRemoved(long epoch, Set<Node.Id> removed)
     {
+        if (removed.isEmpty()) return;
         syncPropagator.onNodesRemoved(removed);
         for (long oldEpoch : nonCompletedEpochsBefore(epoch))
         {
             for (Node.Id node : removed)
-                receiveRemoteSyncComplete(node, oldEpoch);
+                receiveRemoteSyncCompletePreListenerNotify(node, oldEpoch);
         }
         listeners.forEach(l -> l.onRemoveNodes(epoch, removed));
     }
@@ -350,7 +387,6 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
     @Override
     public void notifyPostCommit(ClusterMetadata prev, ClusterMetadata next, boolean fromSnapshot)
     {
-        maybeReportMetadata(prev);
         maybeReportMetadata(next);
     }
 
diff --git a/src/java/org/apache/cassandra/service/accord/AccordSafeCommandStore.java b/src/java/org/apache/cassandra/service/accord/AccordSafeCommandStore.java
index 2b60bfcd51..8dabbc7bb3 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordSafeCommandStore.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordSafeCommandStore.java
@@ -20,9 +20,12 @@ package org.apache.cassandra.service.accord;
 
 import java.util.Map;
 import java.util.NavigableMap;
+import java.util.Set;
 import java.util.function.BiFunction;
 import javax.annotation.Nullable;
 
+import com.google.common.annotations.VisibleForTesting;
+
 import accord.api.Agent;
 import accord.api.DataStore;
 import accord.api.Key;
@@ -79,6 +82,12 @@ public class AccordSafeCommandStore extends AbstractSafeCommandStore<AccordSafeC
         return new AccordSafeCommandStore(preLoadContext, commands, timestampsForKey, commandsForKey, commandsForRanges, commandStore);
     }
 
+    @VisibleForTesting
+    public Set<Key> commandsForKeysKeys()
+    {
+        return commandsForKeys.keySet();
+    }
+
     @Override
     protected AccordSafeCommand getCommandInternal(TxnId txnId)
     {
diff --git a/src/java/org/apache/cassandra/service/accord/AccordService.java b/src/java/org/apache/cassandra/service/accord/AccordService.java
index 9026de81a9..a90ca24351 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordService.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordService.java
@@ -18,10 +18,15 @@
 
 package org.apache.cassandra.service.accord;
 
+import java.math.BigInteger;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
+import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeUnit;
@@ -38,79 +43,102 @@ import javax.annotation.concurrent.GuardedBy;
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Stopwatch;
 import com.google.common.base.Throwables;
+import com.google.common.collect.Sets;
 import com.google.common.primitives.Ints;
+
+import accord.coordinate.Barrier;
+import accord.coordinate.CoordinateSyncPoint;
+import accord.coordinate.Exhausted;
+import accord.coordinate.FailureAccumulator;
+import accord.coordinate.Invalidated;
+import accord.coordinate.TopologyMismatch;
+import accord.impl.CoordinateDurabilityScheduling;
+import accord.local.Command;
+import accord.local.PreLoadContext;
+import accord.primitives.Ranges;
+import accord.primitives.SyncPoint;
+import accord.topology.Topology;
+import org.apache.cassandra.config.CassandraRelevantProperties;
+import org.apache.cassandra.cql3.statements.RequestValidations;
+import org.apache.cassandra.exceptions.RequestExecutionException;
+import org.apache.cassandra.repair.SharedContext;
+import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.locator.InetAddressAndPort;
+import org.apache.cassandra.service.accord.exceptions.ReadExhaustedException;
+import org.apache.cassandra.service.accord.interop.AccordInteropAdapter.AccordInteropFactory;
+import org.apache.cassandra.tcm.ClusterMetadata;
+import org.apache.cassandra.service.accord.repair.RepairSyncPointAdapter;
+import org.apache.cassandra.tcm.ClusterMetadataService;
+import org.apache.cassandra.tcm.ownership.DataPlacement;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import accord.api.BarrierType;
 import accord.api.LocalConfig;
 import accord.api.Result;
-import accord.coordinate.Barrier;
-import accord.coordinate.CoordinateSyncPoint;
 import accord.coordinate.CoordinationFailed;
-import accord.coordinate.Exhausted;
-import accord.coordinate.FailureAccumulator;
 import accord.coordinate.Preempted;
 import accord.coordinate.Timeout;
-import accord.coordinate.TopologyMismatch;
+import accord.api.RoutingKey;
+import accord.coordinate.ExecuteSyncPoint;
+import accord.coordinate.tracking.AllTracker;
+import accord.coordinate.tracking.RequestStatus;
 import accord.impl.AbstractConfigurationService;
-import accord.impl.CoordinateDurabilityScheduling;
 import accord.impl.DefaultLocalListeners;
 import accord.impl.DefaultRemoteListeners;
 import accord.impl.DefaultRequestTimeouts;
 import accord.impl.SizeOfIntersectionSorter;
-import accord.local.Command;
-import accord.local.CommandStore;
 import accord.impl.progresslog.DefaultProgressLogs;
+import accord.local.CommandStore;
 import accord.local.CommandStores;
 import accord.local.DurableBefore;
 import accord.local.KeyHistory;
 import accord.local.Node;
 import accord.local.Node.Id;
 import accord.local.NodeTimeService;
-import accord.local.PreLoadContext;
 import accord.local.RedundantBefore;
 import accord.local.SaveStatus;
 import accord.local.ShardDistributor.EvenSplit;
 import accord.local.Status;
 import accord.local.cfk.CommandsForKey;
+import accord.messages.Callback;
+import accord.messages.ReadData;
 import accord.messages.Request;
+import accord.messages.WaitUntilApplied;
 import accord.primitives.Keys;
-import accord.primitives.Ranges;
 import accord.primitives.Seekable;
 import accord.primitives.Seekables;
-import accord.primitives.SyncPoint;
 import accord.primitives.Timestamp;
 import accord.primitives.Txn;
 import accord.primitives.Txn.Kind;
 import accord.primitives.TxnId;
+import accord.topology.Topologies;
 import accord.topology.TopologyManager;
 import accord.utils.DefaultRandom;
 import accord.utils.Invariants;
 import accord.utils.async.AsyncChain;
 import accord.utils.async.AsyncChains;
 import accord.utils.async.AsyncResult;
+import accord.utils.async.AsyncResults;
 import org.agrona.collections.Int2ObjectHashMap;
 import org.apache.cassandra.concurrent.Shutdownable;
-import org.apache.cassandra.config.CassandraRelevantProperties;
 import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.cql3.statements.RequestValidations;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.ConsistencyLevel;
 import org.apache.cassandra.db.WriteType;
+import org.apache.cassandra.dht.AccordSplitter;
 import org.apache.cassandra.exceptions.ReadTimeoutException;
-import org.apache.cassandra.exceptions.RequestExecutionException;
 import org.apache.cassandra.exceptions.RequestTimeoutException;
 import org.apache.cassandra.exceptions.WriteTimeoutException;
-import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.metrics.AccordClientRequestMetrics;
 import org.apache.cassandra.net.IVerbHandler;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.MessageDelivery;
 import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.TableId;
-import org.apache.cassandra.schema.TableMetadata;
-import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.service.accord.AccordSyncPropagator.Notification;
 import org.apache.cassandra.service.accord.api.AccordAgent;
 import org.apache.cassandra.service.accord.api.AccordRoutingKey.KeyspaceSplitter;
@@ -118,20 +146,15 @@ import org.apache.cassandra.service.accord.api.AccordScheduler;
 import org.apache.cassandra.service.accord.api.AccordTopologySorter;
 import org.apache.cassandra.service.accord.api.CompositeTopologySorter;
 import org.apache.cassandra.service.accord.api.PartitionKey;
-import org.apache.cassandra.service.accord.exceptions.ReadExhaustedException;
 import org.apache.cassandra.service.accord.exceptions.ReadPreemptedException;
 import org.apache.cassandra.service.accord.exceptions.WritePreemptedException;
-import org.apache.cassandra.service.accord.interop.AccordInteropAdapter.AccordInteropFactory;
-import org.apache.cassandra.service.accord.repair.RepairSyncPointAdapter;
 import org.apache.cassandra.service.accord.txn.TxnResult;
 import org.apache.cassandra.service.consensus.TransactionalMode;
 import org.apache.cassandra.service.consensus.migration.TableMigrationState;
-import org.apache.cassandra.tcm.ClusterMetadata;
-import org.apache.cassandra.tcm.ClusterMetadataService;
 import org.apache.cassandra.tcm.Epoch;
 import org.apache.cassandra.tcm.membership.NodeId;
-import org.apache.cassandra.transport.Dispatcher;
 import org.apache.cassandra.tracing.Tracing;
+import org.apache.cassandra.transport.Dispatcher;
 import org.apache.cassandra.utils.Blocking;
 import org.apache.cassandra.utils.Clock;
 import org.apache.cassandra.utils.ExecutorUtils;
@@ -276,6 +299,19 @@ public class AccordService implements IAccordService, Shutdownable
         {
             return Collections.emptyList();
         }
+
+        @Nullable
+        @Override
+        public Long minEpoch(Collection<TokenRange> ranges)
+        {
+            return null;
+        }
+
+        @Override
+        public void tryMarkRemoved(Topology topology, Id node)
+        {
+
+        }
     };
 
     private static volatile IAccordService instance = null;
@@ -350,6 +386,7 @@ public class AccordService implements IAccordService, Shutdownable
         Invariants.checkState(localId != null, "static localId must be set before instantiating AccordService");
         logger.info("Starting accord with nodeId {}", localId);
         AccordAgent agent = FBUtilities.construct(CassandraRelevantProperties.ACCORD_AGENT_CLASS.getString(AccordAgent.class.getName()), "AccordAgent");
+        agent.setNodeId(localId);
         this.configService = new AccordConfigurationService(localId);
         this.fastPathCoordinator = AccordFastPathCoordinator.create(localId, configService);
         this.messageSink = new AccordMessageSink(agent, configService);
@@ -387,10 +424,51 @@ public class AccordService implements IAccordService, Shutdownable
         if (state != State.INIT)
             return;
         journal.start(node);
-        configService.start();
+        ClusterMetadataService cms = ClusterMetadataService.instance();
+        class Ref { List<ClusterMetadata> historic = Collections.emptyList();}
+        Ref ref = new Ref();
+        configService.start((optMaxEpoch -> {
+            // when max epoch isn't know, this means the node started for the first time; check cluster's min epoch
+            // when max epoch is known, then there is no reason to discover min epoch (we already did it)
+            if (optMaxEpoch.isPresent()) return;
+            List<ClusterMetadata> historic = ref.historic = discoverHistoric(node, cms);
+            for (ClusterMetadata m : historic)
+                configService.reportMetadataInternal(m);
+        }));
+        ClusterMetadata current = cms.metadata();
+        if (!ref.historic.isEmpty())
+        {
+            List<ClusterMetadata> historic = ref.historic;
+            long lastHistoric = ref.historic.get(historic.size() - 1).epoch.getEpoch();
+            if (lastHistoric + 1 < current.epoch.getEpoch())
+            {
+                // new epochs added while loading... load the deltas
+                for (ClusterMetadata metadata : tcmLoadRange(lastHistoric + 1, current.epoch.getEpoch()))
+                {
+                    historic.add(metadata);
+                    configService.reportMetadataInternal(metadata);
+                }
+            }
+
+            // sync doesn't happen when this node isn't in the epoch
+            //TODO (now, correctness): sync points use "closed" and not "syncComplete", so need to call TM.epochRedundant or TM.onEpochClosed
+            // epochRedundant implies all txn that have been proposed for this epoch have been executed "globally" - we don't have this knowlege
+            // epochClosed implies no "new" txn can be proposed
+            for (ClusterMetadata m : historic)
+            {
+                Topology t = AccordTopology.createAccordTopology(m);
+                long epoch = t.epoch();
+                for (Id id : t.nodes())
+                    node.onRemoteSyncComplete(id, epoch);
+                //TODO (correctness): is this true?
+                node.onEpochClosed(t.ranges(), t.epoch());
+                node.onEpochRedundant(t.ranges(), t.epoch());
+            }
+        }
+        configService.reportMetadataInternal(current);
 
         fastPathCoordinator.start();
-        ClusterMetadataService.instance().log().addListener(fastPathCoordinator);
+        cms.log().addListener(fastPathCoordinator);
         durabilityScheduling.setGlobalCycleTime(Ints.checkedCast(DatabaseDescriptor.getAccordGlobalDurabilityCycle(SECONDS)), SECONDS);
         durabilityScheduling.setShardCycleTime(Ints.checkedCast(DatabaseDescriptor.getAccordShardDurabilityCycle(SECONDS)), SECONDS);
         durabilityScheduling.setTxnIdLag(Ints.checkedCast(DatabaseDescriptor.getAccordScheduleDurabilityTxnIdLag(SECONDS)), TimeUnit.SECONDS);
@@ -399,6 +477,74 @@ public class AccordService implements IAccordService, Shutdownable
         state = State.STARTED;
     }
 
+    private List<ClusterMetadata> discoverHistoric(Node node, ClusterMetadataService cms)
+    {
+        ClusterMetadata current = cms.metadata();
+        Topology topology = AccordTopology.createAccordTopology(current);
+        Ranges localRanges = topology.rangesForNode(node.id());
+        if (!localRanges.isEmpty()) // already joined, nothing to see here
+            return Collections.emptyList();
+
+        Map<InetAddressAndPort, Set<TokenRange>> peers = new HashMap<>();
+        for (KeyspaceMetadata keyspace : current.schema.getKeyspaces())
+        {
+            List<TableMetadata> tables = keyspace.tables.stream().filter(TableMetadata::requiresAccordSupport).collect(Collectors.toList());
+            if (tables.isEmpty())
+                continue;
+            DataPlacement placement = current.placements.get(keyspace.params.replication);
+            DataPlacement whenSettled = current.writePlacementAllSettled(keyspace);
+            Sets.SetView<InetAddressAndPort> alive = Sets.intersection(whenSettled.writes.byEndpoint().keySet(), placement.writes.byEndpoint().keySet());
+            InetAddressAndPort self = FBUtilities.getBroadcastAddressAndPort();
+            whenSettled.writes.forEach((range, group) -> {
+                if (group.endpoints().contains(self))
+                {
+                    for (InetAddressAndPort peer : group.endpoints())
+                    {
+                        if (!alive.contains(peer)) continue;
+                        for (TableMetadata table : tables)
+                            peers.computeIfAbsent(peer, i -> new HashSet<>()).add(AccordTopology.fullRange(table.id));
+                    }
+                }
+            });
+        }
+        if (peers.isEmpty())
+            return Collections.emptyList();
+
+        Long minEpoch = findMinEpoch(SharedContext.Global.instance, peers);
+        if (minEpoch == null)
+            return Collections.emptyList();
+        return tcmLoadRange(minEpoch, current.epoch.getEpoch());
+    }
+
+    private static List<ClusterMetadata> tcmLoadRange(long min, long max)
+    {
+        List<ClusterMetadata> afterLoad = ClusterMetadataService.instance().processor().reconstructFull(Epoch.create(min - 1), Epoch.create(max));
+        while (!afterLoad.isEmpty() && afterLoad.get(0).epoch.getEpoch() < min)
+            afterLoad.remove(0);
+        assert !afterLoad.isEmpty() : String.format("TCM was unable to return the needed epochs: %d -> %d", min, max);
+        assert afterLoad.get(0).epoch.getEpoch() == min : String.format("Unexpected epoch: expected %d but given %d", min, afterLoad.get(0).epoch.getEpoch());
+        assert afterLoad.get(afterLoad.size() - 1).epoch.getEpoch() == max : String.format("Unexpected epoch: expected %d but given %d", max, afterLoad.get(afterLoad.size() - 1).epoch.getEpoch());
+        return afterLoad;
+    }
+
+    @VisibleForTesting
+    static Long findMinEpoch(SharedContext context, Map<InetAddressAndPort, Set<TokenRange>> peers)
+    {
+        try
+        {
+            return FetchMinEpoch.fetch(context, peers).get();
+        }
+        catch (InterruptedException e)
+        {
+            Thread.currentThread().interrupt();
+            throw new UncheckedInterruptedException(e);
+        }
+        catch (ExecutionException e)
+        {
+            throw new RuntimeException(e.getCause());
+        }
+    }
+
     @Override
     public IVerbHandler<? extends Request> verbHandler()
     {
@@ -437,12 +583,14 @@ public class AccordService implements IAccordService, Shutdownable
             if (cause instanceof Timeout)
             {
                 TxnId txnId = ((Timeout) cause).txnId();
+                ((AccordAgent) node.agent()).onFailedBarrier(txnId, keysOrRanges, cause);
                 metrics.timeouts.mark();
                 throw newBarrierTimeout(txnId, barrierType, isForWrite, keysOrRanges);
             }
             if (cause instanceof Preempted)
             {
                 TxnId txnId = ((Preempted) cause).txnId();
+                ((AccordAgent) node.agent()).onFailedBarrier(txnId, keysOrRanges, cause);
                 //TODO need to improve
                 // Coordinator "could" query the accord state to see whats going on but that doesn't exist yet.
                 // Protocol also doesn't have a way to denote "unknown" outcome, so using a timeout as the closest match
@@ -451,6 +599,7 @@ public class AccordService implements IAccordService, Shutdownable
             if (cause instanceof Exhausted)
             {
                 TxnId txnId = ((Exhausted) cause).txnId();
+                ((AccordAgent) node.agent()).onFailedBarrier(txnId, keysOrRanges, cause);
                 // this case happens when a non-timeout exception is seen, and we are unable to move forward
                 metrics.failures.mark();
                 throw newBarrierExhausted(txnId, barrierType, isForWrite, keysOrRanges);
@@ -973,6 +1122,30 @@ public class AccordService implements IAccordService, Shutdownable
         return cmdTxnState.build();
     }
 
+    @Nullable
+    @Override
+    public Long minEpoch(Collection<TokenRange> ranges)
+    {
+        return node.topology().minEpoch();
+    }
+
+    @Override
+    public void tryMarkRemoved(Topology topology, Id target)
+    {
+        if (node.commandStores().count() == 0) return; // when starting up stores can be empty, so ignore
+        Ranges ranges = topology.rangesForNode(target);
+        if (ranges.isEmpty()) return;
+        tryMarkRemoved(ranges, 0).begin(node().agent());
+    }
+
+    private AsyncChain<SyncPoint<Ranges>> tryMarkRemoved(Ranges ranges, int attempt)
+    {
+        return CoordinateSyncPoint.exclusive(node, ranges)
+                                  .recover(t ->
+                                           //TODO (operability): make this configurable / monitorable?
+                                           attempt <= 3 && t instanceof Invalidated || t instanceof Preempted || t instanceof Timeout ? tryMarkRemoved(ranges, attempt + 1) : null);
+    }
+
     public Node node()
     {
         return node;
@@ -1073,4 +1246,227 @@ public class AccordService implements IAccordService, Shutdownable
         }));
         return new CompactionInfo(redundantBefores, ranges, durableBefore.get());
     }
+
+    @Override
+    public void awaitTableDrop(TableId id)
+    {
+        // Need to make sure no existing txn are still being processed for this table... this is only used by DROP TABLE so NEW txn are expected to be blocked, so just need to "wait" for existing ones to complete
+        Topology topology = node.topology().current();
+        List<TokenRange> ranges = topology.reduce(new ArrayList<>(),
+                                                  s -> ((TokenRange) s.range).table().equals(id),
+                                                  (accum, s) -> {
+                                                      accum.add((TokenRange) s.range);
+                                                      return accum;
+                                                  });
+        if (ranges.isEmpty()) return; // nothing to see here
+
+        ColumnFamilyStore cfs = Schema.instance.getColumnFamilyStoreInstance(id);
+        Invariants.checkState(cfs != null, "Unable to find table %s", id);
+        BigInteger targetSplitSize = BigInteger.valueOf(Math.max(1, cfs.estimateKeys() / 1_000_000));
+
+        List<AsyncChain<?>> syncs = new ArrayList<>(ranges.size());
+        for (TokenRange range : ranges)
+            syncs.add(awaitTableDrop(cfs, range, targetSplitSize));
+        AsyncChain<Object[]> all = AsyncChains.allOf(syncs);
+        try
+        {
+            AsyncChains.getBlocking(all);
+        }
+        catch (InterruptedException e)
+        {
+            Thread.currentThread().interrupt();
+            throw new UncheckedInterruptedException(e);
+        }
+        catch (ExecutionException e)
+        {
+            throw new RuntimeException(e);
+        }
+    }
+
+    private AsyncChain<?> awaitTableDrop(ColumnFamilyStore cfs, TokenRange range, BigInteger targetSplitSize)
+    {
+        List<TokenRange> splits = split(cfs, range, targetSplitSize);
+        List<AsyncChain<?>> syncs = new ArrayList<>(splits.size());
+        for (TokenRange tr : splits)
+            syncs.add(awaitTableDropSubRange(tr));
+        return AsyncChains.allOf(syncs);
+    }
+
+    private List<TokenRange> split(ColumnFamilyStore cfs, TokenRange range, BigInteger targetSplitSize)
+    {
+        if (targetSplitSize.equals(BigInteger.ONE)) return Collections.singletonList(range);
+
+        AccordSplitter splitter = cfs.getPartitioner().accordSplitter().apply(Ranges.single(range));
+        RoutingKey remainingStart = range.start();
+
+        BigInteger rangeSize = splitter.sizeOf(range);
+        BigInteger divide = splitter.divide(rangeSize, targetSplitSize);
+        BigInteger rangeStep = divide.equals(BigInteger.ZERO) ? rangeSize : BigInteger.ONE.max(divide);
+        BigInteger offset = BigInteger.ZERO;
+        List<TokenRange> result = new ArrayList<>();
+
+        while (splitter.compare(offset, rangeSize) < 0)
+        {
+            BigInteger remaining = rangeSize.subtract(offset);
+            BigInteger length = remaining.min(rangeStep);
+
+            TokenRange next = splitter.subRange(range, offset, splitter.add(offset, length));
+            result.add(next);
+            remainingStart = next.end();
+            offset = offset.add(length);
+        }
+
+        if (!remainingStart.equals(range.end()))
+            result.add(range.newRange(remainingStart, range.end()));
+        assert result.get(0).start().equals(range.start()) : String.format("Starting range %s does not have the same start as %s", result.get(0), range);
+        assert result.get(result.size() - 1).end().equals(range.end()) : String.format("Ending range %s does not have the same end as %s", result.get(result.size() - 1), range);
+        return result;
+    }
+
+    private AsyncChain<?> awaitTableDropSubRange(TokenRange range)
+    {
+        return awaitTableDropSubRange(Ranges.single(range), 0);
+    }
+
+    private AsyncChain<Void> awaitTableDropSubRange(Ranges ranges, int attempt)
+    {
+        return exclusiveSyncPoint(ranges, attempt)
+               .flatMap(s -> s == null ? AsyncChains.success(null) : Await.coordinate(node, s));
+    }
+
+    private AsyncChain<SyncPoint<Ranges>> exclusiveSyncPoint(Ranges ranges, int attempt)
+    {
+        //TODO (on merge): CASSANDRA-19769 has the same logic... should this be refactored?  Would make it nice so we could split the range on retries?
+        return CoordinateSyncPoint.exclusive(node, ranges)
+                                  .recover(t -> {
+                                      //TODO (operability): make this configurable / monitorable?
+                                      if (attempt > 3) return null;
+                                      switch (shouldRetry(t))
+                                      {
+                                          case SUCCESS:
+                                              return AsyncChains.success(null);
+                                          case RETRY:
+                                              return exclusiveSyncPoint(ranges, attempt + 1);
+                                          case FAIL:
+                                              return null;
+                                          default:
+                                              throw new UnsupportedOperationException();
+                                      }
+                                  });
+    }
+
+    private enum RetryDecission { SUCCESS, RETRY, FAIL }
+    private static RetryDecission shouldRetry(Throwable t)
+    {
+        if (t.getClass() == ExecuteSyncPoint.SyncPointErased.class)
+            return RetryDecission.SUCCESS;
+        if (t instanceof Invalidated || t instanceof Preempted || t instanceof Timeout)
+            return RetryDecission.RETRY;
+        return RetryDecission.FAIL;
+    }
+
+    // TODO (duplication): this is 95% of accord.coordinate.CoordinateShardDurable
+    //   we already report all this information to EpochState; would be better to use that
+    //   Taken from ListStore...
+    private static class Await extends AsyncResults.SettableResult<SyncPoint<Ranges>> implements Callback<ReadData.ReadReply>
+    {
+        private final Node node;
+        private final AllTracker tracker;
+        private final SyncPoint<Ranges> exclusiveSyncPoint;
+
+        private Await(Node node, SyncPoint<Ranges> exclusiveSyncPoint)
+        {
+            Topologies topologies = node.topology().forEpoch(exclusiveSyncPoint.keysOrRanges, exclusiveSyncPoint.sourceEpoch());
+            this.node = node;
+            this.tracker = new AllTracker(topologies);
+            this.exclusiveSyncPoint = exclusiveSyncPoint;
+        }
+
+        public static AsyncChain<Void> coordinate(Node node, SyncPoint<Ranges> sp)
+        {
+            return node.withEpoch(sp.sourceEpoch(), () -> {
+                Await coordinate = new Await(node, sp);
+                coordinate.start();
+                AsyncChain<Void> chain = coordinate.map(i -> null);
+                return chain.recover(t -> {
+                    switch (shouldRetry(t))
+                    {
+                        case SUCCESS: return AsyncChains.success(null);
+                        case RETRY: return coordinate(node, sp);
+                        case FAIL: return null;
+                        default: throw new UnsupportedOperationException();
+                    }
+                });
+            });
+        }
+
+        private void start()
+        {
+            node.send(tracker.nodes(), to -> new WaitUntilApplied(to, tracker.topologies(), exclusiveSyncPoint.syncId, exclusiveSyncPoint.keysOrRanges, exclusiveSyncPoint.syncId.epoch()), this);
+        }
+        @Override
+        public void onSuccess(Node.Id from, ReadData.ReadReply reply)
+        {
+            if (!reply.isOk())
+            {
+                ReadData.CommitOrReadNack nack = (ReadData.CommitOrReadNack) reply;
+                switch (nack)
+                {
+                    default: throw new AssertionError("Unhandled: " + reply);
+
+                    case Insufficient:
+                        CoordinateSyncPoint.sendApply(node, from, exclusiveSyncPoint);
+                        return;
+                    case Rejected:
+                        tryFailure(new RuntimeException(nack.name()));
+                    case Redundant:
+                        tryFailure(new ExecuteSyncPoint.SyncPointErased());
+                        return;
+                    case Invalid:
+                        tryFailure(new Invalidated(exclusiveSyncPoint.syncId, exclusiveSyncPoint.homeKey));
+                        return;
+                }
+            }
+            else
+            {
+                if (tracker.recordSuccess(from) == RequestStatus.Success)
+                {
+                    node.configService().reportEpochRedundant(exclusiveSyncPoint.keysOrRanges, exclusiveSyncPoint.syncId.epoch());
+                    trySuccess(exclusiveSyncPoint);
+                }
+            }
+        }
+
+        private Throwable cause;
+
+        @Override
+        public void onFailure(Node.Id from, Throwable failure)
+        {
+            synchronized (this)
+            {
+                if (cause == null) cause = failure;
+                else
+                {
+                    try
+                    {
+                        cause.addSuppressed(failure);
+                    }
+                    catch (Throwable t)
+                    {
+                        // can not always add suppress
+                        node.agent().onUncaughtException(failure);
+                    }
+                }
+                failure = cause;
+            }
+            if (tracker.recordFailure(from) == RequestStatus.Failed)
+                tryFailure(failure);
+        }
+
+        @Override
+        public void onCallbackFailure(Node.Id from, Throwable failure)
+        {
+            tryFailure(failure);
+        }
+    }
 }
diff --git a/src/java/org/apache/cassandra/service/accord/AccordStaleReplicas.java b/src/java/org/apache/cassandra/service/accord/AccordStaleReplicas.java
index 2502fa1a63..f729759fe6 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordStaleReplicas.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordStaleReplicas.java
@@ -44,7 +44,7 @@ public class AccordStaleReplicas implements MetadataValue<AccordStaleReplicas>
     private final Set<Node.Id> staleIds;
     private final Epoch lastModified;
 
-    AccordStaleReplicas(Set<Node.Id> staleIds, Epoch lastModified)
+    public AccordStaleReplicas(Set<Node.Id> staleIds, Epoch lastModified)
     {
         this.staleIds = staleIds;
         this.lastModified = lastModified;
diff --git a/src/java/org/apache/cassandra/service/accord/AccordTopology.java b/src/java/org/apache/cassandra/service/accord/AccordTopology.java
index 45f3b3fd76..eb8f660b0a 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordTopology.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordTopology.java
@@ -65,16 +65,17 @@ public class AccordTopology
 
     private static class ShardLookup extends HashMap<accord.primitives.Range, Shard>
     {
-        private Shard createOrReuse(accord.primitives.Range range, SortedArrayList<Node.Id> nodes, Set<Node.Id> fastPathElectorate, Set<Node.Id> joining)
+        private Shard createOrReuse(boolean pendingRemoval, accord.primitives.Range range, SortedArrayList<Node.Id> nodes, Set<Node.Id> fastPathElectorate, Set<Node.Id> joining)
         {
             Shard prev = get(range);
             if (prev != null
+                && prev.pendingRemoval == pendingRemoval
                 && Objects.equals(prev.nodes, nodes)
                 && Objects.equals(prev.fastPathElectorate, fastPathElectorate)
                 && Objects.equals(prev.joining, joining))
                 return prev;
 
-            return new Shard(range, nodes, fastPathElectorate, joining);
+            return new Shard(range, nodes, fastPathElectorate, joining, pendingRemoval);
         }
     }
 
@@ -109,7 +110,7 @@ public class AccordTopology
 
             SortedArrayList<Node.Id> fastPath = strategyFor(metadata).calculateFastPath(nodes, unavailable, dcMap);
 
-            return lookup.createOrReuse(tokenRange, nodes, fastPath, pending);
+            return lookup.createOrReuse(metadata.params.pendingDrop, tokenRange, nodes, fastPath, pending);
         }
 
         private static KeyspaceShard forRange(KeyspaceMetadata keyspace, Range<Token> range, Directory directory, VersionedEndpoints.ForRange reads, VersionedEndpoints.ForRange writes)
diff --git a/src/java/org/apache/cassandra/service/accord/FetchMinEpoch.java b/src/java/org/apache/cassandra/service/accord/FetchMinEpoch.java
new file mode 100644
index 0000000000..0e40afc6c1
--- /dev/null
+++ b/src/java/org/apache/cassandra/service/accord/FetchMinEpoch.java
@@ -0,0 +1,209 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.accord;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Set;
+
+import javax.annotation.Nullable;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.collect.Iterators;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.TypeSizes;
+import org.apache.cassandra.io.IVersionedSerializer;
+import org.apache.cassandra.io.util.DataInputPlus;
+import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.locator.InetAddressAndPort;
+import org.apache.cassandra.net.IVerbHandler;
+import org.apache.cassandra.net.Message;
+import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.Verb;
+import org.apache.cassandra.repair.SharedContext;
+import org.apache.cassandra.utils.Backoff;
+import org.apache.cassandra.utils.concurrent.Future;
+import org.apache.cassandra.utils.concurrent.FutureCombiner;
+
+public class FetchMinEpoch
+{
+    public static final IVersionedSerializer<FetchMinEpoch> serializer = new IVersionedSerializer<>()
+    {
+
+        @Override
+        public void serialize(FetchMinEpoch t, DataOutputPlus out, int version) throws IOException
+        {
+            out.writeUnsignedVInt32(t.ranges.size());
+            for (TokenRange range : t.ranges)
+                TokenRange.serializer.serialize(range, out, version);
+        }
+
+        @Override
+        public FetchMinEpoch deserialize(DataInputPlus in, int version) throws IOException
+        {
+            int size = in.readUnsignedVInt32();
+            List<TokenRange> ranges = new ArrayList<>(size);
+            for (int i = 0; i < size; i++)
+                ranges.add(TokenRange.serializer.deserialize(in, version));
+            return new FetchMinEpoch(ranges);
+        }
+
+        @Override
+        public long serializedSize(FetchMinEpoch t, int version)
+        {
+            long size = TypeSizes.sizeofUnsignedVInt(t.ranges.size());
+            for (TokenRange range : t.ranges)
+                size += TokenRange.serializer.serializedSize(range, version);
+            return size;
+        }
+    };
+    public static final IVerbHandler<FetchMinEpoch> handler = new IVerbHandler<FetchMinEpoch>()
+    {
+        @Override
+        public void doVerb(Message<FetchMinEpoch> message) throws IOException
+        {
+            Long epoch = AccordService.instance().minEpoch(message.payload.ranges);
+            MessagingService.instance().respond(new Response(epoch), message);
+        }
+    };
+    public final Collection<TokenRange> ranges;
+
+    public FetchMinEpoch(Collection<TokenRange> ranges)
+    {
+        this.ranges = ranges;
+    }
+
+    @Override
+    public boolean equals(Object o)
+    {
+        if (this == o) return true;
+        if (o == null || getClass() != o.getClass()) return false;
+        FetchMinEpoch that = (FetchMinEpoch) o;
+        return Objects.equals(ranges, that.ranges);
+    }
+
+    @Override
+    public int hashCode()
+    {
+        return Objects.hash(ranges);
+    }
+
+    @Override
+    public String toString()
+    {
+        return "FetchMinEpoch{" +
+               "ranges=" + ranges +
+               '}';
+    }
+
+    public static Future<Long> fetch(SharedContext context, Map<InetAddressAndPort, Set<TokenRange>> peers)
+    {
+        List<Future<Long>> accum = new ArrayList<>(peers.size());
+        for (Map.Entry<InetAddressAndPort, Set<TokenRange>> e : peers.entrySet())
+            accum.add(fetch(context, e.getKey(), e.getValue()));
+        return FutureCombiner.successfulOf(accum).map(ls -> {
+            Long min = null;
+            for (Long l : ls)
+            {
+                if (l == null) continue;
+                if (min == null) min = l;
+                else min = Math.min(min, l);
+            }
+            return min;
+        });
+    }
+
+    @VisibleForTesting
+    static Future<Long> fetch(SharedContext context, InetAddressAndPort to, Set<TokenRange> value)
+    {
+        FetchMinEpoch req = new FetchMinEpoch(value);
+        Backoff backoff = Backoff.fromConfig(context, DatabaseDescriptor.getAccord().minEpochSyncRetry);
+        return context.messaging().<FetchMinEpoch, FetchMinEpoch.Response>sendWithRetries(backoff, context.optionalTasks()::schedule,
+                                                                                          Verb.ACCORD_FETCH_MIN_EPOCH_REQ, req,
+                                                                                          Iterators.cycle(to),
+                                                                                          (i1, i2, i3) -> true,
+                                                                                          (i1, i2, i3, i4) -> null)
+                      .map(m -> m.payload.minEpoch);
+    }
+
+    public static class Response
+    {
+        public static final IVersionedSerializer<Response> serializer = new IVersionedSerializer<Response>()
+        {
+            @Override
+            public void serialize(Response t, DataOutputPlus out, int version) throws IOException
+            {
+                out.writeBoolean(t.minEpoch != null);
+                if (t.minEpoch != null)
+                    out.writeUnsignedVInt(t.minEpoch);
+            }
+
+            @Override
+            public Response deserialize(DataInputPlus in, int version) throws IOException
+            {
+                boolean notNull = in.readBoolean();
+                return new Response(notNull ? in.readUnsignedVInt() : null);
+            }
+
+            @Override
+            public long serializedSize(Response t, int version)
+            {
+                int size = TypeSizes.BOOL_SIZE;
+                if (t.minEpoch != null)
+                    size += TypeSizes.sizeofUnsignedVInt(t.minEpoch);
+                return size;
+            }
+        };
+        @Nullable
+        public final Long minEpoch;
+
+        public Response(@Nullable Long minEpoch)
+        {
+            this.minEpoch = minEpoch;
+        }
+
+        @Override
+        public boolean equals(Object o)
+        {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+            Response response = (Response) o;
+            return Objects.equals(minEpoch, response.minEpoch);
+        }
+
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(minEpoch);
+        }
+
+        @Override
+        public String toString()
+        {
+            return "Response{" +
+                   "minEpoch=" + minEpoch +
+                   '}';
+        }
+    }
+}
diff --git a/src/java/org/apache/cassandra/service/accord/IAccordService.java b/src/java/org/apache/cassandra/service/accord/IAccordService.java
index 2daa31e272..a27a29f104 100644
--- a/src/java/org/apache/cassandra/service/accord/IAccordService.java
+++ b/src/java/org/apache/cassandra/service/accord/IAccordService.java
@@ -31,6 +31,7 @@ import com.google.common.collect.ImmutableSet;
 import accord.api.BarrierType;
 import accord.local.CommandStores;
 import accord.local.DurableBefore;
+import accord.local.Node;
 import accord.local.Node.Id;
 import accord.local.RedundantBefore;
 import accord.messages.Request;
@@ -38,6 +39,7 @@ import accord.primitives.Ranges;
 import accord.primitives.Seekables;
 import accord.primitives.Txn;
 import accord.primitives.TxnId;
+import accord.topology.Topology;
 import accord.topology.TopologyManager;
 import org.agrona.collections.Int2ObjectHashMap;
 import org.apache.cassandra.db.ColumnFamilyStore;
@@ -47,6 +49,7 @@ import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.net.IVerbHandler;
 import org.apache.cassandra.net.Message;
+import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.service.accord.api.AccordScheduler;
 import org.apache.cassandra.service.accord.txn.TxnResult;
 import org.apache.cassandra.tcm.Epoch;
@@ -54,6 +57,8 @@ import org.apache.cassandra.transport.Dispatcher;
 import org.apache.cassandra.utils.concurrent.AsyncPromise;
 import org.apache.cassandra.utils.concurrent.Future;
 
+import java.util.Collection;
+
 import static com.google.common.base.Preconditions.checkNotNull;
 
 
@@ -150,4 +155,12 @@ public interface IAccordService
     default Id nodeId() { throw new UnsupportedOperationException(); }
 
     List<CommandStoreTxnBlockedGraph> debugTxnBlockedGraph(TxnId txnId);
+    @Nullable
+    Long minEpoch(Collection<TokenRange> ranges);
+
+    void tryMarkRemoved(Topology topology, Node.Id node);
+    default void awaitTableDrop(TableId id)
+    {
+
+    }
 }
diff --git a/src/java/org/apache/cassandra/service/accord/TokenRange.java b/src/java/org/apache/cassandra/service/accord/TokenRange.java
index be3eaa80ca..aed0270979 100644
--- a/src/java/org/apache/cassandra/service/accord/TokenRange.java
+++ b/src/java/org/apache/cassandra/service/accord/TokenRange.java
@@ -48,13 +48,30 @@ public class TokenRange extends Range.EndInclusive
 
     public TableId table()
     {
-        return ((AccordRoutingKey) start()).table();
+        return start().table();
+    }
+
+    @Override
+    public AccordRoutingKey start()
+    {
+        return (AccordRoutingKey) super.start();
+    }
+
+    @Override
+    public AccordRoutingKey end()
+    {
+        return  (AccordRoutingKey) super.end();
+    }
+
+    public boolean isFullRange()
+    {
+        return start().kindOfRoutingKey() == AccordRoutingKey.RoutingKeyKind.SENTINEL && end().kindOfRoutingKey() == AccordRoutingKey.RoutingKeyKind.SENTINEL;
     }
 
     @VisibleForTesting
     public Range withTable(TableId table)
     {
-        return new TokenRange(((AccordRoutingKey) start()).withTable(table), ((AccordRoutingKey) end()).withTable(table));
+        return new TokenRange(start().withTable(table), end().withTable(table));
     }
 
     public static TokenRange fullRange(TableId table)
@@ -80,20 +97,20 @@ public class TokenRange extends Range.EndInclusive
     public org.apache.cassandra.dht.Range<Token> toKeyspaceRange ()
     {
         IPartitioner partitioner = DatabaseDescriptor.getPartitioner();
-        AccordRoutingKey start = (AccordRoutingKey) start();
-        AccordRoutingKey end = (AccordRoutingKey) end();
+        AccordRoutingKey start = start();
+        AccordRoutingKey end = end();
         Token left = start instanceof SentinelKey ? partitioner.getMinimumToken() : start.token();
         Token right = end instanceof SentinelKey ? partitioner.getMinimumToken() : end.token();
         return new org.apache.cassandra.dht.Range<>(left, right);
     }
 
-    public static final IVersionedSerializer<TokenRange> serializer = new IVersionedSerializer<TokenRange>()
+    public static final IVersionedSerializer<TokenRange> serializer = new IVersionedSerializer<>()
     {
         @Override
         public void serialize(TokenRange range, DataOutputPlus out, int version) throws IOException
         {
-            AccordRoutingKey.serializer.serialize((AccordRoutingKey) range.start(), out, version);
-            AccordRoutingKey.serializer.serialize((AccordRoutingKey) range.end(), out, version);
+            AccordRoutingKey.serializer.serialize(range.start(), out, version);
+            AccordRoutingKey.serializer.serialize(range.end(), out, version);
         }
 
         @Override
@@ -106,8 +123,8 @@ public class TokenRange extends Range.EndInclusive
         @Override
         public long serializedSize(TokenRange range, int version)
         {
-            return AccordRoutingKey.serializer.serializedSize((AccordRoutingKey) range.start(), version)
-                 + AccordRoutingKey.serializer.serializedSize((AccordRoutingKey) range.end(), version);
+            return AccordRoutingKey.serializer.serializedSize(range.start(), version)
+                 + AccordRoutingKey.serializer.serializedSize(range.end(), version);
         }
     };
 }
diff --git a/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java b/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java
index bf351c323f..23a3520853 100644
--- a/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java
+++ b/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java
@@ -69,10 +69,17 @@ public class AccordAgent implements Agent
 {
     private static final Logger logger = LoggerFactory.getLogger(AccordAgent.class);
 
+    protected Node.Id self;
+
     // TODO (required): this should be configurable and have exponential back-off, escaping to operator input past a certain number of retries
     private long retryBootstrapDelayMicros = SECONDS.toMicros(1L);
     private final RandomSource random = new DefaultRandom();
 
+    public void setNodeId(Node.Id id)
+    {
+        self = id;
+    }
+
     public void setRetryBootstrapDelay(long delay, TimeUnit units)
     {
         retryBootstrapDelayMicros = units.toMicros(delay);
@@ -93,6 +100,11 @@ public class AccordAgent implements Agent
         throw error;
     }
 
+    public void onFailedBarrier(TxnId id, Seekables<?, ?> keysOrRanges, Throwable cause)
+    {
+
+    }
+
     @Override
     public void onFailedBootstrap(String phase, Ranges ranges, Runnable retry, Throwable failure)
     {
diff --git a/src/java/org/apache/cassandra/service/accord/fastpath/InheritKeyspaceFastPathStrategy.java b/src/java/org/apache/cassandra/service/accord/fastpath/InheritKeyspaceFastPathStrategy.java
index 2ffc3c7cbf..39fae55d92 100644
--- a/src/java/org/apache/cassandra/service/accord/fastpath/InheritKeyspaceFastPathStrategy.java
+++ b/src/java/org/apache/cassandra/service/accord/fastpath/InheritKeyspaceFastPathStrategy.java
@@ -28,7 +28,7 @@ import accord.utils.SortedArrays.SortedArrayList;
 
 public class InheritKeyspaceFastPathStrategy implements FastPathStrategy
 {
-    static final FastPathStrategy instance = new InheritKeyspaceFastPathStrategy();
+    public static final FastPathStrategy instance = new InheritKeyspaceFastPathStrategy();
 
     private static final Map<String, String> SCHEMA_PARAMS = ImmutableMap.of(Kind.KEY, Kind.INHERIT_KEYSPACE.name());
 
diff --git a/src/java/org/apache/cassandra/service/accord/fastpath/ParameterizedFastPathStrategy.java b/src/java/org/apache/cassandra/service/accord/fastpath/ParameterizedFastPathStrategy.java
index 10828202b6..13eebb8ce8 100644
--- a/src/java/org/apache/cassandra/service/accord/fastpath/ParameterizedFastPathStrategy.java
+++ b/src/java/org/apache/cassandra/service/accord/fastpath/ParameterizedFastPathStrategy.java
@@ -50,8 +50,8 @@ import javax.annotation.Nonnull;
 
 public class ParameterizedFastPathStrategy implements FastPathStrategy
 {
-    static final String SIZE = "size";
-    static final String DCS = "dcs";
+    public static final String SIZE = "size";
+    public static final String DCS = "dcs";
     private static final Joiner DC_JOINER = Joiner.on(',');
     private static final Pattern COMMA_SEPARATOR = Pattern.compile(",");
     private static final Pattern COLON_SEPARATOR = Pattern.compile(":");
@@ -64,7 +64,7 @@ public class ParameterizedFastPathStrategy implements FastPathStrategy
             public void serialize(WeightedDc dc, DataOutputPlus out, Version version) throws IOException
             {
                 out.writeUTF(dc.name);
-                out.writeUnsignedVInt(dc.weight);
+                out.writeUnsignedVInt32(dc.weight);
                 out.writeBoolean(dc.autoWeight);
             }
 
@@ -237,7 +237,7 @@ public class ParameterizedFastPathStrategy implements FastPathStrategy
         return new ConfigurationException(String.format(fmt, args));
     }
 
-    static ParameterizedFastPathStrategy fromMap(Map<String, String> map)
+    public static ParameterizedFastPathStrategy fromMap(Map<String, String> map)
     {
         if (!map.containsKey(SIZE))
             throw cfe("fast_path must be set to 'keyspace' or 'default' or a map defining '%s' and optionally '%s'", SIZE, DCS);
diff --git a/src/java/org/apache/cassandra/service/accord/fastpath/SimpleFastPathStrategy.java b/src/java/org/apache/cassandra/service/accord/fastpath/SimpleFastPathStrategy.java
index 37d51b6c82..8a278faaa2 100644
--- a/src/java/org/apache/cassandra/service/accord/fastpath/SimpleFastPathStrategy.java
+++ b/src/java/org/apache/cassandra/service/accord/fastpath/SimpleFastPathStrategy.java
@@ -31,7 +31,7 @@ import accord.utils.SortedArrays.SortedArrayList;
 
 public class SimpleFastPathStrategy implements FastPathStrategy
 {
-    static final SimpleFastPathStrategy instance = new SimpleFastPathStrategy();
+    public static final SimpleFastPathStrategy instance = new SimpleFastPathStrategy();
 
     private static final Map<String, String> SCHEMA_PARAMS = ImmutableMap.of(Kind.KEY, Kind.SIMPLE.name());
 
diff --git a/src/java/org/apache/cassandra/service/consensus/migration/ConsensusMigrationState.java b/src/java/org/apache/cassandra/service/consensus/migration/ConsensusMigrationState.java
index fa6b146d77..731aabb735 100644
--- a/src/java/org/apache/cassandra/service/consensus/migration/ConsensusMigrationState.java
+++ b/src/java/org/apache/cassandra/service/consensus/migration/ConsensusMigrationState.java
@@ -34,6 +34,7 @@ import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Sets;
 
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.dht.Token;
@@ -204,6 +205,8 @@ public class ConsensusMigrationState implements MetadataValue<ConsensusMigration
 
     public ConsensusMigrationState withMigrationsRemovedFor(Set<TableId> removed)
     {
+        if (tableStates.isEmpty() || Sets.intersection(tableStates.keySet(), removed).isEmpty())
+            return this;
         ImmutableMap.Builder<TableId, TableMigrationState> updated = ImmutableMap.builder();
         putUnchanged(tableStates, updated, removed);
         return new ConsensusMigrationState(lastModified, updated.build());
diff --git a/src/java/org/apache/cassandra/service/consensus/migration/TransactionalMigrationFromMode.java b/src/java/org/apache/cassandra/service/consensus/migration/TransactionalMigrationFromMode.java
index 8cbef514d8..517e8fd872 100644
--- a/src/java/org/apache/cassandra/service/consensus/migration/TransactionalMigrationFromMode.java
+++ b/src/java/org/apache/cassandra/service/consensus/migration/TransactionalMigrationFromMode.java
@@ -19,7 +19,8 @@
 package org.apache.cassandra.service.consensus.migration;
 
 import org.apache.cassandra.service.consensus.TransactionalMode;
-import org.apache.cassandra.utils.LocalizeString;
+
+import static org.apache.cassandra.utils.LocalizeString.toLowerCaseLocalized;
 
 /**
  * This tracks the state of a migration either from Paxos -> Accord, Accord [interop mode a] -> Accord [interop mode b] or Accord -> Paxos.
@@ -64,7 +65,7 @@ public enum TransactionalMigrationFromMode
 
     public static TransactionalMigrationFromMode fromString(String name)
     {
-        return valueOf(LocalizeString.toLowerCaseLocalized(name));
+        return valueOf(toLowerCaseLocalized(name));
     }
 
     public boolean migratingFromAccord()
@@ -81,4 +82,9 @@ public enum TransactionalMigrationFromMode
     {
         return this != none;
     }
+
+    public String asCqlParam()
+    {
+        return String.format("transactional_migration_from = '%s'", toLowerCaseLocalized(this.name()));
+    }
 }
diff --git a/src/java/org/apache/cassandra/tcm/CMSOperations.java b/src/java/org/apache/cassandra/tcm/CMSOperations.java
index 5b21acd142..a0917584d9 100644
--- a/src/java/org/apache/cassandra/tcm/CMSOperations.java
+++ b/src/java/org/apache/cassandra/tcm/CMSOperations.java
@@ -34,6 +34,7 @@ import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.virtual.ClusterMetadataDirectoryTable;
 import org.apache.cassandra.db.virtual.ClusterMetadataLogTable;
 import org.apache.cassandra.schema.ReplicationParams;
+import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.tcm.membership.NodeId;
 import org.apache.cassandra.tcm.membership.NodeState;
 import org.apache.cassandra.tcm.membership.NodeVersion;
@@ -42,6 +43,7 @@ import org.apache.cassandra.tcm.sequences.CancelCMSReconfiguration;
 import org.apache.cassandra.tcm.sequences.InProgressSequences;
 import org.apache.cassandra.tcm.sequences.ReconfigureCMS;
 import org.apache.cassandra.tcm.serialization.Version;
+import org.apache.cassandra.tcm.sequences.DropAccordTable;
 import org.apache.cassandra.tcm.transformations.Unregister;
 import org.apache.cassandra.tcm.transformations.cms.AdvanceCMSReconfiguration;
 import org.apache.cassandra.utils.FBUtilities;
@@ -288,4 +290,19 @@ public class CMSOperations implements CMSOperationsMBean
         }
         return res;
     }
+
+    @Override
+    public void resumeDropAccordTable(String tableId)
+    {
+        TableId id = TableId.fromString(tableId);
+        for (MultiStepOperation.SequenceKey key : ClusterMetadata.current().inProgressSequences.keys())
+        {
+            if (key instanceof DropAccordTable.TableReference && ((DropAccordTable.TableReference) key).id.equals(id))
+            {
+                InProgressSequences.finishInProgressSequences(key);
+                return;
+            }
+        }
+        throw new IllegalArgumentException("No drop table operation is in progress for table with id " + tableId);
+    }
 }
diff --git a/src/java/org/apache/cassandra/tcm/CMSOperationsMBean.java b/src/java/org/apache/cassandra/tcm/CMSOperationsMBean.java
index 7ff0c0191b..6656634a64 100644
--- a/src/java/org/apache/cassandra/tcm/CMSOperationsMBean.java
+++ b/src/java/org/apache/cassandra/tcm/CMSOperationsMBean.java
@@ -48,4 +48,6 @@ public interface CMSOperationsMBean
     public void unregisterLeftNodes(List<String> nodeIds);
     public Map<Long, Map<String, String>> dumpDirectory(boolean includeTokens);
     public Map<Long, Map<String, String>> dumpLog(long startEpoch, long endEpoch);
+
+    public void resumeDropAccordTable(String tableId);
 }
diff --git a/src/java/org/apache/cassandra/tcm/ClusterMetadata.java b/src/java/org/apache/cassandra/tcm/ClusterMetadata.java
index 9c497e2d15..321a69b7d3 100644
--- a/src/java/org/apache/cassandra/tcm/ClusterMetadata.java
+++ b/src/java/org/apache/cassandra/tcm/ClusterMetadata.java
@@ -82,7 +82,7 @@ import org.apache.cassandra.utils.Pair;
 import static com.google.common.collect.ImmutableSet.toImmutableSet;
 import static org.apache.cassandra.config.CassandraRelevantProperties.LINE_SEPARATOR;
 import static org.apache.cassandra.db.TypeSizes.sizeof;
-import static org.apache.cassandra.tcm.serialization.Version.V2;
+import static org.apache.cassandra.tcm.serialization.Version.MIN_ACCORD_VERSION;
 
 public class ClusterMetadata
 {
@@ -205,16 +205,6 @@ public class ClusterMetadata
         this.accordStaleReplicas = accordStaleReplicas;
     }
 
-    public ClusterMetadata withDirectory(Directory directory)
-    {
-        return new ClusterMetadata(epoch, partitioner, schema, directory, tokenMap, placements, accordFastPath, lockedRanges, inProgressSequences, consensusMigrationState, extensions, accordStaleReplicas);
-    }
-
-    public ClusterMetadata withPlacements(DataPlacements placements)
-    {
-        return new ClusterMetadata(epoch, partitioner, schema, directory, tokenMap, placements, accordFastPath, lockedRanges, inProgressSequences, consensusMigrationState, extensions, accordStaleReplicas);
-    }
-
     public Set<InetAddressAndPort> fullCMSMembers()
     {
         if (fullCMSEndpoints == null)
@@ -632,7 +622,7 @@ public class ClusterMetadata
 
         public Transformer with(ExtensionKey<?, ?> key, ExtensionValue<?> obj)
         {
-            if (MetadataKeys.CORE_METADATA.contains(key))
+            if (MetadataKeys.CORE_METADATA.containsKey(key))
                 throw new IllegalArgumentException("Core cluster metadata objects should be addressed directly, " +
                                                    "not using the associated MetadataKey");
 
@@ -655,7 +645,7 @@ public class ClusterMetadata
 
         public Transformer without(ExtensionKey<?, ?> key)
         {
-            if (MetadataKeys.CORE_METADATA.contains(key))
+            if (MetadataKeys.CORE_METADATA.containsKey(key))
                 throw new IllegalArgumentException("Core cluster metadata objects should be addressed directly, " +
                                                    "not using the associated MetadataKey");
             if (extensions.remove(key) != null)
@@ -754,7 +744,7 @@ public class ClusterMetadata
                                                        inProgressSequences,
                                                        consensusMigrationState,
                                                        extensions,
-                    accordStaleReplicas),
+                                                       accordStaleReplicas),
                                    ImmutableSet.copyOf(modifiedKeys));
         }
 
@@ -1030,7 +1020,7 @@ public class ClusterMetadata
             Directory.serializer.serialize(metadata.directory, out, version);
             TokenMap.serializer.serialize(metadata.tokenMap, out, version);
             DataPlacements.serializer.serialize(metadata.placements, out, version);
-            if (version.isAtLeast(V2))
+            if (version.isAtLeast(MIN_ACCORD_VERSION))
             {
                 AccordFastPath.serializer.serialize(metadata.accordFastPath, out, version);
                 ConsensusMigrationState.serializer.serialize(metadata.consensusMigrationState, out, version);
@@ -1078,7 +1068,7 @@ public class ClusterMetadata
             ConsensusMigrationState consensusMigrationState;
             AccordStaleReplicas staleReplicas;
 
-            if (version.isAtLeast(V2))
+            if (version.isAtLeast(MIN_ACCORD_VERSION))
             {
                 accordFastPath = AccordFastPath.serializer.deserialize(in, version);
                 consensusMigrationState = ConsensusMigrationState.serializer.deserialize(in, version);
@@ -1135,7 +1125,7 @@ public class ClusterMetadata
                     TokenMap.serializer.serializedSize(metadata.tokenMap, version) +
                     DataPlacements.serializer.serializedSize(metadata.placements, version);
 
-            if (version.isAtLeast(V2))
+            if (version.isAtLeast(MIN_ACCORD_VERSION))
             {
                 size += AccordFastPath.serializer.serializedSize(metadata.accordFastPath, version) +
                         ConsensusMigrationState.serializer.serializedSize(metadata.consensusMigrationState, version) +
diff --git a/src/java/org/apache/cassandra/tcm/MetadataKeys.java b/src/java/org/apache/cassandra/tcm/MetadataKeys.java
index 0aed60581e..0be621b201 100644
--- a/src/java/org/apache/cassandra/tcm/MetadataKeys.java
+++ b/src/java/org/apache/cassandra/tcm/MetadataKeys.java
@@ -24,6 +24,7 @@ import java.util.Map;
 import java.util.Set;
 import java.util.function.Function;
 
+import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
 
 import org.apache.cassandra.tcm.extensions.ExtensionKey;
@@ -45,15 +46,18 @@ public class MetadataKeys
     public static final MetadataKey IN_PROGRESS_SEQUENCES   = make(CORE_NS, "sequences", "in_progress");
     public static final MetadataKey CONSENSUS_MIGRATION_STATE = make(CORE_NS, "consensus", "migration_state");
 
-    public static final ImmutableSet<MetadataKey> CORE_METADATA = ImmutableSet.of(SCHEMA,
-                                                                                  NODE_DIRECTORY,
-                                                                                  TOKEN_MAP,
-                                                                                  DATA_PLACEMENTS,
-                                                                                  ACCORD_FAST_PATH,
-                                                                                  ACCORD_STALE_REPLICAS,   
-                                                                                  LOCKED_RANGES,
-                                                                                  IN_PROGRESS_SEQUENCES,
-                                                                                  CONSENSUS_MIGRATION_STATE);
+    public static final ImmutableMap<MetadataKey, Function<ClusterMetadata, MetadataValue<?>>> CORE_METADATA
+    = ImmutableMap.<MetadataKey, Function<ClusterMetadata, MetadataValue<?>>>builder()
+                  .put(SCHEMA, cm -> cm.schema)
+                  .put(NODE_DIRECTORY, cm -> cm.directory)
+                  .put(TOKEN_MAP, cm -> cm.tokenMap)
+                  .put(DATA_PLACEMENTS, cm -> cm.placements)
+                  .put(LOCKED_RANGES, cm -> cm.lockedRanges)
+                  .put(IN_PROGRESS_SEQUENCES, cm -> cm.inProgressSequences)
+                  .put(ACCORD_FAST_PATH, cm -> cm.accordFastPath)
+                  .put(ACCORD_STALE_REPLICAS, cm -> cm.accordStaleReplicas)
+                  .put(CONSENSUS_MIGRATION_STATE, cm -> cm.consensusMigrationState)
+                  .build();
 
     public static MetadataKey make(String...parts)
     {
@@ -67,6 +71,15 @@ public class MetadataKeys
         return new MetadataKey(b.toString());
     }
 
+    public static MetadataValue<?> extract(ClusterMetadata cm, MetadataKey key)
+    {
+        if (CORE_METADATA.containsKey(key))
+            return CORE_METADATA.get(key).apply(cm);
+        if (!(key instanceof ExtensionKey<?, ?>))
+            throw new IllegalArgumentException("Unknown key: " + key);
+        return cm.extensions.get(key);
+    }
+
     public static ImmutableSet<MetadataKey> diffKeys(ClusterMetadata before, ClusterMetadata after)
     {
         ImmutableSet.Builder<MetadataKey> builder = new ImmutableSet.Builder<>();
@@ -76,12 +89,8 @@ public class MetadataKeys
 
     private static void diffKeys(ClusterMetadata before, ClusterMetadata after, ImmutableSet.Builder<MetadataKey> builder)
     {
-        checkKey(before, after, builder, cm -> cm.schema, MetadataKeys.SCHEMA);
-        checkKey(before, after, builder, cm -> cm.directory, MetadataKeys.NODE_DIRECTORY);
-        checkKey(before, after, builder, cm -> cm.tokenMap, MetadataKeys.TOKEN_MAP);
-        checkKey(before, after, builder, cm -> cm.placements, MetadataKeys.DATA_PLACEMENTS);
-        checkKey(before, after, builder, cm -> cm.lockedRanges, MetadataKeys.LOCKED_RANGES);
-        checkKey(before, after, builder, cm -> cm.inProgressSequences, MetadataKeys.IN_PROGRESS_SEQUENCES);
+        for (Map.Entry<MetadataKey, Function<ClusterMetadata, MetadataValue<?>>> e : CORE_METADATA.entrySet())
+            checkKey(before, after, builder, e.getValue(), e.getKey());
 
         Set<ExtensionKey<?,?>> added = new HashSet<>(after.extensions.keySet());
         for (Map.Entry<ExtensionKey<?, ?>, ExtensionValue<?>> entry : before.extensions.entrySet())
diff --git a/src/java/org/apache/cassandra/tcm/MultiStepOperation.java b/src/java/org/apache/cassandra/tcm/MultiStepOperation.java
index d447974f85..3d42772518 100644
--- a/src/java/org/apache/cassandra/tcm/MultiStepOperation.java
+++ b/src/java/org/apache/cassandra/tcm/MultiStepOperation.java
@@ -33,6 +33,7 @@ import org.apache.cassandra.tcm.sequences.ProgressBarrier;
 import org.apache.cassandra.tcm.sequences.UnbootstrapAndLeave;
 import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializer;
 import org.apache.cassandra.tcm.serialization.MetadataSerializer;
+import org.apache.cassandra.tcm.sequences.DropAccordTable;
 
 /**
  * Represents a multi-step process performed in order to transition the cluster to some state.
@@ -67,7 +68,8 @@ public abstract class MultiStepOperation<CONTEXT>
         LEAVE(UnbootstrapAndLeave.serializer),
         REMOVE(UnbootstrapAndLeave.serializer),
 
-        RECONFIGURE_CMS(ReconfigureCMS.serializer)
+        RECONFIGURE_CMS(ReconfigureCMS.serializer),
+        DROP_ACCORD_TABLE(DropAccordTable.serializer),
         ;
 
         public final AsymmetricMetadataSerializer<MultiStepOperation<?>, ? extends MultiStepOperation<?>> serializer;
diff --git a/src/java/org/apache/cassandra/tcm/Processor.java b/src/java/org/apache/cassandra/tcm/Processor.java
index 3d29b43375..46fce6aeab 100644
--- a/src/java/org/apache/cassandra/tcm/Processor.java
+++ b/src/java/org/apache/cassandra/tcm/Processor.java
@@ -18,6 +18,8 @@
 
 package org.apache.cassandra.tcm;
 
+import java.util.ArrayList;
+import java.util.List;
 import java.util.concurrent.TimeUnit;
 
 import com.codahale.metrics.Meter;
@@ -27,6 +29,8 @@ import org.apache.cassandra.tcm.log.Entry;
 import org.apache.cassandra.tcm.log.LogState;
 import org.apache.cassandra.utils.Clock;
 
+import static java.util.concurrent.TimeUnit.NANOSECONDS;
+
 public interface Processor
 {
     /**
@@ -105,4 +109,20 @@ public interface Processor
     ClusterMetadata fetchLogAndWait(Epoch waitFor, Retry.Deadline retryPolicy);
 
     LogState reconstruct(Epoch lowEpoch, Epoch highEpoch, Retry.Deadline retryPolicy);
+
+    default List<ClusterMetadata> reconstructFull(Epoch lowEpoch, Epoch highEpoch)
+    {
+        LogState logState = reconstruct(lowEpoch, highEpoch, Retry.Deadline.retryIndefinitely(DatabaseDescriptor.getCmsAwaitTimeout().to(NANOSECONDS),
+                                                                                              TCMMetrics.instance.commitRetries));
+        List<ClusterMetadata> cms = new ArrayList<>(logState.entries.size());
+        ClusterMetadata accum = logState.baseState;
+        for (Entry entry : logState.entries)
+        {
+            Transformation.Result res = entry.transform.execute(accum);
+            assert res.isSuccess() : res.toString();
+            accum = res.success().metadata;
+            cms.add(accum);
+        }
+        return cms;
+    }
 }
diff --git a/src/java/org/apache/cassandra/tcm/Startup.java b/src/java/org/apache/cassandra/tcm/Startup.java
index 7acfe643c6..537a505eb6 100644
--- a/src/java/org/apache/cassandra/tcm/Startup.java
+++ b/src/java/org/apache/cassandra/tcm/Startup.java
@@ -416,13 +416,21 @@ import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;
     {
         ClusterMetadata metadata = ClusterMetadata.current();
         NodeId self = metadata.myNodeId();
-        AccordService.startup(self);
 
         // finish in-progress sequences first
         InProgressSequences.finishInProgressSequences(self, true);
         metadata = ClusterMetadata.current();
 
-        switch (metadata.directory.peerState(self))
+        NodeState startingstate = metadata.directory.peerState(self);
+        switch (startingstate)
+        {
+            case REGISTERED:
+            case LEFT:
+                break;
+            default:
+                AccordService.startup(self);
+        }
+        switch (startingstate)
         {
             case REGISTERED:
             case LEFT:
@@ -430,6 +438,10 @@ import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;
                     ReconfigureCMS.maybeReconfigureCMS(metadata, DatabaseDescriptor.getReplaceAddress());
 
                 ClusterMetadataService.instance().commit(initialTransformation.get());
+                // When Accord starts up it needs to check for any historic epochs that it needs to know about (in order
+                // to handle pending transactions), in order to know what nodes to check with it needs to know what the
+                // settled placement is (so it knows what peers to reach out to).
+                AccordService.startup(self);
                 InProgressSequences.finishInProgressSequences(self, true); // potentially finish the MSO committed above
                 metadata = ClusterMetadata.current();
 
diff --git a/src/java/org/apache/cassandra/tcm/StubClusterMetadataService.java b/src/java/org/apache/cassandra/tcm/StubClusterMetadataService.java
index 16cf324799..fc89ec79d9 100644
--- a/src/java/org/apache/cassandra/tcm/StubClusterMetadataService.java
+++ b/src/java/org/apache/cassandra/tcm/StubClusterMetadataService.java
@@ -74,7 +74,7 @@ public class StubClusterMetadataService extends ClusterMetadataService
 
     private ClusterMetadata metadata;
 
-    private StubClusterMetadataService(ClusterMetadata initial)
+    protected StubClusterMetadataService(ClusterMetadata initial)
     {
         super(new UniformRangePlacement(),
               MetadataSnapshots.NO_OP,
@@ -105,15 +105,20 @@ public class StubClusterMetadataService extends ClusterMetadataService
     @Override
     public <T1> T1 commit(Transformation transform, CommitSuccessHandler<T1> onSuccess, CommitFailureHandler<T1> onFailure)
     {
-        Transformation.Result result = transform.execute(metadata);
+        Transformation.Result result = execute(transform);
         if (result.isSuccess())
         {
-            metadata = result.success().metadata;
+            setMetadata(result.success().metadata);
             return  onSuccess.accept(result.success().metadata);
         }
         return onFailure.accept(result.rejected().code, result.rejected().reason);
     }
 
+    protected Transformation.Result execute(Transformation transform)
+    {
+        return transform.execute(metadata());
+    }
+
     @Override
     public ClusterMetadata fetchLogFromCMS(Epoch awaitAtLeast)
     {
diff --git a/src/java/org/apache/cassandra/tcm/Transformation.java b/src/java/org/apache/cassandra/tcm/Transformation.java
index b8ce1cbc9a..928ce59aca 100644
--- a/src/java/org/apache/cassandra/tcm/Transformation.java
+++ b/src/java/org/apache/cassandra/tcm/Transformation.java
@@ -46,8 +46,10 @@ import org.apache.cassandra.tcm.transformations.Assassinate;
 import org.apache.cassandra.tcm.transformations.BeginConsensusMigrationForTableAndRange;
 import org.apache.cassandra.tcm.transformations.CancelInProgressSequence;
 import org.apache.cassandra.tcm.transformations.CustomTransformation;
+import org.apache.cassandra.tcm.transformations.FinishDropAccordTable;
 import org.apache.cassandra.tcm.transformations.ForceSnapshot;
 import org.apache.cassandra.tcm.transformations.MaybeFinishConsensusMigrationForTableAndRange;
+import org.apache.cassandra.tcm.transformations.PrepareDropAccordTable;
 import org.apache.cassandra.tcm.transformations.PrepareJoin;
 import org.apache.cassandra.tcm.transformations.PrepareLeave;
 import org.apache.cassandra.tcm.transformations.PrepareMove;
@@ -246,6 +248,8 @@ public interface Transformation
         MAYBE_FINISH_CONSENSUS_MIGRATION_FOR_TABLE_AND_RANGE(38, () -> MaybeFinishConsensusMigrationForTableAndRange.serializer),
         ACCORD_MARK_STALE(39, () -> AccordMarkStale.serializer),
         ACCORD_MARK_REJOINING(40, () -> AccordMarkRejoining.serializer),
+        PREPARE_DROP_ACCORD_TABLE(41, () -> PrepareDropAccordTable.serializer),
+        FINISH_DROP_ACCORD_TABLE(42, () -> FinishDropAccordTable.serializer),
         ;
 
         private final Supplier<AsymmetricMetadataSerializer<Transformation, ? extends Transformation>> serializer;
diff --git a/src/java/org/apache/cassandra/tcm/sequences/DropAccordTable.java b/src/java/org/apache/cassandra/tcm/sequences/DropAccordTable.java
new file mode 100644
index 0000000000..46047ef494
--- /dev/null
+++ b/src/java/org/apache/cassandra/tcm/sequences/DropAccordTable.java
@@ -0,0 +1,324 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.tcm.sequences;
+
+import java.io.IOException;
+import java.time.Duration;
+import java.util.Objects;
+import java.util.concurrent.ExecutionException;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.io.util.DataInputPlus;
+import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.schema.Keyspaces;
+import org.apache.cassandra.schema.TableId;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.accord.AccordService;
+import org.apache.cassandra.tcm.ClusterMetadata;
+import org.apache.cassandra.tcm.ClusterMetadataService;
+import org.apache.cassandra.tcm.Epoch;
+import org.apache.cassandra.tcm.MultiStepOperation;
+import org.apache.cassandra.tcm.Transformation;
+import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializer;
+import org.apache.cassandra.tcm.serialization.MetadataSerializer;
+import org.apache.cassandra.tcm.serialization.Version;
+import org.apache.cassandra.tcm.transformations.FinishDropAccordTable;
+import org.apache.cassandra.utils.JVMStabilityInspector;
+
+import static org.apache.cassandra.tcm.Transformation.Kind.FINISH_DROP_ACCORD_TABLE;
+import static org.apache.cassandra.tcm.sequences.SequenceState.continuable;
+import static org.apache.cassandra.tcm.sequences.SequenceState.error;
+import static org.apache.cassandra.tcm.sequences.SequenceState.halted;
+import static org.apache.cassandra.utils.Clock.Global.nanoTime;
+
+/**
+ * A slightly atypical implementation as it consists of only a single step. To perform the drop of an
+ * Accord table, we first commit a PrepareDropAccordTable transformation. Upon enactement, that
+ * marks the table as pending drop, which blocks any new transactions from being started. It also
+ * instantiates an instance of this operation and adds it to the set of in progress operations.
+ *
+ * The intention is to introduce a barrier which blocks until the Accord service acknowledges that
+ * it was learned of the epoch in which the table was marked for deletion and that all prior transactions
+ * are completed. Once this is complete, we can proceed to actually drop the table. The transformation
+ * which performs that schema modification also removes this MSO from ClusterMetadata's in-flight set.
+ * This obviates the need to 'advance' this MSO in the way that other implementations with more steps do.
+ *
+ */
+public class DropAccordTable extends MultiStepOperation<Epoch>
+{
+    private static final Logger logger = LoggerFactory.getLogger(DropAccordTable.class);
+
+    public static final Serializer serializer = new Serializer();
+
+    public final TableReference table;
+
+    public static DropAccordTable newSequence(TableReference table, Epoch preparedAt)
+    {
+        return new DropAccordTable(table, preparedAt);
+    }
+
+    /**
+     * Used by factory method for external callers and by the serializer.
+     * We don't need to include the serialized FinishDropAccordTable step in the serialization
+     * of the MSO itself because they have no parameters other than the table reference and so
+     * we can just construct a new one when we execute it
+     */
+    private DropAccordTable(TableReference table, Epoch latestModification)
+    {
+        super(0, latestModification);
+        this.table = table;
+    }
+
+    @Override
+    public boolean equals(Object o)
+    {
+        if (this == o) return true;
+        if (o == null || getClass() != o.getClass()) return false;
+        DropAccordTable that = (DropAccordTable) o;
+        return latestModification.equals(that.latestModification)
+               && table.equals(that.table);
+    }
+
+    @Override
+    public int hashCode()
+    {
+        return Objects.hash(latestModification, table);
+    }
+
+    @Override
+    public Kind kind()
+    {
+        return Kind.DROP_ACCORD_TABLE;
+    }
+
+    @Override
+    protected SequenceKey sequenceKey()
+    {
+        return table;
+    }
+
+    @Override
+    public MetadataSerializer<? extends SequenceKey> keySerializer()
+    {
+        return TableReference.serializer;
+    }
+
+    @Override
+    public Transformation.Kind nextStep()
+    {
+        return FINISH_DROP_ACCORD_TABLE;
+    }
+
+    @Override
+    public SequenceState executeNext()
+    {
+        try
+        {
+            SequenceState failure = awaitSafeFromAccord();
+            if (failure != null) return failure;
+        }
+        catch (Throwable t)
+        {
+            JVMStabilityInspector.inspectThrowable(t);
+            logger.warn("Exception while waiting for Accord service to notify all table txns are complete", t);
+            // this is actually continuable as we can simply retry
+            return continuable();
+        }
+        try
+        {
+            // Now we're satisfied that all Accord txns have finished for the table,
+            // go ahead and actually drop it
+            ClusterMetadataService.instance().commit(new FinishDropAccordTable(table));
+            return continuable();
+        }
+        catch (Throwable t)
+        {
+            JVMStabilityInspector.inspectThrowable(t);
+            logger.warn("Exception committing finish_drop_accord_table. " +
+                        "Accord service has acknowledged the operation but table remains present in schema", t);
+            return halted();
+        }
+    }
+
+    private SequenceState awaitSafeFromAccord() throws ExecutionException, InterruptedException
+    {
+        // make sure that Accord sees the current epoch, which must necessarily follow the
+        // one which marked the table as pending drop
+        ClusterMetadata metadata = ClusterMetadata.current();
+        // just for the sake of paranoia, assert that the table is actually marked as being dropped
+        if (!verifyTableMarked(metadata.schema.getKeyspaces()))
+            return error(new IllegalStateException(String.format("Table %s is in an invalid state to be dropped", table)));
+
+        long startNanos = nanoTime();
+        AccordService.instance().epochReady(metadata.epoch).get();
+        long epochEndNanos = nanoTime();
+
+        // As of this writing this logic is based off ExclusiveSyncPoints which is a bit heavy weight for what is needed, this could cause timeouts for clusters that have a lot of data.
+        // There are retries baked into this call, but trying to handle timeouts more broadly is put on hold as there is active work to define a EpochSyncPoint that should be far cheaper
+        // which would avoid the timeout issues
+        // NOTE: ExclusiveSyncPoint must find all keys in the range, then make sure nothing is blocking them... this causes a lot of IO.  EpochSyncPoint just needs to validate that the last txn processed is in the newer epoch, this can work with in-memory state.
+        AccordService.instance().awaitTableDrop(table.id);
+        long awaitEndNanos = nanoTime();
+        logger.info("Wait for Accord to see the drop table was success.  " +
+                    "Took {} to wait for Accord to learn about the change, then {} to process everything",
+                    Duration.ofNanos(epochEndNanos - startNanos), Duration.ofNanos(awaitEndNanos - epochEndNanos));
+        return null;
+    }
+
+    private boolean verifyTableMarked(Keyspaces keyspaces)
+    {
+        TableMetadata tm = keyspaces.getTableOrViewNullable(table.id);
+        if (tm == null)
+        {
+            logger.warn("Unable to drop accord table {}, table not found", table);
+            return false;
+        }
+
+        if (!tm.params.pendingDrop)
+        {
+            logger.warn("Unexpected state, table {} was not marked pending drop", table);
+            return false;
+        }
+
+        return true;
+    }
+
+    @Override
+    public Transformation.Result applyTo(ClusterMetadata metadata)
+    {
+        // note: that this will apply the finish drop transformation to the supplied metadata. It's
+        // not used to actually execute the MSO, but to determine what the metadata state will/would
+        // be if it were executed.
+        return new FinishDropAccordTable(table).execute(metadata);
+    }
+
+    @Override
+    public DropAccordTable advance(Epoch epoch)
+    {
+        // note: this isn't really used by this MSO impl as it consists of a single step so there's nothing
+        // to advance. An action of the single step is to remove the MSO from the set of in progress sequences
+        return new DropAccordTable(this.table, epoch);
+    }
+
+    @Override
+    public ProgressBarrier barrier()
+    {
+        return ProgressBarrier.immediate();
+    }
+
+    public static class TableReference implements SequenceKey, Comparable<TableReference>
+    {
+        public static final Serializer serializer = new Serializer();
+
+        public final TableId id;
+
+        public TableReference(TableId id)
+        {
+            this.id = id;
+        }
+
+        public static TableReference from(TableMetadata metadata)
+        {
+            return new TableReference(metadata.id);
+        }
+
+        @Override
+        public boolean equals(Object o)
+        {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+            TableReference that = (TableReference) o;
+            return id.equals(that.id);
+        }
+
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(id);
+        }
+
+        @Override
+        public int compareTo(TableReference o)
+        {
+            return id.compareTo(o.id);
+        }
+
+        @Override
+        public String toString()
+        {
+            return "TableReference{id=" + id + '}';
+        }
+
+        public static class Serializer implements MetadataSerializer<TableReference>
+        {
+            @Override
+            public void serialize(TableReference t, DataOutputPlus out, Version version) throws IOException
+            {
+                t.id.serialize(out);
+            }
+
+            @Override
+            public TableReference deserialize(DataInputPlus in, Version version) throws IOException
+            {
+                TableId id = TableId.deserialize(in);
+                return new TableReference(id);
+            }
+
+            @Override
+            public long serializedSize(TableReference t, Version version)
+            {
+                return t.id.serializedSize();
+            }
+        }
+    }
+
+    public static class Serializer implements AsymmetricMetadataSerializer<MultiStepOperation<?>, DropAccordTable>
+    {
+        @Override
+        public void serialize(MultiStepOperation<?> t, DataOutputPlus out, Version version) throws IOException
+        {
+            DropAccordTable plan = (DropAccordTable) t;
+            Epoch.serializer.serialize(plan.latestModification, out, version);
+            // This type of sequence only has a single step so no need to include the index in serde.
+            // Similarly, the only parameter to that single step (FinishDropAccordTable) is the table
+            // reference, so that's all we really need to include in the serialization.
+            TableReference.serializer.serialize(plan.table, out, version);
+        }
+
+        @Override
+        public DropAccordTable deserialize(DataInputPlus in, Version version) throws IOException
+        {
+            Epoch lastModified = Epoch.serializer.deserialize(in, version);
+            TableReference table = TableReference.serializer.deserialize(in, version);
+            return new DropAccordTable(table, lastModified);
+        }
+
+        @Override
+        public long serializedSize(MultiStepOperation<?> t, Version version)
+        {
+            DropAccordTable plan = (DropAccordTable) t;
+            long size = 0;
+            size += Epoch.serializer.serializedSize(plan.latestModification, version);
+            size += TableReference.serializer.serializedSize(plan.table, version);
+            return size;
+        }
+    }
+}
diff --git a/src/java/org/apache/cassandra/tcm/sequences/InProgressSequences.java b/src/java/org/apache/cassandra/tcm/sequences/InProgressSequences.java
index 735a7f6935..840c2505f4 100644
--- a/src/java/org/apache/cassandra/tcm/sequences/InProgressSequences.java
+++ b/src/java/org/apache/cassandra/tcm/sequences/InProgressSequences.java
@@ -27,6 +27,7 @@ import java.util.function.Function;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.ImmutableSet;
 
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
@@ -59,27 +60,27 @@ public class InProgressSequences implements MetadataValue<InProgressSequences>,
         this.state = state;
     }
 
-    public static void finishInProgressSequences(MultiStepOperation.SequenceKey sequenceKey)
+    public static ClusterMetadata finishInProgressSequences(MultiStepOperation.SequenceKey sequenceKey)
     {
-        finishInProgressSequences(sequenceKey, false);
+        return finishInProgressSequences(sequenceKey, false);
     }
 
-    public static void finishInProgressSequences(MultiStepOperation.SequenceKey sequenceKey, boolean onlyStartupSafeSequences)
+    public static ClusterMetadata finishInProgressSequences(MultiStepOperation.SequenceKey sequenceKey, boolean onlyStartupSafeSequences)
     {
         ClusterMetadata metadata = ClusterMetadata.current();
         while (true)
         {
             MultiStepOperation<?> sequence = metadata.inProgressSequences.get(sequenceKey);
             if (sequence == null)
-                break;
+                return metadata;
             if (onlyStartupSafeSequences && !sequence.finishDuringStartup())
-                break;
+                return metadata;
             if (isLeave(sequence))
                 StorageService.instance.maybeInitializeServices();
             if (resume(sequence))
                 metadata = ClusterMetadata.current();
             else
-                return;
+                return metadata;
         }
     }
 
@@ -225,6 +226,11 @@ public class InProgressSequences implements MetadataValue<InProgressSequences>,
         return state.values().iterator();
     }
 
+    public ImmutableSet<MultiStepOperation.SequenceKey> keys()
+    {
+        return state.keySet();
+    }
+
     public static class Serializer implements MetadataSerializer<InProgressSequences>
     {
         public void serialize(InProgressSequences t, DataOutputPlus out, Version version) throws IOException
diff --git a/src/java/org/apache/cassandra/tcm/serialization/Version.java b/src/java/org/apache/cassandra/tcm/serialization/Version.java
index 245ef32bbc..f0b56c9917 100644
--- a/src/java/org/apache/cassandra/tcm/serialization/Version.java
+++ b/src/java/org/apache/cassandra/tcm/serialization/Version.java
@@ -18,7 +18,10 @@
 
 package org.apache.cassandra.tcm.serialization;
 
+import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashMap;
+import java.util.List;
 import java.util.Map;
 
 import org.apache.cassandra.tcm.ClusterMetadata;
@@ -36,30 +39,33 @@ public enum Version
     /**
      *  - Added version to PlacementForRange serializer
      *  - Serialize MemtableParams when serializing TableParams
-     *  - Added AccordFastPath
-     *  - Added AccordStaleReplicas
      */
     V2(2),
+
     /**
-     * - down nodes serialized in PrepareCMSReconfiguration
+     *  - Added AccordFastPath
+     *  - Added ConsensusMigrationState
+     *  - Added AccordStaleReplicas
+     *  - TableParam now has pendingDrop (accord table drop is multistep)
      */
     V3(3),
-    /**
-     * - Serialize allowAutoSnapshot and incrementalBackups when serializing TableParams
-     */
+
+    // Padding
     V4(4),
-    /**
-     * - AlterSchema includes execution timestamp
-     * - PreInitialize includes datacenter (affects local serialization on first CMS node only)
-     */
     V5(5),
+    V6(6),
     /**
-     * CEP-42 - Constraints framework. New version due to modifications in table metadata serialization.
+     *  - Accord
      */
-    V6(6),
+    V7(7),
 
     UNKNOWN(Integer.MAX_VALUE);
 
+    /**
+     * The version that Accord was added to TCM.
+     */
+    public static final Version MIN_ACCORD_VERSION = V3;
+
     private static Map<Integer, Version> values = new HashMap<>();
     static
     {
@@ -113,4 +119,15 @@ public enum Version
 
         throw new IllegalArgumentException("Unsupported metadata version (" + i + ")");
     }
+
+    public List<Version> greaterThanOrEqual()
+    {
+        Version[] all = Version.values();
+        if (ordinal() == all.length - 1)
+            return Collections.singletonList(this);
+        List<Version> values = new ArrayList<>(all.length - ordinal());
+        for (int i = ordinal(); i < all.length; i++)
+            values.add(all[i]);
+        return values;
+    }
 }
diff --git a/src/java/org/apache/cassandra/tcm/transformations/AlterSchema.java b/src/java/org/apache/cassandra/tcm/transformations/AlterSchema.java
index 3fe49e63bb..ba72930fb2 100644
--- a/src/java/org/apache/cassandra/tcm/transformations/AlterSchema.java
+++ b/src/java/org/apache/cassandra/tcm/transformations/AlterSchema.java
@@ -261,7 +261,7 @@ public class AlterSchema implements Transformation
         return byReplication;
     }
 
-    private Transformer maybeUpdateConsensusMigrationState(ConsensusMigrationState prev, Transformer next, ImmutableList<KeyspaceDiff> altered, Keyspaces dropped)
+    public static Transformer maybeUpdateConsensusMigrationState(ConsensusMigrationState prev, Transformer next, ImmutableList<KeyspaceDiff> altered, Keyspaces dropped)
     {
         ConsensusMigrationState migrationState = prev;
 
diff --git a/src/java/org/apache/cassandra/tcm/transformations/FinishDropAccordTable.java b/src/java/org/apache/cassandra/tcm/transformations/FinishDropAccordTable.java
new file mode 100644
index 0000000000..2019adb8ad
--- /dev/null
+++ b/src/java/org/apache/cassandra/tcm/transformations/FinishDropAccordTable.java
@@ -0,0 +1,143 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.tcm.transformations;
+
+import java.io.IOException;
+import java.util.Objects;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.io.util.DataInputPlus;
+import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.schema.DistributedSchema;
+import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.Keyspaces;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.tcm.ClusterMetadata;
+import org.apache.cassandra.tcm.Transformation;
+import org.apache.cassandra.tcm.sequences.DropAccordTable.TableReference;
+import org.apache.cassandra.tcm.sequences.LockedRanges;
+import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializer;
+import org.apache.cassandra.tcm.serialization.Version;
+
+import static org.apache.cassandra.tcm.Transformation.Kind.FINISH_DROP_ACCORD_TABLE;
+
+/**
+ * Dropping an Accord table is a three-step process.
+ * <ol>
+ *     <li>Mark the table as pending drop</li>
+ *     <li>Await all in-flight txns to finish</li>
+ *     <li>Drop the table from schema (this step)</li>
+ * </ol>
+ * <p/>
+ * Hypothetically it is possible that after {1} has been committed, but before {3} is executed
+ * interleaving metadata changes occur. These could include dropping the table's keyspace, or
+ * modifying the transactional mode of the table to make it a non-accord table. Validation
+ * exists to prevent these schema changes from being committed while the drop is in-flight.
+ * However, if something like this did happen, by the time we come to execute this transformation,
+ * there's nothing really to do other than return success (as the table has indeed already been dropped).
+ */
+public class FinishDropAccordTable implements Transformation
+{
+    private static final Logger logger = LoggerFactory.getLogger(FinishDropAccordTable.class);
+
+    public static final Serializer serializer = new Serializer();
+    public final TableReference tableRef;
+
+    public FinishDropAccordTable(TableReference tableRef)
+    {
+        this.tableRef = tableRef;
+    }
+
+    @Override
+    public Kind kind()
+    {
+        return FINISH_DROP_ACCORD_TABLE;
+    }
+
+    @Override
+    public Result execute(ClusterMetadata prev)
+    {
+        // In every case we remove the operation to drop this table from the set of in-flight sequences
+        ClusterMetadata.Transformer proposed = prev.transformer()
+                                                   .with(prev.inProgressSequences.without(tableRef));
+
+        Keyspaces keyspaces = prev.schema.getKeyspaces();
+        TableMetadata table = keyspaces.getTableOrViewNullable(tableRef.id);
+        // Table was already dropped
+        if (table == null)
+        {
+            logger.warn("Table {} was dropped while drop accord table sequence was in flight", tableRef);
+            return Transformation.success(proposed, LockedRanges.AffectedRanges.EMPTY);
+        }
+        KeyspaceMetadata keyspace = keyspaces.getNullable(table.keyspace);
+
+        // Actually drop the table
+        Keyspaces withoutTable = keyspaces.withAddedOrUpdated(keyspace.withSwapped(keyspace.tables.without(table)));
+
+        Keyspaces.KeyspacesDiff diff = Keyspaces.diff(prev.schema.getKeyspaces(), withoutTable);
+
+        proposed = AlterSchema.maybeUpdateConsensusMigrationState(prev.consensusMigrationState, proposed, diff.altered, Keyspaces.NONE);
+
+        proposed = proposed.with(new DistributedSchema(withoutTable));
+        return Transformation.success(proposed, LockedRanges.AffectedRanges.EMPTY);
+    }
+
+    @Override
+    public boolean equals(Object o)
+    {
+        if (this == o) return true;
+        if (!(o instanceof FinishDropAccordTable)) return false;
+
+        FinishDropAccordTable that = (FinishDropAccordTable) o;
+
+        return Objects.equals(tableRef, that.tableRef);
+    }
+
+    @Override
+    public int hashCode()
+    {
+        return Objects.hash(tableRef);
+    }
+
+    public static class Serializer implements AsymmetricMetadataSerializer<Transformation, FinishDropAccordTable>
+    {
+        @Override
+        public void serialize(Transformation t, DataOutputPlus out, Version version) throws IOException
+        {
+            FinishDropAccordTable plan = (FinishDropAccordTable) t;
+            TableReference.serializer.serialize(plan.tableRef, out, version);
+        }
+
+        @Override
+        public FinishDropAccordTable deserialize(DataInputPlus in, Version version) throws IOException
+        {
+            TableReference table = TableReference.serializer.deserialize(in, version);
+            return new FinishDropAccordTable(table);
+        }
+
+        @Override
+        public long serializedSize(Transformation t, Version version)
+        {
+            FinishDropAccordTable plan = (FinishDropAccordTable) t;
+            return TableReference.serializer.serializedSize(plan.tableRef, version);
+        }
+    }
+}
\ No newline at end of file
diff --git a/src/java/org/apache/cassandra/tcm/transformations/PrepareDropAccordTable.java b/src/java/org/apache/cassandra/tcm/transformations/PrepareDropAccordTable.java
new file mode 100644
index 0000000000..2c960a0bd3
--- /dev/null
+++ b/src/java/org/apache/cassandra/tcm/transformations/PrepareDropAccordTable.java
@@ -0,0 +1,115 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.tcm.transformations;
+
+import java.io.IOException;
+import java.util.Objects;
+
+import org.apache.cassandra.exceptions.ExceptionCode;
+import org.apache.cassandra.io.util.DataInputPlus;
+import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.schema.DistributedSchema;
+import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.tcm.ClusterMetadata;
+import org.apache.cassandra.tcm.Transformation;
+import org.apache.cassandra.tcm.sequences.DropAccordTable;
+import org.apache.cassandra.tcm.sequences.DropAccordTable.TableReference;
+import org.apache.cassandra.tcm.sequences.LockedRanges;
+import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializer;
+import org.apache.cassandra.tcm.serialization.Version;
+
+public class PrepareDropAccordTable implements Transformation
+{
+    public static final Serializer serializer = new Serializer();
+
+    public final TableReference tableRef;
+
+    public PrepareDropAccordTable(TableReference tableRef)
+    {
+        this.tableRef = tableRef;
+    }
+
+    @Override
+    public Kind kind()
+    {
+        return Kind.PREPARE_DROP_ACCORD_TABLE;
+    }
+
+    @Override
+    public Result execute(ClusterMetadata prev)
+    {
+        TableMetadata metadata = prev.schema.getKeyspaces().getTableOrViewNullable(tableRef.id);
+        if (metadata == null)
+            return new Rejected(ExceptionCode.INVALID, "Table " + tableRef + " is not known");
+        if (!metadata.isAccordEnabled())
+            return new Rejected(ExceptionCode.INVALID, "Table " + metadata + " is not an Accord table and should be dropped normally");
+        if (metadata.params.pendingDrop)
+            return new Rejected(ExceptionCode.INVALID, "Table " + metadata + " is in the process of being dropped");
+
+        KeyspaceMetadata ks = prev.schema.getKeyspaceMetadata(metadata.keyspace);
+        metadata = metadata.unbuild().params(metadata.params.unbuild().pendingDrop(true).build()).build();
+        ks = ks.withSwapped(ks.tables.withSwapped(metadata));
+
+        DropAccordTable operation = DropAccordTable.newSequence(tableRef, prev.nextEpoch());
+        ClusterMetadata.Transformer proposed = prev.transformer()
+                                                   .with(new DistributedSchema(prev.schema.getKeyspaces().withAddedOrUpdated(ks)))
+                                                   .with(prev.inProgressSequences.with(tableRef, operation));
+        return Transformation.success(proposed, LockedRanges.AffectedRanges.EMPTY);
+    }
+
+    @Override
+    public boolean equals(Object o)
+    {
+        if (this == o) return true;
+        if (o == null || getClass() != o.getClass()) return false;
+        PrepareDropAccordTable that = (PrepareDropAccordTable) o;
+        return tableRef.equals(that.tableRef);
+    }
+
+    @Override
+    public int hashCode()
+    {
+        return Objects.hash(tableRef);
+    }
+
+    public static class Serializer implements AsymmetricMetadataSerializer<Transformation, PrepareDropAccordTable>
+    {
+        @Override
+        public void serialize(Transformation t, DataOutputPlus out, Version version) throws IOException
+        {
+            PrepareDropAccordTable plan = (PrepareDropAccordTable) t;
+            TableReference.serializer.serialize(plan.tableRef, out, version);
+        }
+
+        @Override
+        public PrepareDropAccordTable deserialize(DataInputPlus in, Version version) throws IOException
+        {
+            TableReference table = TableReference.serializer.deserialize(in, version);
+            return new PrepareDropAccordTable(table);
+        }
+
+        @Override
+        public long serializedSize(Transformation t, Version version)
+        {
+            PrepareDropAccordTable plan = (PrepareDropAccordTable) t;
+            return TableReference.serializer.serializedSize(plan.tableRef, version);
+        }
+    }
+}
diff --git a/src/java/org/apache/cassandra/tools/NodeTool.java b/src/java/org/apache/cassandra/tools/NodeTool.java
index d821735586..2823bf112b 100644
--- a/src/java/org/apache/cassandra/tools/NodeTool.java
+++ b/src/java/org/apache/cassandra/tools/NodeTool.java
@@ -269,7 +269,8 @@ public class NodeTool
                .withCommand(CMSAdmin.Unregister.class)
                .withCommand(CMSAdmin.AbortInitialization.class)
                .withCommand(CMSAdmin.DumpDirectory.class)
-               .withCommand(CMSAdmin.DumpLog.class);
+               .withCommand(CMSAdmin.DumpLog.class)
+               .withCommand(CMSAdmin.ResumeDropAccordTable.class);
 
         builder.withGroup("consensus_admin")
             .withDescription("List and mark ranges as migrating between consensus protocols")
diff --git a/src/java/org/apache/cassandra/tools/nodetool/CMSAdmin.java b/src/java/org/apache/cassandra/tools/nodetool/CMSAdmin.java
index 7f54fdd9be..84d23dc3f8 100644
--- a/src/java/org/apache/cassandra/tools/nodetool/CMSAdmin.java
+++ b/src/java/org/apache/cassandra/tools/nodetool/CMSAdmin.java
@@ -257,4 +257,16 @@ public abstract class CMSAdmin extends NodeTool.NodeToolCmd
         assert !map.isEmpty();
         return map.entrySet().iterator().next().getValue().keySet().stream().max(Comparator.comparingInt(String::length)).get().length() + 1;
     }
+
+    @Command(name = "resumedropaccordtable", description = "Resume a drop accord table operation which has stalled")
+    public static class ResumeDropAccordTable extends NodeTool.NodeToolCmd
+    {
+        @Arguments(usage = "[tableId]", description = "Table id of the table being dropped")
+        private String tableId;
+        @Override
+        public void execute(NodeProbe probe)
+        {
+            probe.getCMSOperationsProxy().resumeDropAccordTable(tableId);
+        }
+    }
 }
diff --git a/test/distributed/org/apache/cassandra/distributed/impl/Coordinator.java b/test/distributed/org/apache/cassandra/distributed/impl/Coordinator.java
index 5053735336..50ffe781f5 100644
--- a/test/distributed/org/apache/cassandra/distributed/impl/Coordinator.java
+++ b/test/distributed/org/apache/cassandra/distributed/impl/Coordinator.java
@@ -29,7 +29,7 @@ import java.util.function.BiConsumer;
 
 import com.google.common.collect.Iterators;
 
-import accord.utilsfork.Invariants;
+import accord.utils.Invariants;
 import org.apache.cassandra.cql3.CQLStatement;
 import org.apache.cassandra.cql3.QueryOptions;
 import org.apache.cassandra.cql3.QueryProcessor;
diff --git a/test/distributed/org/apache/cassandra/distributed/shared/ClusterUtils.java b/test/distributed/org/apache/cassandra/distributed/shared/ClusterUtils.java
index 79daae1583..0cbb1f7cad 100644
--- a/test/distributed/org/apache/cassandra/distributed/shared/ClusterUtils.java
+++ b/test/distributed/org/apache/cassandra/distributed/shared/ClusterUtils.java
@@ -25,11 +25,13 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.HashMap;
+import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.Set;
+import java.util.UUID;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.TimeUnit;
@@ -52,8 +54,18 @@ import org.junit.Assert;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import accord.primitives.TxnId;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.ICluster;
+import org.apache.cassandra.distributed.api.IInstance;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.api.IMessageFilters;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.api.SimpleQueryResult;
 import org.apache.cassandra.distributed.impl.AbstractCluster;
 import org.apache.cassandra.distributed.impl.InstanceConfig;
 import org.apache.cassandra.distributed.impl.TestChangeListener;
@@ -67,6 +79,8 @@ import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.net.RequestCallback;
 import org.apache.cassandra.net.Verb;
 import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.tcm.ClusterMetadata;
 import org.apache.cassandra.tcm.ClusterMetadataService;
@@ -85,6 +99,7 @@ import static org.apache.cassandra.config.CassandraRelevantProperties.BROADCAST_
 import static org.apache.cassandra.config.CassandraRelevantProperties.REPLACE_ADDRESS_FIRST_BOOT;
 import static org.apache.cassandra.config.CassandraRelevantProperties.RING_DELAY;
 import static org.apache.cassandra.distributed.impl.TestEndpointCache.toCassandraInetAddressAndPort;
+import static org.apache.cassandra.schema.SchemaConstants.VIRTUAL_VIEWS;
 import static org.assertj.core.api.Assertions.assertThat;
 
 /**
@@ -1555,5 +1570,50 @@ public class ClusterUtils
                 .describedAs("Unexpected StorageService operation mode")
                 .isEqualTo(StorageService.Mode.NORMAL);
     }
+
+    public static <T extends IInstance> LinkedHashMap<String, SimpleQueryResult> queryTxnState(AbstractCluster<T> cluster, TxnId txnId, int... nodes)
+    {
+        String cql = String.format("SELECT * FROM %s.txn_blocked_by WHERE txn_id=?", VIRTUAL_VIEWS);
+        LinkedHashMap<String, SimpleQueryResult> map = new LinkedHashMap<>();
+        Iterable<T> it = nodes.length == 0 ? cluster::iterator : cluster.get(nodes);
+        for (T i : it)
+        {
+            if (i.isShutdown())
+                continue;
+            SimpleQueryResult result = i.executeInternalWithResult(cql, txnId.toString());
+            map.put(i.toString(), result);
+        }
+        return map;
+    }
+
+    public static <T extends IInstance> String queryTxnStateAsString(AbstractCluster<T> cluster, TxnId txnId, int... nodes)
+    {
+        StringBuilder sb = new StringBuilder();
+        queryTxnStateAsString(sb, cluster, txnId, nodes);
+        return sb.toString();
+    }
+
+    public static <T extends IInstance> void queryTxnStateAsString(StringBuilder sb, AbstractCluster<T> cluster, TxnId txnId, int... nodes)
+    {
+        LinkedHashMap<String, SimpleQueryResult> map = queryTxnState(cluster, txnId, nodes);
+        for (var e : map.entrySet())
+        {
+            sb.append(e.getKey()).append(":\n");
+            SimpleQueryResult result = e.getValue();
+            if (!result.names().isEmpty())
+                sb.append(result.names()).append('\n');
+            while (result.hasNext())
+            {
+                var row = result.next();
+                sb.append(Arrays.asList(row.toObjectArray())).append('\n');
+            }
+        }
+    }
+
+    public static TableId tableId(Cluster cluster, String ks, String table)
+    {
+        String str = cluster.getFirstRunningInstance().callOnInstance(() -> Schema.instance.getKeyspaceInstance(ks).getColumnFamilyStore(table).getTableId().toString());
+        return TableId.fromUUID(UUID.fromString(str));
+    }
 }
 
diff --git a/test/distributed/org/apache/cassandra/distributed/test/TestBaseImpl.java b/test/distributed/org/apache/cassandra/distributed/test/TestBaseImpl.java
index 7eadb7e0b4..14ac84b404 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/TestBaseImpl.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/TestBaseImpl.java
@@ -293,4 +293,27 @@ public class TestBaseImpl extends DistributedTestBase
         asyncThread.start();
         return task;
     }
+
+    /**
+     * @see org.apache.cassandra.cql3.CQLTester#wrapInTxn(String...)
+     */
+    protected static String wrapInTxn(String... stmts)
+    {
+        return wrapInTxn(Arrays.asList(stmts));
+    }
+
+    protected static String wrapInTxn(List<String> stmts)
+    {
+        StringBuilder sb = new StringBuilder();
+        sb.append("BEGIN TRANSACTION\n");
+        for (String stmt : stmts)
+        {
+            sb.append('\t').append(stmt);
+            if (!stmt.endsWith(";"))
+                sb.append(';');
+            sb.append('\n');
+        }
+        sb.append("COMMIT TRANSACTION");
+        return sb.toString();
+    }
 }
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordCQLTestBase.java b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordCQLTestBase.java
index c0956391b2..824498b229 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordCQLTestBase.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordCQLTestBase.java
@@ -389,6 +389,7 @@ public abstract class AccordCQLTestBase extends AccordTestBase
 
     private void assertResultsFromAccordMatches(Cluster cluster, String accordRead, String simpleRead, int key)
     {
+        accordRead = wrapInTxn(accordRead);
         Object[][] simpleReadResult;
         if (transactionalMode.ignoresSuppliedConsistencyLevel)
             // With accord non-SERIAL write strategy the commit CL is effectively ANY so we need to read at SERIAL
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropKeyspaceTest.java b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropKeyspaceTest.java
new file mode 100644
index 0000000000..353980f55f
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropKeyspaceTest.java
@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test.accord;
+
+import java.io.IOException;
+
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.schema.TableId;
+
+public class AccordDropKeyspaceTest extends AccordDropTableBase
+{
+    @Test
+    public void dropKeyspace() throws IOException
+    {
+        int examples = 5;
+        int steps = 5;
+        try (Cluster cluster = Cluster.build(3)
+                                      .withoutVNodes()
+                                      .withConfig(c -> c.with(Feature.values())
+                                                        .set("auto_snapshot", false))
+                                      .start())
+        {
+            fixDistributedSchemas(cluster);
+            for (int i = 0; i < examples; i++)
+            {
+                int j = 0;
+                try
+                {
+                    addChaos(cluster, i);
+                    init(cluster);
+                    TableId id = createTable(cluster);
+                    for (j = 0; j < steps; j++)
+                        doTxn(cluster, j);
+                    dropKeyspace(cluster);
+                    validateAccord(cluster, id);
+                }
+                catch (Throwable t)
+                {
+                    throw new AssertionError("Error at example " + i + ", " + j, t);
+                }
+            }
+        }
+    }
+}
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropTableBase.java b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropTableBase.java
new file mode 100644
index 0000000000..732fe303cb
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropTableBase.java
@@ -0,0 +1,159 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test.accord;
+
+import java.util.UUID;
+
+import com.google.common.base.Throwables;
+
+import accord.api.Key;
+import accord.local.CommandStores;
+import accord.local.KeyHistory;
+import accord.local.PreLoadContext;
+import accord.local.cfk.CommandsForKey;
+import accord.primitives.Ranges;
+import accord.primitives.TxnId;
+import accord.utils.async.AsyncChains;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.ICoordinator;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.shared.ClusterUtils;
+import org.apache.cassandra.distributed.test.TestBaseImpl;
+import org.apache.cassandra.net.Verb;
+import org.apache.cassandra.schema.TableId;
+import org.apache.cassandra.service.accord.AccordCommandStore;
+import org.apache.cassandra.service.accord.AccordSafeCommandStore;
+import org.apache.cassandra.service.accord.AccordSafeCommandsForKey;
+import org.apache.cassandra.service.accord.AccordService;
+import org.apache.cassandra.service.accord.TokenRange;
+import org.assertj.core.api.Assertions;
+
+import static org.apache.cassandra.service.accord.AccordTestUtils.wrapInTxn;
+
+public class AccordDropTableBase extends TestBaseImpl
+{
+    protected static void addChaos(Cluster cluster, int example)
+    {
+        cluster.filters().reset();
+        cluster.filters().verbs(Verb.ACCORD_APPLY_REQ.id).from(1).to(3).drop();
+    }
+
+    protected static void doTxn(Cluster cluster, int step)
+    {
+        int stepId = step % 3;
+        int partitionId = step % 10;
+        int coordinatorId = (step % 2) + 1; // avoid node3 as it can't get applies from node1, so leads to user errors
+        ICoordinator coordinator = cluster.coordinator(coordinatorId);
+        switch (stepId)
+        {
+            case 0: // insert
+                retry(3, () -> coordinator.executeWithResult(wrapInTxn(withKeyspace("INSERT INTO %s.tbl(pk, v) VALUES (?, ?);")), ConsistencyLevel.ANY, partitionId, step));
+                break;
+            case 1: // insert + read
+                retry(3, () -> coordinator.executeWithResult(wrapInTxn(withKeyspace("UPDATE %s.tbl SET v+=1 WHERE pk=?;")), ConsistencyLevel.ANY, partitionId));
+                break;
+            case 2: // read
+                retry(3, () -> coordinator.executeWithResult(wrapInTxn(withKeyspace("SELECT * FROM %s.tbl WHERE pk=?")), ConsistencyLevel.ANY, partitionId));
+                break;
+            default:
+                throw new UnsupportedOperationException();
+        }
+    }
+
+    protected static void retry(int maxAttempts, Runnable fn)
+    {
+        for (int i = 0; i < maxAttempts; i++)
+        {
+            try
+            {
+                fn.run();
+            }
+            catch (Throwable t)
+            {
+                if (i == (maxAttempts - 1))
+                    throw t;
+            }
+        }
+    }
+
+    protected static TableId createTable(Cluster cluster)
+    {
+        cluster.schemaChange(withKeyspace("CREATE TABLE %s.tbl(pk int PRIMARY KEY, v int) WITH transactional_mode='full'"));
+        return ClusterUtils.tableId(cluster, KEYSPACE, "tbl");
+    }
+
+    protected void dropKeyspace(Cluster cluster)
+    {
+        // drop keyspace should be rejected as there is an accord table... so validate that is true then do both
+        try
+        {
+            cluster.schemaChange(withKeyspace("DROP KEYSPACE %s"));
+        }
+        catch (Throwable t)
+        {
+            Assertions.assertThat(Throwables.getRootCause(t))
+                      .hasMessage("Cannot drop keyspace 'distributed_test_keyspace' as it contains accord tables. (distributed_test_keyspace.tbl)");
+        }
+
+        // now do it for real
+        dropTable(cluster);
+        cluster.schemaChange(withKeyspace("DROP KEYSPACE %s"));
+    }
+
+    protected static void dropTable(Cluster cluster)
+    {
+        cluster.schemaChange(withKeyspace("DROP TABLE %s.tbl"));
+    }
+
+    protected static void validateAccord(Cluster cluster, TableId id)
+    {
+        String s = id.toString();
+        for (IInvokableInstance inst : cluster)
+        {
+            inst.runOnInstance(() -> {
+                TableId tableId = TableId.fromUUID(UUID.fromString(s));
+                AccordService accord = (AccordService) AccordService.instance();
+                PreLoadContext ctx = PreLoadContext.contextFor(Ranges.single(TokenRange.fullRange(tableId)), KeyHistory.COMMANDS);
+                CommandStores stores = accord.node().commandStores();
+                for (int storeId : stores.ids())
+                {
+                    AccordCommandStore store = (AccordCommandStore) stores.forId(storeId);
+                    AsyncChains.getUnchecked(store.submit(ctx, input -> {
+                        AccordSafeCommandStore safe = (AccordSafeCommandStore) input;
+                        for (Key key : safe.commandsForKeysKeys())
+                        {
+                            AccordSafeCommandsForKey safeCFK = safe.maybeCommandsForKey(key);
+                            if (safeCFK == null) // we read and found a key, but its null at load time... so ignore it
+                                continue;
+                            CommandsForKey cfk = safeCFK.current();
+                            CommandsForKey.TxnInfo minUndecided = cfk.minUndecided();
+                            if (minUndecided != null)
+                                throw new AssertionError("Undecided txn: " + minUndecided);
+                            TxnId next = cfk.nextWaitingToApply();
+                            if (next != null)
+                                throw new AssertionError("Unapplied txn: " + next);
+                        }
+                        return null;
+                    }));
+                }
+            });
+        }
+    }
+}
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropTableTest.java b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropTableTest.java
new file mode 100644
index 0000000000..b13bcb05ce
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordDropTableTest.java
@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test.accord;
+
+import java.io.IOException;
+
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.schema.TableId;
+
+public class AccordDropTableTest extends AccordDropTableBase
+{
+    @Test
+    public void dropTable() throws IOException
+    {
+        int examples = 5;
+        int steps = 5;
+        try (Cluster cluster = Cluster.build(3)
+                                      .withoutVNodes()
+                                      .withConfig(c -> c.with(Feature.values())
+                                                       .set("auto_snapshot", false))
+                                      .start())
+        {
+            fixDistributedSchemas(cluster);
+            init(cluster);
+            for (int i = 0; i < examples; i++)
+            {
+                int j = 0;
+                try
+                {
+                    addChaos(cluster, i);
+                    TableId id = createTable(cluster);
+                    for (j = 0; j < steps; j++)
+                        doTxn(cluster, j);
+                    dropTable(cluster);
+                    validateAccord(cluster, id);
+                }
+                catch (Throwable t)
+                {
+                    throw new AssertionError("Error at example " + i + ", " + j, t);
+                }
+            }
+        }
+    }
+}
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordHostReplacementTest.java b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordHostReplacementTest.java
new file mode 100644
index 0000000000..0105ad7eae
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordHostReplacementTest.java
@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test.accord;
+
+import java.io.IOException;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
+
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.TokenSupplier;
+import org.apache.cassandra.distributed.shared.ClusterUtils;
+import org.apache.cassandra.distributed.test.TestBaseImpl;
+import org.apache.cassandra.harry.SchemaSpec;
+import org.apache.cassandra.harry.dsl.HistoryBuilder;
+import org.apache.cassandra.harry.dsl.ReplayingHistoryBuilder;
+import org.apache.cassandra.harry.execution.RingAwareInJvmDTestVisitExecutor;
+import org.apache.cassandra.harry.gen.Generator;
+import org.apache.cassandra.harry.gen.Generators;
+import org.apache.cassandra.harry.gen.SchemaGenerators;
+import org.apache.cassandra.harry.model.TokenPlacementModel;
+import org.apache.cassandra.service.consensus.TransactionalMode;
+
+import static org.apache.cassandra.distributed.shared.ClusterUtils.stopUnchecked;
+import static org.apache.cassandra.distributed.shared.ClusterUtils.waitForCMSToQuiesce;
+import static org.apache.cassandra.harry.checker.TestHelper.withRandom;
+
+public class AccordHostReplacementTest extends TestBaseImpl
+{
+    private static final Generator<TransactionalMode> transactionalModeGen = Generators.pick(Stream.of(TransactionalMode.values()).filter(t -> t.accordIsEnabled).collect(Collectors.toList()));
+
+    @Test
+    public void hostReplace() throws IOException
+    {
+        // start 3 node cluster, then do a host replacement of one of the nodes
+        Cluster.Builder clusterBuilder = Cluster.build(3)
+                .withConfig(c -> c.with(Feature.values())
+                        .set("accord.command_store_shard_count", "1")
+                        .set("write_request_timeout", "10s")
+                        .set("read_request_timeout", "10s")
+                        .set("accord.queue_shard_count", "1")
+                );
+        TokenSupplier tokenRing = TokenSupplier.evenlyDistributedTokens(3, clusterBuilder.getTokenCount());
+        int nodeToReplace = 2;
+        clusterBuilder = clusterBuilder.withTokenSupplier((TokenSupplier) node -> tokenRing.tokens(node == 4 ? nodeToReplace : node));
+        try (Cluster cluster = clusterBuilder.start())
+        {
+            fixDistributedSchemas(cluster);
+            init(cluster);
+
+            withRandom(rng -> {
+                Generator<SchemaSpec> schemaGen = SchemaGenerators.schemaSpecGen(KEYSPACE, "host_replace", 1000,
+                        SchemaSpec.optionsBuilder().withTransactionalMode(transactionalModeGen.generate(rng)));
+                SchemaSpec schema = schemaGen.generate(rng);
+                Generators.TrackingGenerator<Integer> pkGen = Generators.tracking(Generators.int32(0, Math.min(schema.valueGenerators.pkPopulation(), 1000)));
+
+                HistoryBuilder history = historyBuilder(schema, cluster);
+                waitForCMSToQuiesce(cluster, cluster.get(1));
+
+                for (int i = 0; i < 1000; i++)
+                    history.insert(pkGen.generate(rng));
+                for (int pk : pkGen.generated())
+                    history.selectPartition(pk);
+
+                history.custom(() -> {
+                    stopUnchecked(cluster.get(nodeToReplace));
+                    ClusterUtils.replaceHostAndStart(cluster, cluster.get(nodeToReplace));
+                }, "Replace");
+
+                for (int pk : pkGen.generated())
+                    history.selectPartition(pk);
+            });
+        }
+    }
+
+    private static HistoryBuilder historyBuilder(SchemaSpec schema, Cluster cluster)
+    {
+        HistoryBuilder history = new ReplayingHistoryBuilder(schema.valueGenerators,
+                hb -> RingAwareInJvmDTestVisitExecutor.builder()
+                        .replicationFactor(new TokenPlacementModel.SimpleReplicationFactor(3))
+                        .consistencyLevel(ConsistencyLevel.ALL)
+                        .build(schema, hb, cluster));
+        history.customThrowing(() -> cluster.schemaChange(schema.compile()), "Setup");
+        return history;
+    }
+}
\ No newline at end of file
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordTestBase.java b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordTestBase.java
index 6180a5fc54..318b922d29 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordTestBase.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordTestBase.java
@@ -35,6 +35,12 @@ import java.util.stream.StreamSupport;
 import com.google.common.base.Splitter;
 import com.google.common.collect.ImmutableList;
 import com.google.common.primitives.Ints;
+
+import org.apache.cassandra.cql3.CQLStatement;
+import org.apache.cassandra.cql3.QueryProcessor;
+import org.apache.cassandra.distributed.shared.ClusterUtils;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
 import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Assert;
@@ -84,11 +90,9 @@ import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.Verb;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.service.accord.AccordService;
-import org.apache.cassandra.service.accord.AccordTestUtils;
 import org.apache.cassandra.service.accord.api.AccordRoutingKey;
+import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.service.accord.exceptions.ReadPreemptedException;
 import org.apache.cassandra.service.accord.exceptions.WritePreemptedException;
 import org.apache.cassandra.service.consensus.TransactionalMode;
@@ -104,7 +108,6 @@ import static org.apache.cassandra.db.SystemKeyspace.CONSENSUS_MIGRATION_STATE;
 import static org.apache.cassandra.db.SystemKeyspace.PAXOS;
 import static org.apache.cassandra.distributed.api.ConsistencyLevel.ALL;
 import static org.apache.cassandra.schema.SchemaConstants.SYSTEM_KEYSPACE_NAME;
-import static org.apache.cassandra.schema.SchemaConstants.VIRTUAL_VIEWS;
 import static org.junit.Assert.assertArrayEquals;
 
 public abstract class AccordTestBase extends TestBaseImpl
@@ -406,43 +409,27 @@ public abstract class AccordTestBase extends TestBaseImpl
 
     }
 
-    private static SimpleQueryResult executeWithRetry0(int count, Cluster cluster, String check, Object... boundValues)
+    private static SimpleQueryResult executeWithRetry0(int count, Cluster cluster, IInvokableInstance inst, String check, Object... boundValues)
     {
         try
         {
-            return execute(cluster, check, boundValues);
+            logger.info("Executing statement:\n{}", check);
+            return inst.coordinator().executeWithResult(check, ConsistencyLevel.ANY, boundValues);
         }
         catch (RuntimeException ex)
         {
             if (count <= MAX_RETRIES && (hasRootCause(ex, ReadPreemptedException.class) || hasRootCause(ex, WritePreemptedException.class) || hasRootCause(ex, Invalidated.class)))
             {
                 logger.warn("[Retry attempt={}] Preempted failure for\n{}", count, check);
-                return executeWithRetry0(count + 1, cluster, check, boundValues);
+                return executeWithRetry0(count + 1, cluster, inst, check, boundValues);
             }
             TxnId txnId = maybeExtractId(ex);
             if (txnId != null)
             {
                 // query the cluster to find its status...
-                String cql = String.format("SELECT * FROM %s.txn_blocked_by WHERE txn_id=?", VIRTUAL_VIEWS);
                 StringBuilder sb = new StringBuilder();
                 sb.append("Txn ").append(txnId).append(" timed out...\n");
-                for (IInvokableInstance inst : cluster)
-                {
-                    if (inst.isShutdown())
-                    {
-                        sb.append(inst).append(": is down\n");
-                        continue;
-                    }
-                    sb.append(inst).append(":\n");
-                    SimpleQueryResult result = inst.executeInternalWithResult(cql, txnId.toString());
-                    if (!result.names().isEmpty())
-                        sb.append(result.names()).append('\n');
-                    while (result.hasNext())
-                    {
-                        var row = result.next();
-                        sb.append(Arrays.asList(row.toObjectArray())).append('\n');
-                    }
-                }
+                ClusterUtils.queryTxnStateAsString(sb, cluster, txnId);
                 throw new AssertionError(sb.toString(), ex.getCause());
             }
             throw ex;
@@ -470,21 +457,37 @@ public abstract class AccordTestBase extends TestBaseImpl
 
     public static SimpleQueryResult executeWithRetry(Cluster cluster, String check, Object... boundValues)
     {
-        check = wrapInTxn(check);
+        return executeWithRetry(cluster, cluster.get(1), check, boundValues);
+    }
 
+    public static SimpleQueryResult executeWithRetry(Cluster cluster, IInvokableInstance inst, String check, Object... boundValues)
+    {
         // is this method safe?
 
-        if (!isIdempotent(cluster, check))
+        if (!isIdempotent(inst, check))
             throw new AssertionError("Unable to retry txn that is not idempotent: cql=\n" + check);
 
-        return executeWithRetry0(0, cluster, check, boundValues);
+        return executeWithRetry0(0, cluster, inst, check, boundValues);
     }
 
-    private static boolean isIdempotent(Cluster cluster, String cql)
+    public static Boolean isIdempotent(IInvokableInstance inst, String cql)
     {
-        return cluster.get(1).callOnInstance(() -> {
-            TransactionStatement stmt = AccordTestUtils.parse(cql);
-            return isIdempotent(stmt);
+        return inst.callOnInstance(() -> {
+            CQLStatement.Raw parsed = QueryProcessor.parseStatement(cql);
+            if (parsed instanceof TransactionStatement.Parsed)
+            {
+                TransactionStatement stmt = (TransactionStatement) parsed.prepare(ClientState.forInternalCalls());
+                return isIdempotent(stmt);
+            }
+            else if (parsed instanceof ModificationStatement.Parsed)
+            {
+                ModificationStatement stmt = (ModificationStatement) parsed.prepare(ClientState.forInternalCalls());
+                return isIdempotent(stmt);
+            }
+            else
+            {
+                throw new IllegalArgumentException("Unexpected type: " + parsed.getClass());
+            }
         });
     }
 
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/NewSchemaTest.java b/test/distributed/org/apache/cassandra/distributed/test/accord/NewSchemaTest.java
index 82c9e2f806..4a6fab41fe 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/accord/NewSchemaTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/NewSchemaTest.java
@@ -20,6 +20,7 @@ package org.apache.cassandra.distributed.test.accord;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
+import java.util.Arrays;
 import java.util.List;
 
 import org.junit.BeforeClass;
@@ -27,8 +28,11 @@ import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import org.apache.cassandra.cql3.ast.Select;
+import org.apache.cassandra.cql3.ast.Txn;
 import org.apache.cassandra.distributed.api.SimpleQueryResult;
 import org.apache.cassandra.service.accord.AccordService;
+import org.assertj.core.api.Assertions;
 
 import static java.util.function.UnaryOperator.identity;
 
@@ -54,25 +58,29 @@ public class NewSchemaTest extends AccordTestBase
         for (int i = 0; i < 20; i++)
         {
             String ks = "ks" + i;
-            String table = ks + ".tbl" + i;
+            String tableName = "tbl" + i;
+            String table = ks + "." + tableName;
             SHARED_CLUSTER.schemaChange("CREATE KEYSPACE " + ks + " WITH REPLICATION={'class':'SimpleStrategy', 'replication_factor': 1}");
             SHARED_CLUSTER.schemaChange(String.format("CREATE TABLE %s (pk blob primary key) WITH transactional_mode='full'", table));
             SHARED_CLUSTER.forEach(node -> node.runOnInstance(() -> AccordService.instance().setCacheSize(0)));
 
             List<ByteBuffer> keys = tokensToKeys(tokens());
 
-            read(table, keys).exec();
+            read(ks, tableName, keys).exec();
         }
     }
 
-    private static Query read(String table, List<ByteBuffer> keys)
+    private static Query read(String ks, String table, List<ByteBuffer> keys)
     {
         assert !keys.isEmpty();
-        StringBuilder sb = new StringBuilder();
+        Txn.Builder builder = new Txn.Builder();
         for (int i = 0; i < keys.size(); i++)
-            sb.append("let row").append(i).append(" = (select * from ").append(table).append(" where pk = ?);\n");
-        sb.append("SELECT row0.pk;");
-        return new Query(sb.toString(), keys.toArray());
+            builder.addLet("row" + i, new Select.Builder().wildcard().table(ks, table).value("pk", keys.get(i)));
+        builder.addReturnReferences("row0.pk");
+        Txn txn = builder.build();
+        ByteBuffer[] binds = txn.bindsEncoded();
+        Assertions.assertThat(Arrays.asList(binds)).isEqualTo(keys);
+        return new Query(txn.toCQL(), binds);
     }
 
     private static class Query
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/CasMultiNodeTableWalkBase.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/CasMultiNodeTableWalkBase.java
index ee2be216f0..31d1aab31f 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/CasMultiNodeTableWalkBase.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/CasMultiNodeTableWalkBase.java
@@ -18,8 +18,8 @@
 
 package org.apache.cassandra.distributed.test.cql3;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gen;
+import accord.utils.RandomSource;
 import org.apache.cassandra.config.Config;
 import org.apache.cassandra.cql3.KnownIssue;
 import org.apache.cassandra.cql3.ast.CasCondition;
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkBase.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkBase.java
index 5de56c9230..d6c0183473 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkBase.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkBase.java
@@ -20,7 +20,7 @@ package org.apache.cassandra.distributed.test.cql3;
 
 import java.io.IOException;
 
-import accord.utilsfork.RandomSource;
+import accord.utils.RandomSource;
 import net.bytebuddy.ByteBuddy;
 import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;
 import net.bytebuddy.implementation.MethodDelegation;
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithReadRepairTest.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithReadRepairTest.java
index 7d1b7ab71d..7727e3a76a 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithReadRepairTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithReadRepairTest.java
@@ -20,7 +20,7 @@ package org.apache.cassandra.distributed.test.cql3;
 
 import org.junit.Ignore;
 
-import accord.utilsfork.Property;
+import accord.utils.Property;
 import org.apache.cassandra.distributed.Cluster;
 import org.apache.cassandra.service.reads.repair.ReadRepairStrategy;
 
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithoutReadRepairTest.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithoutReadRepairTest.java
index f0c3d57ec4..5a0ce66ccc 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithoutReadRepairTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTableWalkWithoutReadRepairTest.java
@@ -18,7 +18,7 @@
 
 package org.apache.cassandra.distributed.test.cql3;
 
-import accord.utilsfork.Property;
+import accord.utils.Property;
 import org.apache.cassandra.distributed.Cluster;
 import org.apache.cassandra.service.reads.repair.ReadRepairStrategy;
 
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTokenConflictTest.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTokenConflictTest.java
index 64d6b91ea3..969b075643 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTokenConflictTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/MultiNodeTokenConflictTest.java
@@ -20,8 +20,8 @@ package org.apache.cassandra.distributed.test.cql3;
 
 import java.io.IOException;
 
-import accord.utilsfork.Property;
-import accord.utilsfork.RandomSource;
+import accord.utils.Property;
+import accord.utils.RandomSource;
 import org.apache.cassandra.distributed.Cluster;
 import org.apache.cassandra.distributed.api.ConsistencyLevel;
 import org.apache.cassandra.distributed.api.IInstanceConfig;
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV1MultiNodeTableWalkTest.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV1MultiNodeTableWalkTest.java
index 1d8a5919f1..0cf333d2ab 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV1MultiNodeTableWalkTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV1MultiNodeTableWalkTest.java
@@ -18,7 +18,7 @@
 
 package org.apache.cassandra.distributed.test.cql3;
 
-import accord.utilsfork.Property;
+import accord.utils.Property;
 import org.apache.cassandra.config.Config;
 import org.apache.cassandra.distributed.Cluster;
 
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV2MultiNodeTableWalkTest.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV2MultiNodeTableWalkTest.java
index d8d8bcb1bd..fa098edaac 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV2MultiNodeTableWalkTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/PaxosV2MultiNodeTableWalkTest.java
@@ -18,7 +18,7 @@
 
 package org.apache.cassandra.distributed.test.cql3;
 
-import accord.utilsfork.Property;
+import accord.utils.Property;
 import org.apache.cassandra.config.Config;
 import org.apache.cassandra.distributed.Cluster;
 
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTableWalkTest.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTableWalkTest.java
index 5bffefb111..60b1090dc1 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTableWalkTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTableWalkTest.java
@@ -38,10 +38,10 @@ import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
-import accord.utilsfork.Property;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.Property;
+import accord.utils.RandomSource;
 import org.apache.cassandra.cql3.KnownIssue;
 import org.apache.cassandra.cql3.ast.Bind;
 import org.apache.cassandra.cql3.ast.Conditional;
@@ -72,8 +72,8 @@ import org.apache.cassandra.utils.CassandraGenerators.TableMetadataBuilder;
 import org.apache.cassandra.utils.Generators;
 import org.apache.cassandra.utils.ImmutableUniqueList;
 
-import static accord.utilsfork.Property.commands;
-import static accord.utilsfork.Property.stateful;
+import static accord.utils.Property.commands;
+import static accord.utils.Property.stateful;
 import static org.apache.cassandra.utils.AbstractTypeGenerators.getTypeSupport;
 import static org.apache.cassandra.utils.Generators.toGen;
 
@@ -371,7 +371,8 @@ public class SingleNodeTableWalkTest extends StatefulASTBase
                                   .addIf(State::allowNonPartitionMultiColumnQuery, this::multiColumnQuery)
                                   .addIf(State::allowPartitionQuery, this::partitionRestrictedQuery)
                                   .destroyState(State::close)
-                                  .onSuccess(onSuccess(logger))
+                    // TODO: add back when accord-core Property supports it
+//                                  .onSuccess(onSuccess(logger))
                                   .build());
         }
     }
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTokenConflictTest.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTokenConflictTest.java
index df27614397..3a7930ee42 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTokenConflictTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/SingleNodeTokenConflictTest.java
@@ -37,10 +37,10 @@ import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
-import accord.utilsfork.Property;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.Property;
+import accord.utils.RandomSource;
 import org.apache.cassandra.cql3.ColumnIdentifier;
 import org.apache.cassandra.cql3.KnownIssue;
 import org.apache.cassandra.cql3.ast.Conditional.Where.Inequality;
@@ -66,8 +66,8 @@ import org.apache.cassandra.utils.Generators;
 import org.apache.cassandra.utils.ImmutableUniqueList;
 import org.quicktheories.generators.SourceDSL;
 
-import static accord.utilsfork.Property.commands;
-import static accord.utilsfork.Property.stateful;
+import static accord.utils.Property.commands;
+import static accord.utils.Property.stateful;
 import static org.apache.cassandra.dht.Murmur3Partitioner.LongToken.keyForToken;
 import static org.apache.cassandra.utils.Generators.toGen;
 
@@ -267,7 +267,8 @@ public class SingleNodeTokenConflictTest extends StatefulASTBase
                                   .addIf(State::hasEnoughMemtable, StatefulASTBase::flushTable)
                                   .addIf(State::hasEnoughSSTables, StatefulASTBase::compactTable)
                                   .destroyState(State::close)
-                                  .onSuccess(onSuccess(logger))
+                    // TODO: add back when accord-core Property supports it
+                                  //.onSuccess(onSuccess(logger))
                                   .build());
         }
     }
@@ -402,7 +403,8 @@ public class SingleNodeTokenConflictTest extends StatefulASTBase
             LinkedHashSet<ByteBuffer> pks = new LinkedHashSet<>();
             for (int i = 0; i < numPks; i++)
             {
-                ByteBuffer value = rs.pickOrderedSet(available);
+                // TODO: add back when accord-core Property supports it
+                ByteBuffer value = null;//rs.pickOrderedSet(available);
                 pks.add(value);
                 available.remove(value);
             }
diff --git a/test/distributed/org/apache/cassandra/distributed/test/cql3/StatefulASTBase.java b/test/distributed/org/apache/cassandra/distributed/test/cql3/StatefulASTBase.java
index 90a5385667..423bfd4477 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/cql3/StatefulASTBase.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/cql3/StatefulASTBase.java
@@ -35,12 +35,12 @@ import javax.annotation.Nullable;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.collect.Maps;
-import org.slf4j.Logger;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
-import accord.utilsfork.Property;
-import accord.utilsfork.RandomSource;
+
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.Property;
+import accord.utils.RandomSource;
 import com.datastax.driver.core.ColumnDefinitions;
 import com.datastax.driver.core.ResultSet;
 import com.datastax.driver.core.Row;
@@ -86,7 +86,7 @@ import org.apache.cassandra.utils.FastByteOperations;
 import org.apache.cassandra.utils.Generators;
 import org.quicktheories.generators.SourceDSL;
 
-import static accord.utilsfork.Property.multistep;
+import static accord.utils.Property.multistep;
 import static org.apache.cassandra.distributed.test.JavaDriverUtils.toDriverCL;
 import static org.apache.cassandra.utils.AbstractTypeGenerators.overridePrimitiveTypeSupport;
 import static org.apache.cassandra.utils.AbstractTypeGenerators.stringComparator;
@@ -177,10 +177,11 @@ public class StatefulASTBase extends TestBaseImpl
         return cluster;
     }
 
-    protected <S extends BaseState> Property.StatefulSuccess<S, Void> onSuccess(Logger logger)
-    {
-        return (state, sut, history) -> logger.info("Successful for the following:\nState {}\nHistory:\n{}", state, Property.formatList("\t\t", history));
-    }
+    // TODO: add back when accord-core Property supports it
+//    protected <S extends BaseState> Property.StatefulSuccess<S, Void> onSuccess(Logger logger)
+//    {
+//        return (state, sut, history) -> logger.info("Successful for the following:\nState {}\nHistory:\n{}", state, Property.formatList("\t\t", history));
+//    }
 
     protected static <S extends BaseState> Property.Command<S, Void, ?> flushTable(RandomSource rs, S state)
     {
diff --git a/test/distributed/org/apache/cassandra/distributed/test/log/ClusterMetadataTestHelper.java b/test/distributed/org/apache/cassandra/distributed/test/log/ClusterMetadataTestHelper.java
index 69d4001bd1..b606a94fc4 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/log/ClusterMetadataTestHelper.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/log/ClusterMetadataTestHelper.java
@@ -59,6 +59,7 @@ import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.schema.SchemaTransformation;
 import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.service.accord.AccordStaleReplicas;
+import org.apache.cassandra.service.consensus.migration.ConsensusMigrationState;
 import org.apache.cassandra.tcm.AtomicLongBackedProcessor;
 import org.apache.cassandra.tcm.ClusterMetadata;
 import org.apache.cassandra.tcm.ClusterMetadataService;
@@ -158,41 +159,22 @@ public class ClusterMetadataTestHelper
                                    AccordFastPath.EMPTY,
                                    LockedRanges.EMPTY,
                                    InProgressSequences.EMPTY,
-                                   null,
+                                   ConsensusMigrationState.EMPTY,
                                    ImmutableMap.of(),
                                    AccordStaleReplicas.EMPTY);
     }
 
     public static ClusterMetadata minimalForTesting(IPartitioner partitioner)
     {
-        return new ClusterMetadata(Epoch.EMPTY,
-                                   partitioner,
-                                   null,
-                                   null,
-                                   null,
-                                   DataPlacements.empty(),
-                                   AccordFastPath.EMPTY,
-                                   null,
-                                   null,
-                                   null,
-                                   ImmutableMap.of(),
-                                   AccordStaleReplicas.EMPTY);
+        return minimalForTesting(Epoch.EMPTY, partitioner);
     }
 
     public static ClusterMetadata minimalForTesting(Keyspaces keyspaces)
     {
-        return new ClusterMetadata(Epoch.EMPTY,
-                                   Murmur3Partitioner.instance,
-                                   new DistributedSchema(keyspaces),
-                                   null,
-                                   null,
-                                   DataPlacements.empty(),
-                                   AccordFastPath.EMPTY,
-                                   null,
-                                   null,
-                                   null,
-                                   ImmutableMap.of(),
-                                   AccordStaleReplicas.EMPTY);
+        return minimalForTesting(Murmur3Partitioner.instance).transformer()
+                                                             .with(new DistributedSchema(keyspaces))
+                                                             .build()
+               .metadata.forceEpoch(Epoch.EMPTY);
     }
 
     public static ClusterMetadataService syncInstanceForTest()
diff --git a/test/distributed/org/apache/cassandra/fuzz/snapshots/SnapshotsTest.java b/test/distributed/org/apache/cassandra/fuzz/snapshots/SnapshotsTest.java
index 233f49976d..2145a0ac6a 100644
--- a/test/distributed/org/apache/cassandra/fuzz/snapshots/SnapshotsTest.java
+++ b/test/distributed/org/apache/cassandra/fuzz/snapshots/SnapshotsTest.java
@@ -41,8 +41,8 @@ import com.google.common.collect.Maps;
 import com.google.common.util.concurrent.Uninterruptibles;
 import org.junit.Test;
 
-import accord.utilsfork.Property.StateOnlyCommand;
-import accord.utilsfork.RandomSource;
+import accord.utils.Property.StateOnlyCommand;
+import accord.utils.RandomSource;
 import org.apache.cassandra.distributed.Cluster;
 import org.apache.cassandra.distributed.api.Feature;
 import org.apache.cassandra.distributed.api.IInvokableInstance;
@@ -65,8 +65,8 @@ import org.quicktheories.core.RandomnessSource;
 import org.quicktheories.generators.SourceDSL;
 import org.quicktheories.impl.JavaRandom;
 
-import static accord.utilsfork.Property.commands;
-import static accord.utilsfork.Property.stateful;
+import static accord.utils.Property.commands;
+import static accord.utils.Property.stateful;
 import static com.google.common.collect.Sets.difference;
 import static java.lang.String.format;
 import static java.util.UUID.randomUUID;
diff --git a/test/distributed/org/apache/cassandra/fuzz/topology/AccordTopologyMixupTest.java b/test/distributed/org/apache/cassandra/fuzz/topology/AccordTopologyMixupTest.java
new file mode 100644
index 0000000000..b077479696
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/fuzz/topology/AccordTopologyMixupTest.java
@@ -0,0 +1,321 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.fuzz.topology;
+
+import java.nio.ByteBuffer;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.CopyOnWriteArrayList;
+import java.util.concurrent.ExecutionException;
+import java.util.function.BiFunction;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
+import javax.annotation.Nullable;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import accord.coordinate.Exhausted;
+import accord.coordinate.Preempted;
+import accord.coordinate.Timeout;
+import accord.local.Node;
+import accord.primitives.Ranges;
+import accord.primitives.Seekables;
+import accord.primitives.TxnId;
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.Invariants;
+import accord.utils.Property;
+import accord.utils.Property.Command;
+import accord.utils.RandomSource;
+import org.apache.cassandra.config.CassandraRelevantProperties;
+import org.apache.cassandra.config.Config;
+import org.apache.cassandra.cql3.ast.Mutation;
+import org.apache.cassandra.cql3.ast.Statement;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.api.SimpleQueryResult;
+import org.apache.cassandra.distributed.shared.ClusterUtils;
+import org.apache.cassandra.distributed.test.accord.AccordTestBase;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.accord.AccordService;
+import org.apache.cassandra.service.accord.api.AccordAgent;
+import org.apache.cassandra.service.consensus.TransactionalMode;
+import org.apache.cassandra.tcm.Epoch;
+import org.apache.cassandra.utils.ASTGenerators;
+import org.apache.cassandra.utils.CassandraGenerators;
+import org.apache.cassandra.utils.Isolated;
+import org.apache.cassandra.utils.Shared;
+
+import static org.apache.cassandra.utils.AccordGenerators.fromQT;
+
+public class AccordTopologyMixupTest extends TopologyMixupTestBase<AccordTopologyMixupTest.Spec>
+{
+    private static final Logger logger = LoggerFactory.getLogger(AccordTopologyMixupTest.class);
+
+    static
+    {
+        CassandraRelevantProperties.ACCORD_AGENT_CLASS.setString(InterceptAgent.class.getName());
+        // enable most expensive debugging checks
+        CassandraRelevantProperties.ACCORD_KEY_PARANOIA_CPU.setString(Invariants.Paranoia.QUADRATIC.name());
+        CassandraRelevantProperties.ACCORD_KEY_PARANOIA_MEMORY.setString(Invariants.Paranoia.QUADRATIC.name());
+        CassandraRelevantProperties.ACCORD_KEY_PARANOIA_COSTFACTOR.setString(Invariants.ParanoiaCostFactor.HIGH.name());
+    }
+
+    private static final List<TransactionalMode> TRANSACTIONAL_MODES = Stream.of(TransactionalMode.values()).filter(t -> t.accordIsEnabled).collect(Collectors.toList());
+
+    @Override
+    protected Gen<State<Spec>> stateGen()
+    {
+        return AccordState::new;
+    }
+
+    @Override
+    protected void preCheck(Property.StatefulBuilder builder)
+    {
+        // if a failing seed is detected, populate here
+        // Example: builder.withSeed(42L);
+    }
+
+    private static Spec createSchemaSpec(RandomSource rs, Cluster cluster)
+    {
+        TransactionalMode mode = rs.pick(TRANSACTIONAL_MODES);
+        boolean enableMigration = allowsMigration(mode) && rs.nextBoolean();
+        TableMetadata metadata = fromQT(new CassandraGenerators.TableMetadataBuilder()
+                .withKeyspaceName(KEYSPACE)
+                .withTableKinds(TableMetadata.Kind.REGULAR)
+                .withKnownMemtables()
+                //TODO (coverage): include "fast_path = 'keyspace'" override
+                .withTransactionalMode(enableMigration ? TransactionalMode.off : mode)
+                .withoutEmpty()
+                .build())
+                .next(rs);
+        maybeCreateUDTs(cluster, metadata);
+        String schemaCQL = metadata.toCqlString(false, false, false);
+        logger.info("Creating test table:\n{}", schemaCQL);
+        cluster.schemaChange(schemaCQL);
+        if (enableMigration)
+        {
+            cluster.schemaChange("ALTER TABLE " + metadata + " WITH " + mode.asCqlParam());
+            cluster.get(1).nodetoolResult("consensus_admin", "begin-migration", "--target-protocol", "accord", metadata.keyspace, metadata.name).asserts().success();
+        }
+        return new Spec(mode, enableMigration, metadata);
+    }
+
+    private static BiFunction<RandomSource, State<Spec>, Command<State<Spec>, Void, ?>> cqlOperations(Spec spec)
+    {
+        Gen<Statement> select = (Gen<Statement>) (Gen<?>) fromQT(new ASTGenerators.SelectGenBuilder(spec.metadata).withLimit1().build());
+        Gen<Statement> mutation = (Gen<Statement>) (Gen<?>) fromQT(new ASTGenerators.MutationGenBuilder(spec.metadata).withoutTimestamp().build());
+        Gen<Statement> txn = (Gen<Statement>) (Gen<?>) fromQT(new ASTGenerators.TxnGenBuilder(spec.metadata).build());
+        Map<Gen<Statement>, Integer> operations = new LinkedHashMap<>();
+        operations.put(select, 1);
+        operations.put(mutation, 1);
+        operations.put(txn, 1);
+        Gen<Statement> statementGen = Gens.oneOf(operations);
+        return (rs, state) -> cqlOperation(rs, state, statementGen);
+    }
+
+    private static Command<State<Spec>, Void, ?> cqlOperation(RandomSource rs, State<Spec> state, Gen<Statement> statementGen)
+    {
+        Statement stmt = statementGen.next(rs);
+        String cql;
+        //TODO (usability): are there any transaction_modes that actually need simple mutations/select to be wrapped in a BEGIN TRANSACTION?  If not then this logica can be simplified
+        if (stmt.kind() == Statement.Kind.TXN || stmt.kind() == Statement.Kind.MUTATION && ((Mutation) stmt).isCas())
+            cql = stmt.toCQL();
+        else cql = wrapInTxn(stmt.toCQL());
+        IInvokableInstance node = state.cluster.get(rs.pickInt(state.topologyHistory.up()));
+        return new Property.SimpleCommand<>(node + ": " + stmt.kind() + "; epoch=" + state.currentEpoch.get(), s2 -> executeTxn(s2.cluster, node, cql, stmt.bindsEncoded()));
+    }
+
+    private static boolean allowsMigration(TransactionalMode mode)
+    {
+        switch (mode)
+        {
+            case unsafe_writes:
+            case mixed_reads:
+            case full:
+                return true;
+            default:
+                return false;
+        }
+    }
+
+    private static SimpleQueryResult executeTxn(Cluster cluster, IInvokableInstance node, String stmt, ByteBuffer[] binds)
+    {
+        if (!AccordTestBase.isIdempotent(node, stmt))
+        {
+            // won't be able to retry...
+            return node.coordinator().executeWithResult(stmt, ConsistencyLevel.ANY, (Object[]) binds);
+        }
+        return AccordTestBase.executeWithRetry(cluster, node, stmt, (Object[]) binds);
+    }
+
+    private static void maybeCreateUDTs(Cluster cluster, TableMetadata metadata)
+    {
+        CassandraGenerators.visitUDTs(metadata, next -> {
+            String cql = next.toCqlString(false, false, false);
+            logger.warn("Creating UDT {}", cql);
+            cluster.schemaChange(cql);
+        });
+    }
+
+    public static class Spec implements TopologyMixupTestBase.SchemaSpec
+    {
+        private final TransactionalMode mode;
+        private final boolean enableMigration;
+        private final TableMetadata metadata;
+
+        public Spec(TransactionalMode mode, boolean enableMigration, TableMetadata metadata)
+        {
+            this.mode = mode;
+            this.enableMigration = enableMigration;
+            this.metadata = metadata;
+        }
+
+        @Override
+        public String name()
+        {
+            return metadata.name;
+        }
+
+        @Override
+        public String keyspaceName()
+        {
+            return metadata.keyspace;
+        }
+    }
+
+    private static class AccordState extends State<Spec> implements SharedState.Listener
+    {
+        private final List<Runnable> onError = new CopyOnWriteArrayList<>();
+
+        public AccordState(RandomSource rs)
+        {
+            super(rs, AccordTopologyMixupTest::createSchemaSpec, AccordTopologyMixupTest::cqlOperations);
+
+            SharedState.listeners.add(this);
+        }
+
+        @Override
+        protected void onConfigure(IInstanceConfig c)
+        {
+            c.set("accord.shard_count", 1)
+                    .set("paxos_variant", Config.PaxosVariant.v2.name());
+        }
+
+        @Override
+        protected void onStartupComplete(long tcmEpoch)
+        {
+            cluster.forEach(i -> {
+                if (i.isShutdown()) return;
+                i.runOnInstance(() -> {
+                    try
+                    {
+                        AccordService.instance().epochReady(Epoch.create(tcmEpoch)).get();
+                    }
+                    catch (InterruptedException | ExecutionException e)
+                    {
+                        throw new RuntimeException(e);
+                    }
+                });
+            });
+        }
+
+        @Override
+        public void debugTxn(@Nullable Node.Id exclude, String type, TxnId txnId)
+        {
+            onError.add(new Runnable()
+            {
+                @Override
+                public void run()
+                {
+                    // this runs in the main thread, so is actually thread safe
+                    int[] up = topologyHistory.up();
+                    logger.error("{} failed with txn id {}; global debug summary:\n{}", type, txnId, ClusterUtils.queryTxnStateAsString(cluster, txnId, up));
+                    onError.remove(this);
+                }
+            });
+        }
+
+        @Override
+        public void close() throws Exception
+        {
+            for (Runnable r : onError)
+            {
+                try
+                {
+                    r.run();
+                }
+                catch (Throwable t)
+                {
+                    // TODO (correctness): how to handle?
+                    logger.error("Unhandled error in onError listeners", t);
+                }
+            }
+            onError.clear();
+            SharedState.listeners.remove(this);
+            super.close();
+        }
+    }
+
+    @Shared
+    public static class SharedState
+    {
+        public interface Listener
+        {
+            void debugTxn(Node.Id node, String type, TxnId txnId);
+        }
+
+        public static final CopyOnWriteArrayList<Listener> listeners = new CopyOnWriteArrayList<>();
+
+        public static void debugTxn(@Nullable Integer node, String type, String id)
+        {
+            Node.Id nodeId = node == null ? null : new Node.Id(node);
+            TxnId txnId = TxnId.parse(id);
+            listeners.forEach(l -> l.debugTxn(nodeId, type, txnId));
+        }
+    }
+
+    @Isolated
+    public static class InterceptAgent extends AccordAgent
+    {
+        @Override
+        public void onFailedBarrier(TxnId id, Seekables<?, ?> keysOrRanges, Throwable cause)
+        {
+            if (cause instanceof Timeout || cause instanceof Preempted)
+            {
+                SharedState.debugTxn(null, "Repair Barrier", id.toString());
+            }
+        }
+
+        @Override
+        public void onFailedBootstrap(String phase, Ranges ranges, Runnable retry, Throwable failure)
+        {
+            if (failure instanceof Exhausted)
+            {
+                Exhausted e = (Exhausted) failure;
+                SharedState.debugTxn(self.id, "Bootstrap#" + phase, e.txnId().toString());
+            }
+            super.onFailedBootstrap(phase, ranges, retry, failure);
+        }
+    }
+}
diff --git a/test/distributed/org/apache/cassandra/fuzz/topology/HarryTopologyMixupTest.java b/test/distributed/org/apache/cassandra/fuzz/topology/HarryTopologyMixupTest.java
deleted file mode 100644
index 73f59c2d43..0000000000
--- a/test/distributed/org/apache/cassandra/fuzz/topology/HarryTopologyMixupTest.java
+++ /dev/null
@@ -1,228 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.cassandra.fuzz.topology;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.function.BiFunction;
-import java.util.function.Consumer;
-import java.util.function.Function;
-import javax.annotation.Nullable;
-
-import com.google.common.base.Throwables;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import accord.utilsfork.Gen;
-import accord.utilsfork.Property;
-import accord.utilsfork.Property.Command;
-import accord.utilsfork.Property.PreCheckResult;
-import accord.utilsfork.Property.SimpleCommand;
-import accord.utilsfork.RandomSource;
-import org.apache.cassandra.distributed.Cluster;
-import org.apache.cassandra.distributed.api.IInstanceConfig;
-import org.apache.cassandra.exceptions.RequestTimeoutException;
-import org.apache.cassandra.harry.SchemaSpec;
-import org.apache.cassandra.harry.dsl.HistoryBuilder;
-import org.apache.cassandra.harry.dsl.ReplayingHistoryBuilder;
-import org.apache.cassandra.harry.execution.InJvmDTestVisitExecutor;
-import org.apache.cassandra.harry.gen.EntropySource;
-import org.apache.cassandra.harry.gen.Generator;
-import org.apache.cassandra.harry.gen.Generators;
-import org.apache.cassandra.harry.gen.SchemaGenerators;
-import org.apache.cassandra.harry.gen.rng.JdkRandomEntropySource;
-import org.apache.cassandra.utils.AssertionUtils;
-import org.assertj.core.api.Condition;
-
-import static org.apache.cassandra.distributed.shared.ClusterUtils.waitForCMSToQuiesce;
-
-public class HarryTopologyMixupTest extends TopologyMixupTestBase<HarryTopologyMixupTest.Spec>
-{
-    protected static final Condition<Object> TIMEOUT_CHECKER = AssertionUtils.isInstanceof(RequestTimeoutException.class);
-    private static final Logger logger = LoggerFactory.getLogger(HarryTopologyMixupTest.class);
-
-    public HarryTopologyMixupTest()
-    {
-    }
-
-    @Override
-    protected Gen<State<Spec>> stateGen()
-    {
-        return HarryState::new;
-    }
-
-    @Override
-    protected void preCheck(Property.StatefulBuilder builder)
-    {
-        // if a failing seed is detected, populate here
-        // Example: builder.withSeed(42L);
-    }
-
-    @Override
-    protected void destroyState(State<Spec> state, @Nullable Throwable cause)
-    {
-        if (cause != null) return;
-        if (((HarryState) state).numInserts > 0)
-        {
-            for (Integer pkIdx : state.schema.pkGen.generated())
-                state.schema.harry.selectPartition(pkIdx);
-        }
-    }
-
-    private static BiFunction<RandomSource, Cluster, Spec> createSchemaSpec()
-    {
-        return (rs, cluster) -> {
-            EntropySource rng = new JdkRandomEntropySource(rs.nextLong());
-            Generator<SchemaSpec> schemaGen = SchemaGenerators.schemaSpecGen("harry", "table", 1000);;
-            SchemaSpec schema = schemaGen.generate(rng);
-
-            HistoryBuilder harry = new ReplayingHistoryBuilder(schema.valueGenerators,
-                    hb -> {
-                        InJvmDTestVisitExecutor.Builder builder = InJvmDTestVisitExecutor.builder();
-                        return builder.nodeSelector(new InJvmDTestVisitExecutor.NodeSelector()
-                                {
-                                    private final AtomicLong cnt = new AtomicLong();
-
-                                    @Override
-                                    public int select(long lts)
-                                    {
-                                        for (int i = 0; i < 42; i++)
-                                        {
-                                            int selected = (int) (cnt.getAndIncrement() % cluster.size() + 1);
-                                            if (!cluster.get(selected).isShutdown())
-                                                return selected;
-                                        }
-                                        throw new IllegalStateException("Unable to find an alive instance");
-                                    }
-                                })
-                                .retryPolicy(t -> {
-                                    t = Throwables.getRootCause(t);
-                                    if (!TIMEOUT_CHECKER.matches(t))
-                                        return false;
-                                    return false;
-                                })
-                                .build(schema, hb, cluster);
-                    });
-            cluster.schemaChange(String.format("CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 3};", schema.keyspace));
-            cluster.schemaChange(schema.compile());
-            waitForCMSToQuiesce(cluster, cluster.get(1));
-            return new Spec(harry, schema);
-        };
-    }
-
-    private static class HarryCommand extends SimpleCommand<State<Spec>>
-    {
-        HarryCommand(Function<State<Spec>, String> name, Consumer<State<Spec>> fn)
-        {
-            super(name, fn);
-        }
-
-        @Override
-        public PreCheckResult checkPreconditions(State<Spec> state)
-        {
-            int clusterSize = state.topologyHistory.up().length;
-            return clusterSize >= 3 ? PreCheckResult.Ok : PreCheckResult.Ignore;
-        }
-    }
-
-    private static CommandGen<Spec> cqlOperations(Spec spec)
-    {
-        Command<State<Spec>, Void, ?> insert = new HarryCommand(state -> "Harry Insert" + state.commandNamePostfix(), state -> {
-            spec.harry.insert();
-            ((HarryState) state).numInserts++;
-        });
-        return (rs, state) -> {
-            HarryState harryState = (HarryState) state;
-            TopologyHistory history = state.topologyHistory;
-            // if any topology change happened, then always validate all
-            if (harryState.generation != history.generation())
-            {
-                harryState.generation = history.generation();
-                return validateAll(state);
-            }
-            if ((harryState.numInserts > 0 && rs.decide(0.2))) // 20% of the time do reads
-                return validateAll(state);
-            return insert;
-        };
-    }
-
-    private static Command<State<Spec>, Void, ?> validateAll(State<Spec> state)
-    {
-        Spec spec = state.schema;
-        List<Command<State<Spec>, Void, ?>> reads = new ArrayList<>();
-
-        for (Integer pkIdx : spec.pkGen.generated())
-        {
-            long pd = spec.harry.valueGenerators().pkGen().descriptorAt(pkIdx);
-            reads.add(new HarryCommand(s -> String.format("Harry Validate pd=%d%s", pd, state.commandNamePostfix()), s -> spec.harry.selectPartition(pkIdx)));
-        }
-        reads.add(new HarryCommand(s -> "Reset Harry Write State" + state.commandNamePostfix(), s -> ((HarryState) s).numInserts = 0));
-        return Property.multistep(reads);
-    }
-
-    public static class Spec implements Schema
-    {
-        private final Generators.TrackingGenerator<Integer> pkGen;
-        private final HistoryBuilder harry;
-        private final SchemaSpec schema;
-
-        public Spec(HistoryBuilder harry, SchemaSpec schema)
-        {
-            this.harry = harry;
-            this.schema = schema;
-            this.pkGen = Generators.tracking(Generators.int32(0, schema.valueGenerators.pkPopulation()));
-        }
-
-        @Override
-        public String table()
-        {
-            return schema.table;
-        }
-
-        @Override
-        public String keyspace()
-        {
-            return schema.keyspace;
-        }
-
-        @Override
-        public String createSchema()
-        {
-            return schema.compile();
-        }
-    }
-
-    public class HarryState extends State<Spec>
-    {
-        private long generation;
-        private int numInserts = 0;
-
-        public HarryState(RandomSource rs)
-        {
-            super(rs, createSchemaSpec(), HarryTopologyMixupTest::cqlOperations);
-        }
-
-        @Override
-        protected void onConfigure(IInstanceConfig config)
-        {
-            config.set("metadata_snapshot_frequency", 5);
-        }
-    }
-}
\ No newline at end of file
diff --git a/test/distributed/org/apache/cassandra/fuzz/topology/TopologyMixupTestBase.java b/test/distributed/org/apache/cassandra/fuzz/topology/TopologyMixupTestBase.java
index 74988fb618..a027518847 100644
--- a/test/distributed/org/apache/cassandra/fuzz/topology/TopologyMixupTestBase.java
+++ b/test/distributed/org/apache/cassandra/fuzz/topology/TopologyMixupTestBase.java
@@ -18,7 +18,6 @@
 
 package org.apache.cassandra.fuzz.topology;
 
-import javax.annotation.Nullable;
 import java.io.IOException;
 import java.io.UncheckedIOException;
 import java.net.InetSocketAddress;
@@ -26,6 +25,7 @@ import java.time.Duration;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
+import java.util.Comparator;
 import java.util.EnumSet;
 import java.util.HashSet;
 import java.util.LinkedHashMap;
@@ -33,76 +33,64 @@ import java.util.List;
 import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Objects;
-import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.atomic.AtomicLong;
-import java.util.function.BiConsumer;
 import java.util.function.BiFunction;
 import java.util.function.Function;
 import java.util.stream.Collectors;
-import java.util.stream.Stream;
+import javax.annotation.Nullable;
 
-import com.google.common.base.Throwables;
-import com.google.common.collect.Iterables;
 import com.google.common.collect.Sets;
-import org.agrona.collections.Int2ObjectHashMap;
-import org.agrona.collections.IntArrayList;
-import org.agrona.collections.IntHashSet;
 import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
-import accord.utilsfork.Invariants;
-import accord.utilsfork.Property;
-import accord.utilsfork.Property.Command;
-import accord.utilsfork.Property.SimpleCommand;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.Invariants;
+import accord.utils.Property;
+import accord.utils.Property.Command;
+import accord.utils.Property.SimpleCommand;
+import accord.utils.RandomSource;
+import org.agrona.collections.Int2ObjectHashMap;
+import org.agrona.collections.IntArrayList;
+import org.agrona.collections.IntHashSet;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.YamlConfigurationLoader;
 import org.apache.cassandra.distributed.Cluster;
-import org.apache.cassandra.distributed.Constants;
 import org.apache.cassandra.distributed.api.Feature;
-import org.apache.cassandra.distributed.api.ICoordinator;
 import org.apache.cassandra.distributed.api.IInstanceConfig;
 import org.apache.cassandra.distributed.api.IInvokableInstance;
 import org.apache.cassandra.distributed.api.NodeToolResult;
-import org.apache.cassandra.distributed.api.Row;
-import org.apache.cassandra.distributed.api.SimpleQueryResult;
 import org.apache.cassandra.distributed.api.TokenSupplier;
 import org.apache.cassandra.distributed.impl.INodeProvisionStrategy;
 import org.apache.cassandra.distributed.impl.InstanceConfig;
 import org.apache.cassandra.distributed.shared.ClusterUtils;
 import org.apache.cassandra.distributed.test.TestBaseImpl;
-import org.apache.cassandra.harry.model.TokenPlacementModelHelper;
 import org.apache.cassandra.locator.InetAddressAndPort;
+import org.apache.cassandra.metrics.TCMMetrics;
 import org.apache.cassandra.schema.ReplicationParams;
 import org.apache.cassandra.tcm.ClusterMetadata;
 import org.apache.cassandra.tcm.ClusterMetadataService;
 import org.apache.cassandra.tcm.Epoch;
-import org.apache.cassandra.tools.nodetool.formatter.TableBuilder;
-import org.apache.cassandra.utils.Clock;
+import org.apache.cassandra.tcm.Retry;
+import org.apache.cassandra.tcm.log.Entry;
+import org.apache.cassandra.tcm.log.LogState;
 import org.apache.cassandra.utils.ConfigGenBuilder;
-import org.apache.cassandra.utils.Retry;
-
-import static accord.utilsfork.Property.commands;
-import static accord.utilsfork.Property.ignoreCommand;
-import static accord.utilsfork.Property.multistep;
-import static accord.utilsfork.Property.stateful;
-import static org.apache.cassandra.harry.model.TokenPlacementModel.Range;
-import static org.apache.cassandra.harry.model.TokenPlacementModel.Replica;
-import static org.apache.cassandra.harry.model.TokenPlacementModel.ReplicatedRanges;
-import static org.apache.cassandra.harry.model.TokenPlacementModel.ReplicationFactor;
-import static org.apache.cassandra.harry.model.TokenPlacementModel.SimpleReplicationFactor;
+
+import static accord.utils.Property.commands;
+import static accord.utils.Property.ignoreCommand;
+import static accord.utils.Property.multistep;
+import static accord.utils.Property.stateful;
+import static java.util.concurrent.TimeUnit.NANOSECONDS;
 
 /**
  * These tests can create many instances, so mac users may need to run the following to avoid address bind failures
  * <p>
  * {@code for id in $(seq 0 15); do sudo ifconfig lo0 alias "127.0.0.$id"; done;}
  */
-public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Schema> extends TestBaseImpl
+public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.SchemaSpec> extends TestBaseImpl
 {
     private static final Logger logger = LoggerFactory.getLogger(TopologyMixupTestBase.class);
 
@@ -116,9 +104,9 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
         AddNode,
         RemoveNode,
         HostReplace,
-        StopNode,
-        StartNode,
         //TODO (coverage): add the following states once supported
+//        StopNode,
+//        StartNode,
 //        MoveToken
         //TODO (coverage): node migrate to another rack or dc (unsupported on trunk as of this writing, but planned work for TCM)
 //        MoveNodeToNewRack,
@@ -139,95 +127,14 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
     // common commands
     private Command<State<S>, Void, ?> repairCommand(int toCoordinate)
     {
-        return new SimpleCommand<>(state -> "nodetool repair " + state.schema.keyspace() + ' ' + state.schema.table() + " from node" + toCoordinate + state.commandNamePostfix(),
-                state -> state.cluster.get(toCoordinate).nodetoolResult("repair", state.schema.keyspace(), state.schema.table(), "--force").asserts().success());
-    }
-
-    private static <S extends Schema> Command<State<S>, Void, ?> repairCommand(int toCoordinate, String ks, String... tables) {
-        return new SimpleCommand<>(state -> "nodetool repair " + ks + (tables.length == 0 ? "" : " " + Arrays.asList(tables)) + " from node" + toCoordinate + state.commandNamePostfix(),
-                state -> {
-                    if (tables.length == 0) {
-                        state.cluster.get(toCoordinate).nodetoolResult("repair", ks, "--force").asserts().success();
-                        return;
-                    }
-                    List<String> args = new ArrayList<>(3 + tables.length);
-                    args.add("repair");
-                    args.add(ks);
-                    args.addAll(Arrays.asList(tables));
-                    args.add("--force");
-                    state.cluster.get(toCoordinate).nodetoolResult(args.toArray(String[]::new)).asserts().success();
-                });
+        return new SimpleCommand<>(state -> "nodetool repair " + state.schemaSpec.keyspaceName() + ' ' + state.schemaSpec.name() + " from node" + toCoordinate + state.commandNamePostfix(),
+                state -> state.cluster.get(toCoordinate).nodetoolResult("repair", state.schemaSpec.keyspaceName(), state.schemaSpec.name()).asserts().success());
     }
 
     private Command<State<S>, Void, ?> waitForCMSToQuiesce()
     {
-        return new Property.StateOnlyCommand<>()
-        {
-            private Epoch maxEpoch = null;
-            @Override
-            public String detailed(State<S> state)
-            {
-                if (maxEpoch == null)
-                    maxEpoch = ClusterUtils.maxEpoch(state.cluster, state.topologyHistory.up());
-                return "Waiting for CMS to Quiesce on epoch " + maxEpoch.getEpoch() + state.commandNamePostfix();
-            }
-
-            @Override
-            public void applyUnit(State<S> state)
-            {
-                Invariants.nonNull(maxEpoch, "detailed was not called before calling apply");
-                ClusterUtils.waitForCMSToQuiesce(state.cluster, maxEpoch, true);
-            }
-        };
-    }
-
-    private Command<State<S>, Void, ?> waitForGossipToSettle()
-    {
-        return new SimpleCommand<>(state -> "Waiting for Ring to Settle" + state.commandNamePostfix(),
-                state -> {
-                    int[] up = state.topologyHistory.up();
-                    for (int node : up)
-                    {
-                        IInvokableInstance instance = state.cluster.get(node);
-                        ClusterUtils.awaitRingJoin(state.cluster, up, instance);
-                    }
-                });
-    }
-
-    private Command<State<S>, Void, ?> waitAllNodesInPeers()
-    {
-        return new SimpleCommand<>(state -> "Waiting for all alive nodes to be in peers" + state.commandNamePostfix(),
-                state -> {
-                    int[] up = state.topologyHistory.up();
-                    for (int node : up)
-                    {
-                        IInvokableInstance instance = state.cluster.get(node);
-                        ClusterUtils.awaitInPeers(state.cluster, up, instance);
-                    }
-                });
-    }
-
-    private Command<State<S>, Void, ?> stopInstance(RandomSource rs, State<S> state)
-    {
-        int toStop = rs.pickInt(state.upAndSafe());
-        return stopInstance(toStop, "Normal Stop");
-    }
-
-    private Command<State<S>, Void, ?> startInstance(RandomSource rs, State<S> state)
-    {
-        int toStop = rs.pickInt(state.topologyHistory.down());
-        return startInstance(toStop);
-    }
-
-    private Command<State<S>, Void, ?> startInstance(int toStart)
-    {
-        return new SimpleCommand<>(state -> "Start Node" + toStart + state.commandNamePostfix(),
-                state -> {
-                    IInvokableInstance inst = state.cluster.get(toStart);
-                    TopologyHistory.Node node = state.topologyHistory.node(toStart);
-                    inst.startup();
-                    node.up();
-                });
+        return new SimpleCommand<>(state -> "Waiting for CMS to Quiesce" + state.commandNamePostfix(),
+                state -> ClusterUtils.waitForCMSToQuiesce(state.cluster, state.cmsGroup));
     }
 
     private Command<State<S>, Void, ?> stopInstance(int toRemove, String why)
@@ -248,14 +155,13 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
                     TopologyHistory.Node n = state.topologyHistory.addNode();
                     IInvokableInstance newInstance = ClusterUtils.addInstance(state.cluster, n.dc, n.rack, c -> c.set("auto_bootstrap", true));
                     newInstance.startup(state.cluster);
-                    ClusterUtils.assertModeJoined(newInstance);
                     n.up();
                 });
     }
 
     private Command<State<S>, Void, ?> removeNodeDecommission(RandomSource rs, State<S> state)
     {
-        int toRemove = rs.pickInt(state.upAndSafe());
+        int toRemove = rs.pickInt(state.topologyHistory.up());
         return new SimpleCommand<>("nodetool decommission node" + toRemove + state.commandNamePostfix(), s2 -> {
             IInvokableInstance inst = s2.cluster.get(toRemove);
             TopologyHistory.Node node = s2.topologyHistory.node(toRemove);
@@ -269,7 +175,7 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
     private Command<State<S>, Void, ?> removeNode(RandomSource rs, State<S> state)
     {
         int[] up = state.topologyHistory.up();
-        int toRemove = rs.pickInt(state.upAndSafe());
+        int toRemove = rs.pickInt(up);
         int toCoordinate;
         {
             int picked;
@@ -294,7 +200,14 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
 
     private Command<State<S>, Void, ?> removeNodeAssassinate(RandomSource rs, State<S> state)
     {
-        int toRemove = rs.pickInt(state.upAndSafe());
+        //TODO (correctness): assassinate CMS member isn't allowed
+        IntHashSet up = asSet(state.topologyHistory.up());
+        IntHashSet cmsGroup = asSet(state.cmsGroup);
+        Sets.SetView<Integer> upAndNotInCMS = Sets.difference(up, cmsGroup);
+        if (upAndNotInCMS.isEmpty()) throw new AssertionError("Every node is a CMS member");
+        List<Integer> allowed = new ArrayList<>(upAndNotInCMS);
+        allowed.sort(Comparator.naturalOrder());
+        int toRemove = rs.pick(allowed);
         int toCoordinate;
         {
             int[] upInt = state.topologyHistory.up();
@@ -338,17 +251,19 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
 
     private Command<State<S>, Void, ?> hostReplace(RandomSource rs, State<S> state)
     {
-        int nodeToReplace = rs.pickInt(state.upAndSafe());
+        int nodeToReplace = rs.pickInt(state.topologyHistory.up());
         IInvokableInstance toReplace = state.cluster.get(nodeToReplace);
         TopologyHistory.Node adding = state.topologyHistory.replace(nodeToReplace);
         TopologyHistory.Node removing = state.topologyHistory.nodes.get(nodeToReplace);
 
-        return multistep(stopInstance(nodeToReplace, "HostReplace; Node" + adding.id),
+        return multistep(new SimpleCommand<>("Stop Node" + nodeToReplace + " for HostReplace; Node" + adding.id + state.commandNamePostfix(), s2 -> {
+                    ClusterUtils.stopUnchecked(toReplace);
+                    removing.down();
+                }),
                 new SimpleCommand<>("Host Replace Node" + nodeToReplace + "; Node" + adding.id + state.commandNamePostfix(), s2 -> {
                     logger.info("node{} starting host replacement; epoch={}", adding.id, HackSerialization.tcmEpochAndSync(s2.cluster.getFirstRunningInstance()));
                     removing.status = TopologyHistory.Node.Status.BeingReplaced;
                     IInvokableInstance inst = ClusterUtils.replaceHostAndStart(s2.cluster, toReplace);
-                    ClusterUtils.assertModeJoined(inst);
                     s2.topologyHistory.replaced(removing, adding);
                     long epoch = HackSerialization.tcmEpoch(inst);
                     s2.currentEpoch.set(epoch);
@@ -374,7 +289,7 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
     @Test
     public void test()
     {
-        Property.StatefulBuilder statefulBuilder = stateful().withSteps(20).withStepTimeout(Duration.ofMinutes(3)).withExamples(1);
+        Property.StatefulBuilder statefulBuilder = stateful().withSteps(20).withStepTimeout(Duration.ofMinutes(2)).withExamples(1);
         preCheck(statefulBuilder);
         statefulBuilder.check(commands(this::stateGen)
                 .preCommands(state -> state.preActions.forEach(Runnable::run))
@@ -391,12 +306,6 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
                         TopologyMixupTestBase.this.destroyState(state, cause);
                     }
                 })
-                .commandsTransformer((state, gen) -> {
-                    for (BiFunction<State<S>, Gen<Command<State<S>, Void, ?>>, Gen<Command<State<S>, Void, ?>>> fn : state.commandsTransformers)
-                        gen = fn.apply(state, gen);
-                    return gen;
-                })
-                .onSuccess((state, sut, history) -> logger.info("Successful for the following:\nState {}\nHistory:\n{}", state, Property.formatList("\t\t", history)))
                 .build());
     }
 
@@ -405,32 +314,18 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
         EnumSet<TopologyChange> possibleTopologyChanges = EnumSet.noneOf(TopologyChange.class);
         // up or down is logically more correct, but since this runs sequentially and after the topology changes are complete, we don't have downed nodes at this point
         // so up is enough to know the topology size
-        int up = state.topologyHistory.up().length;
-        int down = state.topologyHistory.down().length;
-        int[] upAndSafe = state.upAndSafe();
-        int total = up + down;
-        if (total < state.topologyHistory.maxNodes)
+        int size = state.topologyHistory.up().length;
+        if (size < state.topologyHistory.maxNodes)
             possibleTopologyChanges.add(TopologyChange.AddNode);
-        if (upAndSafe.length > 0)
+        if (size > state.topologyHistory.quorum())
         {
-            // can't remove the node if all nodes are CMS nodes
-            if (!Sets.difference(asSet(upAndSafe), asSet(state.cmsGroup)).isEmpty())
+            if (size > TARGET_RF)
                 possibleTopologyChanges.add(TopologyChange.RemoveNode);
             possibleTopologyChanges.add(TopologyChange.HostReplace);
-            possibleTopologyChanges.add(TopologyChange.StopNode);
         }
-        if (down > 0)
-            possibleTopologyChanges.add(TopologyChange.StartNode);
         return possibleTopologyChanges;
     }
 
-    private Command<State<S>, Void, ?> awaitClusterStable()
-    {
-        return multistep(waitForCMSToQuiesce(),
-                waitForGossipToSettle(),
-                waitAllNodesInPeers());
-    }
-
     private Gen<Command<State<S>, Void, ?>> topologyCommand(State<S> state, EnumSet<TopologyChange> possibleTopologyChanges)
     {
         Map<Gen<Command<State<S>, Void, ?>>, Integer> possible = new LinkedHashMap<>();
@@ -439,19 +334,13 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
             switch (task)
             {
                 case AddNode:
-                    possible.put(ignore -> multistep(addNode(), awaitClusterStable()), 1);
+                    possible.put(ignore -> multistep(addNode(), waitForCMSToQuiesce()), 1);
                     break;
                 case RemoveNode:
-                    possible.put(rs -> multistep(removeNodeRandomizedDispatch(rs, state), awaitClusterStable()), 1);
+                    possible.put(rs -> multistep(removeNodeRandomizedDispatch(rs, state), waitForCMSToQuiesce()), 1);
                     break;
                 case HostReplace:
-                    possible.put(rs -> multistep(hostReplace(rs, state), awaitClusterStable()), 1);
-                    break;
-                case StartNode:
-                    possible.put(rs -> startInstance(rs, state), 1);
-                    break;
-                case StopNode:
-                    possible.put(rs -> stopInstance(rs, state), 1);
+                    possible.put(rs -> multistep(hostReplace(rs, state), waitForCMSToQuiesce()), 1);
                     break;
                 default:
                     throw new UnsupportedOperationException(task.name());
@@ -468,66 +357,28 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
         return set;
     }
 
-    public interface Schema
+    public interface SchemaSpec
     {
-        String table();
-        String keyspace();
-        String createSchema();
-    }
+        String name();
 
-    protected interface CommandGen<S extends Schema>
-    {
-        Command<State<S>, Void, ?> apply(RandomSource rs, State<S> state);
+        String keyspaceName();
     }
 
-    private static class LoggingCommand<State, SystemUnderTest, Result> extends Property.ForwardingCommand<State, SystemUnderTest, Result>
-    {
-        private static final Logger logger = LoggerFactory.getLogger(LoggingCommand.class);
-
-        private LoggingCommand(Command<State, SystemUnderTest, Result> delegate)
-        {
-            super(delegate);
-        }
-
-        @Override
-        public Result apply(State s) throws Throwable
-        {
-            String name = detailed(s);
-            long startNanos = Clock.Global.nanoTime();
-            try
-            {
-                logger.info("Starting command: {}", name);
-                Result o = super.apply(s);
-                logger.info("Command {} was success after {}", name, Duration.ofNanos(Clock.Global.nanoTime() - startNanos));
-                return o;
-            }
-            catch (Throwable t)
-            {
-                logger.warn("Command {} failed after {}: {}", name, Duration.ofNanos(Clock.Global.nanoTime() - startNanos), t.toString()); // don't want stack trace, just type/msg
-                throw t;
-            }
-        }
-    }
-
-    protected static class State<S extends Schema> implements AutoCloseable
+    protected static class State<S extends SchemaSpec> implements AutoCloseable
     {
         final TopologyHistory topologyHistory;
         final Cluster cluster;
-        final S schema;
-        final List<BiFunction<State<S>, Gen<Command<State<S>, Void, ?>>, Gen<Command<State<S>, Void, ?>>>> commandsTransformers = new ArrayList<>();
+        final S schemaSpec;
         final List<Runnable> preActions = new CopyOnWriteArrayList<>();
         final AtomicLong currentEpoch = new AtomicLong();
-        final CommandGen<S> statementGen;
+        final BiFunction<RandomSource, State<S>, Command<State<S>, Void, ?>> statementGen;
         final Gen<RemoveType> removeTypeGen;
         private final Map<String, Object> yamlConfigOverrides;
         int[] cmsGroup = new int[0];
-        private ReplicationFactor rf;
-        private final RingModel ring = new RingModel();
 
-        public State(RandomSource rs, BiFunction<RandomSource, Cluster, S> schemaSpecGen, Function<S, CommandGen<S>> cqlOperationsGen)
+        public State(RandomSource rs, BiFunction<RandomSource, Cluster, S> schemaSpecGen, Function<S, BiFunction<RandomSource, State<S>, Command<State<S>, Void, ?>>> cqlOperationsGen)
         {
             this.topologyHistory = new TopologyHistory(rs.fork(), 2, 4);
-            rf = new SimpleReplicationFactor(2);
             try
             {
 
@@ -536,18 +387,7 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
                         .withTokenSupplier(topologyHistory)
                         .withConfig(c -> {
                             c.with(Feature.values())
-                                    .set("write_request_timeout", "10s")
-                                    .set("read_request_timeout", "10s")
-                                    .set("range_request_timeout", "20s")
-                                    .set("request_timeout", "20s")
-                                    .set("native_transport_timeout", "30s")
-                                    // bound startup to some value larger than the task timeout, this is to allow the
-                                    // tests to stop blocking when a startup issue is detected.  The main reason for
-                                    // this is that startup blocks forever, waiting for accord and streaming to
-                                    // complete... but if there are bugs at these layers then the startup will never
-                                    // exit, blocking the JVM from giving the needed information (logs/seed) to debug.
-                                    .set(Constants.KEY_DTEST_STARTUP_TIMEOUT, "4m")
-                                    .set(Constants.KEY_DTEST_API_STARTUP_FAILURE_AS_SHUTDOWN, false);
+                                    .set("write_request_timeout", "10s");
                             //TODO (maintenance): where to put this?  Anything touching ConfigGenBuilder with jvm-dtest needs this...
                             ((InstanceConfig) c).remove("commitlog_sync_period_in_ms");
                             for (Map.Entry<String, Object> e : yamlConfigOverrides.entrySet())
@@ -585,25 +425,6 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
             {
                 throw new UncheckedIOException(e);
             }
-            cluster.setUncaughtExceptionsFilter((node, t) -> {
-                // api is "ignore" so false means include,
-                var rootCause = Throwables.getRootCause(t);
-                if (rootCause.getMessage() != null)
-                {
-                    if (rootCause.getMessage().startsWith("Queried for epoch") && rootCause.getMessage().contains("but could not catch up. Current epoch:"))
-                        return true;
-                    if (rootCause.getMessage().startsWith("Operation timed out"))
-                    {
-                        // is this due to TCM fetching epochs? PaxosBackedProcessor.getLogState is costly and more likely to timeout... so ignore those
-                        Optional<StackTraceElement> match = Stream.of(rootCause.getStackTrace())
-                                .filter(s -> s.getClassName().equals("org.apache.cassandra.tcm.PaxosBackedProcessor") && s.getMethodName().equals("getLogState"))
-                                .findFirst();
-                        if (match.isPresent())
-                            return true;
-                    }
-                }
-                return false;
-            });
             fixDistributedSchemas(cluster);
             init(cluster, TARGET_RF);
             // fix TCM
@@ -612,71 +433,31 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
                 result.asserts().success();
                 logger.info("CMS reconfigure: {}", result.getStdout());
             }
-            commandsTransformers.add(new BiFunction<State<S>, Gen<Command<State<S>, Void, ?>>, Gen<Command<State<S>, Void, ?>>>() {
+            preActions.add(new Runnable()
+            {
                 // in order to remove this action, an anonymous class is needed so "this" works, lambda "this" is the parent class
                 @Override
-                public Gen<Command<State<S>, Void, ?>> apply(State<S> state, Gen<Command<State<S>, Void, ?>> commandGen) {
-                    if (topologyHistory.up().length < TARGET_RF)
-                        return commandGen;
-                    SimpleCommand<State<S>> reconfig = new SimpleCommand<>("nodetool cms reconfigure " + TARGET_RF, ignore -> {
+                public void run()
+                {
+                    if (topologyHistory.up().length == TARGET_RF)
+                    {
                         NodeToolResult result = cluster.get(1).nodetoolResult("cms", "reconfigure", Integer.toString(TARGET_RF));
                         result.asserts().success();
                         logger.info("CMS reconfigure: {}", result.getStdout());
-                    });
-                    SimpleCommand<State<S>> fixDistributedSchemas = new SimpleCommand<>("Set system distributed keyspaces to RF=" + TARGET_RF, ignore ->
-                            fixDistributedSchemas(cluster));
-                    SimpleCommand<State<S>> fixTestKeyspace = new SimpleCommand<>("Set " + KEYSPACE + " keyspace to RF=" + TARGET_RF, s -> {
-                        cluster.schemaChange("ALTER KEYSPACE " + KEYSPACE + " WITH replication = {'class': 'SimpleStrategy', 'replication_factor': " + TARGET_RF + "}");
-                        rf = new SimpleReplicationFactor(TARGET_RF);
-                    });
-                    var self = this;
-                    return rs -> {
-                        Command<State<S>, Void, ?> next = commandGen.next(rs);
-                        if (next.checkPreconditions(state) == Property.PreCheckResult.Ignore)
-                            return next;
-                        commandsTransformers.remove(self);
-                        int[] up = state.topologyHistory.up();
-                        List<Command<State<S>, Void, ?>> commands = new ArrayList<>();
-                        commands.add(fixDistributedSchemas);
-                        for (String ks : Arrays.asList("system_auth", "system_traces"))
-                        {
-                            int coordinator = rs.pickInt(up);
-                            commands.add(repairCommand(coordinator, ks));
-                        }
-                        commands.add(fixTestKeyspace);
-                        {
-                            int coordinator = rs.pickInt(up);
-                            commands.add(repairCommand(coordinator, KEYSPACE));
-                        }
-                        commands.add(reconfig);
-                        commands.add(next);
-                        return multistep(commands);
-                    };
+                        preActions.remove(this);
+                    }
                 }
             });
-            commandsTransformers.add((state, commandGen) -> rs2 -> {
-                Command<State<S>, Void, ?> c = commandGen.next(rs2);
-                if (!(c instanceof Property.MultistepCommand))
-                    return new LoggingCommand<>(c);
-                Property.MultistepCommand<State<S>, Void> multistep = (Property.MultistepCommand<State<S>, Void>) c;
-                List<Command<State<S>, Void, ?>> subcommands = new ArrayList<>();
-                for (var sub : multistep)
-                    subcommands.add(new LoggingCommand<>(sub));
-                return multistep(subcommands);
-            });
             preActions.add(() -> {
                 int[] up = topologyHistory.up();
                 // use the most recent node just in case the cluster isn't in-sync
                 IInvokableInstance node = cluster.get(up[up.length - 1]);
                 cmsGroup = HackSerialization.cmsGroup(node);
                 currentEpoch.set(HackSerialization.tcmEpoch(node));
-
-                ring.rebuild(cluster.coordinator(up[0]), rf, up);
-                // ring must know about the up nodes
             });
             preActions.add(() -> cluster.checkAndResetUncaughtExceptions());
-            this.schema = schemaSpecGen.apply(rs, cluster);
-            statementGen = cqlOperationsGen.apply(schema);
+            this.schemaSpec = schemaSpecGen.apply(rs, cluster);
+            statementGen = cqlOperationsGen.apply(schemaSpec);
 
             removeTypeGen = REMOVE_TYPE_DISTRIBUTION.next(rs);
 
@@ -697,38 +478,7 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
 
         protected String commandNamePostfix()
         {
-            return "; epoch=" + currentEpoch.get() + ", cms=" + Arrays.toString(cmsGroup) + ", up=" + Arrays.toString(topologyHistory.up()) + ", down=" + Arrays.toString(topologyHistory.down());
-        }
-
-        public int[] upAndSafe()
-        {
-            IntHashSet up = asSet(topologyHistory.up());
-            int quorum = topologyHistory.quorum();
-            // find what ranges are able to handle 1 node loss
-            Set<Range> safeRanges = new HashSet<>();
-            ring.rangesToReplicas((range, replicas) -> {
-                IntHashSet alive = new IntHashSet();
-                for (int peer : replicas)
-                {
-                    if (up.contains(peer))
-                        alive.add(peer);
-                }
-                if (quorum < alive.size())
-                    safeRanges.add(range);
-            });
-
-            // filter nodes where 100% of their ranges are "safe"
-            IntArrayList safeNodes = new IntArrayList();
-            for (int id : up)
-            {
-                List<Range> ranges = ring.ranges(id);
-                if (ranges.stream().allMatch(safeRanges::contains))
-                    safeNodes.add(id);
-            }
-
-            int[] upAndSafe = safeNodes.toIntArray();
-            Arrays.sort(upAndSafe);
-            return upAndSafe;
+            return "; epoch=" + currentEpoch.get() + ", cms=" + Arrays.toString(cmsGroup);
         }
 
         @Override
@@ -736,8 +486,6 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
         {
             StringBuilder sb = new StringBuilder();
             sb.append("Yaml Config:\n").append(YamlConfigurationLoader.toYaml(this.yamlConfigOverrides));
-            String cql = schema.createSchema();
-            sb.append("\n-- Setup Schema\n").append(cql);
             sb.append("\nTopology:\n").append(topologyHistory);
             sb.append("\nCMS Voting Group: ").append(Arrays.toString(cmsGroup));
             if (epochHistory != null)
@@ -750,28 +498,14 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
         @Override
         public void close() throws Exception
         {
-            var cmsNodesUp = Sets.intersection(asSet(cmsGroup), asSet(topologyHistory.up()));
-            int cmsNode = Iterables.getFirst(cmsNodesUp, null);
-            try
-            {
-                SimpleQueryResult qr = Retry.retryWithBackoffBlocking(5, () -> cluster.get(cmsNode).executeInternalWithResult("SELECT epoch, kind, transformation FROM system_views.cluster_metadata_log"));
-                TableBuilder builder = new TableBuilder(" | ");
-                builder.add(qr.names());
-                while (qr.hasNext())
-                {
-                    Row next = qr.next();
-                    builder.add(Stream.of(next.toObjectArray())
-                            .map(Objects::toString)
-                            .map(s -> s.length() > 100 ? s.substring(0, 100) + "..." : s)
-                            .collect(Collectors.toList()));
-                }
-                epochHistory = "Epochs:\n" + builder;
-            }
-            catch (Throwable t)
-            {
-                logger.warn("Unable to fetch epoch history on node{}", cmsNode, t);
-            }
-            logger.info("Shutting down clusters");
+            epochHistory = cluster.get(cmsGroup[0]).callOnInstance(() -> {
+                LogState all = ClusterMetadataService.instance().processor().reconstruct(Epoch.EMPTY, Epoch.create(Long.MAX_VALUE), Retry.Deadline.retryIndefinitely(DatabaseDescriptor.getCmsAwaitTimeout().to(NANOSECONDS),
+                        TCMMetrics.instance.commitRetries));
+                StringBuilder sb = new StringBuilder("Epochs:");
+                for (Entry e : all.entries)
+                    sb.append("\n").append(e.epoch.getEpoch()).append(": ").append(e.transform);
+                return sb.toString();
+            });
             cluster.close();
         }
     }
@@ -834,21 +568,11 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
         }
 
         public int[] up()
-        {
-            return nodes(Node.Status.Up);
-        }
-
-        public int[] down()
-        {
-            return nodes(Node.Status.Down);
-        }
-
-        private int[] nodes(Node.Status target)
         {
             IntArrayList up = new IntArrayList(nodes.size(), -1);
             for (Map.Entry<Integer, Node> n : nodes.entrySet())
             {
-                if (n.getValue().status == target)
+                if (n.getValue().status == Node.Status.Up)
                     up.add(n.getKey());
             }
             int[] ints = up.toIntArray();
@@ -988,63 +712,4 @@ public abstract class TopologyMixupTestBase<S extends TopologyMixupTestBase.Sche
             return Integer.parseInt(parts[3]);
         }
     }
-
-    private static class RingModel
-    {
-        ReplicatedRanges ring = null;
-        Int2ObjectHashMap<Replica> idToReplica = null;
-
-        private void rebuild(ICoordinator coordinator, ReplicationFactor rf, int[] up)
-        {
-            ring = TokenPlacementModelHelper.getRing(coordinator, rf);
-
-            Int2ObjectHashMap<Replica> idToReplica = new Int2ObjectHashMap<>();
-            for (Map.Entry<Range, List<Replica>> e : ring.asMap().entrySet())
-            {
-                for (var replica : e.getValue())
-                    idToReplica.put(toNodeId(replica), replica);
-            }
-            this.idToReplica = idToReplica;
-
-            IntHashSet upSet = asSet(up);
-            if (!idToReplica.keySet().containsAll(upSet))
-            {
-                int coordinatorNode = coordinator.instance().config().num();
-                Sets.SetView<Integer> diff = Sets.difference(upSet, idToReplica.keySet());
-                throw new AssertionError("Unable to find nodes " + diff + " in the ring on node" + coordinatorNode);
-            }
-        }
-
-        private static int toNodeId(Replica replica)
-        {
-            //TODO (fix test api): NodeId is in the API but is always null.  Cheapest way to get the id is to assume the address has it
-            // same issue with address...
-            // /127.0.0.2
-            String harryId = replica.node().id();
-            int index = harryId.lastIndexOf('.');
-            int peer = Integer.parseInt(harryId.substring(index + 1));
-            return peer;
-        }
-
-        List<Range> ranges(int node)
-        {
-            Replica replica = idToReplica.get(node);
-            if (replica == null)
-                throw new AssertionError("Unknown node" + node);
-            List<Range> ranges = ring.ranges(replica);
-            if (ranges == null)
-                throw new AssertionError("node" + node + " some how does not have ranges...");
-            return ranges;
-        }
-
-        private void rangesToReplicas(BiConsumer<Range, int[]> fn)
-        {
-            for (Map.Entry<Range, List<Replica>> e : ring.asMap().entrySet())
-            {
-                int[] replicas = e.getValue().stream().mapToInt(RingModel::toNodeId).toArray();
-                Arrays.sort(replicas);
-                fn.accept(e.getKey(), replicas);
-            }
-        }
-    }
 }
diff --git a/test/harry/main/org/apache/cassandra/harry/SchemaSpec.java b/test/harry/main/org/apache/cassandra/harry/SchemaSpec.java
index dbfa6e5f53..b103d82e37 100644
--- a/test/harry/main/org/apache/cassandra/harry/SchemaSpec.java
+++ b/test/harry/main/org/apache/cassandra/harry/SchemaSpec.java
@@ -30,6 +30,7 @@ import org.apache.cassandra.harry.gen.Generator;
 import org.apache.cassandra.harry.gen.Generators;
 import org.apache.cassandra.harry.gen.ValueGenerators;
 import org.apache.cassandra.harry.util.IteratorsUtil;
+import org.apache.cassandra.service.consensus.TransactionalMode;
 import org.apache.cassandra.utils.ByteArrayUtil;
 
 import static org.apache.cassandra.harry.gen.InvertibleGenerator.MAX_ENTROPY;
@@ -177,6 +178,15 @@ public class SchemaSpec
             shouldAppendAnd = true;
         }
 
+        if (options.transactionalMode() != null)
+        {
+            appendWith.run();
+            if (shouldAppendAnd)
+                sb.append(" AND");
+            sb.append(" ").append(options.transactionalMode().asCqlParam());
+            shouldAppendAnd = true;
+        }
+
         if (options.disableReadRepair())
         {
             appendWith.run();
@@ -339,6 +349,7 @@ public class SchemaSpec
 
     public interface Options
     {
+        TransactionalMode transactionalMode();
         boolean addWriteTimestamps();
         boolean disableReadRepair();
         String compactionStrategy();
@@ -354,6 +365,7 @@ public class SchemaSpec
 
     public static class OptionsBuilder implements Options
     {
+        private TransactionalMode transactionalMode = null;
         private boolean addWriteTimestamps = true;
         private boolean disableReadRepair = false;
         private String compactionStrategy = null;
@@ -365,6 +377,23 @@ public class SchemaSpec
         {
         }
 
+        public Options build()
+        {
+            return this;
+        }
+
+        public OptionsBuilder withTransactionalMode(TransactionalMode mode)
+        {
+            this.transactionalMode = mode;
+            return this;
+        }
+
+        @Override
+        public TransactionalMode transactionalMode()
+        {
+            return transactionalMode;
+        }
+
         public OptionsBuilder addWriteTimestamps(boolean newValue)
         {
             this.addWriteTimestamps = newValue;
diff --git a/test/harry/main/org/apache/cassandra/harry/execution/DataTracker.java b/test/harry/main/org/apache/cassandra/harry/execution/DataTracker.java
index df4d44cbc9..37b40f5acc 100644
--- a/test/harry/main/org/apache/cassandra/harry/execution/DataTracker.java
+++ b/test/harry/main/org/apache/cassandra/harry/execution/DataTracker.java
@@ -27,7 +27,7 @@ import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicLong;
 
-import accord.utilsfork.Invariants;
+import accord.utils.Invariants;
 import org.apache.cassandra.harry.op.Visit;
 import org.apache.cassandra.harry.op.Operations;
 import org.apache.cassandra.harry.model.Model;
diff --git a/test/unit/accord/utilsfork/WrappedRandomSource.java b/test/harry/main/org/apache/cassandra/harry/gen/EntropyRandomSource.java
similarity index 60%
rename from test/unit/accord/utilsfork/WrappedRandomSource.java
rename to test/harry/main/org/apache/cassandra/harry/gen/EntropyRandomSource.java
index 39e899cb1d..63f62ab7e2 100644
--- a/test/unit/accord/utilsfork/WrappedRandomSource.java
+++ b/test/harry/main/org/apache/cassandra/harry/gen/EntropyRandomSource.java
@@ -16,82 +16,74 @@
  * limitations under the License.
  */
 
-package accord.utilsfork;
+package org.apache.cassandra.harry.gen;
 
-import java.util.Random;
+import accord.utils.RandomSource;
 
-class WrappedRandomSource implements accord.utilsfork.RandomSource
+public class EntropyRandomSource implements RandomSource
 {
-    private final Random random;
+    private final EntropySource delegate;
 
-    WrappedRandomSource(Random random)
+    public EntropyRandomSource(EntropySource delegate)
     {
-        this.random = random;
-    }
-
-    @Override
-    public Random asJdkRandom()
-    {
-        return random;
+        this.delegate = delegate;
     }
 
     @Override
     public void nextBytes(byte[] bytes)
     {
-        random.nextBytes(bytes);
+        for (int i = 0, len = bytes.length; i < len; )
+            for (int rnd = nextInt(),
+                 n = Math.min(len - i, Integer.SIZE/Byte.SIZE);
+                 n-- > 0; rnd >>= Byte.SIZE)
+                bytes[i++] = (byte)rnd;
     }
 
     @Override
     public boolean nextBoolean()
     {
-        return random.nextBoolean();
+        return delegate.nextBoolean();
     }
 
     @Override
     public int nextInt()
     {
-        return random.nextInt();
-    }
-
-    @Override
-    public int nextInt(int maxExclusive)
-    {
-        return random.nextInt(maxExclusive);
+        return delegate.nextInt();
     }
 
     @Override
     public long nextLong()
     {
-        return random.nextLong();
+        return ((long) nextInt() << 32) + nextInt();
     }
 
     @Override
     public float nextFloat()
     {
-        return random.nextFloat();
+        return delegate.nextFloat();
     }
 
     @Override
     public double nextDouble()
     {
-        return random.nextDouble();
+        throw new UnsupportedOperationException("TODO: Implement");
     }
 
     @Override
     public double nextGaussian()
     {
-        return random.nextGaussian();
+        throw new UnsupportedOperationException("TODO: Implement");
     }
 
     @Override
     public void setSeed(long seed)
     {
-        random.setSeed(seed);
+        delegate.seed(seed);
     }
 
     @Override
     public RandomSource fork()
     {
-        return new WrappedRandomSource(new Random(nextLong()));
+        return new EntropyRandomSource(delegate.derive());
     }
 }
diff --git a/test/harry/main/org/apache/cassandra/harry/gen/Generators.java b/test/harry/main/org/apache/cassandra/harry/gen/Generators.java
index 1f39b0cd2f..e3391099b4 100644
--- a/test/harry/main/org/apache/cassandra/harry/gen/Generators.java
+++ b/test/harry/main/org/apache/cassandra/harry/gen/Generators.java
@@ -31,7 +31,8 @@ import java.util.Set;
 import java.util.UUID;
 import java.util.function.Supplier;
 
-import accord.utilsfork.Invariants;
+import accord.utils.Gen;
+import accord.utils.Invariants;
 import org.apache.cassandra.harry.util.BitSet;
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.utils.TimeUUID;
@@ -460,4 +461,14 @@ public class Generators
     {
         return (random) -> constant.get();
     }
+
+    public static <T> Gen<T> toAccord(Generator<T> gen)
+    {
+        return rng -> gen.generate(new RandomSourceEntropySource(rng));
+    }
+
+    public static <T> Generator<T> toHarry(Gen<T> gen)
+    {
+        return rng -> gen.next(new EntropyRandomSource(rng));
+    }
 }
diff --git a/test/harry/main/org/apache/cassandra/harry/gen/InvertibleGenerator.java b/test/harry/main/org/apache/cassandra/harry/gen/InvertibleGenerator.java
index 50a42f67ba..ae8f4a8f71 100644
--- a/test/harry/main/org/apache/cassandra/harry/gen/InvertibleGenerator.java
+++ b/test/harry/main/org/apache/cassandra/harry/gen/InvertibleGenerator.java
@@ -27,7 +27,7 @@ import java.util.List;
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import accord.utilsfork.Invariants;
+import accord.utils.Invariants;
 import org.agrona.collections.IntHashSet;
 import org.apache.cassandra.harry.ColumnSpec;
 import org.apache.cassandra.harry.MagicConstants;
diff --git a/test/unit/accord/utilsfork/DefaultRandom.java b/test/harry/main/org/apache/cassandra/harry/gen/RandomSourceEntropySource.java
similarity index 68%
rename from test/unit/accord/utilsfork/DefaultRandom.java
rename to test/harry/main/org/apache/cassandra/harry/gen/RandomSourceEntropySource.java
index 49f9085569..b1aed196db 100644
--- a/test/unit/accord/utilsfork/DefaultRandom.java
+++ b/test/harry/main/org/apache/cassandra/harry/gen/RandomSourceEntropySource.java
@@ -16,33 +16,35 @@
  * limitations under the License.
  */
 
-package accord.utilsfork;
+package org.apache.cassandra.harry.gen;
 
-import java.util.Random;
+import accord.utils.RandomSource;
 
-public class DefaultRandom implements RandomSource
+public class RandomSourceEntropySource implements EntropySource
 {
-    private final Random delegate;
-    public DefaultRandom()
+    private final RandomSource delegate;
+
+    public RandomSourceEntropySource(RandomSource delegate)
     {
-        this.delegate = new Random();
+        this.delegate = delegate;
     }
 
-    public DefaultRandom(long seed)
+    @Override
+    public long next()
     {
-        this.delegate = new Random(seed);
+        return delegate.nextLong();
     }
 
     @Override
-    public void nextBytes(byte[] bytes)
+    public void seed(long seed)
     {
-        delegate.nextBytes(bytes);
+        delegate.setSeed(seed);
     }
 
     @Override
-    public boolean nextBoolean()
+    public EntropySource derive()
     {
-        return delegate.nextBoolean();
+        return new RandomSourceEntropySource(delegate.fork());
     }
 
     @Override
@@ -52,43 +54,32 @@ public class DefaultRandom implements RandomSource
     }
 
     @Override
-    public long nextLong()
+    public int nextInt(int max)
     {
-        return delegate.nextLong();
+        return delegate.nextInt(max);
     }
 
     @Override
-    public float nextFloat()
+    public int nextInt(int min, int max)
     {
-        return delegate.nextFloat();
+        return delegate.nextInt(min, max);
     }
 
     @Override
-    public double nextDouble()
-    {
-        return delegate.nextDouble();
-    }
-
-    @Override
-    public double nextGaussian()
+    public float nextFloat()
     {
-        return delegate.nextGaussian();
+        return delegate.nextFloat();
     }
 
     @Override
-    public void setSeed(long seed)
+    public double nextDouble()
     {
-        delegate.setSeed(seed);
-    }
-
-    @Override
-    public DefaultRandom fork() {
-        return new DefaultRandom(nextLong());
+        return delegate.nextDouble();
     }
 
     @Override
-    public Random asJdkRandom()
+    public boolean nextBoolean()
     {
-        return delegate;
+        return delegate.nextBoolean();
     }
 }
diff --git a/test/harry/main/org/apache/cassandra/harry/model/ASTSingleTableModel.java b/test/harry/main/org/apache/cassandra/harry/model/ASTSingleTableModel.java
index 0382f79872..e1df90e0c2 100644
--- a/test/harry/main/org/apache/cassandra/harry/model/ASTSingleTableModel.java
+++ b/test/harry/main/org/apache/cassandra/harry/model/ASTSingleTableModel.java
@@ -45,12 +45,13 @@ import com.google.common.base.Preconditions;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 
-import accord.utilsfork.Invariants;
+
+import accord.utils.Invariants;
 import org.apache.cassandra.cql3.KnownIssue;
 import org.apache.cassandra.cql3.ast.AssignmentOperator;
 import org.apache.cassandra.cql3.ast.CasCondition;
-import org.apache.cassandra.cql3.ast.Conditional;
 import org.apache.cassandra.cql3.ast.Conditional.Where.Inequality;
+import org.apache.cassandra.cql3.ast.Conditional;
 import org.apache.cassandra.cql3.ast.Element;
 import org.apache.cassandra.cql3.ast.Expression;
 import org.apache.cassandra.cql3.ast.ExpressionEvaluator;
diff --git a/test/harry/main/org/apache/cassandra/harry/test/SimpleBijectionTest.java b/test/harry/main/org/apache/cassandra/harry/test/SimpleBijectionTest.java
index cc6531e132..fde20aa363 100644
--- a/test/harry/main/org/apache/cassandra/harry/test/SimpleBijectionTest.java
+++ b/test/harry/main/org/apache/cassandra/harry/test/SimpleBijectionTest.java
@@ -18,7 +18,7 @@
 
 package org.apache.cassandra.harry.test;
 
-import accord.utilsfork.Invariants;
+import accord.utils.Invariants;
 import org.apache.cassandra.harry.ColumnSpec;
 import org.apache.cassandra.harry.SchemaSpec;
 import org.apache.cassandra.harry.dsl.HistoryBuilder;
diff --git a/test/simulator/test/org/apache/cassandra/simulator/test/HarrySimulatorTest.java b/test/simulator/test/org/apache/cassandra/simulator/test/HarrySimulatorTest.java
index 872f6611df..b870c214bb 100644
--- a/test/simulator/test/org/apache/cassandra/simulator/test/HarrySimulatorTest.java
+++ b/test/simulator/test/org/apache/cassandra/simulator/test/HarrySimulatorTest.java
@@ -41,7 +41,7 @@ import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import accord.utilsfork.Invariants;
+import accord.utils.Invariants;
 import io.airlift.airline.Command;
 import io.airlift.airline.HelpOption;
 import io.airlift.airline.Option;
diff --git a/test/unit/accord/utilsfork/Gen.java b/test/unit/accord/utilsfork/Gen.java
deleted file mode 100644
index e9468cb24e..0000000000
--- a/test/unit/accord/utilsfork/Gen.java
+++ /dev/null
@@ -1,237 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork;
-
-import java.util.function.BiFunction;
-import java.util.function.Function;
-import java.util.function.IntPredicate;
-import java.util.function.IntSupplier;
-import java.util.function.IntUnaryOperator;
-import java.util.function.LongPredicate;
-import java.util.function.LongSupplier;
-import java.util.function.LongUnaryOperator;
-import java.util.function.Predicate;
-import java.util.function.Supplier;
-import java.util.function.ToIntFunction;
-import java.util.function.ToLongFunction;
-import java.util.stream.IntStream;
-import java.util.stream.LongStream;
-import java.util.stream.Stream;
-
-public interface Gen<A> {
-    /**
-     * For cases where method handles isn't able to detect the proper type, this method acts as a cast
-     * to inform the compiler of the desired type.
-     */
-    static <A> Gen<A> of(Gen<A> fn)
-    {
-        return fn;
-    }
-
-    A next(accord.utilsfork.RandomSource random);
-
-    default <B> Gen<B> map(Function<? super A, ? extends B> fn)
-    {
-        return r -> fn.apply(this.next(r));
-    }
-
-    default <B> Gen<B> map(BiFunction<accord.utilsfork.RandomSource, ? super A, ? extends B> fn)
-    {
-        return r -> fn.apply(r, this.next(r));
-    }
-
-    default IntGen mapToInt(ToIntFunction<A> fn)
-    {
-        return r -> fn.applyAsInt(next(r));
-    }
-
-    default LongGen mapToLong(ToLongFunction<A> fn)
-    {
-        return r -> fn.applyAsLong(next(r));
-    }
-
-    default <B> Gen<B> flatMap(Function<? super A, Gen<? extends B>> mapper)
-    {
-        return rs -> mapper.apply(this.next(rs)).next(rs);
-    }
-
-    default <B> Gen<B> flatMap(BiFunction<accord.utilsfork.RandomSource, ? super A, Gen<? extends B>> mapper)
-    {
-        return rs -> mapper.apply(rs, this.next(rs)).next(rs);
-    }
-
-    default Gen<A> filter(Predicate<A> fn)
-    {
-        Gen<A> self = this;
-        return r -> {
-            A value;
-            do {
-                value = self.next(r);
-            }
-            while (!fn.test(value));
-            return value;
-        };
-    }
-
-    default Gen<A> filter(int maxAttempts, A defaultValue, Predicate<A> fn)
-    {
-        Invariants.checkArgument(maxAttempts > 0, "Max attempts must be positive; given %d", maxAttempts);
-        Gen<A> self = this;
-        return r -> {
-            for (int i = 0; i < maxAttempts; i++)
-            {
-                A v = self.next(r);
-                if (fn.test(v))
-                    return v;
-
-            }
-            return defaultValue;
-        };
-    }
-
-    default Supplier<A> asSupplier(accord.utilsfork.RandomSource rs)
-    {
-        return () -> next(rs);
-    }
-
-    default Stream<A> asStream(accord.utilsfork.RandomSource rs)
-    {
-        return Stream.generate(() -> next(rs));
-    }
-
-    interface Int2IntMapFunction
-    {
-        int applyAsInt(accord.utilsfork.RandomSource rs, int value);
-    }
-
-    interface Int2LongMapFunction
-    {
-        long applyAsLong(accord.utilsfork.RandomSource rs, int value);
-    }
-
-    interface Long2LongMapFunction
-    {
-        long applyAsLong(accord.utilsfork.RandomSource rs, long value);
-    }
-
-    interface IntGen extends Gen<Integer>
-    {
-        int nextInt(accord.utilsfork.RandomSource random);
-
-        @Override
-        default Integer next(accord.utilsfork.RandomSource random)
-        {
-            return nextInt(random);
-        }
-
-        default IntGen mapAsInt(IntUnaryOperator fn)
-        {
-            return r -> fn.applyAsInt(nextInt(r));
-        }
-
-        default IntGen mapAsInt(Int2IntMapFunction fn)
-        {
-            return r -> fn.applyAsInt(r, nextInt(r));
-        }
-
-        default LongGen mapAsLong(Int2LongMapFunction fn)
-        {
-            return r -> fn.applyAsLong(r, nextInt(r));
-        }
-
-        default Gen.IntGen filterAsInt(IntPredicate fn)
-        {
-            return rs -> {
-                int value;
-                do
-                {
-                    value = nextInt(rs);
-                }
-                while (!fn.test(value));
-                return value;
-            };
-        }
-
-        @Override
-        default Gen.IntGen filter(Predicate<Integer> fn)
-        {
-            return filterAsInt(i -> fn.test(i));
-        }
-
-        default IntSupplier asIntSupplier(accord.utilsfork.RandomSource rs)
-        {
-            return () -> nextInt(rs);
-        }
-
-        default IntStream asIntStream(accord.utilsfork.RandomSource rs)
-        {
-            return IntStream.generate(() -> nextInt(rs));
-        }
-    }
-
-    interface LongGen extends Gen<Long>
-    {
-        long nextLong(accord.utilsfork.RandomSource random);
-
-        @Override
-        default Long next(accord.utilsfork.RandomSource random)
-        {
-            return nextLong(random);
-        }
-
-        default LongGen mapAsLong(LongUnaryOperator fn)
-        {
-            return r -> fn.applyAsLong(nextLong(r));
-        }
-
-        default LongGen mapAsLong(Long2LongMapFunction fn)
-        {
-            return r -> fn.applyAsLong(r, nextLong(r));
-        }
-
-        default Gen.LongGen filterAsLong(LongPredicate fn)
-        {
-            return rs -> {
-                long value;
-                do
-                {
-                    value = nextLong(rs);
-                }
-                while (!fn.test(value));
-                return value;
-            };
-        }
-
-        @Override
-        default Gen.LongGen filter(Predicate<Long> fn)
-        {
-            return filterAsLong(i -> fn.test(i));
-        }
-
-        default LongSupplier asLongSupplier(accord.utilsfork.RandomSource rs)
-        {
-            return () -> nextLong(rs);
-        }
-
-        default LongStream asLongStream(RandomSource rs)
-        {
-            return LongStream.generate(() -> nextLong(rs));
-        }
-    }
-}
diff --git a/test/unit/accord/utilsfork/Gens.java b/test/unit/accord/utilsfork/Gens.java
deleted file mode 100644
index 72eccbf232..0000000000
--- a/test/unit/accord/utilsfork/Gens.java
+++ /dev/null
@@ -1,1152 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork;
-
-import java.lang.reflect.Array;
-import java.math.BigDecimal;
-import java.math.RoundingMode;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.EnumMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.LinkedHashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.NavigableSet;
-import java.util.Objects;
-import java.util.Set;
-import java.util.function.BooleanSupplier;
-import java.util.function.Function;
-import java.util.function.Supplier;
-import java.util.stream.IntStream;
-import java.util.stream.LongStream;
-import java.util.stream.Stream;
-
-import com.google.common.collect.Iterables;
-
-import accord.utilsfork.random.Picker;
-
-public class Gens {
-    private Gens() {
-    }
-
-    public static <T> Gen<T> flatten(Gen<Gen<T>> gen)
-    {
-        return rs -> gen.next(rs).next(rs);
-    }
-
-    public static <T> Gen<T> constant(T constant)
-    {
-        return ignore -> constant;
-    }
-
-    public static <T> Gen<T> constant(Supplier<T> constant)
-    {
-        return ignore -> constant.get();
-    }
-
-    public static <T> Gen<T> oneOf(Gen<? extends T>... gens)
-    {
-        switch (gens.length)
-        {
-            case 0: throw new IllegalArgumentException("Unable to select oneOf an empty list");
-            case 1: return (Gen<T>) gens[0];
-        }
-        return oneOf(Arrays.asList(gens));
-    }
-
-    public static <T> Gen<T> oneOf(List<Gen<? extends T>> gens)
-    {
-        switch (gens.size())
-        {
-            case 0: throw new IllegalArgumentException("Unable to select oneOf an empty list");
-            case 1: return (Gen<T>) gens.get(0);
-        }
-        return rs -> rs.pick(gens).next(rs);
-    }
-
-    public static <T> Gen<T> oneOf(Map<Gen<T>, Integer> values)
-    {
-        Gen<Gen<T>> gen = pick(values);
-        return rs -> gen.next(rs).next(rs);
-    }
-
-    public static <T> OneOfBuilder<T> oneOf()
-    {
-        return new OneOfBuilder<>();
-    }
-
-    public static class OneOfBuilder<T>
-    {
-        private final Map<Gen<T>, Integer> weighted = new LinkedHashMap<>();
-        private final Set<Gen<T>> unweighted = new LinkedHashSet<>();
-        private Gen.IntGen unknownWeightGen = Gens.ints().between(1, 10);
-
-        public OneOfBuilder<T> add(Gen<T> gen)
-        {
-            unweighted.add(gen);
-            return this;
-        }
-
-        public OneOfBuilder<T> add(int weight, Gen<T> gen)
-        {
-            weighted.put(gen, weight);
-            return this;
-        }
-
-        public OneOfBuilder<T> unknownWeights(Gen.IntGen gen)
-        {
-            this.unknownWeightGen = gen;
-            return this;
-        }
-
-        public Gen<Gen<T>> buildWithDynamicWeights()
-        {
-            if (unweighted.isEmpty())
-            {
-                Gen<T> gen = build();
-                return i -> gen;
-            }
-            return rs -> {
-                Map<Gen<T>, Integer> commands = new LinkedHashMap<>();
-                commands.putAll(weighted);
-                for (var gen : unweighted)
-                    commands.put(gen, unknownWeightGen.nextInt(rs));
-                var top = pick(commands);
-                return rs2 -> top.next(rs2).next(rs2);
-            };
-        }
-
-        public Gen<T> build()
-        {
-            Map<Gen<T>, Integer> commands = new LinkedHashMap<>();
-            commands.putAll(weighted);
-            for (var gen : unweighted)
-                commands.put(gen, 1);
-            var top = pick(commands);
-            return rs -> top.next(rs).next(rs);
-        }
-    }
-
-    public static Gen.IntGen pickInt(int... ts)
-    {
-        return rs -> ts[rs.nextInt(0, ts.length)];
-    }
-
-    public static <T> Gen<T> pick(T... ts)
-    {
-        return pick(Arrays.asList(ts));
-    }
-
-    public static <T> Gen<T> pick(List<T> ts)
-    {
-        Gen.IntGen offset = ints().between(0, ts.size() - 1);
-        return rs -> ts.get(offset.nextInt(rs));
-    }
-
-    public static <T extends Comparable<T>> Gen<T> pick(Set<T> set)
-    {
-        List<T> list = new ArrayList<>(set);
-        // Non-ordered sets may have different iteration order on different environments, which would make a seed produce different histories!
-        // To avoid such a problem, make sure to apply a deterministic function (sort).
-        if (!(set instanceof NavigableSet))
-            list.sort(Comparator.naturalOrder());
-        return pick(list);
-    }
-
-    public static <T> Gen<T> pick(Map<T, Integer> values)
-    {
-        if (values == null || values.isEmpty())
-            throw new IllegalArgumentException("values is empty");
-        // if 2 values have the same weight we need some way to tie-break, but that isn't always possible...
-        // this method relies on the map having some order and will reject any map that doesn't define a deterministic order
-        if (!(values instanceof EnumMap || values instanceof LinkedHashMap))
-            throw new IllegalArgumentException("pick(Map) requires a map with deterministic iteration; given " + values.getClass());
-        if (values.size() == 1)
-            return constant(Objects.requireNonNull(Iterables.getFirst(values.keySet(), null)));
-        double totalWeight = values.values().stream().mapToDouble(Integer::intValue).sum();
-        List<Weight<T>> list = new ArrayList<>(values.size());
-        Iterator<Map.Entry<T, Integer>> it = values.entrySet().iterator();
-        for (int i = 0; it.hasNext(); i++)
-        {
-            Map.Entry<T, Integer> e = it.next();
-            list.add(new Weight<>(e.getKey(), e.getValue(), i));
-        }
-        Collections.sort(list);
-        return rs -> {
-            double value = rs.nextDouble() * totalWeight;
-            for (Weight<T> w : list)
-            {
-                value -= w.weight;
-                if (value <= 0)
-                    return w.value;
-            }
-            return list.get(list.size() - 1).value;
-        };
-    }
-
-    public static Gen.IntGen pickZipf(int[] array)
-    {
-        if (array == null || array.length == 0)
-            throw new IllegalArgumentException("Empty array given");
-        if (array.length == 1)
-            return ignore -> array[0];
-        BigDecimal[] weights = new BigDecimal[array.length];
-        BigDecimal base = BigDecimal.valueOf(Math.pow(2, array.length));
-        weights[0] = base;
-        for (int i = 1; i < array.length; i++)
-            weights[i] = base.divide(BigDecimal.valueOf(i + 1), RoundingMode.UP);
-        BigDecimal totalWeights = Stream.of(weights).reduce(BigDecimal.ZERO, BigDecimal::add);
-
-        return rs -> {
-            BigDecimal value = BigDecimal.valueOf(rs.nextDouble()).multiply(totalWeights);
-            for (int i = 0; i < weights.length; i++)
-            {
-                value = value.subtract(weights[i]);
-                if (value.compareTo(BigDecimal.ZERO) <= 0)
-                    return array[i];
-            }
-            return array[array.length - 1];
-        };
-    }
-
-    public static Gen.LongGen pickZipf(long[] array)
-    {
-        if (array == null || array.length == 0)
-            throw new IllegalArgumentException("Empty array given");
-        if (array.length == 1)
-            return ignore -> array[0];
-        BigDecimal[] weights = new BigDecimal[array.length];
-        BigDecimal base = BigDecimal.valueOf(Math.pow(2, array.length));
-        weights[0] = base;
-        for (int i = 1; i < array.length; i++)
-            weights[i] = base.divide(BigDecimal.valueOf(i + 1), RoundingMode.UP);
-        BigDecimal totalWeights = Stream.of(weights).reduce(BigDecimal.ZERO, BigDecimal::add);
-
-        return rs -> {
-            BigDecimal value = BigDecimal.valueOf(rs.nextDouble()).multiply(totalWeights);
-            for (int i = 0; i < weights.length; i++)
-            {
-                value = value.subtract(weights[i]);
-                if (value.compareTo(BigDecimal.ZERO) <= 0)
-                    return array[i];
-            }
-            return array[array.length - 1];
-        };
-    }
-
-    public static <T> Gen<T> pickZipf(T... array)
-    {
-        return pickZipf(Arrays.asList(array));
-    }
-
-    public static <T> Gen<T> pickZipf(List<T> array)
-    {
-        if (array == null || array.isEmpty())
-            throw new IllegalArgumentException("Empty array given");
-        if (array.size() == 1)
-            return ignore -> array.get(0);
-        BigDecimal[] weights = new BigDecimal[array.size()];
-        BigDecimal base = BigDecimal.valueOf(Math.pow(2, array.size()));
-        weights[0] = base;
-        for (int i = 1; i < array.size(); i++)
-            weights[i] = base.divide(BigDecimal.valueOf(i + 1), RoundingMode.UP);
-        BigDecimal totalWeights = Stream.of(weights).reduce(BigDecimal.ZERO, BigDecimal::add);
-
-        return rs -> {
-            BigDecimal value = BigDecimal.valueOf(rs.nextDouble()).multiply(totalWeights);
-            for (int i = 0; i < weights.length; i++)
-            {
-                value = value.subtract(weights[i]);
-                if (value.compareTo(BigDecimal.ZERO) <= 0)
-                    return array.get(i);
-            }
-            return array.get(array.size() - 1);
-        };
-    }
-
-    public static Gen<Gen.IntGen> randomWeights(int[] array)
-    {
-        return rs -> {
-            float[] weights = Picker.randomWeights(rs, array.length);
-            return r -> array[index(r, weights)];
-        };
-    }
-
-    public static Gen<Gen.LongGen> randomWeights(long[] array)
-    {
-        return rs -> {
-            float[] weights = Picker.randomWeights(rs, array.length);
-            return r -> array[index(r, weights)];
-        };
-    }
-
-    public static <T> Gen<Gen<T>> randomWeights(T[] array)
-    {
-        return rs -> {
-            float[] weights = Picker.randomWeights(rs, array.length);
-            return r -> array[index(r, weights)];
-        };
-    }
-
-    public static <T> Gen<Gen<T>> randomWeights(List<T> array)
-    {
-        return rs -> {
-            float[] weights = Picker.randomWeights(rs, array.size());
-            return r -> array.get(index(r, weights));
-        };
-    }
-
-    private static int index(RandomSource rs, float[] weights)
-    {
-        int i = Arrays.binarySearch(weights, rs.nextFloat());
-        if (i < 0) i = -1 - i;
-        return i;
-    }
-
-    public static Gen<Gen.IntGen> mixedDistribution(int minInclusive, int maxExclusive, int numBuckets)
-    {
-        int domainSize = (maxExclusive - minInclusive);
-        if (domainSize < 0)
-            throw new IllegalArgumentException("Range is too large; min=" + minInclusive + ", max=" + maxExclusive);
-        if (numBuckets <= 0 || numBuckets > domainSize)
-            throw new IllegalArgumentException("Num buckets must be between 1 and " + domainSize + "; given " + numBuckets);
-        int[] bucket, indexes;
-        bucket = new int[numBuckets];
-        int delta = domainSize / numBuckets;
-        for (int i = 0; i < numBuckets; i++)
-            bucket[i] = minInclusive + i * delta;
-        indexes = IntStream.range(0, bucket.length).toArray();
-        Gen<Gen.IntGen> indexDistro = mixedDistribution(indexes);
-        return rs -> {
-            Gen.IntGen indexGen = indexDistro.next(rs);
-            switch (rs.nextInt(0, 2))
-            {
-                case 0: // uniform
-                {
-                    return r -> {
-                        int idx = indexGen.next(rs);
-                        int start = bucket[idx];
-                        int end = idx == bucket.length - 1 ? maxExclusive : bucket[idx + 1];
-                        return r.nextInt(start, end);
-                    };
-                }
-                case 1: // median biased
-                {
-                    int medians[] = new int[bucket.length];
-                    for (int i = 0; i < medians.length; i++)
-                    {
-                        int start = bucket[i];
-                        int end = i == bucket.length - 1 ? maxExclusive : bucket[i + 1];
-                        medians[i] = rs.nextInt(start, end);
-                    }
-                    return r -> {
-                        int idx = indexGen.next(rs);
-                        int start = bucket[idx];
-                        int end = idx == bucket.length - 1 ? maxExclusive : bucket[idx + 1];
-                        int median = medians[idx];
-                        return r.nextBiasedInt(start, median, end);
-                    };
-                }
-                default:
-                    throw new AssertionError();
-            }
-        };
-    }
-
-    public static Gen<Gen.IntGen> mixedDistribution(int minInclusive, int maxExclusive)
-    {
-        int domainSize = (maxExclusive - minInclusive + 1);
-        if (domainSize < 0)
-            throw new IllegalArgumentException("Range is too large; min=" + minInclusive + ", max=" + maxExclusive);
-        int[] array, indexes;
-        if (domainSize > 200) // randomly selected
-        {
-            int numBuckets = 10;
-            int delta = domainSize / numBuckets;
-            array = new int[numBuckets];
-            for (int i = 0; i < numBuckets; i++)
-                array[i] = minInclusive + i * delta;
-            indexes = IntStream.range(0, array.length).toArray();
-        }
-        else
-        {
-            array = IntStream.range(minInclusive, maxExclusive).toArray();
-            indexes = null;
-        }
-        return rs -> {
-            switch (rs.nextInt(0, 4))
-            {
-                case 0: // uniform
-                    return r -> r.nextInt(minInclusive, maxExclusive);
-                case 1: // median biased
-                    int median = rs.nextInt(minInclusive, maxExclusive);
-                    return r -> r.nextBiasedInt(minInclusive, median, maxExclusive);
-                case 2: // zipf
-                    if (indexes == null)
-                        return Gens.pickZipf(rs.nextBoolean() ? reverseAndCopy(array) : array);
-                    return Gens.pickZipf(rs.nextBoolean() ? reverseAndCopy(indexes) : indexes).mapAsInt((r, index) -> {
-                        int start = array[index];
-                        int end = index == array.length - 1 ? maxExclusive : array[index + 1];
-                        return r.nextInt(start, end);
-                    });
-                case 3: // random weight
-                    if (indexes == null)
-                        return randomWeights(array).next(rs);
-                    return randomWeights(indexes).next(rs).mapAsInt((r, index) -> {
-                        int start = array[index];
-                        int end = index == array.length - 1 ? maxExclusive : array[index + 1];
-                        return r.nextInt(start, end);
-                    });
-                default:
-                    throw new AssertionError();
-            }
-        };
-    }
-
-    private static int[] reverseAndCopy(int[] array)
-    {
-        array = Arrays.copyOf(array, array.length);
-        for (int i = 0, mid = array.length / 2, j = array.length - 1; i < mid; i++, j--)
-        {
-            int tmp = array[i];
-            array[i] = array[j];
-            array[j] = tmp;
-        }
-        return array;
-    }
-
-    public static Gen<Gen.LongGen> mixedDistribution(long minInclusive, long maxExclusive)
-    {
-        long domainSize = (maxExclusive - minInclusive + 1);
-        if (domainSize < 0)
-            throw new IllegalArgumentException("Range is too large; min=" + minInclusive + ", max=" + maxExclusive);
-        long[] array;
-        int[] indexes;
-        if (domainSize > 200) // randomly selected
-        {
-            int numBuckets = 10;
-            long delta = domainSize / numBuckets;
-            array = new long[numBuckets];
-            for (int i = 0; i < numBuckets; i++)
-                array[i] = minInclusive + i * delta;
-            indexes = IntStream.range(0, array.length).toArray();
-        }
-        else
-        {
-            array = LongStream.range(minInclusive, maxExclusive).toArray();
-            indexes = null;
-        }
-        return rs -> {
-            switch (rs.nextInt(0, 4))
-            {
-                case 0: // uniform
-                    return r -> r.nextLong(minInclusive, maxExclusive);
-                case 1: // median biased
-                    long median = rs.nextLong(minInclusive, maxExclusive);
-                    return r -> r.nextBiasedLong(minInclusive, median, maxExclusive);
-                case 2: // zipf
-                    if (indexes == null)
-                        return Gens.pickZipf(rs.nextBoolean() ? reverseAndCopy(array) : array);
-                    return Gens.pickZipf(rs.nextBoolean() ? reverseAndCopy(indexes) : indexes).mapAsLong((r, index) -> {
-                        long start = array[index];
-                        long end = index == array.length - 1 ? maxExclusive : array[index + 1];
-                        return r.nextLong(start, end);
-                    });
-                case 3: // random weight
-                    if (indexes == null)
-                        return randomWeights(array).next(rs);
-                    return randomWeights(indexes).next(rs).mapAsLong((r, index) -> {
-                        long start = array[index];
-                        long end = index == array.length - 1 ? maxExclusive : array[index + 1];
-                        return r.nextLong(start, end);
-                    });
-                default:
-                    throw new AssertionError();
-            }
-        };
-    }
-
-    private static long[] reverseAndCopy(long[] array)
-    {
-        array = Arrays.copyOf(array, array.length);
-        for (int i = 0, mid = array.length / 2, j = array.length - 1; i < mid; i++, j--)
-        {
-            long tmp = array[i];
-            array[i] = array[j];
-            array[j] = tmp;
-        }
-        return array;
-    }
-
-    public static <T> Gen<Gen<T>> mixedDistribution(T... list)
-    {
-        return mixedDistribution(Arrays.asList(list));
-    }
-
-    public static <T> Gen<Gen<T>> mixedDistribution(List<T> list)
-    {
-        return rs -> {
-            switch (rs.nextInt(0, 4))
-            {
-                case 0: // uniform
-                    return r -> list.get(rs.nextInt(0, list.size()));
-                case 1: // median biased
-                    int median = rs.nextInt(0, list.size());
-                    return r -> list.get(r.nextBiasedInt(0, median, list.size()));
-                case 2: // zipf
-                    List<T> array = list;
-                    if (rs.nextBoolean())
-                    {
-                        array = new ArrayList<>(list);
-                        Collections.reverse(array);
-                    }
-                    return pickZipf(array);
-                case 3: // random weight
-                    return randomWeights(list).next(rs);
-                default:
-                    throw new AssertionError();
-            }
-        };
-    }
-
-    public static <T> Gen<Gen.IntGen> mixedDistribution(int[] list)
-    {
-        return rs -> {
-            switch (rs.nextInt(0, 4))
-            {
-                case 0: // uniform
-                    return r -> list[rs.nextInt(0, list.length)];
-                case 1: // median biased
-                    int median = rs.nextInt(0, list.length);
-                    return r -> list[r.nextBiasedInt(0, median, list.length)];
-                case 2: // zipf
-                    int[] array = list;
-                    if (rs.nextBoolean())
-                    {
-                        array = Arrays.copyOf(array, array.length);
-                        reverse(array);
-                    }
-                    return pickZipf(array);
-                case 3: // random weight
-                    return randomWeights(list).next(rs);
-                default:
-                    throw new AssertionError();
-            }
-        };
-    }
-
-    /**
-     * This is a change from accord as that uses {@link accord.utils.Utils#reverse}, which doesn't exist in this forward port.
-     *
-     * To avoid adding another class and merge conflicts to cep-15-accord, this method was inlined
-     */
-    private static void reverse(int[] array)
-    {
-        for (int i = 0; i < array.length / 2; i++)
-        {
-            int tmp = array[i];
-            array[i] = array[array.length- 1 - i];
-            array[array.length - 1 - i] = tmp;
-        }
-    }
-
-    public static Gen<char[]> charArray(Gen.IntGen sizes, char[] domain)
-    {
-        return charArray(sizes, domain, (a, b) -> true);
-    }
-
-    public interface IntCharBiPredicate
-    {
-        boolean test(int a, char b);
-    }
-
-    public static Gen<char[]> charArray(Gen.IntGen sizes, char[] domain, IntCharBiPredicate fn)
-    {
-        Gen.IntGen indexGen = ints().between(0, domain.length - 1);
-        return rs -> {
-            int size = sizes.nextInt(rs);
-            char[] is = new char[size];
-            for (int i = 0; i != size; i++)
-            {
-                char c;
-                do
-                {
-                    c = domain[indexGen.nextInt(rs)];
-                }
-                while (!fn.test(i, c));
-                is[i] = c;
-            }
-            return is;
-        };
-    }
-
-    public static Gen<accord.utilsfork.RandomSource> random() {
-        return r -> r;
-    }
-
-    public static BooleanDSL bools()
-    {
-        return new BooleanDSL();
-    }
-
-    public static IntDSL ints()
-    {
-        return new IntDSL();
-    }
-
-    public static LongDSL longs() {
-        return new LongDSL();
-    }
-
-    public static <T> ListDSL<T> lists(Gen<T> fn) {
-        return new ListDSL<>(fn);
-    }
-
-    public static <T> ArrayDSL<T> arrays(Class<T> type, Gen<T> fn) {
-        return new ArrayDSL<>(type, fn);
-    }
-
-    public static IntArrayDSL arrays(Gen.IntGen fn) {
-        return new IntArrayDSL(fn);
-    }
-
-    public static LongArrayDSL arrays(Gen.LongGen fn) {
-        return new LongArrayDSL(fn);
-    }
-
-    public static EnumDSL enums()
-    {
-        return new EnumDSL();
-    }
-
-    public static StringDSL strings()
-    {
-        return new StringDSL();
-    }
-
-    public static BooleanSupplier supplier(Gen<Boolean> gen, accord.utilsfork.RandomSource rs)
-    {
-        return () -> gen.next(rs);
-    }
-
-    public static class BooleanDSL
-    {
-        public Gen<Boolean> all()
-        {
-            return accord.utilsfork.RandomSource::nextBoolean;
-        }
-
-        public Gen<Boolean> biasedRepeatingRuns(double ratio, int maxRuns)
-        {
-            accord.utilsfork.Invariants.checkArgument(ratio > 0 && ratio <= 1, "Expected %d to be larger than 0 and <= 1", ratio);
-            double lower = ratio * .8;
-            double upper = ratio * 1.2;
-            return new Gen<Boolean>() {
-                // run represents how many consecutaive true values should be returned; -1 implies no active "run" exists
-                private int run = -1;
-                private long falseCount = 0, trueCount = 0;
-                @Override
-                public Boolean next(accord.utilsfork.RandomSource rs)
-                {
-                    if (run != -1)
-                    {
-                        run--;
-                        trueCount++;
-                        return true;
-                    }
-                    double currentRatio = trueCount / (double) (falseCount + trueCount);
-                    if (currentRatio < lower)
-                    {
-                        // not enough true
-                        trueCount++;
-                        return true;
-                    }
-                    if (currentRatio > upper)
-                    {
-                        // not enough false
-                        falseCount++;
-                        return false;
-                    }
-                    if (rs.decide(ratio))
-                    {
-                        run = rs.nextInt(maxRuns);
-                        run--;
-                        trueCount++;
-                        return true;
-                    }
-                    falseCount++;
-                    return false;
-                }
-            };
-        }
-
-        public Gen<Gen<Boolean>> mixedDistribution()
-        {
-            return rs -> {
-                int selection = rs.nextInt(0, 4);
-                switch (selection)
-                {
-                    case 0: // uniform 50/50
-                        return r -> r.nextBoolean();
-                    case 1: // variable frequency
-                        var freq = rs.nextFloat();
-                        return r -> r.decide(freq);
-                    case 2: // fixed result
-                        boolean result = rs.nextBoolean();
-                        return ignore -> result;
-                    case 3: // biased repeating runs
-                        return biasedRepeatingRuns(rs.nextDouble(), rs.nextInt(1, 100));
-                    default:
-                        throw new IllegalStateException("Unexpected int for bool selection: " + selection);
-                }
-            };
-        }
-    }
-
-    public static class IntDSL
-    {
-        public Gen.IntGen of(int value)
-        {
-            return r -> value;
-        }
-
-        public Gen.IntGen all()
-        {
-            return accord.utilsfork.RandomSource::nextInt;
-        }
-
-        public Gen.IntGen between(int min, int max)
-        {
-            accord.utilsfork.Invariants.checkArgument(max >= min, "max (%d) < min (%d)", max, min);
-            if (min == max)
-                return of(min);
-            // since bounds is exclusive, if max == max_value unable to do +1 to include... so will return a gen
-            // that does not include
-            if (max == Integer.MAX_VALUE)
-                return r -> r.nextInt(min, max);
-            return r -> r.nextInt(min, max + 1);
-        }
-
-        public Gen<Gen.IntGen> mixedDistribution(int minInclusive, int maxExclusive)
-        {
-            return Gens.mixedDistribution(minInclusive, maxExclusive);
-        }
-
-        public Gen<Gen.IntGen> mixedDistribution(int minInclusive, int maxExclusive, int numBuckets)
-        {
-            return Gens.mixedDistribution(minInclusive, maxExclusive, numBuckets);
-        }
-    }
-
-    public static class LongDSL {
-        public Gen.LongGen of(long value)
-        {
-            return r -> value;
-        }
-
-        public Gen.LongGen all() {
-            return accord.utilsfork.RandomSource::nextLong;
-        }
-
-        public Gen.LongGen between(long min, long max) {
-            Invariants.checkArgument(max >= min);
-            if (min == max)
-                return of(min);
-            // since bounds is exclusive, if max == max_value unable to do +1 to include... so will return a gen
-            // that does not include
-            if (max == Long.MAX_VALUE)
-                return r -> r.nextLong(min, max);
-            return r -> r.nextLong(min, max + 1);
-        }
-    }
-
-    public static class EnumDSL
-    {
-        public <T extends Enum<T>> Gen<T> all(Class<T> klass)
-        {
-            return pick(klass.getEnumConstants());
-        }
-
-        public <T extends Enum<T>> Gen<Gen<T>> allMixedDistribution(Class<T> klass)
-        {
-            return mixedDistribution(klass.getEnumConstants());
-        }
-
-        public <T extends Enum<T>> Gen<T> allWithWeights(Class<T> klass, int... weights)
-        {
-            T[] constants = klass.getEnumConstants();
-            if (constants.length != weights.length)
-                throw new IllegalArgumentException(String.format("Total number of weights (%s) does not match the enum (%s)", Arrays.toString(weights), Arrays.toString(constants)));
-            Map<T, Integer> values = new EnumMap<>(klass);
-            for (int i = 0; i < constants.length; i++)
-                values.put(constants[i], weights[i]);
-            return pick(values);
-        }
-    }
-
-    public static class StringDSL
-    {
-        public Gen<String> of(Gen.IntGen sizes, char[] domain)
-        {
-            // note, map is overloaded so String::new is ambugious to javac, so need a lambda here
-            return charArray(sizes, domain).map(c -> new String(c));
-        }
-
-        public SizeBuilder<String> of(char[] domain)
-        {
-            return new SizeBuilder<>(sizes -> of(sizes, domain));
-        }
-
-        public Gen<String> of(Gen.IntGen sizes, char[] domain, IntCharBiPredicate fn)
-        {
-            // note, map is overloaded so String::new is ambugious to javac, so need a lambda here
-            return charArray(sizes, domain, fn).map(c -> new String(c));
-        }
-
-        public SizeBuilder<String> of(char[] domain, IntCharBiPredicate fn)
-        {
-            return new SizeBuilder<>(sizes -> of(sizes, domain, fn));
-        }
-
-        public Gen<String> all(Gen.IntGen sizes)
-        {
-            return betweenCodePoints(sizes, Character.MIN_CODE_POINT, Character.MAX_CODE_POINT);
-        }
-
-        public SizeBuilder<String> all()
-        {
-            return new SizeBuilder<>(this::all);
-        }
-
-        public Gen<String> ascii(Gen.IntGen sizes)
-        {
-            return betweenCodePoints(sizes, 0, 127);
-        }
-
-        public SizeBuilder<String> ascii()
-        {
-            return new SizeBuilder<>(this::ascii);
-        }
-
-        public Gen<String> betweenCodePoints(Gen.IntGen sizes, int min, int max)
-        {
-            Gen.IntGen codePointGen = ints().between(min, max).filter(Character::isDefined);
-            return rs -> {
-                int[] array = new int[sizes.nextInt(rs)];
-                for (int i = 0; i < array.length; i++)
-                    array[i] = codePointGen.nextInt(rs);
-                return new String(array, 0, array.length);
-            };
-        }
-
-        public SizeBuilder<String> betweenCodePoints(int min, int max)
-        {
-            return new SizeBuilder<>(sizes -> betweenCodePoints(sizes, min, max));
-        }
-    }
-
-    public static class SizeBuilder<T>
-    {
-        private final Function<Gen.IntGen, Gen<T>> fn;
-
-        public SizeBuilder(Function<Gen.IntGen, Gen<T>> fn)
-        {
-            this.fn = fn;
-        }
-
-        public Gen<T> ofLength(int fixed)
-        {
-            return ofLengthBetween(fixed, fixed);
-        }
-
-        public Gen<T> ofLengthBetween(int min, int max)
-        {
-            return fn.apply(ints().between(min, max));
-        }
-    }
-
-    public static class ListDSL<T> implements BaseSequenceDSL<ListDSL<T>, List<T>> {
-        private final Gen<T> fn;
-
-        public ListDSL(Gen<T> fn) {
-            this.fn = Objects.requireNonNull(fn);
-        }
-
-        @Override
-        public ListDSL<T> unique()
-        {
-            return new ListDSL<>(new GenReset<>(fn, false));
-        }
-
-        public ListDSL<T> uniqueBestEffort()
-        {
-            return new ListDSL<>(new GenReset<>(fn, true));
-        }
-
-        @Override
-        public Gen<List<T>> ofSizeBetween(int minSize, int maxSize) {
-            Gen.IntGen sizeGen = ints().between(minSize, maxSize);
-            return r ->
-            {
-                Reset.tryReset(fn);
-                int size = sizeGen.nextInt(r);
-                List<T> list = new ArrayList<>(size);
-                for (int i = 0; i < size; i++)
-                {
-                    try
-                    {
-                        list.add(fn.next(r));
-                    }
-                    catch (IgnoreGenResult e)
-                    {
-                        // ignore
-                    }
-                }
-                return list;
-            };
-        }
-    }
-
-    public static class ArrayDSL<T> implements BaseSequenceDSL<ArrayDSL<T>, T[]> {
-        private final Class<T> type;
-        private final Gen<T> fn;
-
-        public ArrayDSL(Class<T> type, Gen<T> fn) {
-            this.type = Objects.requireNonNull(type);
-            this.fn = Objects.requireNonNull(fn);
-        }
-
-        @Override
-        public ArrayDSL<T> unique()
-        {
-            return new ArrayDSL<>(type, new GenReset<>(fn, false));
-        }
-
-        public ArrayDSL<T> uniqueBestEffort()
-        {
-            return new ArrayDSL<>(type, new GenReset<>(fn, true));
-        }
-
-        @Override
-        public Gen<T[]> ofSizeBetween(int minSize, int maxSize) {
-            Gen.IntGen sizeGen = ints().between(minSize, maxSize);
-            return r ->
-            {
-                Reset.tryReset(fn);
-                int size = sizeGen.nextInt(r);
-                T[] list = (T[]) Array.newInstance(type, size);
-                for (int i = 0; i < size; i++)
-                    list[i] = fn.next(r);
-                return list;
-            };
-        }
-    }
-
-    public static class IntArrayDSL implements BaseSequenceDSL<IntArrayDSL, int[]> {
-        private final Gen.IntGen fn;
-
-        public IntArrayDSL(Gen.IntGen fn) {
-            this.fn = Objects.requireNonNull(fn);
-        }
-
-        @Override
-        public IntArrayDSL unique()
-        {
-            return new IntArrayDSL(new IntGenReset(fn));
-        }
-
-        @Override
-        public Gen<int[]> ofSizeBetween(int minSize, int maxSize) {
-            Gen.IntGen sizeGen = ints().between(minSize, maxSize);
-            return r ->
-            {
-                int size = sizeGen.nextInt(r);
-                int[] list = new int[size];
-                for (int i = 0; i < size; i++)
-                    list[i] = fn.nextInt(r);
-                return list;
-            };
-        }
-    }
-
-    public static class LongArrayDSL implements BaseSequenceDSL<LongArrayDSL, long[]> {
-        private final Gen.LongGen fn;
-
-        public LongArrayDSL(Gen.LongGen fn) {
-            this.fn = Objects.requireNonNull(fn);
-        }
-
-        @Override
-        public LongArrayDSL unique()
-        {
-            return new LongArrayDSL(new LongGenReset(fn));
-        }
-
-        @Override
-        public Gen<long[]> ofSizeBetween(int minSize, int maxSize) {
-            Gen.IntGen sizeGen = ints().between(minSize, maxSize);
-            return r ->
-            {
-                int size = sizeGen.nextInt(r);
-                long[] list = new long[size];
-                for (int i = 0; i < size; i++)
-                    list[i] = fn.nextLong(r);
-                return list;
-            };
-        }
-    }
-
-    public interface BaseSequenceDSL<A extends BaseSequenceDSL<A, B>, B>
-    {
-        A unique();
-
-        Gen<B> ofSizeBetween(int min, int max);
-
-        default Gen<B> ofSize(int size) {
-            return ofSizeBetween(size, size);
-        }
-    }
-
-    protected interface Reset {
-        static void tryReset(Object o)
-        {
-            if (o instanceof Reset)
-                ((Reset) o).reset();
-        }
-
-        void reset();
-    }
-
-    private static final class IgnoreGenResult extends RuntimeException
-    {
-        private static final IgnoreGenResult INSTANCE = new IgnoreGenResult();
-        private IgnoreGenResult()
-        {
-            super(null, null, false, false);
-        }
-    }
-
-    private static class GenReset<T> implements Gen<T>, Reset
-    {
-        private final Set<T> seen = new HashSet<>();
-        private final Gen<T> fn;
-        private final boolean bestEffort;
-
-        private GenReset(Gen<T> fn, boolean bestEffort)
-        {
-            this.fn = fn;
-            this.bestEffort = bestEffort;
-        }
-
-        @Override
-        public T next(accord.utilsfork.RandomSource random)
-        {
-            if (!bestEffort)
-            {
-                T value;
-                // 10k attempts
-                for (int i = 0; i < 10_000; i++)
-                {
-                    if (seen.add((value = fn.next(random))))
-                        return value;
-                }
-
-                throw new IllegalArgumentException("Could not generate a unique value after 10k attempts");
-            }
-            else
-            {
-                T value = null;
-                int i;
-                for (i = 0; i < 42 && !seen.add((value = fn.next(random))); i++) {}
-                if (i == 42) throw IgnoreGenResult.INSTANCE;
-                return value;
-            }
-        }
-
-        @Override
-        public void reset()
-        {
-            seen.clear();
-        }
-    }
-
-    private static class IntGenReset implements Gen.IntGen, Reset
-    {
-        private final GenReset<Integer> base;
-
-        private IntGenReset(IntGen fn)
-        {
-            this.base = new GenReset<>(fn, false);
-        }
-        @Override
-        public int nextInt(accord.utilsfork.RandomSource random) {
-            return base.next(random);
-        }
-
-        @Override
-        public void reset() {
-            base.reset();
-        }
-    }
-
-    private static class LongGenReset implements Gen.LongGen, Reset
-    {
-        private final GenReset<Long> base;
-
-        private LongGenReset(LongGen fn)
-        {
-            this.base = new GenReset<>(fn, false);
-        }
-        @Override
-        public long nextLong(RandomSource random) {
-            return base.next(random);
-        }
-
-        @Override
-        public void reset() {
-            base.reset();
-        }
-    }
-
-    private static class Weight<T> implements Comparable<Weight<T>>
-    {
-        private final T value;
-        private final double weight;
-        private final int index;
-
-        private Weight(T value, double weight, int index) {
-            this.value = value;
-            this.weight = weight;
-            this.index = index;
-        }
-
-        @Override
-        public int compareTo(Weight<T> o) {
-            int rc = Double.compare(weight, o.weight);
-            if (rc == 0)
-                rc = Integer.compare(index, o.index);
-            return rc;
-        }
-    }
-}
diff --git a/test/unit/accord/utilsfork/Invariants.java b/test/unit/accord/utilsfork/Invariants.java
deleted file mode 100644
index 6028b69078..0000000000
--- a/test/unit/accord/utilsfork/Invariants.java
+++ /dev/null
@@ -1,339 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork;
-
-import net.nicoulaj.compilecommand.annotations.Inline;
-
-import javax.annotation.Nullable;
-import java.util.function.Predicate;
-import java.util.function.Supplier;
-
-import static java.lang.String.format;
-
-public class Invariants
-{
-    private static final boolean PARANOID = true;
-    private static final boolean DEBUG = true;
-
-    public static boolean isParanoid()
-    {
-        return PARANOID;
-    }
-    public static boolean debug()
-    {
-        return DEBUG;
-    }
-
-    public static IllegalStateException createIllegalState(String msg)
-    {
-        return new IllegalStateException(msg);
-    }
-
-    public static IllegalStateException illegalState(String msg)
-    {
-        throw createIllegalState(msg);
-    }
-
-    private static void illegalState()
-    {
-        illegalState(null);
-    }
-
-    private static void illegalArgument(String msg)
-    {
-        throw new IllegalArgumentException(msg);
-    }
-
-
-    private static void illegalArgument()
-    {
-        illegalArgument(null);
-    }
-
-    public static <T1, T2 extends T1> T2 checkType(T1 cast)
-    {
-        return (T2)cast;
-    }
-
-    public static <T1, T2 extends T1> T2 checkType(Class<T2> to, T1 cast)
-    {
-        if (cast != null && !to.isInstance(cast))
-            illegalState();
-        return (T2)cast;
-    }
-
-    public static <T1, T2 extends T1> T2 checkType(Class<T2> to, T1 cast, String msg)
-    {
-        if (cast != null && !to.isInstance(cast))
-            illegalState(msg);
-        return (T2)cast;
-    }
-
-    public static void paranoid(boolean condition)
-    {
-        if (PARANOID && !condition)
-            illegalState();
-    }
-
-    public static void checkState(boolean condition)
-    {
-        if (!condition)
-            illegalState();
-    }
-
-    public static void checkState(boolean condition, Supplier<String> msg)
-    {
-        if (!condition)
-            throw illegalState(msg.get());
-    }
-
-    public static void checkState(boolean condition, String msg)
-    {
-        if (!condition)
-            illegalState(msg);
-    }
-
-    public static void checkState(boolean condition, String fmt, int p1)
-    {
-        if (!condition)
-            illegalState(format(fmt, p1));
-    }
-
-    public static void checkState(boolean condition, String fmt, int p1, int p2)
-    {
-        if (!condition)
-            illegalState(format(fmt, p1, p2));
-    }
-
-    public static void checkState(boolean condition, String fmt, long p1)
-    {
-        if (!condition)
-            illegalState(format(fmt, p1));
-    }
-
-    public static void checkState(boolean condition, String fmt, long p1, long p2)
-    {
-        if (!condition)
-            illegalState(format(fmt, p1, p2));
-    }
-
-    public static void checkState(boolean condition, String fmt, @Nullable Object p1)
-    {
-        if (!condition)
-            illegalState(format(fmt, p1));
-    }
-
-    public static void checkState(boolean condition, String fmt, @Nullable Object p1, @Nullable Object p2)
-    {
-        if (!condition)
-            illegalState(format(fmt, p1, p2));
-    }
-
-    public static void checkState(boolean condition, String fmt, Object... args)
-    {
-        if (!condition)
-            illegalState(format(fmt, args));
-    }
-
-    public static <T> T nonNull(T param)
-    {
-        if (param == null)
-            throw new NullPointerException();
-        return param;
-    }
-
-    public static <T> T nonNull(T param, String fmt, Object... args)
-    {
-        if (param == null)
-            throw new NullPointerException(format(fmt, args));
-        return param;
-    }
-
-    public static int isNatural(int input)
-    {
-        if (input < 0)
-            illegalState();
-        return input;
-    }
-
-    public static long isNatural(long input)
-    {
-        if (input < 0)
-            illegalState();
-        return input;
-    }
-
-    public static void checkArgument(boolean condition)
-    {
-        if (!condition)
-            illegalArgument();
-    }
-
-    public static void checkArgument(boolean condition, String msg)
-    {
-        if (!condition)
-            illegalArgument(msg);
-    }
-
-    public static void checkArgument(boolean condition, String fmt, int p1)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1));
-    }
-
-    public static void checkArgument(boolean condition, String fmt, int p1, int p2)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1, p2));
-    }
-
-    public static void checkArgument(boolean condition, String fmt, long p1)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1));
-    }
-
-    public static void checkArgument(boolean condition, String fmt, long p1, long p2)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1, p2));
-    }
-
-    public static void checkArgument(boolean condition, String fmt, @Nullable Object p1)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1));
-    }
-
-    public static void checkArgument(boolean condition, String fmt, @Nullable Object p1, @Nullable Object p2)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1, p2));
-    }
-
-    public static void checkArgument(boolean condition, String fmt, Object... args)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, args));
-    }
-
-    public static <T> T checkArgument(T param, boolean condition)
-    {
-        if (!condition)
-            illegalArgument();
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String msg)
-    {
-        if (!condition)
-            illegalArgument(msg);
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String fmt, int p1)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1));
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String fmt, int p1, int p2)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1, p2));
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String fmt, long p1)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1));
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String fmt, long p1, long p2)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1, p2));
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String fmt, @Nullable Object p1)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1));
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String fmt, @Nullable Object p1, @Nullable Object p2)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, p1, p2));
-        return param;
-    }
-
-    public static <T> T checkArgument(T param, boolean condition, String fmt, Object... args)
-    {
-        if (!condition)
-            illegalArgument(format(fmt, args));
-        return param;
-    }
-
-    @Inline
-    public static <T> T checkArgument(T param, Predicate<T> condition)
-    {
-        if (!condition.test(param))
-            illegalArgument();
-        return param;
-    }
-
-    @Inline
-    public static <T> T checkArgument(T param, Predicate<T> condition, String msg)
-    {
-        if (!condition.test(param))
-            illegalArgument(msg);
-        return param;
-    }
-
-    public static <O> O cast(Object o, Class<O> klass)
-    {
-        try
-        {
-            return klass.cast(o);
-        }
-        catch (ClassCastException e)
-        {
-            throw new IllegalArgumentException(format("Unable to cast %s to %s", o, klass.getName()));
-        }
-    }
-
-    public static void checkIndexInBounds(int realLength, int offset, int length)
-    {
-        if (realLength == 0 || length == 0)
-            throw new IndexOutOfBoundsException("Unable to access offset " + offset + "; empty");
-        if (offset < 0)
-            throw new IndexOutOfBoundsException("Offset " + offset + " must not be negative");
-        if (length < 0)
-            throw new IndexOutOfBoundsException("Length " + length + " must not be negative");
-        int endOffset = offset + length;
-        if (endOffset > realLength)
-            throw new IndexOutOfBoundsException(String.format("Offset %d, length = %d; real length was %d", offset, length, realLength));
-    }
-}
diff --git a/test/unit/accord/utilsfork/Property.java b/test/unit/accord/utilsfork/Property.java
deleted file mode 100644
index fbf1f4c7c5..0000000000
--- a/test/unit/accord/utilsfork/Property.java
+++ /dev/null
@@ -1,1075 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork;
-
-import accord.utilsfork.async.TimeoutUtils;
-
-import java.time.Duration;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.LinkedHashMap;
-import java.util.LinkedHashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-import java.util.Set;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.TimeoutException;
-import java.util.function.BiFunction;
-import java.util.function.Consumer;
-import java.util.function.Function;
-import java.util.function.Predicate;
-import java.util.function.Supplier;
-import java.util.stream.Collectors;
-import javax.annotation.Nullable;
-
-import org.agrona.collections.LongArrayList;
-
-public class Property
-{
-    public static abstract class Common<T extends Common<T>>
-    {
-        protected long seed = SeedProvider.instance.nextSeed();
-        protected int examples = 1000;
-
-        protected boolean pure = true;
-        @Nullable
-        protected Duration timeout = null;
-
-        protected Common() {
-        }
-
-        protected Common(Common<?> other) {
-            this.seed = other.seed;
-            this.examples = other.examples;
-            this.pure = other.pure;
-            this.timeout = other.timeout;
-        }
-
-        public T withSeed(long seed)
-        {
-            this.seed = seed;
-            return (T) this;
-        }
-
-        public T withExamples(int examples)
-        {
-            if (examples <= 0)
-                throw new IllegalArgumentException("Examples must be positive");
-            this.examples = examples;
-            return (T) this;
-        }
-
-        public T withPure(boolean pure)
-        {
-            this.pure = pure;
-            return (T) this;
-        }
-
-        public T withTimeout(Duration timeout)
-        {
-            this.timeout = timeout;
-            this.pure = false;
-            return (T) this;
-        }
-
-        protected void checkWithTimeout(Runnable fn)
-        {
-            try
-            {
-                TimeoutUtils.runBlocking(timeout, "property with timeout", fn::run);
-            }
-            catch (ExecutionException e)
-            {
-                throw new PropertyError(propertyError(this, e.getCause()));
-            }
-            catch (InterruptedException e)
-            {
-                throw new PropertyError(propertyError(this, e));
-            }
-            catch (TimeoutException e)
-            {
-                TimeoutException override = new TimeoutException("property test did not complete within " + this.timeout);
-                override.setStackTrace(new StackTraceElement[0]);
-                throw new PropertyError(propertyError(this, override));
-            }
-        }
-    }
-
-    public static class ForBuilder extends Common<ForBuilder>
-    {
-        public void check(FailingConsumer<accord.utilsfork.RandomSource> fn)
-        {
-            forAll(accord.utilsfork.Gens.random()).check(fn);
-        }
-
-        public <T> SingleBuilder<T> forAll(accord.utilsfork.Gen<T> gen)
-        {
-            return new SingleBuilder<>(gen, this);
-        }
-
-        public <A, B> DoubleBuilder<A, B> forAll(accord.utilsfork.Gen<A> a, accord.utilsfork.Gen<B> b)
-        {
-            return new DoubleBuilder<>(a, b, this);
-        }
-
-        public <A, B, C> TrippleBuilder<A, B, C> forAll(accord.utilsfork.Gen<A> a, accord.utilsfork.Gen<B> b, accord.utilsfork.Gen<C> c)
-        {
-            return new TrippleBuilder<>(a, b, c, this);
-        }
-    }
-
-    private static Object normalizeValue(Object value)
-    {
-        if (value == null)
-            return null;
-        // one day java arrays will have a useful toString... one day...
-        if (value.getClass().isArray())
-        {
-            Class<?> subType = value.getClass().getComponentType();
-            if (!subType.isPrimitive())
-                return Arrays.asList((Object[]) value);
-            if (Byte.TYPE == subType)
-                return Arrays.toString((byte[]) value);
-            if (Character.TYPE == subType)
-                return Arrays.toString((char[]) value);
-            if (Short.TYPE == subType)
-                return Arrays.toString((short[]) value);
-            if (Integer.TYPE == subType)
-                return Arrays.toString((int[]) value);
-            if (Long.TYPE == subType)
-                return Arrays.toString((long[]) value);
-            if (Float.TYPE == subType)
-                return Arrays.toString((float[]) value);
-            if (Double.TYPE == subType)
-                return Arrays.toString((double[]) value);
-        }
-        try
-        {
-            String result = value.toString();
-            if (result != null && result.length() > 100 && value instanceof Collection)
-                result = ((Collection<?>) value).stream().map(o -> "\n\t     " + o).collect(Collectors.joining(",", "[", "]"));
-            return result;
-        }
-        catch (Throwable t)
-        {
-            return "Object.toString failed: " + t.getClass().getCanonicalName() + ": " + t.getMessage();
-        }
-    }
-
-    private static StringBuilder propertyErrorCommon(Common<?> input, Throwable cause)
-    {
-        StringBuilder sb = new StringBuilder();
-        // return "Seed=" + seed + "\nExamples=" + examples;
-        sb.append("Property error detected:\nSeed = ").append(input.seed).append('\n');
-        sb.append("Examples = ").append(input.examples).append('\n');
-        sb.append("Pure = ").append(input.pure).append('\n');
-        if (cause != null)
-        {
-            String msg = cause.getMessage();
-            sb.append("Error: ");
-            // to improve readability, if a newline is detected move the error msg to the next line
-            if (msg != null && msg.contains("\n"))
-                msg = "\n\t" + msg.replace("\n", "\n\t");
-            if (msg == null)
-                msg = cause.getClass().getCanonicalName();
-            sb.append(msg).append('\n');
-        }
-        return sb;
-    }
-
-    private static String propertyError(Common<?> input, Throwable cause, Object... values)
-    {
-        StringBuilder sb = propertyErrorCommon(input, cause);
-        if (values != null)
-        {
-            sb.append("Values:\n");
-            for (int i = 0; i < values.length; i++)
-                sb.append('\t').append(i).append(" = ").append(normalizeValue(values[i])).append(": ").append(values[i] == null ? "unknown type" : values[i].getClass().getCanonicalName()).append('\n');
-        }
-        return sb.toString();
-    }
-
-    private static String statefulPropertyError(StatefulBuilder input, Throwable cause, Object state, List<String> history)
-    {
-        StringBuilder sb = propertyErrorCommon(input, cause);
-        sb.append("Steps: ").append(input.steps).append('\n');
-        sb.append("Values:\n");
-        String stateStr = state == null ? null : state.toString().replace("\n", "\n\t\t");
-        sb.append("\tState: ").append(stateStr).append(": ").append(state == null ? "unknown type" : state.getClass().getCanonicalName()).append('\n');
-        sb.append("\tHistory:").append('\n');
-        addList(sb, "\t\t", history);
-        return sb.toString();
-    }
-
-    private static void addList(StringBuilder sb, String prefix, List<String> list)
-    {
-        int idx = 0;
-        for (var event : list)
-            sb.append(prefix).append(++idx).append(": ").append(event).append('\n');
-    }
-
-    public static String formatList(String prefix, List<String> list)
-    {
-        StringBuilder sb = new StringBuilder();
-        addList(sb, prefix, list);
-        return sb.toString();
-    }
-
-    public interface FailingConsumer<A>
-    {
-        void accept(A value) throws Exception;
-    }
-
-    public static class SingleBuilder<T> extends Common<SingleBuilder<T>>
-    {
-        private final accord.utilsfork.Gen<T> gen;
-
-        private SingleBuilder(accord.utilsfork.Gen<T> gen, Common<?> other) {
-            super(other);
-            this.gen = Objects.requireNonNull(gen);
-        }
-
-        public void check(FailingConsumer<T> fn)
-        {
-            if (timeout != null)
-            {
-                checkWithTimeout(() -> checkInternal(fn));
-                return;
-            }
-            checkInternal(fn);
-        }
-
-        private void checkInternal(FailingConsumer<T> fn)
-        {
-            accord.utilsfork.RandomSource random = new accord.utilsfork.DefaultRandom(seed);
-            for (int i = 0; i < examples; i++)
-            {
-                T value = null;
-                try
-                {
-                    checkInterrupted();
-                    fn.accept(value = gen.next(random));
-                }
-                catch (Throwable t)
-                {
-                    throw new PropertyError(propertyError(this, t, value), t);
-                }
-                if (pure)
-                {
-                    seed = random.nextLong();
-                    random.setSeed(seed);
-                }
-            }
-        }
-    }
-
-    public interface FailingBiConsumer<A, B>
-    {
-        void accept(A a, B b) throws Exception;
-    }
-
-    public static class DoubleBuilder<A, B> extends Common<DoubleBuilder<A, B>>
-    {
-        private final accord.utilsfork.Gen<A> aGen;
-        private final accord.utilsfork.Gen<B> bGen;
-
-        private DoubleBuilder(accord.utilsfork.Gen<A> aGen, accord.utilsfork.Gen<B> bGen, Common<?> other) {
-            super(other);
-            this.aGen = Objects.requireNonNull(aGen);
-            this.bGen = Objects.requireNonNull(bGen);
-        }
-
-        public void check(FailingBiConsumer<A, B> fn)
-        {
-            if (timeout != null)
-            {
-                checkWithTimeout(() -> checkInternal(fn));
-                return;
-            }
-            checkInternal(fn);
-        }
-
-        private void checkInternal(FailingBiConsumer<A, B> fn)
-        {
-            accord.utilsfork.RandomSource random = new accord.utilsfork.DefaultRandom(seed);
-            for (int i = 0; i < examples; i++)
-            {
-                A a = null;
-                B b = null;
-                try
-                {
-                    checkInterrupted();
-                    fn.accept(a = aGen.next(random), b = bGen.next(random));
-                }
-                catch (Throwable t)
-                {
-                    throw new PropertyError(propertyError(this, t, a, b), t);
-                }
-                if (pure)
-                {
-                    seed = random.nextLong();
-                    random.setSeed(seed);
-                }
-            }
-        }
-    }
-
-    public interface FailingTriConsumer<A, B, C>
-    {
-        void accept(A a, B b, C c) throws Exception;
-    }
-
-    public static class TrippleBuilder<A, B, C> extends Common<TrippleBuilder<A, B, C>>
-    {
-        private final accord.utilsfork.Gen<A> as;
-        private final accord.utilsfork.Gen<B> bs;
-        private final accord.utilsfork.Gen<C> cs;
-
-        public TrippleBuilder(accord.utilsfork.Gen<A> as, accord.utilsfork.Gen<B> bs, accord.utilsfork.Gen<C> cs, Common<?> other)
-        {
-            super(other);
-            this.as = as;
-            this.bs = bs;
-            this.cs = cs;
-        }
-
-        public void check(FailingTriConsumer<A, B, C> fn)
-        {
-            if (timeout != null)
-            {
-                checkWithTimeout(() -> checkInternal(fn));
-                return;
-            }
-            checkInternal(fn);
-        }
-
-        private void checkInternal(FailingTriConsumer<A, B, C> fn)
-        {
-            accord.utilsfork.RandomSource random = new accord.utilsfork.DefaultRandom(seed);
-            for (int i = 0; i < examples; i++)
-            {
-                A a = null;
-                B b = null;
-                C c = null;
-                try
-                {
-                    checkInterrupted();
-                    fn.accept(a = as.next(random), b = bs.next(random), c = cs.next(random));
-                }
-                catch (Throwable t)
-                {
-                    throw new PropertyError(propertyError(this, t, a, b, c), t);
-                }
-                if (pure)
-                {
-                    seed = random.nextLong();
-                    random.setSeed(seed);
-                }
-            }
-        }
-    }
-
-    private static void checkInterrupted() throws InterruptedException
-    {
-        if (Thread.currentThread().isInterrupted())
-            throw new InterruptedException();
-    }
-
-    public static class PropertyError extends AssertionError
-    {
-        public PropertyError(String message, Throwable cause)
-        {
-            super(message, cause);
-        }
-
-        public PropertyError(String message)
-        {
-            super(message);
-        }
-    }
-
-    public static ForBuilder qt()
-    {
-        return new ForBuilder();
-    }
-
-    public static StatefulBuilder stateful()
-    {
-        return new StatefulBuilder();
-    }
-
-    public static class StatefulBuilder extends Common<StatefulBuilder>
-    {
-        protected int steps = 1000;
-        @Nullable
-        protected Duration stepTimeout = null;
-
-        public StatefulBuilder()
-        {
-            examples = 500;
-        }
-
-        public StatefulBuilder withSteps(int steps)
-        {
-            this.steps = steps;
-            return this;
-        }
-
-        public StatefulBuilder withStepTimeout(Duration duration)
-        {
-            stepTimeout = duration;
-            return this;
-        }
-
-        @SuppressWarnings("rawtypes")
-        public <State, SystemUnderTest> void check(Commands<State, SystemUnderTest> commands)
-        {
-            accord.utilsfork.RandomSource rs = new DefaultRandom(seed);
-            for (int i = 0; i < examples; i++)
-            {
-                State state = null;
-                List<String> history = new ArrayList<>(steps);
-                LongArrayList historyTiming = stepTimeout == null ? null : new LongArrayList();
-                try
-                {
-                    checkInterrupted();
-
-                    state = commands.genInitialState().next(rs);
-                    SystemUnderTest sut = commands.createSut(state);
-
-                    try
-                    {
-                        for (int j = 0; j < steps; j++)
-                        {
-                            accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>> cmdGen = commands.commands(state);
-                            Command cmd = cmdGen.next(rs);
-                            for (int a = 0; cmd.checkPreconditions(state) != PreCheckResult.Ok && a < 42; a++)
-                            {
-                                if (a == 41)
-                                    throw new IllegalArgumentException("Unable to find next command");
-                                cmd = cmdGen.next(rs);
-                            }
-                            if (cmd instanceof MultistepCommand)
-                            {
-                                for (Command<State, SystemUnderTest, ?> sub : ((MultistepCommand<State, SystemUnderTest>) cmd))
-                                {
-                                    history.add(sub.detailed(state));
-                                    process(sub, state, sut, history.size(), historyTiming);
-                                }
-                            }
-                            else
-                            {
-                                history.add(cmd.detailed(state));
-                                process(cmd, state, sut, history.size(), historyTiming);
-                            }
-                        }
-                        commands.destroySut(sut, null);
-                        commands.destroyState(state, null);
-                        commands.onSuccess(state, sut, maybeRewriteHistory(history, historyTiming));
-                    }
-                    catch (Throwable t)
-                    {
-                        try
-                        {
-                            commands.destroySut(sut, t);
-                            commands.destroyState(state, t);
-                        }
-                        catch (Throwable t2)
-                        {
-                            t.addSuppressed(t2);
-                        }
-                        throw t;
-                    }
-                }
-                catch (Throwable t)
-                {
-
-                    throw new PropertyError(statefulPropertyError(this, t, state, maybeRewriteHistory(history, historyTiming)), t);
-                }
-                if (pure)
-                {
-                    seed = rs.nextLong();
-                    rs.setSeed(seed);
-                }
-            }
-        }
-
-        private static List<String> maybeRewriteHistory(List<String> history, @Nullable LongArrayList historyTiming)
-        {
-            if (historyTiming == null) return history;
-            List<String> newHistory = new ArrayList<>(history.size());
-            for (int i = 0; i < history.size(); i++)
-            {
-                String step = history.get(i);
-                long timeNanos = historyTiming.getLong(i);
-                newHistory.add(step + ";\tDuration " + Duration.ofNanos(timeNanos));
-            }
-            return newHistory;
-        }
-
-        private <State, SystemUnderTest> void process(Command cmd, State state, SystemUnderTest sut, int id, @Nullable LongArrayList stepTiming) throws Throwable
-        {
-            if (stepTimeout == null)
-            {
-                cmd.process(state, sut);
-                return;
-            }
-            long startNanos = System.nanoTime();
-            try
-            {
-                TimeoutUtils.runBlocking(stepTimeout, "Stateful Step " + id + ": " + cmd.detailed(state), () -> cmd.process(state, sut));
-            }
-            finally
-            {
-                stepTiming.add(System.nanoTime() - startNanos);
-            }
-        }
-    }
-
-    public enum PreCheckResult { Ok, Ignore }
-    public interface Command<State, SystemUnderTest, Result>
-    {
-        default PreCheckResult checkPreconditions(State state) {return PreCheckResult.Ok;}
-        Result apply(State state) throws Throwable;
-        Result run(SystemUnderTest sut) throws Throwable;
-        default void checkPostconditions(State state, Result expected,
-                                         SystemUnderTest sut, Result actual) throws Throwable {}
-        default String detailed(State state) {return this.toString();}
-        default void process(State state, SystemUnderTest sut) throws Throwable
-        {
-            checkPostconditions(state, apply(state),
-                                sut, run(sut));
-        }
-    }
-
-    public static class ForwardingCommand<State, SystemUnderTest, Result> implements Command<State, SystemUnderTest, Result>
-    {
-        private final Command<State, SystemUnderTest, Result> delegate;
-
-        public ForwardingCommand(Command<State, SystemUnderTest, Result> delegate)
-        {
-            this.delegate = delegate;
-        }
-
-        protected Command<State, SystemUnderTest, Result> delegate()
-        {
-            return delegate;
-        }
-
-        @Override
-        public PreCheckResult checkPreconditions(State state)
-        {
-            return delegate().checkPreconditions(state);
-        }
-
-        @Override
-        public Result apply(State state) throws Throwable
-        {
-            return delegate().apply(state);
-        }
-
-        @Override
-        public Result run(SystemUnderTest sut) throws Throwable
-        {
-            return delegate().run(sut);
-        }
-
-        @Override
-        public void checkPostconditions(State state, Result expected, SystemUnderTest sut, Result actual) throws Throwable
-        {
-            delegate().checkPostconditions(state, expected, sut, actual);
-        }
-
-        @Override
-        public String detailed(State state)
-        {
-            return delegate().detailed(state);
-        }
-
-        @Override
-        public void process(State state, SystemUnderTest sut) throws Throwable
-        {
-            // don't call delegate here else the process function calls the delegate and not this class
-            Command.super.process(state, sut);
-        }
-    }
-
-    public static <State, SystemUnderTest> MultistepCommand<State, SystemUnderTest> multistep(Command<State, SystemUnderTest, ?>... cmds)
-    {
-        return multistep(Arrays.asList(cmds));
-    }
-
-    public static <State, SystemUnderTest> MultistepCommand<State, SystemUnderTest> multistep(List<Command<State, SystemUnderTest, ?>> cmds)
-    {
-        List<Command<State, SystemUnderTest, ?>> result = new ArrayList<>(cmds.size());
-        for (Command<State, SystemUnderTest, ?> c : cmds)
-        {
-            if (c instanceof MultistepCommand) result.addAll(flatten((MultistepCommand<State, SystemUnderTest>) c));
-            else                               result.add(c);
-        }
-        return result::iterator;
-    }
-
-    private static <State, SystemUnderTest> Collection<? extends Command<State, SystemUnderTest, ?>> flatten(MultistepCommand<State, SystemUnderTest> mc)
-    {
-        List<Command<State, SystemUnderTest, ?>> result = new ArrayList<>();
-        for (Command<State, SystemUnderTest, ?> c : mc)
-        {
-            if (c instanceof MultistepCommand) result.addAll(flatten((MultistepCommand<State, SystemUnderTest>) c));
-            else                               result.add(c);
-        }
-        return result;
-    }
-
-    public interface MultistepCommand<State, SystemUnderTest> extends Command<State, SystemUnderTest, Object>, Iterable<Command<State, SystemUnderTest, ?>>
-    {
-        @Override
-        default PreCheckResult checkPreconditions(State state)
-        {
-            for (Command<State, SystemUnderTest, ?> cmd : this)
-            {
-                PreCheckResult result = cmd.checkPreconditions(state);
-                if (result != PreCheckResult.Ok) return result;
-            }
-            return PreCheckResult.Ok;
-        }
-
-        @Override
-        default Object apply(State state) throws Throwable
-        {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        default Object run(SystemUnderTest sut) throws Throwable
-        {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        default void checkPostconditions(State state, Object expected, SystemUnderTest sut, Object actual) throws Throwable
-        {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        default String detailed(State state)
-        {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        default void process(State state, SystemUnderTest sut) throws Throwable
-        {
-            throw new UnsupportedOperationException();
-        }
-    }
-
-    public static <State, SystemUnderTest, Result> Command<State, SystemUnderTest, Result> ignoreCommand()
-    {
-        return new Command<>()
-        {
-            @Override
-            public PreCheckResult checkPreconditions(State state)
-            {
-                return PreCheckResult.Ignore;
-            }
-
-            @Override
-            public Result apply(State state) throws Throwable
-            {
-                throw new UnsupportedOperationException();
-            }
-
-            @Override
-            public Result run(SystemUnderTest sut) throws Throwable
-            {
-                throw new UnsupportedOperationException();
-            }
-
-            @Override
-            public String detailed(State state)
-            {
-                throw new UnsupportedOperationException();
-            }
-        };
-    }
-
-    public interface UnitCommand<State, SystemUnderTest> extends Command<State, SystemUnderTest, Void>
-    {
-        void applyUnit(State state) throws Throwable;
-        void runUnit(SystemUnderTest sut) throws Throwable;
-
-        @Override
-        default Void apply(State state) throws Throwable
-        {
-            applyUnit(state);
-            return null;
-        }
-
-        @Override
-        default Void run(SystemUnderTest sut) throws Throwable
-        {
-            runUnit(sut);
-            return null;
-        }
-    }
-
-    public interface StateOnlyCommand<State> extends UnitCommand<State, Void>
-    {
-        @Override
-        default void runUnit(Void sut) throws Throwable {}
-    }
-
-    public static class SimpleCommand<State> implements StateOnlyCommand<State>
-    {
-        private final Function<State, String> name;
-        private final Consumer<State> fn;
-
-        public SimpleCommand(String name, Consumer<State> fn)
-        {
-            this.name = ignore -> name;
-            this.fn = fn;
-        }
-
-        public SimpleCommand(Function<State, String> name, Consumer<State> fn)
-        {
-            this.name = name;
-            this.fn = fn;
-        }
-
-        @Override
-        public String detailed(State state)
-        {
-            return name.apply(state);
-        }
-
-        @Override
-        public void applyUnit(State state)
-        {
-            fn.accept(state);
-        }
-    }
-
-    public interface Commands<State, SystemUnderTest>
-    {
-        accord.utilsfork.Gen<State> genInitialState() throws Throwable;
-        SystemUnderTest createSut(State state) throws Throwable;
-        default void onSuccess(State state, SystemUnderTest sut, List<String> history) throws Throwable {}
-        default void destroyState(State state, @Nullable Throwable cause) throws Throwable {}
-        default void destroySut(SystemUnderTest sut, @Nullable Throwable cause) throws Throwable {}
-        accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>> commands(State state) throws Throwable;
-    }
-
-    public static <State, SystemUnderTest> CommandsBuilder<State, SystemUnderTest> commands(Supplier<accord.utilsfork.Gen<State>> stateGen, Function<State, SystemUnderTest> sutFactory)
-    {
-        return new CommandsBuilder<>(stateGen, sutFactory);
-    }
-
-    public static <State> CommandsBuilder<State, Void> commands(Supplier<accord.utilsfork.Gen<State>> stateGen)
-    {
-        return new CommandsBuilder<>(stateGen, ignore -> null);
-    }
-
-    public interface StatefulSuccess<State, SystemUnderTest>
-    {
-        void apply(State state, SystemUnderTest sut, List<String> history) throws Throwable;
-    }
-
-    public static class CommandsBuilder<State, SystemUnderTest>
-    {
-        public interface Setup<State, SystemUnderTest>
-        {
-            Command<State, SystemUnderTest, ?> setup(accord.utilsfork.RandomSource rs, State state);
-        }
-        private final Supplier<accord.utilsfork.Gen<State>> stateGen;
-        private final Function<State, SystemUnderTest> sutFactory;
-        private final Map<Setup<State, SystemUnderTest>, Integer> knownWeights = new LinkedHashMap<>();
-        @Nullable
-        private Set<Setup<State, SystemUnderTest>> unknownWeights = null;
-        @Nullable
-        private Map<Predicate<State>, List<Setup<State, SystemUnderTest>>> conditionalCommands = null;
-        private accord.utilsfork.Gen.IntGen unknownWeightGen = accord.utilsfork.Gens.ints().between(1, 10);
-        @Nullable
-        private FailingConsumer<State> preCommands = null;
-        @Nullable
-        private FailingBiConsumer<State, Throwable> destroyState = null;
-        @Nullable
-        private FailingBiConsumer<SystemUnderTest, Throwable> destroySut = null;
-        @Nullable
-        private BiFunction<State, accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>>, accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>>> commandsTransformer = null;
-        private final List<StatefulSuccess<State, SystemUnderTest>> onSuccess = new ArrayList<>();
-
-        public CommandsBuilder(Supplier<accord.utilsfork.Gen<State>> stateGen, Function<State, SystemUnderTest> sutFactory)
-        {
-            this.stateGen = stateGen;
-            this.sutFactory = sutFactory;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> preCommands(FailingConsumer<State> preCommands)
-        {
-            this.preCommands = preCommands;
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> destroyState(FailingConsumer<State> destroyState)
-        {
-            return destroyState((success, failure) -> {
-                if (failure == null)
-                    destroyState.accept(success);
-            });
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> destroyState(FailingBiConsumer<State, Throwable> destroyState)
-        {
-            this.destroyState = destroyState;
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> destroySut(FailingConsumer<SystemUnderTest> destroySut)
-        {
-            return destroySut((success, failure) -> {
-                if (failure == null)
-                    destroySut.accept(success);
-            });
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> destroySut(FailingBiConsumer<SystemUnderTest, Throwable> destroySut)
-        {
-            this.destroySut = destroySut;
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> add(int weight, Command<State, SystemUnderTest, ?> cmd)
-        {
-            return add(weight, (i1, i2) -> cmd);
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> add(int weight, accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>> cmd)
-        {
-            return add(weight, (rs, state) -> cmd.next(rs));
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> add(int weight, Setup<State, SystemUnderTest> cmd)
-        {
-            knownWeights.put(cmd, weight);
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> add(Command<State, SystemUnderTest, ?> cmd)
-        {
-            return add((i1, i2) -> cmd);
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> add(accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>> cmd)
-        {
-            return add((rs, state) -> cmd.next(rs));
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> add(Setup<State, SystemUnderTest> cmd)
-        {
-            if (unknownWeights == null)
-                unknownWeights = new LinkedHashSet<>();
-            unknownWeights.add(cmd);
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> addIf(Predicate<State> predicate, accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>> cmd)
-        {
-            return addIf(predicate, (rs, state) -> cmd.next(rs));
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> addIf(Predicate<State> predicate, Command<State, SystemUnderTest, ?> cmd)
-        {
-            return addIf(predicate, (rs, state) -> cmd);
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> addIf(Predicate<State> predicate, Setup<State, SystemUnderTest> cmd)
-        {
-            if (conditionalCommands == null)
-                conditionalCommands = new LinkedHashMap<>();
-            conditionalCommands.computeIfAbsent(predicate, i -> new ArrayList<>()).add(cmd);
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> addAllIf(Predicate<State> predicate, Consumer<IfBuilder<State, SystemUnderTest>> sub)
-        {
-            sub.accept(new IfBuilder<>()
-            {
-                @Override
-                public IfBuilder<State, SystemUnderTest> add(Setup<State, SystemUnderTest> cmd)
-                {
-                    CommandsBuilder.this.addIf(predicate, cmd);
-                    return this;
-                }
-
-                @Override
-                public IfBuilder<State, SystemUnderTest> addIf(Predicate<State> nextPredicate, Setup<State, SystemUnderTest> cmd) {
-                    CommandsBuilder.this.addIf(predicate.and(nextPredicate), cmd);
-                    return this;
-                }
-            });
-            return this;
-        }
-
-        public interface IfBuilder<State, SystemUnderTest>
-        {
-            IfBuilder<State, SystemUnderTest> add(Setup<State, SystemUnderTest> cmd);
-            IfBuilder<State, SystemUnderTest> addIf(Predicate<State> predicate, Setup<State, SystemUnderTest> cmd);
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> unknownWeight(accord.utilsfork.Gen.IntGen unknownWeightGen)
-        {
-            this.unknownWeightGen = Objects.requireNonNull(unknownWeightGen);
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> commandsTransformer(BiFunction<State, accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>>, accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>>> commandsTransformer)
-        {
-            this.commandsTransformer = commandsTransformer;
-            return this;
-        }
-
-        public CommandsBuilder<State, SystemUnderTest> onSuccess(StatefulSuccess<State, SystemUnderTest> fn)
-        {
-            onSuccess.add(fn);
-            return this;
-        }
-
-        public Commands<State, SystemUnderTest> build()
-        {
-            accord.utilsfork.Gen<Setup<State, SystemUnderTest>> commandsGen;
-            if (unknownWeights == null && conditionalCommands == null)
-            {
-                commandsGen = accord.utilsfork.Gens.pick(new LinkedHashMap<>(knownWeights));
-            }
-            else
-            {
-                class DynamicWeightsGen implements accord.utilsfork.Gen<Setup<State, SystemUnderTest>>, accord.utilsfork.Gens.Reset
-                {
-                    LinkedHashMap<Setup<State, SystemUnderTest>, Integer> weights;
-                    LinkedHashMap<Setup<State, SystemUnderTest>, Integer> conditionalWeights;
-                    accord.utilsfork.Gen<Setup<State, SystemUnderTest>> nonConditional;
-                    @Override
-                    public Setup<State, SystemUnderTest> next(RandomSource rs)
-                    {
-                        if (weights == null)
-                        {
-                            // create random weights
-                            weights = new LinkedHashMap<>(knownWeights);
-                            if (unknownWeights != null)
-                            {
-                                for (Setup<State, SystemUnderTest> s : unknownWeights)
-                                    weights.put(s, unknownWeightGen.nextInt(rs));
-                            }
-                            nonConditional = accord.utilsfork.Gens.pick(weights);
-                            if (conditionalCommands != null)
-                            {
-                                conditionalWeights = new LinkedHashMap<>();
-                                for (List<Setup<State, SystemUnderTest>> commands : conditionalCommands.values())
-                                {
-                                    for (Setup<State, SystemUnderTest> c : commands)
-                                        conditionalWeights.put(c, unknownWeightGen.nextInt(rs));
-                                }
-                            }
-                        }
-                        if (conditionalWeights == null) return nonConditional.next(rs);
-                        return (r, s) -> {
-                            // need to figure out what conditions apply...
-                            LinkedHashMap<Setup<State, SystemUnderTest>, Integer> clone = new LinkedHashMap<>(weights);
-                            for (Map.Entry<Predicate<State>, List<Setup<State, SystemUnderTest>>> e : conditionalCommands.entrySet())
-                            {
-                                if (e.getKey().test(s))
-                                    e.getValue().forEach(c -> clone.put(c, conditionalWeights.get(c)));
-                            }
-                            Setup<State, SystemUnderTest> select = accord.utilsfork.Gens.pick(clone).next(r);
-                            return select.setup(r, s);
-                        };
-                    }
-
-                    @Override
-                    public void reset()
-                    {
-                        weights = null;
-                        nonConditional = null;
-                        conditionalWeights = null;
-                    }
-                }
-                commandsGen = new DynamicWeightsGen();
-            }
-            return new Commands<>()
-            {
-                @Override
-                public accord.utilsfork.Gen<State> genInitialState() throws Throwable
-                {
-                    return stateGen.get();
-                }
-
-                @Override
-                public SystemUnderTest createSut(State state) throws Throwable
-                {
-                    return sutFactory.apply(state);
-                }
-
-                @Override
-                public accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>> commands(State state) throws Throwable
-                {
-                    if (preCommands != null)
-                        preCommands.accept(state);
-                    accord.utilsfork.Gen<Command<State, SystemUnderTest, ?>> map = commandsGen.map((rs, setup) -> setup.setup(rs, state));
-                    return commandsTransformer == null ? map : commandsTransformer.apply(state, map);
-                }
-
-                @Override
-                public void destroyState(State state, @Nullable Throwable cause) throws Throwable
-                {
-                    accord.utilsfork.Gens.Reset.tryReset(commandsGen);
-                    if (destroyState != null)
-                        destroyState.accept(state, cause);
-                }
-
-                @Override
-                public void destroySut(SystemUnderTest sut, @Nullable Throwable cause) throws Throwable
-                {
-                    if (destroySut != null)
-                        destroySut.accept(sut, cause);
-                }
-
-                @Override
-                public void onSuccess(State state, SystemUnderTest sut, List<String> history) throws Throwable
-                {
-                    for (var fn : onSuccess)
-                        fn.apply(state, sut, history);
-                }
-            };
-        }
-
-        public interface FailingConsumer<T>
-        {
-            void accept(T value) throws Throwable;
-        }
-
-        public interface FailingBiConsumer<A, B>
-        {
-            void accept(A a, B b) throws Throwable;
-        }
-    }
-}
diff --git a/test/unit/accord/utilsfork/RandomSource.java b/test/unit/accord/utilsfork/RandomSource.java
deleted file mode 100644
index b3e3708709..0000000000
--- a/test/unit/accord/utilsfork/RandomSource.java
+++ /dev/null
@@ -1,429 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork;
-
-import java.util.ArrayList;
-import java.util.Comparator;
-import java.util.EnumSet;
-import java.util.LinkedHashSet;
-import java.util.List;
-import java.util.Random;
-import java.util.Set;
-import java.util.SortedSet;
-import java.util.function.BooleanSupplier;
-import java.util.function.IntSupplier;
-import java.util.function.LongSupplier;
-import java.util.function.Supplier;
-
-import com.google.common.collect.Iterables;
-
-import accord.utilsfork.random.Picker;
-
-// TODO (expected): merge with C* RandomSource
-public interface RandomSource
-{
-    static RandomSource wrap(Random random)
-    {
-        return new accord.utilsfork.WrappedRandomSource(random);
-    }
-    //TODO (maintaince): once the rebase is over remove this...
-    static RandomSource wrap(accord.utils.RandomSource rs)
-    {
-        return new WrappedRandomSource(rs.asJdkRandom());
-    }
-
-    void nextBytes(byte[] bytes);
-
-    boolean nextBoolean();
-    default BooleanSupplier uniformBools() { return this::nextBoolean; }
-    default BooleanSupplier biasedUniformBools(float chance) { return () -> decide(chance); }
-    default Supplier<BooleanSupplier> biasedUniformBoolsSupplier(float minChance)
-    {
-        return () -> {
-            float chance = minChance + (1 - minChance)*nextFloat();
-            return () -> decide(chance);
-        };
-    }
-
-    /**
-     * Returns true with a probability of {@code chance}. This is logically the same as
-     * <pre>{@code nextFloat() < chance}</pre>
-     *
-     * @param chance cumulative probability in range [0..1]
-     */
-    default boolean decide(float chance)
-    {
-        return nextFloat() < chance;
-    }
-
-    /**
-     * Returns true with a probability of {@code chance}. This is logically the same as
-     * <pre>{@code nextDouble() < chance}</pre>
-     *
-     * @param chance cumulative probability in range [0..1]
-     */
-    default boolean decide(double chance)
-    {
-        return nextDouble() < chance;
-    }
-
-    int nextInt();
-    default int nextInt(int maxExclusive) { return nextInt(0, maxExclusive); }
-    default int nextInt(int minInclusive, int maxExclusive)
-    {
-        // this is diff behavior than ThreadLocalRandom, which returns nextInt
-        if (minInclusive >= maxExclusive)
-            throw new IllegalArgumentException(String.format("Min (%s) should be less than max (%d).", minInclusive, maxExclusive));
-
-        int result = nextInt();
-        int delta = maxExclusive - minInclusive;
-        int mask = delta - 1;
-        if ((delta & mask) == 0) // power of two
-            result = (result & mask) + minInclusive;
-        else if (delta > 0)
-        {
-            // reject over-represented candidates
-            for (int u = result >>> 1;                  // ensure nonnegative
-                 u + mask - (result = u % delta) < 0;   // rejection check
-                 u = nextInt() >>> 1)                   // retry
-                ;
-            result += minInclusive;
-        }
-        else
-        {
-            // range not representable as int
-            while (result < minInclusive || result >= maxExclusive)
-                result = nextInt();
-        }
-        return result;
-    }
-    default int nextBiasedInt(int minInclusive, int median, int maxExclusive)
-    {
-        checkBiasedUniform(minInclusive, median, maxExclusive);
-
-        int range = Math.max(maxExclusive - median, median - minInclusive) * 2;
-        int next = nextInt(range) - range/2;
-        next += median;
-        return next >= median ? next <  maxExclusive ? next : nextInt(median, maxExclusive)
-                              : next >= minInclusive ? next : minInclusive == median ? median : nextInt(minInclusive, median);
-    }
-
-    default IntSupplier uniformInts(int minInclusive, int maxExclusive) { return () -> nextInt(minInclusive, maxExclusive); }
-    default IntSupplier biasedUniformInts(int minInclusive, int median, int maxExclusive)
-    {
-        checkBiasedUniform(minInclusive, median, maxExclusive);
-        return () -> nextBiasedInt(minInclusive, median, maxExclusive);
-    }
-    default Supplier<IntSupplier> biasedUniformIntsSupplier(int absoluteMinInclusive, int absoluteMaxExclusive, int minMedian, int maxMedian, int minRange, int maxRange)
-    {
-        return biasedUniformIntsSupplier(absoluteMinInclusive, absoluteMaxExclusive, minMedian, (minMedian+maxMedian)/2, maxMedian, minRange, (minRange+maxRange)/2, maxRange);
-    }
-    default Supplier<IntSupplier> biasedUniformIntsSupplier(int absoluteMinInclusive, int absoluteMaxExclusive, int minMedian, int medianMedian, int maxMedian, int minRange, int medianRange, int maxRange)
-    {
-        checkBiasedUniform(minMedian, medianMedian, maxMedian);
-        checkBiasedUniform(minRange, medianRange, maxRange);
-        if (minMedian < absoluteMinInclusive)
-            throw new IllegalArgumentException(String.format("absoluteMin (%s) should be less than or equal to minMedian (%s)", absoluteMinInclusive, minMedian));
-        if (maxMedian > absoluteMaxExclusive)
-            throw new IllegalArgumentException(String.format("absoluteMax (%s) should be greater than or equal to maxMedian (%s)", absoluteMaxExclusive, maxMedian));
-        if (minRange < 1)
-            throw new IllegalArgumentException(String.format("minRange (%s) should be greater than or equal to 1", minRange));
-        return () -> {
-            int median = nextBiasedInt(minMedian, medianMedian, maxMedian);
-            int minInclusive = Math.max(absoluteMinInclusive, median - nextBiasedInt(minRange, medianRange, maxRange)/2);
-            int maxExclusive = Math.min(absoluteMaxExclusive, median + (nextBiasedInt(minRange, medianRange, maxRange)+1)/2);
-            return biasedUniformInts(minInclusive, median, maxExclusive);
-        };
-    }
-
-    long nextLong();
-    default long nextLong(long maxExclusive) { return nextLong(0, maxExclusive); }
-    default long nextLong(long minInclusive, long maxExclusive)
-    {
-        // this is diff behavior than ThreadLocalRandom, which returns nextLong
-        if (minInclusive >= maxExclusive)
-            throw new IllegalArgumentException(String.format("Min (%s) should be less than max (%d).", minInclusive, maxExclusive));
-
-        long result = nextLong();
-        long delta = maxExclusive - minInclusive;
-        long mask = delta - 1;
-        if ((delta & mask) == 0L) // power of two
-            result = (result & mask) + minInclusive;
-        else if (delta > 0L)
-        {
-            // reject over-represented candidates
-            for (long u = result >>> 1;                 // ensure nonnegative
-                 u + mask - (result = u % delta) < 0L;  // rejection check
-                 u = nextLong() >>> 1)                  // retry
-                ;
-            result += minInclusive;
-        }
-        else
-        {
-            // range not representable as long
-            while (result < minInclusive || result >= maxExclusive)
-                result = nextLong();
-        }
-        return result;
-    }
-    default long nextBiasedLong(long minInclusive, long median, long maxExclusive)
-    {
-        checkBiasedUniform(minInclusive, median, maxExclusive);
-
-        long range = Math.max(maxExclusive - median, median - minInclusive) * 2;
-        long next = nextLong(range) - range/2;
-        next += median;
-        return next >= median ? next <  maxExclusive ? next : nextLong(median, maxExclusive)
-                              : next >= minInclusive ? next : minInclusive == median ? median : nextLong(minInclusive, median);
-    }
-
-    default LongSupplier uniformLongs(long minInclusive, long maxExclusive) { return () -> nextLong(minInclusive, maxExclusive); }
-    default LongSupplier biasedUniformLongs(long minInclusive, long median, long maxExclusive)
-    {
-        checkBiasedUniform(minInclusive, median, maxExclusive);
-        return () -> nextBiasedLong(minInclusive, median, maxExclusive);
-    }
-    default Supplier<LongSupplier> biasedUniformLongsSupplier(long absoluteMinInclusive, long absoluteMaxExclusive, long minMedian, long maxMedian, long minRange, long maxRange)
-    {
-        return biasedUniformLongsSupplier(absoluteMinInclusive, absoluteMaxExclusive, minMedian, (minMedian+maxMedian)/2, maxRange, minRange, (minRange+maxRange)/2, maxRange);
-    }
-    default Supplier<LongSupplier> biasedUniformLongsSupplier(long absoluteMinInclusive, long absoluteMaxExclusive, long minMedian, long medianMedian, long maxMedian, long minRange, long medianRange, long maxRange)
-    {
-        checkBiasedUniform(minMedian, medianMedian, maxMedian);
-        checkBiasedUniform(minRange, medianRange, maxRange);
-        if (minMedian < absoluteMinInclusive)
-            throw new IllegalArgumentException(String.format("absoluteMin (%s) should be less than or equal to minMedian (%s)", absoluteMinInclusive, minMedian));
-        if (maxMedian > absoluteMaxExclusive)
-            throw new IllegalArgumentException(String.format("absoluteMax (%s) should be greater than or equal to maxMedian (%s)", absoluteMaxExclusive, maxMedian));
-        if (minRange < 1)
-            throw new IllegalArgumentException(String.format("minRange (%s) should be greater than or equal to 1", minRange));
-        return () -> {
-            long median = nextBiasedLong(minMedian, medianMedian, maxMedian);
-            long minInclusive = Math.max(absoluteMinInclusive, median - nextBiasedLong(minRange, medianRange, maxRange)/2);
-            long maxExclusive = Math.min(absoluteMaxExclusive, median + (1+nextBiasedLong(minRange, medianRange, maxRange))/2);
-            return biasedUniformLongs(minInclusive, median, maxExclusive);
-        };
-    }
-
-    static void checkBiasedUniform(long minInclusive, long median, long maxExclusive)
-    {
-        if (minInclusive > median)
-            throw new IllegalArgumentException(String.format("Min (%s) should be equal to or less than median (%d).", minInclusive, median));
-        if (median >= maxExclusive)
-            throw new IllegalArgumentException(String.format("Median (%s) should be less than max (%d).", median, maxExclusive));
-    }
-
-    float nextFloat();
-
-    double nextDouble();
-    default double nextDouble(double maxExclusive) { return nextDouble(0, maxExclusive); }
-    default double nextDouble(double minInclusive, double maxExclusive)
-    {
-        if (minInclusive >= maxExclusive)
-            throw new IllegalArgumentException(String.format("Min (%s) should be less than max (%d).", minInclusive, maxExclusive));
-
-        double result = nextDouble();
-        result = result * (maxExclusive - minInclusive) + minInclusive;
-        if (result >= maxExclusive) // correct for rounding
-            result = Double.longBitsToDouble(Double.doubleToLongBits(maxExclusive) - 1);
-        return result;
-    }
-
-    double nextGaussian();
-
-    default int pickInt(int first, int second, int... rest)
-    {
-        int offset = nextInt(0, rest.length + 2);
-        switch (offset)
-        {
-            case 0:  return first;
-            case 1:  return second;
-            default: return rest[offset - 2];
-        }
-    }
-
-    default int pickInt(int[] array)
-    {
-        return pickInt(array, 0, array.length);
-    }
-
-    default int pickInt(int[] array, int offset, int length)
-    {
-        accord.utilsfork.Invariants.checkIndexInBounds(array.length, offset, length);
-        if (length == 1)
-            return array[offset];
-        return array[nextInt(offset, offset + length)];
-    }
-
-    default long pickLong(long first, long second, long... rest)
-    {
-        int offset = nextInt(0, rest.length + 2);
-        switch (offset)
-        {
-            case 0:  return first;
-            case 1:  return second;
-            default: return rest[offset - 2];
-        }
-    }
-
-    default long pickLong(long[] array)
-    {
-        return pickLong(array, 0, array.length);
-    }
-
-    default long pickLong(long[] array, int offset, int length)
-    {
-        accord.utilsfork.Invariants.checkIndexInBounds(array.length, offset, length);
-        if (length == 1)
-            return array[offset];
-        return array[nextInt(offset, offset + length)];
-    }
-
-    default <T> T pickOrderedSet(SortedSet<T> set)
-    {
-        int offset = nextInt(0, set.size());
-        return Iterables.get(set, offset);
-    }
-
-    default <T> T pickOrderedSet(LinkedHashSet<T> set)
-    {
-        int offset = nextInt(0, set.size());
-        return Iterables.get(set, offset);
-    }
-
-    default <T extends Enum<T>> T pickOrderedSet(EnumSet<T> set)
-    {
-        int offset = nextInt(0, set.size());
-        return Iterables.get(set, offset);
-    }
-
-    default <T extends Comparable<? super T>> T pickUnorderedSet(Set<T> set)
-    {
-        if (set instanceof SortedSet)
-            return pickOrderedSet((SortedSet<T>) set);
-        List<T> values = new ArrayList<>(set);
-        // Non-ordered sets may have different iteration order on different environments, which would make a seed produce different histories!
-        // To avoid such a problem, make sure to apply a deterministic function (sort).
-        values.sort(Comparator.naturalOrder());
-        return pick(values);
-    }
-
-    default <T> T pick(T first, T second, T... rest)
-    {
-        int offset = nextInt(0, rest.length + 2);
-        switch (offset)
-        {
-            case 0:  return first;
-            case 1:  return second;
-            default: return rest[offset - 2];
-        }
-    }
-
-    default <T> T pick(T[] array)
-    {
-        return array[nextInt(array.length)];
-    }
-
-    default <T> T pick(List<T> values)
-    {
-        return pick(values, 0, values.size());
-    }
-
-    default <T> T pick(List<T> values, int offset, int length)
-    {
-        Invariants.checkIndexInBounds(values.size(), offset, length);
-        if (length == 1)
-            return values.get(offset);
-        return values.get(nextInt(offset, offset + length));
-    }
-
-    default <T> Supplier<T> randomWeightedPicker(T[] objects) { return Picker.WeightedObjectPicker.randomWeighted(this, objects); }
-    default <T> Supplier<T> randomWeightedPicker(T[] objects, float[] bias) { return Picker.WeightedObjectPicker.randomWeighted(this, objects, bias); }
-    default <T> Supplier<T> weightedPicker(T[] objects, float[] proportionalWeights) { return Picker.WeightedObjectPicker.weighted(this, objects, proportionalWeights); }
-
-    void setSeed(long seed);
-    RandomSource fork();
-
-    default long reset()
-    {
-        long seed = nextLong();
-        setSeed(seed);
-        return seed;
-    }
-
-    default Random asJdkRandom()
-    {
-        return new Random(nextLong())
-        {
-            @Override
-            public void setSeed(long seed)
-            {
-                RandomSource.this.setSeed(seed);
-            }
-
-            @Override
-            public void nextBytes(byte[] bytes)
-            {
-                RandomSource.this.nextBytes(bytes);
-            }
-
-            @Override
-            public int nextInt()
-            {
-                return RandomSource.this.nextInt();
-            }
-
-            @Override
-            public int nextInt(int bound)
-            {
-                return RandomSource.this.nextInt(bound);
-            }
-
-            @Override
-            public long nextLong()
-            {
-                return RandomSource.this.nextLong();
-            }
-
-            @Override
-            public boolean nextBoolean()
-            {
-                return RandomSource.this.nextBoolean();
-            }
-
-            @Override
-            public float nextFloat()
-            {
-                return RandomSource.this.nextFloat();
-            }
-
-            @Override
-            public double nextDouble()
-            {
-                return RandomSource.this.nextDouble();
-            }
-
-            @Override
-            public double nextGaussian()
-            {
-                return RandomSource.this.nextGaussian();
-            }
-        };
-    }
-}
diff --git a/test/unit/accord/utilsfork/SeedProvider.java b/test/unit/accord/utilsfork/SeedProvider.java
deleted file mode 100644
index ded732f42f..0000000000
--- a/test/unit/accord/utilsfork/SeedProvider.java
+++ /dev/null
@@ -1,51 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork;
-
-import java.util.concurrent.atomic.AtomicLong;
-
-/**
- * Utility class for creating seeds.  This class mostly matches the semantics of {@link java.util.Random} but makes the logic work
- * for any random source.  This class should be used in replacement of most seed methods, and should always replace {@link java.util.concurrent.ThreadLocalRandom}
- * as that randomness will have a bias twords the same seed after a restart (if you rerun randomized tests by restarting
- * the JVM you will run with the same seed over and over again).
- */
-public class SeedProvider
-{
-    public static final SeedProvider instance = new SeedProvider();
-    private final AtomicLong seedUniquifier = new AtomicLong(8682522807148012L);
-
-    private long seedUniquifier()
-    {
-        // L'Ecuyer, "Tables of Linear Congruential Generators of
-        // Different Sizes and Good Lattice Structure", 1999
-        for (; ; )
-        {
-            long current = seedUniquifier.get();
-            long next = current * 1181783497276652981L;
-            if (seedUniquifier.compareAndSet(current, next))
-                return next;
-        }
-    }
-
-    public long nextSeed()
-    {
-        return seedUniquifier() ^ System.nanoTime();
-    }
-}
diff --git a/test/unit/accord/utilsfork/async/TimeoutUtils.java b/test/unit/accord/utilsfork/async/TimeoutUtils.java
deleted file mode 100644
index 2008918ac1..0000000000
--- a/test/unit/accord/utilsfork/async/TimeoutUtils.java
+++ /dev/null
@@ -1,70 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork.async;
-
-import java.time.Duration;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-
-import org.apache.cassandra.utils.concurrent.AsyncPromise;
-
-public class TimeoutUtils
-{
-    public interface FailingRunnable
-    {
-        void run() throws Throwable;
-    }
-
-    public static void runBlocking(Duration timeout, String threadName, FailingRunnable fn) throws ExecutionException, InterruptedException, TimeoutException
-    {
-        // MAINTENANCE: Once the accord branch merges to trunk this can be dropped and will be AsyncChain again, but since this is forked into C* (that doesn't have AsyncChain) need to use Futures
-//        AsyncResult.Settable<?> promise = AsyncResults.settable();
-        AsyncPromise<?> promise = new AsyncPromise<>();
-        Thread t = new Thread(() -> {
-            try
-            {
-                fn.run();
-                promise.setSuccess(null);
-            }
-            catch (Throwable e)
-            {
-                promise.setFailure(e);
-            }
-        });
-        t.setName(threadName);
-        t.setDaemon(true);
-        t.start();
-        try
-        {
-//            AsyncChains.getBlocking(promise, timeout.toNanos(), TimeUnit.NANOSECONDS);
-            promise.get(timeout.toNanos(), TimeUnit.NANOSECONDS);
-        }
-        catch (InterruptedException e)
-        {
-            t.interrupt();
-            throw e;
-        }
-        catch (TimeoutException e)
-        {
-            t.interrupt();
-            throw e;
-        }
-    }
-}
diff --git a/test/unit/accord/utilsfork/random/Picker.java b/test/unit/accord/utilsfork/random/Picker.java
deleted file mode 100644
index f9584a5f98..0000000000
--- a/test/unit/accord/utilsfork/random/Picker.java
+++ /dev/null
@@ -1,118 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package accord.utilsfork.random;
-
-import java.util.Arrays;
-import java.util.function.Supplier;
-
-import accord.utils.Invariants;
-import accord.utilsfork.RandomSource;
-
-public class Picker
-{
-    public static float[] randomWeights(RandomSource random, int length)
-    {
-        float[] weights = new float[length - 1];
-        float sum = 0;
-        for (int i = 0 ; i < weights.length ; ++i)
-            weights[i] = sum += random.nextFloat();
-        sum += random.nextFloat();
-        for (int i = 0 ; i < weights.length ; ++i)
-            weights[i] /= sum;
-        return weights;
-    }
-
-    static abstract class Weighted
-    {
-        final RandomSource random;
-        final float[] weights;
-
-        public Weighted(RandomSource random, float[] weights)
-        {
-            this.random = random;
-            this.weights = weights;
-        }
-
-
-        static float[] randomWeights(RandomSource random, float[] bias)
-        {
-            float[] weights = new float[bias.length - 1];
-            float sum = 0;
-            for (int i = 0 ; i < weights.length ; ++i)
-                weights[i] = sum += random.nextFloat() * bias[i];
-            sum += random.nextFloat() * bias[weights.length];
-            for (int i = 0 ; i < weights.length ; ++i)
-                weights[i] /= sum;
-            return weights;
-        }
-
-        static float[] normaliseWeights(float[] input)
-        {
-            float[] output = new float[input.length - 1];
-            float sum = 0;
-            for (int i = 0 ; i < output.length ; ++i)
-                output[i] = sum += input[i];
-            sum += input[output.length];
-            for (int i = 0 ; i < output.length ; ++i)
-                output[i] /= sum;
-            return output;
-        }
-
-        int pickIndex()
-        {
-            int i = Arrays.binarySearch(weights, random.nextFloat());
-            if (i < 0) i = -1 - i;
-            return i;
-        }
-    }
-
-    public static class WeightedObjectPicker<T> extends Weighted implements Supplier<T>
-    {
-        final T[] values;
-
-        private WeightedObjectPicker(RandomSource random, T[] values, float[] weights)
-        {
-            super(random, weights);
-            this.values = values;
-        }
-
-        @Override
-        public T get()
-        {
-            return values[pickIndex()];
-        }
-
-        public static <T> WeightedObjectPicker<T> randomWeighted(RandomSource random, T[] values)
-        {
-            return new WeightedObjectPicker<>(random, values, Picker.randomWeights(random, values.length));
-        }
-
-        public static <T> WeightedObjectPicker<T> randomWeighted(RandomSource random, T[] values, float[] bias)
-        {
-            Invariants.checkArgument(values.length == bias.length);
-            return new WeightedObjectPicker<>(random, values, randomWeights(random, bias));
-        }
-
-        public static <T> WeightedObjectPicker<T> weighted(RandomSource random, T[] values, float[] proportionalWeights)
-        {
-            Invariants.checkArgument(values.length == proportionalWeights.length);
-            return new WeightedObjectPicker<>(random, values, normaliseWeights(proportionalWeights));
-        }
-    }
-}
diff --git a/test/unit/org/apache/cassandra/concurrent/SimulatedExecutorFactory.java b/test/unit/org/apache/cassandra/concurrent/SimulatedExecutorFactory.java
index 839488875c..c7a03dc79c 100644
--- a/test/unit/org/apache/cassandra/concurrent/SimulatedExecutorFactory.java
+++ b/test/unit/org/apache/cassandra/concurrent/SimulatedExecutorFactory.java
@@ -39,8 +39,8 @@ import java.util.function.LongSupplier;
 
 import javax.annotation.Nullable;
 
-import accord.utilsfork.Gens;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gens;
+import accord.utils.RandomSource;
 import org.apache.cassandra.utils.Clock;
 import org.apache.cassandra.utils.Generators;
 import org.apache.cassandra.utils.concurrent.Future;
diff --git a/test/unit/org/apache/cassandra/config/DatabaseDescriptorRefTest.java b/test/unit/org/apache/cassandra/config/DatabaseDescriptorRefTest.java
index 697214f76a..058871776c 100644
--- a/test/unit/org/apache/cassandra/config/DatabaseDescriptorRefTest.java
+++ b/test/unit/org/apache/cassandra/config/DatabaseDescriptorRefTest.java
@@ -79,6 +79,7 @@ public class DatabaseDescriptorRefTest
     "org.apache.cassandra.auth.IRoleManager",
     "org.apache.cassandra.config.AccordSpec",
     "org.apache.cassandra.config.AccordSpec$JournalSpec",
+    "org.apache.cassandra.config.AccordSpec$MinEpochRetrySpec",
     "org.apache.cassandra.config.AccordSpec$TransactionalRangeMigration",
     "org.apache.cassandra.config.CassandraRelevantProperties",
     "org.apache.cassandra.config.CassandraRelevantProperties$PropertyConverter",
diff --git a/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnCqlConstraintValidationTest.java b/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnCqlConstraintValidationTest.java
index 4c9ec9fdc1..857ec85f40 100644
--- a/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnCqlConstraintValidationTest.java
+++ b/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnCqlConstraintValidationTest.java
@@ -33,7 +33,7 @@ import org.apache.cassandra.utils.Generators;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 import static org.quicktheories.generators.SourceDSL.doubles;
 import static org.quicktheories.generators.SourceDSL.integers;
 
diff --git a/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnOctetLengthConstraintValidationTest.java b/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnOctetLengthConstraintValidationTest.java
index 9d0816e644..6f9260f022 100644
--- a/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnOctetLengthConstraintValidationTest.java
+++ b/test/unit/org/apache/cassandra/constraints/CreateTableWithColumnOctetLengthConstraintValidationTest.java
@@ -29,7 +29,7 @@ import org.junit.runners.Parameterized;
 import org.apache.cassandra.exceptions.InvalidRequestException;
 import org.apache.cassandra.utils.Generators;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 import static org.quicktheories.generators.SourceDSL.integers;
diff --git a/test/unit/org/apache/cassandra/cql3/CQLTester.java b/test/unit/org/apache/cassandra/cql3/CQLTester.java
index c47b244d05..c9e0ced979 100644
--- a/test/unit/org/apache/cassandra/cql3/CQLTester.java
+++ b/test/unit/org/apache/cassandra/cql3/CQLTester.java
@@ -67,8 +67,6 @@ import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterables;
 
-import org.apache.cassandra.db.marshal.ByteBufferAccessor;
-import org.apache.cassandra.db.virtual.SystemViewsKeyspace;
 import org.assertj.core.api.Assertions;
 import org.awaitility.Awaitility;
 import org.apache.commons.lang3.ArrayUtils;
@@ -85,10 +83,10 @@ import org.junit.runner.Description;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import accord.utilsfork.DefaultRandom;
-import accord.utilsfork.Gen;
-import accord.utilsfork.Property;
-import accord.utilsfork.RandomSource;
+import accord.utils.DefaultRandom;
+import accord.utils.Gen;
+import accord.utils.Property;
+import accord.utils.RandomSource;
 import com.codahale.metrics.Gauge;
 import com.datastax.driver.core.CloseFuture;
 import com.datastax.driver.core.Cluster;
@@ -131,6 +129,7 @@ import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.db.SystemKeyspace;
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.BooleanType;
+import org.apache.cassandra.db.marshal.ByteBufferAccessor;
 import org.apache.cassandra.db.marshal.ByteType;
 import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.db.marshal.CollectionType;
@@ -152,6 +151,7 @@ import org.apache.cassandra.db.marshal.TupleType;
 import org.apache.cassandra.db.marshal.UTF8Type;
 import org.apache.cassandra.db.marshal.UUIDType;
 import org.apache.cassandra.db.marshal.VectorType;
+import org.apache.cassandra.db.virtual.SystemViewsKeyspace;
 import org.apache.cassandra.db.virtual.VirtualKeyspace;
 import org.apache.cassandra.db.virtual.VirtualKeyspaceRegistry;
 import org.apache.cassandra.db.virtual.VirtualSchemaKeyspace;
@@ -191,13 +191,17 @@ import org.apache.cassandra.transport.SimpleClient;
 import org.apache.cassandra.transport.TlsTestUtils;
 import org.apache.cassandra.transport.messages.ResultMessage;
 import org.apache.cassandra.utils.ByteBufferUtil;
+import org.apache.cassandra.utils.CassandraGenerators;
 import org.apache.cassandra.utils.ConfigGenBuilder;
 import org.apache.cassandra.utils.FBUtilities;
+import org.apache.cassandra.utils.Generators;
 import org.apache.cassandra.utils.JMXServerUtils;
 import org.apache.cassandra.utils.LazyToString;
 import org.apache.cassandra.utils.Pair;
 import org.apache.cassandra.utils.TimeUUID;
 
+import static org.apache.cassandra.utils.CassandraGenerators.regularKeyspace;
+import static org.apache.cassandra.utils.CassandraGenerators.regularTable;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
@@ -302,6 +306,7 @@ public abstract class CQLTester
 
     private List<String> keyspaces = new ArrayList<>();
     private List<String> tables = new ArrayList<>();
+    private List<String> indexes = new ArrayList<>();
     private List<String> views = new ArrayList<>();
     private List<String> types = new ArrayList<>();
     private List<String> functions = new ArrayList<>();
@@ -385,6 +390,7 @@ public abstract class CQLTester
     public static void prepareServer()
     {
         ServerTestUtils.prepareServer();
+        AccordStateCache.validateLoadOnEvict(true);
     }
 
     public static void cleanup()
@@ -442,7 +448,6 @@ public abstract class CQLTester
 
         // Once per-JVM is enough
         prepareServer();
-        AccordStateCache.validateLoadOnEvict(true);
     }
 
     protected static void prePrepareServer()
@@ -508,6 +513,7 @@ public abstract class CQLTester
 
         keyspaces = null;
         tables = null;
+        indexes = null;
         views = null;
         types = null;
         functions = null;
@@ -525,6 +531,27 @@ public abstract class CQLTester
         VirtualKeyspaceRegistry.instance.register(SystemViewsKeyspace.instance);
     }
 
+    protected void clearSchema()
+    {
+        ServerTestUtils.resetCMS();
+        keyspaces.clear();
+        tables.clear();
+        indexes.clear();;
+        views.clear();
+        types.clear();
+        functions.clear();
+        aggregates.clear();
+    }
+
+    protected void clearState()
+    {
+        clearSchema();
+        usePrepared = USE_PREPARED_VALUES;
+        reusePrepared = REUSE_PREPARED;
+
+        seqNumber.set(0);
+    }
+
     protected void resetSchema() throws Throwable
     {
         for (TableMetadata table : SchemaKeyspace.metadata().tables)
@@ -2224,7 +2251,10 @@ public abstract class CQLTester
                 if (!((cellValidator == null && actualValue == null) || (cellValidator != null && cellValidator.equals(actualValue))))
                 {
                     Object actualValueDecoded = actualValue == null ? null : column.type.getSerializer().deserialize(actualValue);
-                    if (!Objects.equal(expected != null ? expected[j] : null, actualValueDecoded))
+                    Object expectedValueDecoded = expected != null ? expected[j] : null;
+                    if (expectedValueDecoded instanceof ByteBuffer && !(actualValueDecoded instanceof ByteBuffer))
+                        expectedValueDecoded = column.type.getSerializer().deserialize(((ByteBuffer) expectedValueDecoded).duplicate());
+                    if (!Objects.equal(expectedValueDecoded, actualValueDecoded))
                     {
                         if (isEmptyContainerNull(column.type, cellValidator != null ? cellValidator.expected() : null, actualValue))
                             continue;
@@ -2654,6 +2684,116 @@ public abstract class CQLTester
                                   values);
     }
 
+    protected CassandraGenerators.KeyspaceMetadataBuilder createKeyspaceMetadataBuilder()
+    {
+        return regularKeyspace()
+               .withName(createKeyspaceName())
+               .withReplication(new CassandraGenerators.AbstractReplicationStrategyBuilder()
+                                .withUserAllowed()
+                                .withDatacenters("datacenter1")
+                                .withRf(1));
+    }
+
+    protected KeyspaceMetadata createKeyspace(RandomSource rs)
+    {
+        KeyspaceMetadata metadata = Generators.toGen(createKeyspaceMetadataBuilder().build()).next(rs);
+        String fullQuery = metadata.toCqlString(false, false, false);
+        logger.info(fullQuery);
+        schemaChange(fullQuery);
+        return metadata;
+    }
+
+    protected CassandraGenerators.TableMetadataBuilder createTableMetadataBuilder()
+    {
+        String ks = currentKeyspace();
+        if (ks == null)
+            ks = KEYSPACE;
+        return createTableMetadataBuilder(ks);
+    }
+
+    protected CassandraGenerators.TableMetadataBuilder createTableMetadataBuilder(String ks)
+    {
+        return regularTable()
+               .withKeyspaceName(ks)
+               .withSimpleColumnNames();
+    }
+
+    protected TableMetadata createTable(RandomSource rs)
+    {
+        TableMetadata metadata = Generators.toGen(createTableMetadataBuilder().build()).next(rs);
+        maybeCreateUDTs(metadata);
+        String fullQuery = metadata.toCqlString(false, false, false);
+        logger.info(fullQuery);
+        schemaChange(fullQuery);
+        return metadata;
+    }
+
+    protected TableMetadata createTable(RandomSource rs, String keyspace)
+    {
+        TableMetadata metadata = Generators.toGen(createTableMetadataBuilder(keyspace).build()).next(rs);
+        maybeCreateUDTs(metadata);
+        String fullQuery = metadata.toCqlString(false, false, false);
+        logger.info(fullQuery);
+        schemaChange(fullQuery);
+        return Schema.instance.getTableMetadata(keyspace, metadata.name);
+    }
+
+    protected void maybeCreateUDTs(TableMetadata metadata)
+    {
+        CassandraGenerators.visitUDTs(metadata, next -> {
+            String cql = next.toCqlString(false, false, true);
+            logger.warn("Creating UDT {}", cql);
+            schemaChange(cql);
+        });
+    }
+
+//    protected String createIndexName()
+//    {
+//        String name = createSchemaElementName(SchemaElement.SchemaElementType.INDEX, null);
+//        indexes.add(name);
+//        return name;
+//    }
+//
+//    protected UntypedResultSet execute(org.apache.cassandra.cql3.ast.Statement stmt)
+//    {
+//        return executeFormattedQuery(stmt.toCQL(), stmt.bindsEncoded());
+//    }
+//
+//    protected ResultSet executeNet(ProtocolVersion protocolVersion, org.apache.cassandra.cql3.ast.Statement stmt)
+//    {
+//        return sessionNet(protocolVersion).execute(stmt.toCQL(), stmt.bindsEncoded());
+//    }
+//
+//    protected Mutation nonTransactionMutation(RandomSource rs, TableMetadata metadata)
+//    {
+//        return Generators.toGen(new ASTGenerators.MutationGenBuilder(metadata).withoutTransaction().build()).next(rs);
+//    }
+
+//    protected Select select(Mutation mutation)
+//    {
+//        // select * from table where <primaryKeys>
+//        return new Select(Collections.emptyList(),
+//                          Optional.of(new TableReference(mutation.table.keyspace, mutation.table.name)),
+//                          where(mutation.primaryKeys()),
+//                          Optional.empty(),
+//                          Optional.empty());
+//    }
+
+//    private Optional<Conditional> where(Map<Symbol, Expression> keys)
+//    {
+//        if (keys.isEmpty())
+//            throw new IllegalArgumentException("Unable to create a where clause from empty keys");
+//        Conditional.Builder builder = new Conditional.Builder();
+//        for (Map.Entry<Symbol, Expression> e : keys.entrySet())
+//            builder.where(Where.Inequalities.EQUAL, e.getKey(), e.getValue());
+//        return Optional.of(builder.build());
+//    }
+
+//    protected Object[][] rows(Mutation mutation)
+//    {
+//        return mutation.kind == Mutation.Kind.DELETE ? new Object[0][] : new Object[][]{row(mutation.toRowEncoded())};
+//    }
+
     @FunctionalInterface
     public interface CheckedFunction
     {
@@ -2933,8 +3073,15 @@ public abstract class CQLTester
             // CollectionType override getString() to use hexToBytes. We can't change that
             // without breaking SSTable2json, but the serializer for collection have the
             // right getString so using it directly instead.
-            TypeSerializer ser = type.getSerializer();
-            return ser.toString(ser.deserialize(bb));
+            try
+            {
+                TypeSerializer ser = type.getSerializer();
+                return ser.toString(ser.deserialize(bb));
+            }
+            catch (Throwable t)
+            {
+                return "TypeSerializer.toString failed for type " + type.asCQL3Type() + ": " + t.getMessage();
+            }
         }
 
         try
diff --git a/test/unit/org/apache/cassandra/cql3/PreparedStatementsTest.java b/test/unit/org/apache/cassandra/cql3/PreparedStatementsTest.java
index 70e49bc7fe..c6559ee851 100644
--- a/test/unit/org/apache/cassandra/cql3/PreparedStatementsTest.java
+++ b/test/unit/org/apache/cassandra/cql3/PreparedStatementsTest.java
@@ -218,6 +218,7 @@ public class PreparedStatementsTest extends CQLTester
         session.execute(preparedBatch.bind(2, 2, "value2"));
         session.execute(preparedTxn.bind(3, 3, "value3"));
 
+        sessionSchemaUpdate(session, dropTableStatement); // since this is an accord table, need to drop the table before the keyspace
         sessionSchemaUpdate(session, dropKsStatement);
         sessionSchemaUpdate(session, createKsStatement);
         sessionSchemaUpdate(session, createTableStatement);
@@ -229,6 +230,7 @@ public class PreparedStatementsTest extends CQLTester
         session.execute(prepared.bind(1, 1, "value"));
         session.execute(preparedBatch.bind(2, 2, "value2"));
         session.execute(preparedTxn.bind(3, 3, "value3"));
+        sessionSchemaUpdate(session, dropTableStatement); // since this is an accord table, need to drop the table before the keyspace
         sessionSchemaUpdate(session, dropKsStatement);
     }
 
@@ -249,6 +251,7 @@ public class PreparedStatementsTest extends CQLTester
         Session session = sessionNet(version);
         String createTableStatement = "CREATE TABLE IF NOT EXISTS " + KEYSPACE + ".qp_cleanup (a int PRIMARY KEY, b int, c int) WITH transactional_mode='unsafe';";
         String alterTableStatement = "ALTER TABLE " + KEYSPACE + ".qp_cleanup ADD d int;";
+        String dropTableStatement = "DROP TABLE IF EXISTS " + KEYSPACE + ".qp_cleanup;";
 
         sessionSchemaUpdate(session, dropKsStatement);
         sessionSchemaUpdate(session, createKsStatement);
@@ -315,6 +318,7 @@ public class PreparedStatementsTest extends CQLTester
             }
         }
 
+        sessionSchemaUpdate(session, dropTableStatement);
         sessionSchemaUpdate(session, dropKsStatement);
     }
 
@@ -335,6 +339,7 @@ public class PreparedStatementsTest extends CQLTester
         Session session = sessionNet(version);
         String createTableStatement = "CREATE TABLE IF NOT EXISTS " + KEYSPACE + ".qp_cleanup (a int PRIMARY KEY, b int, c int) WITH transactional_mode='unsafe';";
         String alterTableStatement = "ALTER TABLE " + KEYSPACE + ".qp_cleanup ADD d int;";
+        String dropTableStatement = "DROP TABLE IF EXISTS " + KEYSPACE + ".qp_cleanup;";
 
         sessionSchemaUpdate(session, dropKsStatement);
         sessionSchemaUpdate(session, createKsStatement);
@@ -382,6 +387,7 @@ public class PreparedStatementsTest extends CQLTester
             Assertions.assertThat(columnNames(rs)).containsExactlyInAnyOrder("a", "b", "c");
         }
 
+        sessionSchemaUpdate(session, dropTableStatement);
         sessionSchemaUpdate(session, dropKsStatement);
     }
 
diff --git a/test/unit/org/apache/cassandra/cql3/RandomSchemaTest.java b/test/unit/org/apache/cassandra/cql3/RandomSchemaTest.java
index 00abdc9ca1..075fbf8e91 100644
--- a/test/unit/org/apache/cassandra/cql3/RandomSchemaTest.java
+++ b/test/unit/org/apache/cassandra/cql3/RandomSchemaTest.java
@@ -20,27 +20,18 @@ package org.apache.cassandra.cql3;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
-import java.util.ArrayDeque;
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Deque;
-import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
-import java.util.NavigableMap;
-import java.util.Set;
-import java.util.TreeMap;
 import java.util.stream.Collectors;
 
 import com.google.common.collect.ImmutableList;
 import org.junit.Assert;
 import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
 
 import org.apache.cassandra.config.CassandraRelevantProperties;
 import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.db.marshal.UserType;
 import org.apache.cassandra.io.sstable.format.SSTableFormat;
 import org.apache.cassandra.io.util.DataInputBuffer;
 import org.apache.cassandra.io.util.DataOutputBuffer;
@@ -65,8 +56,6 @@ import static org.junit.Assert.assertTrue;
 
 public class RandomSchemaTest extends CQLTester.InMemory
 {
-    private static final Logger logger = LoggerFactory.getLogger(RandomSchemaTest.class);
-
     static
     {
         // make sure blob is always the same
@@ -80,20 +69,17 @@ public class RandomSchemaTest extends CQLTester.InMemory
     {
         // in accord branch there is a much cleaner api for this pattern...
         Gen<AbstractTypeGenerators.ValueDomain> domainGen = SourceDSL.integers().between(1, 100).map(i -> i < 2 ? AbstractTypeGenerators.ValueDomain.NULL : i < 4 ? AbstractTypeGenerators.ValueDomain.EMPTY_BYTES : AbstractTypeGenerators.ValueDomain.NORMAL);
-        // make sure ordering is determanstic, else repeatability breaks
-        NavigableMap<String, SSTableFormat<?, ?>> formats = new TreeMap<>(DatabaseDescriptor.getSSTableFormats());
-        Gen<SSTableFormat<?, ?>> ssTableFormatGen = SourceDSL.arbitrary().pick(new ArrayList<>(formats.values()));
+
+        Gen<SSTableFormat<?, ?>> sstableFormatGen = CassandraGenerators.sstableFormat();
         qt().checkAssert(random -> {
             resetSchema();
 
             // TODO : when table level override of sstable format is allowed, migrate to that
-            SSTableFormat<?, ?> sstableFormat = ssTableFormatGen.generate(random);
-            DatabaseDescriptor.setSelectedSSTableFormat(sstableFormat);
+            DatabaseDescriptor.setSelectedSSTableFormat(sstableFormatGen.generate(random));
 
             Gen<String> udtName = Generators.unique(IDENTIFIER_GEN);
 
             TypeGenBuilder withoutUnsafeEquality = AbstractTypeGenerators.withoutUnsafeEquality()
-                                                                         .withUserTypeKeyspace(KEYSPACE)
                                                                          .withUDTNames(udtName);
             TableMetadata metadata = new TableMetadataBuilder()
                                      .withKeyspaceName(KEYSPACE)
@@ -101,7 +87,6 @@ public class RandomSchemaTest extends CQLTester.InMemory
                                      .withKnownMemtables()
                                      .withDefaultTypeGen(AbstractTypeGenerators.builder()
                                                                                .withoutEmpty()
-                                                                               .withUserTypeKeyspace(KEYSPACE)
                                                                                .withMaxDepth(2)
                                                                                .withDefaultSetKey(withoutUnsafeEquality)
                                                                                .withoutTypeKinds(AbstractTypeGenerators.TypeKind.COUNTER)
@@ -187,36 +172,6 @@ public class RandomSchemaTest extends CQLTester.InMemory
         }
     }
 
-    private void maybeCreateUDTs(TableMetadata metadata)
-    {
-        Set<UserType> udts = CassandraGenerators.extractUDTs(metadata);
-        if (!udts.isEmpty())
-        {
-            Deque<UserType> pending = new ArrayDeque<>(udts);
-            Set<ByteBuffer> created = new HashSet<>();
-            while (!pending.isEmpty())
-            {
-                UserType next = pending.poll();
-                Set<UserType> subTypes = AbstractTypeGenerators.extractUDTs(next);
-                subTypes.remove(next); // it includes self
-                if (subTypes.isEmpty() || subTypes.stream().allMatch(t -> created.contains(t.name)))
-                {
-                    String cql = next.toCqlString(true, false, false);
-                    logger.warn("Creating UDT {}", cql);
-                    schemaChange(cql);
-                    created.add(next.name);
-                }
-                else
-                {
-                    logger.warn("Unable to create UDT {}; following sub-types still not created: {}",
-                                next.getCqlTypeName(),
-                                subTypes.stream().filter(t -> !created.contains(t.name)).collect(Collectors.toSet()));
-                    pending.add(next);
-                }
-            }
-        }
-    }
-
     private static int primaryColumnCount(TableMetadata metadata)
     {
         return metadata.partitionKeyColumns().size() + metadata.clusteringColumns().size();
diff --git a/test/unit/org/apache/cassandra/cql3/ast/ExpressionTest.java b/test/unit/org/apache/cassandra/cql3/ast/ExpressionTest.java
index fe4f73efe0..a2805e8569 100644
--- a/test/unit/org/apache/cassandra/cql3/ast/ExpressionTest.java
+++ b/test/unit/org/apache/cassandra/cql3/ast/ExpressionTest.java
@@ -20,14 +20,14 @@ package org.apache.cassandra.cql3.ast;
 
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.apache.cassandra.cql3.ast.Conditional.And;
 import org.apache.cassandra.cql3.ast.Conditional.Where;
 import org.apache.cassandra.db.marshal.Int32Type;
 import org.assertj.core.api.Assertions;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class ExpressionTest
 {
diff --git a/test/unit/org/apache/cassandra/cql3/ast/Select.java b/test/unit/org/apache/cassandra/cql3/ast/Select.java
index 10d98dee63..eea9ded9ad 100644
--- a/test/unit/org/apache/cassandra/cql3/ast/Select.java
+++ b/test/unit/org/apache/cassandra/cql3/ast/Select.java
@@ -170,11 +170,11 @@ FROM [keyspace_name.] table_name
     public Stream<? extends Element> stream()
     {
         List<Element> es = new ArrayList<>(selections.size()
-                                           + (source.isPresent() ? 1 : 0)
-                                           + (where.isPresent() ? 1 : 0)
-                                           + (orderBy.isPresent() ? 1 : 0)
-                                           + (perPartitionLimit.isPresent() ? 1 : 0)
-                                           + (limit.isPresent() ? 1 : 0));
+                + (source.isPresent() ? 1 : 0)
+                + (where.isPresent() ? 1 : 0)
+                + (orderBy.isPresent() ? 1 : 0)
+                + (perPartitionLimit.isPresent() ? 1 : 0)
+                + (limit.isPresent() ? 1 : 0));
         es.addAll(selections);
         if (source.isPresent())
             es.add(source.get());
@@ -445,11 +445,11 @@ FROM [keyspace_name.] table_name
         public Select build()
         {
             return new Select((selections == null || selections.isEmpty()) ? Collections.emptyList() : ImmutableList.copyOf(selections),
-                              source,
-                              where.isEmpty() ? Optional.empty() : Optional.of(where.build()),
-                              orderBy.isEmpty() ? Optional.empty() : Optional.of(orderBy.build()),
-                              perPartitionLimit, limit,
-                              allowFiltering);
+                    source,
+                    where.isEmpty() ? Optional.empty() : Optional.of(where.build()),
+                    orderBy.isEmpty() ? Optional.empty() : Optional.of(orderBy.build()),
+                    perPartitionLimit, limit,
+                    allowFiltering);
         }
     }
 
diff --git a/test/unit/org/apache/cassandra/cql3/conditions/ColumnConditionTest.java b/test/unit/org/apache/cassandra/cql3/conditions/ColumnConditionTest.java
index 4d72bae35c..368687b5af 100644
--- a/test/unit/org/apache/cassandra/cql3/conditions/ColumnConditionTest.java
+++ b/test/unit/org/apache/cassandra/cql3/conditions/ColumnConditionTest.java
@@ -20,9 +20,9 @@ package org.apache.cassandra.cql3.conditions;
 import java.nio.ByteBuffer;
 import java.util.*;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.RandomSource;
 import org.apache.cassandra.cql3.terms.*;
 import org.junit.Assert;
 import org.junit.Test;
@@ -58,7 +58,7 @@ import org.assertj.core.api.Assertions;
 import org.mockito.Mockito;
 import org.quicktheories.generators.SourceDSL;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
diff --git a/test/unit/org/apache/cassandra/gms/VersionedValueTest.java b/test/unit/org/apache/cassandra/gms/VersionedValueTest.java
index 42728040ec..af0177e357 100644
--- a/test/unit/org/apache/cassandra/gms/VersionedValueTest.java
+++ b/test/unit/org/apache/cassandra/gms/VersionedValueTest.java
@@ -20,7 +20,7 @@ package org.apache.cassandra.gms;
 
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
+import accord.utils.Gen;
 import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializers;
 import org.apache.cassandra.io.util.DataOutputBuffer;
@@ -28,7 +28,7 @@ import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.utils.CassandraGenerators;
 import org.apache.cassandra.utils.Generators;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class VersionedValueTest
 {
diff --git a/test/unit/org/apache/cassandra/index/sai/cql/AbstractSimpleEqTestBase.java b/test/unit/org/apache/cassandra/index/sai/cql/AbstractSimpleEqTestBase.java
index 1663fbe5c3..fae644f389 100644
--- a/test/unit/org/apache/cassandra/index/sai/cql/AbstractSimpleEqTestBase.java
+++ b/test/unit/org/apache/cassandra/index/sai/cql/AbstractSimpleEqTestBase.java
@@ -24,8 +24,8 @@ import java.util.Map;
 import java.util.TreeMap;
 import javax.annotation.Nullable;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Property;
+import accord.utils.Gen;
+import accord.utils.Property;
 import org.agrona.collections.IntArrayList;
 import org.apache.cassandra.config.CassandraRelevantProperties;
 import org.apache.cassandra.cql3.UntypedResultSet;
@@ -33,7 +33,7 @@ import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.index.sai.SAITester;
 import org.assertj.core.api.Assertions;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public abstract class AbstractSimpleEqTestBase extends SAITester
 {
diff --git a/test/unit/org/apache/cassandra/index/sai/cql/AllTypesSimpleEqTest.java b/test/unit/org/apache/cassandra/index/sai/cql/AllTypesSimpleEqTest.java
index 9cca64d3d5..91bff0de97 100644
--- a/test/unit/org/apache/cassandra/index/sai/cql/AllTypesSimpleEqTest.java
+++ b/test/unit/org/apache/cassandra/index/sai/cql/AllTypesSimpleEqTest.java
@@ -28,8 +28,8 @@ import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.apache.cassandra.cql3.CQL3Type;
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.DecimalType;
diff --git a/test/unit/org/apache/cassandra/io/util/CompressedChunkReaderTest.java b/test/unit/org/apache/cassandra/io/util/CompressedChunkReaderTest.java
index e1a42552d1..af4b458fec 100644
--- a/test/unit/org/apache/cassandra/io/util/CompressedChunkReaderTest.java
+++ b/test/unit/org/apache/cassandra/io/util/CompressedChunkReaderTest.java
@@ -18,8 +18,8 @@
 
 package org.apache.cassandra.io.util;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.ClusteringComparator;
 import org.apache.cassandra.io.compress.CompressedSequentialWriter;
@@ -36,7 +36,7 @@ import java.nio.ByteBuffer;
 import java.nio.file.Files;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class CompressedChunkReaderTest
 {
diff --git a/test/unit/org/apache/cassandra/net/MessageDeliveryTest.java b/test/unit/org/apache/cassandra/net/MessageDeliveryTest.java
index e8fcf286a6..9d2fa5de21 100644
--- a/test/unit/org/apache/cassandra/net/MessageDeliveryTest.java
+++ b/test/unit/org/apache/cassandra/net/MessageDeliveryTest.java
@@ -30,7 +30,7 @@ import com.google.common.collect.Iterators;
 import org.junit.Assert;
 import org.junit.Test;
 
-import accord.utilsfork.RandomSource;
+import accord.utils.RandomSource;
 import org.apache.cassandra.concurrent.ScheduledExecutorPlus;
 import org.apache.cassandra.concurrent.SimulatedExecutorFactory;
 import org.apache.cassandra.config.DatabaseDescriptor;
@@ -46,7 +46,7 @@ import org.apache.cassandra.tcm.StubClusterMetadataService;
 import org.apache.cassandra.utils.Backoff;
 import org.mockito.Mockito;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 import static org.assertj.core.api.Assertions.assertThat;
 
 public class MessageDeliveryTest
diff --git a/test/unit/org/apache/cassandra/net/SimulatedMessageDelivery.java b/test/unit/org/apache/cassandra/net/SimulatedMessageDelivery.java
index dd9472a911..2f5014abd8 100644
--- a/test/unit/org/apache/cassandra/net/SimulatedMessageDelivery.java
+++ b/test/unit/org/apache/cassandra/net/SimulatedMessageDelivery.java
@@ -29,8 +29,8 @@ import java.util.function.Consumer;
 import java.util.function.LongSupplier;
 import javax.annotation.Nullable;
 
-import accord.utilsfork.Gens;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gens;
+import accord.utils.RandomSource;
 
 import org.apache.cassandra.exceptions.RequestFailure;
 import org.apache.cassandra.locator.InetAddressAndPort;
diff --git a/test/unit/org/apache/cassandra/repair/ConcurrentIrWithPreviewFuzzTest.java b/test/unit/org/apache/cassandra/repair/ConcurrentIrWithPreviewFuzzTest.java
index e4791f5a54..4eba7f0e36 100644
--- a/test/unit/org/apache/cassandra/repair/ConcurrentIrWithPreviewFuzzTest.java
+++ b/test/unit/org/apache/cassandra/repair/ConcurrentIrWithPreviewFuzzTest.java
@@ -24,8 +24,8 @@ import java.util.concurrent.TimeUnit;
 
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.RetrySpec;
 import org.apache.cassandra.db.ColumnFamilyStore;
@@ -35,7 +35,7 @@ import org.apache.cassandra.utils.Closeable;
 import org.apache.cassandra.utils.FailingBiConsumer;
 import org.assertj.core.api.Assertions;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class ConcurrentIrWithPreviewFuzzTest extends FuzzTestBase
 {
diff --git a/test/unit/org/apache/cassandra/repair/FailedAckTest.java b/test/unit/org/apache/cassandra/repair/FailedAckTest.java
index f96bf3732d..c77a812f92 100644
--- a/test/unit/org/apache/cassandra/repair/FailedAckTest.java
+++ b/test/unit/org/apache/cassandra/repair/FailedAckTest.java
@@ -23,8 +23,8 @@ import java.util.List;
 
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.RetrySpec;
 import org.apache.cassandra.db.compaction.ICompactionManager;
@@ -39,7 +39,7 @@ import org.apache.cassandra.utils.Closeable;
 import org.assertj.core.api.Assertions;
 import org.mockito.Mockito;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class FailedAckTest extends FuzzTestBase
 {
diff --git a/test/unit/org/apache/cassandra/repair/FailingRepairFuzzTest.java b/test/unit/org/apache/cassandra/repair/FailingRepairFuzzTest.java
index 7e58fd13b5..ccce173d44 100644
--- a/test/unit/org/apache/cassandra/repair/FailingRepairFuzzTest.java
+++ b/test/unit/org/apache/cassandra/repair/FailingRepairFuzzTest.java
@@ -29,8 +29,8 @@ import java.util.stream.Collectors;
 import com.google.common.collect.ImmutableList;
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.RetrySpec;
 import org.apache.cassandra.locator.InetAddressAndPort;
@@ -42,7 +42,7 @@ import org.apache.cassandra.utils.Closeable;
 import org.assertj.core.api.AbstractStringAssert;
 import org.assertj.core.api.Assertions;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class FailingRepairFuzzTest extends FuzzTestBase
 {
diff --git a/test/unit/org/apache/cassandra/repair/FuzzTestBase.java b/test/unit/org/apache/cassandra/repair/FuzzTestBase.java
index 1665ef80c6..ad814f0032 100644
--- a/test/unit/org/apache/cassandra/repair/FuzzTestBase.java
+++ b/test/unit/org/apache/cassandra/repair/FuzzTestBase.java
@@ -53,10 +53,10 @@ import com.google.common.collect.Sets;
 
 import org.junit.BeforeClass;
 
-import accord.utilsfork.DefaultRandom;
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
-import accord.utilsfork.RandomSource;
+import accord.utils.DefaultRandom;
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.RandomSource;
 import org.agrona.collections.LongHashSet;
 import org.apache.cassandra.ServerTestUtils;
 import org.apache.cassandra.concurrent.ExecutorBuilder;
diff --git a/test/unit/org/apache/cassandra/repair/HappyPathFuzzTest.java b/test/unit/org/apache/cassandra/repair/HappyPathFuzzTest.java
index 9809421931..f8e570b5c1 100644
--- a/test/unit/org/apache/cassandra/repair/HappyPathFuzzTest.java
+++ b/test/unit/org/apache/cassandra/repair/HappyPathFuzzTest.java
@@ -28,14 +28,14 @@ import java.util.stream.LongStream;
 
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.agrona.collections.LongArrayList;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.RetrySpec;
 import org.apache.cassandra.utils.Closeable;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class HappyPathFuzzTest extends FuzzTestBase
 {
diff --git a/test/unit/org/apache/cassandra/repair/SlowMessageFuzzTest.java b/test/unit/org/apache/cassandra/repair/SlowMessageFuzzTest.java
index 6160532e8f..03c151ec68 100644
--- a/test/unit/org/apache/cassandra/repair/SlowMessageFuzzTest.java
+++ b/test/unit/org/apache/cassandra/repair/SlowMessageFuzzTest.java
@@ -23,13 +23,13 @@ import java.util.List;
 
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
+import accord.utils.Gen;
+import accord.utils.Gens;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.RetrySpec;
 import org.apache.cassandra.utils.Closeable;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class SlowMessageFuzzTest extends FuzzTestBase
 {
diff --git a/test/unit/org/apache/cassandra/schema/MemtableParamsTest.java b/test/unit/org/apache/cassandra/schema/MemtableParamsTest.java
index acd0e0f8f8..e34d299a15 100644
--- a/test/unit/org/apache/cassandra/schema/MemtableParamsTest.java
+++ b/test/unit/org/apache/cassandra/schema/MemtableParamsTest.java
@@ -21,7 +21,7 @@ package org.apache.cassandra.schema;
 import java.util.LinkedHashMap;
 import java.util.Map;
 
-import accord.utilsfork.Gen;
+import accord.utils.Gen;
 import com.google.common.collect.ImmutableMap;
 import org.apache.cassandra.config.Config;
 import org.apache.cassandra.utils.ConfigGenBuilder;
@@ -33,7 +33,7 @@ import org.apache.cassandra.config.ParameterizedClass;
 import org.apache.cassandra.db.memtable.SkipListMemtableFactory;
 import org.apache.cassandra.exceptions.ConfigurationException;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 import static org.apache.cassandra.config.YamlConfigurationLoader.fromMap;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
diff --git a/test/unit/org/apache/cassandra/schema/TableParamsTest.java b/test/unit/org/apache/cassandra/schema/TableParamsTest.java
new file mode 100644
index 0000000000..e8bf30fe0a
--- /dev/null
+++ b/test/unit/org/apache/cassandra/schema/TableParamsTest.java
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import org.junit.Test;
+
+import org.apache.cassandra.io.util.DataOutputBuffer;
+import org.apache.cassandra.tcm.membership.NodeVersion;
+import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializers;
+import org.apache.cassandra.utils.CassandraGenerators.TableParamsBuilder;
+import org.apache.cassandra.utils.FailingConsumer;
+import org.quicktheories.core.Gen;
+
+import static org.quicktheories.QuickTheory.qt;
+
+
+public class TableParamsTest
+{
+    @Test
+    public void serdeLatest()
+    {
+        DataOutputBuffer output = new DataOutputBuffer();
+        qt().forAll(tableParams()).checkAssert(FailingConsumer.orFail(params -> {
+            AsymmetricMetadataSerializers.testSerde(output, TableParams.serializer, params, NodeVersion.CURRENT_METADATA_VERSION);
+        }));
+    }
+
+    private static Gen<TableParams> tableParams()
+    {
+        return new TableParamsBuilder()
+               .withKnownMemtables()
+               .withTransactionalMode()
+               .withFastPathStrategy()
+               .build();
+    }
+}
\ No newline at end of file
diff --git a/test/unit/org/apache/cassandra/service/accord/AccordKeyspaceTest.java b/test/unit/org/apache/cassandra/service/accord/AccordKeyspaceTest.java
index 02d823cfd4..3939371ad9 100644
--- a/test/unit/org/apache/cassandra/service/accord/AccordKeyspaceTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/AccordKeyspaceTest.java
@@ -135,7 +135,7 @@ public class AccordKeyspaceTest extends CQLTester.InMemory
     public void findOverlappingKeys()
     {
         var tableIdGen = fromQT(CassandraGenerators.TABLE_ID_GEN);
-        var partitionGen = fromQT(CassandraGenerators.partitioners());
+        var partitionGen = fromQT(CassandraGenerators.partitioners()).map(CassandraGenerators::simplify);
 
         var sstableFormats = DatabaseDescriptor.getSSTableFormats();
         List<String> sstableFormatNames = new ArrayList<>(sstableFormats.keySet());
diff --git a/test/unit/org/apache/cassandra/service/accord/AccordStaleReplicasTest.java b/test/unit/org/apache/cassandra/service/accord/AccordStaleReplicasTest.java
index 83eced9b66..bce9a3fb14 100644
--- a/test/unit/org/apache/cassandra/service/accord/AccordStaleReplicasTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/AccordStaleReplicasTest.java
@@ -47,7 +47,7 @@ public class AccordStaleReplicasTest
             qt().check(rs -> {
                 Epoch epoch = epochGen.next(rs);
                 Set<Node.Id> nodes = nodesGen.next(rs);
-                AsymmetricMetadataSerializers.testSerde(buffer, AccordStaleReplicas.serializer, new AccordStaleReplicas(nodes, epoch), Version.V2);
+                AsymmetricMetadataSerializers.testSerde(buffer, AccordStaleReplicas.serializer, new AccordStaleReplicas(nodes, epoch), Version.MIN_ACCORD_VERSION);
             });
         }
     }
diff --git a/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java b/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java
index 12d5c75c01..5969770e2e 100644
--- a/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java
@@ -58,7 +58,6 @@ import accord.utils.RandomSource;
 import org.apache.cassandra.concurrent.AdaptingScheduledExecutorPlus;
 import org.apache.cassandra.concurrent.ScheduledExecutorPlus;
 import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.exceptions.RequestFailure;
 import org.apache.cassandra.gms.EndpointState;
 import org.apache.cassandra.gms.Gossiper;
@@ -70,8 +69,8 @@ import org.apache.cassandra.net.ConnectionType;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.MessageDelivery;
 import org.apache.cassandra.net.RequestCallback;
-import org.apache.cassandra.tcm.ClusterMetadataService;
-import org.apache.cassandra.tcm.StubClusterMetadataService;
+import org.apache.cassandra.tcm.ValidatingClusterMetadataService;
+import org.apache.cassandra.tcm.serialization.Version;
 import org.apache.cassandra.utils.AccordGenerators;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.concurrent.Future;
@@ -86,9 +85,7 @@ public class AccordSyncPropagatorTest
     public static void setup() throws NoSuchFieldException, IllegalAccessException
     {
         DatabaseDescriptor.daemonInitialization();
-        DatabaseDescriptor.setPartitionerUnsafe(Murmur3Partitioner.instance);
-        ClusterMetadataService.unsetInstance();
-        ClusterMetadataService.setInstance(StubClusterMetadataService.forTesting());
+        ValidatingClusterMetadataService.createAndRegister(Version.MIN_ACCORD_VERSION);
     }
 
     @Test
diff --git a/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java b/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java
index 55aa527e94..f5faef62c9 100644
--- a/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java
@@ -20,7 +20,6 @@ package org.apache.cassandra.service.accord;
 
 import java.net.UnknownHostException;
 import java.util.ArrayList;
-import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Comparator;
@@ -28,6 +27,7 @@ import java.util.EnumMap;
 import java.util.EnumSet;
 import java.util.HashMap;
 import java.util.HashSet;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.NavigableSet;
@@ -38,7 +38,7 @@ import java.util.TreeSet;
 import java.util.concurrent.Callable;
 import java.util.concurrent.TimeUnit;
 import java.util.function.BiConsumer;
-import java.util.function.Consumer;
+import java.util.function.Predicate;
 import java.util.stream.Collectors;
 import java.util.stream.LongStream;
 
@@ -49,8 +49,8 @@ import org.slf4j.LoggerFactory;
 
 import accord.api.ConfigurationService;
 import accord.api.ConfigurationService.EpochReady;
-import accord.api.Scheduler;
 import accord.api.LocalConfig;
+import accord.api.Scheduler;
 import accord.impl.SizeOfIntersectionSorter;
 import accord.impl.TestAgent;
 import accord.local.Node;
@@ -60,7 +60,7 @@ import accord.topology.Topology;
 import accord.topology.TopologyManager;
 import accord.utils.Gen;
 import accord.utils.Invariants;
-import accord.utils.Property.UnitCommand;
+import accord.utils.Property.SimpleCommand;
 import accord.utils.RandomSource;
 import accord.utils.async.AsyncChain;
 import accord.utils.async.AsyncChains;
@@ -74,17 +74,14 @@ import org.apache.cassandra.dht.Murmur3Partitioner.LongToken;
 import org.apache.cassandra.gms.IFailureDetectionEventListener;
 import org.apache.cassandra.gms.IFailureDetector;
 import org.apache.cassandra.locator.InetAddressAndPort;
-import org.apache.cassandra.locator.Replica;
 import org.apache.cassandra.net.IVerbHandler;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.SimulatedMessageDelivery;
 import org.apache.cassandra.net.SimulatedMessageDelivery.Action;
 import org.apache.cassandra.net.Verb;
-import org.apache.cassandra.schema.DistributedMetadataLogKeyspace;
 import org.apache.cassandra.schema.DistributedSchema;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Keyspaces;
 import org.apache.cassandra.schema.ReplicationParams;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.TableParams;
@@ -94,13 +91,19 @@ import org.apache.cassandra.service.consensus.TransactionalMode;
 import org.apache.cassandra.tcm.ClusterMetadata;
 import org.apache.cassandra.tcm.ClusterMetadataService;
 import org.apache.cassandra.tcm.Epoch;
+import org.apache.cassandra.tcm.MultiStepOperation;
 import org.apache.cassandra.tcm.StubClusterMetadataService;
-import org.apache.cassandra.tcm.membership.Directory;
+import org.apache.cassandra.tcm.Transformation;
+import org.apache.cassandra.tcm.ValidatingClusterMetadataService;
 import org.apache.cassandra.tcm.membership.Location;
 import org.apache.cassandra.tcm.membership.NodeAddresses;
 import org.apache.cassandra.tcm.membership.NodeId;
-import org.apache.cassandra.tcm.ownership.DataPlacement;
-import org.apache.cassandra.tcm.ownership.DataPlacements;
+import org.apache.cassandra.tcm.membership.NodeState;
+import org.apache.cassandra.tcm.membership.NodeVersion;
+import org.apache.cassandra.tcm.ownership.UniformRangePlacement;
+import org.apache.cassandra.tcm.sequences.LeaveStreams;
+import org.apache.cassandra.tcm.transformations.PrepareJoin;
+import org.apache.cassandra.tcm.transformations.PrepareLeave;
 import org.apache.cassandra.utils.ByteArrayUtil;
 import org.apache.cassandra.utils.Pair;
 import org.assertj.core.api.Assertions;
@@ -123,85 +126,75 @@ public class EpochSyncTest
     @Test
     public void test()
     {
-        stateful().withExamples(50).check(commands(() -> Cluster::new)
-                                          .destroyState(cluster -> {
-                                              cluster.processAll();
-                                              cluster.validate(true);
-                                          })
-                                          .addIf(cluster -> cluster.alive().size() <= cluster.maxNodes, EpochSyncTest::addNode)
-                                          .addIf(cluster -> cluster.alive().size() > cluster.minNodes, EpochSyncTest::removeNode)
-                                          .addIf(cluster -> cluster.hasWork(), EpochSyncTest::processSome)
-                                          .add(rs -> new SimpleCommand("Validate", c -> c.validate(false)))
-                                          .add((rs, cluster) -> new SimpleCommand("Bump Epoch " + (cluster.current.epoch.getEpoch() + 1), Cluster::bumpEpoch))
-                                          .build());
+        stateful().withExamples(50).withSteps(500).check(commands(() -> Cluster::new)
+                .destroyState(cluster -> {
+                    finishPendingWork(cluster);
+                    cluster.processAll();
+                    cluster.validate(true);
+                })
+                .addAllIf(Cluster::hasPendingWork, b ->
+                        b.addIf(c -> !c.status(s -> s == Cluster.Status.Registered).isEmpty(), (rs, state) -> {
+                                    long epoch = state.cms.metadata().epoch.getEpoch() + 1;
+                                    Node.Id pick = rs.pick(state.status(s -> s == Cluster.Status.Registered));
+                                    return new SimpleCommand<>(pick + " Start Joining; epoch=" + epoch,
+                                            c -> c.increment(pick));
+                                })
+                                .addIf(c -> !c.cms.metadata().inProgressSequences.isEmpty(),
+                                        (rs, state) -> new SimpleCommand<>("Next Epoch Step; epoch=" + (state.cms.metadata().epoch.getEpoch() + 1),
+                                                Cluster::incrementInProgressSequences))
+                )
+                .addAllIf(Cluster::hasNoPendingWork, b ->
+                        b.addIf(cluster -> cluster.joined().size() <= cluster.maxNodes, EpochSyncTest::addNode)
+                                .addIf(cluster -> cluster.joined().size() > cluster.minNodes, EpochSyncTest::removeNode)
+                )
+                .addIf(Cluster::hasWork, EpochSyncTest::processSome)
+                .add(rs -> new SimpleCommand<>("Validate", c -> c.validate(false)))
+                .add((rs, cluster) -> new SimpleCommand<>("Bump Epoch " + (cluster.cms.metadata().epoch.getEpoch() + 1), Cluster::bumpEpoch))
+                .build());
+    }
+
+    private static void finishPendingWork(Cluster cluster)
+    {
+        List<Node.Id> registered = cluster.status(s -> s == Cluster.Status.Registered);
+        if (!registered.isEmpty())
+            registered.forEach(cluster::increment);
+        while (!cluster.cms.metadata().inProgressSequences.isEmpty())
+            cluster.incrementInProgressSequences();
     }
 
-    private static SimpleCommand addNode(RandomSource rs, Cluster cluster)
+    private static SimpleCommand<Cluster> addNode(RandomSource rs, Cluster cluster)
     {
         Node.Id id = new Node.Id(++cluster.nodeCounter);
         long token = cluster.tokenGen.nextLong(rs);
         while (cluster.tokens.contains(token))
             token = cluster.tokenGen.nextLong(rs);
-        long epoch = cluster.current.epoch.getEpoch() + 1;
+        long epoch = cluster.cms.metadata().epoch.getEpoch() + 1;
         long finalToken = token;
-        return new SimpleCommand("Add Node " + id + "; token=" + token + ", epoch=" + epoch,
-                                 c -> c.addNode(id, finalToken));
+        return new SimpleCommand<>("Start Node " + id + "; token=" + token + ", epoch=" + epoch,
+                                 c -> c.registerNode(id, finalToken));
     }
 
-    private static SimpleCommand removeNode(RandomSource rs, Cluster cluster)
+    private static SimpleCommand<Cluster> removeNode(RandomSource rs, Cluster cluster)
     {
-        List<Node.Id> alive = cluster.alive();
+        List<Node.Id> alive = cluster.joined();
         Node.Id pick = rs.pick(alive);
         long token = cluster.instances.get(pick).token;
-        long epoch = cluster.current.epoch.getEpoch() + 1;
-        return new SimpleCommand("Remove Node " + pick + "; token=" + token + "; epoch=" + epoch, c -> c.removeNode(pick));
+        long epoch = cluster.cms.metadata().epoch.getEpoch() + 1;
+        return new SimpleCommand<>("Remove Node " + pick + "; token=" + token + "; epoch=" + epoch, c -> c.removeNode(pick));
     }
 
-    private static SimpleCommand processSome(RandomSource rs)
-    {
-        return new SimpleCommand("Process Some",
-                                 c -> {//noinspection StatementWithEmptyBody
-                                     for (int i = 0, attempts = rs.nextInt(1, 100); i < attempts && c.processOne(); i++)
-                                     {
-                                     }
-                                 });
-    }
-
-    private static class SimpleCommand implements UnitCommand<Cluster, Void>
-    {
-        private final String name;
-        private final Consumer<Cluster> fn;
-
-        private SimpleCommand(String name, Consumer<Cluster> fn)
-        {
-            this.name = name;
-            this.fn = fn;
-        }
-
-        @Override
-        public String detailed(Cluster Cluster)
-        {
-            return name;
-        }
-
-        @Override
-        public void applyUnit(Cluster Cluster)
-        {
-            fn.accept(Cluster);
-        }
-
-        @Override
-        public void runUnit(Void Void)
-        {
-            
-        }
+    private static SimpleCommand<Cluster> processSome(RandomSource rs) {
+        return new SimpleCommand<>("Process Some",
+                c -> {//noinspection StatementWithEmptyBody
+                    for (int i = 0, attempts = rs.nextInt(1, 100); i < attempts && c.processOne(); i++) {
+                    }
+                });
     }
 
     private static class Cluster
     {
         private static final int rf = 2;
         private static final ReplicationParams replication_params = ReplicationParams.simple(rf);
-        private static final ReplicationParams meta = ReplicationParams.simpleMeta(1, Collections.singleton("dc1"));
 
         private final RandomSource rs;
         private final int minNodes, maxNodes;
@@ -213,16 +206,13 @@ public class EpochSyncTest
         private final SimulatedExecutorFactory globalExecutor;
         private final ScheduledExecutorPlus scheduler;
         private int nodeCounter = 0;
-        private ClusterMetadata current = new ClusterMetadata(Murmur3Partitioner.instance, Directory.EMPTY,
-                                                              new DistributedSchema(Keyspaces.of(
-                                                              DistributedMetadataLogKeyspace.initialMetadata(Collections.singleton("dc1")),
-                                                              KeyspaceMetadata.create("test", KeyspaceParams.simple(rf), Tables.of(TableMetadata.minimal("test", "tb1").unbuild().params(TableParams.builder().transactionalMode(TransactionalMode.full).build()).build())))));
+        private final ValidatingClusterMetadataService cms = ValidatingClusterMetadataService.createAndRegister(NodeVersion.CURRENT_METADATA_VERSION);
         private final IFailureDetector fd = new IFailureDetector()
         {
             @Override
             public boolean isAlive(InetAddressAndPort ep)
             {
-                return !removed.contains(nodeId(ep));
+                return instances.get(nodeId(ep)).status != Status.Removed;
             }
 
             @Override
@@ -262,47 +252,16 @@ public class EpochSyncTest
             }
         };
 
-        private static InetAddressAndPort address(Node.Id id)
-        {
-            try
-            {
-                return InetAddressAndPort.getByAddress(ByteArrayUtil.bytes(id.id));
-            }
-            catch (UnknownHostException e)
-            {
-                throw new AssertionError("Unable to create address for id " + id, e);
-            }
-        }
-
-        public enum EpochTracker { topologyManager, accordSyncPropagator, configurationService}
-
-        Set<EpochTracker> globalSynced(long epoch)
-        {
-            return alive().stream()
-                   .filter(n -> instances.get(n).epoch.getEpoch() <= epoch)
-                   .map(n -> instances.get(n).synced(epoch))
-                   .reduce(EnumSet.allOf(EpochTracker.class), Sets::intersection);
-        }
-
-        boolean allSynced(long epoch)
-        {
-            Set<EpochTracker> done = globalSynced(epoch);
-            return done.contains(EpochTracker.topologyManager);
-        }
-
-        private static Node.Id nodeId(InetAddressAndPort address)
-        {
-            return new Node.Id(ByteArrayUtil.getInt(address.addressBytes));
-        }
-
         public Cluster(RandomSource rs)
         {
+            // add the test keyspace
+            createTestKeyspaceAndTable();
             this.rs = rs;
             this.minNodes = 3;
             this.maxNodes = 10;
             this.tokenGen = rs2 -> rs2.nextLong(Long.MIN_VALUE + 1, Long.MAX_VALUE);
 
-            this.globalExecutor = new SimulatedExecutorFactory(accord.utilsfork.RandomSource.wrap(rs.asJdkRandom()), failures::add);
+            this.globalExecutor = new SimulatedExecutorFactory(rs, failures::add);
             this.scheduler = globalExecutor.scheduled("ignored");
             Stage.MISC.unsafeSetExecutor(scheduler);
 
@@ -321,7 +280,7 @@ public class EpochSyncTest
                 else
                 {
                     // add partition
-                    List<Node.Id> alive = alive();
+                    List<Node.Id> alive = notRemoved();
                     InetAddressAndPort a = address(rs.pick(alive));
                     InetAddressAndPort b = address(rs.pick(alive));
                     while (a.equals(b))
@@ -331,15 +290,110 @@ public class EpochSyncTest
             }, 1, 1, TimeUnit.MINUTES);
         }
 
+        private static InetAddressAndPort address(Node.Id id)
+        {
+            try
+            {
+                return InetAddressAndPort.getByAddress(ByteArrayUtil.bytes(id.id));
+            }
+            catch (UnknownHostException e)
+            {
+                throw new AssertionError("Unable to create address for id " + id, e);
+            }
+        }
+
+        private boolean hasPendingWork()
+        {
+            return !status(s -> s == Cluster.Status.Registered).isEmpty()
+                    || !cms.metadata().inProgressSequences.isEmpty();
+        }
+
+        private boolean hasNoPendingWork()
+        {
+            return !hasPendingWork();
+        }
+
+        private Transformation.Success process(Transformation transformation)
+        {
+            Transformation.Result result = transformation.execute(cms.metadata());
+            if (result.isRejected())
+                throw new IllegalStateException("Unable to make TCM transition: " + result.rejected());
+            return result.success();
+        }
+
+        private Transformation.Success process(MultiStepOperation<?> transformation)
+        {
+            Transformation.Result result = transformation.applyTo(cms.metadata());
+            if (result.isRejected())
+                throw new IllegalStateException("Unable to make TCM transition");
+            return result.success();
+        }
+
+        public void incrementInProgressSequences()
+        {
+            if (cms.metadata().inProgressSequences.isEmpty())
+                throw new IllegalStateException("Attempted to bump epoch when nothing was pending");
+            Iterator<MultiStepOperation<?>> it = cms.metadata().inProgressSequences.iterator();
+            Invariants.checkState(it.hasNext());
+            notify(process(it.next()).metadata);
+        }
+
+        private static boolean left(ClusterMetadata metadata, Node.Id id)
+        {
+            return metadata.directory.peerState(new NodeId(id.id)) == NodeState.LEFT;
+        }
+
+        private static boolean joined(ClusterMetadata metadata, Node.Id id)
+        {
+            NodeAddresses address = metadata.directory.getNodeAddresses(new NodeId(id.id));
+            return metadata.placements.get(replication_params).reads.byEndpoint().keySet().contains(address.broadcastAddress);
+        }
+
+        public enum EpochTracker { topologyManager, accordSyncPropagator, configurationService}
+
+        Set<EpochTracker> globalSynced(long epoch)
+        {
+            return notRemoved().stream()
+                               .filter(n -> instances.get(n).epoch.getEpoch() <= epoch)
+                               .map(n -> instances.get(n).synced(epoch))
+                               .reduce(EnumSet.allOf(EpochTracker.class), Sets::intersection);
+        }
+
+        boolean allSynced(long epoch)
+        {
+            Set<EpochTracker> done = globalSynced(epoch);
+            return done.contains(EpochTracker.topologyManager);
+        }
+
+        private static Node.Id nodeId(InetAddressAndPort address)
+        {
+            return new Node.Id(ByteArrayUtil.getInt(address.addressBytes));
+        }
+
+        private void createTestKeyspaceAndTable()
+        {
+            ClusterMetadata current = cms.metadata();
+            Tables tables = Tables.of(TableMetadata.minimal("test", "tb1").unbuild()
+                                                   .partitioner(Murmur3Partitioner.instance)
+                                                   .params(TableParams.builder().transactionalMode(TransactionalMode.full).build())
+                                                   .build());
+            KeyspaceMetadata ks = KeyspaceMetadata.create("test", KeyspaceParams.simple(rf), tables);
+
+            cms.setMetadata(current.transformer()
+                                   .with(new DistributedSchema(current.schema.getKeyspaces().with(ks)))
+                                   .build()
+                            .metadata);
+        }
+
         void validate(boolean isDone)
         {
-            for (Node.Id id : alive())
+            for (Node.Id id : notRemoved())
             {
                 Instance inst = instances.get(id);
                 if (removed.contains(id)) continue; // ignore removed nodes
                 AccordConfigurationService conf = inst.config;
                 TopologyManager tm = inst.topology;
-                for (long epoch = inst.epoch.getEpoch(); epoch <= current.epoch.getEpoch(); epoch++)
+                for (long epoch = inst.epoch.getEpoch(); epoch <= cms.metadata().epoch.getEpoch(); epoch++)
                 {
                     // validate config
                     EpochSnapshot snapshot = conf.getEpochSnapshot(epoch);
@@ -352,7 +406,9 @@ public class EpochSyncTest
                         Assertions.assertThat(tm.hasEpoch(epoch)).describedAs("node%s does not have epoch %d", id, epoch).isTrue();
                         Ranges ranges = tm.globalForEpoch(epoch).ranges().mergeTouching();
                         Ranges actual = tm.syncComplete(epoch).mergeTouching();
-                        Assertions.assertThat(actual).describedAs("node%s does not have all expected sync ranges for epoch %d; missing %s", id, epoch, ranges.without(actual)).isEqualTo(ranges);
+                        Assertions.assertThat(actual)
+                                  .describedAs("node%s does not have all expected sync ranges for epoch %d; missing %s", id, epoch, ranges.without(actual))
+                                  .isEqualTo(ranges);
                     }
                     else
                     {
@@ -379,13 +435,32 @@ public class EpochSyncTest
 
         String displayTopology()
         {
-            List<Node.Id> alive = alive();
-            List<Pair<Node.Id, Long>> withToken = new ArrayList<>(alive.size());
-            for (Node.Id n : alive)
-                withToken.add(Pair.create(n, instances.get(n).token));
-            withToken.sort(Comparator.comparing(a -> a.right));
+            class Hold {
+                final Cluster.Status status;
+                final long token;
+
+                Hold(Status status, long token)
+                {
+                    this.status = status;
+                    this.token = token;
+                }
+
+                @Override
+                public String toString()
+                {
+                    return status + "\t" + (status == Status.Registered ? "?" : Long.toString(token));
+                }
+            }
+            List<Node.Id> notRemoved = notRemoved();
+            List<Pair<Node.Id, Hold>> list = new ArrayList<>(notRemoved.size());
+            for (Node.Id n : notRemoved)
+            {
+                Instance instance = instances.get(n);
+                list.add(Pair.create(n, new Hold(instance.status, instance.token)));
+            }
+            list.sort(Comparator.comparing(a -> a.right.token));
             StringBuilder sb = new StringBuilder();
-            for (var p : withToken)
+            for (var p : list)
                 sb.append(p.left).append('\t').append(p.right).append('\n');
             return sb.toString();
         }
@@ -427,7 +502,24 @@ public class EpochSyncTest
             throw error;
         }
 
-        List<Node.Id> alive()
+        List<Node.Id> joined()
+        {
+            return status(s -> s == Status.Joined);
+        }
+
+        List<Node.Id> status(Predicate<Status> fn)
+        {
+            List<Node.Id> ids = new ArrayList<>(instances.size());
+            for (Instance i : instances.values())
+            {
+                if (fn.test(i.status))
+                    ids.add(i.id);
+            }
+            ids.sort(Comparator.naturalOrder());
+            return ids;
+        }
+
+        List<Node.Id> notRemoved()
         {
             ArrayList<Node.Id> ids = new ArrayList<>(Sets.difference(instances.keySet(), removed));
             ids.sort(Comparator.naturalOrder());
@@ -459,73 +551,74 @@ public class EpochSyncTest
                                                         return rs.nextBoolean() ? Action.DELIVER_WITH_FAILURE : Action.FAILURE;
                                                     return Action.DELIVER;
                                                 },
-                                                SimulatedMessageDelivery.randomDelay(accord.utilsfork.RandomSource.wrap(rs.asJdkRandom())),
+                                                SimulatedMessageDelivery.randomDelay(rs.fork()),
                                                 (to, msg) -> instances.get(nodeId(to)).reciver.recieve(msg),
-                                                (action, to, msg) -> logger.warn("{} message {}", action, msg),
+                                                (action, to, msg) -> logger.trace("{} message {}", action, msg),
                                                 scheduler::schedule,
                                                 failures::add);
         }
 
-        void addNode(Node.Id id, long token)
+        void registerNode(Node.Id id, long token)
         {
             Invariants.checkState(!tokens.contains(token), "Attempted to add token %d for node %s but token is already taken", token, id);
-            Epoch epoch = Epoch.create(current.epoch.getEpoch() + 1);
+            Invariants.checkState(!instances.containsKey(id), "Attempted to add node %s; but already exists", id);
 
-            Instance instance = new Instance(id, token, epoch, createMessaging(id), fd);
+            ClusterMetadata.Transformer builder = cms.metadata().transformer();
+
+            Instance instance = new Instance(id, token, builder.epoch(), createMessaging(id), fd);
             instances.put(id, instance);
             tokens.add(token);
 
-            current = current.forceEpoch(epoch)
-                             .withPlacements(DataPlacements.builder(2)
-                                                           .with(meta, DataPlacement.empty())
-                                                           .with(replication_params, rebuildPlacements(epoch))
-                                                           .build())
-                             .withDirectory(current.directory.with(new NodeAddresses(address(id)), new Location("dc1", "r1")));
-            notify(current);
+            builder.register(new NodeAddresses(address(id)), new Location("dc1", "r1"), NodeVersion.CURRENT);
+            notify(builder.build().metadata);
         }
 
-        void removeNode(Node.Id pick)
+        void increment(Node.Id pick)
         {
             Instance inst = Objects.requireNonNull(instances.get(pick), "Unknown id " + pick);
-            Invariants.checkState(!removed.contains(pick), "Can not remove node twice; node " + pick);
-            tokens.remove(inst.token);
-            removed.add(pick);
-            inst.stop();
-            current = current.forceEpoch(Epoch.create(current.epoch.getEpoch() + 1))
-                             .withDirectory(current.directory.without(new NodeId(pick.id)));
 
-            current = current.withPlacements(DataPlacements.builder(2)
-                                                           .with(meta, DataPlacement.empty())
-                                                           .with(replication_params, rebuildPlacements(current.epoch))
-                                                           .build());
-            notify(current);
+            switch (inst.status)
+            {
+                case Init:
+                case Joined:
+                case Removed:
+                    throw new IllegalStateException("Unexpected status: " + inst.status);
+                case Registered:
+                    inst.status = Status.Joining;
+                    PrepareJoin task = new PrepareJoin(new NodeId(pick.id), Collections.singleton(new LongToken(inst.token)), new UniformRangePlacement(), true, false);
+                    notify(process(task).metadata);
+                    break;
+                default:
+                    throw new UnsupportedOperationException("Unknown status: " + inst.status);
+            }
         }
 
-        private DataPlacement rebuildPlacements(Epoch epoch)
+        void removeNode(Node.Id pick)
         {
-            DataPlacement.Builder builder = DataPlacement.builder();
-            for (Node.Id inst : alive())
-                for (Replica replica : instances.get(inst).replica())
-                    builder.withReadReplica(epoch, replica).withWriteReplica(epoch, replica);
-            return builder.build();
+            Instance inst = Objects.requireNonNull(instances.get(pick), "Unknown id " + pick);
+            Invariants.checkState(!removed.contains(pick), "Can not remove node twice; node " + pick);
+            removed.add(pick);
+            inst.status = Status.Leaving;
+            PrepareLeave prepareLeave = new PrepareLeave(new NodeId(pick.id), false, new UniformRangePlacement(), LeaveStreams.Kind.REMOVENODE);
+            notify(process(prepareLeave).metadata);
         }
 
         void bumpEpoch()
         {
-            current = current.forceEpoch(Epoch.create(current.epoch.getEpoch() + 1));
-            notify(current);
+            notify(cms.metadata().forceEpoch(Epoch.create(cms.metadata().epoch.getEpoch() + 1)));
         }
 
         private void notify(ClusterMetadata current)
         {
-            Ranges ranges = AccordTopology.createAccordTopology(current).ranges().mergeTouching();
-            if (!current.directory.isEmpty())
+            Topology t = AccordTopology.createAccordTopology(current);
+            Ranges ranges = t.ranges().mergeTouching();
+            if (!current.placements.get(replication_params).reads.isEmpty())
                 Assertions.assertThat(ranges).hasSize(1);
-            ((StubClusterMetadataService) ClusterMetadataService.instance()).setMetadata(current);
-            for (Node.Id id : alive())
+            cms.setMetadata(current);
+            for (Node.Id id : status(s -> s != Status.Removed))
             {
                 Instance inst = instances.get(id);
-                inst.maybeStart();
+                inst.maybeTransition(current, t);
                 inst.config.maybeReportMetadata(current);
             }
         }
@@ -555,7 +648,7 @@ public class EpochSyncTest
             };
         }
 
-        private enum Status { Init, Started}
+        private enum Status { Init, Registered, Joining, Joined, Leaving, Removed}
         private class Instance
         {
             private final Node.Id id;
@@ -634,12 +727,47 @@ public class EpochSyncTest
                 this.reciver = messagingService.receiver(new SimulatedMessageDelivery.SimpleVerbHandler(handlers));
             }
 
-            void maybeStart()
+            @Override
+            public String toString()
+            {
+                return "Instance{" +
+                       "id=" + id +
+                       ", token=" + token +
+                       ", epoch=" + epoch +
+                       ", status=" + status +
+                       '}';
+            }
+
+            void maybeTransition(ClusterMetadata current, Topology t)
             {
-                if (status == Status.Init)
+                switch (status)
                 {
-                    start();
-                    status = Status.Started;
+                    case Init:
+                        Invariants.checkState(!t.nodes().contains(id), "Node was in Init state but present in the Topology!");
+                        Invariants.checkState(current.directory.peerId(address(id)) != null, "Node exists but not in TCM");
+                        start();
+                        status = Status.Registered;
+                        break;
+                    case Registered:
+                        Invariants.checkState(!t.nodes().contains(id), "Node was in Init state but present in the Topology!");
+                        Invariants.checkState(current.directory.peerId(address(id)) != null, "Node exists but not in TCM");
+                        if (current.placements.get(replication_params).writes.byEndpoint().keySet().contains(address(id)))
+                            status = Status.Joining;
+                        break;
+                    case Joining:
+                        Invariants.checkState(current.directory.peerId(address(id)) != null, "Node exists but not in TCM");
+                        if (joined(current, id))
+                            status = Status.Joined;
+                    case Removed:
+                    case Joined:
+                        // nothing to do
+                        break;
+                    case Leaving:
+                        if (left(current, id))
+                            stop();
+                        break;
+                    default:
+                        throw new UnsupportedOperationException("Unknown status: " + status);
                 }
             }
 
@@ -653,20 +781,6 @@ public class EpochSyncTest
                 return topology;
             }
 
-            Collection<Replica> replica()
-            {
-                InetAddressAndPort address = Cluster.address(id);
-                SortedSet<Long> lessThan = tokens.headSet(token);
-                if (lessThan.isEmpty())
-                {
-                    // wrap around
-                    return Arrays.asList(new Replica(address, new LongToken(Long.MIN_VALUE), new LongToken(token), true),
-                                         new Replica(address, new LongToken(tokens.last()), new LongToken(Long.MIN_VALUE), true));
-                }
-
-                return Collections.singletonList(new Replica(address, new LongToken(lessThan.last()), new LongToken(token), true));
-            }
-
             Set<EpochTracker> synced(long epoch)
             {
                 if (epoch < this.epoch.getEpoch()) throw new IllegalArgumentException("Asked for epoch before this instance existed");
@@ -683,6 +797,8 @@ public class EpochSyncTest
 
             void stop()
             {
+                status = Status.Removed;
+                tokens.remove(token);
                 messaging.stop();
             }
         }
diff --git a/test/unit/org/apache/cassandra/service/accord/FetchMinEpochTest.java b/test/unit/org/apache/cassandra/service/accord/FetchMinEpochTest.java
new file mode 100644
index 0000000000..53319a7ec2
--- /dev/null
+++ b/test/unit/org/apache/cassandra/service/accord/FetchMinEpochTest.java
@@ -0,0 +1,284 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.accord;
+
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ExecutionException;
+import java.util.function.Supplier;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
+
+import com.google.common.collect.ImmutableMap;
+import org.junit.Assert;
+import org.junit.Test;
+
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.RandomSource;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.config.RetrySpec;
+import org.apache.cassandra.dht.IPartitioner;
+import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.io.IVersionedSerializers;
+import org.apache.cassandra.io.util.DataOutputBuffer;
+import org.apache.cassandra.locator.InetAddressAndPort;
+import org.apache.cassandra.net.MessageDelivery;
+import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.SimulatedMessageDelivery.Action;
+import org.apache.cassandra.service.accord.api.AccordRoutingKey;
+import org.apache.cassandra.utils.AccordGenerators;
+import org.apache.cassandra.utils.CassandraGenerators;
+import org.apache.cassandra.utils.SimulatedMiniCluster;
+import org.apache.cassandra.utils.SimulatedMiniCluster.Node;
+import org.apache.cassandra.utils.concurrent.Future;
+import org.assertj.core.api.Assertions;
+
+import static accord.utils.Property.qt;
+import static org.apache.cassandra.net.MessagingService.Version.VERSION_51;
+import static org.apache.cassandra.utils.AccordGenerators.fromQT;
+import static org.assertj.core.api.Assertions.assertThat;
+
+public class FetchMinEpochTest
+{
+    static
+    {
+        DatabaseDescriptor.clientInitialization();
+        DatabaseDescriptor.setPartitionerUnsafe(Murmur3Partitioner.instance);
+    }
+
+    private static final Gen<Gen<Action>> ACTION_DISTRIBUTION = Gens.enums().allMixedDistribution(Action.class);
+    private static final List<MessagingService.Version> SUPPORTED = Stream.of(MessagingService.Version.values()).filter(v -> v.compareTo(VERSION_51) >= 0).collect(Collectors.toList());
+
+    private static void boundedRetries(int retries)
+    {
+        DatabaseDescriptor.getAccord().minEpochSyncRetry.maxAttempts = new RetrySpec.MaxAttempt(retries);
+    }
+
+    @Test
+    public void requestSerde()
+    {
+        DataOutputBuffer output = new DataOutputBuffer();
+        Gen<FetchMinEpoch> gen = fromQT(CassandraGenerators.partitioners())
+                                 .map(CassandraGenerators::simplify)
+                                 .flatMap(partitioner ->
+                                          Gens.lists(AccordGenerators.range(partitioner)
+                                                                     .map(r -> (TokenRange) r))
+                                              .ofSizeBetween(0, 10)
+                                              .map(FetchMinEpoch::new));
+        qt().forAll(gen).check(req -> {
+            maybeSetPartitioner(req);
+            for (MessagingService.Version version : SUPPORTED)
+                IVersionedSerializers.testSerde(output, FetchMinEpoch.serializer, req, version.value);
+        });
+    }
+
+    @Test
+    public void responseSerde()
+    {
+        Gen<Long> all = Gens.longs().all();
+        Gen<Long> nulls = ignore -> null;
+        Gen<Long> domain = rs -> rs.nextBoolean() ? nulls.next(rs) : all.next(rs);
+        DataOutputBuffer output = new DataOutputBuffer();
+        qt().forAll(domain.map(FetchMinEpoch.Response::new)).check(rsp -> {
+            for (MessagingService.Version version : SUPPORTED)
+                IVersionedSerializers.testSerde(output, FetchMinEpoch.Response.serializer, rsp, version.value);
+        });
+    }
+
+    @Test
+    public void fetchOneNodeAlwaysFails()
+    {
+        int expectedMaxAttempts = 3;
+        boundedRetries(expectedMaxAttempts);
+        qt().check(rs -> {
+            SimulatedMiniCluster cluster = new SimulatedMiniCluster.Builder(rs, node -> msg -> {throw new IllegalStateException();}).build();
+            Node from = cluster.createNodeAndJoin();
+            Node to = cluster.createNodeAndJoin();
+
+            Future<Long> f = FetchMinEpoch.fetch(from, to.broadcastAddressAndPort(), Collections.emptySet());
+            assertThat(f).isNotDone();
+            cluster.processAll();
+            assertThat(f).isDone();
+            MessageDelivery.MaxRetriesException maxRetries = getMaxRetriesException(f);
+            Assertions.assertThat(maxRetries.attempts).isEqualTo(expectedMaxAttempts);
+        });
+    }
+
+    @Test
+    public void fetchOneNode()
+    {
+        int maxRetries = 42;
+        boundedRetries(maxRetries);
+        qt().check(rs -> {
+            long epoch = rs.nextLong(0, Long.MAX_VALUE);
+            SimulatedMiniCluster cluster = new SimulatedMiniCluster.Builder(rs, node -> msg -> node.messaging().respond(new FetchMinEpoch.Response(epoch), msg)).build();
+            Node from = cluster.createNodeAndJoin();
+            {
+                Supplier<Action> safeActionGen = actionGen(rs, maxRetries);
+                from.messagingActions((self, msg, to) -> safeActionGen.get());
+            }
+            Node to = cluster.createNodeAndJoin();
+
+            Future<Long> f = FetchMinEpoch.fetch(from, to.broadcastAddressAndPort(), Collections.emptySet());
+            assertThat(f).isNotDone();
+            cluster.processAll();
+            assertThat(f).isDone();
+            assertThat(f.get()).isEqualTo(epoch);
+        });
+    }
+
+    @Test
+    public void fetchManyNodesAllNodesFail()
+    {
+        int expectedMaxAttempts = 3;
+        boundedRetries(expectedMaxAttempts);
+        qt().check(rs -> {
+            SimulatedMiniCluster cluster = new SimulatedMiniCluster.Builder(rs, node -> msg -> {throw new IllegalStateException();}).build();
+
+            Node from = cluster.createNodeAndJoin();
+            Node to1 = cluster.createNodeAndJoin();
+            Node to2 = cluster.createNodeAndJoin();
+            Node to3 = cluster.createNodeAndJoin();
+            Node to4 = cluster.createNodeAndJoin();
+
+            Future<Long> f = FetchMinEpoch.fetch(from, ImmutableMap.of(to1.broadcastAddressAndPort(), Collections.emptySet(),
+                                                                       to2.broadcastAddressAndPort(), Collections.emptySet(),
+                                                                       to3.broadcastAddressAndPort(), Collections.emptySet(),
+                                                                       to4.broadcastAddressAndPort(), Collections.emptySet()));
+            assertThat(f).isNotDone();
+            cluster.processAll();
+            assertThat(f).isDone();
+            assertThat(f.get()).isNull();
+        });
+    }
+
+    @Test
+    public void fetchManyNodes()
+    {
+        boundedRetries(Integer.MAX_VALUE); // networking should be unbounded, but the actions should be bounded
+        int maxRetries = 3;
+        qt().check(rs -> {
+            Map<Integer, Long> nodeToEpoch = new HashMap<>();
+            Long min = null;
+            for (int i = 2; i < 6; i++)
+            {
+                Long epoch = rs.nextBoolean() ? null : rs.nextLong();
+                nodeToEpoch.put(i, epoch);
+                if (min == null)        min = epoch;
+                else if (epoch != null) min = Math.min(min, epoch);
+            }
+
+            SimulatedMiniCluster cluster = new SimulatedMiniCluster.Builder(rs, node -> msg -> node.messaging().respond(new FetchMinEpoch.Response(nodeToEpoch.get(node.id().id())), msg)).build();
+
+            Node from = cluster.createNodeAndJoin();
+            Node to1 = cluster.createNodeAndJoin();
+            Node to2 = cluster.createNodeAndJoin();
+            Node to3 = cluster.createNodeAndJoin();
+            Node to4 = cluster.createNodeAndJoin();
+            Map<InetAddressAndPort, Supplier<Action>> nodeToActions = ImmutableMap.of(to1.broadcastAddressAndPort(), actionGen(rs, maxRetries),
+                                                                                      to2.broadcastAddressAndPort(), actionGen(rs, maxRetries),
+                                                                                      to3.broadcastAddressAndPort(), actionGen(rs, maxRetries),
+                                                                                      to4.broadcastAddressAndPort(), actionGen(rs, maxRetries));
+            from.messagingActions((self, msg, to) -> nodeToActions.get(to).get());
+
+            Future<Long> f = FetchMinEpoch.fetch(from, ImmutableMap.of(to1.broadcastAddressAndPort(), Collections.emptySet(),
+                                                                       to2.broadcastAddressAndPort(), Collections.emptySet(),
+                                                                       to3.broadcastAddressAndPort(), Collections.emptySet(),
+                                                                       to4.broadcastAddressAndPort(), Collections.emptySet()));
+            assertThat(f).isNotDone();
+            cluster.processAll();
+            assertThat(f).isDone();
+            assertThat(f.get()).isEqualTo(min);
+        });
+    }
+
+    private static Supplier<Action> actionGen(RandomSource rs, int maxRetries)
+    {
+        RandomSource actionSource = rs.fork();
+        Gen<Action> actionGen = ACTION_DISTRIBUTION.next(actionSource);
+        // it is very possible that DELIVER is very rare, which will cause the test to run for a long time and could fail in CI,
+        // when a long history of non-DELIVER is seen, start to force DELIVER to bound the amount of processing in the test
+        Gen<Action> safeActionGen = new Gen<>()
+        {
+            private int notDelivers = 0;
+            @Override
+            public Action next(RandomSource rng)
+            {
+                if (notDelivers > maxRetries - 1)
+                    return Action.DELIVER;
+                Action action = actionGen.next(rng);
+                if (action == Action.DELIVER) notDelivers = 0;
+                else notDelivers++;
+                return action;
+            }
+        };
+        return safeActionGen.asSupplier(actionSource);
+    }
+
+    private static void maybeSetPartitioner(FetchMinEpoch req)
+    {
+        IPartitioner partitioner = null;
+        for (TokenRange r : req.ranges)
+        {
+            IPartitioner rangePartitioner = null;
+            if (r.start().kindOfRoutingKey() == AccordRoutingKey.RoutingKeyKind.TOKEN)
+                rangePartitioner = r.start().token().getPartitioner();
+            if (rangePartitioner == null && r.end().kindOfRoutingKey() == AccordRoutingKey.RoutingKeyKind.TOKEN)
+                rangePartitioner = r.end().token().getPartitioner();
+            if (rangePartitioner == null)
+                continue;
+            if (partitioner == null)
+            {
+                partitioner = rangePartitioner;
+            }
+            else
+            {
+                Assertions.assertThat(rangePartitioner).isEqualTo(partitioner);
+            }
+        }
+        if (partitioner != null)
+            DatabaseDescriptor.setPartitionerUnsafe(partitioner);
+    }
+
+    private static MessageDelivery.MaxRetriesException getMaxRetriesException(Future<Long> f) throws InterruptedException, ExecutionException
+    {
+        MessageDelivery.MaxRetriesException maxRetries;
+        try
+        {
+            f.get();
+            Assert.fail("Future should have failed");
+            throw new AssertionError("Unreachable");
+        }
+        catch (ExecutionException e)
+        {
+            if (e.getCause() instanceof MessageDelivery.MaxRetriesException)
+            {
+                maxRetries = (MessageDelivery.MaxRetriesException) e.getCause();
+            }
+            else
+            {
+                throw e;
+            }
+        }
+        return maxRetries;
+    }
+}
\ No newline at end of file
diff --git a/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java b/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java
index cb8929bf37..68eadd0d1b 100644
--- a/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java
+++ b/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java
@@ -102,7 +102,7 @@ public class SimulatedAccordCommandStore implements AutoCloseable
 
     public SimulatedAccordCommandStore(RandomSource rs)
     {
-        globalExecutor = new SimulatedExecutorFactory(accord.utilsfork.RandomSource.wrap(rs).fork(), fromQT(Generators.TIMESTAMP_GEN.map(java.sql.Timestamp::getTime)).mapToLong(TimeUnit.MILLISECONDS::toNanos).next(rs), failures::add);
+        globalExecutor = new SimulatedExecutorFactory(rs.fork(), fromQT(Generators.TIMESTAMP_GEN.map(java.sql.Timestamp::getTime)).mapToLong(TimeUnit.MILLISECONDS::toNanos).next(rs), failures::add);
         this.unorderedScheduled = globalExecutor.scheduled("ignored");
         ExecutorFactory.Global.unsafeSet(globalExecutor);
         Stage.READ.unsafeSetExecutor(unorderedScheduled);
diff --git a/test/unit/org/apache/cassandra/service/accord/async/AsyncOperationTest.java b/test/unit/org/apache/cassandra/service/accord/async/AsyncOperationTest.java
index 4d4424e1b2..aca8702454 100644
--- a/test/unit/org/apache/cassandra/service/accord/async/AsyncOperationTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/async/AsyncOperationTest.java
@@ -303,7 +303,7 @@ public class AsyncOperationTest
     @Test
     public void testFutureCleanup() throws Throwable
     {
-        SimulatedExecutorFactory factory = new SimulatedExecutorFactory(accord.utilsfork.RandomSource.wrap(new DefaultRandom(42)), 42);
+        SimulatedExecutorFactory factory = new SimulatedExecutorFactory(new DefaultRandom(42), 42);
         AccordCommandStore commandStore = createAccordCommandStore(clock::incrementAndGet, "ks", "tbl", factory.scheduled("ignored"), Stage.MUTATION.executor());
 
         TxnId txnId = txnId(1, clock.incrementAndGet(), 1);
diff --git a/test/unit/org/apache/cassandra/service/accord/serializers/AccordRoutingKeyByteSourceTest.java b/test/unit/org/apache/cassandra/service/accord/serializers/AccordRoutingKeyByteSourceTest.java
index aaa1db454d..78dcb5b70c 100644
--- a/test/unit/org/apache/cassandra/service/accord/serializers/AccordRoutingKeyByteSourceTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/serializers/AccordRoutingKeyByteSourceTest.java
@@ -49,7 +49,7 @@ public class AccordRoutingKeyByteSourceTest
     @Test
     public void tokenSerde()
     {
-        qt().forAll(fromQT(token())).check(token -> {
+        qt().forAll(fromQT(CassandraGenerators.partitioners().map(CassandraGenerators::simplify).flatMap(CassandraGenerators::token))).check(token -> {
             var serializer = AccordRoutingKeyByteSource.create(token.getPartitioner());
             byte[] min = ByteSourceInverse.readBytes(serializer.minAsComparableBytes());
             byte[] max = ByteSourceInverse.readBytes(serializer.maxAsComparableBytes());
diff --git a/test/unit/org/apache/cassandra/service/accord/serializers/DepsSerializerTest.java b/test/unit/org/apache/cassandra/service/accord/serializers/DepsSerializerTest.java
index 4238f8a687..5283a8b6ea 100644
--- a/test/unit/org/apache/cassandra/service/accord/serializers/DepsSerializerTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/serializers/DepsSerializerTest.java
@@ -24,18 +24,15 @@ import org.junit.Test;
 
 import accord.primitives.Deps;
 import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.db.marshal.AbstractType;
-import org.apache.cassandra.db.marshal.Int32Type;
 import org.apache.cassandra.dht.IPartitioner;
-import org.apache.cassandra.dht.LocalPartitioner;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.io.IVersionedSerializers;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaProvider;
-import org.apache.cassandra.utils.AbstractTypeGenerators;
 import org.apache.cassandra.utils.AccordGenerators;
+import org.apache.cassandra.utils.CassandraGenerators;
 import org.mockito.Mockito;
 
 import static accord.utils.Property.qt;
@@ -56,7 +53,7 @@ public class DepsSerializerTest
     {
         DataOutputBuffer buffer = new DataOutputBuffer();
         qt().check(rs -> {
-            IPartitioner partitioner = AccordGenerators.partitioner().map(DepsSerializerTest::normalize).next(rs);
+            IPartitioner partitioner = AccordGenerators.partitioner().map(CassandraGenerators::simplify).next(rs);
             Schema.instance = Mockito.mock(SchemaProvider.class);
             DatabaseDescriptor.setPartitionerUnsafe(partitioner);
             Mockito.when(Schema.instance.getExistingTablePartitioner(Mockito.any())).thenReturn(partitioner);
@@ -65,17 +62,4 @@ public class DepsSerializerTest
                 IVersionedSerializers.testSerde(buffer, DepsSerializer.deps, deps, version.value);
         });
     }
-
-    private static IPartitioner normalize(IPartitioner partitioner)
-    {
-        // serializers require tokens to fit within 1 << 16, but that makes the test flakey when LocalPartitioner with a nested type is found...
-        if (!(partitioner instanceof LocalPartitioner)) return partitioner;
-        if (!shouldSimplify(partitioner.getTokenValidator())) return partitioner;
-        return new LocalPartitioner(Int32Type.instance);
-    }
-
-    private static boolean shouldSimplify(AbstractType<?> type)
-    {
-        return AbstractTypeGenerators.contains(type, t -> t.isCollection());
-    }
 }
\ No newline at end of file
diff --git a/test/unit/org/apache/cassandra/tcm/ClusterMetadataMetadataKeyTest.java b/test/unit/org/apache/cassandra/tcm/ClusterMetadataMetadataKeyTest.java
new file mode 100644
index 0000000000..291be79bf4
--- /dev/null
+++ b/test/unit/org/apache/cassandra/tcm/ClusterMetadataMetadataKeyTest.java
@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.tcm;
+
+import java.lang.reflect.Field;
+import java.lang.reflect.Modifier;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
+
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.ImmutableSet;
+import org.junit.Test;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.utils.FBUtilities;
+import org.assertj.core.api.Assertions;
+
+/**
+ * This test is to make sure that the fields of {@link ClusterMetadata} have a matching {@link MetadataKey} and the
+ * utility functions linking key to field are maintained.
+ *
+ * If this test is failing it likely means a new field was added to {@link ClusterMetadata} and {@link MetadataKeys} was
+ * not updated to know about it.
+ */
+public class ClusterMetadataMetadataKeyTest
+{
+    static
+    {
+        DatabaseDescriptor.clientInitialization();
+    }
+
+    private static final Map<String, Field> NAME_TO_KEY;
+
+    static
+    {
+        ImmutableMap.Builder<String, Field> builder = ImmutableMap.builder();
+        for (Field field : MetadataKeys.class.getDeclaredFields())
+        {
+            if (field.getType() == MetadataKey.class
+                && Modifier.isStatic(field.getModifiers())
+                && Modifier.isPublic(field.getModifiers()))
+                builder.put(field.getName(), field);
+        }
+        NAME_TO_KEY = builder.build();
+    }
+
+    @Test
+    public void metadataKeyExists() throws IllegalAccessException
+    {
+        ClusterMetadata empty = new ClusterMetadata(Murmur3Partitioner.instance);
+        // Theese are fields that should not have MetadataKeys and should be ignored.
+        Set<String> exclude = ImmutableSet.of("metadataIdentifier",
+                                              "epoch",
+                                              "partitioner",
+                                              "extensions",
+                                              "locator");
+        // Mapping of ClusterMetadata field names to MetadataKey name; mapping is only needed if the names don't match.
+        Map<String, String> mapping = ImmutableMap.of("directory", "node_directory",
+                                                      "placements", "data_placements");
+        for (Field field : ClusterMetadata.class.getDeclaredFields())
+        {
+            if (Modifier.isStatic(field.getModifiers())
+                || !Modifier.isPublic(field.getModifiers())
+                || !Modifier.isFinal(field.getModifiers()))
+                continue;
+            String name = field.getName();
+            if (exclude.contains(name)) continue;
+            if (mapping.containsKey(name))
+                name = mapping.get(name);
+            String snakeName = FBUtilities.camelToSnake(name).toUpperCase(Locale.ROOT);
+            Assertions.assertThat(NAME_TO_KEY.keySet())
+                      .describedAs("Unable to locate MetadataKey for %s", snakeName)
+                      .contains(snakeName);
+            MetadataKey expectedKey = (MetadataKey) NAME_TO_KEY.get(snakeName).get(null);
+            if (!MetadataKeys.CORE_METADATA.containsKey(expectedKey))
+                throw new IllegalStateException("MetadataKeys.CORE_METADATA is missing key " + expectedKey + " for field " + name);
+
+            Assertions.assertThat(field.get(empty))
+                      .describedAs("Extraction function does not seem to match the field %s and key %s", name, snakeName)
+                      .isSameAs(MetadataKeys.CORE_METADATA.get(expectedKey).apply(empty));
+        }
+    }
+}
diff --git a/test/unit/org/apache/cassandra/tcm/ClusterMetadataSerializerTest.java b/test/unit/org/apache/cassandra/tcm/ClusterMetadataSerializerTest.java
new file mode 100644
index 0000000000..1117b4ab88
--- /dev/null
+++ b/test/unit/org/apache/cassandra/tcm/ClusterMetadataSerializerTest.java
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.tcm;
+
+import org.junit.Test;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.io.util.DataInputBuffer;
+import org.apache.cassandra.io.util.DataOutputBuffer;
+import org.apache.cassandra.service.accord.AccordFastPath;
+import org.apache.cassandra.service.accord.AccordStaleReplicas;
+import org.apache.cassandra.service.consensus.migration.ConsensusMigrationState;
+import org.apache.cassandra.tcm.membership.NodeVersion;
+import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializers;
+import org.apache.cassandra.tcm.serialization.Version;
+import org.apache.cassandra.utils.CassandraGenerators.ClusterMetadataBuilder;
+import org.assertj.core.api.Assertions;
+import org.quicktheories.core.Gen;
+
+import static org.apache.cassandra.utils.FailingConsumer.orFail;
+import static org.quicktheories.QuickTheory.qt;
+
+public class ClusterMetadataSerializerTest
+{
+    static
+    {
+        DatabaseDescriptor.clientInitialization();
+    }
+
+    @Test
+    public void serdeLatest()
+    {
+        DataOutputBuffer output = new DataOutputBuffer();
+        qt().forAll(new ClusterMetadataBuilder().build()).checkAssert(orFail(cm -> {
+            AsymmetricMetadataSerializers.testSerde(output, ClusterMetadata.serializer, cm, NodeVersion.CURRENT_METADATA_VERSION);
+        }));
+    }
+
+    @Test
+    public void serdeWithoutAccord()
+    {
+        DataOutputBuffer output = new DataOutputBuffer();
+        Gen<ClusterMetadata> gen = new ClusterMetadataBuilder().build().assuming(cm -> {
+            if (!cm.consensusMigrationState.equals(ConsensusMigrationState.EMPTY))
+                return true;
+            if (!cm.accordStaleReplicas.equals(AccordStaleReplicas.EMPTY))
+                return true;
+            if (!cm.accordFastPath.equals(AccordFastPath.EMPTY))
+                return true;
+            return false;
+        });
+        qt().forAll(gen).checkAssert(orFail(cm -> {
+            output.clear();
+            Version version = Version.V2; // this is the version before accord
+            long expectedSize = ClusterMetadata.serializer.serializedSize(cm, version);
+            ClusterMetadata.serializer.serialize(cm, output, version);
+            Assertions.assertThat(output.getLength()).describedAs("The serialized size and bytes written do not match").isEqualTo(expectedSize);
+            DataInputBuffer in = new DataInputBuffer(output.unsafeGetBufferAndFlip(), false);
+            ClusterMetadata read = ClusterMetadata.serializer.deserialize(in, version);
+            Assertions.assertThat(read).isNotEqualTo(cm);
+
+            Assertions.assertThat(read.consensusMigrationState).isEqualTo(ConsensusMigrationState.EMPTY);
+            Assertions.assertThat(read.accordStaleReplicas).isEqualTo(AccordStaleReplicas.EMPTY);
+            Assertions.assertThat(read.accordFastPath).isEqualTo(AccordFastPath.EMPTY);
+        }));
+    }
+}
diff --git a/test/unit/org/apache/cassandra/tcm/ClusterMetadataTransformationTest.java b/test/unit/org/apache/cassandra/tcm/ClusterMetadataTransformationTest.java
index 1219502e98..cf8bdcb79c 100644
--- a/test/unit/org/apache/cassandra/tcm/ClusterMetadataTransformationTest.java
+++ b/test/unit/org/apache/cassandra/tcm/ClusterMetadataTransformationTest.java
@@ -267,7 +267,7 @@ public class ClusterMetadataTransformationTest
         // anything modified by in this transformation, and therefore included in the modified keys,
         // should have the same epoch as the CM itself. Anything not modified now must have a strictly
         // earlier epoch
-        for (MetadataKey key : Iterables.concat(MetadataKeys.CORE_METADATA, transformed.metadata.extensions.keySet()))
+        for (MetadataKey key : Iterables.concat(MetadataKeys.CORE_METADATA.keySet(), transformed.metadata.extensions.keySet()))
         {
             MetadataValue<?> value = valueFor(key, transformed.metadata);
             if (transformed.modifiedKeys.contains(key))
@@ -279,7 +279,7 @@ public class ClusterMetadataTransformationTest
 
     private static MetadataValue<?> valueFor(MetadataKey key, ClusterMetadata metadata)
     {
-        if (!MetadataKeys.CORE_METADATA.contains(key))
+        if (!MetadataKeys.CORE_METADATA.containsKey(key))
         {
             assert key instanceof ExtensionKey<?,?>;
             return metadata.extensions.get((ExtensionKey<?, ?>)key);
diff --git a/test/unit/org/apache/cassandra/tcm/ValidatingClusterMetadataService.java b/test/unit/org/apache/cassandra/tcm/ValidatingClusterMetadataService.java
new file mode 100644
index 0000000000..fd37346aa0
--- /dev/null
+++ b/test/unit/org/apache/cassandra/tcm/ValidatingClusterMetadataService.java
@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.tcm;
+
+import java.io.IOException;
+import java.util.List;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.dht.IPartitioner;
+import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.io.util.DataOutputBuffer;
+import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializer;
+import org.apache.cassandra.tcm.serialization.AsymmetricMetadataSerializers;
+import org.apache.cassandra.tcm.serialization.Version;
+import org.assertj.core.api.Assertions;
+
+public class ValidatingClusterMetadataService extends StubClusterMetadataService
+{
+    private final List<Version> supportedVersions;
+
+    private ValidatingClusterMetadataService(List<Version> supportedVersions)
+    {
+        super(new ClusterMetadata(safeGetPartitioner()));
+        this.supportedVersions = supportedVersions;
+    }
+
+    public static ValidatingClusterMetadataService createAndRegister(Version minVersion)
+    {
+        return createAndRegister(minVersion.greaterThanOrEqual());
+    }
+
+    public static ValidatingClusterMetadataService createAndRegister(List<Version> supportedVersions)
+    {
+        ValidatingClusterMetadataService cms = new ValidatingClusterMetadataService(supportedVersions);
+
+        ClusterMetadataService.unsetInstance();
+        ClusterMetadataService.setInstance(cms);
+        return cms;
+    }
+
+    private static IPartitioner safeGetPartitioner()
+    {
+        IPartitioner partitioner = DatabaseDescriptor.getPartitioner();
+        return partitioner == null ? Murmur3Partitioner.instance : partitioner;
+    }
+
+    private <In, Out> void testSerde(AsymmetricMetadataSerializer<In, Out> serializer, In input)
+    {
+        for (Version version : supportedVersions)
+        {
+            try (DataOutputBuffer buffer = DataOutputBuffer.scratchBuffer.get())
+            {
+                AsymmetricMetadataSerializers.testSerde(buffer, serializer, input, version);
+            }
+            catch (IOException e)
+            {
+                throw new AssertionError(String.format("Serde error for version=%s; input=%s", version, input), e);
+            }
+        }
+    }
+
+    @Override
+    protected Transformation.Result execute(Transformation transform)
+    {
+        Transformation.Result result = super.execute(transform);
+        if (result.isSuccess())
+        {
+            Transformation.Success success = result.success();
+            Assertions.assertThat(success.affectedMetadata)
+                      .describedAs("Affected Metadata keys do not match")
+                      .isEqualTo(MetadataKeys.diffKeys(metadata(), success.metadata));
+        }
+        return result;
+    }
+
+    @Override
+    public <T1> T1 commit(Transformation transform, CommitSuccessHandler<T1> onSuccess, CommitFailureHandler<T1> onFailure)
+    {
+        testSerde(transform.kind().serializer(), transform);
+        return super.commit(transform, onSuccess, onFailure);
+    }
+
+    @Override
+    public void setMetadata(ClusterMetadata metadata)
+    {
+        if (!metadata.epoch.equals(metadata().epoch.nextEpoch()))
+            throw new AssertionError("Epochs were not sequential: expected " + metadata().epoch.nextEpoch() + " but given " + metadata.epoch);
+        testSerde(ClusterMetadata.serializer, metadata);
+        super.setMetadata(metadata);
+    }
+}
diff --git a/test/unit/org/apache/cassandra/tcm/log/LogListenerNotificationTest.java b/test/unit/org/apache/cassandra/tcm/log/LogListenerNotificationTest.java
index 59aafa37e0..55df4e868e 100644
--- a/test/unit/org/apache/cassandra/tcm/log/LogListenerNotificationTest.java
+++ b/test/unit/org/apache/cassandra/tcm/log/LogListenerNotificationTest.java
@@ -111,7 +111,7 @@ public class LogListenerNotificationTest
 
     static Set<MetadataKey> affectedMetadata(Random random)
     {
-        List<MetadataKey> src = new ArrayList<>(CORE_METADATA);
+        List<MetadataKey> src = new ArrayList<>(CORE_METADATA.keySet());
         int required = random.nextInt(src.size());
         Set<MetadataKey> keys = new HashSet<>();
         while (keys.size() < required)
diff --git a/test/unit/org/apache/cassandra/tcm/sequences/DropAccordTableTest.java b/test/unit/org/apache/cassandra/tcm/sequences/DropAccordTableTest.java
new file mode 100644
index 0000000000..8b18368809
--- /dev/null
+++ b/test/unit/org/apache/cassandra/tcm/sequences/DropAccordTableTest.java
@@ -0,0 +1,223 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.tcm.sequences;
+
+import java.util.TreeSet;
+import java.util.stream.Stream;
+
+import org.junit.Test;
+
+import accord.utils.Gen;
+import accord.utils.Property;
+import accord.utils.Property.Command;
+import accord.utils.RandomSource;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.locator.MetaStrategy;
+import org.apache.cassandra.schema.DistributedSchema;
+import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.KeyspaceParams;
+import org.apache.cassandra.schema.Keyspaces;
+import org.apache.cassandra.schema.TableId;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.schema.Types;
+import org.apache.cassandra.service.consensus.TransactionalMode;
+import org.apache.cassandra.tcm.ClusterMetadata;
+import org.apache.cassandra.tcm.ClusterMetadataService;
+import org.apache.cassandra.tcm.MultiStepOperation;
+import org.apache.cassandra.tcm.StubClusterMetadataService;
+import org.apache.cassandra.tcm.ValidatingClusterMetadataService;
+import org.apache.cassandra.tcm.serialization.Version;
+import org.apache.cassandra.tcm.transformations.PrepareDropAccordTable;
+import org.apache.cassandra.tcm.sequences.DropAccordTable.TableReference;
+import org.apache.cassandra.utils.AbstractTypeGenerators;
+import org.apache.cassandra.utils.CassandraGenerators;
+import org.apache.cassandra.utils.CassandraGenerators.TableMetadataBuilder;
+import org.apache.cassandra.utils.Generators;
+import org.assertj.core.api.Assertions;
+import org.quicktheories.generators.SourceDSL;
+
+import static accord.utils.Property.commands;
+import static accord.utils.Property.qt;
+import static accord.utils.Property.stateful;
+import static org.apache.cassandra.utils.CassandraGenerators.TABLE_ID_GEN;
+
+public class DropAccordTableTest
+{
+    static
+    {
+        DatabaseDescriptor.clientInitialization();
+    }
+
+    private static final TransactionalMode[] ACCORD_ENABLED_MODES = Stream.of(TransactionalMode.values())
+                                                                          .filter(t -> t.accordIsEnabled)
+                                                                          .toArray(TransactionalMode[]::new);
+
+    private static final Gen<TableMetadata> TABLE_GEN = Generators.toGen(defaultTableMetadataBuilder().build());
+
+    private static TableMetadataBuilder defaultTableMetadataBuilder()
+    {
+        return new TableMetadataBuilder()
+               .withUseCounter(false)
+               .withPartitioner(Murmur3Partitioner.instance)
+               .withTransactionalMode(SourceDSL.arbitrary().pick(ACCORD_ENABLED_MODES));
+    }
+
+    @Test
+    public void e2e()
+    {
+        qt().check(rs -> {
+            ValidatingClusterMetadataService cms = createCMS();
+            TableMetadata metadata = TABLE_GEN.next(rs);
+            addTable(cms, metadata); // hack this table into the schema...
+
+            TableReference table = TableReference.from(metadata);
+
+            cms.commit(new PrepareDropAccordTable(table));
+
+            // This is only here because "applyTo" is not touched without it...
+            for (KeyspaceMetadata ks : cms.metadata().schema.getKeyspaces())
+                cms.metadata().writePlacementAllSettled(ks);
+
+            Assertions.assertThat(cms.metadata().inProgressSequences.isEmpty()).isFalse();
+            InProgressSequences.finishInProgressSequences(table);
+            Assertions.assertThat(cms.metadata().inProgressSequences.isEmpty()).isTrue();
+
+            // table is dropped
+            Assertions.assertThat(cms.metadata().schema.getTableMetadata(metadata.id)).isNull();
+        });
+    }
+
+    @Test
+    public void multi()
+    {
+        stateful().withExamples(50).withSteps(500).check(commands(() -> State::new)
+                                                        .destroyState(DropAccordTableTest::validate)
+                                                        .add(DropAccordTableTest::addTable)
+                                                        .addIf(s -> !s.aliveTables.isEmpty(), DropAccordTableTest::dropTable)
+                                                        .addIf(s -> !s.cms.metadata().inProgressSequences.isEmpty(), DropAccordTableTest::inProgressSequences)
+                                                        .build());
+    }
+
+    private static void validate(State state)
+    {
+        while (!state.cms.metadata().inProgressSequences.isEmpty())
+        {
+            for (MultiStepOperation<?> opt : state.cms.metadata().inProgressSequences)
+                InProgressSequences.resume(opt);
+        }
+        // all tables are dropped, unless they were never dropped
+        Keyspaces keyspaces = state.cms.metadata().schema.getKeyspaces();
+        for (KeyspaceMetadata k : keyspaces)
+        {
+            if (k.tables.size() == 0) continue;
+            if (k.replicationStrategy instanceof MetaStrategy) continue;
+            for (TableMetadata t : k.tables)
+            {
+                Assertions.assertThat(t.params.pendingDrop).isFalse();
+                Assertions.assertThat(state.aliveTables).contains(t.id);
+            }
+        }
+    }
+
+    private static Command<State, Void, ?> addTable(RandomSource rs, State state)
+    {
+        TableMetadata metadata = Generators.toGen(defaultTableMetadataBuilder()
+                                                  .withKeyspaceName(CassandraGenerators.KEYSPACE_NAME_GEN.assuming(name -> !state.cms.metadata().schema.getKeyspaces().containsKeyspace(name)))
+                                                  .withTableId(TABLE_ID_GEN.assuming(id -> state.cms.metadata().schema.getTableMetadata(id) == null))
+                                                  // other tests better cover serialization so can speed up tests by only doing primitive types
+                                                  .withDefaultTypeGen(CassandraGenerators.TableMetadataBuilder.defaultTypeGen().withTypeKinds(AbstractTypeGenerators.TypeKind.PRIMITIVE))
+                                                  .build())
+                                           .next(rs);
+        return new Property.SimpleCommand<>("Add Table " + metadata, s2 -> {
+            addTable(s2.cms, metadata);
+            s2.aliveTables.add(metadata.id);
+        });
+    }
+
+    private static Command<State, Void, ?> dropTable(RandomSource rs, State state)
+    {
+        TableId id = rs.pickOrderedSet(state.aliveTables);
+        TableMetadata metadata = state.cms.metadata().schema.getTableMetadata(id);
+        return new Property.SimpleCommand<>("Drop Table " + metadata, s2 -> {
+            TableReference table = TableReference.from(metadata);
+
+            s2.cms.commit(new PrepareDropAccordTable(table));
+            s2.aliveTables.remove(id);
+        });
+    }
+
+    private static Command<State, Void, ?> inProgressSequences(RandomSource rs, State state)
+    {
+        ClusterMetadata current = state.cms.metadata();
+        TreeSet<TableReference> pending = new TreeSet<>();
+        for (MultiStepOperation<?> opt : current.inProgressSequences)
+        {
+            if (!(opt instanceof DropAccordTable)) throw new AssertionError("Only DropAccordTable should exist in this test; found " + opt);
+            pending.add(((DropAccordTable) opt).table);
+        }
+        TableReference ref = rs.pickOrderedSet(pending);
+        MultiStepOperation<?> seq = current.inProgressSequences.get(ref);
+        Assertions.assertThat(seq).isNotNull();
+        return new Property.SimpleCommand<>("Progress  for " + ref + ": " + seq.nextStep(), s2 -> InProgressSequences.resume(seq));
+    }
+
+    public static class State
+    {
+        private final StubClusterMetadataService cms;
+        private final TreeSet<TableId> aliveTables = new TreeSet<>();
+
+        public State(RandomSource rs)
+        {
+            // With validation enabled the test runtime is dominated by serialization checks, so enable them rarely
+            // just so tests do run with them, but the whole test runtime isn't serde testing.
+            if (rs.decide(0.01))
+            {
+                cms = ValidatingClusterMetadataService.createAndRegister(Version.MIN_ACCORD_VERSION);
+            }
+            else
+            {
+                cms = StubClusterMetadataService.forTesting(new ClusterMetadata(Murmur3Partitioner.instance));
+                ClusterMetadataService.unsetInstance();
+                ClusterMetadataService.setInstance(cms);
+            }
+        }
+    }
+
+    private static ValidatingClusterMetadataService createCMS()
+    {
+        return ValidatingClusterMetadataService.createAndRegister(Version.MIN_ACCORD_VERSION);
+    }
+
+    private static void addTable(StubClusterMetadataService cms, TableMetadata table)
+    {
+        class Ref { Types types;}
+        // first mock out a keyspace
+        ClusterMetadata prev = cms.metadata();
+        KeyspaceMetadata schema = KeyspaceMetadata.create(table.keyspace, KeyspaceParams.simple(3));
+        Ref ref = new Ref();
+        ref.types = schema.types;
+        CassandraGenerators.visitUDTs(table, udt -> ref.types = ref.types.with(udt.unfreeze()));
+        schema = schema.withSwapped(ref.types);
+        schema = schema.withSwapped(schema.tables.with(table));
+        Keyspaces keyspaces = prev.schema.getKeyspaces().withAddedOrUpdated(schema);
+        ClusterMetadata metadata = prev.transformer().with(new DistributedSchema(keyspaces)).build().metadata;
+        cms.setMetadata(metadata);
+    }
+}
\ No newline at end of file
diff --git a/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkRejoiningTest.java b/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkRejoiningTest.java
index 032c8dd1ec..32999a8aae 100644
--- a/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkRejoiningTest.java
+++ b/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkRejoiningTest.java
@@ -35,7 +35,7 @@ public class AccordMarkRejoiningTest
     public void shouldSerializeEmpty() throws IOException
     {
         DataOutputBuffer buffer = new DataOutputBuffer();
-        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkRejoining.serializer, new AccordMarkRejoining(Collections.emptySet()), Version.V2);
+        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkRejoining.serializer, new AccordMarkRejoining(Collections.emptySet()), Version.MIN_ACCORD_VERSION);
     }
 
     @Test
@@ -43,7 +43,7 @@ public class AccordMarkRejoiningTest
     {
         DataOutputBuffer buffer = new DataOutputBuffer();
         AccordMarkRejoining markStale = new AccordMarkRejoining(Collections.singleton(NodeId.fromString("1")));
-        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkRejoining.serializer, markStale, Version.V2);
+        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkRejoining.serializer, markStale, Version.MIN_ACCORD_VERSION);
     }
 
     @Test
@@ -51,6 +51,6 @@ public class AccordMarkRejoiningTest
     {
         DataOutputBuffer buffer = new DataOutputBuffer();
         AccordMarkRejoining markStale = new AccordMarkRejoining(ImmutableSet.of(NodeId.fromString("1"), NodeId.fromString("2")));
-        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkRejoining.serializer, markStale, Version.V2);
+        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkRejoining.serializer, markStale, Version.MIN_ACCORD_VERSION);
     }
 }
diff --git a/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkStaleTest.java b/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkStaleTest.java
index d794b3a2a9..baa4936a07 100644
--- a/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkStaleTest.java
+++ b/test/unit/org/apache/cassandra/tcm/transformations/AccordMarkStaleTest.java
@@ -35,7 +35,7 @@ public class AccordMarkStaleTest
     public void shouldSerializeEmpty() throws IOException
     {
         DataOutputBuffer buffer = new DataOutputBuffer();
-        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkStale.serializer, new AccordMarkStale(Collections.emptySet()), Version.V2);
+        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkStale.serializer, new AccordMarkStale(Collections.emptySet()), Version.MIN_ACCORD_VERSION);
     }
 
     @Test
@@ -43,7 +43,7 @@ public class AccordMarkStaleTest
     {
         DataOutputBuffer buffer = new DataOutputBuffer();
         AccordMarkStale markStale = new AccordMarkStale(Collections.singleton(NodeId.fromString("1")));
-        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkStale.serializer, markStale, Version.V2);
+        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkStale.serializer, markStale, Version.MIN_ACCORD_VERSION);
     }
 
     @Test
@@ -51,6 +51,6 @@ public class AccordMarkStaleTest
     {
         DataOutputBuffer buffer = new DataOutputBuffer();
         AccordMarkStale markStale = new AccordMarkStale(ImmutableSet.of(NodeId.fromString("1"), NodeId.fromString("2")));
-        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkStale.serializer, markStale, Version.V2);
+        AsymmetricMetadataSerializers.testSerde(buffer, AccordMarkStale.serializer, markStale, Version.MIN_ACCORD_VERSION);
     }
 }
diff --git a/test/unit/org/apache/cassandra/transport/CBUtilTest.java b/test/unit/org/apache/cassandra/transport/CBUtilTest.java
index 3ce8603078..4409655d33 100644
--- a/test/unit/org/apache/cassandra/transport/CBUtilTest.java
+++ b/test/unit/org/apache/cassandra/transport/CBUtilTest.java
@@ -22,13 +22,13 @@ import org.junit.After;
 import org.junit.Assert;
 import org.junit.Test;
 
-import accord.utilsfork.Gens;
+import accord.utils.Gens;
 import io.netty.buffer.ByteBuf;
 import io.netty.buffer.ByteBufAllocator;
 import io.netty.buffer.PooledByteBufAllocator;
 import org.assertj.core.api.Assertions;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 
 public class CBUtilTest
 {
diff --git a/test/unit/org/apache/cassandra/utils/AbstractTypeGeneratorsTest.java b/test/unit/org/apache/cassandra/utils/AbstractTypeGeneratorsTest.java
new file mode 100644
index 0000000000..2cd5470a6b
--- /dev/null
+++ b/test/unit/org/apache/cassandra/utils/AbstractTypeGeneratorsTest.java
@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.utils;
+
+import java.util.ArrayList;
+
+import org.junit.Test;
+
+import accord.utils.LazyToString;
+import org.apache.cassandra.db.marshal.AbstractType;
+import org.assertj.core.api.Assertions;
+import org.quicktheories.core.Gen;
+import org.quicktheories.generators.SourceDSL;
+
+import static org.quicktheories.QuickTheory.qt;
+
+public class AbstractTypeGeneratorsTest
+{
+    @Test
+    public void withoutPrimitive()
+    {
+        Gen<AbstractType<?>> primitiveGen = SourceDSL.arbitrary().pick(new ArrayList<>(AbstractTypeGenerators.primitiveTypes()));
+        qt().forAll(r -> r).checkAssert(rs -> {
+            AbstractType<?> primitiveType = primitiveGen.generate(rs);
+            Gen<AbstractType<?>> gen = AbstractTypeGenerators.builder().withoutPrimitive(primitiveType).build();
+            for (int i = 0; i < 1000; i++)
+            {
+                AbstractType<?> type = gen.generate(rs);
+                Assertions.assertThat(AbstractTypeGenerators.contains(type, primitiveType))
+                          .describedAs("Expected type %s not to be found in %s", primitiveType.asCQL3Type(), new LazyToString(() -> AbstractTypeGenerators.typeTree(type)))
+                          .isFalse();
+                if (type.subTypes().isEmpty())
+                    break; // not worth checking this type again...
+            }
+        });
+    }
+}
\ No newline at end of file
diff --git a/test/unit/org/apache/cassandra/utils/CassandraGenerators.java b/test/unit/org/apache/cassandra/utils/CassandraGenerators.java
index a114c4605e..469a486807 100644
--- a/test/unit/org/apache/cassandra/utils/CassandraGenerators.java
+++ b/test/unit/org/apache/cassandra/utils/CassandraGenerators.java
@@ -38,6 +38,7 @@ import java.util.Objects;
 import java.util.Set;
 import java.util.TreeMap;
 import java.util.UUID;
+import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
@@ -49,9 +50,19 @@ import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Sets;
+import org.apache.cassandra.schema.*;
+import org.apache.cassandra.service.consensus.migration.ConsensusMigrationState;
+import org.apache.cassandra.tcm.extensions.ExtensionKey;
+import org.apache.cassandra.tcm.extensions.ExtensionValue;
+import org.apache.cassandra.tcm.membership.Directory;
+import org.apache.cassandra.tcm.ownership.DataPlacements;
+import org.apache.cassandra.tcm.ownership.TokenMap;
+import org.apache.cassandra.tcm.sequences.InProgressSequences;
+import org.apache.cassandra.tcm.sequences.LockedRanges;
 import org.apache.commons.lang3.builder.MultilineRecursiveToStringStyle;
 import org.apache.commons.lang3.builder.ReflectionToStringBuilder;
 
+import accord.local.Node;
 import org.apache.cassandra.config.DataStorageSpec;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.cql3.ColumnIdentifier;
@@ -78,7 +89,6 @@ import org.apache.cassandra.db.rows.Cell;
 import org.apache.cassandra.db.marshal.UserType;
 import org.apache.cassandra.dht.ByteOrderedPartitioner;
 import org.apache.cassandra.dht.IPartitioner;
-import org.apache.cassandra.dht.LocalCompositePrefixPartitioner;
 import org.apache.cassandra.dht.LocalPartitioner;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.dht.OrderPreservingPartitioner;
@@ -105,22 +115,13 @@ import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.NoPayload;
 import org.apache.cassandra.net.PingRequest;
 import org.apache.cassandra.net.Verb;
-import org.apache.cassandra.schema.CachingParams;
-import org.apache.cassandra.schema.ColumnMetadata;
-import org.apache.cassandra.schema.CompactionParams;
-import org.apache.cassandra.schema.CompressionParams;
-import org.apache.cassandra.schema.KeyspaceMetadata;
-import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.MemtableParams;
-import org.apache.cassandra.schema.ReplicationParams;
-import org.apache.cassandra.schema.TableId;
-import org.apache.cassandra.schema.TableMetadata;
-import org.apache.cassandra.schema.TableParams;
-import org.apache.cassandra.schema.Tables;
-import org.apache.cassandra.schema.Types;
-import org.apache.cassandra.schema.UserFunctions;
-import org.apache.cassandra.schema.Views;
 import org.apache.cassandra.service.accord.fastpath.FastPathStrategy;
+import org.apache.cassandra.service.accord.AccordFastPath;
+import org.apache.cassandra.service.accord.AccordStaleReplicas;
+import org.apache.cassandra.service.accord.fastpath.InheritKeyspaceFastPathStrategy;
+import org.apache.cassandra.service.accord.fastpath.ParameterizedFastPathStrategy;
+import org.apache.cassandra.service.accord.fastpath.SimpleFastPathStrategy;
+import org.apache.cassandra.service.consensus.TransactionalMode;
 import org.apache.cassandra.tcm.ClusterMetadata;
 import org.apache.cassandra.tcm.Epoch;
 import org.apache.cassandra.utils.AbstractTypeGenerators.TypeGenBuilder;
@@ -158,7 +159,7 @@ public final class CassandraGenerators
         return InetAddressAndPort.getByAddressOverrideDefaults(address, NETWORK_PORT_GEN.generate(rnd));
     };
 
-    public static final Gen<TableId> TABLE_ID_GEN = Generators.UUID_RANDOM_GEN.map(TableId::fromUUID);
+    public static final Gen<TableId> TABLE_ID_GEN = Generate.booleans().flatMap(uuid -> uuid ? Generators.UUID_RANDOM_GEN.map(TableId::fromUUID) : Generate.longRange(Long.MIN_VALUE, Long.MAX_VALUE).map(TableId::fromLong));
     private static final Gen<TableMetadata.Kind> TABLE_KIND_GEN = SourceDSL.arbitrary().pick(TableMetadata.Kind.REGULAR, TableMetadata.Kind.INDEX, TableMetadata.Kind.VIRTUAL);
     public static final Gen<TableMetadata> TABLE_METADATA_GEN = gen(rnd -> createTableMetadata(IDENTIFIER_GEN.generate(rnd), rnd)).describedAs(CassandraGenerators::toStringRecursive);
 
@@ -748,6 +749,10 @@ public final class CassandraGenerators
         private Gen<CompactionParams> compactionParamsGen = null;
         @Nullable
         private Gen<CompressionParams> compressionParamsGen = null;
+        @Nullable
+        private Gen<TransactionalMode> transactionalMode = null;
+        @Nullable
+        private Gen<FastPathStrategy> fastPathStrategy = null;
 
         public TableParamsBuilder withKnownMemtables()
         {
@@ -776,6 +781,81 @@ public final class CassandraGenerators
             return this;
         }
 
+        public TableParamsBuilder withTransactionalMode(Gen<TransactionalMode> transactionalMode)
+        {
+            this.transactionalMode = transactionalMode;
+            return this;
+        }
+
+        public TableParamsBuilder withTransactionalMode()
+        {
+            return withTransactionalMode(SourceDSL.arbitrary().enumValues(TransactionalMode.class));
+        }
+
+        public TableParamsBuilder withTransactionalMode(TransactionalMode transactionalMode)
+        {
+            return withTransactionalMode(SourceDSL.arbitrary().constant(transactionalMode));
+        }
+
+        public TableParamsBuilder withFastPathStrategy()
+        {
+            fastPathStrategy = rnd -> {
+                FastPathStrategy.Kind kind = SourceDSL.arbitrary().enumValues(FastPathStrategy.Kind.class).generate(rnd);
+                switch (kind)
+                {
+                    case SIMPLE:
+                        return SimpleFastPathStrategy.instance;
+                    case INHERIT_KEYSPACE:
+                        return InheritKeyspaceFastPathStrategy.instance;
+                    case PARAMETERIZED:
+                    {
+                        Map<String, String> map = new HashMap<>();
+                        int size = SourceDSL.integers().between(1, Integer.MAX_VALUE).generate(rnd);
+                        map.put(ParameterizedFastPathStrategy.SIZE, Integer.toString(size));
+                        Set<String> names = new HashSet<>();
+                        Gen<String> nameGen = SourceDSL.strings().allPossible().ofLengthBetween(1, 10)
+                                                       // If : is in the name then the parser will fail; we have validation to disalow this
+                                                       .map(s -> s.replace(":", "_"))
+                                                       // Names are used for DCs and those are seperated by ,
+                                                       .map(s -> s.replace(",", "_"))
+                                                       .assuming(s -> !s.trim().isEmpty());
+                        int numNames = SourceDSL.integers().between(1, 10).generate(rnd);
+                        for (int i = 0; i < numNames; i++)
+                        {
+                            while (!names.add(nameGen.generate(rnd)))
+                            {
+                            }
+                        }
+                        List<String> sortedNames = new ArrayList<>(names);
+                        sortedNames.sort(Comparator.naturalOrder());
+                        List<String> dcs = new ArrayList<>(names.size());
+                        boolean auto = SourceDSL.booleans().all().generate(rnd);
+                        if (auto)
+                        {
+                            dcs.addAll(sortedNames);
+                        }
+                        else
+                        {
+                            for (String name : sortedNames)
+                            {
+                                int weight = SourceDSL.integers().between(0, 10).generate(rnd);
+                                dcs.add(name + ":" + weight);
+                            }
+                        }
+                        // str: dcFormat(,dcFormat)*
+                        //      dcFormat: name | weight
+                        //      weight: int: >= 0
+                        //      note: can't mix auto and user defined weight; need one or the other.  Names must be unique
+                        map.put(ParameterizedFastPathStrategy.DCS, String.join(",", dcs));
+                        return ParameterizedFastPathStrategy.fromMap(map);
+                    }
+                    default:
+                        throw new UnsupportedOperationException(kind.name());
+                }
+            };
+            return this;
+        }
+
         public Gen<TableParams> build()
         {
             return rnd -> {
@@ -788,6 +868,10 @@ public final class CassandraGenerators
                     params.compaction(compactionParamsGen.generate(rnd));
                 if (compressionParamsGen != null)
                     params.compression(compressionParamsGen.generate(rnd));
+                if (transactionalMode != null)
+                    params.transactionalMode(transactionalMode.generate(rnd));
+                if (fastPathStrategy != null)
+                    params.fastPath(fastPathStrategy.generate(rnd));
                 return params.build();
             };
         }
@@ -864,6 +948,18 @@ public final class CassandraGenerators
             return this;
         }
 
+        public TableMetadataBuilder withTransactionalMode(Gen<TransactionalMode> transactionalMode)
+        {
+            paramsBuilder.withTransactionalMode(transactionalMode);
+            return this;
+        }
+
+        public TableMetadataBuilder withTransactionalMode(TransactionalMode transactionalMode)
+        {
+            paramsBuilder.withTransactionalMode(transactionalMode);
+            return this;
+        }
+
         public TableMetadataBuilder withKnownMemtables()
         {
             paramsBuilder.withKnownMemtables();
@@ -1081,6 +1177,11 @@ public final class CassandraGenerators
         }
     }
 
+    public static Gen<ColumnMetadata> columnMetadataGen()
+    {
+        return columnMetadataGen(SourceDSL.arbitrary().enumValues(ColumnMetadata.Kind.class), AbstractTypeGenerators.typeGen());
+    }
+
     public static Gen<ColumnMetadata> columnMetadataGen(Gen<ColumnMetadata.Kind> kindGen, Gen<AbstractType<?>> typeGen)
     {
         Gen<String> ksNameGen = CassandraGenerators.KEYSPACE_NAME_GEN;
@@ -1304,16 +1405,6 @@ public final class CassandraGenerators
         return AbstractTypeGenerators.safeTypeGen().map(LocalPartitioner::new);
     }
 
-    public static Gen<LocalCompositePrefixPartitioner> localCompositePrefixPartitioner()
-    {
-        return AbstractTypeGenerators.safeTypeGen().map(type -> {
-            if (type instanceof CompositeType)
-                return new LocalCompositePrefixPartitioner((CompositeType) type);
-            else
-                return new LocalCompositePrefixPartitioner(type);
-        });
-    }
-
     public static Gen<Token> localPartitionerToken()
     {
         var lpGen = localPartitioner();
@@ -1324,16 +1415,6 @@ public final class CassandraGenerators
         };
     }
 
-    public static Gen<Token> localCompositePrefixPartitionerToken()
-    {
-        var lpGen = localCompositePrefixPartitioner();
-        return rs -> {
-            var lp = lpGen.generate(rs);
-            var bytes = AbstractTypeGenerators.getTypeSupport(lp.getTokenValidator()).bytesGen();
-            return lp.getToken(bytes.generate(rs));
-        };
-    }
-
     public static Gen<Token> reversedLongLocalToken()
     {
         Constraint range = Constraint.between(0, Long.MAX_VALUE);
@@ -1369,8 +1450,7 @@ public final class CassandraGenerators
         ByteOrdered(ByteOrderedPartitioner.class,                       ignore -> ByteOrderedPartitioner.instance),
         Random(RandomPartitioner.class,                                 ignore -> RandomPartitioner.instance),
         Local(LocalPartitioner.class,                                   localPartitioner()),
-        OrderPreserving(OrderPreservingPartitioner.class,               ignore -> OrderPreservingPartitioner.instance),
-        LocalCompositePrefix(LocalCompositePrefixPartitioner.class,     localCompositePrefixPartitioner());
+        OrderPreserving(OrderPreservingPartitioner.class,               ignore -> OrderPreservingPartitioner.instance);
 
         private final Class<? extends IPartitioner> clazz;
         private final Gen<? extends IPartitioner> partitioner;
@@ -1410,8 +1490,7 @@ public final class CassandraGenerators
     public static Gen<IPartitioner> nonLocalPartitioners()
     {
         return SourceDSL.arbitrary().enumValues(SupportedPartitioners.class)
-                        .assuming(p -> p != SupportedPartitioners.Local &&
-                                       p != SupportedPartitioners.LocalCompositePrefix)
+                        .assuming(p -> p != SupportedPartitioners.Local)
                         .flatMap(SupportedPartitioners::partitioner);
     }
 
@@ -1443,7 +1522,6 @@ public final class CassandraGenerators
         if (partitioner instanceof Murmur3Partitioner) return murmurToken();
         if (partitioner instanceof ByteOrderedPartitioner) return byteOrderToken();
         if (partitioner instanceof RandomPartitioner) return randomPartitionerToken();
-        if (partitioner instanceof LocalCompositePrefixPartitioner) return localCompositePrefixPartitionerToken();
         if (partitioner instanceof LocalPartitioner) return localPartitionerToken((LocalPartitioner) partitioner);
         if (partitioner instanceof OrderPreservingPartitioner) return orderPreservingToken();
         throw new UnsupportedOperationException("Unsupported partitioner: " + partitioner.getClass());
@@ -1757,4 +1835,62 @@ public final class CassandraGenerators
             return Epoch.create(SourceDSL.longs().between(2, Long.MAX_VALUE).generate(rnd));
         };
     }
+
+    public static Gen<Node.Id> accordNodeId()
+    {
+        return SourceDSL.integers().between(0, Integer.MAX_VALUE).map(Node.Id::new);
+    }
+
+    public static Gen<AccordStaleReplicas> accordStaleReplicas()
+    {
+        Gen<Set<Node.Id>> staleIdsGen = Generators.set(accordNodeId(), SourceDSL.integers().between(0, 10));
+        Gen<Epoch> epochGen = epochs();
+        return rnd -> new AccordStaleReplicas(staleIdsGen.generate(rnd), epochGen.generate(rnd));
+    }
+
+    public static Gen<AccordFastPath> accordFastPath()
+    {
+        Gen<List<Node.Id>> nodesGen = Generators.uniqueList(accordNodeId(), SourceDSL.integers().between(0, 10));
+        Gen<AccordFastPath.Status> statusGen = SourceDSL.arbitrary().enumValues(AccordFastPath.Status.class);
+        Gen<Long> updateTimeMillis = TIMESTAMP_NANOS.map(TimeUnit.NANOSECONDS::toMillis);
+        Gen<Long> updateDelayMillis = SourceDSL.longs().between(0, TimeUnit.HOURS.toMillis(2));
+        return rnd -> {
+            AccordFastPath accum = AccordFastPath.EMPTY;
+            for (Node.Id node : nodesGen.generate(rnd))
+            {
+                AccordFastPath.Status status = statusGen.generate(rnd);
+                // can't add a NORMAL node that doesn't exist, it must be ab-NORMAL first...
+                if (status == AccordFastPath.Status.NORMAL)
+                    accum = accum.withNodeStatusSince(node, AccordFastPath.Status.UNAVAILABLE, 0, 0);
+                accum = accum.withNodeStatusSince(node, status, updateTimeMillis.generate(rnd), updateDelayMillis.generate(rnd));
+            }
+            return accum;
+        };
+    }
+
+    public static class ClusterMetadataBuilder
+    {
+        private Gen<Epoch> epochGen = epochs();
+        private Gen<IPartitioner> partitionerGen = nonLocalPartitioners();
+        private Gen<AccordStaleReplicas> accordStaleReplicasGen = accordStaleReplicas();
+        private Gen<AccordFastPath> accordFastPathGen = accordFastPath();
+        public Gen<ClusterMetadata> build()
+        {
+            return rnd -> {
+                Epoch epoch = epochGen.generate(rnd);
+                IPartitioner partitioner = partitionerGen.generate(rnd);
+                Directory directory = Directory.EMPTY;
+                DistributedSchema schema = DistributedSchema.first(directory.knownDatacenters());
+                TokenMap tokenMap = new TokenMap(partitioner);
+                DataPlacements placements = DataPlacements.EMPTY;
+                AccordFastPath accordFastPath = accordFastPathGen.generate(rnd);
+                LockedRanges lockedRanges = LockedRanges.EMPTY;
+                InProgressSequences inProgressSequences = InProgressSequences.EMPTY;
+                ConsensusMigrationState consensusMigrationState = ConsensusMigrationState.EMPTY;
+                Map<ExtensionKey<?, ?>, ExtensionValue<?>> extensions = ImmutableMap.of();
+                AccordStaleReplicas accordStaleReplicas = accordStaleReplicasGen.generate(rnd);
+                return new ClusterMetadata(epoch, partitioner, schema, directory, tokenMap, placements, accordFastPath, lockedRanges, inProgressSequences, consensusMigrationState, extensions, accordStaleReplicas);
+            };
+        }
+    }
 }
diff --git a/test/unit/org/apache/cassandra/utils/CassandraGeneratorsTest.java b/test/unit/org/apache/cassandra/utils/CassandraGeneratorsTest.java
index 0e2c60a34d..1c1f0eead1 100644
--- a/test/unit/org/apache/cassandra/utils/CassandraGeneratorsTest.java
+++ b/test/unit/org/apache/cassandra/utils/CassandraGeneratorsTest.java
@@ -18,20 +18,36 @@
 
 package org.apache.cassandra.utils;
 
-import org.junit.Test;
+import java.util.Arrays;
+import java.util.List;
 
-import accord.utilsfork.Gens;
 import org.assertj.core.api.Assertions;
+import org.junit.Test;
+
+import accord.utils.Gens;
+import accord.utils.LazyToString;
+import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.db.marshal.CounterColumnType;
+import org.apache.cassandra.db.marshal.DecimalType;
+import org.apache.cassandra.db.marshal.DurationType;
+import org.apache.cassandra.db.marshal.EmptyType;
+import org.apache.cassandra.schema.ColumnMetadata;
+import org.apache.cassandra.utils.CassandraGenerators.TableMetadataBuilder;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 import static org.apache.cassandra.utils.Generators.toGen;
 
 public class CassandraGeneratorsTest
 {
+    private static final List<AbstractType<?>> NOT_ALLOWED_IN_PRIMARY_KEY = Arrays.asList(EmptyType.instance,
+                                                                                          DurationType.instance,
+                                                                                          DecimalType.instance,
+                                                                                          CounterColumnType.instance);
+
     @Test
     public void partitionerToToken()
     {
-        qt().forAll(Gens.random(), toGen(CassandraGenerators.partitioners()))
+        qt().forAll(Gens.random(), toGen(CassandraGenerators.partitioners().map(CassandraGenerators::simplify)))
             .check((rs, p) -> Assertions.assertThat(toGen(CassandraGenerators.token(p)).next(rs)).isNotNull());
     }
 
@@ -41,4 +57,20 @@ public class CassandraGeneratorsTest
         qt().forAll(Gens.random(), toGen(CassandraGenerators.partitioners()))
             .check((rs, p) -> Assertions.assertThat(toGen(CassandraGenerators.decoratedKeys(i -> p)).next(rs)).isNotNull());
     }
+
+    @Test
+    public void primaryKeysNoUnsafeTypes()
+    {
+        qt().forAll(toGen(new TableMetadataBuilder().build())).check(table -> {
+            for (ColumnMetadata pk : table.primaryKeyColumns())
+            {
+                for (AbstractType<?> t : NOT_ALLOWED_IN_PRIMARY_KEY)
+                {
+                    Assertions.assertThat(AbstractTypeGenerators.contains(pk.type, t))
+                              .describedAs("Expected type %s not to be found in %s", t.asCQL3Type(), new LazyToString(() -> AbstractTypeGenerators.typeTree(pk.type)))
+                              .isFalse();
+                }
+            }
+        });
+    }
 }
diff --git a/test/unit/org/apache/cassandra/utils/ConfigGenBuilder.java b/test/unit/org/apache/cassandra/utils/ConfigGenBuilder.java
index dcc54f5157..c103a8dc6d 100644
--- a/test/unit/org/apache/cassandra/utils/ConfigGenBuilder.java
+++ b/test/unit/org/apache/cassandra/utils/ConfigGenBuilder.java
@@ -25,9 +25,9 @@ import javax.annotation.Nullable;
 
 import com.google.common.collect.ImmutableMap;
 
-import accord.utilsfork.Gen;
-import accord.utilsfork.Gens;
-import accord.utilsfork.RandomSource;
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.RandomSource;
 import org.apache.cassandra.config.Config;
 import org.apache.cassandra.config.DurationSpec;
 import org.apache.cassandra.dht.IPartitioner;
diff --git a/test/unit/org/apache/cassandra/utils/ConfigGenBuilderTest.java b/test/unit/org/apache/cassandra/utils/ConfigGenBuilderTest.java
index 7b1091d4c5..7bf1d12fd8 100644
--- a/test/unit/org/apache/cassandra/utils/ConfigGenBuilderTest.java
+++ b/test/unit/org/apache/cassandra/utils/ConfigGenBuilderTest.java
@@ -23,7 +23,7 @@ import java.util.Map;
 import com.google.common.jimfs.Jimfs;
 import org.junit.Test;
 
-import accord.utilsfork.Gen;
+import accord.utils.Gen;
 import org.apache.cassandra.config.Config;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.ParameterizedClass;
@@ -31,7 +31,7 @@ import org.apache.cassandra.config.YamlConfigurationLoader;
 import org.apache.cassandra.io.util.File;
 import org.apache.cassandra.locator.SimpleSeedProvider;
 
-import static accord.utilsfork.Property.qt;
+import static accord.utils.Property.qt;
 import static org.apache.cassandra.config.CassandraRelevantProperties.STORAGE_DIR;
 
 public class ConfigGenBuilderTest
diff --git a/test/unit/org/apache/cassandra/utils/Generators.java b/test/unit/org/apache/cassandra/utils/Generators.java
index 2acedf174b..6bb7f56a8d 100644
--- a/test/unit/org/apache/cassandra/utils/Generators.java
+++ b/test/unit/org/apache/cassandra/utils/Generators.java
@@ -42,8 +42,8 @@ import org.apache.commons.lang3.ArrayUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import accord.utilsfork.DefaultRandom;
-import accord.utilsfork.RandomSource;
+import accord.utils.DefaultRandom;
+import accord.utils.RandomSource;
 import org.apache.cassandra.cql3.ReservedKeywords;
 import org.quicktheories.core.Gen;
 import org.quicktheories.core.RandomnessSource;
@@ -613,7 +613,7 @@ public final class Generators
                                                    .map(end -> Range.closed(start, end)));
     }
 
-    public static <T> accord.utilsfork.Gen<T> toGen(org.quicktheories.core.Gen<T> qt)
+    public static <T> accord.utils.Gen<T> toGen(org.quicktheories.core.Gen<T> qt)
     {
         return rs -> {
             JavaRandom r = new JavaRandom(rs.asJdkRandom());
@@ -621,7 +621,7 @@ public final class Generators
         };
     }
 
-    public static <T> org.quicktheories.core.Gen<T> fromGen(accord.utilsfork.Gen<T> accord)
+    public static <T> org.quicktheories.core.Gen<T> fromGen(accord.utils.Gen<T> accord)
     {
         return rnd -> {
             RandomSource rs = new DefaultRandom(rnd.next(Constraint.none()));
diff --git a/test/unit/org/apache/cassandra/utils/SimulatedMiniCluster.java b/test/unit/org/apache/cassandra/utils/SimulatedMiniCluster.java
new file mode 100644
index 0000000000..c60a633069
--- /dev/null
+++ b/test/unit/org/apache/cassandra/utils/SimulatedMiniCluster.java
@@ -0,0 +1,620 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.utils;
+
+import java.net.UnknownHostException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Random;
+import java.util.TreeSet;
+import java.util.UUID;
+import java.util.concurrent.TimeUnit;
+import java.util.function.Function;
+import java.util.function.Supplier;
+import javax.annotation.Nullable;
+
+import com.google.common.collect.Iterables;
+
+import accord.utils.Gen;
+import accord.utils.Gens;
+import accord.utils.Invariants;
+import accord.utils.RandomSource;
+import org.apache.cassandra.concurrent.ExecutorFactory;
+import org.apache.cassandra.concurrent.ScheduledExecutorPlus;
+import org.apache.cassandra.concurrent.SequentialExecutorPlus;
+import org.apache.cassandra.concurrent.SimulatedExecutorFactory;
+import org.apache.cassandra.concurrent.Stage;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.compaction.ICompactionManager;
+import org.apache.cassandra.db.repair.CassandraTableRepairManager;
+import org.apache.cassandra.dht.IPartitioner;
+import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.gms.ApplicationState;
+import org.apache.cassandra.gms.EndpointState;
+import org.apache.cassandra.gms.HeartBeatState;
+import org.apache.cassandra.gms.IEndpointStateChangeSubscriber;
+import org.apache.cassandra.gms.IFailureDetector;
+import org.apache.cassandra.gms.IGossiper;
+import org.apache.cassandra.gms.VersionedValue;
+import org.apache.cassandra.locator.InetAddressAndPort;
+import org.apache.cassandra.locator.Locator;
+import org.apache.cassandra.net.IVerbHandler;
+import org.apache.cassandra.net.MessageDelivery;
+import org.apache.cassandra.net.SimulatedMessageDelivery;
+import org.apache.cassandra.net.SimulatedMessageDelivery.ActionSupplier;
+import org.apache.cassandra.repair.IValidationManager;
+import org.apache.cassandra.repair.SharedContext;
+import org.apache.cassandra.repair.StreamExecutor;
+import org.apache.cassandra.repair.TableRepairManager;
+import org.apache.cassandra.repair.ValidationManager;
+import org.apache.cassandra.service.ActiveRepairService;
+import org.apache.cassandra.service.paxos.cleanup.PaxosRepairState;
+import org.apache.cassandra.streaming.StreamEventHandler;
+import org.apache.cassandra.streaming.StreamState;
+import org.apache.cassandra.tcm.ClusterMetadata;
+import org.apache.cassandra.tcm.ClusterMetadataService;
+import org.apache.cassandra.tcm.MultiStepOperation;
+import org.apache.cassandra.tcm.StubClusterMetadataService;
+import org.apache.cassandra.tcm.Transformation;
+import org.apache.cassandra.tcm.membership.Directory;
+import org.apache.cassandra.tcm.membership.Location;
+import org.apache.cassandra.tcm.membership.NodeAddresses;
+import org.apache.cassandra.tcm.membership.NodeId;
+import org.apache.cassandra.tcm.membership.NodeVersion;
+import org.apache.cassandra.tcm.ownership.UniformRangePlacement;
+import org.apache.cassandra.tcm.transformations.PrepareJoin;
+import org.mockito.Mockito;
+
+import static org.apache.cassandra.utils.AccordGenerators.fromQT;
+
+public class SimulatedMiniCluster
+{
+    private final RandomSource rs;
+    private final Function<Node, IVerbHandler<?>> verbHandlerFactory;
+    private final SimulatedExecutorFactory executorFactory;
+    private final SequentialExecutorPlus orderedExecutor;
+    private final ScheduledExecutorPlus unorderedScheduled;
+    private final IFailureDetector failureDetector = Mockito.mock(IFailureDetector.class);
+    private final Locator locator = Mockito.mock(Locator.class);
+    private final MBeanWrapper mbean = Mockito.mock(MBeanWrapper.class);
+    private final SimulatedGossip gossiper = new SimulatedGossip();
+    private final List<Throwable> failures = new ArrayList<>();
+    private final IPartitioner partitioner;
+    private final Map<String, List<String>> dcsToRacks;
+    private final List<String> dcs;
+    private final int tokensPerInstance;
+    private final Gen<Token> tokenGen;
+    private ClusterMetadata current;
+    private final Map<NodeId, Node> nodes = new LinkedHashMap<>();
+    private final TreeSet<Token> knownTokens = new TreeSet<>(); // includes bootstraping nodes tokens (aka tokens not in the ring)
+
+    private SimulatedMiniCluster(Builder builder)
+    {
+        this.rs = builder.rs;
+        this.verbHandlerFactory = builder.verbHandlerFactory;
+        this.executorFactory = new SimulatedExecutorFactory(rs, failures::add);
+        this.orderedExecutor = executorFactory.configureSequential("ignore").build();
+        this.unorderedScheduled = executorFactory.scheduled("ignored");
+        this.partitioner = fromQT(CassandraGenerators.nonLocalPartitioners()).next(rs);
+        this.dcsToRacks = createDcRackDetails(rs);
+        this.dcs = new ArrayList<>(dcsToRacks.keySet());
+        dcs.sort(Comparator.naturalOrder());
+        this.tokensPerInstance = rs.nextBoolean() ? 1 : 4;
+        this.tokenGen = fromQT(CassandraGenerators.token(partitioner)).filter(t -> !knownTokens.contains(t));
+        // setup Directory with known dcs
+        this.current = new ClusterMetadata(partitioner);
+        ClusterMetadataService.unsetInstance();
+        ClusterMetadataService.setInstance(StubClusterMetadataService.forTesting(current));
+    }
+
+    public Node node(int id)
+    {
+        return node(new NodeId(id));
+    }
+
+    public Node node(NodeId id)
+    {
+        Node node = nodes.get(id);
+        if (node == null)
+            throw new AssertionError("Unable to find node for id " + id);
+        return node;
+    }
+
+    public Node node(InetAddressAndPort address)
+    {
+        //TODO (performance): don't walk, keep index?
+        for (Node node : nodes.values())
+        {
+            if (node.broadcastAddressAndPort.equals(address))
+                return node;
+        }
+        throw new AssertionError("Unable to find node for address " + address);
+    }
+
+    private Collection<Token> nextUnknownTokens()
+    {
+        if (tokensPerInstance == 1) return Collections.singleton(tokenGen.next(rs));
+        return Gens.lists(tokenGen).unique().ofSize(tokensPerInstance).next(rs);
+    }
+
+    public Node createNode()
+    {
+        if (nodes.isEmpty())
+            return createFirstNode();
+
+        NodeId id = new NodeId(nodes.size() + 1);
+        UUID hostId = id.toUUID();
+        Collection<Token> tokens = nextUnknownTokens();
+        String dc = rs.pick(dcs);
+        String rack = rs.pick(dcsToRacks.get(dc));
+        Node node = new Node(id, hostId, address(id), tokens, dc, rack);
+        register(node);
+        return node;
+    }
+
+    public Node createNodeAndJoin()
+    {
+        if (nodes.isEmpty())
+            return createFirstNode();
+
+        NodeId id = new NodeId(nodes.size() + 1);
+        UUID hostId = id.toUUID();
+        Collection<Token> tokens = nextUnknownTokens();
+        String dc = rs.pick(dcs);
+        String rack = rs.pick(dcsToRacks.get(dc));
+        Node node = new Node(id, hostId, address(id), tokens, dc, rack);
+        registerAndJoin(node);
+        return node;
+    }
+
+    private Node createFirstNode()
+    {
+        NodeId id = new NodeId(nodes.size() + 1);
+        UUID hostId = id.toUUID();
+        Collection<Token> tokens = nextUnknownTokens();
+        String dc = dcs.get(0);
+        String rack = dcsToRacks.get(dc).get(0);
+        Node node = new Node(id, hostId, address(id), tokens, dc, rack);
+        registerAndJoin(node);
+        return node;
+    }
+
+    private void registerAndJoin(Node node)
+    {
+        register(node);
+        prepareJoin(node.id);
+        while (!current.inProgressSequences.isEmpty())
+            bumpInProgress();
+    }
+
+    private void register(Node node)
+    {
+        nodes.put(node.id, node);
+        knownTokens.addAll(node.tokens);
+        registerWithSnitch(node);
+        registerWithGossip(node);
+        registerWithCMS(node);
+    }
+
+    private void registerWithCMS(Node node)
+    {
+        if (node.id.id() == 1)
+        {
+            // rebuild metadata from scratch
+            Directory directory = Directory.EMPTY.with(new NodeAddresses(node.hostId, node.broadcastAddressAndPort, node.broadcastAddressAndPort, node.broadcastAddressAndPort), new Location(node.dc, node.rack));
+            notifyMetadataChange(new ClusterMetadata(partitioner, directory));
+        }
+        else
+        {
+            notifyMetadataChange(current.transformer().register(new NodeAddresses(node.hostId, node.broadcastAddressAndPort, node.broadcastAddressAndPort, node.broadcastAddressAndPort),
+                                                                new Location(node.dc, node.rack),
+                                                                NodeVersion.CURRENT)
+                                        .build().metadata);
+        }
+    }
+
+    private void prepareJoin(NodeId id)
+    {
+        Node node = nodes.get(id);
+        if (node == null)
+            throw new IllegalArgumentException("Unknown " + id);
+        PrepareJoin task = new PrepareJoin(id, new HashSet<>(node.tokens), new UniformRangePlacement(), true, false);
+        notifyMetadataChange(process(task).metadata);
+    }
+
+    private void bumpInProgress()
+    {
+        if (current.inProgressSequences.isEmpty())
+            throw new IllegalStateException("Attempted to bump epoch when nothing was pending");
+        Iterator<MultiStepOperation<?>> it = current.inProgressSequences.iterator();
+        Invariants.checkState(it.hasNext());
+        notifyMetadataChange(process(it.next()).metadata);
+    }
+
+    protected void notifyMetadataChange(ClusterMetadata current)
+    {
+        this.current = current;
+        ((StubClusterMetadataService) ClusterMetadataService.instance()).setMetadata(current);
+    }
+
+    private Transformation.Success process(Transformation transformation)
+    {
+        Transformation.Result result = transformation.execute(current);
+        if (result.isRejected())
+            throw new IllegalStateException("Unable to make TCM transition");
+        return result.success();
+    }
+
+    private Transformation.Success process(MultiStepOperation<?> transformation)
+    {
+        Transformation.Result result = transformation.applyTo(current);
+        if (result.isRejected())
+            throw new IllegalStateException("Unable to make TCM transition");
+        return result.success();
+    }
+
+    private static InetAddressAndPort address(NodeId id)
+    {
+        try
+        {
+            return InetAddressAndPort.getByAddress(ByteArrayUtil.bytes(id.id()));
+        }
+        catch (UnknownHostException e)
+        {
+            throw new AssertionError("Unable to create address for id " + id, e);
+        }
+    }
+
+    private static Map<String, List<String>> createDcRackDetails(RandomSource rs)
+    {
+        int numDCs = rs.nextInt(1, 4);
+        Map<String, List<String>> map = new LinkedHashMap<>();
+        for (int i = 0; i < numDCs; i++)
+        {
+            String name = "DC" + (i + 1);
+            int numRacks = rs.nextInt(1, 10);
+            List<String> racks = Gens.lists(Gens.strings().ascii().ofLength(5).map(s -> "R" + s)).unique().ofSize(numRacks).next(rs);
+            racks.sort(Comparator.naturalOrder());
+            map.put(name, racks);
+        }
+        return map;
+    }
+
+    public boolean hasWork()
+    {
+        return executorFactory.hasWork();
+    }
+
+    public boolean processAny()
+    {
+        return executorFactory.processAny();
+    }
+
+    public boolean processOne()
+    {
+        return executorFactory.processOne();
+    }
+
+    public void processAll()
+    {
+        executorFactory.processAll();;
+    }
+
+    public void simulateStages(Stage... stages)
+    {
+        for (Stage stage : stages)
+        {
+            switch (stage)
+            {
+                case GOSSIP:
+                case ANTI_ENTROPY:
+                case MIGRATION:
+                case MISC:
+                case TRACING:
+                case FETCH_LOG:
+                    stage.unsafeSetExecutor(orderedExecutor);
+                    break;
+                default:
+                    stage.unsafeSetExecutor(unorderedScheduled);
+            }
+        }
+    }
+
+    private void registerWithSnitch(Node node)
+    {
+        Mockito.when(locator.location(Mockito.eq(node.broadcastAddressAndPort))).thenReturn(new Location(node.dc, node.rack));
+    }
+
+    private void registerWithGossip(Node node)
+    {
+        VersionedValue.VersionedValueFactory valueFactory = node.valueFactory;
+        EndpointState state = new EndpointState(new HeartBeatState(42, 42));
+        state.addApplicationState(ApplicationState.STATUS, valueFactory.normal(node.tokens));
+        state.addApplicationState(ApplicationState.STATUS_WITH_PORT, valueFactory.normal(node.tokens));
+        state.addApplicationState(ApplicationState.HOST_ID, valueFactory.hostId(node.hostId));
+        state.addApplicationState(ApplicationState.TOKENS, valueFactory.tokens(node.tokens));
+        state.addApplicationState(ApplicationState.DC, valueFactory.datacenter(node.dc));
+        state.addApplicationState(ApplicationState.RACK, valueFactory.rack(node.rack));
+        state.addApplicationState(ApplicationState.RELEASE_VERSION, valueFactory.releaseVersion());
+
+        gossiper.endpoints.put(node.broadcastAddressAndPort, state);
+    }
+
+    public static class Builder
+    {
+        private final RandomSource rs;
+        private final Function<Node, IVerbHandler<?>> verbHandlerFactory;
+
+        public Builder(RandomSource rs, Function<Node, IVerbHandler<?>> verbHandlerFactory)
+        {
+            this.rs = rs;
+            this.verbHandlerFactory = verbHandlerFactory;
+        }
+
+        public SimulatedMiniCluster build()
+        {
+            return new SimulatedMiniCluster(this);
+        }
+    }
+
+     private enum NodeStatus { Init, Registered, Joining, Joined, Leaving, Removed}
+
+    public class Node implements SharedContext
+    {
+        private final ICompactionManager compactionManager = Mockito.mock(ICompactionManager.class);
+        private final NodeId id;
+        private final UUID hostId;
+        private final InetAddressAndPort broadcastAddressAndPort;
+        private final Collection<Token> tokens;
+        private final String dc, rack;
+        private final VersionedValue.VersionedValueFactory valueFactory;
+        private final SimulatedMessageDelivery messaging;
+        private final SimulatedMessageDelivery.SimulatedMessageReceiver receiver;
+        private final ActiveRepairService activeRepairService;
+        private final PaxosRepairState paxosRepairState;
+        private final IValidationManager validationManager;
+        private final StreamExecutor streamExecutor;
+        private NodeStatus status = NodeStatus.Init;
+        private ActionSupplier messagingActions = (self, msg, to) -> SimulatedMessageDelivery.Action.DELIVER;
+
+        public Node(NodeId id, UUID hostId, InetAddressAndPort broadcastAddressAndPort, Collection<Token> tokens, String dc, String rack)
+        {
+            this.id = id;
+            this.hostId = hostId;
+            this.broadcastAddressAndPort = broadcastAddressAndPort;
+            this.tokens = tokens;
+            this.dc = dc;
+            this.rack = rack;
+
+            IPartitioner partitioner = Iterables.getFirst(tokens, null).getPartitioner();
+            this.valueFactory = new VersionedValue.VersionedValueFactory(partitioner);
+            this.messaging = new SimulatedMessageDelivery(broadcastAddressAndPort,
+                                                          messagingActions::get,
+                                                          SimulatedMessageDelivery.randomDelay(rs),
+                                                          (to, msg) -> unorderedScheduled.submit(() -> node(to).receiver.recieve(msg)),
+                                                          (action, to, msg) -> {},
+                                                          unorderedScheduled::schedule,
+                                                          failures::add);
+            this.activeRepairService = new ActiveRepairService(this);
+            this.paxosRepairState = new PaxosRepairState(this);
+            this.validationManager = (cfs, validator) -> unorderedScheduled.submit(() -> {
+                try
+                {
+                    ValidationManager.doValidation(cfs, validator);
+                }
+                catch (Throwable e)
+                {
+                    validator.fail(e);
+                }
+            });
+            this.streamExecutor = plan -> {
+                long delayNanos = rs.nextLong(TimeUnit.SECONDS.toNanos(5), TimeUnit.MINUTES.toNanos(10));
+                unorderedScheduled.schedule(() -> {
+                    StreamState success = new StreamState(plan.planId(), plan.streamOperation(), Collections.emptySet());
+                    for (StreamEventHandler handler : plan.handlers())
+                        handler.onSuccess(success);
+                }, delayNanos, TimeUnit.NANOSECONDS);
+                return null;
+            };
+
+            // setup last as "this" is leaking, so make sure all final fields are defined first
+            this.receiver = messaging.receiver(verbHandlerFactory.apply(this));
+        }
+
+        public NodeId id()
+        {
+            return id;
+        }
+
+        public UUID hostId()
+        {
+            return hostId;
+        }
+
+        public void messagingActions(ActionSupplier messagingActions)
+        {
+            this.messagingActions = Objects.requireNonNull(messagingActions);
+        }
+
+        @Override
+        public InetAddressAndPort broadcastAddressAndPort()
+        {
+            return broadcastAddressAndPort;
+        }
+
+        @Override
+        public Supplier<Random> random()
+        {
+            return () -> rs.fork().asJdkRandom();
+        }
+
+        @Override
+        public Clock clock()
+        {
+            return executorFactory;
+        }
+
+        @Override
+        public ExecutorFactory executorFactory()
+        {
+            return executorFactory;
+        }
+
+        @Override
+        public MBeanWrapper mbean()
+        {
+            return mbean;
+        }
+
+        @Override
+        public ScheduledExecutorPlus optionalTasks()
+        {
+            return unorderedScheduled;
+        }
+
+        @Override
+        public ScheduledExecutorPlus nonPeriodicTasks()
+        {
+            return unorderedScheduled;
+        }
+
+        @Override
+        public ScheduledExecutorPlus scheduledTasks()
+        {
+            return unorderedScheduled;
+        }
+
+
+        @Override
+        public IFailureDetector failureDetector()
+        {
+            return failureDetector;
+        }
+
+        @Override
+        public Locator locator()
+        {
+            return locator;
+        }
+
+        @Override
+        public IGossiper gossiper()
+        {
+            return gossiper;
+        }
+
+        @Override
+        public MessageDelivery messaging()
+        {
+            return messaging;
+        }
+
+        @Override
+        public ActiveRepairService repair()
+        {
+            return activeRepairService;
+        }
+
+        @Override
+        public PaxosRepairState paxosRepairState()
+        {
+            return paxosRepairState;
+        }
+
+        @Override
+        public ICompactionManager compactionManager()
+        {
+            return compactionManager;
+        }
+
+        @Override
+        public IValidationManager validationManager()
+        {
+            return validationManager;
+        }
+
+        @Override
+        public TableRepairManager repairManager(ColumnFamilyStore store)
+        {
+            return new CassandraTableRepairManager(store, this)
+            {
+                @Override
+                public void snapshot(String name, Collection<Range<Token>> ranges, boolean force)
+                {
+                    // no-op
+                }
+            };
+        }
+
+        @Override
+        public StreamExecutor streamExecutor()
+        {
+            return streamExecutor;
+        }
+    }
+
+    private class SimulatedGossip implements IGossiper
+    {
+        private final Map<InetAddressAndPort, EndpointState> endpoints = new HashMap<>();
+
+        @Override
+        public void register(IEndpointStateChangeSubscriber subscriber)
+        {
+
+        }
+
+        @Override
+        public void unregister(IEndpointStateChangeSubscriber subscriber)
+        {
+
+        }
+
+        @Nullable
+        @Override
+        public EndpointState getEndpointStateForEndpoint(InetAddressAndPort ep)
+        {
+            return endpoints.get(ep);
+        }
+
+        @Override
+        public void notifyFailureDetector(Map<InetAddressAndPort, EndpointState> remoteEpStateMap)
+        {
+
+        }
+
+        @Override
+        public void applyStateLocally(Map<InetAddressAndPort, EndpointState> epStateMap)
+        {
+            // If we were testing paxos this would be wrong...
+            // CASSANDRA-18917 added support for simulating Gossip, but gossip issues were found so couldn't merge that patch...
+            // For the paxos repair, since we don't care about paxos messages, this is ok to no-op for now, but if paxos cleanup
+            // ever was to be tested this logic would need to be implemented
+        }
+    }
+}
