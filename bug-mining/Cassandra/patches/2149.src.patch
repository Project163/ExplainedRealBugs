diff --git a/CHANGES.txt b/CHANGES.txt
index 16fab51ecd..10e2e6ec2c 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,4 +1,6 @@
 2.0
+ * Removed compatibility with pre-1.2.5 sstables and network messages
+   (CASSANDRA-5511)
  * removed PBSPredictor (CASSANDRA-5455)
  * CAS support (CASSANDRA-5062, )
  * Leveled compaction performs size-tiered compactions in L0 
diff --git a/NEWS.txt b/NEWS.txt
index ea4ae1e9bd..31f30ab321 100644
--- a/NEWS.txt
+++ b/NEWS.txt
@@ -13,6 +13,10 @@ by version X, but the inverse is not necessarily the case.)
 
 Upgrading
 ---------
+    - Upgrading is ONLY supported from Cassandra 1.2.5 or later.  This
+      goes for sstable compatibility as well as network.  When
+      upgrading from an earlier release, upgrade to 1.2.5 first and
+      run upgradesstables before proceeding to 2.0.
     - Replication and strategy options do not accept unknown options anymore.
       This was already the case for CQL3 in 1.2 but this is now the case for
       thrift too.
diff --git a/src/java/org/apache/cassandra/config/Avro.java b/src/java/org/apache/cassandra/config/Avro.java
index bbdca816db..c712e07389 100644
--- a/src/java/org/apache/cassandra/config/Avro.java
+++ b/src/java/org/apache/cassandra/config/Avro.java
@@ -206,9 +206,6 @@ public class Avro
             throw new RuntimeException(e);
         }
 
-        // adding old -> new style ID mapping to support backward compatibility
-        Schema.instance.addOldCfIdMapping(cf.id, newCFMD.cfId);
-
         return newCFMD.comment(cf.comment.toString())
                       .readRepairChance(cf.read_repair_chance)
                       .dcLocalReadRepairChance(cf.dclocal_read_repair_chance)
diff --git a/src/java/org/apache/cassandra/config/CFMetaData.java b/src/java/org/apache/cassandra/config/CFMetaData.java
index 049668ae41..a686bf66b9 100644
--- a/src/java/org/apache/cassandra/config/CFMetaData.java
+++ b/src/java/org/apache/cassandra/config/CFMetaData.java
@@ -88,15 +88,6 @@ public final class CFMetaData
     // Note that this is the default only for user created tables
     public final static String DEFAULT_COMPRESSOR = LZ4Compressor.class.getCanonicalName();
 
-    @Deprecated
-    public static final CFMetaData OldStatusCf = newSystemMetadata(Table.SYSTEM_KS, SystemTable.OLD_STATUS_CF, 0, "unused", BytesType.instance, null);
-    @Deprecated
-    public static final CFMetaData OldHintsCf = newSystemMetadata(Table.SYSTEM_KS, SystemTable.OLD_HINTS_CF, 1, "unused", BytesType.instance, BytesType.instance);
-    @Deprecated
-    public static final CFMetaData OldMigrationsCf = newSystemMetadata(Table.SYSTEM_KS, DefsTable.OLD_MIGRATIONS_CF, 2, "unused", TimeUUIDType.instance, null);
-    @Deprecated
-    public static final CFMetaData OldSchemaCf = newSystemMetadata(Table.SYSTEM_KS, DefsTable.OLD_SCHEMA_CF, 3, "unused", UTF8Type.instance, null);
-
     public static final CFMetaData IndexCf = compile(5, "CREATE TABLE \"" + SystemTable.INDEX_CF + "\" ("
                                                         + "table_name text,"
                                                         + "index_name text,"
@@ -120,7 +111,6 @@ public final class CFMetaData
     public static final CFMetaData SchemaColumnFamiliesCf = compile(9, "CREATE TABLE " + SystemTable.SCHEMA_COLUMNFAMILIES_CF + "("
                                                                        + "keyspace_name text,"
                                                                        + "columnfamily_name text,"
-                                                                       + "id int,"
                                                                        + "type text,"
                                                                        + "comparator text,"
                                                                        + "subcomparator text,"
@@ -418,7 +408,7 @@ public final class CFMetaData
 
     public CFMetaData(String keyspace, String name, ColumnFamilyType type, AbstractType<?> comp, AbstractType<?> subcc)
     {
-        this(keyspace, name, type,  makeComparator(type, comp, subcc));
+        this(keyspace, name, type, makeComparator(type, comp, subcc));
     }
 
     public CFMetaData(String keyspace, String name, ColumnFamilyType type, AbstractType<?> comp)
@@ -449,7 +439,7 @@ public final class CFMetaData
         try
         {
             CreateColumnFamilyStatement statement = (CreateColumnFamilyStatement) QueryProcessor.parseStatement(cql).prepare().statement;
-            CFMetaData cfmd = newSystemMetadata(keyspace, statement.columnFamily(), id, "", statement.comparator, null);
+            CFMetaData cfmd = newSystemMetadata(keyspace, statement.columnFamily(), "", statement.comparator, null);
             statement.applyPropertiesTo(cfmd);
             return cfmd;
         }
@@ -486,14 +476,11 @@ public final class CFMetaData
         return UUID.nameUUIDFromBytes(ArrayUtils.addAll(ksName.getBytes(), cfName.getBytes()));
     }
 
-    private static CFMetaData newSystemMetadata(String keyspace, String cfName, Integer oldCfId, String comment, AbstractType<?> comparator, AbstractType<?> subcc)
+    private static CFMetaData newSystemMetadata(String keyspace, String cfName, String comment, AbstractType<?> comparator, AbstractType<?> subcc)
     {
         ColumnFamilyType type = subcc == null ? ColumnFamilyType.Standard : ColumnFamilyType.Super;
         CFMetaData newCFMD = new CFMetaData(keyspace, cfName, type, comparator,  subcc);
 
-        // adding old -> new style ID mapping to support backward compatibility
-        Schema.instance.addOldCfIdMapping(oldCfId, newCFMD.cfId);
-
         return newCFMD.comment(comment)
                 .readRepairChance(0)
                 .dcLocalReadRepairChance(0)
@@ -1490,11 +1477,6 @@ public final class CFMetaData
         ColumnFamily cf = rm.addOrGet(SystemTable.SCHEMA_COLUMNFAMILIES_CF);
         int ldt = (int) (System.currentTimeMillis() / 1000);
 
-        Integer oldId = Schema.instance.convertNewCfId(cfId);
-
-        if (oldId != null) // keep old ids (see CASSANDRA-3794 for details)
-            cf.addColumn(Column.create(oldId, timestamp, cfName, "id"));
-
         cf.addColumn(Column.create(cfType.toString(), timestamp, cfName, "type"));
 
         if (isSuper())
@@ -1554,9 +1536,6 @@ public final class CFMetaData
                                             TypeParser.parse(result.getString("comparator")),
                                             result.has("subcomparator") ? TypeParser.parse(result.getString("subcomparator")) : null);
 
-            if (result.has("id"))// try to identify if ColumnFamily Id is old style (before C* 1.2) and add old -> new mapping if so
-                Schema.instance.addOldCfIdMapping(result.getInt("id"), cfm.cfId);
-
             cfm.readRepairChance(result.getDouble("read_repair_chance"));
             cfm.dcLocalReadRepairChance(result.getDouble("local_read_repair_chance"));
             cfm.replicateOnWrite(result.getBoolean("replicate_on_write"));
diff --git a/src/java/org/apache/cassandra/config/DatabaseDescriptor.java b/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
index 7048975ca7..aad4dd3b2f 100644
--- a/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
+++ b/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
@@ -492,35 +492,12 @@ public class DatabaseDescriptor
         // if table with definitions is empty try loading the old way
         if (schemaCFS.estimateKeys() == 0)
         {
-            // we can load tables from local storage if a version is set in the system table and that actually maps to
-            // real data in the definitions table.  If we do end up loading from xml, store the definitions so that we
-            // don't load from xml anymore.
-            UUID uuid = MigrationManager.getLastMigrationId();
-
-            if (uuid == null)
-            {
-                logger.info("Couldn't detect any schema definitions in local storage.");
-                // peek around the data directories to see if anything is there.
-                if (hasExistingNoSystemTables())
-                    logger.info("Found table data in data directories. Consider using the CLI to define your schema.");
-                else
-                    logger.info("To create keyspaces and column families, see 'help create keyspace' in the CLI, or set up a schema using the thrift system_* calls.");
-            }
+            logger.info("Couldn't detect any schema definitions in local storage.");
+            // peek around the data directories to see if anything is there.
+            if (hasExistingNoSystemTables())
+                logger.info("Found table data in data directories. Consider using cqlsh to define your schema.");
             else
-            {
-                logger.info("Loading schema version " + uuid.toString());
-                Collection<KSMetaData> tableDefs = DefsTable.loadFromStorage(uuid);
-
-                // happens when someone manually deletes all tables and restarts.
-                if (tableDefs.size() == 0)
-                {
-                    logger.warn("No schema definitions were found in local storage.");
-                }
-                else // if non-system tables where found, trying to load them
-                {
-                    Schema.instance.load(tableDefs);
-                }
-            }
+                logger.info("To create keyspaces and column families, see 'help create table' in cqlsh.");
         }
         else
         {
diff --git a/src/java/org/apache/cassandra/config/KSMetaData.java b/src/java/org/apache/cassandra/config/KSMetaData.java
index b954b32fff..db08da8c95 100644
--- a/src/java/org/apache/cassandra/config/KSMetaData.java
+++ b/src/java/org/apache/cassandra/config/KSMetaData.java
@@ -89,11 +89,7 @@ public final class KSMetaData
                                                 CFMetaData.SchemaColumnFamiliesCf,
                                                 CFMetaData.SchemaColumnsCf,
                                                 CFMetaData.CompactionLogCf,
-                                                CFMetaData.PaxosCf,
-                                                CFMetaData.OldStatusCf,
-                                                CFMetaData.OldHintsCf,
-                                                CFMetaData.OldMigrationsCf,
-                                                CFMetaData.OldSchemaCf);
+                                                CFMetaData.PaxosCf);
         return new KSMetaData(Table.SYSTEM_KS, LocalStrategy.class, Collections.<String, String>emptyMap(), true, cfDefs);
     }
 
diff --git a/src/java/org/apache/cassandra/config/Schema.java b/src/java/org/apache/cassandra/config/Schema.java
index 9d670c0d91..ae3126962a 100644
--- a/src/java/org/apache/cassandra/config/Schema.java
+++ b/src/java/org/apache/cassandra/config/Schema.java
@@ -59,8 +59,6 @@ public class Schema
 
     /* metadata map for faster ColumnFamily lookup */
     private final BiMap<Pair<String, String>, UUID> cfIdMap = HashBiMap.create();
-    // mapping from old ColumnFamily Id (Integer) to a new version which is UUID
-    private final BiMap<Integer, UUID> oldCfIdMap = HashBiMap.create();
 
     private volatile UUID version;
 
@@ -313,29 +311,6 @@ public class Schema
 
     /* ColumnFamily query/control methods */
 
-    public void addOldCfIdMapping(Integer oldId, UUID newId)
-    {
-        if (oldId == null)
-            return;
-
-        oldCfIdMap.put(oldId, newId);
-    }
-
-    public UUID convertOldCfId(Integer oldCfId) throws UnknownColumnFamilyException
-    {
-        UUID cfId = oldCfIdMap.get(oldCfId);
-
-        if (cfId == null)
-            throw new UnknownColumnFamilyException("ColumnFamily identified by old " + oldCfId + " was not found.", null);
-
-        return cfId;
-    }
-
-    public Integer convertNewCfId(UUID newCfId)
-    {
-        return oldCfIdMap.containsValue(newCfId) ? oldCfIdMap.inverse().get(newCfId) : null;
-    }
-
     /**
      * @param cfId The identifier of the ColumnFamily to lookup
      * @return The (ksname,cfname) pair for the given id, or null if it has been dropped.
diff --git a/src/java/org/apache/cassandra/cql3/statements/SelectStatement.java b/src/java/org/apache/cassandra/cql3/statements/SelectStatement.java
index 5585df4ece..38fa3619d0 100644
--- a/src/java/org/apache/cassandra/cql3/statements/SelectStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/SelectStatement.java
@@ -280,8 +280,7 @@ public class SelectStatement implements CQLStatement
             SliceQueryFilter filter = new SliceQueryFilter(new ColumnSlice[]{slice},
                                                            isReversed,
                                                            getLimit(),
-                                                           toGroup,
-                                                           multiplier);
+                                                           toGroup);
             QueryProcessor.validateSliceFilter(cfDef.cfm, filter);
             return filter;
         }
diff --git a/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java b/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java
index ff967956e2..30164991f4 100644
--- a/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java
+++ b/src/java/org/apache/cassandra/db/ColumnFamilySerializer.java
@@ -187,27 +187,12 @@ public class ColumnFamilySerializer implements IVersionedSerializer<ColumnFamily
 
     public void serializeCfId(UUID cfId, DataOutput out, int version) throws IOException
     {
-        if (version < MessagingService.VERSION_12) // try to use CF's old id where possible (CASSANDRA-3794)
-        {
-            Integer oldId = Schema.instance.convertNewCfId(cfId);
-
-            if (oldId == null)
-                throw new IOException("Can't serialize ColumnFamily ID " + cfId + " to be used by version " + version +
-                                      ", because int <-> uuid mapping could not be established (CF was created in mixed version cluster).");
-
-            out.writeInt(oldId);
-        }
-        else
-            UUIDSerializer.serializer.serialize(cfId, out, version);
+        UUIDSerializer.serializer.serialize(cfId, out, version);
     }
 
     public UUID deserializeCfId(DataInput in, int version) throws IOException
     {
-        // create a ColumnFamily based on the cf id
-        UUID cfId = (version < MessagingService.VERSION_12)
-                     ? Schema.instance.convertOldCfId(in.readInt())
-                     : UUIDSerializer.serializer.deserialize(in, version);
-
+        UUID cfId = UUIDSerializer.serializer.deserialize(in, version);
         if (Schema.instance.getCF(cfId) == null)
             throw new UnknownColumnFamilyException("Couldn't find cfId=" + cfId, cfId);
 
@@ -216,17 +201,6 @@ public class ColumnFamilySerializer implements IVersionedSerializer<ColumnFamily
 
     public int cfIdSerializedSize(UUID cfId, TypeSizes typeSizes, int version)
     {
-        if (version < MessagingService.VERSION_12) // try to use CF's old id where possible (CASSANDRA-3794)
-        {
-            Integer oldId = Schema.instance.convertNewCfId(cfId);
-
-            if (oldId == null)
-                throw new RuntimeException("Can't serialize ColumnFamily ID " + cfId + " to be used by version " + version +
-                        ", because int <-> uuid mapping could not be established (CF was created in mixed version cluster).");
-
-            return typeSizes.sizeof(oldId);
-        }
-
         return typeSizes.sizeof(cfId);
     }
 }
diff --git a/src/java/org/apache/cassandra/db/DefinitionsUpdateVerbHandler.java b/src/java/org/apache/cassandra/db/DefinitionsUpdateVerbHandler.java
index 5d595492ba..95187ec754 100644
--- a/src/java/org/apache/cassandra/db/DefinitionsUpdateVerbHandler.java
+++ b/src/java/org/apache/cassandra/db/DefinitionsUpdateVerbHandler.java
@@ -47,11 +47,6 @@ public class DefinitionsUpdateVerbHandler implements IVerbHandler<Collection<Row
         {
             public void runMayThrow() throws Exception
             {
-                if (message.version < MessagingService.VERSION_117)
-                {
-                    logger.error("Can't accept schema migrations from Cassandra versions previous to 1.1.7, please upgrade first");
-                    return;
-                }
                 DefsTable.mergeSchema(message.payload);
             }
         });
diff --git a/src/java/org/apache/cassandra/db/DefsTable.java b/src/java/org/apache/cassandra/db/DefsTable.java
index 878248c6b0..83d9c226ac 100644
--- a/src/java/org/apache/cassandra/db/DefsTable.java
+++ b/src/java/org/apache/cassandra/db/DefsTable.java
@@ -156,80 +156,6 @@ public class DefsTable
         return keyspaces;
     }
 
-    public static void fixSchemaNanoTimestamps()
-    {
-        fixSchemaNanoTimestamp(SystemTable.SCHEMA_KEYSPACES_CF);
-        fixSchemaNanoTimestamp(SystemTable.SCHEMA_COLUMNFAMILIES_CF);
-        fixSchemaNanoTimestamp(SystemTable.SCHEMA_COLUMNS_CF);
-    }
-
-    private static void fixSchemaNanoTimestamp(String columnFamily)
-    {
-        ColumnFamilyStore cfs = Table.open(Table.SYSTEM_KS).getColumnFamilyStore(columnFamily);
-
-        boolean needsCleanup = false;
-        Date now = new Date();
-
-        List<Row> rows = SystemTable.serializedSchema(columnFamily);
-
-        row_check_loop:
-        for (Row row : rows)
-        {
-            if (Schema.invalidSchemaRow(row))
-                continue;
-
-            for (Column column : row.cf)
-            {
-                Date columnDate = new Date(column.timestamp());
-
-                if (columnDate.after(now))
-                {
-                    Date micros = new Date(column.timestamp() / 1000); // assume that it was in micros
-
-                    Calendar calendar = Calendar.getInstance();
-                    calendar.setTime(micros);
-
-                    if ((micros.before(now) && calendar.get(Calendar.YEAR) == 1970) || micros.after(now))
-                    {
-                        needsCleanup = true;
-                        break row_check_loop;
-                    }
-                }
-                else // millis and we have to fix it to micros
-                {
-                    needsCleanup = true;
-                    break row_check_loop;
-                }
-            }
-        }
-
-        if (!needsCleanup)
-            return;
-
-        logger.info("Fixing timestamps of schema ColumnFamily " + columnFamily + "...");
-
-        cfs.truncateBlocking();
-
-        long microTimestamp = now.getTime() * 1000;
-        for (Row row : rows)
-        {
-            if (Schema.invalidSchemaRow(row))
-                continue;
-
-            RowMutation mutation = new RowMutation(Table.SYSTEM_KS, row.key.key);
-
-            for (Column column : row.cf)
-            {
-                if (column.isLive())
-                    mutation.add(columnFamily, column.name(), column.value(), microTimestamp);
-            }
-
-            mutation.apply();
-        }
-        // flush immediately because we read schema before replaying the commitlog
-        cfs.forceBlockingFlush();
-    }
-
     public static ByteBuffer searchComposite(String name, boolean start)
     {
         assert name != null;
diff --git a/src/java/org/apache/cassandra/db/DeletionInfo.java b/src/java/org/apache/cassandra/db/DeletionInfo.java
index 70c0e764be..cdb2ddeef3 100644
--- a/src/java/org/apache/cassandra/db/DeletionInfo.java
+++ b/src/java/org/apache/cassandra/db/DeletionInfo.java
@@ -310,18 +310,7 @@ public class DeletionInfo
         public void serialize(DeletionInfo info, DataOutput out, int version) throws IOException
         {
             DeletionTime.serializer.serialize(info.topLevel, out);
-            // Pre-1.2 version don't know about range tombstones and thus users should upgrade all
-            // nodes before using them. If they didn't, better fail early that propagating bad info
-            if (version < MessagingService.VERSION_12)
-            {
-                if (!info.ranges.isEmpty())
-                    throw new RuntimeException("Cannot send range tombstone to pre-1.2 node. You should upgrade all node to Cassandra 1.2+ before using range tombstone.");
-                // Otherwise we're done
-            }
-            else
-            {
-                itSerializer.serialize(info.ranges, out, version);
-            }
+            itSerializer.serialize(info.ranges, out, version);
         }
 
         public void serializeForSSTable(DeletionInfo info, DataOutput out) throws IOException
@@ -340,11 +329,7 @@ public class DeletionInfo
 
         public DeletionInfo deserialize(DataInput in, int version, Comparator<ByteBuffer> comparator) throws IOException
         {
-            assert version < MessagingService.VERSION_12 || comparator != null;
             DeletionTime topLevel = DeletionTime.serializer.deserialize(in);
-            if (version < MessagingService.VERSION_12)
-                return new DeletionInfo(topLevel, IntervalTree.<ByteBuffer, DeletionTime, RangeTombstone>emptyTree());
-
             IntervalTree<ByteBuffer, DeletionTime, RangeTombstone> ranges = itSerializer.deserialize(in, version, comparator);
             return new DeletionInfo(topLevel, ranges);
         }
@@ -358,9 +343,6 @@ public class DeletionInfo
         public long serializedSize(DeletionInfo info, TypeSizes typeSizes, int version)
         {
             long size = DeletionTime.serializer.serializedSize(info.topLevel, typeSizes);
-            if (version < MessagingService.VERSION_12)
-                return size;
-
             return size + itSerializer.serializedSize(info.ranges, typeSizes, version);
         }
 
diff --git a/src/java/org/apache/cassandra/db/Directories.java b/src/java/org/apache/cassandra/db/Directories.java
index 7aebe8d93a..bfef737790 100644
--- a/src/java/org/apache/cassandra/db/Directories.java
+++ b/src/java/org/apache/cassandra/db/Directories.java
@@ -484,196 +484,6 @@ public class Directories
         return StringUtils.join(s, File.separator);
     }
 
-    /**
-     * To check if sstables needs migration, we look at the System directory.
-     * If it does not contain a directory for the schema cfs, we'll attempt a sstable
-     * migration.
-     *
-     * Note that it is mostly harmless to try a migration uselessly, except
-     * maybe for some wasted cpu cycles.
-     */
-    public static boolean sstablesNeedsMigration()
-    {
-        if (StorageService.instance.isClientMode())
-            return false;
-
-        boolean hasSystemKeyspace = false;
-        for (DataDirectory dir : dataFileLocations)
-        {
-            File systemDir = new File(dir.location, Table.SYSTEM_KS);
-            hasSystemKeyspace |= (systemDir.exists() && systemDir.isDirectory());
-            File statusCFDir = new File(systemDir, SystemTable.SCHEMA_KEYSPACES_CF);
-            if (statusCFDir.exists())
-                return false;
-        }
-        if (!hasSystemKeyspace)
-            // This is a brand new node.
-            return false;
-
-        // Check whether the migration might create too long a filename
-        int longestLocation = -1;
-        for (DataDirectory loc : dataFileLocations)
-            longestLocation = Math.max(longestLocation, FileUtils.getCanonicalPath(loc.location).length());
-
-        // Check that migration won't error out halfway through from too-long paths.  For Windows, we need to check
-        // total path length <= 255 (see http://msdn.microsoft.com/en-us/library/aa365247.aspx and discussion on CASSANDRA-2749);
-        // elsewhere, we just need to make sure filename is <= 255.
-        for (KSMetaData ksm : Schema.instance.getTableDefinitions())
-        {
-            String ksname = ksm.name;
-            for (Map.Entry<String, CFMetaData> entry : ksm.cfMetaData().entrySet())
-            {
-                String cfname = entry.getKey();
-
-                // max path is roughly (guess-estimate) <location>/ksname/cfname/snapshots/1324314347102-somename/ksname-cfname-tmp-hb-65536-Statistics.db
-                if (System.getProperty("os.name").startsWith("Windows")
-                    && longestLocation + (ksname.length() + cfname.length()) * 2 + 63 > 255)
-                {
-                    throw new RuntimeException(String.format("Starting with 1.1, keyspace names and column family " +
-                                                             "names must be less than %s characters long. %s/%s doesn't" +
-                                                             " respect that restriction. Please rename your " +
-                                                             "keyspace/column families to respect that restriction " +
-                                                             "before updating.", Schema.NAME_LENGTH, ksname, cfname));
-                }
-
-                if (ksm.name.length() + cfname.length() + 28 > 255)
-                {
-                    throw new RuntimeException("Starting with 1.1, the keyspace name is included in data filenames.  For "
-                                               + ksm.name + "/" + cfname + ", this puts you over the largest possible filename of 255 characters");
-                }
-            }
-        }
-
-        return true;
-    }
-
-    /**
-     * Move sstables from the pre-#2749 layout to their new location/names.
-     * This involves:
-     *   - moving each sstable to their CF specific directory
-     *   - rename the sstable to include the keyspace in the filename
-     *
-     * Note that this also move leveled manifests, snapshots and backups.
-     */
-    public static void migrateSSTables()
-    {
-        logger.info("Upgrade from pre-1.1 version detected: migrating sstables to new directory layout");
-
-        for (DataDirectory dir : dataFileLocations)
-        {
-            if (!dir.location.exists() || !dir.location.isDirectory())
-                continue;
-
-            File[] ksDirs = dir.location.listFiles();
-            if (ksDirs != null)
-            {
-                for (File ksDir : ksDirs)
-                {
-                    if (!ksDir.isDirectory())
-                        continue;
-
-                    File[] files = ksDir.listFiles();
-                    if (files != null)
-                    {
-                        for (File file : files)
-                            migrateFile(file, ksDir, null);
-                    }
-
-                    migrateSnapshots(ksDir);
-                    migrateBackups(ksDir);
-                }
-            }
-        }
-    }
-
-    private static void migrateSnapshots(File ksDir)
-    {
-        File snapshotDir = new File(ksDir, SNAPSHOT_SUBDIR);
-        if (!snapshotDir.exists())
-            return;
-
-        File[] snapshots = snapshotDir.listFiles();
-        if (snapshots != null)
-        {
-            for (File snapshot : snapshots)
-            {
-                if (!snapshot.isDirectory())
-                    continue;
-
-                File[] files = snapshot.listFiles();
-                if (files != null)
-                {
-                    for (File f : files)
-                        migrateFile(f, ksDir, join(SNAPSHOT_SUBDIR, snapshot.getName()));
-                }
-                if (!snapshot.delete())
-                    logger.info("Old snapsot directory {} not deleted by migraation as it is not empty", snapshot);
-            }
-        }
-        if (!snapshotDir.delete())
-            logger.info("Old directory {} not deleted by migration as it is not empty", snapshotDir);
-    }
-
-    private static void migrateBackups(File ksDir)
-    {
-        File backupDir = new File(ksDir, BACKUPS_SUBDIR);
-        if (!backupDir.exists())
-            return;
-
-        File[] files = backupDir.listFiles();
-        if (files != null)
-        {
-            for (File f : files)
-                migrateFile(f, ksDir, BACKUPS_SUBDIR);
-        }
-        if (!backupDir.delete())
-            logger.info("Old directory {} not deleted by migration as it is not empty", backupDir);
-    }
-
-    private static void migrateFile(File file, File ksDir, String additionalPath)
-    {
-        if (file.isDirectory())
-            return;
-
-        try
-        {
-            String name = file.getName();
-            boolean isManifest = name.endsWith(LeveledManifest.EXTENSION);
-            int separatorIndex = name.indexOf(Component.separator);
-
-            if (isManifest || (separatorIndex >= 0))
-            {
-                String cfname = isManifest
-                              ? getCfNameFromManifest(name)
-                              : name.substring(0, separatorIndex);
-
-                int idx = cfname.indexOf(SECONDARY_INDEX_NAME_SEPARATOR); // idx > 0 => secondary index
-                String dirname = idx > 0 ? cfname.substring(0, idx) : cfname;
-                File destDir = getOrCreate(ksDir, dirname, additionalPath);
-
-                File destFile = new File(destDir, isManifest ? name : ksDir.getName() + Component.separator + name);
-                logger.debug(String.format("[upgrade to 1.1] Moving %s to %s", file, destFile));
-                FileUtils.renameWithConfirm(file, destFile);
-            }
-            else
-            {
-                logger.warn("Found unrecognized file {} while migrating sstables from pre 1.1 format, ignoring.", file);
-            }
-        }
-        catch (Exception e)
-        {
-            throw new RuntimeException(String.format("Failed migrating file %s from pre 1.1 format.", file.getPath()), e);
-        }
-    }
-
-    private static String getCfNameFromManifest(String name)
-    {
-        String withoutExt = name.substring(0, name.length() - LeveledManifest.EXTENSION.length());
-        return withoutExt.endsWith("-old") || withoutExt.endsWith("-tmp")
-                ? withoutExt.substring(0, withoutExt.length() - 4)
-                : withoutExt;
-    }
-
     // Hack for tests, don't use otherwise
     static void overrideDataDirectoriesForTest(String loc)
     {
diff --git a/src/java/org/apache/cassandra/db/IndexScanCommand.java b/src/java/org/apache/cassandra/db/IndexScanCommand.java
deleted file mode 100644
index e4be841df9..0000000000
--- a/src/java/org/apache/cassandra/db/IndexScanCommand.java
+++ /dev/null
@@ -1,95 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.cassandra.db;
-
-import java.io.DataInput;
-import java.io.DataOutput;
-import java.io.IOException;
-
-import org.apache.cassandra.dht.AbstractBounds;
-import org.apache.cassandra.io.IVersionedSerializer;
-import org.apache.cassandra.net.MessageOut;
-import org.apache.cassandra.net.MessagingService;
-import org.apache.cassandra.thrift.IndexClause;
-import org.apache.cassandra.thrift.SlicePredicate;
-import org.apache.cassandra.thrift.TBinaryProtocol;
-import org.apache.cassandra.utils.FBUtilities;
-import org.apache.thrift.TDeserializer;
-import org.apache.thrift.TSerializer;
-
-public class IndexScanCommand
-{
-    public static final IndexScanCommandSerializer serializer = new IndexScanCommandSerializer();
-
-    public final String keyspace;
-    public final String column_family;
-    public final IndexClause index_clause;
-    public final SlicePredicate predicate;
-    public final AbstractBounds<RowPosition> range;
-
-    public IndexScanCommand(String keyspace, String column_family, IndexClause index_clause, SlicePredicate predicate, AbstractBounds<RowPosition> range)
-    {
-
-        this.keyspace = keyspace;
-        this.column_family = column_family;
-        this.index_clause = index_clause;
-        this.predicate = predicate;
-        this.range = range;
-    }
-
-    public MessageOut<IndexScanCommand> createMessage()
-    {
-        return new MessageOut<IndexScanCommand>(MessagingService.Verb.INDEX_SCAN, this, serializer);
-    }
-
-    static class IndexScanCommandSerializer implements IVersionedSerializer<IndexScanCommand>
-    {
-        public void serialize(IndexScanCommand o, DataOutput out, int version) throws IOException
-        {
-            assert version < MessagingService.VERSION_12; // 1.2 only uses RangeScanCommand
-
-            out.writeUTF(o.keyspace);
-            out.writeUTF(o.column_family);
-            TSerializer ser = new TSerializer(new TBinaryProtocol.Factory());
-            FBUtilities.serialize(ser, o.index_clause, out);
-            FBUtilities.serialize(ser, o.predicate, out);
-            AbstractBounds.serializer.serialize(o.range, out, version);
-        }
-
-        public IndexScanCommand deserialize(DataInput in, int version) throws IOException
-        {
-            assert version < MessagingService.VERSION_12; // 1.2 only uses RangeScanCommand
-
-            String keyspace = in.readUTF();
-            String columnFamily = in.readUTF();
-
-            IndexClause indexClause = new IndexClause();
-            SlicePredicate predicate = new SlicePredicate();
-            TDeserializer dser = new TDeserializer(new TBinaryProtocol.Factory());
-            FBUtilities.deserialize(dser, indexClause, in);
-            FBUtilities.deserialize(dser, predicate, in);
-            AbstractBounds<RowPosition> range = AbstractBounds.serializer.deserialize(in, version).toRowBounds();
-            return new IndexScanCommand(keyspace, columnFamily, indexClause, predicate, range);
-        }
-
-        public long serializedSize(IndexScanCommand object, int version)
-        {
-            throw new UnsupportedOperationException();
-        }
-    }
-}
diff --git a/src/java/org/apache/cassandra/db/MigrationRequestVerbHandler.java b/src/java/org/apache/cassandra/db/MigrationRequestVerbHandler.java
index 5a6625f8e4..8c5b12aa44 100644
--- a/src/java/org/apache/cassandra/db/MigrationRequestVerbHandler.java
+++ b/src/java/org/apache/cassandra/db/MigrationRequestVerbHandler.java
@@ -41,12 +41,7 @@ public class MigrationRequestVerbHandler implements IVerbHandler
     {
         logger.debug("Received migration request from {}.", message.from);
 
-        if (message.version < MessagingService.VERSION_12)
-            logger.debug("Returning empty response to the migration request from {} (version < 1.2).", message.from);
-
-        Collection<RowMutation> schema = message.version < MessagingService.VERSION_12
-                                         ? Collections.EMPTY_SET
-                                         : SystemTable.serializeSchema();
+        Collection<RowMutation> schema = SystemTable.serializeSchema();
 
         MessageOut<Collection<RowMutation>> response = new MessageOut<Collection<RowMutation>>(MessagingService.Verb.INTERNAL_RESPONSE,
                                                                                                schema,
diff --git a/src/java/org/apache/cassandra/db/RangeSliceCommand.java b/src/java/org/apache/cassandra/db/RangeSliceCommand.java
index 706def2e3c..ae9fab17cf 100644
--- a/src/java/org/apache/cassandra/db/RangeSliceCommand.java
+++ b/src/java/org/apache/cassandra/db/RangeSliceCommand.java
@@ -131,37 +131,6 @@ public class RangeSliceCommand implements IReadCommand
         return keyspace;
     }
 
-    // Convert to a equivalent IndexScanCommand for backward compatibility sake
-    public IndexScanCommand toIndexScanCommand()
-    {
-        assert row_filter != null && !row_filter.isEmpty();
-        if (countCQL3Rows || isPaging)
-            throw new IllegalStateException("Cannot proceed with range query as the remote end has a version < 1.1. Please update the full cluster first.");
-
-        CFMetaData cfm = Schema.instance.getCFMetaData(keyspace, column_family);
-        try
-        {
-            if (!ThriftValidation.validateFilterClauses(cfm, row_filter))
-                throw new IllegalStateException("Cannot proceed with non-indexed query as the remote end has a version < 1.1. Please update the full cluster first.");
-        }
-        catch (InvalidRequestException e)
-        {
-            throw new RuntimeException(e);
-        }
-
-        RowPosition start = range.left;
-        ByteBuffer startKey = ByteBufferUtil.EMPTY_BYTE_BUFFER;
-        if (start instanceof DecoratedKey)
-        {
-            startKey = ((DecoratedKey)start).key;
-        }
-
-        IndexClause clause = new IndexClause(row_filter, startKey, maxResults);
-        // IndexScanCommand is deprecated so don't bother
-        SlicePredicate pred = RangeSliceCommandSerializer.asSlicePredicate(predicate);
-        return new IndexScanCommand(keyspace, column_family, clause, pred, range);
-    }
-
     public long getTimeout()
     {
         return DatabaseDescriptor.getRangeRpcTimeout();
@@ -211,46 +180,26 @@ class RangeSliceCommandSerializer implements IVersionedSerializer<RangeSliceComm
                 ByteBufferUtil.write(sc, out);
         }
 
-        if (version < MessagingService.VERSION_12)
+        IDiskAtomFilter.Serializer.instance.serialize(sliceCommand.predicate, out, version);
+
+        if (sliceCommand.row_filter == null)
         {
-            FBUtilities.serialize(new TSerializer(new TBinaryProtocol.Factory()), asSlicePredicate(sliceCommand.predicate), out);
+            out.writeInt(0);
         }
         else
         {
-            IDiskAtomFilter.Serializer.instance.serialize(sliceCommand.predicate, out, version);
-        }
-
-        if (version >= MessagingService.VERSION_11)
-        {
-            if (sliceCommand.row_filter == null)
+            out.writeInt(sliceCommand.row_filter.size());
+            for (IndexExpression expr : sliceCommand.row_filter)
             {
-                out.writeInt(0);
-            }
-            else
-            {
-                out.writeInt(sliceCommand.row_filter.size());
-                for (IndexExpression expr : sliceCommand.row_filter)
-                {
-                    if (version < MessagingService.VERSION_12)
-                    {
-                        FBUtilities.serialize(new TSerializer(new TBinaryProtocol.Factory()), expr, out);
-                    }
-                    else
-                    {
-                        ByteBufferUtil.writeWithShortLength(expr.column_name, out);
-                        out.writeInt(expr.op.getValue());
-                        ByteBufferUtil.writeWithShortLength(expr.value, out);
-                    }
-                }
+                ByteBufferUtil.writeWithShortLength(expr.column_name, out);
+                out.writeInt(expr.op.getValue());
+                ByteBufferUtil.writeWithShortLength(expr.value, out);
             }
         }
         AbstractBounds.serializer.serialize(sliceCommand.range, out, version);
         out.writeInt(sliceCommand.maxResults);
-        if (version >= MessagingService.VERSION_11)
-        {
-            out.writeBoolean(sliceCommand.countCQL3Rows);
-            out.writeBoolean(sliceCommand.isPaging);
-        }
+        out.writeBoolean(sliceCommand.countCQL3Rows);
+        out.writeBoolean(sliceCommand.isPaging);
     }
 
     public RangeSliceCommand deserialize(DataInput in, int version) throws IOException
@@ -283,16 +232,7 @@ class RangeSliceCommandSerializer implements IVersionedSerializer<RangeSliceComm
                 comparator = metadata.comparator;
             }
 
-            if (version < MessagingService.VERSION_12)
-            {
-                SlicePredicate pred = new SlicePredicate();
-                FBUtilities.deserialize(new TDeserializer(new TBinaryProtocol.Factory()), pred, in);
-                predicate = ThriftValidation.asIFilter(pred, metadata, superColumn);
-            }
-            else
-            {
-                predicate = IDiskAtomFilter.Serializer.instance.deserialize(in, version, comparator);
-            }
+            predicate = IDiskAtomFilter.Serializer.instance.deserialize(in, version, comparator);
 
             if (metadata.cfType == ColumnFamilyType.Super)
                 predicate = SuperColumns.fromSCFilter((CompositeType)metadata.comparator, superColumn, predicate);
@@ -303,37 +243,21 @@ class RangeSliceCommandSerializer implements IVersionedSerializer<RangeSliceComm
         }
 
         List<IndexExpression> rowFilter = null;
-        if (version >= MessagingService.VERSION_11)
+        int filterCount = in.readInt();
+        rowFilter = new ArrayList<IndexExpression>(filterCount);
+        for (int i = 0; i < filterCount; i++)
         {
-            int filterCount = in.readInt();
-            rowFilter = new ArrayList<IndexExpression>(filterCount);
-            for (int i = 0; i < filterCount; i++)
-            {
-                IndexExpression expr;
-                if (version < MessagingService.VERSION_12)
-                {
-                    expr = new IndexExpression();
-                    FBUtilities.deserialize(new TDeserializer(new TBinaryProtocol.Factory()), expr, in);
-                }
-                else
-                {
-                    expr = new IndexExpression(ByteBufferUtil.readWithShortLength(in),
-                                               IndexOperator.findByValue(in.readInt()),
-                                               ByteBufferUtil.readWithShortLength(in));
-                }
-                rowFilter.add(expr);
-            }
+            IndexExpression expr;
+            expr = new IndexExpression(ByteBufferUtil.readWithShortLength(in),
+                                       IndexOperator.findByValue(in.readInt()),
+                                       ByteBufferUtil.readWithShortLength(in));
+            rowFilter.add(expr);
         }
         AbstractBounds<RowPosition> range = AbstractBounds.serializer.deserialize(in, version).toRowBounds();
 
         int maxResults = in.readInt();
-        boolean countCQL3Rows = false;
-        boolean isPaging = false;
-        if (version >= MessagingService.VERSION_11)
-        {
-            countCQL3Rows = in.readBoolean();
-            isPaging = in.readBoolean();
-        }
+        boolean countCQL3Rows = in.readBoolean();
+        boolean isPaging = in.readBoolean();
         return new RangeSliceCommand(keyspace, columnFamily, predicate, range, rowFilter, maxResults, countCQL3Rows, isPaging);
     }
 
@@ -365,66 +289,26 @@ class RangeSliceCommandSerializer implements IVersionedSerializer<RangeSliceComm
             }
         }
 
-        if (version < MessagingService.VERSION_12)
+        size += IDiskAtomFilter.Serializer.instance.serializedSize(filter, version);
+
+        if (rsc.row_filter == null)
         {
-            TSerializer ser = new TSerializer(new TBinaryProtocol.Factory());
-            try
-            {
-                int predicateLength = ser.serialize(asSlicePredicate(filter)).length;
-                if (version < MessagingService.VERSION_12)
-                    size += TypeSizes.NATIVE.sizeof(predicateLength);
-                size += predicateLength;
-            }
-            catch (TException e)
-            {
-                throw new RuntimeException(e);
-            }
+            size += TypeSizes.NATIVE.sizeof(0);
         }
         else
         {
-            size += IDiskAtomFilter.Serializer.instance.serializedSize(filter, version);
-        }
-
-        if (version >= MessagingService.VERSION_11)
-        {
-            if (rsc.row_filter == null)
+            size += TypeSizes.NATIVE.sizeof(rsc.row_filter.size());
+            for (IndexExpression expr : rsc.row_filter)
             {
-                size += TypeSizes.NATIVE.sizeof(0);
-            }
-            else
-            {
-                size += TypeSizes.NATIVE.sizeof(rsc.row_filter.size());
-                for (IndexExpression expr : rsc.row_filter)
-                {
-                    if (version < MessagingService.VERSION_12)
-                    {
-                        try
-                        {
-                            int filterLength = new TSerializer(new TBinaryProtocol.Factory()).serialize(expr).length;
-                            size += TypeSizes.NATIVE.sizeof(filterLength);
-                            size += filterLength;
-                        }
-                        catch (TException e)
-                        {
-                            throw new RuntimeException(e);
-                        }
-                    }
-                    else
-                    {
-                        size += TypeSizes.NATIVE.sizeofWithShortLength(expr.column_name);
-                        size += TypeSizes.NATIVE.sizeof(expr.op.getValue());
-                        size += TypeSizes.NATIVE.sizeofWithLength(expr.value);
-                    }
-                }
+                size += TypeSizes.NATIVE.sizeofWithShortLength(expr.column_name);
+                size += TypeSizes.NATIVE.sizeof(expr.op.getValue());
+                size += TypeSizes.NATIVE.sizeofWithLength(expr.value);
             }
         }
         size += AbstractBounds.serializer.serializedSize(rsc.range, version);
         size += TypeSizes.NATIVE.sizeof(rsc.maxResults);
-        if (version >= MessagingService.VERSION_11)
-        {
-            size += TypeSizes.NATIVE.sizeof(rsc.countCQL3Rows);
-            size += TypeSizes.NATIVE.sizeof(rsc.isPaging);
-        }
+        size += TypeSizes.NATIVE.sizeof(rsc.countCQL3Rows);
+        size += TypeSizes.NATIVE.sizeof(rsc.isPaging);
         return size;
     }
 }
diff --git a/src/java/org/apache/cassandra/db/RowIndexEntry.java b/src/java/org/apache/cassandra/db/RowIndexEntry.java
index bd9b48367e..e987cb54a0 100644
--- a/src/java/org/apache/cassandra/db/RowIndexEntry.java
+++ b/src/java/org/apache/cassandra/db/RowIndexEntry.java
@@ -110,9 +110,6 @@ public class RowIndexEntry implements IMeasurableMemory
         {
             long position = in.readLong();
 
-            if (!version.hasPromotedIndexes)
-                return new RowIndexEntry(position);
-
             int size = in.readInt();
             if (size > 0)
             {
@@ -123,14 +120,6 @@ public class RowIndexEntry implements IMeasurableMemory
                 for (int i = 0; i < entries; i++)
                     columnsIndex.add(IndexHelper.IndexInfo.deserialize(in));
 
-                if (version.hasRowLevelBF)
-                {
-                    // we only ever used murmur3 BF in the promoted index
-                    in.readInt(); // hash count
-                    int words = in.readInt(); // number of Longs in the OpenBitSet
-                    FileUtils.skipBytesFully(in, words * 8);
-                }
-
                 return new IndexedEntry(position, deletionTime, columnsIndex);
             }
             else
@@ -139,11 +128,10 @@ public class RowIndexEntry implements IMeasurableMemory
             }
         }
 
-        public void skip(DataInput in, Descriptor.Version version) throws IOException
+        public void skip(DataInput in) throws IOException
         {
             in.readLong();
-            if (version.hasPromotedIndexes)
-                skipPromotedIndex(in);
+            skipPromotedIndex(in);
         }
 
         public void skipPromotedIndex(DataInput in) throws IOException
diff --git a/src/java/org/apache/cassandra/db/RowMutation.java b/src/java/org/apache/cassandra/db/RowMutation.java
index 9e0e78fb69..b08055fb07 100644
--- a/src/java/org/apache/cassandra/db/RowMutation.java
+++ b/src/java/org/apache/cassandra/db/RowMutation.java
@@ -252,11 +252,7 @@ public class RowMutation implements IMutation
             out.writeInt(size);
             assert size > 0;
             for (Map.Entry<UUID, ColumnFamily> entry : rm.modifications.entrySet())
-            {
-                if (version < MessagingService.VERSION_12)
-                    ColumnFamily.serializer.serializeCfId(entry.getKey(), out, version);
                 ColumnFamily.serializer.serialize(entry.getValue(), out, version);
-            }
         }
 
         public RowMutation deserialize(DataInput in, int version, ColumnSerializer.Flag flag) throws IOException
@@ -292,9 +288,6 @@ public class RowMutation implements IMutation
 
         private ColumnFamily deserializeOneCf(DataInput in, int version, ColumnSerializer.Flag flag) throws IOException
         {
-            // We used to uselessly write the cf id here
-            if (version < MessagingService.VERSION_12)
-                ColumnFamily.serializer.deserializeCfId(in, version);
             ColumnFamily cf = ColumnFamily.serializer.deserialize(in, UnsortedColumns.factory, flag, version);
             // We don't allow RowMutation with null column family, so we should never get null back.
             assert cf != null;
@@ -319,11 +312,7 @@ public class RowMutation implements IMutation
 
             size += sizes.sizeof(rm.modifications.size());
             for (Map.Entry<UUID,ColumnFamily> entry : rm.modifications.entrySet())
-            {
-                if (version < MessagingService.VERSION_12)
-                    size += ColumnFamily.serializer.cfIdSerializedSize(entry.getValue().id(), sizes, version);
                 size += ColumnFamily.serializer.serializedSize(entry.getValue(), TypeSizes.NATIVE, version);
-            }
 
             return size;
         }
diff --git a/src/java/org/apache/cassandra/db/RowMutationVerbHandler.java b/src/java/org/apache/cassandra/db/RowMutationVerbHandler.java
index 588852cb50..744dca9a67 100644
--- a/src/java/org/apache/cassandra/db/RowMutationVerbHandler.java
+++ b/src/java/org/apache/cassandra/db/RowMutationVerbHandler.java
@@ -45,7 +45,7 @@ public class RowMutationVerbHandler implements IVerbHandler<RowMutation>
             if (from == null)
             {
                 byte[] forwardBytes = message.parameters.get(RowMutation.FORWARD_TO);
-                if (forwardBytes != null && message.version >= MessagingService.VERSION_11)
+                if (forwardBytes != null)
                     forwardToLocalNodes(rm, message.verb, forwardBytes, message.from);
             }
             else
diff --git a/src/java/org/apache/cassandra/db/SuperColumns.java b/src/java/org/apache/cassandra/db/SuperColumns.java
index adcde06079..753cd9178b 100644
--- a/src/java/org/apache/cassandra/db/SuperColumns.java
+++ b/src/java/org/apache/cassandra/db/SuperColumns.java
@@ -34,7 +34,6 @@ import org.apache.cassandra.config.CFMetaData;
 import org.apache.cassandra.db.filter.*;
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.CompositeType;
-import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
 public class SuperColumns
@@ -69,7 +68,7 @@ public class SuperColumns
             List<DeletionTime> delTimes = delInfo.rangeCovering(entry.getKey());
             assert delTimes.size() <= 1; // We're supposed to have either no deletion, or a full SC deletion.
             DeletionInfo scDelInfo = delTimes.isEmpty() ? DeletionInfo.LIVE : new DeletionInfo(delTimes.get(0));
-            DeletionInfo.serializer().serialize(scDelInfo, out, MessagingService.VERSION_10);
+            DeletionTime.serializer.serialize(scDelInfo.getTopLevelDeletion(), out);
 
             out.writeInt(entry.getValue().size());
             for (Column subColumn : entry.getValue())
@@ -129,7 +128,7 @@ public class SuperColumns
             List<DeletionTime> delTimes = delInfo.rangeCovering(entry.getKey());
             assert delTimes.size() <= 1; // We're supposed to have either no deletion, or a full SC deletion.
             DeletionInfo scDelInfo = delTimes.isEmpty() ? DeletionInfo.LIVE : new DeletionInfo(delTimes.get(0));
-            size += DeletionInfo.serializer().serializedSize(scDelInfo, MessagingService.VERSION_10);
+            size += DeletionTime.serializer.serializedSize(scDelInfo.getTopLevelDeletion(), TypeSizes.NATIVE);
 
             size += typeSizes.sizeof(entry.getValue().size());
             for (Column subColumn : entry.getValue())
@@ -177,7 +176,7 @@ public class SuperColumns
                 ++read;
 
                 scName = ByteBufferUtil.readWithShortLength(in);
-                DeletionInfo delInfo = DeletionInfo.serializer().deserialize(in, MessagingService.VERSION_10, null);
+                DeletionInfo delInfo = new DeletionInfo(DeletionTime.serializer.deserialize(in));
                 assert !delInfo.rangeIterator().hasNext(); // We assume no range tombstone (there was no way to insert some in a SCF in 1.2)
 
                 /* read the number of columns */
@@ -379,7 +378,7 @@ public class SuperColumns
                 CompositeType.Builder builder = type.builder().add(bb);
                 slices[i++] = new ColumnSlice(builder.build(), builder.buildAsEndOfRange());
             }
-            return new SliceQueryFilter(slices, false, slices.length, 1, 1);
+            return new SliceQueryFilter(slices, false, slices.length, 1);
         }
         else
         {
diff --git a/src/java/org/apache/cassandra/db/SystemTable.java b/src/java/org/apache/cassandra/db/SystemTable.java
index 5a1831445a..dc99bc877c 100644
--- a/src/java/org/apache/cassandra/db/SystemTable.java
+++ b/src/java/org/apache/cassandra/db/SystemTable.java
@@ -78,11 +78,6 @@ public class SystemTable
     public static final String COMPACTION_LOG = "compactions_in_progress";
     public static final String PAXOS_CF = "paxos";
 
-    @Deprecated
-    public static final String OLD_STATUS_CF = "LocationInfo";
-    @Deprecated
-    public static final String OLD_HINTS_CF = "HintsColumnFamily";
-
     private static final String LOCAL_KEY = "local";
     private static final ByteBuffer ALL_LOCAL_NODE_ID_KEY = ByteBufferUtil.bytes("Local");
 
@@ -100,20 +95,7 @@ public class SystemTable
 
     public static void finishStartup()
     {
-        DefsTable.fixSchemaNanoTimestamps();
         setupVersion();
-        try
-        {
-            upgradeSystemData();
-        }
-        catch (ExecutionException e)
-        {
-            throw new RuntimeException(e);
-        }
-        catch (InterruptedException e)
-        {
-            throw new RuntimeException(e);
-        }
 
         // add entries to system schema columnfamilies for the hardcoded system definitions
         for (String ksname : Schema.systemKeyspaceNames)
@@ -146,47 +128,6 @@ public class SystemTable
                                          DatabaseDescriptor.getPartitioner().getClass().getName()));
     }
 
-    /** if system data becomes incompatible across versions of cassandra, that logic (and associated purging) is managed here */
-    private static void upgradeSystemData() throws ExecutionException, InterruptedException
-    {
-        Table table = Table.open(Table.SYSTEM_KS);
-        ColumnFamilyStore oldStatusCfs = table.getColumnFamilyStore(OLD_STATUS_CF);
-        if (oldStatusCfs.getSSTables().size() > 0)
-        {
-            SortedSet<ByteBuffer> cols = new TreeSet<ByteBuffer>(BytesType.instance);
-            cols.add(ByteBufferUtil.bytes("ClusterName"));
-            cols.add(ByteBufferUtil.bytes("Token"));
-            QueryFilter filter = QueryFilter.getNamesFilter(decorate(ByteBufferUtil.bytes("L")), OLD_STATUS_CF, cols);
-            ColumnFamily oldCf = oldStatusCfs.getColumnFamily(filter);
-            Iterator<Column> oldColumns = oldCf.iterator();
-
-            String clusterName = null;
-            try
-            {
-                clusterName = ByteBufferUtil.string(oldColumns.next().value());
-            }
-            catch (CharacterCodingException e)
-            {
-                throw new RuntimeException(e);
-            }
-            // serialize the old token as a collection of (one )tokens.
-            Token token = StorageService.getPartitioner().getTokenFactory().fromByteArray(oldColumns.next().value());
-            String tokenBytes = tokensAsSet(Collections.singleton(token));
-            // (assume that any node getting upgraded was bootstrapped, since that was stored in a separate row for no particular reason)
-            String req = "INSERT INTO system.%s (key, cluster_name, tokens, bootstrapped) VALUES ('%s', '%s', %s, '%s')";
-            processInternal(String.format(req, LOCAL_CF, LOCAL_KEY, clusterName, tokenBytes, BootstrapState.COMPLETED.name()));
-
-            oldStatusCfs.truncateBlocking();
-        }
-
-        ColumnFamilyStore oldHintsCfs = table.getColumnFamilyStore(OLD_HINTS_CF);
-        if (oldHintsCfs.getSSTables().size() > 0)
-        {
-            logger.info("Possible old-format hints found. Truncating");
-            oldHintsCfs.truncateBlocking();
-        }
-    }
-
     /**
      * Write compaction log, except columfamilies under system keyspace.
      *
diff --git a/src/java/org/apache/cassandra/db/WriteResponse.java b/src/java/org/apache/cassandra/db/WriteResponse.java
index 7bc20321b1..bfed215e9a 100644
--- a/src/java/org/apache/cassandra/db/WriteResponse.java
+++ b/src/java/org/apache/cassandra/db/WriteResponse.java
@@ -45,30 +45,15 @@ public class WriteResponse
     {
         public void serialize(WriteResponse wm, DataOutput out, int version) throws IOException
         {
-            if (version < MessagingService.VERSION_12)
-            {
-                out.writeUTF("");
-                ByteBufferUtil.writeWithShortLength(ByteBufferUtil.EMPTY_BYTE_BUFFER, out);
-                out.writeBoolean(true);
-            }
         }
 
         public WriteResponse deserialize(DataInput in, int version) throws IOException
         {
-            if (version < MessagingService.VERSION_12)
-            {
-                in.readUTF();
-                ByteBufferUtil.readWithShortLength(in);
-                in.readBoolean();
-            }
             return new WriteResponse();
         }
 
         public long serializedSize(WriteResponse response, int version)
         {
-            TypeSizes sizes = TypeSizes.NATIVE;
-            if (version < MessagingService.VERSION_12)
-                return sizes.sizeof("") + sizes.sizeof((short) 0) + sizes.sizeof(true);
             return 0;
         }
     }
diff --git a/src/java/org/apache/cassandra/db/columniterator/IndexedSliceReader.java b/src/java/org/apache/cassandra/db/columniterator/IndexedSliceReader.java
index f315ee9eb5..ffbca1a5ec 100644
--- a/src/java/org/apache/cassandra/db/columniterator/IndexedSliceReader.java
+++ b/src/java/org/apache/cassandra/db/columniterator/IndexedSliceReader.java
@@ -73,34 +73,19 @@ class IndexedSliceReader extends AbstractIterator<OnDiskAtom> implements OnDiskA
         try
         {
             Descriptor.Version version = sstable.descriptor.version;
-            if (version.hasPromotedIndexes)
-            {
-                this.indexes = indexEntry.columnsIndex();
-                if (indexes.isEmpty())
-                {
-                    setToRowStart(sstable, indexEntry, input);
-                    this.emptyColumnFamily = EmptyColumns.factory.create(sstable.metadata);
-                    emptyColumnFamily.delete(DeletionInfo.serializer().deserializeFromSSTable(file, version));
-                    fetcher = new SimpleBlockFetcher();
-                }
-                else
-                {
-                    emptyColumnFamily = EmptyColumns.factory.create(sstable.metadata);
-                    emptyColumnFamily.delete(indexEntry.deletionTime());
-                    fetcher = new IndexedBlockFetcher(indexEntry.position);
-                }
-            }
-            else
+            this.indexes = indexEntry.columnsIndex();
+            if (indexes.isEmpty())
             {
                 setToRowStart(sstable, indexEntry, input);
-                IndexHelper.skipBloomFilter(file);
-                this.indexes = IndexHelper.deserializeIndex(file);
                 this.emptyColumnFamily = EmptyColumns.factory.create(sstable.metadata);
                 emptyColumnFamily.delete(DeletionInfo.serializer().deserializeFromSSTable(file, version));
-                fetcher = indexes.isEmpty()
-                        ? new SimpleBlockFetcher()
-                        : new IndexedBlockFetcher(file.getFilePointer() + 4); // We still have the column count to
-                                                                              // skip to get the basePosition
+                fetcher = new SimpleBlockFetcher();
+            }
+            else
+            {
+                emptyColumnFamily = EmptyColumns.factory.create(sstable.metadata);
+                emptyColumnFamily.delete(indexEntry.deletionTime());
+                fetcher = new IndexedBlockFetcher(indexEntry.position);
             }
         }
         catch (IOException e)
@@ -124,8 +109,8 @@ class IndexedSliceReader extends AbstractIterator<OnDiskAtom> implements OnDiskA
             this.file = input;
             input.seek(indexEntry.position);
         }
-        sstable.decodeKey(ByteBufferUtil.readWithShortLength(file));
-        SSTableReader.readRowSize(file, sstable.descriptor);
+        sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(file));
+        file.readLong();
     }
 
     public ColumnFamily getColumnFamily()
diff --git a/src/java/org/apache/cassandra/db/columniterator/SSTableNamesIterator.java b/src/java/org/apache/cassandra/db/columniterator/SSTableNamesIterator.java
index c2027630ef..bc0af30e48 100644
--- a/src/java/org/apache/cassandra/db/columniterator/SSTableNamesIterator.java
+++ b/src/java/org/apache/cassandra/db/columniterator/SSTableNamesIterator.java
@@ -113,23 +113,12 @@ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement
             else
                 file.seek(indexEntry.position);
 
-            DecoratedKey keyInDisk = SSTableReader.decodeKey(sstable.partitioner,
-                                                             sstable.descriptor,
-                                                             ByteBufferUtil.readWithShortLength(file));
+            DecoratedKey keyInDisk = sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(file));
             assert keyInDisk.equals(key) : String.format("%s != %s in %s", keyInDisk, key, file.getPath());
-            SSTableReader.readRowSize(file, sstable.descriptor);
+            file.readLong();
         }
 
-        if (sstable.descriptor.version.hasPromotedIndexes)
-        {
-            indexList = indexEntry.columnsIndex();
-        }
-        else
-        {
-            assert file != null;
-            IndexHelper.skipBloomFilter(file);
-            indexList = IndexHelper.deserializeIndex(file);
-        }
+        indexList = indexEntry.columnsIndex();
 
         if (!indexEntry.isIndexed())
         {
@@ -157,18 +146,7 @@ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement
         }
         else
         {
-            long basePosition;
-            if (sstable.descriptor.version.hasPromotedIndexes)
-            {
-                basePosition = indexEntry.position;
-            }
-            else
-            {
-                assert file != null;
-                file.readInt(); // column count
-                basePosition = file.getFilePointer();
-            }
-            readIndexedColumns(sstable.metadata, file, columns, indexList, basePosition, result);
+            readIndexedColumns(sstable.metadata, file, columns, indexList, indexEntry.position, result);
         }
 
         // create an iterator view of the columns we read
diff --git a/src/java/org/apache/cassandra/db/columniterator/SimpleSliceReader.java b/src/java/org/apache/cassandra/db/columniterator/SimpleSliceReader.java
index 45f58a7745..efbb92cd72 100644
--- a/src/java/org/apache/cassandra/db/columniterator/SimpleSliceReader.java
+++ b/src/java/org/apache/cassandra/db/columniterator/SimpleSliceReader.java
@@ -63,14 +63,9 @@ class SimpleSliceReader extends AbstractIterator<OnDiskAtom> implements OnDiskAt
 
             // Skip key and data size
             ByteBufferUtil.skipShortLength(file);
-            SSTableReader.readRowSize(file, sstable.descriptor);
+            file.readLong();
 
             Descriptor.Version version = sstable.descriptor.version;
-            if (!version.hasPromotedIndexes)
-            {
-                IndexHelper.skipBloomFilter(file);
-                IndexHelper.skipIndex(file);
-            }
 
             emptyColumnFamily = EmptyColumns.factory.create(sstable.metadata);
             emptyColumnFamily.delete(DeletionInfo.serializer().deserializeFromSSTable(file, version));
diff --git a/src/java/org/apache/cassandra/db/commitlog/CommitLogDescriptor.java b/src/java/org/apache/cassandra/db/commitlog/CommitLogDescriptor.java
index 533219c89c..87de7d843b 100644
--- a/src/java/org/apache/cassandra/db/commitlog/CommitLogDescriptor.java
+++ b/src/java/org/apache/cassandra/db/commitlog/CommitLogDescriptor.java
@@ -33,7 +33,6 @@ public class CommitLogDescriptor
     // match both legacy and new version of commitlogs Ex: CommitLog-12345.log and CommitLog-4-12345.log.
     private static final Pattern COMMIT_LOG_FILE_PATTERN = Pattern.compile(FILENAME_PREFIX + "((\\d+)(" + SEPARATOR + "\\d+)?)" + FILENAME_EXTENSION);
 
-    public static final int LEGACY_VERSION = 1;
     public static final int VERSION_12 = 2;
     public static final int VERSION_20 = 3;
     /**
@@ -62,16 +61,11 @@ public class CommitLogDescriptor
         if (!(matcher = COMMIT_LOG_FILE_PATTERN.matcher(name)).matches())
             throw new RuntimeException("Cannot parse the version of the file: " + name);
 
-        if (matcher.group(3) != null)
-        {
-            long id = Long.parseLong(matcher.group(3).split(SEPARATOR)[1]);
-            return new CommitLogDescriptor(Integer.parseInt(matcher.group(2)), id);
-        }
-        else
-        {
-            long id = Long.parseLong(matcher.group(1));
-            return new CommitLogDescriptor(LEGACY_VERSION, id);
-        }
+        if (matcher.group(3) == null)
+            throw new UnsupportedOperationException("Commitlog segment is too old to open; upgrade to 1.2.5+ first");
+
+        long id = Long.parseLong(matcher.group(3).split(SEPARATOR)[1]);
+        return new CommitLogDescriptor(Integer.parseInt(matcher.group(2)), id);
     }
 
     public int getMessagingVersion()
@@ -79,8 +73,6 @@ public class CommitLogDescriptor
         assert MessagingService.current_version == MessagingService.VERSION_20;
         switch (version)
         {
-            case LEGACY_VERSION:
-                return MessagingService.VERSION_11;
             case VERSION_12:
                 return MessagingService.VERSION_12;
             case VERSION_20:
diff --git a/src/java/org/apache/cassandra/db/compaction/Scrubber.java b/src/java/org/apache/cassandra/db/compaction/Scrubber.java
index 993cf3cb05..fa4dd51403 100644
--- a/src/java/org/apache/cassandra/db/compaction/Scrubber.java
+++ b/src/java/org/apache/cassandra/db/compaction/Scrubber.java
@@ -126,8 +126,8 @@ public class Scrubber implements Closeable
                 long dataSize = -1;
                 try
                 {
-                    key = SSTableReader.decodeKey(sstable.partitioner, sstable.descriptor, ByteBufferUtil.readWithShortLength(dataFile));
-                    dataSize = sstable.descriptor.version.hasIntRowSize ? dataFile.readInt() : dataFile.readLong();
+                    key = sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(dataFile));
+                    dataSize = dataFile.readLong();
                     outputHandler.debug(String.format("row %s is %s bytes", ByteBufferUtil.bytesToHex(key.key), dataSize));
                 }
                 catch (Throwable th)
@@ -155,7 +155,7 @@ public class Scrubber implements Closeable
                 long dataStart = dataFile.getFilePointer();
                 long dataStartFromIndex = currentIndexKey == null
                                         ? -1
-                                        : rowStart + 2 + currentIndexKey.remaining() + (sstable.descriptor.version.hasIntRowSize ? 4 : 8);
+                                        : rowStart + 2 + currentIndexKey.remaining() + 8;
                 long dataSizeFromIndex = nextRowPositionFromIndex - dataStartFromIndex;
                 assert currentIndexKey != null || indexFile.isEOF();
                 if (currentIndexKey != null)
@@ -201,7 +201,7 @@ public class Scrubber implements Closeable
                     {
                         outputHandler.output(String.format("Retrying from row index; data is %s bytes starting at %s",
                                                   dataSizeFromIndex, dataStartFromIndex));
-                        key = SSTableReader.decodeKey(sstable.partitioner, sstable.descriptor, currentIndexKey);
+                        key = sstable.partitioner.decorateKey(currentIndexKey);
                         try
                         {
                             SSTableIdentityIterator row = new SSTableIdentityIterator(sstable, dataFile, key, dataStartFromIndex, dataSizeFromIndex, true);
diff --git a/src/java/org/apache/cassandra/db/filter/NamesQueryFilter.java b/src/java/org/apache/cassandra/db/filter/NamesQueryFilter.java
index bc2f71c35b..4e31cf228a 100644
--- a/src/java/org/apache/cassandra/db/filter/NamesQueryFilter.java
+++ b/src/java/org/apache/cassandra/db/filter/NamesQueryFilter.java
@@ -157,10 +157,7 @@ public class NamesQueryFilter implements IDiskAtomFilter
             {
                 ByteBufferUtil.writeWithShortLength(cName, out);
             }
-            // If we talking against an older node, we have no way to tell him that we want to count CQL3 rows. This does mean that
-            // this node may return less data than required. The workaround being to upgrade all nodes.
-            if (version >= MessagingService.VERSION_12)
-                out.writeBoolean(f.countCQL3Rows);
+            out.writeBoolean(f.countCQL3Rows);
         }
 
         public NamesQueryFilter deserialize(DataInput in, int version) throws IOException
@@ -174,9 +171,7 @@ public class NamesQueryFilter implements IDiskAtomFilter
             SortedSet<ByteBuffer> columns = new TreeSet<ByteBuffer>(comparator);
             for (int i = 0; i < size; ++i)
                 columns.add(ByteBufferUtil.readWithShortLength(in));
-            boolean countCQL3Rows = version >= MessagingService.VERSION_12
-                                  ? in.readBoolean()
-                                  : false;
+            boolean countCQL3Rows = in.readBoolean();
             return new NamesQueryFilter(columns, countCQL3Rows);
         }
 
@@ -189,8 +184,7 @@ public class NamesQueryFilter implements IDiskAtomFilter
                 int cNameSize = cName.remaining();
                 size += sizes.sizeof((short) cNameSize) + cNameSize;
             }
-            if (version >= MessagingService.VERSION_12)
-                size += sizes.sizeof(f.countCQL3Rows);
+            size += sizes.sizeof(f.countCQL3Rows);
             return size;
         }
     }
diff --git a/src/java/org/apache/cassandra/db/filter/SliceQueryFilter.java b/src/java/org/apache/cassandra/db/filter/SliceQueryFilter.java
index e19ddcbd1e..4f93e34832 100644
--- a/src/java/org/apache/cassandra/db/filter/SliceQueryFilter.java
+++ b/src/java/org/apache/cassandra/db/filter/SliceQueryFilter.java
@@ -38,7 +38,6 @@ import org.apache.cassandra.db.marshal.CompositeType;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.sstable.SSTableReader;
 import org.apache.cassandra.io.util.FileDataInput;
-import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.tracing.Tracing;
 
 public class SliceQueryFilter implements IDiskAtomFilter
@@ -50,8 +49,6 @@ public class SliceQueryFilter implements IDiskAtomFilter
     public final boolean reversed;
     public volatile int count;
     public final int compositesToGroup;
-    // This is a hack to allow rolling upgrade with pre-1.2 nodes
-    private final int countMutliplierForCompatibility;
 
     // Not serialized, just a ack for range slices to find the number of live column counted, even when we group
     private ColumnCounter columnCounter;
@@ -63,7 +60,7 @@ public class SliceQueryFilter implements IDiskAtomFilter
 
     public SliceQueryFilter(ByteBuffer start, ByteBuffer finish, boolean reversed, int count, int compositesToGroup)
     {
-        this(new ColumnSlice[] { new ColumnSlice(start, finish) }, reversed, count, compositesToGroup, 1);
+        this(new ColumnSlice[] { new ColumnSlice(start, finish) }, reversed, count, compositesToGroup);
     }
 
     /**
@@ -72,36 +69,35 @@ public class SliceQueryFilter implements IDiskAtomFilter
      */
     public SliceQueryFilter(ColumnSlice[] slices, boolean reversed, int count)
     {
-        this(slices, reversed, count, -1, 1);
+        this(slices, reversed, count, -1);
     }
 
-    public SliceQueryFilter(ColumnSlice[] slices, boolean reversed, int count, int compositesToGroup, int countMutliplierForCompatibility)
+    public SliceQueryFilter(ColumnSlice[] slices, boolean reversed, int count, int compositesToGroup)
     {
         this.slices = slices;
         this.reversed = reversed;
         this.count = count;
         this.compositesToGroup = compositesToGroup;
-        this.countMutliplierForCompatibility = countMutliplierForCompatibility;
     }
 
     public SliceQueryFilter cloneShallow()
     {
-        return new SliceQueryFilter(slices, reversed, count, compositesToGroup, countMutliplierForCompatibility);
+        return new SliceQueryFilter(slices, reversed, count, compositesToGroup);
     }
 
     public SliceQueryFilter withUpdatedCount(int newCount)
     {
-        return new SliceQueryFilter(slices, reversed, newCount, compositesToGroup, countMutliplierForCompatibility);
+        return new SliceQueryFilter(slices, reversed, newCount, compositesToGroup);
     }
 
     public SliceQueryFilter withUpdatedSlices(ColumnSlice[] newSlices)
     {
-        return new SliceQueryFilter(newSlices, reversed, count, compositesToGroup, countMutliplierForCompatibility);
+        return new SliceQueryFilter(newSlices, reversed, count, compositesToGroup);
     }
 
     public SliceQueryFilter withUpdatedSlice(ByteBuffer start, ByteBuffer finish)
     {
-        return new SliceQueryFilter(new ColumnSlice[]{ new ColumnSlice(start, finish) }, reversed, count, compositesToGroup, countMutliplierForCompatibility);
+        return new SliceQueryFilter(new ColumnSlice[]{ new ColumnSlice(start, finish) }, reversed, count, compositesToGroup);
     }
 
     public OnDiskAtomIterator getMemtableColumnIterator(ColumnFamily cf, DecoratedKey key)
@@ -241,50 +237,28 @@ public class SliceQueryFilter implements IDiskAtomFilter
     {
         public void serialize(SliceQueryFilter f, DataOutput out, int version) throws IOException
         {
-            if (version < MessagingService.VERSION_12)
-            {
-                // It's kind of lame, but probably better than throwing an exception
-                ColumnSlice slice = new ColumnSlice(f.start(), f.finish());
+            out.writeInt(f.slices.length);
+            for (ColumnSlice slice : f.slices)
                 ColumnSlice.serializer.serialize(slice, out, version);
-            }
-            else
-            {
-                out.writeInt(f.slices.length);
-                for (ColumnSlice slice : f.slices)
-                    ColumnSlice.serializer.serialize(slice, out, version);
-            }
             out.writeBoolean(f.reversed);
             int count = f.count;
-            if (f.compositesToGroup > 0 && version < MessagingService.VERSION_12)
-                count *= f.countMutliplierForCompatibility;
             out.writeInt(count);
 
-            if (version < MessagingService.VERSION_12)
-                return;
-
             out.writeInt(f.compositesToGroup);
         }
 
         public SliceQueryFilter deserialize(DataInput in, int version) throws IOException
         {
             ColumnSlice[] slices;
-            if (version < MessagingService.VERSION_12)
-            {
-                slices = new ColumnSlice[]{ ColumnSlice.serializer.deserialize(in, version) };
-            }
-            else
-            {
-                slices = new ColumnSlice[in.readInt()];
-                for (int i = 0; i < slices.length; i++)
-                    slices[i] = ColumnSlice.serializer.deserialize(in, version);
-            }
+            slices = new ColumnSlice[in.readInt()];
+            for (int i = 0; i < slices.length; i++)
+                slices[i] = ColumnSlice.serializer.deserialize(in, version);
             boolean reversed = in.readBoolean();
             int count = in.readInt();
             int compositesToGroup = -1;
-            if (version >= MessagingService.VERSION_12)
-                compositesToGroup = in.readInt();
+            compositesToGroup = in.readInt();
 
-            return new SliceQueryFilter(slices, reversed, count, compositesToGroup, 1);
+            return new SliceQueryFilter(slices, reversed, count, compositesToGroup);
         }
 
         public long serializedSize(SliceQueryFilter f, int version)
@@ -292,21 +266,13 @@ public class SliceQueryFilter implements IDiskAtomFilter
             TypeSizes sizes = TypeSizes.NATIVE;
 
             int size = 0;
-            if (version < MessagingService.VERSION_12)
-            {
-                size += ColumnSlice.serializer.serializedSize(new ColumnSlice(f.start(), f.finish()), version);
-            }
-            else
-            {
-                size += sizes.sizeof(f.slices.length);
-                for (ColumnSlice slice : f.slices)
-                    size += ColumnSlice.serializer.serializedSize(slice, version);
-            }
+            size += sizes.sizeof(f.slices.length);
+            for (ColumnSlice slice : f.slices)
+                size += ColumnSlice.serializer.serializedSize(slice, version);
             size += sizes.sizeof(f.reversed);
             size += sizes.sizeof(f.count);
 
-            if (version >= MessagingService.VERSION_12)
-                size += sizes.sizeof(f.compositesToGroup);
+            size += sizes.sizeof(f.compositesToGroup);
             return size;
         }
     }
diff --git a/src/java/org/apache/cassandra/dht/AbstractBounds.java b/src/java/org/apache/cassandra/dht/AbstractBounds.java
index efa886cd0f..5e0e619bdf 100644
--- a/src/java/org/apache/cassandra/dht/AbstractBounds.java
+++ b/src/java/org/apache/cassandra/dht/AbstractBounds.java
@@ -129,11 +129,6 @@ public abstract class AbstractBounds<T extends RingPosition> implements Serializ
     {
         public void serialize(AbstractBounds<?> range, DataOutput out, int version) throws IOException
         {
-            // Older version don't know how to handle abstract bounds of keys
-            // However, the serialization has been designed so that token bounds are serialized the same way that before 1.1
-            if (version < MessagingService.VERSION_11)
-                range = range.toTokenBounds();
-
             /*
              * The first int tells us if it's a range or bounds (depending on the value) _and_ if it's tokens or keys (depending on the
              * sign). We use negative kind for keys so as to preserve the serialization of token from older version.
diff --git a/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java b/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java
index d24977f329..d037518f3b 100644
--- a/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java
@@ -45,11 +45,6 @@ public abstract class AbstractByteOrderedPartitioner extends AbstractPartitioner
         return new DecoratedKey(getToken(key), key);
     }
 
-    public DecoratedKey convertFromDiskFormat(ByteBuffer key)
-    {
-        return new DecoratedKey(getToken(key), key);
-    }
-
     public BytesToken midpoint(Token ltoken, Token rtoken)
     {
         int ll,rl;
diff --git a/src/java/org/apache/cassandra/dht/IPartitioner.java b/src/java/org/apache/cassandra/dht/IPartitioner.java
index 053a95f205..084a1e56c5 100644
--- a/src/java/org/apache/cassandra/dht/IPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/IPartitioner.java
@@ -26,15 +26,6 @@ import org.apache.cassandra.db.marshal.AbstractType;
 
 public interface IPartitioner<T extends Token>
 {
-    /**
-     * @deprecated Used by SSTables before version 'e'.
-     *
-     * Convert the on disk representation to a DecoratedKey object
-     * @param key On disk representation
-     * @return DecoratedKey object
-     */
-    public DecoratedKey convertFromDiskFormat(ByteBuffer key);
-
     /**
      * Transform key to object representation of the on-disk format.
      *
diff --git a/src/java/org/apache/cassandra/dht/LocalPartitioner.java b/src/java/org/apache/cassandra/dht/LocalPartitioner.java
index 51e8f74089..b24eedea5e 100644
--- a/src/java/org/apache/cassandra/dht/LocalPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/LocalPartitioner.java
@@ -35,11 +35,6 @@ public class LocalPartitioner extends AbstractPartitioner<LocalToken>
         this.comparator = comparator;
     }
 
-    public DecoratedKey convertFromDiskFormat(ByteBuffer key)
-    {
-        return decorateKey(key);
-    }
-
     public DecoratedKey decorateKey(ByteBuffer key)
     {
         return new DecoratedKey(getToken(key), key);
diff --git a/src/java/org/apache/cassandra/dht/Murmur3Partitioner.java b/src/java/org/apache/cassandra/dht/Murmur3Partitioner.java
index a969320d39..f1411a4224 100644
--- a/src/java/org/apache/cassandra/dht/Murmur3Partitioner.java
+++ b/src/java/org/apache/cassandra/dht/Murmur3Partitioner.java
@@ -41,11 +41,6 @@ public class Murmur3Partitioner extends AbstractPartitioner<LongToken>
     public static final LongToken MINIMUM = new LongToken(Long.MIN_VALUE);
     public static final long MAXIMUM = Long.MAX_VALUE;
 
-    public DecoratedKey convertFromDiskFormat(ByteBuffer key)
-    {
-        throw new UnsupportedOperationException();
-    }
-
     public DecoratedKey decorateKey(ByteBuffer key)
     {
         return new DecoratedKey(getToken(key), key);
diff --git a/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java b/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java
index a5c194bb5d..57c72979fd 100644
--- a/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java
@@ -44,11 +44,6 @@ public class OrderPreservingPartitioner extends AbstractPartitioner<StringToken>
         return new DecoratedKey(getToken(key), key);
     }
 
-    public DecoratedKey convertFromDiskFormat(ByteBuffer key)
-    {
-        return new DecoratedKey(getToken(key), key);
-    }
-
     public StringToken midpoint(Token ltoken, Token rtoken)
     {
         int sigchars = Math.max(((StringToken)ltoken).token.length(), ((StringToken)rtoken).token.length());
diff --git a/src/java/org/apache/cassandra/dht/RandomPartitioner.java b/src/java/org/apache/cassandra/dht/RandomPartitioner.java
index 26b399e8c5..194f12ef59 100644
--- a/src/java/org/apache/cassandra/dht/RandomPartitioner.java
+++ b/src/java/org/apache/cassandra/dht/RandomPartitioner.java
@@ -20,7 +20,6 @@ package org.apache.cassandra.dht;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.nio.ByteBuffer;
-import java.nio.charset.CharacterCodingException;
 import java.util.*;
 
 import org.apache.cassandra.exceptions.ConfigurationException;
@@ -48,35 +47,6 @@ public class RandomPartitioner extends AbstractPartitioner<BigIntegerToken>
         return new DecoratedKey(getToken(key), key);
     }
 
-    public DecoratedKey convertFromDiskFormat(ByteBuffer fromdisk)
-    {
-        // find the delimiter position
-        int splitPoint = -1;
-        for (int i = fromdisk.position(); i < fromdisk.limit(); i++)
-        {
-            if (fromdisk.get(i) == DELIMITER_BYTE)
-            {
-                splitPoint = i;
-                break;
-            }
-        }
-        assert splitPoint != -1;
-
-        // and decode the token and key
-        String token = null;
-        try
-        {
-            token = ByteBufferUtil.string(fromdisk, fromdisk.position(), splitPoint - fromdisk.position());
-        }
-        catch (CharacterCodingException e)
-        {
-            throw new RuntimeException(e);
-        }
-        ByteBuffer key = fromdisk.duplicate();
-        key.position(splitPoint + 1);
-        return new DecoratedKey(new BigIntegerToken(token), key);
-    }
-
     public Token midpoint(Token ltoken, Token rtoken)
     {
         // the symbolic MINIMUM token should act as ZERO: the empty bit array
diff --git a/src/java/org/apache/cassandra/gms/GossipDigestAck.java b/src/java/org/apache/cassandra/gms/GossipDigestAck.java
index 61244c8ee9..e7a0906a6a 100644
--- a/src/java/org/apache/cassandra/gms/GossipDigestAck.java
+++ b/src/java/org/apache/cassandra/gms/GossipDigestAck.java
@@ -63,8 +63,6 @@ class GossipDigestAckSerializer implements IVersionedSerializer<GossipDigestAck>
     public void serialize(GossipDigestAck gDigestAckMessage, DataOutput out, int version) throws IOException
     {
         GossipDigestSerializationHelper.serialize(gDigestAckMessage.gDigestList, out, version);
-        if (version < MessagingService.VERSION_12)
-            out.writeBoolean(true); // 0.6 compatibility
         out.writeInt(gDigestAckMessage.epStateMap.size());
         for (Map.Entry<InetAddress, EndpointState> entry : gDigestAckMessage.epStateMap.entrySet())
         {
@@ -77,8 +75,6 @@ class GossipDigestAckSerializer implements IVersionedSerializer<GossipDigestAck>
     public GossipDigestAck deserialize(DataInput in, int version) throws IOException
     {
         List<GossipDigest> gDigestList = GossipDigestSerializationHelper.deserialize(in, version);
-        if (version < MessagingService.VERSION_12)
-            in.readBoolean(); // 0.6 compatibility
         int size = in.readInt();
         Map<InetAddress, EndpointState> epStateMap = new HashMap<InetAddress, EndpointState>(size);
 
@@ -94,8 +90,6 @@ class GossipDigestAckSerializer implements IVersionedSerializer<GossipDigestAck>
     public long serializedSize(GossipDigestAck ack, int version)
     {
         int size = GossipDigestSerializationHelper.serializedSize(ack.gDigestList, version);
-        if (version < MessagingService.VERSION_12)
-            size += TypeSizes.NATIVE.sizeof(true);
         size += TypeSizes.NATIVE.sizeof(ack.epStateMap.size());
         for (Map.Entry<InetAddress, EndpointState> entry : ack.epStateMap.entrySet())
             size += CompactEndpointSerializationHelper.serializedSize(entry.getKey())
diff --git a/src/java/org/apache/cassandra/gms/GossipDigestSyn.java b/src/java/org/apache/cassandra/gms/GossipDigestSyn.java
index fce764b381..cf196ff152 100644
--- a/src/java/org/apache/cassandra/gms/GossipDigestSyn.java
+++ b/src/java/org/apache/cassandra/gms/GossipDigestSyn.java
@@ -82,8 +82,7 @@ class GossipDigestSynSerializer implements IVersionedSerializer<GossipDigestSyn>
     public void serialize(GossipDigestSyn gDigestSynMessage, DataOutput out, int version) throws IOException
     {
         out.writeUTF(gDigestSynMessage.clusterId);
-        if (version >= MessagingService.VERSION_12)
-            out.writeUTF(gDigestSynMessage.partioner);
+        out.writeUTF(gDigestSynMessage.partioner);
         GossipDigestSerializationHelper.serialize(gDigestSynMessage.gDigests, out, version);
     }
 
@@ -91,8 +90,7 @@ class GossipDigestSynSerializer implements IVersionedSerializer<GossipDigestSyn>
     {
         String clusterId = in.readUTF();
         String partioner = null;
-        if (version >= MessagingService.VERSION_12)
-            partioner = in.readUTF();
+        partioner = in.readUTF();
         List<GossipDigest> gDigests = GossipDigestSerializationHelper.deserialize(in, version);
         return new GossipDigestSyn(clusterId, partioner, gDigests);
     }
@@ -100,8 +98,7 @@ class GossipDigestSynSerializer implements IVersionedSerializer<GossipDigestSyn>
     public long serializedSize(GossipDigestSyn syn, int version)
     {
         long size = TypeSizes.NATIVE.sizeof(syn.clusterId);
-        if (version >= MessagingService.VERSION_12)
-            size += TypeSizes.NATIVE.sizeof(syn.partioner);
+        size += TypeSizes.NATIVE.sizeof(syn.partioner);
         size += GossipDigestSerializationHelper.serializedSize(syn.gDigests, version);
         return size;
     }
diff --git a/src/java/org/apache/cassandra/gms/Gossiper.java b/src/java/org/apache/cassandra/gms/Gossiper.java
index 88cd76c176..7314429843 100644
--- a/src/java/org/apache/cassandra/gms/Gossiper.java
+++ b/src/java/org/apache/cassandra/gms/Gossiper.java
@@ -647,9 +647,9 @@ public class Gossiper implements IFailureDetectionEventListener, GossiperMBean
 
     public boolean usesHostId(InetAddress endpoint)
     {
-        if (MessagingService.instance().knowsVersion(endpoint) && MessagingService.instance().getVersion(endpoint) >= MessagingService.VERSION_12)
+        if (MessagingService.instance().knowsVersion(endpoint))
             return true;
-        else if (getEndpointStateForEndpoint(endpoint).getApplicationState(ApplicationState.NET_VERSION) != null && Integer.parseInt(getEndpointStateForEndpoint(endpoint).getApplicationState(ApplicationState.NET_VERSION).value) >= MessagingService.VERSION_12)
+        else if (getEndpointStateForEndpoint(endpoint).getApplicationState(ApplicationState.NET_VERSION) != null)
             return true;
         return false;
     }
diff --git a/src/java/org/apache/cassandra/gms/VersionedValue.java b/src/java/org/apache/cassandra/gms/VersionedValue.java
index c6e726d277..b4cfa413fa 100644
--- a/src/java/org/apache/cassandra/gms/VersionedValue.java
+++ b/src/java/org/apache/cassandra/gms/VersionedValue.java
@@ -251,35 +251,7 @@ public class VersionedValue implements Comparable<VersionedValue>
 
         private String outValue(VersionedValue value, int version)
         {
-            String outValue = value.value;
-
-            if (version < MessagingService.VERSION_12)
-            {
-                String[] pieces = value.value.split(DELIMITER_STR, -1);
-                String type = pieces[0];
-
-                if ((type.equals(STATUS_NORMAL)) || type.equals(STATUS_BOOTSTRAPPING))
-                {
-                    assert pieces.length >= 2;
-                    outValue = versionString(pieces[0], pieces[1]);
-                }
-
-                if (type.equals(STATUS_LEFT))
-                {
-                    assert pieces.length >= 3;
-
-                    // three component 'left' was adopted starting from Cassandra 1.0
-                    // previous versions have '<type>:<token>' format
-                    outValue = (version < MessagingService.VERSION_10)
-                               ? versionString(pieces[0], pieces[2])
-                               : versionString(pieces[0], pieces[2], pieces[1]);
-                }
-
-                if ((type.equals(REMOVAL_COORDINATOR)) || (type.equals(REMOVING_TOKEN)) || (type.equals(REMOVED_TOKEN)))
-                    throw new RuntimeException(String.format("Unable to serialize %s(%s...) for nodes older than 1.2",
-                                                             VersionedValue.class.getName(), type));
-            }
-            return outValue;
+            return value.value;
         }
 
         public VersionedValue deserialize(DataInput in, int version) throws IOException
diff --git a/src/java/org/apache/cassandra/io/sstable/Descriptor.java b/src/java/org/apache/cassandra/io/sstable/Descriptor.java
index 3e210252e6..51256ff218 100644
--- a/src/java/org/apache/cassandra/io/sstable/Descriptor.java
+++ b/src/java/org/apache/cassandra/io/sstable/Descriptor.java
@@ -22,7 +22,6 @@ import java.util.StringTokenizer;
 
 import com.google.common.base.Objects;
 
-import org.apache.cassandra.utils.FilterFactory;
 import org.apache.cassandra.utils.Pair;
 
 import static org.apache.cassandra.io.sstable.Component.separator;
@@ -41,31 +40,12 @@ public class Descriptor
     // or have their size changed.
     //
     // Minor versions were introduced with version "hb" for Cassandra 1.0.3; prior to that,
-    // we always incremented the major version.  In particular, versions g and h are
-    // forwards-compatible with version f, so if the above convention had been followed,
-    // we would have labeled them fb and fc.
+    // we always incremented the major version.
     public static class Version
     {
         // This needs to be at the begining for initialization sake
         public static final String current_version = "ja";
 
-        public static final Version LEGACY = new Version("a"); // "pre-history"
-        // b (0.7.0): added version to sstable filenames
-        // c (0.7.0): bloom filter component computes hashes over raw key bytes instead of strings
-        // d (0.7.0): row size in data component becomes a long instead of int
-        // e (0.7.0): stores undecorated keys in data and index components
-        // f (0.7.0): switched bloom filter implementations in data component
-        // g (0.8): tracks flushed-at context in metadata component
-        // h (1.0): tracks max client timestamp in metadata component
-        // hb (1.0.3): records compression ration in metadata component
-        // hc (1.0.4): records partitioner in metadata component
-        // hd (1.0.10): includes row tombstones in maxtimestamp
-        // he (1.1.3): includes ancestors generation in metadata component
-        // hf (1.1.6): marker that replay position corresponds to 1.1.5+ millis-based id (see CASSANDRA-4782)
-        // ia (1.2.0): column indexes are promoted to the index file
-        //             records estimated histogram of deletion times in tombstones
-        //             bloom filter (keys and columns) upgraded to Murmur3
-        // ib (1.2.1): tracks min client timestamp in metadata component
         // ic (1.2.5): omits per-row bloom filter of column names
         // ja (2.0.0): super columns are serialized as composites (note that there is no real format change,
         //               this is mostly a marker to know if we should expect super columns or not. We do need
@@ -78,51 +58,18 @@ public class Descriptor
 
         private final String version;
 
-        public final boolean hasStringsInBloomFilter;
-        public final boolean hasIntRowSize;
-        public final boolean hasEncodedKeys;
         public final boolean isLatestVersion;
-        public final boolean metadataIncludesReplayPosition;
-        public final boolean metadataIncludesModernReplayPosition;
-        public final boolean tracksMaxTimestamp;
-        public final boolean tracksMinTimestamp;
-        public final boolean hasCompressionRatio;
-        public final boolean hasPartitioner;
-        public final boolean tracksTombstones;
-        public final boolean hasPromotedIndexes;
-        public final FilterFactory.Type filterType;
-        public final boolean hasAncestors;
         public final boolean hasSuperColumns;
         public final boolean tracksMaxLocalDeletionTime;
         public final boolean hasBloomFilterFPChance;
-        public final boolean hasRowLevelBF;
 
         public Version(String version)
         {
             this.version = version;
-            hasStringsInBloomFilter = version.compareTo("c") < 0;
-            hasIntRowSize = version.compareTo("d") < 0;
-            hasEncodedKeys = version.compareTo("e") < 0;
-            metadataIncludesReplayPosition = version.compareTo("g") >= 0;
-            hasCompressionRatio = version.compareTo("hb") >= 0;
-            hasPartitioner = version.compareTo("hc") >= 0;
-            tracksMaxTimestamp = version.compareTo("hd") >= 0;
-            tracksMinTimestamp = version.compareTo("ib") >= 0;
             tracksMaxLocalDeletionTime = version.compareTo("ja") >= 0;
-            hasAncestors = version.compareTo("he") >= 0;
-            metadataIncludesModernReplayPosition = version.compareTo("hf") >= 0;
-            tracksTombstones = version.compareTo("ia") >= 0;
-            hasPromotedIndexes = version.compareTo("ia") >= 0;
             isLatestVersion = version.compareTo(current_version) == 0;
-            if (version.compareTo("f") < 0)
-                filterType = FilterFactory.Type.SHA;
-            else if (version.compareTo("ia") < 0)
-                filterType = FilterFactory.Type.MURMUR2;
-            else
-                filterType = FilterFactory.Type.MURMUR3;
             hasSuperColumns = version.compareTo("ja") < 0;
             hasBloomFilterFPChance = version.compareTo("ja") >= 0;
-            hasRowLevelBF = version.compareTo("ic") < 0;
         }
 
         /**
@@ -137,25 +84,12 @@ public class Descriptor
 
         public boolean isCompatible()
         {
-            return version.charAt(0) <= CURRENT.version.charAt(0);
+            return version.compareTo("ic") >= 0 && version.charAt(0) <= CURRENT.version.charAt(0);
         }
 
         public boolean isStreamCompatible()
         {
-            // we could add compatibility for earlier versions with the new single-pass streaming
-            // (see SSTableWriter.appendFromStream) but versions earlier than 0.7.1 don't have the
-            // MessagingService version awareness anyway so there's no point.
-            return isCompatible() && version.charAt(0) >= 'i';
-        }
-
-        /**
-         * Versions [h..hc] contained a timestamp value that was computed incorrectly, ignoring row tombstones.
-         * containsTimestamp returns true if there is a timestamp value in the metadata file; to know if it
-         * actually contains a *correct* timestamp, see tracksMaxTimestamp.
-         */
-        public boolean containsTimestamp()
-        {
-            return version.compareTo("h") >= 0;
+            return isCompatible() && version.charAt(0) >= 'j';
         }
 
         @Override
@@ -233,8 +167,7 @@ public class Descriptor
         buff.append(cfname).append(separator);
         if (temporary)
             buff.append(SSTable.TEMPFILE_MARKER).append(separator);
-        if (!Version.LEGACY.equals(version))
-            buff.append(version).append(separator);
+        buff.append(version).append(separator);
         buff.append(generation);
         return buff.toString();
     }
@@ -286,13 +219,11 @@ public class Descriptor
             nexttok = st.nextToken();
         }
 
-        // optional version string
-        Version version = Version.LEGACY;
-        if (Version.validate(nexttok))
-        {
-            version = new Version(nexttok);
-            nexttok = st.nextToken();
-        }
+        if (!Version.validate(nexttok))
+            throw new UnsupportedOperationException("SSTable " + name + " is too old to open.  Upgrade to 1.2.5 first, and run upgradesstables");
+        Version version = new Version(nexttok);
+
+        nexttok = st.nextToken();
         int generation = Integer.parseInt(nexttok);
 
         // component suffix
diff --git a/src/java/org/apache/cassandra/io/sstable/KeyIterator.java b/src/java/org/apache/cassandra/io/sstable/KeyIterator.java
index 9fe1309567..0af4537dbb 100644
--- a/src/java/org/apache/cassandra/io/sstable/KeyIterator.java
+++ b/src/java/org/apache/cassandra/io/sstable/KeyIterator.java
@@ -47,8 +47,8 @@ public class KeyIterator extends AbstractIterator<DecoratedKey> implements Close
         {
             if (in.isEOF())
                 return endOfData();
-            DecoratedKey key = SSTableReader.decodeKey(StorageService.getPartitioner(), desc, ByteBufferUtil.readWithShortLength(in));
-            RowIndexEntry.serializer.skip(in, desc.version); // skip remainder of the entry
+            DecoratedKey key = StorageService.getPartitioner().decorateKey(ByteBufferUtil.readWithShortLength(in));
+            RowIndexEntry.serializer.skip(in); // skip remainder of the entry
             return key;
         }
         catch (IOException e)
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTable.java b/src/java/org/apache/cassandra/io/sstable/SSTable.java
index f5786cf400..c2256874a2 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTable.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTable.java
@@ -244,7 +244,7 @@ public abstract class SSTable
         while (ifile.getFilePointer() < BYTES_CAP && keys < SAMPLES_CAP)
         {
             ByteBufferUtil.skipShortLength(ifile);
-            RowIndexEntry.serializer.skip(ifile, descriptor.version);
+            RowIndexEntry.serializer.skip(ifile);
             keys++;
         }
         assert keys > 0 && ifile.getFilePointer() > 0 && ifile.length() > 0 : "Unexpected empty index file: " + ifile;
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableIdentityIterator.java b/src/java/org/apache/cassandra/io/sstable/SSTableIdentityIterator.java
index 7c3f146432..8170b29bd7 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableIdentityIterator.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableIdentityIterator.java
@@ -122,38 +122,8 @@ public class SSTableIdentityIterator implements Comparable<SSTableIdentityIterat
                 if (dataStart + dataSize > file.length())
                     throw new IOException(String.format("dataSize of %s starting at %s would be larger than file %s length %s",
                                           dataSize, dataStart, file.getPath(), file.length()));
-                if (checkData && !dataVersion.hasPromotedIndexes)
-                {
-                    try
-                    {
-                        IndexHelper.skipBloomFilter(file);
-                    }
-                    catch (Exception e)
-                    {
-                        if (e instanceof EOFException)
-                            throw (EOFException) e;
-
-                        logger.debug("Invalid bloom filter in {}; will rebuild it", sstable);
-                    }
-                    try
-                    {
-                        // skipping the old row-level BF should have left the file position ready to deserialize index
-                        IndexHelper.deserializeIndex(file);
-                    }
-                    catch (Exception e)
-                    {
-                        logger.debug("Invalid row summary in {}; will rebuild it", sstable);
-                    }
-                    file.seek(this.dataStart);
-                    inputWithTracker.reset(0);
-                }
             }
 
-            if (sstable != null && !dataVersion.hasPromotedIndexes)
-            {
-                IndexHelper.skipBloomFilter(inputWithTracker);
-                IndexHelper.skipIndex(inputWithTracker);
-            }
             columnFamily = EmptyColumns.factory.create(metadata);
             columnFamily.delete(DeletionInfo.serializer().deserializeFromSSTable(inputWithTracker, dataVersion));
 
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableMetadata.java b/src/java/org/apache/cassandra/io/sstable/SSTableMetadata.java
index aa75d75dad..ba6bfb5650 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableMetadata.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableMetadata.java
@@ -356,29 +356,19 @@ public class SSTableMetadata
         {
             EstimatedHistogram.serializer.serialize(sstableStats.estimatedRowSize, out);
             EstimatedHistogram.serializer.serialize(sstableStats.estimatedColumnCount, out);
-            if (legacyDesc.version.metadataIncludesReplayPosition)
-                ReplayPosition.serializer.serialize(sstableStats.replayPosition, out);
-            if (legacyDesc.version.tracksMinTimestamp)
-                out.writeLong(sstableStats.minTimestamp);
-            if (legacyDesc.version.tracksMaxTimestamp)
-                out.writeLong(sstableStats.maxTimestamp);
+            ReplayPosition.serializer.serialize(sstableStats.replayPosition, out);
+            out.writeLong(sstableStats.minTimestamp);
+            out.writeLong(sstableStats.maxTimestamp);
             if (legacyDesc.version.tracksMaxLocalDeletionTime)
                 out.writeInt(sstableStats.maxLocalDeletionTime);
             if (legacyDesc.version.hasBloomFilterFPChance)
                 out.writeDouble(sstableStats.bloomFilterFPChance);
-            if (legacyDesc.version.hasCompressionRatio)
-                out.writeDouble(sstableStats.compressionRatio);
-            if (legacyDesc.version.hasPartitioner)
-                out.writeUTF(sstableStats.partitioner);
-            if (legacyDesc.version.hasAncestors)
-            {
-                out.writeInt(sstableStats.ancestors.size());
-                for (Integer g : sstableStats.ancestors)
-                    out.writeInt(g);
-            }
-            if (legacyDesc.version.tracksTombstones)
-                StreamingHistogram.serializer.serialize(sstableStats.estimatedTombstoneDropTime, out);
-
+            out.writeDouble(sstableStats.compressionRatio);
+            out.writeUTF(sstableStats.partitioner);
+            out.writeInt(sstableStats.ancestors.size());
+            for (Integer g : sstableStats.ancestors)
+                out.writeInt(g);
+            StreamingHistogram.serializer.serialize(sstableStats.estimatedTombstoneDropTime, out);
             out.writeInt(sstableStats.sstableLevel);
         }
 
@@ -416,30 +406,18 @@ public class SSTableMetadata
         {
             EstimatedHistogram rowSizes = EstimatedHistogram.serializer.deserialize(in);
             EstimatedHistogram columnCounts = EstimatedHistogram.serializer.deserialize(in);
-            ReplayPosition replayPosition = desc.version.metadataIncludesReplayPosition
-                                          ? ReplayPosition.serializer.deserialize(in)
-                                          : ReplayPosition.NONE;
-            if (!desc.version.metadataIncludesModernReplayPosition)
-            {
-                // replay position may be "from the future" thanks to older versions generating them with nanotime.
-                // make sure we don't omit replaying something that we should.  see CASSANDRA-4782
-                replayPosition = ReplayPosition.NONE;
-            }
-            long minTimestamp = desc.version.tracksMinTimestamp ? in.readLong() : Long.MIN_VALUE;
-            long maxTimestamp = desc.version.containsTimestamp() ? in.readLong() : Long.MAX_VALUE;
-            if (!desc.version.tracksMaxTimestamp) // see javadoc to Descriptor.containsTimestamp
-                maxTimestamp = Long.MAX_VALUE;
+            ReplayPosition replayPosition = ReplayPosition.serializer.deserialize(in);
+            long minTimestamp = in.readLong();
+            long maxTimestamp = in.readLong();
             int maxLocalDeletionTime = desc.version.tracksMaxLocalDeletionTime ? in.readInt() : Integer.MAX_VALUE;
             double bloomFilterFPChance = desc.version.hasBloomFilterFPChance ? in.readDouble() : NO_BLOOM_FLITER_FP_CHANCE;
-            double compressionRatio = desc.version.hasCompressionRatio ? in.readDouble() : NO_COMPRESSION_RATIO;
-            String partitioner = desc.version.hasPartitioner ? in.readUTF() : null;
-            int nbAncestors = desc.version.hasAncestors ? in.readInt() : 0;
+            double compressionRatio = in.readDouble();
+            String partitioner = in.readUTF();
+            int nbAncestors = in.readInt();
             Set<Integer> ancestors = new HashSet<Integer>(nbAncestors);
             for (int i = 0; i < nbAncestors; i++)
                 ancestors.add(in.readInt());
-            StreamingHistogram tombstoneHistogram = desc.version.tracksTombstones
-                                                   ? StreamingHistogram.serializer.deserialize(in)
-                                                   : defaultTombstoneDropTimeHistogram();
+            StreamingHistogram tombstoneHistogram = StreamingHistogram.serializer.deserialize(in);
             int sstableLevel = 0;
 
             if (loadSSTableLevel && in.available() > 0)
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableReader.java b/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
index f92e9ec603..4e89b3766d 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
@@ -325,11 +325,6 @@ public class SSTableReader extends SSTable
             // bf is enabled, but filter component is missing.
             load(true);
         }
-        else if (descriptor.version.hasStringsInBloomFilter)
-        {
-            // versions before 'c' encoded keys as utf-16 before hashing to the filter.
-            load(true);
-        }
         else if (descriptor.version.hasBloomFilterFPChance && sstableMetadata.bloomFilterFPChance != metadata.getBloomFilterFpChance())
         {
             // bf fp chance in sstable metadata and it has changed since compaction.
@@ -349,7 +344,7 @@ public class SSTableReader extends SSTable
         try
         {
             stream = new DataInputStream(new BufferedInputStream(new FileInputStream(descriptor.filenameFor(Component.FILTER))));
-            bf = FilterFactory.deserialize(stream, descriptor.version.filterType, true);
+            bf = FilterFactory.deserialize(stream, true);
         }
         finally
         {
@@ -393,7 +388,7 @@ public class SSTableReader extends SSTable
             {
                 ByteBuffer key = ByteBufferUtil.readWithShortLength(primaryIndex);
                 RowIndexEntry indexEntry = RowIndexEntry.serializer.deserialize(primaryIndex, descriptor.version);
-                DecoratedKey decoratedKey = decodeKey(partitioner, descriptor, key);
+                DecoratedKey decoratedKey = partitioner.decorateKey(key);
                 if (first == null)
                     first = decoratedKey;
                 last = decoratedKey;
@@ -444,8 +439,8 @@ public class SSTableReader extends SSTable
                 FileUtils.deleteWithConfirm(summariesFile);
                 return false;
             }
-            reader.first = decodeKey(reader.partitioner, reader.descriptor, ByteBufferUtil.readWithLength(iStream));
-            reader.last = decodeKey(reader.partitioner, reader.descriptor, ByteBufferUtil.readWithLength(iStream));
+            reader.first = reader.partitioner.decorateKey(ByteBufferUtil.readWithLength(iStream));
+            reader.last = reader.partitioner.decorateKey(ByteBufferUtil.readWithLength(iStream));
             ibuilder.deserializeBounds(iStream);
             dbuilder.deserializeBounds(iStream);
         }
@@ -537,7 +532,7 @@ public class SSTableReader extends SSTable
      */
     public void forceFilterFailures()
     {
-        bf = LegacyBloomFilter.alwaysMatchingBloomFilter();
+        bf = new AlwaysPresentFilter();
     }
 
     public IFilter getBloomFilter()
@@ -547,7 +542,7 @@ public class SSTableReader extends SSTable
 
     public long getBloomFilterSerializedSize()
     {
-        return FilterFactory.serializedSize(bf, descriptor.version.filterType);
+        return FilterFactory.serializedSize(bf);
     }
 
     /**
@@ -847,7 +842,7 @@ public class SSTableReader extends SSTable
                     }
                     else
                     {
-                        DecoratedKey indexDecoratedKey = decodeKey(partitioner, descriptor, indexKey);
+                        DecoratedKey indexDecoratedKey = partitioner.decorateKey(indexKey);
                         int comparison = indexDecoratedKey.compareTo(key);
                         int v = op.apply(comparison);
                         opSatisfied = (v == 0);
@@ -872,7 +867,7 @@ public class SSTableReader extends SSTable
                             {
                                 // expensive sanity check!  see CASSANDRA-4687
                                 FileDataInput fdi = dfile.getSegment(indexEntry.position);
-                                DecoratedKey keyInDisk = SSTableReader.decodeKey(partitioner, descriptor, ByteBufferUtil.readWithShortLength(fdi));
+                                DecoratedKey keyInDisk = partitioner.decorateKey(ByteBufferUtil.readWithShortLength(fdi));
                                 if (!keyInDisk.equals(key))
                                     throw new AssertionError(String.format("%s != %s in %s", keyInDisk, key, fdi.getPath()));
                                 fdi.close();
@@ -887,7 +882,7 @@ public class SSTableReader extends SSTable
                         return indexEntry;
                     }
 
-                    RowIndexEntry.serializer.skip(in, descriptor.version);
+                    RowIndexEntry.serializer.skip(in);
                 }
             }
             catch (IOException e)
@@ -1045,13 +1040,6 @@ public class SSTableReader extends SSTable
         return maxDataAge > age;
     }
 
-    public static long readRowSize(DataInput in, Descriptor d) throws IOException
-    {
-        if (d.version.hasIntRowSize)
-            return in.readInt();
-        return in.readLong();
-    }
-
     public void createLinks(String snapshotDirectoryPath)
     {
         for (Component component : components)
@@ -1062,21 +1050,6 @@ public class SSTableReader extends SSTable
         }
     }
 
-    /**
-     * Conditionally use the deprecated 'IPartitioner.convertFromDiskFormat' method.
-     */
-    public static DecoratedKey decodeKey(IPartitioner p, Descriptor d, ByteBuffer bytes)
-    {
-        if (d.version.hasEncodedKeys)
-            return p.convertFromDiskFormat(bytes);
-        return p.decorateKey(bytes);
-    }
-
-    public DecoratedKey decodeKey(ByteBuffer bytes)
-    {
-        return decodeKey(partitioner, descriptor, bytes);
-    }
-
     /**
      * TODO: Move someplace reusable
      */
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java b/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java
index 949acda782..30897693a1 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java
@@ -85,7 +85,7 @@ public class SSTableScanner implements ICompactionScanner
             while (!ifile.isEOF())
             {
                 long startPosition = ifile.getFilePointer();
-                DecoratedKey indexDecoratedKey = sstable.decodeKey(ByteBufferUtil.readWithShortLength(ifile));
+                DecoratedKey indexDecoratedKey = sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(ifile));
                 int comparison = indexDecoratedKey.compareTo(seekKey);
                 if (comparison >= 0)
                 {
@@ -98,7 +98,7 @@ public class SSTableScanner implements ICompactionScanner
                 }
                 else
                 {
-                    RowIndexEntry.serializer.skip(ifile, sstable.descriptor.version);
+                    RowIndexEntry.serializer.skip(ifile);
                 }
             }
             exhausted = true;
@@ -169,8 +169,8 @@ public class SSTableScanner implements ICompactionScanner
                 assert !dfile.isEOF();
 
                 // Read data header
-                DecoratedKey key = sstable.decodeKey(ByteBufferUtil.readWithShortLength(dfile));
-                long dataSize = SSTableReader.readRowSize(dfile, sstable.descriptor);
+                DecoratedKey key = sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(dfile));
+                long dataSize = dfile.readLong();
                 long dataStart = dfile.getFilePointer();
                 finishedAt = dataStart + dataSize;
 
@@ -217,7 +217,7 @@ public class SSTableScanner implements ICompactionScanner
 
                 if (row == null)
                 {
-                    currentKey = sstable.decodeKey(ByteBufferUtil.readWithShortLength(ifile));
+                    currentKey = sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(ifile));
                     currentEntry = RowIndexEntry.serializer.deserialize(ifile, sstable.descriptor.version);
                 }
                 else
@@ -233,7 +233,7 @@ public class SSTableScanner implements ICompactionScanner
                 }
                 else
                 {
-                    nextKey = sstable.decodeKey(ByteBufferUtil.readWithShortLength(ifile));
+                    nextKey = sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(ifile));
                     nextEntry = RowIndexEntry.serializer.deserialize(ifile, sstable.descriptor.version);
                 }
 
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java b/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java
index fb77c940be..0cbafdafd1 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableWriter.java
@@ -452,7 +452,7 @@ public class SSTableWriter extends SSTable
                     // bloom filter
                     FileOutputStream fos = new FileOutputStream(path);
                     DataOutputStream stream = new DataOutputStream(fos);
-                    FilterFactory.serialize(bf, stream, descriptor.version.filterType);
+                    FilterFactory.serialize(bf, stream);
                     stream.flush();
                     fos.getFD().sync();
                     stream.close();
diff --git a/src/java/org/apache/cassandra/net/IncomingTcpConnection.java b/src/java/org/apache/cassandra/net/IncomingTcpConnection.java
index c5e9a522b8..809d8c9509 100644
--- a/src/java/org/apache/cassandra/net/IncomingTcpConnection.java
+++ b/src/java/org/apache/cassandra/net/IncomingTcpConnection.java
@@ -138,34 +138,7 @@ public class IncomingTcpConnection extends Thread
 
     private void handleLegacyVersion(int version) throws IOException
     {
-        DataInputStream in = new DataInputStream(new BufferedInputStream(socket.getInputStream(), 4096));
-
-        from = receiveMessage(in, version); // why? see => CASSANDRA-4099
-        logger.debug("Version for {} is {}", from, version);
-        if (version > MessagingService.current_version)
-        {
-            // save the endpoint so gossip will reconnect to it
-            Gossiper.instance.addSavedEndpoint(from);
-            logger.info("Received messages from newer protocol version. Ignoring");
-            return;
-        }
-        int lastVersion = MessagingService.instance().setVersion(from, version);
-        logger.debug("set version for {} to {}", from, version);
-        if (lastVersion < version)
-        {
-            logger.debug("breaking outbound connections to force version upgrade");
-            MessagingService.instance().getConnectionPool(from).resetToNewerVersion(version);
-        }
-
-        while (true)
-        {
-            MessagingService.validateMagic(in.readInt());
-            int header = in.readInt(); // legacy protocol re-sends header for each message
-            assert !(MessagingService.getBits(header, 3, 1) == 1) : "Non-stream connection cannot change to stream";
-            version = MessagingService.getBits(header, 15, 8);
-            logger.trace("Version is now {}", version);
-            receiveMessage(in, version);
-        }
+        throw new UnsupportedOperationException("Unable to read obsolete message version " + version + "; the earliest version supported is 1.2.0");
     }
 
     private void handleStream(DataInputStream input, int version) throws IOException
@@ -187,9 +160,6 @@ public class IncomingTcpConnection extends Thread
 
     private InetAddress receiveMessage(DataInputStream input, int version) throws IOException
     {
-        if (version < MessagingService.VERSION_12)
-            input.readInt(); // size of entire message. in 1.0+ this is just a placeholder
-
         int id;
         if (version < MessagingService.VERSION_20)
             id = Integer.valueOf(input.readUTF());
@@ -197,13 +167,10 @@ public class IncomingTcpConnection extends Thread
             id = input.readInt();
 
         long timestamp = System.currentTimeMillis();
-        if (version >= MessagingService.VERSION_12)
-        {
-            // make sure to readInt, even if cross_node_to is not enabled
-            int partial = input.readInt();
-            if (DatabaseDescriptor.hasCrossNodeTimeout())
-                timestamp = (timestamp & 0xFFFFFFFF00000000L) | (((partial & 0xFFFFFFFFL) << 2) >> 2);
-        }
+        // make sure to readInt, even if cross_node_to is not enabled
+        int partial = input.readInt();
+        if (DatabaseDescriptor.hasCrossNodeTimeout())
+            timestamp = (timestamp & 0xFFFFFFFF00000000L) | (((partial & 0xFFFFFFFFL) << 2) >> 2);
 
         MessageIn message = MessageIn.read(input, version, id);
         if (message == null)
diff --git a/src/java/org/apache/cassandra/net/MessagingService.java b/src/java/org/apache/cassandra/net/MessagingService.java
index 32b07055b6..40cf6650aa 100644
--- a/src/java/org/apache/cassandra/net/MessagingService.java
+++ b/src/java/org/apache/cassandra/net/MessagingService.java
@@ -73,9 +73,6 @@ public final class MessagingService implements MessagingServiceMBean
     public static final String MBEAN_NAME = "org.apache.cassandra.net:type=MessagingService";
 
     // 8 bits version, so don't waste versions
-    public static final int VERSION_10  = 3;
-    public static final int VERSION_11  = 4;
-    public static final int VERSION_117 = 5;
     public static final int VERSION_12  = 6;
     public static final int VERSION_20  = 7;
     public static final int current_version = VERSION_20;
@@ -209,7 +206,6 @@ public final class MessagingService implements MessagingServiceMBean
         put(Verb.GOSSIP_DIGEST_SYN, GossipDigestSyn.serializer);
         put(Verb.DEFINITIONS_UPDATE, MigrationManager.MigrationsSerializer.instance);
         put(Verb.TRUNCATE, Truncation.serializer);
-        put(Verb.INDEX_SCAN, IndexScanCommand.serializer);
         put(Verb.REPLICATION_FINISHED, null);
         put(Verb.COUNTER_MUTATION, CounterMutation.serializer);
         put(Verb.SNAPSHOT, SnapshotCommand.serializer);
diff --git a/src/java/org/apache/cassandra/net/OutboundTcpConnection.java b/src/java/org/apache/cassandra/net/OutboundTcpConnection.java
index c55d64f938..de535806c2 100644
--- a/src/java/org/apache/cassandra/net/OutboundTcpConnection.java
+++ b/src/java/org/apache/cassandra/net/OutboundTcpConnection.java
@@ -222,24 +222,15 @@ public class OutboundTcpConnection extends Thread
     private void writeInternal(MessageOut message, int id, long timestamp) throws IOException
     {
         out.writeInt(MessagingService.PROTOCOL_MAGIC);
-        if (targetVersion < MessagingService.VERSION_12)
-        {
-            writeHeader(out, targetVersion, false);
-            // 0.8 included a total message size int.  1.0 doesn't need it but expects it to be there.
-            out.writeInt(-1);
-        }
 
         if (targetVersion < MessagingService.VERSION_20)
             out.writeUTF(String.valueOf(id));
         else
             out.writeInt(id);
 
-        if (targetVersion >= MessagingService.VERSION_12)
-        {
-            // int cast cuts off the high-order half of the timestamp, which we can assume remains
-            // the same between now and when the recipient reconstructs it.
-            out.writeInt((int) timestamp);
-        }
+        // int cast cuts off the high-order half of the timestamp, which we can assume remains
+        // the same between now and when the recipient reconstructs it.
+        out.writeInt((int) timestamp);
         message.serialize(out, targetVersion);
     }
 
@@ -311,38 +302,35 @@ public class OutboundTcpConnection extends Thread
                 }
                 out = new DataOutputStream(new BufferedOutputStream(socket.getOutputStream(), 4096));
 
-                if (targetVersion >= MessagingService.VERSION_12)
-                {
-                    out.writeInt(MessagingService.PROTOCOL_MAGIC);
-                    writeHeader(out, targetVersion, shouldCompressConnection());
-                    out.flush();
+                out.writeInt(MessagingService.PROTOCOL_MAGIC);
+                writeHeader(out, targetVersion, shouldCompressConnection());
+                out.flush();
 
-                    DataInputStream in = new DataInputStream(socket.getInputStream());
-                    int maxTargetVersion = in.readInt();
-                    if (targetVersion > maxTargetVersion)
-                    {
-                        logger.debug("Target max version is {}; will reconnect with that version", maxTargetVersion);
-                        MessagingService.instance().setVersion(poolReference.endPoint(), maxTargetVersion);
-                        disconnect();
-                        return false;
-                    }
+                DataInputStream in = new DataInputStream(socket.getInputStream());
+                int maxTargetVersion = in.readInt();
+                if (targetVersion > maxTargetVersion)
+                {
+                    logger.debug("Target max version is {}; will reconnect with that version", maxTargetVersion);
+                    MessagingService.instance().setVersion(poolReference.endPoint(), maxTargetVersion);
+                    disconnect();
+                    return false;
+                }
 
-                    if (targetVersion < maxTargetVersion && targetVersion < MessagingService.current_version)
-                    {
-                        logger.trace("Detected higher max version {} (using {}); will reconnect when queued messages are done",
-                                     maxTargetVersion, targetVersion);
-                        MessagingService.instance().setVersion(poolReference.endPoint(), Math.min(MessagingService.current_version, maxTargetVersion));
-                        softCloseSocket();
-                    }
+                if (targetVersion < maxTargetVersion && targetVersion < MessagingService.current_version)
+                {
+                    logger.trace("Detected higher max version {} (using {}); will reconnect when queued messages are done",
+                                 maxTargetVersion, targetVersion);
+                    MessagingService.instance().setVersion(poolReference.endPoint(), Math.min(MessagingService.current_version, maxTargetVersion));
+                    softCloseSocket();
+                }
 
-                    out.writeInt(MessagingService.current_version);
-                    CompactEndpointSerializationHelper.serialize(FBUtilities.getBroadcastAddress(), out);
-                    if (shouldCompressConnection())
-                    {
-                        out.flush();
-                        logger.trace("Upgrading OutputStream to be compressed");
-                        out = new DataOutputStream(new SnappyOutputStream(new BufferedOutputStream(socket.getOutputStream())));
-                    }
+                out.writeInt(MessagingService.current_version);
+                CompactEndpointSerializationHelper.serialize(FBUtilities.getBroadcastAddress(), out);
+                if (shouldCompressConnection())
+                {
+                    out.flush();
+                    logger.trace("Upgrading OutputStream to be compressed");
+                    out = new DataOutputStream(new SnappyOutputStream(new BufferedOutputStream(socket.getOutputStream())));
                 }
 
                 return true;
diff --git a/src/java/org/apache/cassandra/service/ActiveRepairService.java b/src/java/org/apache/cassandra/service/ActiveRepairService.java
index f7a5fa4d10..b692ab0c77 100644
--- a/src/java/org/apache/cassandra/service/ActiveRepairService.java
+++ b/src/java/org/apache/cassandra/service/ActiveRepairService.java
@@ -658,12 +658,6 @@ public class ActiveRepairService
                     logger.error(String.format("[repair #%s] ", getName()) + message);
                     throw new IOException(message);
                 }
-
-                if (MessagingService.instance().getVersion(endpoint) < MessagingService.VERSION_11 && isSequential)
-                {
-                    logger.info(String.format("[repair #%s] Cannot repair using snapshots as node %s is pre-1.1", getName(), endpoint));
-                    return;
-                }
             }
 
             ActiveRepairService.instance.sessions.put(getName(), this);
@@ -1003,9 +997,7 @@ public class ActiveRepairService
                 };
                 StreamingRepairTask task = StreamingRepairTask.create(r1.endpoint, r2.endpoint, tablename, cfname, differences, callback);
 
-                // Pre 1.0, nodes don't know how to handle forwarded streaming task so don't bother
-                if (task.isLocalTask() || MessagingService.instance().getVersion(task.dst) >= MessagingService.VERSION_10)
-                    task.run();
+                task.run();
             }
 
             public String toString()
diff --git a/src/java/org/apache/cassandra/service/CacheService.java b/src/java/org/apache/cassandra/service/CacheService.java
index c927bfbaa2..8396d61783 100644
--- a/src/java/org/apache/cassandra/service/CacheService.java
+++ b/src/java/org/apache/cassandra/service/CacheService.java
@@ -351,9 +351,7 @@ public class CacheService implements CacheServiceMBean
             ByteBufferUtil.writeWithLength(key.key, out);
             Descriptor desc = key.desc;
             out.writeInt(desc.generation);
-            out.writeBoolean(desc.version.hasPromotedIndexes);
-            if (!desc.version.hasPromotedIndexes)
-                return;
+            out.writeBoolean(true);
             RowIndexEntry.serializer.serialize(entry, out);
         }
 
@@ -368,10 +366,8 @@ public class CacheService implements CacheServiceMBean
                 return null;
             }
             RowIndexEntry entry;
-            if (input.readBoolean())
-                entry = RowIndexEntry.serializer.deserialize(input, reader.descriptor.version);
-            else
-                entry = reader.getPosition(reader.partitioner.decorateKey(key), Operator.EQ);
+            input.readBoolean(); // backwards compatibility for "promoted indexes" boolean
+            entry = RowIndexEntry.serializer.deserialize(input, reader.descriptor.version);
             return Futures.immediateFuture(Pair.create(new KeyCacheKey(reader.descriptor, key), entry));
         }
 
diff --git a/src/java/org/apache/cassandra/service/CassandraDaemon.java b/src/java/org/apache/cassandra/service/CassandraDaemon.java
index 1d6cb0cbcd..3d5240f559 100644
--- a/src/java/org/apache/cassandra/service/CassandraDaemon.java
+++ b/src/java/org/apache/cassandra/service/CassandraDaemon.java
@@ -207,10 +207,6 @@ public class CassandraDaemon
                     : String.format("Directory %s is not accessible.", dataDir);
         }
 
-        // Migrate sstables from pre-#2749 to the correct location
-        if (Directories.sstablesNeedsMigration())
-            Directories.migrateSSTables();
-
         if (CacheService.instance == null) // should never happen
             throw new RuntimeException("Failed to initialize Cache Service.");
 
diff --git a/src/java/org/apache/cassandra/service/IndexScanVerbHandler.java b/src/java/org/apache/cassandra/service/IndexScanVerbHandler.java
deleted file mode 100644
index 2e3a92171d..0000000000
--- a/src/java/org/apache/cassandra/service/IndexScanVerbHandler.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.cassandra.service;
-
-import java.util.List;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.cassandra.db.*;
-import org.apache.cassandra.net.IVerbHandler;
-import org.apache.cassandra.net.MessageIn;
-import org.apache.cassandra.net.MessagingService;
-import org.apache.cassandra.thrift.ThriftValidation;
-import org.apache.cassandra.tracing.Tracing;
-
-@Deprecated // 1.1 implements index scan with RangeSliceVerb instead
-public class IndexScanVerbHandler implements IVerbHandler<IndexScanCommand>
-{
-    private static final Logger logger = LoggerFactory.getLogger(IndexScanVerbHandler.class);
-
-    public void doVerb(MessageIn<IndexScanCommand> message, int id)
-    {
-        try
-        {
-            IndexScanCommand command = message.payload;
-            ColumnFamilyStore cfs = Table.open(command.keyspace).getColumnFamilyStore(command.column_family);
-            List<Row> rows = cfs.search(command.index_clause.expressions,
-                                        command.range,
-                                        command.index_clause.count,
-                                        ThriftValidation.asIFilter(command.predicate, cfs.metadata, null));
-            RangeSliceReply reply = new RangeSliceReply(rows);
-            Tracing.trace("Enqueuing response to {}", message.from);
-            MessagingService.instance().sendReply(reply.createMessage(), id, message.from);
-        }
-        catch (Exception ex)
-        {
-            throw new RuntimeException(ex);
-        }
-    }
-}
diff --git a/src/java/org/apache/cassandra/service/MigrationManager.java b/src/java/org/apache/cassandra/service/MigrationManager.java
index d02226a44f..4b5352cbb8 100644
--- a/src/java/org/apache/cassandra/service/MigrationManager.java
+++ b/src/java/org/apache/cassandra/service/MigrationManager.java
@@ -112,10 +112,6 @@ public class MigrationManager implements IEndpointStateChangeSubscriber
      */
     private static void maybeScheduleSchemaPull(final UUID theirVersion, final InetAddress endpoint)
     {
-        // Can't request migrations from nodes with versions younger than 1.1.7
-        if (MessagingService.instance().getVersion(endpoint) < MessagingService.VERSION_117)
-            return;
-
         if (Gossiper.instance.isFatClient(endpoint))
             return;
 
@@ -305,11 +301,7 @@ public class MigrationManager implements IEndpointStateChangeSubscriber
         for (InetAddress endpoint : Gossiper.instance.getLiveMembers())
         {
             if (endpoint.equals(FBUtilities.getBroadcastAddress()))
-                continue; // we've delt with localhost already
-
-            // don't send migrations to the nodes with the versions older than < 1.2
-            if (MessagingService.instance().getVersion(endpoint) < MessagingService.VERSION_12)
-                continue;
+                continue; // we've dealt with localhost already
 
             pushSchemaMutation(endpoint, schema);
         }
@@ -360,37 +352,16 @@ public class MigrationManager implements IEndpointStateChangeSubscriber
         // and due to broken timestamps in versions prior to 1.1.7
         for (InetAddress node : liveEndpoints)
         {
-            if (MessagingService.instance().getVersion(node) >= MessagingService.VERSION_117)
-            {
-                if (logger.isDebugEnabled())
-                    logger.debug("Requesting schema from " + node);
+            if (logger.isDebugEnabled())
+                logger.debug("Requesting schema from " + node);
 
-                FBUtilities.waitOnFuture(StageManager.getStage(Stage.MIGRATION).submit(new MigrationTask(node)));
-                break;
-            }
+            FBUtilities.waitOnFuture(StageManager.getStage(Stage.MIGRATION).submit(new MigrationTask(node)));
+            break;
         }
 
         logger.info("Local schema reset is complete.");
     }
 
-    /**
-     * Used only in case node has old style migration schema (newly updated)
-     * @return the UUID identifying version of the last applied migration
-     */
-    @Deprecated
-    public static UUID getLastMigrationId()
-    {
-        DecoratedKey dkey = StorageService.getPartitioner().decorateKey(LAST_MIGRATION_KEY);
-        Table defs = Table.open(Table.SYSTEM_KS);
-        ColumnFamilyStore cfStore = defs.getColumnFamilyStore(DefsTable.OLD_SCHEMA_CF);
-        QueryFilter filter = QueryFilter.getNamesFilter(dkey, DefsTable.OLD_SCHEMA_CF, LAST_MIGRATION_KEY);
-        ColumnFamily cf = cfStore.getColumnFamily(filter);
-        if (cf == null || Iterables.isEmpty(cf.getColumnNames()))
-            return null;
-        else
-            return UUIDGen.getUUID(cf.getColumn(LAST_MIGRATION_KEY).value());
-    }
-
     public static class MigrationsSerializer implements IVersionedSerializer<Collection<RowMutation>>
     {
         public static MigrationsSerializer instance = new MigrationsSerializer();
diff --git a/src/java/org/apache/cassandra/service/StorageProxy.java b/src/java/org/apache/cassandra/service/StorageProxy.java
index caffaafba6..56730633f0 100644
--- a/src/java/org/apache/cassandra/service/StorageProxy.java
+++ b/src/java/org/apache/cassandra/service/StorageProxy.java
@@ -736,11 +736,6 @@ public class StorageProxy implements StorageProxyMBean
     public static void writeHintForMutation(RowMutation mutation, InetAddress target) throws IOException
     {
         UUID hostId = StorageService.instance.getTokenMetadata().getHostId(target);
-        if ((hostId == null) && (MessagingService.instance().getVersion(target) < MessagingService.VERSION_12))
-        {
-            logger.warn("Unable to store hint for host with missing ID, {} (old node?)", target.toString());
-            return;
-        }
         assert hostId != null : "Missing host ID for " + target.getHostAddress();
         RowMutation hintedMutation = HintedHandOffManager.hintFor(mutation, hostId);
         hintedMutation.apply();
diff --git a/src/java/org/apache/cassandra/service/StorageService.java b/src/java/org/apache/cassandra/service/StorageService.java
index 8e14d7966b..d720df258d 100644
--- a/src/java/org/apache/cassandra/service/StorageService.java
+++ b/src/java/org/apache/cassandra/service/StorageService.java
@@ -66,7 +66,6 @@ import org.apache.cassandra.locator.AbstractReplicationStrategy;
 import org.apache.cassandra.locator.DynamicEndpointSnitch;
 import org.apache.cassandra.locator.IEndpointSnitch;
 import org.apache.cassandra.locator.TokenMetadata;
-import org.apache.cassandra.metrics.StorageMetrics;
 import org.apache.cassandra.net.AsyncOneResponse;
 import org.apache.cassandra.net.MessageOut;
 import org.apache.cassandra.net.MessagingService;
@@ -138,8 +137,6 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
 
     public static final StorageService instance = new StorageService();
 
-    private static final StorageMetrics metrics = new StorageMetrics();
-
     public static IPartitioner getPartitioner()
     {
         return DatabaseDescriptor.getPartitioner();
@@ -238,7 +235,6 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         MessagingService.instance().registerVerbHandlers(MessagingService.Verb.READ_REPAIR, new ReadRepairVerbHandler());
         MessagingService.instance().registerVerbHandlers(MessagingService.Verb.READ, new ReadVerbHandler());
         MessagingService.instance().registerVerbHandlers(MessagingService.Verb.RANGE_SLICE, new RangeSliceVerbHandler());
-        MessagingService.instance().registerVerbHandlers(MessagingService.Verb.INDEX_SCAN, new IndexScanVerbHandler());
         MessagingService.instance().registerVerbHandlers(MessagingService.Verb.COUNTER_MUTATION, new CounterMutationVerbHandler());
         MessagingService.instance().registerVerbHandlers(MessagingService.Verb.TRUNCATE, new TruncateVerbHandler());
         MessagingService.instance().registerVerbHandlers(MessagingService.Verb.PAXOS_PREPARE, new PrepareVerbHandler());
@@ -306,7 +302,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         if (!initialized)
         {
             logger.warn("Starting gossip by operator request");
-            Gossiper.instance.start((int)(System.currentTimeMillis() / 1000));
+            Gossiper.instance.start((int) (System.currentTimeMillis() / 1000));
             initialized = true;
         }
     }
@@ -605,10 +601,10 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         Set<InetAddress> current = new HashSet<InetAddress>();
         Collection<Token> tokens;
         logger.debug("Bootstrap variables: {} {} {} {}",
-                      new Object[]{ DatabaseDescriptor.isAutoBootstrap(),
-                                    SystemTable.bootstrapInProgress(),
-                                    SystemTable.bootstrapComplete(),
-                                    DatabaseDescriptor.getSeeds().contains(FBUtilities.getBroadcastAddress())});
+                     DatabaseDescriptor.isAutoBootstrap(),
+                     SystemTable.bootstrapInProgress(),
+                     SystemTable.bootstrapComplete(),
+                     DatabaseDescriptor.getSeeds().contains(FBUtilities.getBroadcastAddress()));
         if (DatabaseDescriptor.isAutoBootstrap()
             && !SystemTable.bootstrapComplete()
             && !DatabaseDescriptor.getSeeds().contains(FBUtilities.getBroadcastAddress()))
@@ -1051,7 +1047,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
      */
     public List<String> describeRingJMX(String keyspace) throws IOException
     {
-        List<TokenRange> tokenRanges = null;
+        List<TokenRange> tokenRanges;
         try
         {
             tokenRanges = describeRing(keyspace);
@@ -1400,7 +1396,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
             else if (tokenMetadata.isRelocating(token))
             {
                 logger.info("Token {} is relocating to {}, ignoring update from {}",
-                        new Object[]{token, tokenMetadata.getRelocatingRanges().get(token), endpoint});
+                            token, tokenMetadata.getRelocatingRanges().get(token), endpoint);
             }
             else if (Gossiper.instance.compareEndpointStartup(endpoint, currentOwner) > 0)
             {
@@ -1507,7 +1503,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         if (logger.isDebugEnabled())
             logger.debug("Node " + endpoint + " state left, tokens " + tokens);
 
-        excise(tokens, endpoint, extractExpireTime(pieces, version));
+        excise(tokens, endpoint, extractExpireTime(pieces));
     }
 
     /**
@@ -1579,7 +1575,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
 
             if (VersionedValue.REMOVED_TOKEN.equals(state))
             {
-                excise(removeTokens, endpoint, extractExpireTime(pieces, MessagingService.instance().getVersion(endpoint)));
+                excise(removeTokens, endpoint, extractExpireTime(pieces));
             }
             else if (VersionedValue.REMOVING_TOKEN.equals(state))
             {
@@ -1599,7 +1595,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         }
         else // now that the gossiper has told us about this nonexistent member, notify the gossiper to remove it
         {
-            addExpireTimeIfFound(endpoint, extractExpireTime(pieces, MessagingService.instance().getVersion(endpoint)));
+            addExpireTimeIfFound(endpoint, extractExpireTime(pieces));
             removeEndpoint(endpoint);
         }
     }
@@ -1641,21 +1637,12 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         }
     }
 
-    protected long extractExpireTime(String[] pieces, int version)
+    protected long extractExpireTime(String[] pieces)
     {
-        if (version < MessagingService.VERSION_12)
-        {
-            if (pieces.length >= 3)
-                return Long.parseLong(pieces[2]);
-            else
-                return 0L;
-        } else
-        {
-            if (VersionedValue.STATUS_LEFT.equals(pieces[0]))
-                return Long.parseLong(pieces[1]);
-            else
-                return Long.parseLong(pieces[2]);
-        }
+        if (VersionedValue.STATUS_LEFT.equals(pieces[0]))
+            return Long.parseLong(pieces[1]);
+        else
+            return Long.parseLong(pieces[2]);
     }
 
     /**
@@ -2371,7 +2358,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         Token parsedEndToken = getPartitioner().getTokenFactory().fromString(endToken);
 
         logger.info("starting user-requested repair of range ({}, {}] for keyspace {} and column families {}",
-                new Object[] {parsedBeginToken, parsedEndToken, tableName, columnFamilies});
+                    parsedBeginToken, parsedEndToken, tableName, columnFamilies);
         return forceRepairAsync(tableName, isSequential, isLocal, Collections.singleton(new Range<Token>(parsedBeginToken, parsedEndToken)), columnFamilies);
     }
 
@@ -2411,7 +2398,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
 
     private FutureTask<Object> createRepairTask(final int cmd, final String keyspace, final Collection<Range<Token>> ranges, final boolean isSequential, final boolean isLocal, final String... columnFamilies)
     {
-        FutureTask<Object> task = new FutureTask<Object>(new WrappedRunnable()
+        return new FutureTask<Object>(new WrappedRunnable()
         {
             protected void runMayThrow() throws Exception
             {
@@ -2472,7 +2459,6 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
                 sendNotification("repair", String.format("Repair command #%d finished", cmd), new int[]{cmd, ActiveRepairService.Status.FINISHED.ordinal()});
             }
         }, null);
-        return task;
     }
 
     public ActiveRepairService.RepairFuture forceTableRepair(final Range<Token> range, final String tableName, boolean isSequential, boolean  isLocal, final String... columnFamilies) throws IOException
@@ -2498,24 +2484,6 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
 
     /* End of MBean interface methods */
 
-    /**
-     * This method returns the predecessor of the endpoint ep on the identifier
-     * space.
-     */
-    InetAddress getPredecessor(Token token)
-    {
-        return tokenMetadata.getEndpoint(tokenMetadata.getPredecessor(token));
-    }
-
-    /*
-     * This method returns the successor of the endpoint ep on the identifier
-     * space.
-     */
-    public InetAddress getSuccessor(Token token)
-    {
-        return tokenMetadata.getEndpoint(tokenMetadata.getSuccessor(token));
-    }
-
     /**
      * Get the "primary ranges" for the specified keyspace and endpoint.
      * "Primary ranges" are the ranges that the node is responsible for storing replica primarily.
@@ -3547,7 +3515,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         IEndpointSnitch oldSnitch = DatabaseDescriptor.getEndpointSnitch();
 
         // new snitch registers mbean during construction
-        IEndpointSnitch newSnitch = null;
+        IEndpointSnitch newSnitch;
         try
         {
             newSnitch = FBUtilities.construct(epSnitchClassName, "snitch");
@@ -3661,7 +3629,7 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
             logger.warn("Streaming to " + targetAddr + " failed");
             onSuccess(); // calling onSuccess for latch countdown
         }
-    };
+    }
 
     /**
      * Used to request ranges from endpoints in the ring (will block until all data is fetched and ready)
@@ -3881,7 +3849,6 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         rangeXferExecutor.tearDown();
     }
 
-    @Override
     public void disableAutoCompaction(String ks, String... columnFamilies) throws IOException
     {
         for (ColumnFamilyStore cfs : getValidColumnFamilies(true, true, ks, columnFamilies))
@@ -3890,7 +3857,6 @@ public class StorageService extends NotificationBroadcasterSupport implements IE
         }
     }
 
-    @Override
     public void enableAutoCompaction(String ks, String... columnFamilies) throws IOException
     {
         for (ColumnFamilyStore cfs : getValidColumnFamilies(true, true, ks, columnFamilies))
diff --git a/src/java/org/apache/cassandra/service/StorageServiceMBean.java b/src/java/org/apache/cassandra/service/StorageServiceMBean.java
index 84d0346351..9548fccdd3 100644
--- a/src/java/org/apache/cassandra/service/StorageServiceMBean.java
+++ b/src/java/org/apache/cassandra/service/StorageServiceMBean.java
@@ -474,4 +474,5 @@ public interface StorageServiceMBean extends NotificationEmitter
     void disableAutoCompaction(String ks, String ... columnFamilies) throws IOException;
     void enableAutoCompaction(String ks, String ... columnFamilies) throws IOException;
 
+    public void deliverHints(String host) throws UnknownHostException;
 }
diff --git a/src/java/org/apache/cassandra/streaming/IncomingStreamReader.java b/src/java/org/apache/cassandra/streaming/IncomingStreamReader.java
index c5521056b4..2eca71e834 100644
--- a/src/java/org/apache/cassandra/streaming/IncomingStreamReader.java
+++ b/src/java/org/apache/cassandra/streaming/IncomingStreamReader.java
@@ -151,8 +151,8 @@ public class IncomingStreamReader
                 while (bytesRead < length)
                 {
                     in.reset(0);
-                    key = SSTableReader.decodeKey(StorageService.getPartitioner(), localFile.desc, ByteBufferUtil.readWithShortLength(in));
-                    long dataSize = SSTableReader.readRowSize(in, localFile.desc);
+                    key = StorageService.getPartitioner().decorateKey(ByteBufferUtil.readWithShortLength(in));
+                    long dataSize = in.readLong();
 
                     if (cfs.containsCachedRow(key) && remoteFile.type == OperationType.AES && dataSize <= DatabaseDescriptor.getInMemoryCompactionLimit())
                     {
diff --git a/src/java/org/apache/cassandra/streaming/PendingFile.java b/src/java/org/apache/cassandra/streaming/PendingFile.java
index 7474bd63d2..129b3f70cb 100644
--- a/src/java/org/apache/cassandra/streaming/PendingFile.java
+++ b/src/java/org/apache/cassandra/streaming/PendingFile.java
@@ -138,8 +138,7 @@ public class PendingFile
             }
             out.writeUTF(sc.type.name());
             out.writeLong(sc.estimatedKeys);
-            if (version > MessagingService.VERSION_11)
-                CompressionInfo.serializer.serialize(sc.compressionInfo, out, version);
+            CompressionInfo.serializer.serialize(sc.compressionInfo, out, version);
         }
 
         public PendingFile deserialize(DataInput in, int version) throws IOException
@@ -159,8 +158,7 @@ public class PendingFile
             type = OperationType.valueOf(in.readUTF());
             long estimatedKeys = in.readLong();
             CompressionInfo info = null;
-            if (version > MessagingService.VERSION_11)
-                info = CompressionInfo.serializer.deserialize(in, version);
+            info = CompressionInfo.serializer.deserialize(in, version);
             return new PendingFile(null, desc, component, sections, type, estimatedKeys, info);
         }
 
@@ -176,8 +174,7 @@ public class PendingFile
                 size += TypeSizes.NATIVE.sizeof(section.left) + TypeSizes.NATIVE.sizeof(section.right);
             size += TypeSizes.NATIVE.sizeof(pf.type.name());
             size += TypeSizes.NATIVE.sizeof(pf.estimatedKeys);
-            if (version > MessagingService.VERSION_11)
-                size += CompressionInfo.serializer.serializedSize(pf.compressionInfo, version);
+            size += CompressionInfo.serializer.serializedSize(pf.compressionInfo, version);
             return size;
         }
     }
diff --git a/src/java/org/apache/cassandra/tools/StandaloneScrubber.java b/src/java/org/apache/cassandra/tools/StandaloneScrubber.java
index c9d39bb5de..9db565d5f8 100644
--- a/src/java/org/apache/cassandra/tools/StandaloneScrubber.java
+++ b/src/java/org/apache/cassandra/tools/StandaloneScrubber.java
@@ -56,10 +56,6 @@ public class StandaloneScrubber
         Options options = Options.parseArgs(args);
         try
         {
-            // Migrate sstables from pre-#2749 to the correct location
-            if (Directories.sstablesNeedsMigration())
-                Directories.migrateSSTables();
-
             // load keyspace descriptions.
             DatabaseDescriptor.loadSchemas();
 
diff --git a/src/java/org/apache/cassandra/utils/FilterFactory.java b/src/java/org/apache/cassandra/utils/FilterFactory.java
index 88c8973d76..c8b7b5d3f5 100644
--- a/src/java/org/apache/cassandra/utils/FilterFactory.java
+++ b/src/java/org/apache/cassandra/utils/FilterFactory.java
@@ -35,61 +35,19 @@ public class FilterFactory
     private static final TypeSizes TYPE_SIZES = TypeSizes.NATIVE;
     private static final long BITSET_EXCESS = 20;
 
-    public enum Type
-    {
-        SHA, MURMUR2, MURMUR3
-    }
-
     public static void serialize(IFilter bf, DataOutput output) throws IOException
     {
-        serialize(bf, output, Type.MURMUR3);
-    }
-
-    public static void serialize(IFilter bf, DataOutput output, Type type) throws IOException
-    {
-        switch (type)
-        {
-            case SHA:
-                LegacyBloomFilter.serializer.serialize((LegacyBloomFilter) bf, output);
-                break;
-            case MURMUR2:
-                Murmur2BloomFilter.serializer.serialize((Murmur2BloomFilter) bf, output);
-                break;
-            default:
-                Murmur3BloomFilter.serializer.serialize((Murmur3BloomFilter) bf, output);
-                break;
-        }
+        Murmur3BloomFilter.serializer.serialize((Murmur3BloomFilter) bf, output);
     }
 
-    public static IFilter deserialize(DataInput input, Type type, boolean offheap) throws IOException
+    public static IFilter deserialize(DataInput input, boolean offheap) throws IOException
     {
-        switch (type)
-        {
-            case SHA:
-                return LegacyBloomFilter.serializer.deserialize(input);
-            case MURMUR2:
-                return Murmur2BloomFilter.serializer.deserialize(input, offheap);
-            default:
-                return Murmur3BloomFilter.serializer.deserialize(input, offheap);
-        }
+        return Murmur3BloomFilter.serializer.deserialize(input, offheap);
     }
 
     public static long serializedSize(IFilter bf)
     {
-        return serializedSize(bf, Type.MURMUR3);
-    }
-
-    public static long serializedSize(IFilter bf, Type type)
-    {
-        switch (type)
-        {
-            case SHA:
-                return LegacyBloomFilter.serializer.serializedSize((LegacyBloomFilter) bf);
-            case MURMUR2:
-                return Murmur2BloomFilter.serializer.serializedSize((Murmur2BloomFilter) bf, TYPE_SIZES);
-            default:
-                return Murmur3BloomFilter.serializer.serializedSize((Murmur3BloomFilter) bf, TYPE_SIZES);
-        }
+        return Murmur3BloomFilter.serializer.serializedSize((Murmur3BloomFilter) bf, TYPE_SIZES);
     }
 
     /**
@@ -97,12 +55,6 @@ public class FilterFactory
      *         probability for the given number of elements.
      */
     public static IFilter getFilter(long numElements, int targetBucketsPerElem, boolean offheap)
-    {
-        return getFilter(numElements, targetBucketsPerElem, Type.MURMUR3, offheap);
-    }
-
-    // helper method for test.
-    static IFilter getFilter(long numElements, int targetBucketsPerElem, Type type, boolean offheap)
     {
         int maxBucketsPerElement = Math.max(1, BloomCalculations.maxBucketsPerElement(numElements));
         int bucketsPerElement = Math.min(targetBucketsPerElem, maxBucketsPerElement);
@@ -111,7 +63,7 @@ public class FilterFactory
             logger.warn(String.format("Cannot provide an optimal BloomFilter for %d elements (%d/%d buckets per element).", numElements, bucketsPerElement, targetBucketsPerElem));
         }
         BloomCalculations.BloomSpecification spec = BloomCalculations.computeBloomSpec(bucketsPerElement);
-        return createFilter(spec.K, numElements, spec.bucketsPerElement, type, offheap);
+        return createFilter(spec.K, numElements, spec.bucketsPerElement, offheap);
     }
 
     /**
@@ -122,31 +74,19 @@ public class FilterFactory
      *         filter.
      */
     public static IFilter getFilter(long numElements, double maxFalsePosProbability, boolean offheap)
-    {
-        return getFilter(numElements, maxFalsePosProbability, Type.MURMUR3, offheap);
-    }
-
-    // helper method for test.
-    static IFilter getFilter(long numElements, double maxFalsePosProbability, Type type, boolean offheap)
     {
         assert maxFalsePosProbability <= 1.0 : "Invalid probability";
         if (maxFalsePosProbability == 1.0)
             return new AlwaysPresentFilter();
         int bucketsPerElement = BloomCalculations.maxBucketsPerElement(numElements);
         BloomCalculations.BloomSpecification spec = BloomCalculations.computeBloomSpec(bucketsPerElement, maxFalsePosProbability);
-        return createFilter(spec.K, numElements, spec.bucketsPerElement, type, offheap);
+        return createFilter(spec.K, numElements, spec.bucketsPerElement, offheap);
     }
 
-    private static IFilter createFilter(int hash, long numElements, int bucketsPer, Type type, boolean offheap)
+    private static IFilter createFilter(int hash, long numElements, int bucketsPer, boolean offheap)
     {
         long numBits = (numElements * bucketsPer) + BITSET_EXCESS;
         IBitSet bitset = offheap ? new OffHeapBitSet(numBits) : new OpenBitSet(numBits);
-        switch (type)
-        {
-            case MURMUR2:
-              return new Murmur2BloomFilter(hash, bitset);
-            default:
-              return new Murmur3BloomFilter(hash, bitset);
-        }
+        return new Murmur3BloomFilter(hash, bitset);
     }
 }
diff --git a/src/java/org/apache/cassandra/utils/LegacyBloomFilter.java b/src/java/org/apache/cassandra/utils/LegacyBloomFilter.java
deleted file mode 100644
index f664f66a3f..0000000000
--- a/src/java/org/apache/cassandra/utils/LegacyBloomFilter.java
+++ /dev/null
@@ -1,170 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.cassandra.utils;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.BitSet;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class LegacyBloomFilter implements IFilter
-{
-    private static final int EXCESS = 20;
-    private static final Logger logger = LoggerFactory.getLogger(LegacyBloomFilter.class);
-    public static final LegacyBloomFilterSerializer serializer = new LegacyBloomFilterSerializer();
-
-    private BitSet filter;
-    private final int hashCount;
-
-    LegacyBloomFilter(int hashes, BitSet filter)
-    {
-        hashCount = hashes;
-        this.filter = filter;
-    }
-
-    private static BitSet bucketsFor(long numElements, int bucketsPer)
-    {
-        long numBits = numElements * bucketsPer + EXCESS;
-        return new BitSet((int)Math.min(Integer.MAX_VALUE, numBits));
-    }
-
-    /**
-     * @return A LegacyBloomFilter with the lowest practical false positive probability
-     * for the given number of elements.
-     */
-    public static LegacyBloomFilter getFilter(long numElements, int targetBucketsPerElem)
-    {
-        int maxBucketsPerElement = Math.max(1, BloomCalculations.maxBucketsPerElement(numElements));
-        int bucketsPerElement = Math.min(targetBucketsPerElem, maxBucketsPerElement);
-        if (bucketsPerElement < targetBucketsPerElem)
-        {
-            logger.warn(String.format("Cannot provide an optimal LegacyBloomFilter for %d elements (%d/%d buckets per element).",
-                                      numElements, bucketsPerElement, targetBucketsPerElem));
-        }
-        BloomCalculations.BloomSpecification spec = BloomCalculations.computeBloomSpec(bucketsPerElement);
-        return new LegacyBloomFilter(spec.K, bucketsFor(numElements, spec.bucketsPerElement));
-    }
-
-    /**
-     * @return The smallest LegacyBloomFilter that can provide the given false positive
-     * probability rate for the given number of elements.
-     *
-     * Asserts that the given probability can be satisfied using this filter.
-     */
-    public static LegacyBloomFilter getFilter(long numElements, double maxFalsePosProbability)
-    {
-        assert maxFalsePosProbability <= 1.0 : "Invalid probability";
-        int bucketsPerElement = BloomCalculations.maxBucketsPerElement(numElements);
-        BloomCalculations.BloomSpecification spec = BloomCalculations.computeBloomSpec(bucketsPerElement, maxFalsePosProbability);
-        return new LegacyBloomFilter(spec.K, bucketsFor(numElements, spec.bucketsPerElement));
-    }
-
-    public void clear()
-    {
-        filter.clear();
-    }
-
-    int buckets()
-    {
-        return filter.size();
-    }
-
-    public boolean isPresent(ByteBuffer key)
-    {
-        for (int bucketIndex : getHashBuckets(key))
-        {
-            if (!filter.get(bucketIndex))
-            {
-                return false;
-            }
-        }
-        return true;
-    }
-
-    /*
-     @param key -- value whose hash is used to fill
-     the filter.
-     This is a general purpose API.
-     */
-    public void add(ByteBuffer key)
-    {
-        for (int bucketIndex : getHashBuckets(key))
-        {
-            filter.set(bucketIndex);
-        }
-    }
-
-    public String toString()
-    {
-        return filter.toString();
-    }
-
-    int emptyBuckets()
-    {
-        int n = 0;
-        for (int i = 0; i < buckets(); i++)
-        {
-            if (!filter.get(i))
-            {
-                n++;
-            }
-        }
-        return n;
-    }
-
-    /** @return a LegacyBloomFilter that always returns a positive match, for testing */
-    public static LegacyBloomFilter alwaysMatchingBloomFilter()
-    {
-        BitSet set = new BitSet(64);
-        set.set(0, 64);
-        return new LegacyBloomFilter(1, set);
-    }
-
-    public int[] getHashBuckets(ByteBuffer key)
-    {
-        return LegacyBloomFilter.getHashBuckets(key, hashCount, buckets());
-    }
-
-    // Murmur is faster than an SHA-based approach and provides as-good collision
-    // resistance.  The combinatorial generation approach described in
-    // http://www.eecs.harvard.edu/~kirsch/pubs/bbbf/esa06.pdf
-    // does prove to work in actual tests, and is obviously faster
-    // than performing further iterations of murmur.
-    static int[] getHashBuckets(ByteBuffer b, int hashCount, int max)
-    {
-        int[] result = new int[hashCount];
-        int hash1 = MurmurHash.hash32(b, b.position(), b.remaining(), 0);
-        int hash2 = MurmurHash.hash32(b, b.position(), b.remaining(), hash1);
-        for (int i = 0; i < hashCount; i++)
-        {
-            result[i] = Math.abs((hash1 + i * hash2) % max);
-        }
-        return result;
-    }
-
-    public BitSet getBitSet(){
-      return filter;
-    }
-
-    public void close() throws IOException
-    {
-        // Do nothing for this
-    }
-}
diff --git a/src/java/org/apache/cassandra/utils/LegacyBloomFilterSerializer.java b/src/java/org/apache/cassandra/utils/LegacyBloomFilterSerializer.java
deleted file mode 100644
index 3faf9cd575..0000000000
--- a/src/java/org/apache/cassandra/utils/LegacyBloomFilterSerializer.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.cassandra.utils;
-
-import java.io.*;
-import java.util.BitSet;
-
-public class LegacyBloomFilterSerializer
-{
-    public void serialize(LegacyBloomFilter bf, DataOutput out)
-            throws IOException
-    {
-        throw new UnsupportedOperationException("Shouldn't be serializing legacy bloom filters");
-//        out.writeInt(bf.getHashCount());
-//        ObjectOutputStream oos = new ObjectOutputStream(out);
-//        oos.writeObject(bf.getBitSet());
-//        oos.flush();
-    }
-
-    public LegacyBloomFilter deserialize(final DataInput in) throws IOException
-    {
-        int hashes = in.readInt();
-        ObjectInputStream ois = new ObjectInputStream(new InputStream()
-        {
-            @Override
-            public int read() throws IOException
-            {
-                return in.readByte() & 0xFF;
-            }
-        });
-        try
-        {
-          BitSet bs = (BitSet) ois.readObject();
-          return new LegacyBloomFilter(hashes, bs);
-        } catch (ClassNotFoundException e)
-        {
-          throw new RuntimeException(e);
-        }
-    }
-
-    public long serializedSize(LegacyBloomFilter legacyBloomFilter)
-    {
-        throw new UnsupportedOperationException();
-    }
-}
diff --git a/src/java/org/apache/cassandra/utils/Murmur2BloomFilter.java b/src/java/org/apache/cassandra/utils/Murmur2BloomFilter.java
deleted file mode 100644
index 1c20dd11ac..0000000000
--- a/src/java/org/apache/cassandra/utils/Murmur2BloomFilter.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.cassandra.utils;
-
-import java.nio.ByteBuffer;
-
-import org.apache.cassandra.utils.obs.IBitSet;
-
-public class Murmur2BloomFilter extends BloomFilter
-{
-    public static final Murmur2BloomFilterSerializer serializer = new Murmur2BloomFilterSerializer();
-
-    public Murmur2BloomFilter(int hashes, IBitSet bs)
-    {
-        super(hashes, bs);
-    }
-
-    protected long[] hash(ByteBuffer b, int position, int remaining, long seed)
-    {
-        long hash1 = MurmurHash.hash2_64(b, b.position(), b.remaining(), seed);
-        long hash2 = MurmurHash.hash2_64(b, b.position(), b.remaining(), hash1);
-        return (new long[] { hash1, hash2 });
-    }
-
-    public static class Murmur2BloomFilterSerializer extends BloomFilterSerializer
-    {
-        protected BloomFilter createFilter(int hashes, IBitSet bs)
-        {
-            return new Murmur2BloomFilter(hashes, bs);
-        }
-    }
-}
\ No newline at end of file
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Filter.db b/test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Filter.db
deleted file mode 100644
index 7e129e3838..0000000000
Binary files a/test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Filter.db and /dev/null differ
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-CRC.db b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-CRC.db
new file mode 100644
index 0000000000..3cc23b09a0
Binary files /dev/null and b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-CRC.db differ
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Data.db b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Data.db
similarity index 100%
rename from test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Data.db
rename to test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Data.db
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Digest.sha1 b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Digest.sha1
new file mode 100644
index 0000000000..c53d4789bf
--- /dev/null
+++ b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Digest.sha1
@@ -0,0 +1 @@
+a9fbab0c12f097cfbf91a7b8731a20363daef547  Keyspace1-Standard3-ja-1-Data.db
\ No newline at end of file
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Filter.db b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Filter.db
new file mode 100644
index 0000000000..df0734d873
Binary files /dev/null and b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Filter.db differ
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Index.db b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Index.db
similarity index 100%
rename from test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Index.db
rename to test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Index.db
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Statistics.db b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Statistics.db
similarity index 97%
rename from test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Statistics.db
rename to test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Statistics.db
index 305e010499..28e250ba0b 100644
Binary files a/test/data/corrupt-sstables/Keyspace1-Standard3-ia-1-Statistics.db and b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Statistics.db differ
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Summary.db b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Summary.db
new file mode 100644
index 0000000000..105e42c9ca
Binary files /dev/null and b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-Summary.db differ
diff --git a/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-TOC.txt b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-TOC.txt
new file mode 100644
index 0000000000..39df2ce2dd
--- /dev/null
+++ b/test/data/corrupt-sstables/Keyspace1-Standard3-ja-1-TOC.txt
@@ -0,0 +1,8 @@
+Statistics.db
+Digest.sha1
+Filter.db
+Data.db
+Index.db
+Summary.db
+CRC.db
+TOC.txt
diff --git a/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Data.db b/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Data.db
deleted file mode 100644
index d5752a5d79..0000000000
Binary files a/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Data.db and /dev/null differ
diff --git a/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Filter.db b/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Filter.db
deleted file mode 100644
index 64d8c5d5d1..0000000000
Binary files a/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Filter.db and /dev/null differ
diff --git a/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Index.db b/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Index.db
deleted file mode 100644
index 9b57eece86..0000000000
Binary files a/test/data/legacy-sstables/b/Keyspace1/Keyspace1-Standard1-b-0-Index.db and /dev/null differ
diff --git a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Data.db b/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Data.db
deleted file mode 100644
index bbcf0b7db0..0000000000
Binary files a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Data.db and /dev/null differ
diff --git a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Filter.db b/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Filter.db
deleted file mode 100644
index bd464e517b..0000000000
Binary files a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Filter.db and /dev/null differ
diff --git a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Index.db b/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Index.db
deleted file mode 100644
index 9b3e827f7f..0000000000
Binary files a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Index.db and /dev/null differ
diff --git a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Statistics.db b/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Statistics.db
deleted file mode 100644
index db1e33d768..0000000000
Binary files a/test/data/legacy-sstables/e/Keyspace1/Keyspace1-Standard1-e-0-Statistics.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Data.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Data.db
deleted file mode 100644
index 896897a275..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Data.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Digest.sha1 b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Digest.sha1
deleted file mode 100644
index bc0c4e4a78..0000000000
--- a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Digest.sha1
+++ /dev/null
@@ -1 +0,0 @@
-095dd05150d499846782cdf1c77544048477cc9b  Indexed1-hb-1-Data.db
\ No newline at end of file
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Filter.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Filter.db
deleted file mode 100644
index 4b61a27af7..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Filter.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Index.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Index.db
deleted file mode 100644
index 03b3dc81cf..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Index.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Statistics.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Statistics.db
deleted file mode 100644
index 78c4ed3333..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1-hb-1-Statistics.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Data.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Data.db
deleted file mode 100644
index 2bdae87404..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Data.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Digest.sha1 b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Digest.sha1
deleted file mode 100644
index 7af63e1f97..0000000000
--- a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Digest.sha1
+++ /dev/null
@@ -1 +0,0 @@
-a6a32d25ca3cdf76ac5a1a6bffa78936463f9648  Indexed1.626972746864617465-hb-1-Data.db
\ No newline at end of file
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Filter.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Filter.db
deleted file mode 100644
index 1fd53624a6..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Filter.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Index.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Index.db
deleted file mode 100644
index d9a482fa97..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Index.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Statistics.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Statistics.db
deleted file mode 100644
index 78c4ed3333..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Indexed1.626972746864617465-hb-1-Statistics.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Data.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Data.db
deleted file mode 100644
index 1cd5d15c5d..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Data.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Digest.sha1 b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Digest.sha1
deleted file mode 100644
index fa25470fcc..0000000000
--- a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Digest.sha1
+++ /dev/null
@@ -1 +0,0 @@
-72295cc1b64e6ffdb67a39dec9996c4ff0363cce  Standard1-hb-0-Data.db
\ No newline at end of file
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Filter.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Filter.db
deleted file mode 100644
index 1fc44602d9..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Filter.db and /dev/null differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Index.db b/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Index.db
deleted file mode 100644
index bfe71f58bd..0000000000
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Index.db and /dev/null differ
diff --git a/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Data.db b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Data.db
new file mode 100644
index 0000000000..f134aee5d1
Binary files /dev/null and b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Data.db differ
diff --git a/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Digest.sha1 b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Digest.sha1
new file mode 100644
index 0000000000..91b9562ad5
--- /dev/null
+++ b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Digest.sha1
@@ -0,0 +1 @@
+c22f034592ec31b1998083a34c1593538e8f1ea1  Keyspace1-Standard1-ic-0-Data.db
\ No newline at end of file
diff --git a/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Filter.db b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Filter.db
new file mode 100644
index 0000000000..a3a807c69e
Binary files /dev/null and b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Filter.db differ
diff --git a/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Index.db b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Index.db
new file mode 100644
index 0000000000..715913b049
Binary files /dev/null and b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Index.db differ
diff --git a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Statistics.db b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Statistics.db
similarity index 96%
rename from test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Statistics.db
rename to test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Statistics.db
index 8c256e9168..e9d5d4b154 100644
Binary files a/test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Statistics.db and b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Statistics.db differ
diff --git a/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Summary.db b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Summary.db
new file mode 100644
index 0000000000..e93acef0a5
Binary files /dev/null and b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-Summary.db differ
diff --git a/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-TOC.txt b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-TOC.txt
new file mode 100644
index 0000000000..34b61c7ea3
--- /dev/null
+++ b/test/data/legacy-sstables/ic/Keyspace1/Keyspace1-Standard1-ic-0-TOC.txt
@@ -0,0 +1,7 @@
+Data.db
+TOC.txt
+Index.db
+Summary.db
+Filter.db
+Statistics.db
+Digest.sha1
diff --git a/test/data/serialization/2.0/db.RowMutation.bin b/test/data/serialization/2.0/db.RowMutation.bin
index f77923313d..fcbf7946e9 100644
Binary files a/test/data/serialization/2.0/db.RowMutation.bin and b/test/data/serialization/2.0/db.RowMutation.bin differ
diff --git a/test/long/org/apache/cassandra/utils/LongBloomFilterTest.java b/test/long/org/apache/cassandra/utils/LongBloomFilterTest.java
index 94caa97207..8d916a04fc 100644
--- a/test/long/org/apache/cassandra/utils/LongBloomFilterTest.java
+++ b/test/long/org/apache/cassandra/utils/LongBloomFilterTest.java
@@ -31,72 +31,42 @@ public class LongBloomFilterTest
     /**
      * NB: needs to run with -mx1G
      */
-    public void testBigInt(FilterFactory.Type type)
+    @Test
+    public void testBigInt()
     {
         int size = 10 * 1000 * 1000;
-        IFilter bf = FilterFactory.getFilter(size, FilterTestHelper.spec.bucketsPerElement, type, false);
-        double fp = FilterTestHelper.testFalsePositives(bf, new KeyGenerator.IntGenerator(size),
-                                                            new KeyGenerator.IntGenerator(size, size * 2));
+        IFilter bf = FilterFactory.getFilter(size, FilterTestHelper.spec.bucketsPerElement, false);
+        double fp = FilterTestHelper.testFalsePositives(bf,
+                                                        new KeyGenerator.IntGenerator(size),
+                                                        new KeyGenerator.IntGenerator(size, size * 2));
         logger.info("Bloom filter false positive: {}", fp);
     }
 
-    public void testBigRandom(FilterFactory.Type type)
+    @Test
+    public void testBigRandom()
     {
         int size = 10 * 1000 * 1000;
-        IFilter bf = FilterFactory.getFilter(size, FilterTestHelper.spec.bucketsPerElement, type, false);
-        double fp = FilterTestHelper.testFalsePositives(bf, new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size),
-                                                            new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size));
+        IFilter bf = FilterFactory.getFilter(size, FilterTestHelper.spec.bucketsPerElement, false);
+        double fp = FilterTestHelper.testFalsePositives(bf,
+                                                        new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size),
+                                                        new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size));
         logger.info("Bloom filter false positive: {}", fp);
     }
 
-    public void timeit(FilterFactory.Type type)
+    @Test
+    public void timeit()
     {
         int size = 300 * FilterTestHelper.ELEMENTS;
-        IFilter bf = FilterFactory.getFilter(size, FilterTestHelper.spec.bucketsPerElement, type, false);
+        IFilter bf = FilterFactory.getFilter(size, FilterTestHelper.spec.bucketsPerElement, false);
         double sumfp = 0;
         for (int i = 0; i < 10; i++)
         {
-            FilterTestHelper.testFalsePositives(bf, new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size),
-                                                    new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size));
+            FilterTestHelper.testFalsePositives(bf,
+                                                new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size),
+                                                new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size));
 
             bf.clear();
         }
-        logger.info("Bloom filter mean false positive: {}", sumfp/10);
-    }
-
-    @Test
-    public void testBigIntMurm2()
-    {
-        testBigInt(FilterFactory.Type.MURMUR2);
-    }
-
-    @Test
-    public void testBigRandomMurm2()
-    {
-        testBigRandom(FilterFactory.Type.MURMUR2);
-    }
-
-    @Test
-    public void timeitMurm2()
-    {
-        timeit(FilterFactory.Type.MURMUR2);
-    }
-
-    @Test
-    public void testBigIntMurm3()
-    {
-        testBigInt(FilterFactory.Type.MURMUR3);
-    }
-
-    @Test
-    public void testBigRandomMurm3()
-    {
-        testBigRandom(FilterFactory.Type.MURMUR3);
-    }
-
-    @Test
-    public void timeitMurm3()
-    {
-        timeit(FilterFactory.Type.MURMUR3);
+        logger.info("Bloom filter mean false positive: {}", sumfp / 10);
     }
 }
diff --git a/test/long/org/apache/cassandra/utils/LongLegacyBloomFilterTest.java b/test/long/org/apache/cassandra/utils/LongLegacyBloomFilterTest.java
deleted file mode 100644
index 60d1bc34b5..0000000000
--- a/test/long/org/apache/cassandra/utils/LongLegacyBloomFilterTest.java
+++ /dev/null
@@ -1,65 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.cassandra.utils;
-
-import java.util.Random;
-
-import org.junit.Test;
-
-public class LongLegacyBloomFilterTest
-{
-    public LegacyBloomFilter bf;
-
-    /**
-     * NB: needs to run with -mx1G
-     */
-    @Test
-    public void testBigInt()
-    {
-        int size = 10 * 1000 * 1000;
-        bf = LegacyBloomFilter.getFilter(size, FilterTestHelper.spec.bucketsPerElement);
-        FilterTestHelper.testFalsePositives(bf,
-                                            new KeyGenerator.IntGenerator(size),
-                                            new KeyGenerator.IntGenerator(size, size * 2));
-    }
-
-    @Test
-    public void testBigRandom()
-    {
-        int size = 10 * 1000 * 1000;
-        bf = LegacyBloomFilter.getFilter(size, FilterTestHelper.spec.bucketsPerElement);
-        FilterTestHelper.testFalsePositives(bf,
-                                            new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size),
-                                            new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size));
-    }
-
-    @Test
-    public void timeit()
-    {
-        int size = 300 * FilterTestHelper.ELEMENTS;
-        bf = LegacyBloomFilter.getFilter(size, FilterTestHelper.spec.bucketsPerElement);
-        for (int i = 0; i < 10; i++)
-        {
-            FilterTestHelper.testFalsePositives(bf,
-                                                new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size),
-                                                new KeyGenerator.RandomStringGenerator(new Random().nextInt(), size));
-            bf.clear();
-        }
-    }
-}
diff --git a/test/unit/org/apache/cassandra/SchemaLoader.java b/test/unit/org/apache/cassandra/SchemaLoader.java
index 05f30d7a80..945d8e871a 100644
--- a/test/unit/org/apache/cassandra/SchemaLoader.java
+++ b/test/unit/org/apache/cassandra/SchemaLoader.java
@@ -36,7 +36,6 @@ import org.apache.cassandra.db.*;
 import org.apache.cassandra.db.commitlog.CommitLog;
 import org.apache.cassandra.db.compaction.LeveledCompactionStrategy;
 import org.apache.cassandra.db.filter.QueryFilter;
-import org.apache.cassandra.db.index.composites.CompositesIndex;
 import org.apache.cassandra.db.marshal.*;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.gms.Gossiper;
@@ -153,26 +152,26 @@ public class SchemaLoader
                                            opts_rf1,
 
                                            // Column Families
-                                           standardCFMD(ks1, "Standard1", withOldCfIds).compactionStrategyOptions(compactionOptions),
-                                           standardCFMD(ks1, "Standard2", withOldCfIds),
-                                           standardCFMD(ks1, "Standard3", withOldCfIds),
-                                           standardCFMD(ks1, "Standard4", withOldCfIds),
-                                           standardCFMD(ks1, "StandardLong1", withOldCfIds),
-                                           standardCFMD(ks1, "StandardLong2", withOldCfIds),
+                                           standardCFMD(ks1, "Standard1").compactionStrategyOptions(compactionOptions),
+                                           standardCFMD(ks1, "Standard2"),
+                                           standardCFMD(ks1, "Standard3"),
+                                           standardCFMD(ks1, "Standard4"),
+                                           standardCFMD(ks1, "StandardLong1"),
+                                           standardCFMD(ks1, "StandardLong2"),
                                            new CFMetaData(ks1,
                                                           "ValuesWithQuotes",
                                                           st,
                                                           BytesType.instance,
                                                           null)
                                                    .defaultValidator(UTF8Type.instance),
-                                           superCFMD(ks1, "Super1", LongType.instance, withOldCfIds),
-                                           superCFMD(ks1, "Super2", LongType.instance, withOldCfIds),
-                                           superCFMD(ks1, "Super3", LongType.instance, withOldCfIds),
-                                           superCFMD(ks1, "Super4", UTF8Type.instance, withOldCfIds),
-                                           superCFMD(ks1, "Super5", bytes, withOldCfIds),
-                                           superCFMD(ks1, "Super6", LexicalUUIDType.instance, UTF8Type.instance, withOldCfIds),
-                                           indexCFMD(ks1, "Indexed1", true, withOldCfIds),
-                                           indexCFMD(ks1, "Indexed2", false, withOldCfIds),
+                                           superCFMD(ks1, "Super1", LongType.instance),
+                                           superCFMD(ks1, "Super2", LongType.instance),
+                                           superCFMD(ks1, "Super3", LongType.instance),
+                                           superCFMD(ks1, "Super4", UTF8Type.instance),
+                                           superCFMD(ks1, "Super5", bytes),
+                                           superCFMD(ks1, "Super6", LexicalUUIDType.instance, UTF8Type.instance),
+                                           indexCFMD(ks1, "Indexed1", true),
+                                           indexCFMD(ks1, "Indexed2", false),
                                            new CFMetaData(ks1,
                                                           "StandardInteger1",
                                                           st,
@@ -190,12 +189,12 @@ public class SchemaLoader
                                                           bytes,
                                                           bytes)
                                                    .defaultValidator(CounterColumnType.instance),
-                                           superCFMD(ks1, "SuperDirectGC", BytesType.instance, withOldCfIds).gcGraceSeconds(0),
-                                           jdbcCFMD(ks1, "JdbcInteger", IntegerType.instance, withOldCfIds).columnMetadata(integerColumn),
-                                           jdbcCFMD(ks1, "JdbcUtf8", UTF8Type.instance, withOldCfIds).columnMetadata(utf8Column),
-                                           jdbcCFMD(ks1, "JdbcLong", LongType.instance, withOldCfIds),
-                                           jdbcCFMD(ks1, "JdbcBytes", bytes, withOldCfIds),
-                                           jdbcCFMD(ks1, "JdbcAscii", AsciiType.instance, withOldCfIds),
+                                           superCFMD(ks1, "SuperDirectGC", BytesType.instance).gcGraceSeconds(0),
+                                           jdbcCFMD(ks1, "JdbcInteger", IntegerType.instance).columnMetadata(integerColumn),
+                                           jdbcCFMD(ks1, "JdbcUtf8", UTF8Type.instance).columnMetadata(utf8Column),
+                                           jdbcCFMD(ks1, "JdbcLong", LongType.instance),
+                                           jdbcCFMD(ks1, "JdbcBytes", bytes),
+                                           jdbcCFMD(ks1, "JdbcAscii", AsciiType.instance),
                                            new CFMetaData(ks1,
                                                           "StandardComposite",
                                                           st,
@@ -206,10 +205,10 @@ public class SchemaLoader
                                                           st,
                                                           dynamicComposite,
                                                           null),
-                                           standardCFMD(ks1, "StandardLeveled", withOldCfIds)
+                                           standardCFMD(ks1, "StandardLeveled")
                                                                                .compactionStrategyClass(LeveledCompactionStrategy.class)
                                                                                .compactionStrategyOptions(leveledOptions),
-                                           standardCFMD(ks1, "legacyleveled", withOldCfIds)
+                                           standardCFMD(ks1, "legacyleveled")
                                                                                .compactionStrategyClass(LeveledCompactionStrategy.class)
                                                                                .compactionStrategyOptions(leveledOptions)));
 
@@ -219,11 +218,11 @@ public class SchemaLoader
                                            opts_rf1,
 
                                            // Column Families
-                                           standardCFMD(ks2, "Standard1", withOldCfIds),
-                                           standardCFMD(ks2, "Standard3", withOldCfIds),
-                                           superCFMD(ks2, "Super3", bytes, withOldCfIds),
-                                           superCFMD(ks2, "Super4", TimeUUIDType.instance, withOldCfIds),
-                                           indexCFMD(ks2, "Indexed1", true, withOldCfIds),
+                                           standardCFMD(ks2, "Standard1"),
+                                           standardCFMD(ks2, "Standard3"),
+                                           superCFMD(ks2, "Super3", bytes),
+                                           superCFMD(ks2, "Super4", TimeUUIDType.instance),
+                                           indexCFMD(ks2, "Indexed1", true),
                                            compositeIndexCFMD(ks2, "Indexed2", true, withOldCfIds)));
 
         // Keyspace 3
@@ -232,8 +231,8 @@ public class SchemaLoader
                                            opts_rf5,
 
                                            // Column Families
-                                           standardCFMD(ks3, "Standard1", withOldCfIds),
-                                           indexCFMD(ks3, "Indexed1", true, withOldCfIds)));
+                                           standardCFMD(ks3, "Standard1"),
+                                           indexCFMD(ks3, "Indexed1", true)));
 
         // Keyspace 4
         schema.add(KSMetaData.testMetadata(ks4,
@@ -241,10 +240,10 @@ public class SchemaLoader
                                            opts_rf3,
 
                                            // Column Families
-                                           standardCFMD(ks4, "Standard1", withOldCfIds),
-                                           standardCFMD(ks4, "Standard3", withOldCfIds),
-                                           superCFMD(ks4, "Super3", bytes, withOldCfIds),
-                                           superCFMD(ks4, "Super4", TimeUUIDType.instance, withOldCfIds),
+                                           standardCFMD(ks4, "Standard1"),
+                                           standardCFMD(ks4, "Standard3"),
+                                           superCFMD(ks4, "Super3", bytes),
+                                           superCFMD(ks4, "Super4", TimeUUIDType.instance),
                                            new CFMetaData(ks4,
                                                           "Super5",
                                                           su,
@@ -255,35 +254,35 @@ public class SchemaLoader
         schema.add(KSMetaData.testMetadata(ks5,
                                            simple,
                                            opts_rf2,
-                                           standardCFMD(ks5, "Standard1", withOldCfIds),
-                                           standardCFMD(ks5, "Counter1", withOldCfIds)
+                                           standardCFMD(ks5, "Standard1"),
+                                           standardCFMD(ks5, "Counter1")
                                                    .defaultValidator(CounterColumnType.instance)));
 
         // Keyspace 6
         schema.add(KSMetaData.testMetadata(ks6,
                                            simple,
                                            opts_rf1,
-                                           indexCFMD(ks6, "Indexed1", true, withOldCfIds)));
+                                           indexCFMD(ks6, "Indexed1", true)));
 
         // KeyCacheSpace
         schema.add(KSMetaData.testMetadata(ks_kcs,
                                            simple,
                                            opts_rf1,
-                                           standardCFMD(ks_kcs, "Standard1", withOldCfIds),
-                                           standardCFMD(ks_kcs, "Standard2", withOldCfIds),
-                                           standardCFMD(ks_kcs, "Standard3", withOldCfIds)));
+                                           standardCFMD(ks_kcs, "Standard1"),
+                                           standardCFMD(ks_kcs, "Standard2"),
+                                           standardCFMD(ks_kcs, "Standard3")));
 
         // RowCacheSpace
         schema.add(KSMetaData.testMetadata(ks_rcs,
                                            simple,
                                            opts_rf1,
-                                           standardCFMD(ks_rcs, "CFWithoutCache", withOldCfIds).caching(CFMetaData.Caching.NONE),
-                                           standardCFMD(ks_rcs, "CachedCF", withOldCfIds).caching(CFMetaData.Caching.ALL)));
+                                           standardCFMD(ks_rcs, "CFWithoutCache").caching(CFMetaData.Caching.NONE),
+                                           standardCFMD(ks_rcs, "CachedCF").caching(CFMetaData.Caching.ALL)));
 
         schema.add(KSMetaData.testMetadataNotDurable(ks_nocommit,
                                                      simple,
                                                      opts_rf1,
-                                                     standardCFMD(ks_nocommit, "Standard1", withOldCfIds)));
+                                                     standardCFMD(ks_nocommit, "Standard1")));
 
         // PerRowSecondaryIndexTest
         schema.add(KSMetaData.testMetadata(ks_prsi,
@@ -303,7 +302,7 @@ public class SchemaLoader
         final Map<String, String> indexOptions = Collections.singletonMap(
                                                       SecondaryIndex.CUSTOM_INDEX_OPTION_NAME,
                                                       PerRowSecondaryIndexTest.TestIndex.class.getName());
-        return standardCFMD(ksName, cfName, withOldCfIds)
+        return standardCFMD(ksName, cfName)
                 .keyValidator(AsciiType.instance)
                 .columnMetadata(new HashMap<ByteBuffer, ColumnDefinition>()
                 {{
@@ -328,31 +327,21 @@ public class SchemaLoader
         }
     }
 
-    private static CFMetaData standardCFMD(String ksName, String cfName, boolean withOldCfIds)
+    private static CFMetaData standardCFMD(String ksName, String cfName)
     {
-        CFMetaData cfmd = new CFMetaData(ksName, cfName, ColumnFamilyType.Standard, BytesType.instance, null);
-
-        if (withOldCfIds)
-            Schema.instance.addOldCfIdMapping(oldCfIdGenerator.getAndIncrement(), cfmd.cfId);
-
-        return cfmd;
+        return new CFMetaData(ksName, cfName, ColumnFamilyType.Standard, BytesType.instance, null);
     }
-    private static CFMetaData superCFMD(String ksName, String cfName, AbstractType subcc, boolean withOldCfIds)
+    private static CFMetaData superCFMD(String ksName, String cfName, AbstractType subcc)
     {
-        return superCFMD(ksName, cfName, BytesType.instance, subcc, withOldCfIds);
+        return superCFMD(ksName, cfName, BytesType.instance, subcc);
     }
-    private static CFMetaData superCFMD(String ksName, String cfName, AbstractType cc, AbstractType subcc, boolean withOldCfIds)
+    private static CFMetaData superCFMD(String ksName, String cfName, AbstractType cc, AbstractType subcc)
     {
-        CFMetaData cfmd = new CFMetaData(ksName, cfName, ColumnFamilyType.Super, cc, subcc);
-
-        if (withOldCfIds)
-            Schema.instance.addOldCfIdMapping(oldCfIdGenerator.getAndIncrement(), cfmd.cfId);
-
-        return cfmd;
+        return new CFMetaData(ksName, cfName, ColumnFamilyType.Super, cc, subcc);
     }
-    private static CFMetaData indexCFMD(String ksName, String cfName, final Boolean withIdxType, boolean withOldCfIds) throws ConfigurationException
+    private static CFMetaData indexCFMD(String ksName, String cfName, final Boolean withIdxType) throws ConfigurationException
     {
-        return standardCFMD(ksName, cfName, withOldCfIds)
+        return standardCFMD(ksName, cfName)
                .keyValidator(AsciiType.instance)
                .columnMetadata(new HashMap<ByteBuffer, ColumnDefinition>()
                    {{
@@ -378,14 +367,9 @@ public class SchemaLoader
                 }});
     }
     
-    private static CFMetaData jdbcCFMD(String ksName, String cfName, AbstractType comp, boolean withOldCfIds)
+    private static CFMetaData jdbcCFMD(String ksName, String cfName, AbstractType comp)
     {
-        CFMetaData cfmd = new CFMetaData(ksName, cfName, ColumnFamilyType.Standard, comp, null).defaultValidator(comp);
-
-        if (withOldCfIds)
-            Schema.instance.addOldCfIdMapping(oldCfIdGenerator.getAndIncrement(), cfmd.cfId);
-
-        return cfmd;
+        return new CFMetaData(ksName, cfName, ColumnFamilyType.Standard, comp, null).defaultValidator(comp);
     }
 
     public static void cleanupAndLeaveDirs()
diff --git a/test/unit/org/apache/cassandra/config/DefsTest.java b/test/unit/org/apache/cassandra/config/DefsTest.java
index 66d5f81f2d..04fd5f8a2b 100644
--- a/test/unit/org/apache/cassandra/config/DefsTest.java
+++ b/test/unit/org/apache/cassandra/config/DefsTest.java
@@ -48,14 +48,6 @@ import org.junit.runner.RunWith;
 @RunWith(OrderedJUnit4ClassRunner.class)
 public class DefsTest extends SchemaLoader
 {
-
-    @Test
-    public void ensureStaticCFMIdsAreLessThan1000()
-    {
-        assert CFMetaData.OldStatusCf.cfId.equals(CFMetaData.getId(Table.SYSTEM_KS, SystemTable.OLD_STATUS_CF));
-        assert CFMetaData.OldHintsCf.cfId.equals(CFMetaData.getId(Table.SYSTEM_KS, SystemTable.OLD_HINTS_CF));
-    }
-
     @Test
     public void testCFMetaDataApply() throws ConfigurationException
     {
diff --git a/test/unit/org/apache/cassandra/db/CommitLogTest.java b/test/unit/org/apache/cassandra/db/CommitLogTest.java
index ee2e66316d..68d7028510 100644
--- a/test/unit/org/apache/cassandra/db/CommitLogTest.java
+++ b/test/unit/org/apache/cassandra/db/CommitLogTest.java
@@ -219,11 +219,9 @@ public class CommitLogTest extends SchemaLoader
         Assert.assertFalse(CommitLogDescriptor.isValid("CommitLog-2-1340512736956320000-123.log"));
 
         Assert.assertEquals(1340512736956320000L, CommitLogDescriptor.fromFileName("CommitLog-2-1340512736956320000.log").id);
-        Assert.assertEquals(1340512736956320000L, CommitLogDescriptor.fromFileName("CommitLog-1340512736956320000.log").id);
 
         Assert.assertEquals(MessagingService.current_version, new CommitLogDescriptor(1340512736956320000L).getMessagingVersion());
         String newCLName = "CommitLog-" + CommitLogDescriptor.current_version + "-1340512736956320000.log";
         Assert.assertEquals(MessagingService.current_version, CommitLogDescriptor.fromFileName(newCLName).getMessagingVersion());
-        Assert.assertEquals(MessagingService.VERSION_11, CommitLogDescriptor.fromFileName("CommitLog-1340512736956320000.log").getMessagingVersion());
     }
 }
diff --git a/test/unit/org/apache/cassandra/db/DirectoriesTest.java b/test/unit/org/apache/cassandra/db/DirectoriesTest.java
index 21e183c7f4..89530e14de 100644
--- a/test/unit/org/apache/cassandra/db/DirectoriesTest.java
+++ b/test/unit/org/apache/cassandra/db/DirectoriesTest.java
@@ -175,33 +175,6 @@ public class DirectoriesTest
         }
     }
 
-    @Test
-    public void testHandleBadFiles() throws IOException
-    {
-        /* files not matching the pattern should just be ignored, with a log warning */
-        Directories directories = Directories.create(KS, "bad");
-        File dir = directories.getDirectoryForNewSSTables(1);
-        File f = File.createTempFile("bad", "file", dir.getParentFile());
-        Directories.migrateSSTables();
-        Assert.assertTrue(f.isFile());
-
-        /* real failures should throw an exception with informational message */
-        f = File.createTempFile("locked", ".json", dir.getParentFile());
-        File targetDir = new File(dir.getParentFile(), f.getName().substring(0, f.getName().length() - ".json".length()));
-        targetDir.mkdirs();
-        targetDir.setReadOnly();
-
-        try
-        {
-            Directories.migrateSSTables();
-            Assert.assertFalse(true);
-        }
-        catch (Exception e)
-        {
-            Assert.assertTrue(e.getMessage().contains(f.getPath()));
-        }
-    }
-
     @Test
     public void testDiskFailurePolicy_best_effort() throws IOException
     {
diff --git a/test/unit/org/apache/cassandra/db/KeyCollisionTest.java b/test/unit/org/apache/cassandra/db/KeyCollisionTest.java
index 085534d36f..48838b96c1 100644
--- a/test/unit/org/apache/cassandra/db/KeyCollisionTest.java
+++ b/test/unit/org/apache/cassandra/db/KeyCollisionTest.java
@@ -105,11 +105,6 @@ public class KeyCollisionTest extends SchemaLoader
             return new DecoratedKey(getToken(key), key);
         }
 
-        public DecoratedKey convertFromDiskFormat(ByteBuffer fromdisk)
-        {
-            throw new UnsupportedOperationException();
-        }
-
         public Token midpoint(Token ltoken, Token rtoken)
         {
             // the symbolic MINIMUM token should act as ZERO: the empty bit array
diff --git a/test/unit/org/apache/cassandra/db/ScrubTest.java b/test/unit/org/apache/cassandra/db/ScrubTest.java
index ed2bac1cd1..d1635d8449 100644
--- a/test/unit/org/apache/cassandra/db/ScrubTest.java
+++ b/test/unit/org/apache/cassandra/db/ScrubTest.java
@@ -23,6 +23,7 @@ package org.apache.cassandra.db;
 
 import java.io.File;
 import java.io.IOException;
+import java.util.Collections;
 import java.util.List;
 import java.util.concurrent.ExecutionException;
 
@@ -32,11 +33,17 @@ import org.junit.runner.RunWith;
 import org.apache.cassandra.OrderedJUnit4ClassRunner;
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.Util;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.commitlog.ReplayPosition;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.db.columniterator.IdentityQueryFilter;
 import org.apache.cassandra.db.compaction.CompactionManager;
 import org.apache.cassandra.db.filter.NamesQueryFilter;
 import org.apache.cassandra.db.marshal.CompositeType;
+import org.apache.cassandra.io.sstable.Component;
+import org.apache.cassandra.io.sstable.SSTableMetadata;
+import org.apache.cassandra.io.sstable.SSTableReader;
+import org.apache.cassandra.io.sstable.SSTableWriter;
 import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.CLibrary;
@@ -145,27 +152,31 @@ public class ScrubTest extends SchemaLoader
     @Test
     public void testScubOutOfOrder() throws Exception
     {
-         CompactionManager.instance.disableAutoCompaction();
-         Table table = Table.open(TABLE);
-         String columnFamily = "Standard3";
-         ColumnFamilyStore cfs = table.getColumnFamilyStore(columnFamily);
+        CompactionManager.instance.disableAutoCompaction();
+        Table table = Table.open(TABLE);
+        String columnFamily = "Standard3";
+        ColumnFamilyStore cfs = table.getColumnFamilyStore(columnFamily);
 
         /*
          * Code used to generate an outOfOrder sstable. The test for out-of-order key in SSTableWriter must also be commented out.
          * The test also assumes an ordered partitioner.
          *
-         *  ColumnFamily cf = ColumnFamily.create(TABLE, columnFamily);
-         *  cf.addColumn(new Column(ByteBufferUtil.bytes("someName"), ByteBufferUtil.bytes("someValue"), 0L));
-
-         *  SSTableWriter writer = cfs.createCompactionWriter((long)DatabaseDescriptor.getIndexInterval(), new File("."), Collections.<SSTableReader>emptyList());
-         *  writer.append(Util.dk("a"), cf);
-         *  writer.append(Util.dk("b"), cf);
-         *  writer.append(Util.dk("z"), cf);
-         *  writer.append(Util.dk("c"), cf);
-         *  writer.append(Util.dk("y"), cf);
-         *  writer.append(Util.dk("d"), cf);
-         *  writer.closeAndOpenReader();
-         */
+        ColumnFamily cf = ArrayBackedSortedColumns.factory.create(cfs.metadata);
+        cf.addColumn(new Column(ByteBufferUtil.bytes("someName"), ByteBufferUtil.bytes("someValue"), 0L));
+
+        SSTableWriter writer = new SSTableWriter(cfs.getTempSSTablePath(new File(System.getProperty("corrupt-sstable-root"))),
+                                                 cfs.metadata.getIndexInterval(),
+                                                 cfs.metadata,
+                                                 cfs.partitioner,
+                                                 SSTableMetadata.createCollector());
+        writer.append(Util.dk("a"), cf);
+        writer.append(Util.dk("b"), cf);
+        writer.append(Util.dk("z"), cf);
+        writer.append(Util.dk("c"), cf);
+        writer.append(Util.dk("y"), cf);
+        writer.append(Util.dk("d"), cf);
+        writer.closeAndOpenReader();
+        */
 
         copySSTables(columnFamily);
         cfs.loadNewSSTables();
@@ -178,7 +189,7 @@ public class ScrubTest extends SchemaLoader
         CompactionManager.instance.performScrub(cfs);
         rows = cfs.getRangeSlice(Util.range("", ""), 1000, new IdentityQueryFilter(), null);
         assert isRowOrdered(rows) : "Scrub failed: " + rows;
-        assert rows.size() == 6: "Got " + rows.size();
+        assert rows.size() == 6 : "Got " + rows.size();
     }
 
     private static boolean isRowOrdered(List<Row> rows)
diff --git a/test/unit/org/apache/cassandra/io/LazilyCompactedRowTest.java b/test/unit/org/apache/cassandra/io/LazilyCompactedRowTest.java
index 7e677baac5..f1e689ed67 100644
--- a/test/unit/org/apache/cassandra/io/LazilyCompactedRowTest.java
+++ b/test/unit/org/apache/cassandra/io/LazilyCompactedRowTest.java
@@ -18,10 +18,7 @@
  */
 package org.apache.cassandra.io;
 
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
+import java.io.*;
 import java.nio.ByteBuffer;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
@@ -110,8 +107,8 @@ public class LazilyCompactedRowTest extends SchemaLoader
             // key isn't part of what CompactedRow writes, that's done by SSTW.append
 
             // row size can differ b/c of bloom filter counts being different
-            long rowSize1 = SSTableReader.readRowSize(in1, sstables.iterator().next().descriptor);
-            long rowSize2 = SSTableReader.readRowSize(in2, sstables.iterator().next().descriptor);
+            long rowSize1 = in1.readLong();
+            long rowSize2 = in2.readLong();
             assertEquals(rowSize1 + 8, out1.getLength());
             assertEquals(rowSize2 + 8, out2.getLength());
 
diff --git a/test/unit/org/apache/cassandra/io/sstable/DescriptorTest.java b/test/unit/org/apache/cassandra/io/sstable/DescriptorTest.java
deleted file mode 100644
index 007e0ca8f6..0000000000
--- a/test/unit/org/apache/cassandra/io/sstable/DescriptorTest.java
+++ /dev/null
@@ -1,67 +0,0 @@
-package org.apache.cassandra.io.sstable;
-/*
- *
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- *
- */
-
-import org.apache.cassandra.utils.FilterFactory;
-import org.junit.Test;
-import static org.junit.Assert.*;
-
-public class DescriptorTest
-{
-    @Test
-    public void testLegacy()
-    {
-        Descriptor descriptor = Descriptor.fromFilename("Keyspace1-userActionUtilsKey-9-Data.db");
-
-        assert descriptor.version.equals(Descriptor.Version.LEGACY);
-        assert descriptor.version.filterType == FilterFactory.Type.SHA;
-    }
-
-    @Test
-    public void testVersion()
-    {
-        // letter only
-        Descriptor desc = Descriptor.fromFilename("Keyspace1-Standard1-h-1-Data.db");
-        assert "h".equals(desc.version.toString());
-
-        // multiple letters
-        desc = Descriptor.fromFilename("Keyspace1-Standard1-ha-1-Data.db");
-        assert "ha".equals(desc.version.toString());
-
-        // hypothetical two-letter g version
-        desc = Descriptor.fromFilename("Keyspace1-Standard1-gz-1-Data.db");
-        assert "gz".equals(desc.version.toString());
-        assert !desc.version.tracksMaxTimestamp;
-        assert !desc.version.tracksMinTimestamp;
-    }
-
-    @Test
-    public void testMurmurBloomFilter()
-    {
-        Descriptor desc = Descriptor.fromFilename("Keyspace1-Standard1-hz-1-Data.db");
-        assertEquals("hz", desc.version.toString());
-        assertEquals(desc.version.filterType, FilterFactory.Type.MURMUR2);
-
-        desc = Descriptor.fromFilename("Keyspace1-Standard1-ia-1-Data.db");
-        assertEquals("ia", desc.version.toString());
-        assertEquals(desc.version.filterType, FilterFactory.Type.MURMUR3);
-    }
-}
diff --git a/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java b/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
index db3f1c5fda..0b0ecf80e7 100644
--- a/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
@@ -33,8 +33,7 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 
 /**
- * Tests backwards compatibility for SSTables. Requires that older SSTables match up with the existing config file,
- * and currently only tests specific cases for specific upgrades.
+ * Tests backwards compatibility for SSTables
  */
 public class LegacySSTableTest extends SchemaLoader
 {
@@ -106,6 +105,8 @@ public class LegacySSTableTest extends SchemaLoader
                 SSTableNamesIterator iter = new SSTableNamesIterator(reader, dk, FBUtilities.singleton(key));
                 assert iter.next().name().equals(key);
             }
+
+            // TODO actually test some reads
         }
         catch (Throwable e)
         {
diff --git a/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java b/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
index c0d74793ad..fdb80a261a 100644
--- a/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
@@ -132,9 +132,7 @@ public class SSTableReaderTest extends SchemaLoader
         {
             DecoratedKey dk = Util.dk(String.valueOf(j));
             FileDataInput file = sstable.getFileDataInput(sstable.getPosition(dk, SSTableReader.Operator.EQ).position);
-            DecoratedKey keyInDisk = SSTableReader.decodeKey(sstable.partitioner,
-                                                             sstable.descriptor,
-                                                             ByteBufferUtil.readWithShortLength(file));
+            DecoratedKey keyInDisk = sstable.partitioner.decorateKey(ByteBufferUtil.readWithShortLength(file));
             assert keyInDisk.equals(dk) : String.format("%s != %s in %s", keyInDisk, dk, file.getPath());
         }
 
@@ -222,34 +220,6 @@ public class SSTableReaderTest extends SchemaLoader
         assertIndexQueryWorks(store);
     }
 
-    @Test
-    public void testPersistentStatisticsFromOlderIndexedSSTable() throws IOException, ExecutionException, InterruptedException
-    {
-        // copy legacy indexed sstables
-        String root = System.getProperty("legacy-sstable-root");
-        assert root != null;
-        File rootDir = new File(root + File.separator + "hb" + File.separator + "Keyspace1");
-        assert rootDir.isDirectory();
-
-        File destDir = Directories.create("Keyspace1", "Indexed1").getDirectoryForNewSSTables(0);
-        assert destDir != null;
-
-        FileUtils.createDirectory(destDir);
-        for (File srcFile : rootDir.listFiles())
-        {
-            if (!srcFile.getName().startsWith("Indexed1"))
-                continue;
-            File destFile = new File(destDir, srcFile.getName());
-            CLibrary.createHardLink(srcFile, destFile);
-
-            assert destFile.exists() : destFile.getAbsoluteFile();
-        }
-        ColumnFamilyStore store = Table.open("Keyspace1").getColumnFamilyStore("Indexed1");
-
-        // check if opening and querying works
-        assertIndexQueryWorks(store);
-    }
-
     @Test
     public void testOpeningSSTable() throws Exception
     {
diff --git a/test/unit/org/apache/cassandra/io/sstable/SSTableTest.java b/test/unit/org/apache/cassandra/io/sstable/SSTableTest.java
index d3b3b4bc5d..135f444683 100644
--- a/test/unit/org/apache/cassandra/io/sstable/SSTableTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/SSTableTest.java
@@ -59,7 +59,7 @@ public class SSTableTest extends SchemaLoader
         RandomAccessReader file = sstable.openDataReader();
         file.seek(sstable.getPosition(sstable.partitioner.decorateKey(key), SSTableReader.Operator.EQ).position);
         assert key.equals(ByteBufferUtil.readWithShortLength(file));
-        int size = (int)SSTableReader.readRowSize(file, sstable.descriptor);
+        int size = (int) file.readLong();
         byte[] bytes2 = new byte[size];
         file.readFully(bytes2);
         assert ByteBuffer.wrap(bytes2).equals(bytes);
@@ -103,7 +103,7 @@ public class SSTableTest extends SchemaLoader
         {
             file.seek(sstable.getPosition(sstable.partitioner.decorateKey(key), SSTableReader.Operator.EQ).position);
             assert key.equals( ByteBufferUtil.readWithShortLength(file));
-            int size = (int)SSTableReader.readRowSize(file, sstable.descriptor);
+            int size = (int) file.readLong();
             byte[] bytes2 = new byte[size];
             file.readFully(bytes2);
             assert Arrays.equals(bytes2, map.get(key).array());
diff --git a/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java b/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
index 5ce9160ee6..d28bd8db61 100644
--- a/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
+++ b/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
@@ -33,6 +33,7 @@ import org.junit.runner.RunWith;
 import org.apache.cassandra.OrderedJUnit4ClassRunner;
 import org.apache.cassandra.config.KSMetaData;
 import org.apache.cassandra.config.Schema;
+import org.apache.cassandra.db.SystemTable;
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.dht.StringToken;
 import org.apache.cassandra.exceptions.ConfigurationException;
@@ -93,7 +94,7 @@ public class StorageServiceServerTest
     public void testColumnFamilySnapshot() throws IOException
     {
         // no need to insert extra data, even an "empty" database will have a little information in the system keyspace
-        StorageService.instance.takeColumnFamilySnapshot(Table.SYSTEM_KS, "Schema", "cf_snapshot");
+        StorageService.instance.takeColumnFamilySnapshot(Table.SYSTEM_KS, SystemTable.SCHEMA_KEYSPACES_CF, "cf_snapshot");
     }
 
     @Test
diff --git a/test/unit/org/apache/cassandra/utils/BitSetTest.java b/test/unit/org/apache/cassandra/utils/BitSetTest.java
index c49483cae6..f0959e8a68 100644
--- a/test/unit/org/apache/cassandra/utils/BitSetTest.java
+++ b/test/unit/org/apache/cassandra/utils/BitSetTest.java
@@ -19,23 +19,20 @@ package org.apache.cassandra.utils;
 
 import java.io.ByteArrayInputStream;
 import java.io.DataInputStream;
-import java.io.File;
-import java.io.FileInputStream;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.util.List;
 import java.util.Random;
 
-import junit.framework.Assert;
+import com.google.common.collect.Lists;
+import org.junit.Test;
 
+import junit.framework.Assert;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.utils.KeyGenerator.WordGenerator;
 import org.apache.cassandra.utils.obs.IBitSet;
 import org.apache.cassandra.utils.obs.OffHeapBitSet;
 import org.apache.cassandra.utils.obs.OpenBitSet;
-import org.junit.Test;
-
-import com.google.common.collect.Lists;
 
 import static junit.framework.Assert.assertEquals;
 
@@ -65,25 +62,6 @@ public class BitSetTest
         compare(bf2.bitset, bf3.bitset);
     }
 
-    private static final String LEGACY_SST_FILE = "test/data/legacy-sstables/hb/Keyspace1/Keyspace1-Standard1-hb-0-Filter.db";
-
-    /**
-     * Test compatibility with a 1.1-version data file
-     */
-    @Test
-    public void testExpectedCompatablity() throws IOException
-    {
-        DataInputStream in = new DataInputStream(new FileInputStream(new File(LEGACY_SST_FILE)));
-        in.readInt(); // bloom filter hash count
-        OpenBitSet bs = OpenBitSet.deserialize(in);
-
-        in = new DataInputStream(new FileInputStream(new File(LEGACY_SST_FILE)));
-        in.readInt(); // bloom filter hash count
-        OffHeapBitSet obs = OffHeapBitSet.deserialize(in);
-
-        compare(obs, bs);
-    }
-
     private static final Random random = new Random();
 
     /**
diff --git a/test/unit/org/apache/cassandra/utils/BloomFilterTest.java b/test/unit/org/apache/cassandra/utils/BloomFilterTest.java
index bb0865f8de..d3f6abea3f 100644
--- a/test/unit/org/apache/cassandra/utils/BloomFilterTest.java
+++ b/test/unit/org/apache/cassandra/utils/BloomFilterTest.java
@@ -44,10 +44,10 @@ public class BloomFilterTest
     {
         f.add(ByteBufferUtil.bytes("a"));
         DataOutputBuffer out = new DataOutputBuffer();
-        FilterFactory.serialize(f, out, FilterFactory.Type.MURMUR3);
+        FilterFactory.serialize(f, out);
 
         ByteArrayInputStream in = new ByteArrayInputStream(out.getData(), 0, out.getLength());
-        IFilter f2 = FilterFactory.deserialize(new DataInputStream(in), FilterFactory.Type.MURMUR3, true);
+        IFilter f2 = FilterFactory.deserialize(new DataInputStream(in), true);
 
         assert f2.isPresent(ByteBufferUtil.bytes("a"));
         assert !f2.isPresent(ByteBufferUtil.bytes("b"));
diff --git a/test/unit/org/apache/cassandra/utils/LegacyBloomFilterTest.java b/test/unit/org/apache/cassandra/utils/LegacyBloomFilterTest.java
deleted file mode 100644
index e7319db0b9..0000000000
--- a/test/unit/org/apache/cassandra/utils/LegacyBloomFilterTest.java
+++ /dev/null
@@ -1,132 +0,0 @@
-/*
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*    http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing,
-* software distributed under the License is distributed on an
-* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-* KIND, either express or implied.  See the License for the
-* specific language governing permissions and limitations
-* under the License.
-*/
-package org.apache.cassandra.utils;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.Set;
-import java.io.ByteArrayInputStream;
-import java.io.DataInputStream;
-import org.apache.cassandra.io.util.DataOutputBuffer;
-
-import org.junit.Before;
-import org.junit.Test;
-
-public class LegacyBloomFilterTest
-{
-    public LegacyBloomFilter bf;
-
-    public LegacyBloomFilterTest()
-    {
-        bf = LegacyBloomFilter.getFilter(FilterTestHelper.ELEMENTS, FilterTestHelper.MAX_FAILURE_RATE);
-    }
-
-    public static IFilter testSerialize(LegacyBloomFilter f) throws IOException
-    {
-        f.add(ByteBufferUtil.bytes("a"));
-        DataOutputBuffer out = new DataOutputBuffer();
-        FilterFactory.serialize(f, out, FilterFactory.Type.SHA);
-
-        ByteArrayInputStream in = new ByteArrayInputStream(out.getData(), 0, out.getLength());
-        LegacyBloomFilter f2 = (LegacyBloomFilter) FilterFactory.deserialize(new DataInputStream(in), FilterFactory.Type.SHA, false);
-
-        assert f2.isPresent(ByteBufferUtil.bytes("a"));
-        assert !f2.isPresent(ByteBufferUtil.bytes("b"));
-        return f2;
-    }
-
-
-    @Before
-    public void clear()
-    {
-        bf.clear();
-    }
-
-    @Test(expected=UnsupportedOperationException.class)
-    public void testBloomLimits1()
-    {
-        int maxBuckets = BloomCalculations.probs.length - 1;
-        int maxK = BloomCalculations.probs[maxBuckets].length - 1;
-
-        // possible
-        BloomCalculations.computeBloomSpec(maxBuckets, BloomCalculations.probs[maxBuckets][maxK]);
-
-        // impossible, throws
-        BloomCalculations.computeBloomSpec(maxBuckets, BloomCalculations.probs[maxBuckets][maxK] / 2);
-    }
-
-    @Test
-    public void testOne()
-    {
-        bf.add(ByteBufferUtil.bytes("a"));
-        assert bf.isPresent(ByteBufferUtil.bytes("a"));
-        assert !bf.isPresent(ByteBufferUtil.bytes("b"));
-    }
-
-    @Test
-    public void testFalsePositivesInt()
-    {
-        FilterTestHelper.testFalsePositives(bf, FilterTestHelper.intKeys(), FilterTestHelper.randomKeys2());
-    }
-
-    @Test
-    public void testFalsePositivesRandom()
-    {
-        FilterTestHelper.testFalsePositives(bf, FilterTestHelper.randomKeys(), FilterTestHelper.randomKeys2());
-    }
-
-    @Test
-    public void testWords()
-    {
-        if (KeyGenerator.WordGenerator.WORDS == 0)
-        {
-            return;
-        }
-        LegacyBloomFilter bf2 = LegacyBloomFilter.getFilter(KeyGenerator.WordGenerator.WORDS / 2, FilterTestHelper.MAX_FAILURE_RATE);
-        int skipEven = KeyGenerator.WordGenerator.WORDS % 2 == 0 ? 0 : 2;
-        FilterTestHelper.testFalsePositives(bf2,
-                                      new KeyGenerator.WordGenerator(skipEven, 2),
-                                      new KeyGenerator.WordGenerator(1, 2));
-    }
-
-    public void testManyHashes(Iterator<ByteBuffer> keys)
-    {
-        int MAX_HASH_COUNT = 128;
-        Set<Integer> hashes = new HashSet<Integer>();
-        int collisions = 0;
-        while (keys.hasNext())
-        {
-            hashes.clear();
-            for (int hashIndex : LegacyBloomFilter.getHashBuckets(keys.next(), MAX_HASH_COUNT, 1024 * 1024))
-            {
-                hashes.add(hashIndex);
-            }
-            collisions += (MAX_HASH_COUNT - hashes.size());
-        }
-        assert collisions <= 100;
-    }
-
-    @Test
-    public void testManyRandom()
-    {
-        testManyHashes(FilterTestHelper.randomKeys());
-    }
-}
diff --git a/test/unit/org/apache/cassandra/utils/SerializationsTest.java b/test/unit/org/apache/cassandra/utils/SerializationsTest.java
index 1a1e9fbf30..f2112c2e7f 100644
--- a/test/unit/org/apache/cassandra/utils/SerializationsTest.java
+++ b/test/unit/org/apache/cassandra/utils/SerializationsTest.java
@@ -20,74 +20,34 @@ package org.apache.cassandra.utils;
 
 import org.apache.cassandra.AbstractSerializationsTester;
 import org.apache.cassandra.service.StorageService;
-import org.apache.cassandra.utils.FilterFactory.Type;
+
 import org.junit.Test;
 
 import java.io.DataInputStream;
 import java.io.DataOutputStream;
 import java.io.IOException;
-import java.nio.ByteBuffer;
 
 public class SerializationsTest extends AbstractSerializationsTester
 {
 
-    private void testBloomFilterWrite(Type murmur, boolean offheap) throws IOException
+    private void testBloomFilterWrite(boolean offheap) throws IOException
     {
-        IFilter bf = FilterFactory.getFilter(1000000, 0.0001, murmur, offheap);
+        IFilter bf = FilterFactory.getFilter(1000000, 0.0001, offheap);
         for (int i = 0; i < 100; i++)
             bf.add(StorageService.getPartitioner().getTokenFactory().toByteArray(StorageService.getPartitioner().getRandomToken()));
         DataOutputStream out = getOutput("utils.BloomFilter.bin");
-        FilterFactory.serialize(bf, out, murmur);
+        FilterFactory.serialize(bf, out);
         out.close();
     }
 
-    @Test
-    public void testBloomFilterReadMURMUR2() throws IOException
-    {
-        if (EXECUTE_WRITES)
-            testBloomFilterWrite(FilterFactory.Type.MURMUR2, false);
-
-        DataInputStream in = getInput("utils.BloomFilter.bin");
-        assert FilterFactory.deserialize(in, FilterFactory.Type.MURMUR2, false) != null;
-        in.close();
-    }
-
     @Test
     public void testBloomFilterReadMURMUR3() throws IOException
     {
         if (EXECUTE_WRITES)
-            testBloomFilterWrite(FilterFactory.Type.MURMUR3, true);
+            testBloomFilterWrite(true);
 
         DataInputStream in = getInput("utils.BloomFilter.bin");
-        assert FilterFactory.deserialize(in, FilterFactory.Type.MURMUR3, true) != null;
-        in.close();
-    }
-
-    private void testLegacyBloomFilterWrite() throws IOException
-    {
-        LegacyBloomFilter a = LegacyBloomFilter.getFilter(1000000, 1000);
-        LegacyBloomFilter b = LegacyBloomFilter.getFilter(1000000, 0.0001);
-        for (int i = 0; i < 100; i++)
-        {
-            ByteBuffer key = StorageService.getPartitioner().getTokenFactory().toByteArray(StorageService.getPartitioner().getRandomToken());
-            a.add(key);
-            b.add(key);
-        }
-        DataOutputStream out = getOutput("utils.LegacyBloomFilter.bin");
-        FilterFactory.serialize(a, out, FilterFactory.Type.SHA);
-        FilterFactory.serialize(b, out, FilterFactory.Type.SHA);
-        out.close();
-    }
-
-    @Test
-    public void testLegacyBloomFilterRead() throws IOException
-    {
-        // We never write out a new LBF.  Copy the data file from 0.7 instead.
-        // if (EXECUTE_WRITES)
-        //      testLegacyBloomFilterWrite();
-        
-        DataInputStream in = getInput("utils.LegacyBloomFilter.bin");
-        assert FilterFactory.deserialize(in, FilterFactory.Type.SHA, false) != null;
+        assert FilterFactory.deserialize(in, true) != null;
         in.close();
     }
 
