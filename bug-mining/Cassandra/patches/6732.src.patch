diff --git a/modules/accord b/modules/accord
index f9ed591f1b..41aacd31c9 160000
--- a/modules/accord
+++ b/modules/accord
@@ -1 +1 @@
-Subproject commit f9ed591f1b91115351b871640b6318f11dd208af
+Subproject commit 41aacd31c93251043154b5f73239345ee68b7957
diff --git a/src/java/org/apache/cassandra/cql3/Operation.java b/src/java/org/apache/cassandra/cql3/Operation.java
index 728e04b8a0..646c07e574 100644
--- a/src/java/org/apache/cassandra/cql3/Operation.java
+++ b/src/java/org/apache/cassandra/cql3/Operation.java
@@ -89,6 +89,16 @@ public abstract class Operation
         return false;
     }
 
+
+    /**
+     * @return whether the operation requires its timestamp to be known to be executed safely
+     */
+    public boolean requiresTimestamp()
+    {
+        return false;
+    }
+
+
     /**
      * Collects the column specification for the bind variables of this operation.
      *
diff --git a/src/java/org/apache/cassandra/cql3/Operations.java b/src/java/org/apache/cassandra/cql3/Operations.java
index 8de94015a7..305d2baa89 100644
--- a/src/java/org/apache/cassandra/cql3/Operations.java
+++ b/src/java/org/apache/cassandra/cql3/Operations.java
@@ -126,7 +126,7 @@ public final class Operations implements Iterable<Operation>
      */
     public void add(Operation operation)
     {
-        if (isForTxn && operation.requiresRead())
+        if (isForTxn && (operation.requiresRead() || operation.requiresTimestamp()))
         {
             add(operation.column, ReferenceOperation.create(operation));
             return;
diff --git a/src/java/org/apache/cassandra/cql3/terms/Lists.java b/src/java/org/apache/cassandra/cql3/terms/Lists.java
index e82f0f5ac0..01b29c4a69 100644
--- a/src/java/org/apache/cassandra/cql3/terms/Lists.java
+++ b/src/java/org/apache/cassandra/cql3/terms/Lists.java
@@ -333,6 +333,12 @@ public abstract class Lists
             super(column, t);
         }
 
+        @Override
+        public boolean requiresTimestamp()
+        {
+            return true;
+        }
+
         public void execute(DecoratedKey partitionKey, UpdateParameters params) throws InvalidRequestException
         {
             Term.Terminal value = t.bind(params.options);
@@ -424,6 +430,12 @@ public abstract class Lists
             doAppend(value, column, params);
         }
 
+        @Override
+        public boolean requiresTimestamp()
+        {
+            return true;
+        }
+
         static void doAppend(Term.Terminal value, ColumnMetadata column, UpdateParameters params) throws InvalidRequestException
         {
             ListType<?> type = (ListType<?>) column.type;
@@ -483,6 +495,12 @@ public abstract class Lists
             super(column, t);
         }
 
+        @Override
+        public boolean requiresTimestamp()
+        {
+            return true;
+        }
+
         public void execute(DecoratedKey partitionKey, UpdateParameters params) throws InvalidRequestException
         {
             assert column.type.isMultiCell() : "Attempted to prepend to a frozen list";
diff --git a/src/java/org/apache/cassandra/db/compaction/CompactionIterator.java b/src/java/org/apache/cassandra/db/compaction/CompactionIterator.java
index 05a8e60e32..1f3af90431 100644
--- a/src/java/org/apache/cassandra/db/compaction/CompactionIterator.java
+++ b/src/java/org/apache/cassandra/db/compaction/CompactionIterator.java
@@ -98,6 +98,7 @@ import org.apache.cassandra.service.paxos.uncommitted.PaxosRows;
 import org.apache.cassandra.utils.TimeUUID;
 
 import static accord.local.Cleanup.ERASE;
+import static accord.local.Cleanup.Input.PARTIAL;
 import static com.google.common.base.Preconditions.checkState;
 import static java.util.concurrent.TimeUnit.MICROSECONDS;
 import static org.apache.cassandra.config.Config.PaxosStatePurging.legacy;
@@ -123,7 +124,7 @@ import static org.apache.cassandra.service.accord.AccordKeyspace.CommandsForKeys
 public class CompactionIterator extends CompactionInfo.Holder implements UnfilteredPartitionIterator
 {
     private static final Logger logger = LoggerFactory.getLogger(CompactionIterator.class);
-    private static final long UNFILTERED_TO_UPDATE_PROGRESS = 100;
+    private static final long UNFILTERED_TO_UPDATE_PROGRESS = 128;
 
     private final OperationType type;
     private final AbstractCompactionController controller;
@@ -834,7 +835,6 @@ public class CompactionIterator extends CompactionInfo.Holder implements Unfilte
         Object builder = null;
         FlyweightSerializer<Object, Object> serializer = null;
         Object[] firstClustering = null;
-        long maxSeenTimestamp = -1;
         final int userVersion;
         long lastDescriptor = -1;
         int lastOffset = -1;
@@ -861,7 +861,6 @@ public class CompactionIterator extends CompactionInfo.Holder implements Unfilte
             key = AccordKeyspace.JournalColumns.getJournalKey(partition.partitionKey());
             serializer = (AccordJournalValueSerializers.FlyweightSerializer<Object, Object>) key.type.serializer;
             builder = serializer.mergerFor(key);
-            maxSeenTimestamp = -1;
             lastDescriptor = -1;
             lastOffset = -1;
             firstClustering = null;
@@ -912,9 +911,9 @@ public class CompactionIterator extends CompactionInfo.Holder implements Unfilte
 
                 RedundantBefore redundantBefore = redundantBefores.get(key.commandStoreId);
                 DurableBefore durableBefore = durableBefores.get(key.commandStoreId);
-                Cleanup cleanup = commandBuilder.shouldCleanup(agent, redundantBefore, durableBefore, true);
+                Cleanup cleanup = commandBuilder.shouldCleanup(PARTIAL, agent, redundantBefore, durableBefore);
                 if (cleanup == ERASE)
-                    return PartitionUpdate.fullPartitionDelete(metadata(), partition.partitionKey(), maxSeenTimestamp, nowInSec).unfilteredIterator();
+                    return PartitionUpdate.fullPartitionDelete(metadata(), partition.partitionKey(), Long.MAX_VALUE, nowInSec).unfilteredIterator();
 
                 commandBuilder = commandBuilder.maybeCleanup(cleanup);
                 if (commandBuilder != builder)
@@ -949,7 +948,6 @@ public class CompactionIterator extends CompactionInfo.Holder implements Unfilte
         protected void collect(Row row)
         {
             updateProgress();
-            maxSeenTimestamp = row.primaryKeyLivenessInfo().timestamp();
             ByteBuffer record = row.getCell(recordColumn).buffer();
             long descriptor = LongType.instance.compose(row.clustering().getBufferArray()[0]);
             int offset = Int32Type.instance.compose(row.clustering().getBufferArray()[1]);
diff --git a/src/java/org/apache/cassandra/schema/TableId.java b/src/java/org/apache/cassandra/schema/TableId.java
index dbdf6fcc8d..1f4b5a5837 100644
--- a/src/java/org/apache/cassandra/schema/TableId.java
+++ b/src/java/org/apache/cassandra/schema/TableId.java
@@ -27,6 +27,7 @@ import java.util.concurrent.TimeUnit;
 
 import javax.annotation.Nullable;
 
+import accord.utils.Invariants;
 import org.agrona.collections.Hashing;
 import org.apache.cassandra.concurrent.ScheduledExecutors;
 import org.apache.cassandra.tcm.ClusterMetadata;
@@ -43,6 +44,7 @@ import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.ObjectSizes;
 import org.apache.cassandra.utils.Pair;
 import org.apache.cassandra.utils.UUIDGen;
+import org.apache.cassandra.utils.vint.VIntCoding;
 
 import static java.nio.charset.StandardCharsets.UTF_8;
 import static org.apache.cassandra.utils.TimeUUID.Generator.nextTimeUUID;
@@ -206,11 +208,55 @@ public final class TableId implements Comparable<TableId>
         return 16;
     }
 
+    public void serializeCompact(DataOutputPlus out) throws IOException
+    {
+        if (msb == MAGIC && lsb < Long.MAX_VALUE - 1)
+        {
+            out.writeUnsignedVInt(1 + lsb);
+        }
+        else
+        {
+            out.writeByte(0);
+            out.writeLong(msb);
+            out.writeLong(lsb);
+        }
+    }
+
+    public <V> int serializeCompact(V dst, ValueAccessor<V> accessor, int offset)
+    {
+        if (msb == MAGIC && lsb < Long.MAX_VALUE - 1)
+        {
+            return accessor.putUnsignedVInt(dst, offset, 1 + lsb);
+        }
+        else
+        {
+            int position = offset;
+            position += accessor.putByte(dst, position, (byte)0);
+            position += accessor.putLong(dst, position, msb);
+            position += accessor.putLong(dst, position, lsb);
+            return position - offset;
+        }
+    }
+
+    public final int serializedCompactSize()
+    {
+        if (msb == MAGIC && lsb < Long.MAX_VALUE - 1)
+            return VIntCoding.computeUnsignedVIntSize(1 + lsb);
+        return 17;
+    }
+
     public static int staticSerializedSize()
     {
         return 16;
     }
 
+    public static void skipCompact(DataInputPlus in) throws IOException
+    {
+        long compact = in.readUnsignedVInt();
+        if (compact == 0)
+            in.skipBytesFully(16);
+    }
+
     public static TableId deserialize(DataInput in) throws IOException
     {
         return new TableId(in.readLong(), in.readLong());
@@ -221,6 +267,24 @@ public final class TableId implements Comparable<TableId>
         return new TableId(accessor.getLong(src, offset), accessor.getLong(src, offset + TypeSizes.LONG_SIZE));
     }
 
+    public static TableId deserializeCompact(DataInputPlus in) throws IOException
+    {
+        long compact = in.readUnsignedVInt();
+        if (compact > 0)
+            return fromLong(compact - 1);
+        Invariants.checkState(compact == 0);
+        return deserialize(in);
+    }
+
+    public static <V> TableId deserializeCompact(V src, ValueAccessor<V> accessor, int offset)
+    {
+        long compact = accessor.getUnsignedVInt(src, offset);
+        if (compact > 0)
+            return fromLong(compact - 1);
+        Invariants.checkState(compact == 0);
+        return deserialize(src, accessor, offset + 1);
+    }
+
     public TableId intern()
     {
         TableId interned = internCache.putIfAbsent(this, this);
diff --git a/src/java/org/apache/cassandra/service/accord/AccordCommandStore.java b/src/java/org/apache/cassandra/service/accord/AccordCommandStore.java
index 25f09d2347..463812b35f 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordCommandStore.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordCommandStore.java
@@ -56,7 +56,6 @@ import accord.primitives.Participants;
 import accord.primitives.RangeDeps;
 import accord.primitives.Ranges;
 import accord.primitives.RoutableKey;
-import accord.primitives.Status;
 import accord.primitives.Timestamp;
 import accord.primitives.TxnId;
 import accord.utils.Invariants;
@@ -74,6 +73,8 @@ import static accord.api.Journal.Loader;
 import static accord.api.Journal.OnDone;
 import static accord.local.KeyHistory.SYNC;
 import static accord.primitives.Status.Committed;
+import static accord.primitives.Status.PreCommitted;
+import static accord.primitives.Status.Truncated;
 import static accord.utils.Invariants.checkState;
 
 public class AccordCommandStore extends CommandStore
@@ -494,7 +495,7 @@ public class AccordCommandStore extends CommandStore
             Participants<?> keys = null;
             if (CommandsForKey.manages(txnId))
                 keys = command.hasBeen(Committed) ? command.participants().hasTouched() : command.participants().touches();
-            else if (!CommandsForKey.managesExecution(txnId) && command.hasBeen(Status.Stable) && !command.hasBeen(Status.Truncated))
+            else if (!CommandsForKey.managesExecution(txnId) && command.hasBeen(PreCommitted) && !command.hasBeen(Truncated))
                 keys = command.asCommitted().waitingOn.keys;
 
             if (keys != null)
@@ -506,8 +507,7 @@ public class AccordCommandStore extends CommandStore
         @Override
         public void load(Command command, OnDone onDone)
         {
-            store.execute(context(command, SYNC),
-                          safeStore -> loadInternal(command, safeStore))
+            store.execute(context(command, SYNC), safeStore -> loadInternal(command, safeStore))
                  .begin((unused, throwable) -> {
                      if (throwable != null)
                          onDone.failure(throwable);
diff --git a/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java b/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
index 65e19e79b3..62fdf894d7 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordConfigurationService.java
@@ -30,7 +30,6 @@ import javax.annotation.concurrent.GuardedBy;
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.collect.Sets;
 
-import accord.api.Journal;
 import accord.impl.AbstractConfigurationService;
 import accord.local.Node;
 import accord.primitives.Ranges;
@@ -68,7 +67,6 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
 {
     private final AccordSyncPropagator syncPropagator;
     private final DiskStateManager diskStateManager;
-    private final Journal journal;
 
     @GuardedBy("this")
     private EpochDiskState diskState = EpochDiskState.EMPTY;
@@ -148,6 +146,8 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
 
         EpochDiskState markClosed(Ranges ranges, long epoch, EpochDiskState diskState);
 
+        EpochDiskState markRetired(Ranges ranges, long epoch, EpochDiskState diskState);
+
         EpochDiskState truncateTopologyUntil(long epoch, EpochDiskState diskState);
     }
 
@@ -197,6 +197,12 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
             return AccordKeyspace.markClosed(ranges, epoch, diskState);
         }
 
+        @Override
+        public EpochDiskState markRetired(Ranges ranges, long epoch, EpochDiskState diskState)
+        {
+            return AccordKeyspace.markRetired(ranges, epoch, diskState);
+        }
+
         @Override
         public EpochDiskState truncateTopologyUntil(long epoch, EpochDiskState diskState)
         {
@@ -214,17 +220,16 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
         }
     }
 
-    public AccordConfigurationService(Node.Id node, MessageDelivery messagingService, IFailureDetector failureDetector, DiskStateManager diskStateManager, ScheduledExecutorPlus scheduledTasks, Journal journal)
+    public AccordConfigurationService(Node.Id node, MessageDelivery messagingService, IFailureDetector failureDetector, DiskStateManager diskStateManager, ScheduledExecutorPlus scheduledTasks)
     {
         super(node);
         this.syncPropagator = new AccordSyncPropagator(localId, this, messagingService, failureDetector, scheduledTasks, this);
         this.diskStateManager = diskStateManager;
-        this.journal = journal;
     }
 
-    public AccordConfigurationService(Node.Id node, Journal journal)
+    public AccordConfigurationService(Node.Id node)
     {
-        this(node, MessagingService.instance(), FailureDetector.instance, SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks, journal);
+        this(node, MessagingService.instance(), FailureDetector.instance, SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks);
     }
 
     @Override
@@ -251,7 +256,7 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
             remoteSyncComplete.forEach(id -> receiveRemoteSyncComplete(id, epoch));
             // TODO (required): disk doesn't get updated until we see our own notification, so there is an edge case where this instance notified others and fails in the middle, but Apply was already sent!  This could leave partial closed/redudant accross the cluster
             receiveClosed(closed, epoch);
-            receiveRedundant(redundant, epoch);
+            receiveRetired(redundant, epoch);
         });
         state = State.STARTED;
 
@@ -527,13 +532,13 @@ public class AccordConfigurationService extends AbstractConfigurationService<Acc
     }
 
     @Override
-    public void receiveRedundant(Ranges ranges, long epoch)
+    public void receiveRetired(Ranges ranges, long epoch)
     {
         synchronized (this)
         {
-            diskState = diskStateManager.markClosed(ranges, epoch, diskState);
+            diskState = diskStateManager.markRetired(ranges, epoch, diskState);
         }
-        super.receiveRedundant(ranges, epoch);
+        super.receiveRetired(ranges, epoch);
     }
 
     @Override
diff --git a/src/java/org/apache/cassandra/service/accord/AccordFastPathCoordinator.java b/src/java/org/apache/cassandra/service/accord/AccordFastPathCoordinator.java
index a794b91abb..de14638e77 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordFastPathCoordinator.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordFastPathCoordinator.java
@@ -341,5 +341,5 @@ public abstract class AccordFastPathCoordinator implements ChangeListener, Confi
     @Override public void onRemoteSyncComplete(Node.Id node, long epoch) {}
     @Override public void truncateTopologyUntil(long epoch) {}
     @Override public void onEpochClosed(Ranges ranges, long epoch) {}
-    @Override public void onEpochRedundant(Ranges ranges, long epoch) {}
+    @Override public void onEpochRetired(Ranges ranges, long epoch) {}
 }
diff --git a/src/java/org/apache/cassandra/service/accord/AccordJournal.java b/src/java/org/apache/cassandra/service/accord/AccordJournal.java
index b33f1bfe6a..1776c76b2d 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordJournal.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordJournal.java
@@ -32,7 +32,7 @@ import com.google.common.annotations.VisibleForTesting;
 
 import accord.impl.CommandChange;
 import accord.impl.CommandChange.Field;
-import accord.impl.ErasedSafeCommand;
+import accord.impl.RetiredSafeCommand;
 import accord.local.Cleanup;
 import accord.local.Command;
 import accord.local.CommandStore;
@@ -43,6 +43,7 @@ import accord.local.Node;
 import accord.local.RedundantBefore;
 import accord.primitives.Ranges;
 import accord.primitives.SaveStatus;
+import accord.primitives.Status.Durability;
 import accord.primitives.Timestamp;
 import accord.primitives.TxnId;
 import accord.utils.Invariants;
@@ -69,25 +70,26 @@ import org.apache.cassandra.service.accord.AccordJournalValueSerializers.Identit
 import org.apache.cassandra.service.accord.JournalKey.JournalKeySupport;
 import org.apache.cassandra.service.accord.api.AccordAgent;
 import org.apache.cassandra.service.accord.serializers.CommandSerializers;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 import org.apache.cassandra.service.accord.serializers.DepsSerializers;
 import org.apache.cassandra.service.accord.serializers.ResultSerializers;
 import org.apache.cassandra.service.accord.serializers.WaitingOnSerializer;
 import org.apache.cassandra.utils.ExecutorUtils;
-import org.apache.cassandra.utils.Throwables;
 import org.apache.cassandra.utils.concurrent.AsyncPromise;
 
 import static accord.impl.CommandChange.anyFieldChanged;
-import static accord.impl.CommandChange.getFieldChanged;
-import static accord.impl.CommandChange.getFieldIsNull;
+import static accord.impl.CommandChange.isNull;
 import static accord.impl.CommandChange.getFlags;
-import static accord.impl.CommandChange.getWaitingOn;
+import static accord.impl.CommandChange.isChanged;
 import static accord.impl.CommandChange.nextSetField;
-import static accord.impl.CommandChange.setFieldChanged;
+import static accord.impl.CommandChange.setChanged;
 import static accord.impl.CommandChange.setFieldIsNull;
 import static accord.impl.CommandChange.toIterableSetFields;
-import static accord.impl.CommandChange.unsetIterableFields;
+import static accord.impl.CommandChange.unsetIterable;
 import static accord.impl.CommandChange.validateFlags;
-import static accord.primitives.SaveStatus.ErasedOrVestigial;
+import static accord.local.Cleanup.Input.FULL;
+import static accord.primitives.SaveStatus.Erased;
+import static accord.primitives.SaveStatus.Vestigial;
 import static accord.primitives.Status.Truncated;
 import static org.apache.cassandra.service.accord.AccordJournalValueSerializers.DurableBeforeAccumulator;
 
@@ -222,13 +224,14 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
     public Command loadCommand(int commandStoreId, TxnId txnId, RedundantBefore redundantBefore, DurableBefore durableBefore)
     {
         Builder builder = load(commandStoreId, txnId);
-        Cleanup cleanup = builder.shouldCleanup(agent, redundantBefore, durableBefore, false);
+        Cleanup cleanup = builder.shouldCleanup(FULL, agent, redundantBefore, durableBefore);
         switch (cleanup)
         {
-            case EXPUNGE_PARTIAL:
+            case VESTIGIAL:
+                return RetiredSafeCommand.erased(txnId, Vestigial);
             case EXPUNGE:
             case ERASE:
-                return ErasedSafeCommand.erased(txnId, ErasedOrVestigial);
+                return RetiredSafeCommand.erased(txnId, Erased);
         }
         return builder.construct(redundantBefore);
     }
@@ -240,10 +243,10 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
         if (builder.isEmpty())
             return null;
 
-        Cleanup cleanup = builder.shouldCleanup(node.agent(), redundantBefore, durableBefore, false);
+        Cleanup cleanup = builder.shouldCleanup(FULL, node.agent(), redundantBefore, durableBefore);
         switch (cleanup)
         {
-            case EXPUNGE_PARTIAL:
+            case VESTIGIAL:
             case EXPUNGE:
             case ERASE:
                 return null;
@@ -576,19 +579,22 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
             while (iterable != 0)
             {
                 Field field = nextSetField(iterable);
-                if (getFieldIsNull(field, flags))
+                if (isNull(field, flags))
                 {
-                    iterable = unsetIterableFields(field, iterable);
+                    iterable = unsetIterable(field, iterable);
                     continue;
                 }
 
                 switch (field)
                 {
                     case EXECUTE_AT:
-                        CommandSerializers.timestamp.serialize(command.executeAt(), out, userVersion);
+                        ExecuteAtSerializer.serialize(command.txnId(), command.executeAt(), out);
                         break;
                     case EXECUTES_AT_LEAST:
-                        CommandSerializers.timestamp.serialize(command.executesAtLeast(), out, userVersion);
+                        ExecuteAtSerializer.serialize(command.executesAtLeast(), out);
+                        break;
+                    case MIN_UNIQUE_HLC:
+                        out.writeUnsignedVInt(command.waitingOn().minUniqueHlc());
                         break;
                     case SAVE_STATUS:
                         out.writeShort(command.saveStatus().ordinal());
@@ -612,12 +618,8 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
                         DepsSerializers.partialDeps.serialize(command.partialDeps(), out, userVersion);
                         break;
                     case WAITING_ON:
-                        Command.WaitingOn waitingOn = getWaitingOn(command);
-                        long size = WaitingOnSerializer.serializedSize(command.txnId(), waitingOn);
-                        ByteBuffer serialized = WaitingOnSerializer.serialize(command.txnId(), waitingOn);
-                        Invariants.checkState(serialized.remaining() == size);
-                        out.writeInt((int) size);
-                        out.write(serialized);
+                        Command.WaitingOn waitingOn = command.waitingOn();
+                        WaitingOnSerializer.serializeBitSetsOnly(command.txnId(), waitingOn, out);
                         break;
                     case WRITES:
                         CommandSerializers.writes.serialize(command.writes(), out, userVersion);
@@ -629,13 +631,13 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
                         throw new IllegalStateException();
                 }
 
-                iterable = unsetIterableFields(field, iterable);
+                iterable = unsetIterable(field, iterable);
             }
         }
 
         private boolean hasField(Field fields)
         {
-            return !getFieldIsNull(fields, flags);
+            return !isNull(fields, flags);
         }
 
         public boolean hasParticipants()
@@ -696,17 +698,17 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
             while (iterable != 0)
             {
                 Field field = nextSetField(iterable);
-                if (getFieldChanged(field, this.flags) || getFieldIsNull(field, mask))
+                if (isChanged(field, this.flags) || isNull(field, mask))
                 {
-                    if (!getFieldIsNull(field, flags))
+                    if (!isNull(field, flags))
                         skip(field, in, userVersion);
 
-                    iterable = unsetIterableFields(field, iterable);
+                    iterable = unsetIterable(field, iterable);
                     continue;
                 }
-                this.flags = setFieldChanged(field, this.flags);
+                this.flags = setChanged(field, this.flags);
 
-                if (getFieldIsNull(field, flags))
+                if (isNull(field, flags))
                 {
                     this.flags = setFieldIsNull(field, this.flags);
                 }
@@ -715,7 +717,7 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
                     deserialize(field, in, userVersion);
                 }
 
-                iterable = unsetIterableFields(field, iterable);
+                iterable = unsetIterable(field, iterable);
             }
         }
 
@@ -724,16 +726,19 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
             switch (field)
             {
                 case EXECUTE_AT:
-                    executeAt = CommandSerializers.timestamp.deserialize(in, userVersion);
+                    executeAt = ExecuteAtSerializer.deserialize(txnId, in);
                     break;
                 case EXECUTES_AT_LEAST:
-                    executeAtLeast = CommandSerializers.timestamp.deserialize(in, userVersion);
+                    executeAtLeast = ExecuteAtSerializer.deserialize(in);
+                    break;
+                case MIN_UNIQUE_HLC:
+                    minUniqueHlc = in.readUnsignedVInt();
                     break;
                 case SAVE_STATUS:
                     saveStatus = SaveStatus.values()[in.readShort()];
                     break;
                 case DURABILITY:
-                    durability = accord.primitives.Status.Durability.values()[in.readByte()];
+                    durability = Durability.values()[in.readByte()];
                     break;
                 case ACCEPTED:
                     acceptedOrCommitted = CommandSerializers.ballot.deserialize(in, userVersion);
@@ -751,22 +756,7 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
                     partialDeps = DepsSerializers.partialDeps.deserialize(in, userVersion);
                     break;
                 case WAITING_ON:
-                    int size = in.readInt();
-
-                    byte[] waitingOnBytes = new byte[size];
-                    in.readFully(waitingOnBytes);
-                    ByteBuffer buffer = ByteBuffer.wrap(waitingOnBytes);
-                    waitingOn = (localTxnId, deps) -> {
-                        try
-                        {
-                            Invariants.nonNull(deps);
-                            return WaitingOnSerializer.deserialize(localTxnId, deps.keyDeps.keys(), deps.rangeDeps, deps.directKeyDeps, buffer);
-                        }
-                        catch (IOException e)
-                        {
-                            throw Throwables.unchecked(e);
-                        }
-                    };
+                    waitingOn = WaitingOnSerializer.deserializeProvider(txnId, in);
                     break;
                 case WRITES:
                     writes = CommandSerializers.writes.deserialize(in, userVersion);
@@ -787,8 +777,13 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
             switch (field)
             {
                 case EXECUTE_AT:
+                    ExecuteAtSerializer.skip(txnId, in);
+                    break;
                 case EXECUTES_AT_LEAST:
-                    CommandSerializers.timestamp.skip(in, userVersion);
+                    ExecuteAtSerializer.skip(in);
+                    break;
+                case MIN_UNIQUE_HLC:
+                    in.readUnsignedVInt();
                     break;
                 case SAVE_STATUS:
                     in.readShort();
@@ -812,8 +807,7 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
                     DepsSerializers.partialDeps.deserialize(in, userVersion);
                     break;
                 case WAITING_ON:
-                    int size = in.readInt();
-                    in.skipBytesFully(size);
+                    WaitingOnSerializer.skip(txnId, in);
                     break;
                 case WRITES:
                     // TODO (expected): skip
diff --git a/src/java/org/apache/cassandra/service/accord/AccordKeyspace.java b/src/java/org/apache/cassandra/service/accord/AccordKeyspace.java
index f0662b6662..26e19626d1 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordKeyspace.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordKeyspace.java
@@ -152,9 +152,7 @@ public class AccordKeyspace
     public static final String EPOCH_METADATA = "epoch_metadata";
     public static final String JOURNAL_INDEX_NAME = "record";
 
-    public static final Set<String> TABLE_NAMES = ImmutableSet.of(COMMANDS_FOR_KEY,
-                                                                  TOPOLOGIES, EPOCH_METADATA,
-                                                                  JOURNAL);
+    public static final Set<String> TABLE_NAMES = ImmutableSet.of(COMMANDS_FOR_KEY, TOPOLOGIES, EPOCH_METADATA, JOURNAL);
 
     // TODO (desired): implement a custom type so we can get correct sort order
     public static final TupleType TIMESTAMP_TYPE = new TupleType(Lists.newArrayList(LongType.instance, LongType.instance, Int32Type.instance));
@@ -338,11 +336,11 @@ public class AccordKeyspace
             if (current == null)
                 return null;
 
-            CommandsForKey updated = current.withRedundantBeforeAtLeast(redundantBefore.shardRedundantBefore());
+            CommandsForKey updated = current.withRedundantBeforeAtLeast(redundantBefore.gcBefore());
             if (current == updated)
                 return row;
 
-            if (updated.size() == 0)
+            if (updated.isEmpty())
                 return null;
 
             ByteBuffer buffer = Serialize.toBytesWithoutKey(updated);
@@ -374,7 +372,7 @@ public class AccordKeyspace
               "pending_sync_notify set<int>, " + // nodes that need to be told we're synced
               "remote_sync_complete set<int>, " +  // nodes that have told us they're synced
               "closed map<blob, blob>, " +
-              "redundant map<blob, blob>" +
+              "retired map<blob, blob>" +
               ')').build();
 
     public static final TableMetadata EpochMetadata =
@@ -905,11 +903,11 @@ public class AccordKeyspace
     }
 
     // TODO (required): unused
-    public static EpochDiskState markRedundant(Ranges ranges, long epoch, EpochDiskState diskState)
+    public static EpochDiskState markRetired(Ranges ranges, long epoch, EpochDiskState diskState)
     {
         diskState = maybeUpdateMaxEpoch(diskState, epoch);
         String cql = "UPDATE " + ACCORD_KEYSPACE_NAME + '.' + TOPOLOGIES + ' ' +
-                     "SET redundant = redundant + ? WHERE epoch = ?";
+                     "SET retired = retired + ? WHERE epoch = ?";
         executeInternal(cql,
                         KeySerializers.rangesToBlobMap(ranges), epoch);
         flush(Topologies);
diff --git a/src/java/org/apache/cassandra/service/accord/AccordObjectSizes.java b/src/java/org/apache/cassandra/service/accord/AccordObjectSizes.java
index 53059a0075..fdcd4f5391 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordObjectSizes.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordObjectSizes.java
@@ -57,11 +57,12 @@ import accord.primitives.Txn.Kind;
 import accord.primitives.TxnId;
 import accord.primitives.Unseekables;
 import accord.primitives.Writes;
+import accord.utils.ImmutableBitSet;
 import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.service.accord.api.AccordRoutingKey;
 import org.apache.cassandra.service.accord.api.AccordRoutingKey.TokenKey;
 import org.apache.cassandra.service.accord.api.PartitionKey;
-import org.apache.cassandra.service.accord.serializers.WaitingOnSerializer;
+import org.apache.cassandra.service.accord.serializers.ResultSerializers;
 import org.apache.cassandra.service.accord.txn.AccordUpdate;
 import org.apache.cassandra.service.accord.txn.TxnData;
 import org.apache.cassandra.service.accord.txn.TxnQuery;
@@ -265,6 +266,8 @@ public class AccordObjectSizes
 
     public static long results(Result result)
     {
+        if (result == ResultSerializers.APPLIED)
+            return 0;
         return ((TxnResult) result).estimatedSizeOnHeap();
     }
 
@@ -349,7 +352,7 @@ public class AccordObjectSizes
                 case TruncatedApply:
                 case TruncatedApplyWithDeps:
                 case TruncatedApplyWithOutcome:
-                case ErasedOrVestigial:
+                case Vestigial:
                 case Erased:
                     return TRUNCATED;
                 case Invalidated:
@@ -377,16 +380,19 @@ public class AccordObjectSizes
         size += sizeNullable(command.partialDeps(), AccordObjectSizes::dependencies);
         size += sizeNullable(command.acceptedOrCommitted(), AccordObjectSizes::timestamp);
         size += sizeNullable(command.writes(), AccordObjectSizes::writes);
+        size += sizeNullable(command.result(), AccordObjectSizes::results);
+        size += sizeNullable(command.waitingOn(), AccordObjectSizes::waitingOn);
+        return size;
+    }
 
-        if (command.result() instanceof TxnResult)
-            size += sizeNullable(command.result(), AccordObjectSizes::results);
-
-        if (!(command instanceof Command.Committed && command.saveStatus().hasBeen(Status.Stable)))
-            return size;
-
-        Command.Committed committed = command.asCommitted();
-        size += WaitingOnSerializer.serializedSize(committed.txnId(), committed.waitingOn);
-
+    private static long EMPTY_WAITING_ON_SIZE = measure(new WaitingOn(null, null, null, null, null));
+    private static long EMPTY_BIT_SET_SIZE = measure(new ImmutableBitSet(0));
+    private static long waitingOn(WaitingOn waitingOn)
+    {
+        // TODO (desired): this doesn't correctly account for object padding of bitset arrays
+        long size =  EMPTY_WAITING_ON_SIZE + EMPTY_BIT_SET_SIZE + (waitingOn.waitingOn.size() * 8L);
+        if (waitingOn.appliedOrInvalidated != null)
+            size += EMPTY_BIT_SET_SIZE + (waitingOn.appliedOrInvalidated.size() * 8L);
         return size;
     }
 
diff --git a/src/java/org/apache/cassandra/service/accord/AccordSerializers.java b/src/java/org/apache/cassandra/service/accord/AccordSerializers.java
index 557941afd0..412fbd02b8 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordSerializers.java
@@ -166,19 +166,19 @@ public class AccordSerializers
         @Override
         public void serialize(TableMetadata metadata, DataOutputPlus out, int version) throws IOException
         {
-            metadata.id.serialize(out);
+            metadata.id.serializeCompact(out);
         }
 
         @Override
         public TableMetadata deserialize(DataInputPlus in, int version) throws IOException
         {
-            return Schema.instance.getTableMetadata(TableId.deserialize(in));
+            return Schema.instance.getTableMetadata(TableId.deserializeCompact(in));
         }
 
         @Override
         public long serializedSize(TableMetadata metadata, int version)
         {
-            return metadata.id.serializedSize();
+            return metadata.id.serializedCompactSize();
         }
     };
 
diff --git a/src/java/org/apache/cassandra/service/accord/AccordService.java b/src/java/org/apache/cassandra/service/accord/AccordService.java
index 062e605863..ca98fa7a0e 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordService.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordService.java
@@ -334,7 +334,7 @@ public class AccordService implements IAccordService, Shutdownable
         this.dataStore = new AccordDataStore();
         this.configuration = new AccordConfiguration(DatabaseDescriptor.getRawConfig());
         this.journal = new AccordJournal(DatabaseDescriptor.getAccord().journal, agent);
-        this.configService = new AccordConfigurationService(localId, journal);
+        this.configService = new AccordConfigurationService(localId);
         this.fastPathCoordinator = AccordFastPathCoordinator.create(localId, configService);
         this.messageSink = new AccordMessageSink(agent, configService, callbacks);
         this.node = new Node(localId,
@@ -1172,7 +1172,7 @@ public class AccordService implements IAccordService, Shutdownable
             if (!notification.closed.isEmpty())
                 configService.receiveClosed(notification.closed, notification.epoch);
             if (!notification.redundant.isEmpty())
-                configService.receiveRedundant(notification.redundant, notification.epoch);
+                configService.receiveRetired(notification.redundant, notification.epoch);
         });
         sink.respond(Ok, message);
     }
diff --git a/src/java/org/apache/cassandra/service/accord/CommandsForRanges.java b/src/java/org/apache/cassandra/service/accord/CommandsForRanges.java
index 9a42e8cc93..14326aefb3 100644
--- a/src/java/org/apache/cassandra/service/accord/CommandsForRanges.java
+++ b/src/java/org/apache/cassandra/service/accord/CommandsForRanges.java
@@ -45,7 +45,7 @@ import org.apache.cassandra.service.accord.api.AccordRoutingKey;
 import static accord.local.CommandSummaries.SummaryStatus.NOT_DIRECTLY_WITNESSED;
 
 // TODO (required): move to accord-core, merge with existing logic there
-public class CommandsForRanges extends TreeMap<Timestamp, Summary> implements CommandSummaries.Snapshot
+public class CommandsForRanges extends TreeMap<Timestamp, Summary> implements CommandSummaries.ByTxnIdSnapshot
 {
     public CommandsForRanges(Map<? extends Timestamp, ? extends Summary> m)
     {
diff --git a/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java b/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java
index 3398a6d9f8..a44c76cc66 100644
--- a/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java
+++ b/src/java/org/apache/cassandra/service/accord/api/AccordAgent.java
@@ -128,7 +128,7 @@ public class AccordAgent implements Agent
     }
 
     @Override
-    public void onHandledException(Throwable t, String context)
+    public void onCaughtException(Throwable t, String context)
     {
         logger.warn(context, t);
         JVMStabilityInspector.uncaughtException(Thread.currentThread(), t);
@@ -203,7 +203,9 @@ public class AccordAgent implements Agent
 
         startTime = nonClashingStartTime(startTime, shard == null ? null : shard.nodes, node.id(), oneSecond, random);
         long nowMicros = MILLISECONDS.toMicros(Clock.Global.currentTimeMillis());
-        return units.convert(Math.max(1, startTime - nowMicros), MICROSECONDS);
+        long delayMicros = Math.max(1, startTime - nowMicros);
+        Invariants.checkState(delayMicros < TimeUnit.HOURS.toMicros(1L));
+        return units.convert(delayMicros, MICROSECONDS);
     }
 
     @VisibleForTesting
diff --git a/src/java/org/apache/cassandra/service/accord/api/AccordRoutingKey.java b/src/java/org/apache/cassandra/service/accord/api/AccordRoutingKey.java
index ec89d77058..9088faccc3 100644
--- a/src/java/org/apache/cassandra/service/accord/api/AccordRoutingKey.java
+++ b/src/java/org/apache/cassandra/service/accord/api/AccordRoutingKey.java
@@ -208,7 +208,7 @@ public abstract class AccordRoutingKey extends AccordRoutableKey implements Rout
             @Override
             public void serialize(SentinelKey key, DataOutputPlus out, int version) throws IOException
             {
-                key.table.serialize(out);
+                key.table.serializeCompact(out);
                 out.writeBoolean(key.isMinSentinel);
                 out.writeBoolean(key.isMinMinSentinel);
             }
@@ -216,13 +216,14 @@ public abstract class AccordRoutingKey extends AccordRoutableKey implements Rout
             @Override
             public void skip(DataInputPlus in, int version) throws IOException
             {
-                in.skipBytesFully(TableId.staticSerializedSize() + 1);
+                TableId.skipCompact(in);
+                in.skipBytesFully(2);
             }
 
             @Override
             public SentinelKey deserialize(DataInputPlus in, int version) throws IOException
             {
-                TableId table = TableId.deserialize(in);
+                TableId table = TableId.deserializeCompact(in);
                 boolean isMin = in.readBoolean();
                 boolean isMinMin = in.readBoolean();
                 return new SentinelKey(table, isMin, isMinMin);
@@ -231,7 +232,7 @@ public abstract class AccordRoutingKey extends AccordRoutableKey implements Rout
             @Override
             public long serializedSize(SentinelKey key, int version)
             {
-                return key.table().serializedSize() + TypeSizes.BOOL_SIZE + TypeSizes.BOOL_SIZE;
+                return key.table().serializedCompactSize() + TypeSizes.BOOL_SIZE + TypeSizes.BOOL_SIZE;
             }
         };
 
@@ -255,14 +256,14 @@ public abstract class AccordRoutingKey extends AccordRoutableKey implements Rout
         @Override
         public void serialize(T key, DataOutputPlus out, int version) throws IOException
         {
-            key.table.serialize(out);
+            key.table.serializeCompact(out);
             Token.compactSerializer.serialize(key.token, out, version);
         }
 
         @Override
         public void skip(DataInputPlus in, int version) throws IOException
         {
-            in.skipBytesFully(TableId.staticSerializedSize());
+            TableId.skipCompact(in);
             // TODO (expected): should we be using the TableId partitioner here?
             Token.compactSerializer.skip(in, getPartitioner(), version);
         }
@@ -270,24 +271,24 @@ public abstract class AccordRoutingKey extends AccordRoutableKey implements Rout
         @Override
         public T deserialize(DataInputPlus in, int version) throws IOException
         {
-            TableId table = TableId.deserialize(in).intern();
+            TableId table = TableId.deserializeCompact(in).intern();
             Token token = Token.compactSerializer.deserialize(in, getPartitioner(), version);
             return factory.apply(table, token);
         }
 
         public T fromBytes(ByteBuffer bytes, IPartitioner partitioner)
         {
-            TableId tableId = TableId.deserialize(bytes, ByteBufferAccessor.instance, 0).intern();
-            bytes.position(tableId.serializedSize());
+            TableId tableId = TableId.deserializeCompact(bytes, ByteBufferAccessor.instance, 0).intern();
+            bytes.position(tableId.serializedCompactSize());
             Token token = Token.compactSerializer.deserialize(bytes, partitioner);
             return factory.apply(tableId, token);
         }
 
         public ByteBuffer toBytes(T tokenKey)
         {
-            int size = (int) (tokenKey.table.serializedSize() + Token.compactSerializer.serializedSize(tokenKey.token));
+            int size = (int) (tokenKey.table.serializedCompactSize() + Token.compactSerializer.serializedSize(tokenKey.token));
             ByteBuffer out = ByteBuffer.allocate(size);
-            int position = tokenKey.table.serialize(out, ByteBufferAccessor.instance, 0);
+            int position = tokenKey.table.serializeCompact(out, ByteBufferAccessor.instance, 0);
             out.position(position);
             Token.compactSerializer.serialize(tokenKey.token, out);
             out.flip();
@@ -297,7 +298,7 @@ public abstract class AccordRoutingKey extends AccordRoutableKey implements Rout
         @Override
         public long serializedSize(TokenKey key, int version)
         {
-            return key.table.serializedSize() + Token.compactSerializer.serializedSize(key.token(), version);
+            return key.table.serializedCompactSize() + Token.compactSerializer.serializedSize(key.token(), version);
         }
     }
 
diff --git a/src/java/org/apache/cassandra/service/accord/api/PartitionKey.java b/src/java/org/apache/cassandra/service/accord/api/PartitionKey.java
index a01ae38284..744df8b11c 100644
--- a/src/java/org/apache/cassandra/service/accord/api/PartitionKey.java
+++ b/src/java/org/apache/cassandra/service/accord/api/PartitionKey.java
@@ -126,14 +126,14 @@ public final class PartitionKey extends AccordRoutableKey implements Key
         @Override
         public void serialize(PartitionKey key, DataOutputPlus out, int version) throws IOException
         {
-            key.table().serialize(out);
+            key.table().serializeCompact(out);
             ByteBufferUtil.writeWithShortLength(key.partitionKey().getKey(), out);
         }
 
         public <V> int serialize(PartitionKey key, V dst, ValueAccessor<V> accessor, int offset)
         {
             int position = offset;
-            position += key.table().serialize(dst, accessor, position);
+            position += key.table().serializeCompact(dst, accessor, position);
             ByteBuffer bytes = key.partitionKey().getKey();
             int numBytes = ByteBufferAccessor.instance.size(bytes);
             Preconditions.checkState(numBytes <= Short.MAX_VALUE);
@@ -146,14 +146,14 @@ public final class PartitionKey extends AccordRoutableKey implements Key
         @Override
         public void skip(DataInputPlus in, int version) throws IOException
         {
-            in.skipBytesFully(TableId.staticSerializedSize());
+            TableId.skipCompact(in);
             ByteBufferUtil.skipShortLength(in);
         }
 
         @Override
         public PartitionKey deserialize(DataInputPlus in, int version) throws IOException
         {
-            TableId tableId = TableId.deserialize(in).intern();
+            TableId tableId = TableId.deserializeCompact(in).intern();
             IPartitioner partitioner = Schema.instance.getExistingTablePartitioner(tableId);
             DecoratedKey key = partitioner.decorateKey(ByteBufferUtil.readWithShortLength(in));
             return new PartitionKey(tableId, key);
@@ -161,8 +161,8 @@ public final class PartitionKey extends AccordRoutableKey implements Key
 
         public <V> PartitionKey deserialize(V src, ValueAccessor<V> accessor, int offset) throws IOException
         {
-            TableId tableId = TableId.deserialize(src, accessor, offset).intern();
-            offset += tableId.serializedSize();
+            TableId tableId = TableId.deserializeCompact(src, accessor, offset).intern();
+            offset += tableId.serializedCompactSize();
             TableMetadata metadata = Schema.instance.getTableMetadata(tableId);
             int numBytes = accessor.getShort(src, offset);
             offset += TypeSizes.SHORT_SIZE;
@@ -180,7 +180,7 @@ public final class PartitionKey extends AccordRoutableKey implements Key
 
         public long serializedSize(PartitionKey key)
         {
-            return key.table().serializedSize() + ByteBufferUtil.serializedSizeWithShortLength(key.partitionKey().getKey());
+            return key.table().serializedCompactSize() + ByteBufferUtil.serializedSizeWithShortLength(key.partitionKey().getKey());
         }
     }
 }
diff --git a/src/java/org/apache/cassandra/service/accord/interop/AccordInteropRead.java b/src/java/org/apache/cassandra/service/accord/interop/AccordInteropRead.java
index 9afa576063..67d1ecc72b 100644
--- a/src/java/org/apache/cassandra/service/accord/interop/AccordInteropRead.java
+++ b/src/java/org/apache/cassandra/service/accord/interop/AccordInteropRead.java
@@ -182,9 +182,9 @@ public class AccordInteropRead extends ReadData
     }
 
     @Override
-    protected ReadOk constructReadOk(Ranges unavailable, Data data)
+    protected ReadOk constructReadOk(Ranges unavailable, Data data, long uniqueHlc)
     {
-        return new InteropReadOk(unavailable, data);
+        return new InteropReadOk(unavailable, data, uniqueHlc);
     }
 
     @Override
@@ -204,9 +204,9 @@ public class AccordInteropRead extends ReadData
 
     private static class InteropReadOk extends ReadOk
     {
-        public InteropReadOk(@Nullable Ranges unavailable, @Nullable Data data)
+        public InteropReadOk(@Nullable Ranges unavailable, @Nullable Data data, long uniqueHlc)
         {
-            super(unavailable, data);
+            super(unavailable, data, uniqueHlc);
         }
 
         @Override
diff --git a/src/java/org/apache/cassandra/service/accord/interop/AccordInteropReadRepair.java b/src/java/org/apache/cassandra/service/accord/interop/AccordInteropReadRepair.java
index fdf8e3daf3..81f652351f 100644
--- a/src/java/org/apache/cassandra/service/accord/interop/AccordInteropReadRepair.java
+++ b/src/java/org/apache/cassandra/service/accord/interop/AccordInteropReadRepair.java
@@ -156,9 +156,9 @@ public class AccordInteropReadRepair extends ReadData
     }
 
     @Override
-    protected ReadOk constructReadOk(Ranges unavailable, Data data)
+    protected ReadOk constructReadOk(Ranges unavailable, Data data, long uniqueHlc)
     {
-        return new InteropReadRepairOk(unavailable, data);
+        return new InteropReadRepairOk(unavailable, data, uniqueHlc);
     }
 
     @Override
@@ -169,9 +169,9 @@ public class AccordInteropReadRepair extends ReadData
 
     private static class InteropReadRepairOk extends ReadOk
     {
-        public InteropReadRepairOk(@Nullable Ranges unavailable, @Nullable Data data)
+        public InteropReadRepairOk(@Nullable Ranges unavailable, @Nullable Data data, long uniqueHlc)
         {
-            super(unavailable, data);
+            super(unavailable, data, uniqueHlc);
         }
 
         @Override
diff --git a/src/java/org/apache/cassandra/service/accord/interop/AccordInteropStableThenRead.java b/src/java/org/apache/cassandra/service/accord/interop/AccordInteropStableThenRead.java
index 2093a969ce..256fc64fc4 100644
--- a/src/java/org/apache/cassandra/service/accord/interop/AccordInteropStableThenRead.java
+++ b/src/java/org/apache/cassandra/service/accord/interop/AccordInteropStableThenRead.java
@@ -46,6 +46,7 @@ import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.service.accord.AccordMessageSink.AccordMessageType;
 import org.apache.cassandra.service.accord.serializers.CommandSerializers;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 import org.apache.cassandra.service.accord.serializers.CommitSerializers;
 import org.apache.cassandra.service.accord.serializers.DepsSerializers;
 import org.apache.cassandra.service.accord.serializers.KeySerializers;
@@ -70,7 +71,7 @@ public class AccordInteropStableThenRead extends AccordInteropRead
             KeySerializers.participants.serialize(read.scope, out, version);
             CommitSerializers.kind.serialize(read.kind, out, version);
             out.writeUnsignedVInt(read.minEpoch);
-            CommandSerializers.timestamp.serialize(read.executeAt, out, version);
+            ExecuteAtSerializer.serialize(read.txnId, read.executeAt, out);
             if (read.kind.withTxn != NoTxn)
                 CommandSerializers.nullablePartialTxn.serialize(read.partialTxn, out, version);
             if (read.kind.withDeps == HasDeps)
@@ -87,7 +88,7 @@ public class AccordInteropStableThenRead extends AccordInteropRead
             Participants<?> scope = KeySerializers.participants.deserialize(in, version);
             Commit.Kind kind = CommitSerializers.kind.deserialize(in, version);
             long minEpoch = in.readUnsignedVInt();
-            Timestamp executeAt = CommandSerializers.timestamp.deserialize(in, version);
+            Timestamp executeAt = ExecuteAtSerializer.deserialize(txnId, in);
             PartialTxn partialTxn = kind.withTxn == NoTxn ? null : CommandSerializers.nullablePartialTxn.deserialize(in, version);
             PartialDeps partialDeps = kind.withDeps == NoDeps ? null : DepsSerializers.partialDeps.deserialize(in, version);
             FullRoute < ?> route = kind.withTxn == HasTxn ? KeySerializers.fullRoute.deserialize(in, version) : null;
@@ -102,7 +103,7 @@ public class AccordInteropStableThenRead extends AccordInteropRead
                    + KeySerializers.participants.serializedSize(read.scope, version)
                    + CommitSerializers.kind.serializedSize(read.kind, version)
                    + TypeSizes.sizeofUnsignedVInt(read.minEpoch)
-                   + CommandSerializers.timestamp.serializedSize(read.executeAt, version)
+                   + ExecuteAtSerializer.serializedSize(read.txnId, read.executeAt)
                    + (read.kind.withTxn == NoTxn ? 0 : CommandSerializers.nullablePartialTxn.serializedSize(read.partialTxn, version))
                    + (read.kind.withDeps != HasDeps ? 0 : DepsSerializers.partialDeps.serializedSize(read.partialDeps, version))
                    + (read.kind.withTxn != HasTxn ? 0 : KeySerializers.fullRoute.serializedSize(read.route, version))
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/AcceptSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/AcceptSerializers.java
index bdaf24be8c..79a0911e8e 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/AcceptSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/AcceptSerializers.java
@@ -31,6 +31,7 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 
 import static accord.messages.Accept.SerializerSupport.create;
 import static accord.utils.Invariants.illegalState;
@@ -48,7 +49,7 @@ public class AcceptSerializers
         {
             kindSerializer.serialize(accept.kind, out, version);
             CommandSerializers.ballot.serialize(accept.ballot, out, version);
-            CommandSerializers.timestamp.serialize(accept.executeAt, out, version);
+            ExecuteAtSerializer.serialize(accept.txnId, accept.executeAt, out);
             DepsSerializers.partialDeps.serialize(accept.partialDeps, out, version);
         }
 
@@ -58,7 +59,7 @@ public class AcceptSerializers
             return create(txnId, scope, waitForEpoch, minEpoch,
                           kindSerializer.deserialize(in, version),
                           CommandSerializers.ballot.deserialize(in, version),
-                          CommandSerializers.timestamp.deserialize(in, version),
+                          ExecuteAtSerializer.deserialize(txnId, in),
                           DepsSerializers.partialDeps.deserialize(in, version));
         }
 
@@ -67,7 +68,7 @@ public class AcceptSerializers
         {
             return kindSerializer.serializedSize(accept.kind, version)
                    + CommandSerializers.ballot.serializedSize(accept.ballot, version)
-                   + CommandSerializers.timestamp.serializedSize(accept.executeAt, version)
+                   + ExecuteAtSerializer.serializedSize(accept.txnId, accept.executeAt)
                    + DepsSerializers.partialDeps.serializedSize(accept.partialDeps, version);
         }
     };
@@ -135,7 +136,7 @@ public class AcceptSerializers
                     if (reply.supersededBy != null)
                         CommandSerializers.ballot.serialize(reply.supersededBy, out, version);
                     if (reply.committedExecuteAt != null)
-                        CommandSerializers.timestamp.serialize(reply.committedExecuteAt, out, version);
+                        ExecuteAtSerializer.serialize(reply.committedExecuteAt, out);
             }
         }
 
@@ -154,7 +155,7 @@ public class AcceptSerializers
                     return new AcceptReply(CommandSerializers.ballot.deserialize(in, version));
                 case 4:
                     Ballot supersededBy = (flags & 0x8) == 0 ? null : CommandSerializers.ballot.deserialize(in, version);
-                    Timestamp committedExecuteAt = (flags & 0x10) == 0 ? null : CommandSerializers.timestamp.deserialize(in, version);
+                    Timestamp committedExecuteAt = (flags & 0x10) == 0 ? null : ExecuteAtSerializer.deserialize(in);
                     return new AcceptReply(supersededBy, committedExecuteAt);
             }
         }
@@ -178,7 +179,7 @@ public class AcceptSerializers
                     break;
                 case Redundant:
                     if (reply.supersededBy != null) size += CommandSerializers.ballot.serializedSize(reply.supersededBy, version);
-                    if (reply.committedExecuteAt != null) size += CommandSerializers.timestamp.serializedSize(reply.committedExecuteAt, version);
+                    if (reply.committedExecuteAt != null) size += ExecuteAtSerializer.serializedSize(reply.committedExecuteAt);
             }
             return size;
         }
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/ApplySerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/ApplySerializers.java
index 6189e9c099..4a554a3364 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/ApplySerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/ApplySerializers.java
@@ -34,6 +34,7 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 
 import static accord.primitives.Txn.Kind.Write;
 
@@ -66,7 +67,7 @@ public class ApplySerializers
         {
             out.writeVInt(apply.minEpoch - apply.waitForEpoch);
             kind.serialize(apply.kind, out, version);
-            CommandSerializers.timestamp.serialize(apply.executeAt, out, version);
+            ExecuteAtSerializer.serialize(apply.txnId, apply.executeAt, out);
             DepsSerializers.partialDeps.serialize(apply.deps, out, version);
             CommandSerializers.nullablePartialTxn.serialize(apply.txn, out, version);
             KeySerializers.nullableFullRoute.serialize(apply.fullRoute, out, version);
@@ -82,7 +83,7 @@ public class ApplySerializers
         {
             return deserializeApply(txnId, scope, waitForEpoch + in.readVInt(), waitForEpoch,
                                     kind.deserialize(in, version),
-                                    CommandSerializers.timestamp.deserialize(in, version),
+                                    ExecuteAtSerializer.deserialize(txnId, in),
                                     DepsSerializers.partialDeps.deserialize(in, version),
                                     CommandSerializers.nullablePartialTxn.deserialize(in, version),
                                     KeySerializers.nullableFullRoute.deserialize(in, version),
@@ -95,7 +96,7 @@ public class ApplySerializers
         {
             return   TypeSizes.sizeofVInt(apply.minEpoch - apply.waitForEpoch)
                    + kind.serializedSize(apply.kind, version)
-                   + CommandSerializers.timestamp.serializedSize(apply.executeAt, version)
+                   + ExecuteAtSerializer.serializedSize(apply.txnId, apply.executeAt)
                    + DepsSerializers.partialDeps.serializedSize(apply.deps, version)
                    + CommandSerializers.nullablePartialTxn.serializedSize(apply.txn, version)
                    + KeySerializers.nullableFullRoute.serializedSize(apply.fullRoute, version)
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/CalculateDepsSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/CalculateDepsSerializers.java
index de13575e04..ab9f596374 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/CalculateDepsSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/CalculateDepsSerializers.java
@@ -28,6 +28,7 @@ import accord.primitives.TxnId;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 
 public class CalculateDepsSerializers
 {
@@ -36,20 +37,20 @@ public class CalculateDepsSerializers
         @Override
         public void serializeBody(CalculateDeps msg, DataOutputPlus out, int version) throws IOException
         {
-            CommandSerializers.timestamp.serialize(msg.executeAt, out, version);
+            ExecuteAtSerializer.serialize(msg.executeAt, out);
         }
 
         @Override
         public CalculateDeps deserializeBody(DataInputPlus in, int version, TxnId txnId, Route<?> scope, long waitForEpoch, long minEpoch) throws IOException
         {
-            Timestamp executeAt = CommandSerializers.timestamp.deserialize(in, version);
+            Timestamp executeAt = ExecuteAtSerializer.deserialize(in);
             return CalculateDeps.SerializationSupport.create(txnId, scope, waitForEpoch, minEpoch, executeAt);
         }
 
         @Override
         public long serializedBodySize(CalculateDeps msg, int version)
         {
-            return CommandSerializers.timestamp.serializedSize(msg.executeAt, version);
+            return ExecuteAtSerializer.serializedSize(msg.executeAt);
         }
     };
 
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/CheckStatusSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/CheckStatusSerializers.java
index d81927893d..2905ec6370 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/CheckStatusSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/CheckStatusSerializers.java
@@ -45,6 +45,7 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 
 import static accord.messages.CheckStatus.SerializationSupport.createOk;
 import static org.apache.cassandra.service.accord.serializers.CommandSerializers.known;
@@ -174,7 +175,7 @@ public class CheckStatusSerializers
             CommandSerializers.ballot.serialize(ok.maxPromised, out, version);
             CommandSerializers.ballot.serialize(ok.maxAcceptedOrCommitted, out, version);
             CommandSerializers.ballot.serialize(ok.acceptedOrCommitted, out, version);
-            CommandSerializers.nullableTimestamp.serialize(ok.executeAt, out, version);
+            ExecuteAtSerializer.serializeNullable(ok.executeAt, out);
             out.writeBoolean(ok.isCoordinating);
             CommandSerializers.durability.serialize(ok.durability, out, version);
             KeySerializers.nullableRoute.serialize(ok.route, out, version);
@@ -207,7 +208,7 @@ public class CheckStatusSerializers
                     Ballot maxPromised = CommandSerializers.ballot.deserialize(in, version);
                     Ballot maxAcceptedOrCommitted = CommandSerializers.ballot.deserialize(in, version);
                     Ballot acceptedOrCommitted = CommandSerializers.ballot.deserialize(in, version);
-                    Timestamp executeAt = CommandSerializers.nullableTimestamp.deserialize(in, version);
+                    Timestamp executeAt = ExecuteAtSerializer.deserializeNullable(in);
                     boolean isCoordinating = in.readBoolean();
                     Durability durability = CommandSerializers.durability.deserialize(in, version);
                     Route<?> route = KeySerializers.nullableRoute.deserialize(in, version);
@@ -246,7 +247,7 @@ public class CheckStatusSerializers
             size += CommandSerializers.ballot.serializedSize(ok.maxPromised, version);
             size += CommandSerializers.ballot.serializedSize(ok.maxAcceptedOrCommitted, version);
             size += CommandSerializers.ballot.serializedSize(ok.acceptedOrCommitted, version);
-            size += CommandSerializers.nullableTimestamp.serializedSize(ok.executeAt, version);
+            size += ExecuteAtSerializer.serializedNullableSize(ok.executeAt);
             size += TypeSizes.BOOL_SIZE;
             size += CommandSerializers.durability.serializedSize(ok.durability, version);
             size += KeySerializers.nullableRoute.serializedSize(ok.route, version);
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/CommandSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/CommandSerializers.java
index 32bf98a65f..436849e290 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/CommandSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/CommandSerializers.java
@@ -46,9 +46,11 @@ import accord.primitives.Seekables;
 import accord.primitives.Status;
 import accord.primitives.Status.Durability;
 import accord.primitives.Timestamp;
+import accord.primitives.TimestampWithUniqueHlc;
 import accord.primitives.Txn;
 import accord.primitives.TxnId;
 import accord.primitives.Writes;
+import accord.utils.Invariants;
 import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.db.marshal.ValueAccessor;
 import org.apache.cassandra.io.IVersionedSerializer;
@@ -78,6 +80,217 @@ public class CommandSerializers
     public static final EnumSerializer<Txn.Kind> kind = new EnumSerializer<>(Txn.Kind.class);
     public static final StoreParticipantsSerializer participants = new StoreParticipantsSerializer();
 
+    public static class ExecuteAtSerializer
+    {
+        private static final int IS_TIMESTAMP = 1;
+        private static final int HAS_UNIQUE_HLC = 2;
+        private static final int HAS_EPOCH = 4;
+
+        public static Timestamp deserialize(TxnId txnId, DataInputPlus in) throws IOException
+        {
+            int flags = in.readUnsignedVInt32();
+            if ((flags & 1) == 0)
+                return txnId.addFlags(flags >>> 1);
+
+            long epoch = txnId.epoch();
+            if((flags & HAS_EPOCH) != 0)
+                epoch += in.readUnsignedVInt();
+
+            long hlc = txnId.hlc() + in.readUnsignedVInt();
+            Node.Id node = new Node.Id(in.readUnsignedVInt32());
+            if ((flags & HAS_UNIQUE_HLC) == 0)
+                return Timestamp.fromValues(epoch, hlc, flags >>> 3, node);
+            return new TimestampWithUniqueHlc(epoch, hlc, hlc + in.readUnsignedVInt(), flags >>> 3, node);
+        }
+
+        public static void skip(TxnId txnId, DataInputPlus in) throws IOException
+        {
+            int flags = in.readUnsignedVInt32();
+            if ((flags & 1) != 0)
+            {
+                if ((flags & HAS_EPOCH) != 0)
+                    in.readUnsignedVInt();
+                in.readUnsignedVInt();
+                in.readUnsignedVInt32();
+                if ((flags & HAS_UNIQUE_HLC) != 0)
+                    in.readUnsignedVInt();
+            }
+        }
+
+        public static void serialize(TxnId txnId, Timestamp executeAt, DataOutputPlus out) throws IOException
+        {
+            int flags = flags(txnId, executeAt);
+            out.writeUnsignedVInt32(flags);
+            if ((flags & 1) != 0)
+            {
+                if ((flags & HAS_EPOCH) != 0)
+                    out.writeUnsignedVInt(executeAt.epoch() - txnId.epoch());
+                out.writeUnsignedVInt(executeAt.hlc() - txnId.hlc());
+                out.writeUnsignedVInt32(executeAt.node.id);
+                if ((flags & HAS_UNIQUE_HLC) != 0)
+                    out.writeUnsignedVInt(executeAt.uniqueHlc() - executeAt.hlc());
+            }
+        }
+
+        private static int flags(TxnId txnId, Timestamp executeAt)
+        {
+            if (executeAt.getClass() == TxnId.class)
+                return (executeAt.flags() ^ txnId.flags()) << 1;
+
+            int flags = executeAt.flags() << 3;
+            if (executeAt.epoch() != txnId.epoch())
+                flags |= HAS_EPOCH;
+            if (executeAt.hasDistinctHlcAndUniqueHlc())
+                flags |= HAS_UNIQUE_HLC;
+            return flags | 1;
+        }
+
+        public static long serializedSize(TxnId txnId, Timestamp executeAt)
+        {
+            int flags = flags(txnId, executeAt);
+            long size = TypeSizes.sizeofUnsignedVInt(flags);
+            if ((flags & 1) != 0)
+            {
+                if ((flags & HAS_EPOCH) != 0)
+                    size += TypeSizes.sizeofUnsignedVInt(executeAt.epoch() - txnId.epoch());
+                size += TypeSizes.sizeofUnsignedVInt(executeAt.hlc() - txnId.hlc());
+                size += TypeSizes.sizeofUnsignedVInt(executeAt.node.id);
+                if ((flags & HAS_UNIQUE_HLC) != 0)
+                    size += TypeSizes.sizeofUnsignedVInt(executeAt.uniqueHlc() - executeAt.hlc());
+            }
+            return size;
+        }
+
+        public static Timestamp deserialize(DataInputPlus in) throws IOException
+        {
+            return deserialize(in, false);
+        }
+
+        public static Timestamp deserializeNullable(DataInputPlus in) throws IOException
+        {
+            return deserialize(in, true);
+        }
+
+        private static Timestamp deserialize(DataInputPlus in, boolean nullable) throws IOException
+        {
+            int flags = in.readUnsignedVInt32();
+            if (nullable)
+            {
+                if ((flags & 1) != 0) return null;
+                flags >>>= 1;
+            }
+            long epoch = in.readUnsignedVInt();
+            long hlc = in.readUnsignedVInt();
+            Node.Id node = new Node.Id(in.readUnsignedVInt32());
+            if ((flags & HAS_UNIQUE_HLC) == 0)
+            {
+                if ((flags & IS_TIMESTAMP) == 0)
+                    return TxnId.fromValues(epoch, hlc, flags >>> 2, node);
+                return Timestamp.fromValues(epoch, hlc, flags >>> 2, node);
+            }
+            return new TimestampWithUniqueHlc(epoch, hlc, hlc + in.readUnsignedVInt(), flags >>> 2, node);
+        }
+
+        public static void skip(DataInputPlus in) throws IOException
+        {
+            skip(in, false);
+        }
+
+        public static void skipNullable(DataInputPlus in) throws IOException
+        {
+            skip(in, true);
+        }
+
+        private static void skip(DataInputPlus in, boolean nullable) throws IOException
+        {
+            int flags = in.readUnsignedVInt32();
+            if (nullable)
+            {
+                if ((flags & 1) != 0)
+                    return;
+                flags >>= 1;
+            }
+            in.readUnsignedVInt();
+            in.readUnsignedVInt();
+            in.readUnsignedVInt32();
+            if ((flags & HAS_UNIQUE_HLC) != 0)
+                in.readUnsignedVInt();
+        }
+
+        public static void serialize(Timestamp executeAt, DataOutputPlus out) throws IOException
+        {
+            serialize(executeAt, out, false);
+        }
+
+        public static void serializeNullable(Timestamp executeAt, DataOutputPlus out) throws IOException
+        {
+            serialize(executeAt, out, true);
+        }
+
+        private static void serialize(Timestamp executeAt, DataOutputPlus out, boolean nullable) throws IOException
+        {
+            int flags = flags(executeAt, nullable);
+            out.writeUnsignedVInt32(flags);
+            if (executeAt == null)
+            {
+                Invariants.checkState(nullable);
+            }
+            else
+            {
+                out.writeUnsignedVInt(executeAt.epoch());
+                out.writeUnsignedVInt(executeAt.hlc());
+                out.writeUnsignedVInt32(executeAt.node.id);
+                if ((flags & HAS_UNIQUE_HLC) != 0)
+                    out.writeUnsignedVInt(executeAt.uniqueHlc() - executeAt.hlc());
+            }
+        }
+
+        public static long serializedSize(Timestamp executeAt)
+        {
+            return serializedSize(executeAt, false);
+        }
+
+        public static long serializedNullableSize(Timestamp executeAt)
+        {
+            return serializedSize(executeAt, true);
+        }
+
+        private static long serializedSize(Timestamp executeAt, boolean nullable)
+        {
+            int flags = flags(executeAt, nullable);
+            long size = TypeSizes.sizeofUnsignedVInt(flags);
+            if (executeAt == null)
+            {
+                Invariants.checkState(nullable);
+                return size;
+            }
+            size += TypeSizes.sizeofUnsignedVInt(executeAt.epoch());
+            size += TypeSizes.sizeofUnsignedVInt(executeAt.hlc());
+            size += TypeSizes.sizeofUnsignedVInt(executeAt.node.id);
+            if ((flags & HAS_UNIQUE_HLC) != 0)
+                size += TypeSizes.sizeofUnsignedVInt(executeAt.uniqueHlc() - executeAt.hlc());
+            return size;
+        }
+
+        private static int flags(Timestamp executeAt, boolean nullable)
+        {
+            if (executeAt == null)
+            {
+                Invariants.checkState(nullable);
+                return 1;
+            }
+
+            int flags = executeAt.flags() << 2;
+            // for compatibility with other serialized form
+            flags |= (executeAt.getClass() == TxnId.class) ? 0 : 1;
+            if (executeAt.hasDistinctHlcAndUniqueHlc())
+                flags |= HAS_UNIQUE_HLC;
+            if (nullable)
+                flags <<= 1;
+            return flags;
+        }
+    }
+
     // TODO (expected): optimise using subset serializers, or perhaps simply with some deduping key serializer
     public static class StoreParticipantsSerializer implements IVersionedSerializer<StoreParticipants>
     {
@@ -390,7 +603,7 @@ public class CommandSerializers
         public void serialize(Writes writes, DataOutputPlus out, int version) throws IOException
         {
             txnId.serialize(writes.txnId, out, version);
-            timestamp.serialize(writes.executeAt, out, version);
+            ExecuteAtSerializer.serialize(writes.txnId, writes.executeAt, out);
             KeySerializers.seekables.serialize(writes.keys, out, version);
             boolean hasWrites = writes.write != null;
             out.writeBoolean(hasWrites);
@@ -402,7 +615,8 @@ public class CommandSerializers
         @Override
         public Writes deserialize(DataInputPlus in, int version) throws IOException
         {
-            return new Writes(txnId.deserialize(in, version), timestamp.deserialize(in, version),
+            TxnId id = txnId.deserialize(in, version);
+            return new Writes(id, ExecuteAtSerializer.deserialize(id, in),
                               KeySerializers.seekables.deserialize(in, version),
                               in.readBoolean() ? CommandSerializers.write.deserialize(in, version) : null);
         }
@@ -411,7 +625,7 @@ public class CommandSerializers
         public long serializedSize(Writes writes, int version)
         {
             long size = txnId.serializedSize(writes.txnId, version);
-            size += timestamp.serializedSize(writes.executeAt, version);
+            size += ExecuteAtSerializer.serializedSize(writes.txnId, writes.executeAt);
             size += KeySerializers.seekables.serializedSize(writes.keys, version);
             boolean hasWrites = writes.write != null;
             size += TypeSizes.sizeof(hasWrites);
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/CommitSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/CommitSerializers.java
index c0ee8df142..3043398cea 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/CommitSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/CommitSerializers.java
@@ -33,6 +33,7 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 
 import static org.apache.cassandra.utils.NullableSerializer.deserializeNullable;
 import static org.apache.cassandra.utils.NullableSerializer.serializeNullable;
@@ -50,7 +51,7 @@ public class CommitSerializers
         {
             kind.serialize(msg.kind, out, version);
             CommandSerializers.ballot.serialize(msg.ballot, out, version);
-            CommandSerializers.timestamp.serialize(msg.executeAt, out, version);
+            ExecuteAtSerializer.serialize(msg.txnId, msg.executeAt, out);
             CommandSerializers.nullablePartialTxn.serialize(msg.partialTxn, out, version);
             if (msg.kind.withDeps == Commit.WithDeps.HasDeps)
                 DepsSerializers.partialDeps.serialize(msg.scope, msg.partialDeps, out, version);
@@ -62,7 +63,7 @@ public class CommitSerializers
         {
             Commit.Kind kind = CommitSerializers.kind.deserialize(in, version);
             Ballot ballot = CommandSerializers.ballot.deserialize(in, version);
-            Timestamp executeAt = CommandSerializers.timestamp.deserialize(in, version);
+            Timestamp executeAt = ExecuteAtSerializer.deserialize(txnId, in);
             PartialTxn partialTxn = CommandSerializers.nullablePartialTxn.deserialize(in, version);
             PartialDeps partialDeps = null;
             if (kind.withDeps == Commit.WithDeps.HasDeps)
@@ -76,7 +77,7 @@ public class CommitSerializers
         {
             long size = kind.serializedSize(msg.kind, version)
                    + CommandSerializers.ballot.serializedSize(msg.ballot, version)
-                   + CommandSerializers.timestamp.serializedSize(msg.executeAt, version)
+                   + ExecuteAtSerializer.serializedSize(msg.txnId, msg.executeAt)
                    + CommandSerializers.nullablePartialTxn.serializedSize(msg.partialTxn, version);
 
             if (msg.kind.withDeps == Commit.WithDeps.HasDeps)
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/LatestDepsSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/LatestDepsSerializers.java
index ccb89ada56..e574ec60a5 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/LatestDepsSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/LatestDepsSerializers.java
@@ -34,6 +34,7 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 
 public class LatestDepsSerializers
 {
@@ -118,20 +119,20 @@ public class LatestDepsSerializers
         @Override
         public void serializeBody(GetLatestDeps msg, DataOutputPlus out, int version) throws IOException
         {
-            CommandSerializers.timestamp.serialize(msg.executeAt, out, version);
+            ExecuteAtSerializer.serialize(msg.executeAt, out);
         }
 
         @Override
         public GetLatestDeps deserializeBody(DataInputPlus in, int version, TxnId txnId, Route<?> scope, long waitForEpoch, long minEpoch) throws IOException
         {
-            Timestamp executeAt = CommandSerializers.timestamp.deserialize(in, version);
+            Timestamp executeAt = ExecuteAtSerializer.deserialize(in);
             return GetLatestDeps.SerializationSupport.create(txnId, scope, waitForEpoch, minEpoch, executeAt);
         }
 
         @Override
         public long serializedBodySize(GetLatestDeps msg, int version)
         {
-            return CommandSerializers.timestamp.serializedSize(msg.executeAt, version);
+            return ExecuteAtSerializer.serializedSize(msg.executeAt);
         }
     };
 
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/PreacceptSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/PreacceptSerializers.java
index 23cba8e903..dc4d787d6a 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/PreacceptSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/PreacceptSerializers.java
@@ -33,8 +33,10 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 import org.apache.cassandra.service.accord.serializers.TxnRequestSerializer.WithUnsyncedSerializer;
 
+
 public class PreacceptSerializers
 {
     private PreacceptSerializers() {}
@@ -92,7 +94,7 @@ public class PreacceptSerializers
 
             PreAcceptOk preAcceptOk = (PreAcceptOk) reply;
             CommandSerializers.txnId.serialize(preAcceptOk.txnId, out, version);
-            CommandSerializers.timestamp.serialize(preAcceptOk.witnessedAt, out, version);
+            ExecuteAtSerializer.serialize(preAcceptOk.txnId, preAcceptOk.witnessedAt, out);
             DepsSerializers.deps.serialize(preAcceptOk.deps, out, version);
         }
 
@@ -102,8 +104,9 @@ public class PreacceptSerializers
             if (!in.readBoolean())
                 return PreAccept.PreAcceptNack.INSTANCE;
 
-            return new PreAcceptOk(CommandSerializers.txnId.deserialize(in, version),
-                                   CommandSerializers.timestamp.deserialize(in, version),
+            TxnId txnId = CommandSerializers.txnId.deserialize(in, version);
+            return new PreAcceptOk(txnId,
+                                   ExecuteAtSerializer.deserialize(txnId, in),
                                    DepsSerializers.deps.deserialize(in, version));
         }
 
@@ -116,7 +119,7 @@ public class PreacceptSerializers
 
             PreAcceptOk preAcceptOk = (PreAcceptOk) reply;
             size += CommandSerializers.txnId.serializedSize(preAcceptOk.txnId, version);
-            size += CommandSerializers.timestamp.serializedSize(preAcceptOk.witnessedAt, version);
+            size += ExecuteAtSerializer.serializedSize(preAcceptOk.txnId, preAcceptOk.witnessedAt);
             size += DepsSerializers.deps.serializedSize(preAcceptOk.deps, version);
 
             return size;
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/ReadDataSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/ReadDataSerializers.java
index 453ba69b1f..e7afd47471 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/ReadDataSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/ReadDataSerializers.java
@@ -26,6 +26,7 @@ import accord.messages.Commit;
 import accord.messages.ReadData;
 import accord.messages.ReadData.CommitOrReadNack;
 import accord.messages.ReadData.ReadOk;
+import accord.messages.ReadData.ReadOkWithFutureEpoch;
 import accord.messages.ReadData.ReadReply;
 import accord.messages.ReadData.ReadType;
 import accord.messages.ReadEphemeralTxnData;
@@ -43,6 +44,7 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 import org.apache.cassandra.service.accord.txn.TxnData;
 
 import static accord.messages.Commit.WithDeps.HasDeps;
@@ -88,7 +90,7 @@ public class ReadDataSerializers
             CommandSerializers.txnId.serialize(msg.txnId, out, version);
             KeySerializers.participants.serialize(msg.scope, out, version);
             out.writeUnsignedVInt(msg.minEpoch());
-            CommandSerializers.timestamp.serialize(msg.executeAt, out, version);
+            ExecuteAtSerializer.serialize(msg.txnId, msg.executeAt, out);
             KeySerializers.fullRoute.serialize(msg.route, out, version);
             CommandSerializers.partialTxn.serialize(msg.txn, out, version);
             DepsSerializers.partialDeps.serialize(msg.deps, out, version);
@@ -98,11 +100,12 @@ public class ReadDataSerializers
         @Override
         public ApplyThenWaitUntilApplied deserialize(DataInputPlus in, int version) throws IOException
         {
+            TxnId txnId = CommandSerializers.txnId.deserialize(in, version);
             return ApplyThenWaitUntilApplied.SerializerSupport.create(
-            CommandSerializers.txnId.deserialize(in, version),
+            txnId,
             KeySerializers.participants.deserialize(in, version),
             in.readUnsignedVInt(),
-            CommandSerializers.timestamp.deserialize(in, version),
+            ExecuteAtSerializer.deserialize(txnId, in),
             KeySerializers.fullRoute.deserialize(in, version),
             CommandSerializers.partialTxn.deserialize(in, version),
             DepsSerializers.partialDeps.deserialize(in, version),
@@ -116,7 +119,7 @@ public class ReadDataSerializers
             return CommandSerializers.txnId.serializedSize(msg.txnId, version)
                    + KeySerializers.participants.serializedSize(msg.scope, version)
                    + TypeSizes.sizeofUnsignedVInt(msg.minEpoch())
-                   + CommandSerializers.timestamp.serializedSize(msg.executeAt, version)
+                   + ExecuteAtSerializer.serializedSize(msg.txnId, msg.executeAt)
                    + KeySerializers.fullRoute.serializedSize(msg.route, version)
                    + CommandSerializers.partialTxn.serializedSize(msg.txn, version)
                    + DepsSerializers.partialDeps.serializedSize(msg.deps, version)
@@ -234,33 +237,36 @@ public class ReadDataSerializers
         {
             if (!reply.isOk())
             {
-                out.writeByte(2 + ((CommitOrReadNack) reply).ordinal());
+                out.writeByte(3 + ((CommitOrReadNack) reply).ordinal());
                 return;
             }
 
-            boolean isFutureEpochOk = reply.getClass() == ReadData.ReadOkWithFutureEpoch.class;
-            out.writeByte(isFutureEpochOk ? 1 : 0);
             ReadOk readOk = (ReadOk) reply;
+            int flags = readOk.getClass() == ReadOkWithFutureEpoch.class ? 2 : readOk.uniqueHlc != 0 ? 1 : 0;
+            out.writeByte(flags);
             serializeNullable(readOk.unavailable, out, version, KeySerializers.ranges);
             dataSerializer.serialize((D) readOk.data, out, version);
-            if (isFutureEpochOk)
-                out.writeUnsignedVInt(((ReadData.ReadOkWithFutureEpoch) reply).futureEpoch);
+            switch (flags)
+            {
+                case 2: out.writeUnsignedVInt(((ReadOkWithFutureEpoch) reply).futureEpoch); break;
+                case 1: out.writeUnsignedVInt(readOk.uniqueHlc);
+            }
         }
 
         @Override
         public ReadReply deserialize(DataInputPlus in, int version) throws IOException
         {
-            int id = in.readByte();
-            if (id > 1)
-                return nacks[id - 2];
+            int flags = in.readByte();
+            if (flags > 2)
+                return nacks[flags - 3];
 
             Ranges unavailable = deserializeNullable(in, version, KeySerializers.ranges);
             D data = dataSerializer.deserialize(in, version);
-            if (id == 0)
-                return new ReadOk(unavailable, data);
 
-            long futureEpoch = in.readUnsignedVInt();
-            return new ReadData.ReadOkWithFutureEpoch(unavailable, data, futureEpoch);
+            long extraLong = flags == 0 ? 0 : in.readUnsignedVInt();
+            if (flags <= 1)
+                return new ReadOk(unavailable, data, extraLong);
+            return new ReadOkWithFutureEpoch(unavailable, data, extraLong);
         }
 
         @Override
@@ -273,8 +279,10 @@ public class ReadDataSerializers
             long size = TypeSizes.BYTE_SIZE
                         + serializedNullableSize(readOk.unavailable, version, KeySerializers.ranges)
                         + dataSerializer.serializedSize((D) readOk.data, version);
-            if (readOk instanceof ReadData.ReadOkWithFutureEpoch)
-                size += TypeSizes.sizeofUnsignedVInt(((ReadData.ReadOkWithFutureEpoch) readOk).futureEpoch);
+            if (readOk.uniqueHlc != 0)
+                size += TypeSizes.sizeofUnsignedVInt(readOk.uniqueHlc);
+            else if (readOk instanceof ReadOkWithFutureEpoch)
+                size += TypeSizes.sizeofUnsignedVInt(((ReadOkWithFutureEpoch) readOk).futureEpoch);
             return size;
         }
     }
@@ -323,7 +331,7 @@ public class ReadDataSerializers
             KeySerializers.participants.serialize(read.scope, out, version);
             CommitSerializers.kind.serialize(read.kind, out, version);
             out.writeUnsignedVInt(read.minEpoch);
-            CommandSerializers.timestamp.serialize(read.executeAt, out, version);
+            ExecuteAtSerializer.serialize(read.txnId, read.executeAt, out);
             if (read.kind.withTxn != NoTxn)
                 CommandSerializers.nullablePartialTxn.serialize(read.partialTxn, out, version);
             if (read.kind.withDeps == HasDeps)
@@ -339,7 +347,7 @@ public class ReadDataSerializers
             Participants<?> scope = KeySerializers.participants.deserialize(in, version);
             Commit.Kind kind = CommitSerializers.kind.deserialize(in, version);
             long minEpoch = in.readUnsignedVInt();
-            Timestamp executeAt = CommandSerializers.timestamp.deserialize(in, version);
+            Timestamp executeAt = ExecuteAtSerializer.deserialize(txnId, in);
             PartialTxn partialTxn = kind.withTxn == NoTxn ? null : CommandSerializers.nullablePartialTxn.deserialize(in, version);
             PartialDeps partialDeps = kind.withDeps == NoDeps ? null : DepsSerializers.partialDeps.deserialize(in, version);
             FullRoute < ?> route = kind.withTxn == HasTxn ? KeySerializers.fullRoute.deserialize(in, version) : null;
@@ -353,7 +361,7 @@ public class ReadDataSerializers
                    + KeySerializers.participants.serializedSize(read.scope, version)
                    + CommitSerializers.kind.serializedSize(read.kind, version)
                    + TypeSizes.sizeofUnsignedVInt(read.minEpoch)
-                   + CommandSerializers.timestamp.serializedSize(read.executeAt, version)
+                   + ExecuteAtSerializer.serializedSize(read.txnId, read.executeAt)
                    + (read.kind.withTxn == NoTxn ? 0 : CommandSerializers.nullablePartialTxn.serializedSize(read.partialTxn, version))
                    + (read.kind.withDeps != HasDeps ? 0 : DepsSerializers.partialDeps.serializedSize(read.partialDeps, version))
                    + (read.kind.withTxn != HasTxn ? 0 : KeySerializers.fullRoute.serializedSize(read.route, version));
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/RecoverySerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/RecoverySerializers.java
index c4625e7903..bc1ec7fcbd 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/RecoverySerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/RecoverySerializers.java
@@ -43,6 +43,7 @@ import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 import org.apache.cassandra.service.accord.serializers.TxnRequestSerializer.WithUnsyncedSerializer;
 
 import static accord.messages.BeginRecovery.RecoverReply.Kind.Ok;
@@ -96,7 +97,7 @@ public class RecoverySerializers
             CommandSerializers.txnId.serialize(recoverOk.txnId, out, version);
             CommandSerializers.status.serialize(recoverOk.status, out, version);
             CommandSerializers.ballot.serialize(recoverOk.accepted, out, version);
-            CommandSerializers.nullableTimestamp.serialize(recoverOk.executeAt, out, version);
+            ExecuteAtSerializer.serializeNullable(recoverOk.executeAt, out);
             latestDeps.serialize(recoverOk.deps, out, version);
             DepsSerializers.deps.serialize(recoverOk.earlierWait, out, version);
             DepsSerializers.deps.serialize(recoverOk.earlierNoWait, out, version);
@@ -142,7 +143,7 @@ public class RecoverySerializers
             return deserializeOk(id,
                                  status,
                                  CommandSerializers.ballot.deserialize(in, version),
-                                 CommandSerializers.nullableTimestamp.deserialize(in, version),
+                                 ExecuteAtSerializer.deserializeNullable(in),
                                  latestDeps.deserialize(in, version),
                                  DepsSerializers.deps.deserialize(in, version),
                                  DepsSerializers.deps.deserialize(in, version),
@@ -166,7 +167,7 @@ public class RecoverySerializers
             long size = CommandSerializers.txnId.serializedSize(recoverOk.txnId, version);
             size += CommandSerializers.status.serializedSize(recoverOk.status, version);
             size += CommandSerializers.ballot.serializedSize(recoverOk.accepted, version);
-            size += CommandSerializers.nullableTimestamp.serializedSize(recoverOk.executeAt, version);
+            size += ExecuteAtSerializer.serializedNullableSize(recoverOk.executeAt);
             size += latestDeps.serializedSize(recoverOk.deps, version);
             size += DepsSerializers.deps.serializedSize(recoverOk.earlierWait, version);
             size += DepsSerializers.deps.serializedSize(recoverOk.earlierNoWait, version);
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/SetDurableSerializers.java b/src/java/org/apache/cassandra/service/accord/serializers/SetDurableSerializers.java
index dd2df26abf..513cabf3a0 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/SetDurableSerializers.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/SetDurableSerializers.java
@@ -29,6 +29,7 @@ import accord.primitives.TxnId;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
+import org.apache.cassandra.service.accord.serializers.CommandSerializers.ExecuteAtSerializer;
 
 public class SetDurableSerializers
 {
@@ -80,7 +81,7 @@ public class SetDurableSerializers
         public void serialize(SyncPoint sp, DataOutputPlus out, int version) throws IOException
         {
             CommandSerializers.txnId.serialize(sp.syncId, out, version);
-            CommandSerializers.timestamp.serialize(sp.executeAt, out, version);
+            ExecuteAtSerializer.serialize(sp.syncId, sp.executeAt, out);
             DepsSerializers.deps.serialize(sp.waitFor, out, version);
             KeySerializers.fullRoute.serialize(sp.route, out, version);
         }
@@ -89,7 +90,7 @@ public class SetDurableSerializers
         public SyncPoint deserialize(DataInputPlus in, int version) throws IOException
         {
             TxnId syncId = CommandSerializers.txnId.deserialize(in, version);
-            Timestamp executeAt = CommandSerializers.timestamp.deserialize(in, version);
+            Timestamp executeAt = ExecuteAtSerializer.deserialize(syncId, in);
             Deps waitFor = DepsSerializers.deps.deserialize(in, version);
             FullRoute<?> route = KeySerializers.fullRoute.deserialize(in, version);
             return SyncPoint.SerializationSupport.construct(syncId, executeAt, waitFor, route);
@@ -99,7 +100,7 @@ public class SetDurableSerializers
         public long serializedSize(SyncPoint sp, int version)
         {
             return   CommandSerializers.txnId.serializedSize(sp.syncId, version)
-                   + CommandSerializers.timestamp.serializedSize(sp.executeAt, version)
+                   + ExecuteAtSerializer.serializedSize(sp.syncId, sp.executeAt)
                    + DepsSerializers.deps.serializedSize(sp.waitFor, version)
                    + KeySerializers.fullRoute.serializedSize(sp.route, version);
         }
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/WaitingOnSerializer.java b/src/java/org/apache/cassandra/service/accord/serializers/WaitingOnSerializer.java
index 7ff8d87333..a538e4b756 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/WaitingOnSerializer.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/WaitingOnSerializer.java
@@ -19,126 +19,106 @@
 package org.apache.cassandra.service.accord.serializers;
 
 import java.io.IOException;
-import java.nio.ByteBuffer;
 
+import accord.impl.CommandChange;
 import accord.local.Command;
 import accord.local.Command.WaitingOn;
 import accord.primitives.KeyDeps;
 import accord.primitives.RangeDeps;
-import accord.primitives.Routable;
 import accord.primitives.RoutingKeys;
-import accord.primitives.Timestamp;
 import accord.primitives.TxnId;
 import accord.utils.ImmutableBitSet;
 import accord.utils.Invariants;
 import accord.utils.SimpleBitSet;
 import org.apache.cassandra.db.TypeSizes;
-import org.apache.cassandra.utils.vint.VIntCoding;
+import org.apache.cassandra.io.util.DataInputPlus;
+import org.apache.cassandra.io.util.DataOutputPlus;
+
+import static accord.primitives.Routable.Domain.Key;
+import static accord.primitives.Routable.Domain.Range;
 
 public class WaitingOnSerializer
 {
-    public static long serializedSize(TxnId txnId, WaitingOn waitingOn)
+    public static void serializeBitSetsOnly(TxnId txnId, WaitingOn waitingOn, DataOutputPlus out) throws IOException
     {
-        Invariants.checkState(txnId.is(Routable.Domain.Key) == (waitingOn.appliedOrInvalidated == null));
+        Invariants.checkState(txnId.is(Key) == (waitingOn.appliedOrInvalidated == null));
         int keyCount = waitingOn.keys.size();
         int txnIdCount = waitingOn.txnIdCount();
         int waitingOnLength = (txnIdCount + keyCount + 63) / 64;
-        long size = 1;
-        if (waitingOn.executeAtLeast() != null)
-            size += CommandSerializers.timestamp.serializedSize();
-        size += serializedSize(waitingOnLength, waitingOn.waitingOn);
-        size += TypeSizes.sizeofUnsignedVInt(keyCount);
-        size += TypeSizes.sizeofUnsignedVInt(txnIdCount);
-        if (waitingOn.appliedOrInvalidated == null)
-            return size;
+        out.writeUnsignedVInt32(waitingOnLength);
+        serialize(waitingOnLength, waitingOn.waitingOn, out);
 
-        int appliedOrInvalidatedLength = (txnIdCount + 63) / 64;
-        return size + serializedSize(appliedOrInvalidatedLength, waitingOn.appliedOrInvalidated);
+        if (txnId.is(Range))
+        {
+            int appliedOrInvalidatedLength = (txnIdCount + 63) / 64;
+            out.writeUnsignedVInt32(waitingOnLength - appliedOrInvalidatedLength);
+            serialize(appliedOrInvalidatedLength, waitingOn.appliedOrInvalidated, out);
+        }
     }
 
-    public static long serializedSize(int length, SimpleBitSet write)
+    public static CommandChange.WaitingOnProvider deserializeProvider(TxnId txnId, DataInputPlus in) throws IOException
     {
-        long[] bits = SimpleBitSet.SerializationSupport.getArray(write);
-        Invariants.checkState(length == bits.length, "Expected length %d != %d", length, bits.length);
-        return (long) TypeSizes.LONG_SIZE * length;
-    }
+        ImmutableBitSet waitingOn, appliedOrInvalidated;
+        {
+            int waitingOnLength = in.readUnsignedVInt32();
+            waitingOn = deserialize(waitingOnLength, in);
+            if (txnId.is(Range))
+            {
+                int appliedOrInvalidatedLength = waitingOnLength - in.readUnsignedVInt32();
+                appliedOrInvalidated = deserialize(appliedOrInvalidatedLength, in);
+            }
+            else
+            {
+                appliedOrInvalidated = null;
+            }
+        }
 
-    public static ByteBuffer serialize(TxnId txnId, WaitingOn waitingOn) throws IOException
-    {
-        Invariants.checkState(txnId.is(Routable.Domain.Key) == (waitingOn.appliedOrInvalidated == null));
-        int keyCount = waitingOn.keys.size();
-        int txnIdCount = waitingOn.txnIdCount();
-        int waitingOnLength = (txnIdCount + keyCount + 63) / 64;
-        int appliedOrInvalidatedLength = 0;
-        if (waitingOn.appliedOrInvalidated != null)
-            appliedOrInvalidatedLength = (txnIdCount + 63) / 64;
+        return (id, deps, executeAtLeast, uniqueHlc) -> {
+            RoutingKeys keys = deps.keyDeps.keys();
+            RangeDeps directRangeDeps = deps.rangeDeps;
+            KeyDeps directKeyDeps = deps.directKeyDeps;
+            int txnIdCount = directRangeDeps.txnIdCount() + directKeyDeps.txnIdCount();
+            Invariants.checkState(waitingOn.size()/64 == (txnIdCount + keys.size() + 63) / 64);
+            Invariants.checkState(appliedOrInvalidated == null || (appliedOrInvalidated.size()/64 == (txnIdCount + 63)/64));
 
-        Timestamp executeAtLeast = waitingOn.executeAtLeast();
-        ByteBuffer out = ByteBuffer.allocate(1 + (executeAtLeast == null ? 0 : CommandSerializers.timestamp.serializedSize())
-                                             + TypeSizes.sizeofUnsignedVInt(keyCount) + TypeSizes.sizeofUnsignedVInt(txnIdCount)
-                                             + TypeSizes.LONG_SIZE * (waitingOnLength + appliedOrInvalidatedLength));
+            WaitingOn result = new WaitingOn(keys, directRangeDeps, directKeyDeps, waitingOn, appliedOrInvalidated);
+            if (executeAtLeast != null) return new Command.WaitingOnWithExecuteAt(result, executeAtLeast);
+            else if (uniqueHlc != 0) return new Command.WaitingOnWithMinUniqueHlc(result, uniqueHlc);
+            return result;
+        };
+    }
 
-        if (executeAtLeast == null) out.put((byte)0);
-        else
+    public static void skip(TxnId txnId, DataInputPlus in) throws IOException
+    {
+        int waitingOnLength = in.readUnsignedVInt32();
+        in.skipBytesFully(waitingOnLength * 8);
+        if (txnId.is(Range))
         {
-            out.put((byte) 1);
-            CommandSerializers.timestamp.serialize(executeAtLeast, out);
+            int delta = in.readUnsignedVInt32();
+            in.skipBytesFully((waitingOnLength - delta) * 8);
         }
-        VIntCoding.writeUnsignedVInt32(keyCount, out);
-        VIntCoding.writeUnsignedVInt32(txnIdCount, out);
-        serialize(waitingOnLength, waitingOn.waitingOn, out);
-        if (appliedOrInvalidatedLength > 0)
-            serialize(appliedOrInvalidatedLength, waitingOn.appliedOrInvalidated, out);
-        return out.flip();
     }
 
-    private static void serialize(int length, SimpleBitSet write, ByteBuffer out)
+    private static void serialize(int length, SimpleBitSet write, DataOutputPlus out) throws IOException
     {
         long[] bits = SimpleBitSet.SerializationSupport.getArray(write);
         Invariants.checkState(length == bits.length);
         for (int i = 0; i < length; i++)
-            out.putLong(bits[i]);
-    }
-
-    public static WaitingOn deserialize(TxnId txnId, RoutingKeys keys, RangeDeps directRangeDeps, KeyDeps directKeyDeps, ByteBuffer in) throws IOException
-    {
-        int txnIdCount = directRangeDeps.txnIdCount() + directKeyDeps.txnIdCount();
-        int waitingOnLength = (txnIdCount + keys.size() + 63) / 64;
-        int position = in.position();
-        int flags = in.get(position++);
-        Timestamp executesAtLeast = null;
-        if ((flags & 1) != 0)
-        {
-            executesAtLeast = CommandSerializers.timestamp.deserialize(in, position);
-            position += CommandSerializers.timestamp.serializedSize();
-        }
-        int a = VIntCoding.readUnsignedVInt32(in, position);
-        position += TypeSizes.sizeofUnsignedVInt(a);
-        int b = VIntCoding.readUnsignedVInt32(in, position);
-        position += TypeSizes.sizeofUnsignedVInt(b);
-        ImmutableBitSet waitingOn = deserialize(position, waitingOnLength, in);
-        ImmutableBitSet appliedOrInvalidated = null;
-        if (txnId.domain() == Routable.Domain.Range)
-        {
-            position += waitingOnLength*8;
-            int appliedOrInvalidatedLength = (txnIdCount + 63) / 64;
-            appliedOrInvalidated = deserialize(position, appliedOrInvalidatedLength, in);
-        }
-
-        WaitingOn result = new WaitingOn(keys, directRangeDeps, directKeyDeps, waitingOn, appliedOrInvalidated);
-        if (executesAtLeast != null)
-            result = new Command.WaitingOnWithExecuteAt(result, executesAtLeast);
-        return result;
+            out.writeLong(bits[i]);
     }
 
-    private static ImmutableBitSet deserialize(int position, int length, ByteBuffer in)
+    private static ImmutableBitSet deserialize(int length, DataInputPlus in) throws IOException
     {
         long[] bits = new long[length];
         for (int i = 0 ; i < length ; ++i)
-        {
-            bits[i] = in.getLong(position);
-            position += Long.BYTES;
-        }
+            bits[i] = in.readLong();
         return ImmutableBitSet.SerializationSupport.construct(bits);
     }
+
+    public static long serializedSize(int length, SimpleBitSet write)
+    {
+        long[] bits = SimpleBitSet.SerializationSupport.getArray(write);
+        Invariants.checkState(length == bits.length, "Expected length %d != %d", length, bits.length);
+        return (long) TypeSizes.LONG_SIZE * length;
+    }
 }
diff --git a/src/java/org/apache/cassandra/service/accord/txn/AccordUpdateParameters.java b/src/java/org/apache/cassandra/service/accord/txn/AccordUpdateParameters.java
index 5792b4a50b..24d3ef78ab 100644
--- a/src/java/org/apache/cassandra/service/accord/txn/AccordUpdateParameters.java
+++ b/src/java/org/apache/cassandra/service/accord/txn/AccordUpdateParameters.java
@@ -31,16 +31,19 @@ import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.service.ClientState;
 
 import static com.google.common.base.Preconditions.checkState;
+import static java.util.concurrent.TimeUnit.MICROSECONDS;
 
 public class AccordUpdateParameters
 {
     private final TxnData data;
     private final QueryOptions options;
+    private final long timestamp;
 
-    public AccordUpdateParameters(TxnData data, QueryOptions options)
+    public AccordUpdateParameters(TxnData data, QueryOptions options, long timestamp)
     {
         this.data = data;
         this.options = options;
+        this.timestamp = timestamp;
     }
 
     public TxnData getData()
@@ -55,38 +58,36 @@ public class AccordUpdateParameters
         // For the time being, guardrails are disabled for Accord queries.
         ClientState disabledGuardrails = null;
 
-        // What we use here doesn't matter as they get replaced before actually performing the write.
-        // see org.apache.cassandra.service.accord.txn.TxnWrite.Update.write
-        int nowInSeconds = 42;
-        long timestamp = nowInSeconds;
-
-        // TODO: How should Accord work with TTL?
+        // TODO : How should Accord work with TTL?
         int ttl = metadata.params.defaultTimeToLive;
         return new UpdateParameters(metadata,
                                     disabledGuardrails,
                                     options,
                                     timestamp,
-                                    nowInSeconds,
+                                    MICROSECONDS.toSeconds(timestamp),
                                     ttl,
                                     prefetchRow(metadata, dk, rowIndex));
     }
 
     private Map<DecoratedKey, Partition> prefetchRow(TableMetadata metadata, DecoratedKey dk, int index)
     {
-        for (Map.Entry<Integer, TxnDataValue> e : data.entrySet())
+        if (data != null)
         {
-            int name = e.getKey();
-            TxnDataKeyValue value = (TxnDataKeyValue)e.getValue();
-            switch (TxnData.txnDataNameKind(name))
+            for (Map.Entry<Integer, TxnDataValue> e : data.entrySet())
             {
-                case CAS_READ:
-                    checkState(data.entrySet().size() == 1, "CAS read should only have one entry");
-                    return ImmutableMap.of(dk, value);
-                case AUTO_READ:
-                    // TODO (review): Is this the right DK being passed into that matches what we used to store in TxnDataName
-                    if (TxnData.txnDataNameIndex(name) == index)
+                int name = e.getKey();
+                TxnDataKeyValue value = (TxnDataKeyValue)e.getValue();
+                switch (TxnData.txnDataNameKind(name))
+                {
+                    case CAS_READ:
+                        checkState(data.entrySet().size() == 1, "CAS read should only have one entry");
                         return ImmutableMap.of(dk, value);
-                default:
+                    case AUTO_READ:
+                        // TODO (review): Is this the right DK being passed into that matches what we used to store in TxnDataName
+                        if (TxnData.txnDataNameIndex(name) == index)
+                            return ImmutableMap.of(dk, value);
+                    default:
+                }
             }
         }
         return Collections.emptyMap();
diff --git a/src/java/org/apache/cassandra/service/accord/txn/TxnDataKeyValue.java b/src/java/org/apache/cassandra/service/accord/txn/TxnDataKeyValue.java
index 95e6a9c637..c56b2c49ba 100644
--- a/src/java/org/apache/cassandra/service/accord/txn/TxnDataKeyValue.java
+++ b/src/java/org/apache/cassandra/service/accord/txn/TxnDataKeyValue.java
@@ -73,7 +73,7 @@ public class TxnDataKeyValue extends FilteredPartition implements TxnDataValue
         @Override
         public void serialize(TxnDataKeyValue value, DataOutputPlus out, int version) throws IOException
         {
-            value.metadata().id.serialize(out);
+            value.metadata().id.serializeCompact(out);
             try (UnfilteredRowIterator iterator = value.unfilteredIterator())
             {
                 UnfilteredRowIteratorSerializer.serializer.serialize(iterator, ColumnFilter.all(value.metadata()), out, version, value.rowCount());
@@ -84,7 +84,7 @@ public class TxnDataKeyValue extends FilteredPartition implements TxnDataValue
         public TxnDataKeyValue deserialize(DataInputPlus in, int version) throws IOException
         {
             // TODO (required): This needs to use the correct cluster metadata for schema change
-            TableMetadata metadata = Schema.instance.getExistingTableMetadata(TableId.deserialize(in));
+            TableMetadata metadata = Schema.instance.getExistingTableMetadata(TableId.deserializeCompact(in));
             try (UnfilteredRowIterator partition = UnfilteredRowIteratorSerializer.serializer.deserialize(in, version, metadata, ColumnFilter.all(metadata), DeserializationHelper.Flag.FROM_REMOTE))
             {
                 return new TxnDataKeyValue(UnfilteredRowIterators.filter(partition, 0));
@@ -95,7 +95,7 @@ public class TxnDataKeyValue extends FilteredPartition implements TxnDataValue
         public long serializedSize(TxnDataKeyValue value, int version)
         {
             TableId tableId = value.metadata().id;
-            long size = tableId.serializedSize();
+            long size = tableId.serializedCompactSize();
             try (UnfilteredRowIterator iterator = value.unfilteredIterator())
             {
                 return size + UnfilteredRowIteratorSerializer.serializer.serializedSize(iterator, ColumnFilter.all(value.metadata()), version, value.rowCount());
diff --git a/src/java/org/apache/cassandra/service/accord/txn/TxnUpdate.java b/src/java/org/apache/cassandra/service/accord/txn/TxnUpdate.java
index 674cf5cb23..c72d52c377 100644
--- a/src/java/org/apache/cassandra/service/accord/txn/TxnUpdate.java
+++ b/src/java/org/apache/cassandra/service/accord/txn/TxnUpdate.java
@@ -220,7 +220,7 @@ public class TxnUpdate extends AccordUpdate
         List<TxnWrite.Fragment> fragments = deserialize(this.fragments, TxnWrite.Fragment.serializer);
         List<TxnWrite.Update> updates = new ArrayList<>(fragments.size());
         QueryOptions options = QueryOptions.forProtocolVersion(ProtocolVersion.CURRENT);
-        AccordUpdateParameters parameters = new AccordUpdateParameters((TxnData) data, options);
+        AccordUpdateParameters parameters = new AccordUpdateParameters((TxnData) data, options, executeAt.uniqueHlc());
 
         for (TxnWrite.Fragment fragment : fragments)
             // Filter out fragments that already constitute complete updates to avoid persisting them via TxnWrite:
diff --git a/src/java/org/apache/cassandra/service/accord/txn/TxnWrite.java b/src/java/org/apache/cassandra/service/accord/txn/TxnWrite.java
index 3deca7c171..85c26e629d 100644
--- a/src/java/org/apache/cassandra/service/accord/txn/TxnWrite.java
+++ b/src/java/org/apache/cassandra/service/accord/txn/TxnWrite.java
@@ -27,19 +27,15 @@ import java.util.List;
 import java.util.Objects;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
-import javax.annotation.Nonnull;
 
-import com.google.common.base.Function;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.Iterables;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import accord.api.DataStore;
-import accord.api.RoutingKey;
 import accord.api.Write;
 import accord.local.SafeCommandStore;
-import accord.local.cfk.SafeCommandsForKey;
 import accord.primitives.PartialTxn;
 import accord.primitives.RoutableKey;
 import accord.primitives.Seekable;
@@ -57,8 +53,6 @@ import org.apache.cassandra.db.Mutation;
 import org.apache.cassandra.db.RegularAndStaticColumns;
 import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.db.partitions.PartitionUpdate;
-import org.apache.cassandra.db.rows.Cell;
-import org.apache.cassandra.db.rows.CellPath;
 import org.apache.cassandra.db.rows.Row;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
@@ -69,7 +63,6 @@ import org.apache.cassandra.utils.BooleanSerializer;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.ObjectSizes;
 
-import static org.apache.cassandra.cql3.terms.Lists.accordListPathSupplier;
 import static org.apache.cassandra.service.accord.AccordSerializers.partitionUpdateSerializer;
 import static org.apache.cassandra.utils.ArraySerializers.deserializeArray;
 import static org.apache.cassandra.utils.ArraySerializers.serializeArray;
@@ -137,11 +130,11 @@ public class TxnWrite extends AbstractKeySorted<TxnWrite.Update> implements Writ
                    '}';
         }
 
-        public AsyncChain<Void> write(boolean preserveTimestamps, @Nonnull Function<Cell, CellPath> cellToMaybeNewListPath, long timestamp, int nowInSeconds)
+        public AsyncChain<Void> write(boolean preserveTimestamps, long timestamp)
         {
             PartitionUpdate update = get();
             if (!preserveTimestamps)
-                update = new PartitionUpdate.Builder(get(), 0).updateTimesAndPathsForAccord(cellToMaybeNewListPath, timestamp, nowInSeconds).build();
+                update = new PartitionUpdate.Builder(get(), 0).updateAllTimestamp(timestamp).build();
             Mutation mutation = new Mutation(update, true);
             return AsyncChains.ofRunnable(Stage.MUTATION.executor(), mutation::applyUnsafe);
         }
@@ -304,13 +297,13 @@ public class TxnWrite extends AbstractKeySorted<TxnWrite.Update> implements Writ
             return up.buildRow();
         }
 
-        static final IVersionedSerializer<Fragment> serializer = new IVersionedSerializer<Fragment>()
+        static final IVersionedSerializer<Fragment> serializer = new IVersionedSerializer<>()
         {
             @Override
             public void serialize(Fragment fragment, DataOutputPlus out, int version) throws IOException
             {
                 PartitionKey.serializer.serialize(fragment.key, out, version);
-                out.writeInt(fragment.index);
+                out.writeUnsignedVInt32(fragment.index);
                 partitionUpdateSerializer.serialize(fragment.baseUpdate, out, version);
                 TxnReferenceOperations.serializer.serialize(fragment.referenceOps, out, version);
             }
@@ -319,7 +312,7 @@ public class TxnWrite extends AbstractKeySorted<TxnWrite.Update> implements Writ
             public Fragment deserialize(DataInputPlus in, int version) throws IOException
             {
                 PartitionKey key = PartitionKey.serializer.deserialize(in, version);
-                int idx = in.readInt();
+                int idx = in.readUnsignedVInt32();
                 PartitionUpdate baseUpdate = partitionUpdateSerializer.deserialize(in, version);
                 TxnReferenceOperations referenceOps = TxnReferenceOperations.serializer.deserialize(in, version);
                 return new Fragment(key, idx, baseUpdate, referenceOps);
@@ -330,7 +323,7 @@ public class TxnWrite extends AbstractKeySorted<TxnWrite.Update> implements Writ
             {
                 long size = 0;
                 size += PartitionKey.serializer.serializedSize(fragment.key, version);
-                size += TypeSizes.INT_SIZE;
+                size += TypeSizes.sizeofUnsignedVInt(fragment.index);
                 size += partitionUpdateSerializer.serializedSize(fragment.baseUpdate, version);
                 size += TxnReferenceOperations.serializer.serializedSize(fragment.referenceOps, version);
                 return size;
@@ -381,35 +374,26 @@ public class TxnWrite extends AbstractKeySorted<TxnWrite.Update> implements Writ
     {
         // UnrecoverableRepairUpdate will deserialize as null at other nodes
         // Accord should skip the Update for a read transaction, but handle it here anyways
-        if (txn.update() == null)
-            return Writes.SUCCESS;
-
         TxnUpdate txnUpdate = ((TxnUpdate)txn.update());
-        // TODO (expected, efficiency): 99.9999% of the time we can just use executeAt.hlc(), so can avoid bringing
-        //  cfk into memory by retaining at all times in memory key ranges that are dirty and must use this logic;
-        //  any that aren't can just use executeAt.hlc
-        SafeCommandsForKey safeCfk = safeStore.get((RoutingKey) key.toUnseekable());
+        if (txnUpdate == null)
+            return Writes.SUCCESS;
 
-        long timestamp = safeCfk.current().uniqueHlc(safeStore, txnId, executeAt);
-        // TODO (low priority - do we need to compute nowInSeconds, or can we just use executeAt?)
-        int nowInSeconds = (int) TimeUnit.MICROSECONDS.toSeconds(executeAt.hlc());
+        long timestamp = executeAt.uniqueHlc();
+        int nowInSeconds = (int) TimeUnit.MICROSECONDS.toSeconds(timestamp);
 
+        // TODO (expected): optimise for the common single update case; lots of lists allocated
         List<AsyncChain<Void>> results = new ArrayList<>();
-
-        boolean preserveTimestamps = txnUpdate.preserveTimestamps();
-        // Apply updates not specified fully by the client but built from fragments completed by data from reads.
-        // This occurs, for example, when an UPDATE statement uses a value assigned by a LET statement.
-        Function<Cell, CellPath> accordListPathSuppler = accordListPathSupplier(timestamp);
-        forEachWithKey((PartitionKey) key, write -> results.add(write.write(preserveTimestamps, accordListPathSuppler, timestamp, nowInSeconds)));
-
         if (isConditionMet)
         {
+            boolean preserveTimestamps = txnUpdate.preserveTimestamps();
+            // Apply updates not specified fully by the client but built from fragments completed by data from reads.
+            // This occurs, for example, when an UPDATE statement uses a value assigned by a LET statement.
+            forEachWithKey((PartitionKey) key, write -> results.add(write.write(preserveTimestamps, timestamp)));
             // Apply updates that are fully specified by the client and not reliant on data from reads.
             // ex. INSERT INTO tbl (a, b, c) VALUES (1, 2, 3)
             // These updates are persisted only in TxnUpdate and not in TxnWrite to avoid duplication.
-            assert txnUpdate != null : "PartialTxn should contain an update if we're applying a write!";
             List<Update> updates = txnUpdate.completeUpdatesForKey((RoutableKey) key);
-            updates.forEach(update -> results.add(update.write(preserveTimestamps, accordListPathSuppler, timestamp, nowInSeconds)));
+            updates.forEach(write -> results.add(write.write(preserveTimestamps, timestamp)));
         }
 
         if (results.isEmpty())
diff --git a/test/unit/org/apache/cassandra/db/compaction/CompactionAccordIteratorsTest.java b/test/unit/org/apache/cassandra/db/compaction/CompactionAccordIteratorsTest.java
index 2746306534..08485feefd 100644
--- a/test/unit/org/apache/cassandra/db/compaction/CompactionAccordIteratorsTest.java
+++ b/test/unit/org/apache/cassandra/db/compaction/CompactionAccordIteratorsTest.java
@@ -93,6 +93,7 @@ import org.apache.cassandra.utils.Pair;
 import static accord.local.KeyHistory.SYNC;
 import static accord.local.PreLoadContext.contextFor;
 import static accord.primitives.Routable.Domain.Range;
+import static accord.primitives.Timestamp.Flag.HLC_BOUND;
 import static accord.utils.async.AsyncChains.getUninterruptibly;
 import static org.apache.cassandra.Util.spinAssertEquals;
 import static org.apache.cassandra.cql3.statements.schema.CreateTableStatement.parse;
@@ -117,10 +118,10 @@ public class CompactionAccordIteratorsTest
     private static final TxnId TXN_ID = AccordTestUtils.txnId(EPOCH, LT_TXN_ID.hlc() + 1, NODE);
     private static final TxnId SECOND_TXN_ID = AccordTestUtils.txnId(EPOCH, TXN_ID.hlc() + 1, NODE, Kind.Read);
     private static final TxnId RANGE_TXN_ID = AccordTestUtils.txnId(EPOCH, TXN_ID.hlc() + 2, NODE, Kind.Read, Range);
-    private static final TxnId GT_TXN_ID = SECOND_TXN_ID;
+    private static final TxnId GT_TXN_ID = SECOND_TXN_ID.addFlag(HLC_BOUND);
     // For CommandsForKey where we test with two commands
     private static final TxnId[] TXN_IDS = new TxnId[]{ TXN_ID, SECOND_TXN_ID };
-    private static final TxnId GT_SECOND_TXN_ID = AccordTestUtils.txnId(EPOCH, SECOND_TXN_ID.hlc() + 1, NODE);
+    private static final TxnId GT_SECOND_TXN_ID = AccordTestUtils.txnId(EPOCH, SECOND_TXN_ID.hlc() + 1, NODE).addFlag(HLC_BOUND);
 
     static ColumnFamilyStore commandsForKey;
     static TableMetadata table;
diff --git a/test/unit/org/apache/cassandra/index/accord/RouteIndexTest.java b/test/unit/org/apache/cassandra/index/accord/RouteIndexTest.java
index a6a5ebd545..1e319eb738 100644
--- a/test/unit/org/apache/cassandra/index/accord/RouteIndexTest.java
+++ b/test/unit/org/apache/cassandra/index/accord/RouteIndexTest.java
@@ -634,8 +634,8 @@ public class RouteIndexTest extends CQLTester.InMemory
         Int2ObjectHashMap<DurableBefore> durableBefores = new Int2ObjectHashMap<>();
         Int2ObjectHashMap<CommandStores.RangesForEpoch> ranges = new Int2ObjectHashMap<>();
         RedundantBefore redundantBefore = Mockito.spy(RedundantBefore.EMPTY);
-        Mockito.doReturn(RedundantStatus.LIVE).when(redundantBefore).status(Mockito.any(), (Participants<?>) Mockito.any());
-        Mockito.doReturn(RedundantStatus.LIVE).when(redundantBefore).status(Mockito.any(), (RoutingKey) Mockito.any());
+        Mockito.doReturn(RedundantStatus.LIVE).when(redundantBefore).status(Mockito.any(), Mockito.any(), (Participants<?>) Mockito.any());
+        Mockito.doReturn(RedundantStatus.LIVE).when(redundantBefore).status(Mockito.any(), Mockito.any(), (RoutingKey) Mockito.any());
         for (int i = 0; i < MAX_STORES; i++)
         {
             redundantBefores.put(i, redundantBefore);
diff --git a/test/unit/org/apache/cassandra/service/accord/AccordConfigurationServiceTest.java b/test/unit/org/apache/cassandra/service/accord/AccordConfigurationServiceTest.java
index 04a3289985..b7c3c5c705 100644
--- a/test/unit/org/apache/cassandra/service/accord/AccordConfigurationServiceTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/AccordConfigurationServiceTest.java
@@ -181,7 +181,7 @@ public class AccordConfigurationServiceTest
         ValidatingClusterMetadataService cms = ValidatingClusterMetadataService.createAndRegister(Version.MIN_ACCORD_VERSION);
 
 
-        AccordConfigurationService service = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks, null);
+        AccordConfigurationService service = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks);
         Assert.assertEquals(null, AccordKeyspace.loadEpochDiskState());
         service.start();
         Assert.assertEquals(null, AccordKeyspace.loadEpochDiskState());
@@ -207,7 +207,7 @@ public class AccordConfigurationServiceTest
         ValidatingClusterMetadataService cms = ValidatingClusterMetadataService.createAndRegister(Version.MIN_ACCORD_VERSION);
 
         InMemoryJournal journal = new InMemoryJournal(ID1, new TestAgent());
-        AccordConfigurationService service = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks, journal);
+        AccordConfigurationService service = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks);
         TestListener listener = new TestListener(service, true) {
             @Override
             public AsyncResult<Void> onTopologyUpdate(Topology topology, boolean isLoad, boolean startSync)
@@ -234,7 +234,7 @@ public class AccordConfigurationServiceTest
         Topology topology3 = createTopology(cms);
         service.reportTopology(topology3);
 
-        AccordConfigurationService loaded = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks, journal);
+        AccordConfigurationService loaded = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks);
         loaded.updateMapping(mappingForEpoch(cms.metadata().epoch.getEpoch() + 1));
         listener = new AbstractConfigurationServiceTest.TestListener(loaded, true);
         loaded.registerListener(listener);
@@ -259,7 +259,7 @@ public class AccordConfigurationServiceTest
     {
         ValidatingClusterMetadataService cms = ValidatingClusterMetadataService.createAndRegister(Version.MIN_ACCORD_VERSION);
         InMemoryJournal journal = new InMemoryJournal(ID1, new TestAgent());
-        AccordConfigurationService service = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks, journal);
+        AccordConfigurationService service = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks);
         TestListener serviceListener = new TestListener(service, true) {
             @Override
             public AsyncResult<Void> onTopologyUpdate(Topology topology, boolean isLoad, boolean startSync)
@@ -286,7 +286,7 @@ public class AccordConfigurationServiceTest
         Assert.assertEquals(EpochDiskState.create(3), service.diskState());
         serviceListener.assertTruncates(3L);
 
-        AccordConfigurationService loaded = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks, journal);
+        AccordConfigurationService loaded = new AccordConfigurationService(ID1, new Messaging(), new MockFailureDetector(), AccordConfigurationService.SystemTableDiskStateManager.instance, ScheduledExecutors.scheduledTasks);
         loaded.updateMapping(mappingForEpoch(cms.metadata().epoch.getEpoch() + 1));
         TestListener loadListener = new TestListener(loaded, true);
         loaded.registerListener(loadListener);
diff --git a/test/unit/org/apache/cassandra/service/accord/AccordMessageSinkTest.java b/test/unit/org/apache/cassandra/service/accord/AccordMessageSinkTest.java
index 2d3551851b..4bfbeb8a6f 100644
--- a/test/unit/org/apache/cassandra/service/accord/AccordMessageSinkTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/AccordMessageSinkTest.java
@@ -97,7 +97,7 @@ public class AccordMessageSinkTest
         TxnId txnId = nextTxnId(42, Txn.Kind.Read, Routable.Domain.Key);
         Request request = new ReadTxnData(node, topologies, txnId, topology.ranges(), txnId.epoch());
         checkRequestReplies(request,
-                            new ReadData.ReadOk(null, null),
+                            new ReadData.ReadOk(null, null, 0),
                             CommitOrReadNack.Insufficient);
     }
 
diff --git a/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java b/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java
index 0fdd8debb2..ba6a9ebbc1 100644
--- a/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/AccordSyncPropagatorTest.java
@@ -478,9 +478,9 @@ public class AccordSyncPropagatorTest
             }
 
             @Override
-            public synchronized void receiveRedundant(Ranges ranges, long epoch)
+            public synchronized void receiveRetired(Ranges ranges, long epoch)
             {
-                super.receiveRedundant(ranges, epoch);
+                super.receiveRetired(ranges, epoch);
                 redundant.merge(epoch, ranges, Ranges::with);
             }
         }
diff --git a/test/unit/org/apache/cassandra/service/accord/CommandChangeTest.java b/test/unit/org/apache/cassandra/service/accord/CommandChangeTest.java
index f188affea9..40d75816d3 100644
--- a/test/unit/org/apache/cassandra/service/accord/CommandChangeTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/CommandChangeTest.java
@@ -122,10 +122,10 @@ public class CommandChangeTest
         SoftAssertions checks = new SoftAssertions();
         for (Field field : missing)
         {
-            checks.assertThat(CommandChange.getFieldChanged(field, flags))
+            checks.assertThat(CommandChange.isChanged(field, flags))
                   .describedAs("field %s changed", field).
                   isTrue();
-            checks.assertThat(CommandChange.getFieldIsNull(field, flags))
+            checks.assertThat(CommandChange.isNull(field, flags))
                   .describedAs("field %s not null", field)
                   .isFalse();
         }
@@ -138,11 +138,11 @@ public class CommandChangeTest
         for (Field field : missing)
         {
             if (field == Field.CLEANUP) continue;
-            checks.assertThat(CommandChange.getFieldChanged(field, flags))
+            checks.assertThat(CommandChange.isChanged(field, flags))
                   .describedAs("field %s changed", field)
                   .isFalse();
             // Is null flag can not be set on a field that has not changed
-            checks.assertThat(CommandChange.getFieldIsNull(field, flags))
+            checks.assertThat(CommandChange.isNull(field, flags))
                   .describedAs("field %s not null", field)
                   .isFalse();
         }
diff --git a/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java b/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java
index 66c8ead4e5..14f5b67056 100644
--- a/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/EpochSyncTest.java
@@ -672,7 +672,7 @@ public class EpochSyncTest
                 this.topology = new TopologyManager(SizeOfIntersectionSorter.SUPPLIER, new TestAgent.RethrowAgent(), id, Scheduler.NEVER_RUN_SCHEDULED, TimeService.ofNonMonotonic(globalExecutor::currentTimeMillis, TimeUnit.MILLISECONDS), LocalConfig.DEFAULT);
                 AccordConfigurationService.DiskStateManager instance = MockDiskStateManager.instance;
                 Journal journal = null; // TODO
-                config = new AccordConfigurationService(node, messagingService, failureDetector, instance, scheduler, journal);
+                config = new AccordConfigurationService(node, messagingService, failureDetector, instance, scheduler);
                 config.registerListener(new ConfigurationService.Listener()
                 {
                     @Override
@@ -718,7 +718,7 @@ public class EpochSyncTest
                     }
 
                     @Override
-                    public void onEpochRedundant(Ranges ranges, long epoch)
+                    public void onEpochRetired(Ranges ranges, long epoch)
                     {
                         topology.onEpochRedundant(ranges, epoch);
                     }
diff --git a/test/unit/org/apache/cassandra/service/accord/LoggingDiskStateManager.java b/test/unit/org/apache/cassandra/service/accord/LoggingDiskStateManager.java
index 10f9af4f85..5c8f24de9a 100644
--- a/test/unit/org/apache/cassandra/service/accord/LoggingDiskStateManager.java
+++ b/test/unit/org/apache/cassandra/service/accord/LoggingDiskStateManager.java
@@ -33,7 +33,8 @@ import java.util.Set;
  */
 @SuppressWarnings("unused")
 @VisibleForTesting
-public class LoggingDiskStateManager implements AccordConfigurationService.DiskStateManager {
+public class LoggingDiskStateManager implements AccordConfigurationService.DiskStateManager
+{
     private static final Logger logger = LoggerFactory.getLogger(LoggingDiskStateManager.class);
     private final Node.Id self;
     private final AccordConfigurationService.DiskStateManager delegate;
@@ -85,6 +86,13 @@ public class LoggingDiskStateManager implements AccordConfigurationService.DiskS
         return delegate.markClosed(ranges, epoch, diskState);
     }
 
+    @Override
+    public AccordKeyspace.EpochDiskState markRetired(Ranges ranges, long epoch, AccordKeyspace.EpochDiskState diskState)
+    {
+        logger.info("[node={}] Calling markRetired({}, {}, {})", self, ranges, epoch, diskState);
+        return delegate.markRetired(ranges, epoch, diskState);
+    }
+
     @Override
     public AccordKeyspace.EpochDiskState truncateTopologyUntil(long epoch, AccordKeyspace.EpochDiskState diskState) {
         logger.info("[node={}] Calling truncateTopologyUntil({}, {})", self, epoch, diskState);
diff --git a/test/unit/org/apache/cassandra/service/accord/MockDiskStateManager.java b/test/unit/org/apache/cassandra/service/accord/MockDiskStateManager.java
index 64bb9af180..88178a55ab 100644
--- a/test/unit/org/apache/cassandra/service/accord/MockDiskStateManager.java
+++ b/test/unit/org/apache/cassandra/service/accord/MockDiskStateManager.java
@@ -25,50 +25,66 @@ import accord.utils.Invariants;
 
 import java.util.Set;
 
-public enum MockDiskStateManager implements AccordConfigurationService.DiskStateManager {
+public enum MockDiskStateManager implements AccordConfigurationService.DiskStateManager
+{
     instance;
 
     @Override
-    public AccordKeyspace.EpochDiskState loadLocalTopologyState(AccordKeyspace.TopologyLoadConsumer consumer) {
+    public AccordKeyspace.EpochDiskState loadLocalTopologyState(AccordKeyspace.TopologyLoadConsumer consumer)
+    {
         return AccordKeyspace.EpochDiskState.EMPTY;
     }
 
     @Override
-    public AccordKeyspace.EpochDiskState setNotifyingLocalSync(long epoch, Set<Node.Id> pending, AccordKeyspace.EpochDiskState diskState) {
+    public AccordKeyspace.EpochDiskState setNotifyingLocalSync(long epoch, Set<Node.Id> pending, AccordKeyspace.EpochDiskState diskState)
+    {
         return maybeUpdateMaxEpoch(diskState, epoch);
     }
 
     @Override
-    public AccordKeyspace.EpochDiskState setCompletedLocalSync(long epoch, AccordKeyspace.EpochDiskState diskState) {
+    public AccordKeyspace.EpochDiskState setCompletedLocalSync(long epoch, AccordKeyspace.EpochDiskState diskState)
+    {
         return maybeUpdateMaxEpoch(diskState, epoch);
     }
 
     @Override
-    public AccordKeyspace.EpochDiskState markLocalSyncAck(Node.Id id, long epoch, AccordKeyspace.EpochDiskState diskState) {
+    public AccordKeyspace.EpochDiskState markLocalSyncAck(Node.Id id, long epoch, AccordKeyspace.EpochDiskState diskState)
+    {
         return maybeUpdateMaxEpoch(diskState, epoch);
     }
 
     @Override
-    public AccordKeyspace.EpochDiskState saveTopology(Topology topology, AccordKeyspace.EpochDiskState diskState) {
+    public AccordKeyspace.EpochDiskState saveTopology(Topology topology, AccordKeyspace.EpochDiskState diskState)
+    {
         return maybeUpdateMaxEpoch(diskState, topology.epoch());
     }
 
     @Override
-    public AccordKeyspace.EpochDiskState markRemoteTopologySync(Node.Id node, long epoch, AccordKeyspace.EpochDiskState diskState) {
+    public AccordKeyspace.EpochDiskState markRemoteTopologySync(Node.Id node, long epoch, AccordKeyspace.EpochDiskState diskState)
+    {
         return maybeUpdateMaxEpoch(diskState, epoch);
     }
 
     @Override
-    public AccordKeyspace.EpochDiskState markClosed(Ranges ranges, long epoch, AccordKeyspace.EpochDiskState diskState) {
+    public AccordKeyspace.EpochDiskState markClosed(Ranges ranges, long epoch, AccordKeyspace.EpochDiskState diskState)
+    {
         return maybeUpdateMaxEpoch(diskState, epoch);
     }
 
     @Override
-    public AccordKeyspace.EpochDiskState truncateTopologyUntil(long epoch, AccordKeyspace.EpochDiskState diskState) {
+    public AccordKeyspace.EpochDiskState markRetired(Ranges ranges, long epoch, AccordKeyspace.EpochDiskState diskState)
+    {
         return maybeUpdateMaxEpoch(diskState, epoch);
     }
 
-    private static AccordKeyspace.EpochDiskState maybeUpdateMaxEpoch(AccordKeyspace.EpochDiskState diskState, long epoch) {
+    @Override
+    public AccordKeyspace.EpochDiskState truncateTopologyUntil(long epoch, AccordKeyspace.EpochDiskState diskState)
+    {
+        return maybeUpdateMaxEpoch(diskState, epoch);
+    }
+
+    private static AccordKeyspace.EpochDiskState maybeUpdateMaxEpoch(AccordKeyspace.EpochDiskState diskState, long epoch)
+    {
         if (diskState.isEmpty())
             return AccordKeyspace.EpochDiskState.create(epoch);
         Invariants.checkArgument(epoch >= diskState.minEpoch, "Epoch %d < %d (min)", epoch, diskState.minEpoch);
diff --git a/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java b/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java
index 43cd4402e7..abaed8349e 100644
--- a/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java
+++ b/test/unit/org/apache/cassandra/service/accord/SimulatedAccordCommandStore.java
@@ -298,7 +298,7 @@ public class SimulatedAccordCommandStore implements AutoCloseable
                 {
                     Command command = (Command) state.getExclusive();
                     if (command != null && command.known().isDefinitionKnown()
-                        && (command.partialTxn().keys().intersects(keys) || ranges.intersects(command.partialTxn().keys()))
+                        && (command.partialTxn().keys().intersects(keys) || command.partialTxn().keys().intersects(ranges))
                         && shouldEvict.getAsBoolean())
                         cache.tryEvict(state);
                 }
diff --git a/test/unit/org/apache/cassandra/service/accord/serializers/CommandsForKeySerializerTest.java b/test/unit/org/apache/cassandra/service/accord/serializers/CommandsForKeySerializerTest.java
index 91d3a8b232..a6a3531d8a 100644
--- a/test/unit/org/apache/cassandra/service/accord/serializers/CommandsForKeySerializerTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/serializers/CommandsForKeySerializerTest.java
@@ -305,7 +305,7 @@ public class CommandsForKeySerializerTest
         Arrays.sort(cmds, Comparator.comparing(o -> o.txnId));
         for (int i = 0 ; i < txnIdCount ; ++i)
         {
-            if (!cmds[i].saveStatus.known.deps().hasProposedOrDecidedDeps())
+            if (!cmds[i].saveStatus.known.deps().hasPreAcceptedOrProposedOrDecidedDeps())
                 continue;
 
             Timestamp knownBefore = cmds[i].saveStatus.known.deps().hasCommittedOrDecidedDeps() ? cmds[i].executeAt : cmds[i].txnId;
@@ -404,7 +404,7 @@ public class CommandsForKeySerializerTest
     @Test
     public void serde()
     {
-        testOne(3466420662549679178L);
+        testOne(629993588068216851L);
         Random random = new Random();
         for (int i = 0 ; i < 10000 ; ++i)
         {
@@ -530,6 +530,7 @@ public class CommandsForKeySerializerTest
                 ++i;
             }
 
+            cfk = cfk.updateUniqueHlc(source.nextLong(Long.MAX_VALUE));
             ByteBuffer buffer = Serialize.toBytesWithoutKey(cfk);
             CommandsForKey roundTrip = Serialize.fromBytes(key, buffer);
             Assert.assertEquals(cfk, roundTrip);
@@ -590,7 +591,8 @@ public class CommandsForKeySerializerTest
             }
             else unmanaged = CommandsForKey.NO_PENDING_UNMANAGED;
 
-            CommandsForKey expected = CommandsForKey.SerializerSupport.create(pk, info, 0, unmanaged, TxnId.NONE, NO_BOUNDS_INFO);
+            long maxUniqueHlc = rs.nextLong(0, Long.MAX_VALUE);
+            CommandsForKey expected = CommandsForKey.SerializerSupport.create(pk, info, maxUniqueHlc, unmanaged, TxnId.NONE, NO_BOUNDS_INFO);
 
             ByteBuffer buffer = Serialize.toBytesWithoutKey(expected);
             CommandsForKey roundTrip = Serialize.fromBytes(pk, buffer);
diff --git a/test/unit/org/apache/cassandra/service/accord/serializers/WaitingOnSerializerTest.java b/test/unit/org/apache/cassandra/service/accord/serializers/WaitingOnSerializerTest.java
index 2820760c07..e481e83940 100644
--- a/test/unit/org/apache/cassandra/service/accord/serializers/WaitingOnSerializerTest.java
+++ b/test/unit/org/apache/cassandra/service/accord/serializers/WaitingOnSerializerTest.java
@@ -25,7 +25,10 @@ import org.junit.Test;
 
 import accord.local.Command;
 import accord.primitives.Deps;
+import accord.primitives.KeyDeps;
+import accord.primitives.PartialDeps;
 import accord.primitives.Routable;
+import accord.primitives.RoutingKeys;
 import accord.primitives.TxnId;
 import accord.utils.Gen;
 import accord.utils.Gens;
@@ -33,6 +36,8 @@ import accord.utils.SimpleBitSet;
 import accord.utils.Utils;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.io.util.DataInputBuffer;
+import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.utils.AccordGenerators;
 import org.apache.cassandra.utils.CassandraGenerators;
 import org.assertj.core.api.Assertions;
@@ -54,13 +59,24 @@ public class WaitingOnSerializerTest
         qt().forAll(waitingOnGen()).check(waitingOn -> {
             TxnId txnId = TxnId.NONE;
             if (waitingOn.appliedOrInvalidated != null) txnId = new TxnId(txnId.epoch(), txnId.hlc(), txnId.kind(), Routable.Domain.Range, txnId.node);
-            long expectedSize = WaitingOnSerializer.serializedSize(txnId, waitingOn);
-            ByteBuffer bb = WaitingOnSerializer.serialize(txnId, waitingOn);
-            Assertions.assertThat(bb.remaining()).isEqualTo(expectedSize);
-            Command.WaitingOn read = WaitingOnSerializer.deserialize(txnId, waitingOn.keys, waitingOn.directRangeDeps, waitingOn.directKeyDeps, bb);
-            Assertions.assertThat(read)
-                      .isEqualTo(waitingOn)
-                      .isEqualTo(WaitingOnSerializer.deserialize(txnId, waitingOn.keys, waitingOn.directRangeDeps, waitingOn.directKeyDeps, WaitingOnSerializer.serialize(txnId, waitingOn)));
+            ByteBuffer bb;
+            try (DataOutputBuffer buf = new DataOutputBuffer())
+            {
+                WaitingOnSerializer.serializeBitSetsOnly(txnId, waitingOn, buf);
+                bb = buf.asNewBuffer();
+            }
+            try (DataInputBuffer buf = new DataInputBuffer(bb, true))
+            {
+                PartialDeps deps = new PartialDeps(RoutingKeys.EMPTY, KeyDeps.none(waitingOn.keys), waitingOn.directRangeDeps, waitingOn.directKeyDeps);
+                Command.WaitingOn read = WaitingOnSerializer.deserializeProvider(txnId, buf).provide(txnId, deps, null, 0);
+                Assertions.assertThat(read).isEqualTo(waitingOn);
+                Assertions.assertThat(buf.available()).isEqualTo(0);
+            }
+            try (DataInputBuffer buf = new DataInputBuffer(bb, true))
+            {
+                WaitingOnSerializer.skip(txnId, buf);
+                Assertions.assertThat(buf.available()).isEqualTo(0);
+            }
         });
     }
 
diff --git a/test/unit/org/apache/cassandra/utils/AccordGenerators.java b/test/unit/org/apache/cassandra/utils/AccordGenerators.java
index 026d2c26f8..fef3f9a83f 100644
--- a/test/unit/org/apache/cassandra/utils/AccordGenerators.java
+++ b/test/unit/org/apache/cassandra/utils/AccordGenerators.java
@@ -301,7 +301,7 @@ public class AccordGenerators
                     else return Command.Truncated.truncatedApply(attributes(saveStatus), saveStatus, executeAt, txnId.is(Write) ? new Writes(txnId, executeAt, keysOrRanges, new TxnWrite(Collections.emptyList(), true)) : null, new TxnData());
 
                 case Erased:
-                case ErasedOrVestigial:
+                case Vestigial:
                 case Invalidated:
                     return Command.Truncated.invalidated(txnId, attributes(saveStatus).participants());
             }
