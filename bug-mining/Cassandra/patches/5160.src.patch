diff --git a/src/java/org/apache/cassandra/audit/AuditEvent.java b/src/java/org/apache/cassandra/audit/AuditEvent.java
index b21fe58712..d59114e92c 100644
--- a/src/java/org/apache/cassandra/audit/AuditEvent.java
+++ b/src/java/org/apache/cassandra/audit/AuditEvent.java
@@ -26,7 +26,7 @@ import org.apache.cassandra.diag.DiagnosticEvent;
 import org.apache.cassandra.diag.DiagnosticEventService;
 
 /**
- * {@Link AuditLogEntry} wrapper to expose audit events as {@link DiagnosticEvent}s.
+ * {@link AuditLogEntry} wrapper to expose audit events as {@link DiagnosticEvent}s.
  */
 public final class AuditEvent extends DiagnosticEvent
 {
diff --git a/src/java/org/apache/cassandra/audit/AuditLogFilter.java b/src/java/org/apache/cassandra/audit/AuditLogFilter.java
index 163114d9b9..71c224d940 100644
--- a/src/java/org/apache/cassandra/audit/AuditLogFilter.java
+++ b/src/java/org/apache/cassandra/audit/AuditLogFilter.java
@@ -50,6 +50,9 @@ public class AuditLogFilter
 
     /**
      * (Re-)Loads filters from config. Called during startup as well as JMX invocations.
+     *
+     * @param auditLogOptions
+     * @return
      */
     public static AuditLogFilter create(AuditLogOptions auditLogOptions)
     {
diff --git a/src/java/org/apache/cassandra/audit/AuditLogManager.java b/src/java/org/apache/cassandra/audit/AuditLogManager.java
index d11eaa0ee7..1e1337e568 100644
--- a/src/java/org/apache/cassandra/audit/AuditLogManager.java
+++ b/src/java/org/apache/cassandra/audit/AuditLogManager.java
@@ -181,6 +181,14 @@ public class AuditLogManager
 
     /**
      * Logs Batch queries to both FQL and standard audit logger.
+     *
+     * @param type The type of the batch
+     * @param queryOrIdList
+     * @param values Values to bind to as parameters for the queries
+     * @param prepared Prepared statement
+     * @param options Options associated with the query invocation
+     * @param state Timestamp state associated with the query invocation
+     * @param queryStartTimeMillis Timestamp when the query was started
      */
     public void logBatch(BatchStatement.Type type,
                          List<Object> queryOrIdList,
@@ -287,6 +295,18 @@ public class AuditLogManager
         oldLogger.stop();
     }
 
+
+    /**
+     * Configure FQL
+     *
+     * @param path Path to store FQL files
+     * @param rollCycle How often to roll FQL log segments so they can potentially be reclaimed
+     * @param blocking Whether the FQL should block if the FQL falls behind or should drop log records
+     * @param maxQueueWeight Maximum weight of in memory queue for records waiting to be written to the file before blocking or dropping
+     * @param maxLogSize Maximum size of the rolled files to retain on disk before deleting the oldest file
+     * @param archiveCommand the archive command to execute on rolled log files
+     * @param maxArchiveRetries max number of retries of failed archive commands
+     */
     public void configureFQL(Path path, String rollCycle, boolean blocking, int maxQueueWeight, long maxLogSize, String archiveCommand, int maxArchiveRetries)
     {
         if (path.equals(auditLogger.path()))
@@ -311,6 +331,7 @@ public class AuditLogManager
     /**
      * ONLY FOR TESTING
      */
+    @VisibleForTesting
     FullQueryLogger getFullQueryLogger()
     {
         return fullQueryLogger;
diff --git a/src/java/org/apache/cassandra/auth/AuthCache.java b/src/java/org/apache/cassandra/auth/AuthCache.java
index 4bf15c1490..6d7e31d078 100644
--- a/src/java/org/apache/cassandra/auth/AuthCache.java
+++ b/src/java/org/apache/cassandra/auth/AuthCache.java
@@ -57,9 +57,11 @@ public class AuthCache<K, V> implements AuthCacheMBean
 
     /**
      * @param name Used for MBean
-     * @param setValidityDelegate Used to set cache validity period. See {@link Policy#expireAfterWrite()}
+     * @param setValidityDelegate Used to set cache validity period.
+     *                            See {@link Caffeine#expireAfterAccess}
      * @param getValidityDelegate Getter for validity period
-     * @param setUpdateIntervalDelegate Used to set cache update interval. See {@link Policy#refreshAfterWrite()}
+     * @param setUpdateIntervalDelegate Used to set cache update interval.
+     *                                  See {@link Caffeine#refreshAfterWrite}
      * @param getUpdateIntervalDelegate Getter for update interval
      * @param setMaxEntriesDelegate Used to set max # entries in cache. See {@link com.github.benmanes.caffeine.cache.Policy.Eviction#setMaximum(long)}
      * @param getMaxEntriesDelegate Getter for max entries.
diff --git a/src/java/org/apache/cassandra/auth/Role.java b/src/java/org/apache/cassandra/auth/Role.java
index e98cc7ddf1..f826aea7f3 100644
--- a/src/java/org/apache/cassandra/auth/Role.java
+++ b/src/java/org/apache/cassandra/auth/Role.java
@@ -30,8 +30,8 @@ public class Role
     /**
      * Represents a user or group in the auth subsystem.
      * Roles may be members of other roles, but circular graphs of roles are not permitted.
-     * The reason that memberOf is a Set<String> and not Set<Role> is to simplify loading
-     * for IRoleManager implementations (in particular, CassandraRoleManager)
+     * The reason that memberOf is a {@code Set<String>} and not {@code Set<Role>} is to simplify loading
+     * for {@link IRoleManager} implementations (in particular, {@link CassandraRoleManager})
      */
 
     public final RoleResource resource ;
diff --git a/src/java/org/apache/cassandra/auth/Roles.java b/src/java/org/apache/cassandra/auth/Roles.java
index 22eb0d31e8..243d06e12a 100644
--- a/src/java/org/apache/cassandra/auth/Roles.java
+++ b/src/java/org/apache/cassandra/auth/Roles.java
@@ -70,7 +70,7 @@ public class Roles
      * Get detailed info on all the roles granted to the role identified by the supplied RoleResource.
      * This includes superuser status and login privileges for the primary role and all roles granted directly
      * to it or inherited.
-     * The returnred roles may be cached if roles_validity_in_ms > 0
+     * The returnred roles may be cached if {@code roles_validity_in_ms > 0}
      * This method is used where we need to know specific attributes of the collection of granted roles, i.e.
      * when checking for superuser status which may be inherited from *any* granted role.
      *
@@ -117,7 +117,7 @@ public class Roles
      * Returns the map of custom options for the named role. These options are not inherited from granted roles, but
      * are set directly.
      * @param role the role identifier
-     * @return map of option_name -> value. If no options are set for the named role, the map will be empty
+     * @return map of {@code option_name -> value}. If no options are set for the named role, the map will be empty
      * but never null.
      */
     public static Map<String, String> getOptions(RoleResource role)
diff --git a/src/java/org/apache/cassandra/config/Config.java b/src/java/org/apache/cassandra/config/Config.java
index 7371df7961..99e15bed73 100644
--- a/src/java/org/apache/cassandra/config/Config.java
+++ b/src/java/org/apache/cassandra/config/Config.java
@@ -423,8 +423,8 @@ public class Config
 
     /**
      * flags for enabling tracking repaired state of data during reads
-     * separate flags for range & single partition reads as single partition reads are only tracked
-     * when CL > 1 and a digest mismatch occurs. Currently, range queries don't use digests so if
+     * separate flags for range &amp; single partition reads as single partition reads are only tracked
+     * when {@code CL > 1} and a digest mismatch occurs. Currently, range queries don't use digests so if
      * enabled for range reads, all such reads will include repaired data tracking. As this adds
      * some overhead, operators may wish to disable it whilst still enabling it for partition reads
      */
diff --git a/src/java/org/apache/cassandra/cql3/Terms.java b/src/java/org/apache/cassandra/cql3/Terms.java
index 33ce2e9616..cfd968f309 100644
--- a/src/java/org/apache/cassandra/cql3/Terms.java
+++ b/src/java/org/apache/cassandra/cql3/Terms.java
@@ -197,7 +197,7 @@ public interface Terms
     /**
      * Creates a {@code Terms} containing a set of {@code Term}.
      *
-     * @param term the {@code Term}
+     * @param terms {@code List<Term>}
      * @return a {@code Terms} containing a set of {@code Term}.
      */
     public static Terms of(final List<Term> terms)
diff --git a/src/java/org/apache/cassandra/cql3/functions/TimeFcts.java b/src/java/org/apache/cassandra/cql3/functions/TimeFcts.java
index f029e59de8..045c009dcc 100644
--- a/src/java/org/apache/cassandra/cql3/functions/TimeFcts.java
+++ b/src/java/org/apache/cassandra/cql3/functions/TimeFcts.java
@@ -92,7 +92,7 @@ public abstract class TimeFcts
 
     /**
      * Function that convert a value of <code>TIMEUUID</code> into a value of type <code>TIMESTAMP</code>.
-     * @deprecated Replaced by the {@link #timeUuidToTimestamp} function
+     * @deprecated Replaced by the {@link #toUnixTimestamp} function
      */
     public static final NativeScalarFunction dateOfFct = new NativeScalarFunction("dateof", TimestampType.instance, TimeUUIDType.instance)
     {
@@ -118,7 +118,7 @@ public abstract class TimeFcts
 
     /**
      * Function that convert a value of type <code>TIMEUUID</code> into an UNIX timestamp.
-     * @deprecated Replaced by the {@link #timeUuidToUnixTimestamp} function
+     * @deprecated Replaced by the {@link #toUnixTimestamp} function
      */
     public static final NativeScalarFunction unixTimestampOfFct = new NativeScalarFunction("unixtimestampof", LongType.instance, TimeUUIDType.instance)
     {
diff --git a/src/java/org/apache/cassandra/cql3/selection/Selector.java b/src/java/org/apache/cassandra/cql3/selection/Selector.java
index 3262b9c9e1..985c7c5e98 100644
--- a/src/java/org/apache/cassandra/cql3/selection/Selector.java
+++ b/src/java/org/apache/cassandra/cql3/selection/Selector.java
@@ -108,7 +108,6 @@ public abstract class Selector
         /**
          * Checks if this factory creates <code>Selector</code>s that simply return a column value.
          *
-         * @param index the column index
          * @return <code>true</code> if this factory creates <code>Selector</code>s that simply return a column value,
          * <code>false</code> otherwise.
          */
diff --git a/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java b/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
index c348cc4f8a..27e90a84fe 100644
--- a/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
@@ -90,7 +90,7 @@ public abstract class AlterTableStatement extends AlterSchemaStatement
     abstract KeyspaceMetadata apply(KeyspaceMetadata keyspace, TableMetadata table);
 
     /**
-     * ALTER TABLE <table> ALTER <column> TYPE <newtype>;
+     * {@code ALTER TABLE <table> ALTER <column> TYPE <newtype>;}
      *
      * No longer supported.
      */
diff --git a/src/java/org/apache/cassandra/db/ColumnFamilyStoreMBean.java b/src/java/org/apache/cassandra/db/ColumnFamilyStoreMBean.java
index fb0d611dcc..23c2e2496a 100644
--- a/src/java/org/apache/cassandra/db/ColumnFamilyStoreMBean.java
+++ b/src/java/org/apache/cassandra/db/ColumnFamilyStoreMBean.java
@@ -152,7 +152,6 @@ public interface ColumnFamilyStoreMBean
      * @param verifySSTables if the new sstables should be verified that they are not corrupt
      * @param verifyTokens if the tokens in the new sstables should be verified that they are owned by the current node
      * @param invalidateCaches if row cache should be invalidated for the keys in the new sstables
-     * @param jbodCheck if the new sstables should be placed 'optimally' - count tokens and move the sstable to the directory where it has the most keys
      * @param extendedVerify if we should run an extended verify checking all values in the new sstables
      *
      * @return list of failed import directories
diff --git a/src/java/org/apache/cassandra/db/LivenessInfo.java b/src/java/org/apache/cassandra/db/LivenessInfo.java
index 1340c00caf..60027946cd 100644
--- a/src/java/org/apache/cassandra/db/LivenessInfo.java
+++ b/src/java/org/apache/cassandra/db/LivenessInfo.java
@@ -183,11 +183,11 @@ public class LivenessInfo
      * Whether this liveness information supersedes another one (that is
      * whether is has a greater timestamp than the other or not).
      *
-     * </br>
+     * <br>
      *
      * If timestamps are the same and none of them are expired livenessInfo,
      * livenessInfo with greater TTL supersedes another. It also means, if timestamps are the same,
-     * ttl superseders no-ttl. This is the same rule as {@link Conflicts#resolveRegular}
+     * ttl superseders no-ttl. This is the same rule as {@link org.apache.cassandra.db.rows.Cells#resolveRegular}
      *
      * If timestamps are the same and one of them is expired livenessInfo. Expired livenessInfo
      * supersedes, ie. tombstone supersedes.
diff --git a/src/java/org/apache/cassandra/db/compaction/ActiveCompactions.java b/src/java/org/apache/cassandra/db/compaction/ActiveCompactions.java
index bba06017e9..07319a03eb 100644
--- a/src/java/org/apache/cassandra/db/compaction/ActiveCompactions.java
+++ b/src/java/org/apache/cassandra/db/compaction/ActiveCompactions.java
@@ -51,7 +51,7 @@ public class ActiveCompactions implements ActiveCompactionsTracker
     /**
      * Iterates over the active compactions and tries to find the CompactionInfo for the given sstable
      *
-     * Number of entries in compactions should be small (< 10) but avoid calling in any time-sensitive context
+     * Number of entries in compactions should be small ({@code < 10}) but avoid calling in any time-sensitive context
      */
     public CompactionInfo getCompactionForSSTable(SSTableReader sstable)
     {
diff --git a/src/java/org/apache/cassandra/db/compaction/CompactionManager.java b/src/java/org/apache/cassandra/db/compaction/CompactionManager.java
index 01e3aa6ddb..2a2d18b30c 100644
--- a/src/java/org/apache/cassandra/db/compaction/CompactionManager.java
+++ b/src/java/org/apache/cassandra/db/compaction/CompactionManager.java
@@ -717,7 +717,6 @@ public class CompactionManager implements CompactionManagerMBean
      * @param replicas token ranges to be repaired
      * @param validatedForRepair SSTables containing the repaired ranges. Should be referenced before passing them.
      * @param sessionID the repair session we're anti-compacting for
-     * @throws InterruptedException
      * @throws IOException
      */
     public void performAnticompaction(ColumnFamilyStore cfs,
diff --git a/src/java/org/apache/cassandra/db/compaction/CompactionStrategyManager.java b/src/java/org/apache/cassandra/db/compaction/CompactionStrategyManager.java
index b978641859..5e27f2f61e 100644
--- a/src/java/org/apache/cassandra/db/compaction/CompactionStrategyManager.java
+++ b/src/java/org/apache/cassandra/db/compaction/CompactionStrategyManager.java
@@ -85,13 +85,13 @@ import static org.apache.cassandra.db.compaction.AbstractStrategyHolder.GroupedS
  * pending repair id.
  *
  * Operations on this class are guarded by a {@link ReentrantReadWriteLock}. This lock performs mutual exclusion on
- * reads and writes to the following variables: {@link this#repaired}, {@link this#unrepaired}, {@link this#isActive},
- * {@link this#params}, {@link this#currentBoundaries}. Whenever performing reads on these variables,
- * the {@link this#readLock} should be acquired. Likewise, updates to these variables should be guarded by
- * {@link this#writeLock}.
+ * reads and writes to the following variables: {@link CompactionStrategyManager#repaired}, {@link CompactionStrategyManager#unrepaired}, {@link CompactionStrategyManager#isActive},
+ * {@link CompactionStrategyManager#params}, {@link CompactionStrategyManager#currentBoundaries}. Whenever performing reads on these variables,
+ * the {@link CompactionStrategyManager#readLock} should be acquired. Likewise, updates to these variables should be guarded by
+ * {@link CompactionStrategyManager#writeLock}.
  *
  * Whenever the {@link DiskBoundaries} change, the compaction strategies must be reloaded, so in order to ensure
- * the compaction strategy placement reflect most up-to-date disk boundaries, call {@link this#maybeReloadDiskBoundaries()}
+ * the compaction strategy placement reflect most up-to-date disk boundaries, call {@link CompactionStrategyManager#maybeReloadDiskBoundaries()}
  * before acquiring the read lock to acess the strategies.
  *
  */
@@ -470,11 +470,11 @@ public class CompactionStrategyManager implements INotificationConsumer
      * Checks if the disk boundaries changed and reloads the compaction strategies
      * to reflect the most up-to-date disk boundaries.
      *
-     * This is typically called before acquiring the {@link this#readLock} to ensure the most up-to-date
+     * This is typically called before acquiring the {@link CompactionStrategyManager#readLock} to ensure the most up-to-date
      * disk locations and boundaries are used.
      *
-     * This should *never* be called inside by a thread holding the {@link this#readLock}, since it
-     * will potentially acquire the {@link this#writeLock} to update the compaction strategies
+     * This should *never* be called inside by a thread holding the {@link CompactionStrategyManager#readLock}, since it
+     * will potentially acquire the {@link CompactionStrategyManager#writeLock} to update the compaction strategies
      * what can cause a deadlock.
      */
     //TODO improve this to reload after receiving a notification rather than trying to reload on every operation
diff --git a/src/java/org/apache/cassandra/db/filter/DataLimits.java b/src/java/org/apache/cassandra/db/filter/DataLimits.java
index 50baf2170a..a4000f85e5 100644
--- a/src/java/org/apache/cassandra/db/filter/DataLimits.java
+++ b/src/java/org/apache/cassandra/db/filter/DataLimits.java
@@ -155,7 +155,7 @@ public abstract class DataLimits
      * @param countPartitionsWithOnlyStaticData if {@code true} the partitions with only static data should be counted
      * as 1 valid row.
      * @param enforceStrictLiveness whether the row should be purged if there is no PK liveness info,
-     *                              normally retrieved from {@link CFMetaData#enforceStrictLiveness()}
+     *                              normally retrieved from {@link org.apache.cassandra.schema.TableMetadata#enforceStrictLiveness()}
      * @return a new {@code Counter} for this limits.
      */
     public abstract Counter newCounter(int nowInSec,
diff --git a/src/java/org/apache/cassandra/db/rows/BTreeRow.java b/src/java/org/apache/cassandra/db/rows/BTreeRow.java
index dc3219aa7c..4b5f6dcb3d 100644
--- a/src/java/org/apache/cassandra/db/rows/BTreeRow.java
+++ b/src/java/org/apache/cassandra/db/rows/BTreeRow.java
@@ -379,7 +379,7 @@ public class BTreeRow extends AbstractRow
      * Returns a copy of the row where all timestamps for live data have replaced by {@code newTimestamp} and
      * all deletion timestamp by {@code newTimestamp - 1}.
      *
-     * This exists for the Paxos path, see {@link PartitionUpdate#updateAllTimestamp} for additional details.
+     * This exists for the Paxos path, see {@link PartitionUpdate.Builder#updateAllTimestamp(long)} for additional details.
      */
     public Row updateAllTimestamp(long newTimestamp)
     {
diff --git a/src/java/org/apache/cassandra/db/rows/ColumnData.java b/src/java/org/apache/cassandra/db/rows/ColumnData.java
index f2da132f30..56f7971fa5 100644
--- a/src/java/org/apache/cassandra/db/rows/ColumnData.java
+++ b/src/java/org/apache/cassandra/db/rows/ColumnData.java
@@ -83,7 +83,7 @@ public abstract class ColumnData
      * Returns a copy of the data where all timestamps for live data have replaced by {@code newTimestamp} and
      * all deletion timestamp by {@code newTimestamp - 1}.
      *
-     * This exists for the Paxos path, see {@link PartitionUpdate#updateAllTimestamp} for additional details.
+     * This exists for the Paxos path, see {@link PartitionUpdate.Builder#updateAllTimestamp} for additional details.
      */
     public abstract ColumnData updateAllTimestamp(long newTimestamp);
 
diff --git a/src/java/org/apache/cassandra/db/rows/Row.java b/src/java/org/apache/cassandra/db/rows/Row.java
index 0174adc7ca..52c1767e4e 100644
--- a/src/java/org/apache/cassandra/db/rows/Row.java
+++ b/src/java/org/apache/cassandra/db/rows/Row.java
@@ -115,7 +115,7 @@ public interface Row extends Unfiltered, Iterable<ColumnData>
      * 
      * @param nowInSec the current time to decide what is deleted and what isn't
      * @param enforceStrictLiveness whether the row should be purged if there is no PK liveness info,
-     *                              normally retrieved from {@link CFMetaData#enforceStrictLiveness()}
+     *                              normally retrieved from {@link TableMetadata#enforceStrictLiveness()}
      * @return true if there is some live information
      */
     public boolean hasLiveData(int nowInSec, boolean enforceStrictLiveness);
diff --git a/src/java/org/apache/cassandra/db/rows/ThrottledUnfilteredIterator.java b/src/java/org/apache/cassandra/db/rows/ThrottledUnfilteredIterator.java
index a2e8425052..ebb5675e09 100644
--- a/src/java/org/apache/cassandra/db/rows/ThrottledUnfilteredIterator.java
+++ b/src/java/org/apache/cassandra/db/rows/ThrottledUnfilteredIterator.java
@@ -30,7 +30,7 @@ import org.apache.cassandra.utils.CloseableIterator;
 import com.google.common.annotations.VisibleForTesting;
 
 /**
- * A utility class to split the given {@link#UnfilteredRowIterator} into smaller chunks each
+ * A utility class to split the given {@link UnfilteredRowIterator} into smaller chunks each
  * having at most {@link #throttle} + 1 unfiltereds.
  *
  * Only the first output contains partition level info: {@link UnfilteredRowIterator#partitionLevelDeletion}
@@ -41,7 +41,7 @@ import com.google.common.annotations.VisibleForTesting;
  *
  * The lifecycle of outputed {{@link UnfilteredRowIterator} only last till next call to {@link #next()}.
  *
- * A subsequent {@link #next} call will exhaust the previously returned iterator before computing the next,
+ * A subsequent {@link ThrottledUnfilteredIterator#next} call will exhaust the previously returned iterator before computing the next,
  * effectively skipping unfiltereds up to the throttle size.
  *
  * Closing this iterator will close the underlying iterator.
diff --git a/src/java/org/apache/cassandra/db/rows/Unfiltered.java b/src/java/org/apache/cassandra/db/rows/Unfiltered.java
index 81b63b7e96..132e3962a1 100644
--- a/src/java/org/apache/cassandra/db/rows/Unfiltered.java
+++ b/src/java/org/apache/cassandra/db/rows/Unfiltered.java
@@ -41,7 +41,7 @@ public interface Unfiltered extends Clusterable
     /**
      * Digest the atom using the provided {@link Hasher}.
      *
-     * @param hasher the {@see Hasher} to use.
+     * @param hasher the {@link Hasher} to use.
      */
     public void digest(Hasher hasher);
 
diff --git a/src/java/org/apache/cassandra/dht/RangeFetchMapCalculator.java b/src/java/org/apache/cassandra/dht/RangeFetchMapCalculator.java
index 2a2de0189a..3c501babbd 100644
--- a/src/java/org/apache/cassandra/dht/RangeFetchMapCalculator.java
+++ b/src/java/org/apache/cassandra/dht/RangeFetchMapCalculator.java
@@ -62,9 +62,9 @@ import org.psjava.ds.math.Function;
  *   - if we have more machines than ranges to stream the capacity will be 1 (each machine will stream at most 1 range)
  * * Since the sum of the capacity on the edges from the super source to the range-vertices is less or equal to the sum
  *   of the capacities between the node-vertices and super sink we know that to get maximum flow we will use all the
- *   range-vertices. (Say we have x ranges, y machines to provide them, total supersource -> range-vertice capacity will be x,
- *   total node-vertice -> supersink capacity will be (y * ceil(x / y)) which worst case is x if x==y). The capacity between
- *   the range-vertices and node-vertices is infinite.
+ *   range-vertices. (Say we have x ranges, y machines to provide them, total {@code supersource -> range-vertice capacity} will be x,
+ *   total {@code node-vertice -> supersink} capacity will be {@code(y * ceil(x / y))} which worst case is x {@code if
+ *   x==y)}. The capacity between the range-vertices and node-vertices is infinite.
  * * Then we try to solve the max-flow problem using psjava
  * * If we can't find a solution where the total flow is = number of range-vertices, we bump the capacity between the node-vertices
  *   and the super source and try again.
diff --git a/src/java/org/apache/cassandra/diag/DiagnosticEvent.java b/src/java/org/apache/cassandra/diag/DiagnosticEvent.java
index 5de703bd71..bb7b625396 100644
--- a/src/java/org/apache/cassandra/diag/DiagnosticEvent.java
+++ b/src/java/org/apache/cassandra/diag/DiagnosticEvent.java
@@ -45,6 +45,8 @@ public abstract class DiagnosticEvent
      * maps, but must be Serializable, as returned values may be consumed by external clients. It's strongly recommended
      * to stick to standard Java classes to avoid distributing custom classes to clients and also prevent potential
      * class versioning conflicts.
+     *
+     * @return Returns map of key-value pairs containing relevant event details.
      */
     public abstract Map<String, Serializable> toMap();
 }
diff --git a/src/java/org/apache/cassandra/diag/LastEventIdBroadcasterMBean.java b/src/java/org/apache/cassandra/diag/LastEventIdBroadcasterMBean.java
index 03f05dce60..7fd90d6409 100644
--- a/src/java/org/apache/cassandra/diag/LastEventIdBroadcasterMBean.java
+++ b/src/java/org/apache/cassandra/diag/LastEventIdBroadcasterMBean.java
@@ -6,9 +6,8 @@ import java.util.Map;
  * Provides a list of event types and the corresponding highest event IDs. Consumers may these IDs to determine
  * if new data is available.
  *
- * <p>Example result</p>
- *
  * <table>
+ *     <caption>Example result</caption>
  *     <tr>
  *         <th>Event</th>
  *         <th>Last ID</th>
diff --git a/src/java/org/apache/cassandra/hadoop/cql3/CqlBulkOutputFormat.java b/src/java/org/apache/cassandra/hadoop/cql3/CqlBulkOutputFormat.java
index dfdf855e57..492cf9eea6 100644
--- a/src/java/org/apache/cassandra/hadoop/cql3/CqlBulkOutputFormat.java
+++ b/src/java/org/apache/cassandra/hadoop/cql3/CqlBulkOutputFormat.java
@@ -43,11 +43,8 @@ import org.apache.hadoop.util.Progressable;
  *
  * <p>
  * As is the case with the {@link org.apache.cassandra.hadoop.cql3.CqlOutputFormat}, 
- * you need to set the prepared statement in your
- * Hadoop job Configuration. The {@link CqlConfigHelper} class, through its
- * {@link org.apache.cassandra.hadoop.ConfigHelper#setOutputPreparedStatement} method, is provided to make this
- * simple.
- * you need to set the Keyspace. The {@link ConfigHelper} class, through its
+ * you need to set the prepared statement in your Hadoop job Configuration.
+ * You need to set the Keyspace. The {@link ConfigHelper} class, through its
  * {@link org.apache.cassandra.hadoop.ConfigHelper#setOutputColumnFamily} method, is provided to make this
  * simple.
  * </p>
diff --git a/src/java/org/apache/cassandra/hadoop/cql3/CqlOutputFormat.java b/src/java/org/apache/cassandra/hadoop/cql3/CqlOutputFormat.java
index cc0a6b1ce8..b2d3681644 100644
--- a/src/java/org/apache/cassandra/hadoop/cql3/CqlOutputFormat.java
+++ b/src/java/org/apache/cassandra/hadoop/cql3/CqlOutputFormat.java
@@ -34,8 +34,7 @@ import org.apache.hadoop.mapreduce.*;
  * table.
  *
  * <p>
- * As is the case with the {@link org.apache.cassandra.hadoop.ColumnFamilyInputFormat}, 
- * you need to set the prepared statement in your
+ * You need to set the prepared statement in your
  * Hadoop job Configuration. The {@link CqlConfigHelper} class, through its
  * {@link CqlConfigHelper#setOutputCql} method, is provided to make this
  * simple.
diff --git a/src/java/org/apache/cassandra/index/SecondaryIndexManager.java b/src/java/org/apache/cassandra/index/SecondaryIndexManager.java
index ec54a652a5..f9c7bc28c0 100644
--- a/src/java/org/apache/cassandra/index/SecondaryIndexManager.java
+++ b/src/java/org/apache/cassandra/index/SecondaryIndexManager.java
@@ -110,7 +110,7 @@ import org.apache.cassandra.utils.concurrent.Refs;
  * a target replica.
  * <br><br>
  * Finally, this class provides a clear and safe lifecycle to manage index builds, either full rebuilds via
- * {@link this#rebuildIndexesBlocking(Set)} or builds of new sstables
+ * {@link SecondaryIndexManager#rebuildIndexesBlocking} or builds of new sstables
  * added via {@link org.apache.cassandra.notifications.SSTableAddedNotification}s, guaranteeing
  * the following:
  * <ul>
diff --git a/src/java/org/apache/cassandra/index/sasi/analyzer/StandardTokenizerInterface.java b/src/java/org/apache/cassandra/index/sasi/analyzer/StandardTokenizerInterface.java
index 327a67471f..4641681f5c 100644
--- a/src/java/org/apache/cassandra/index/sasi/analyzer/StandardTokenizerInterface.java
+++ b/src/java/org/apache/cassandra/index/sasi/analyzer/StandardTokenizerInterface.java
@@ -57,7 +57,7 @@ public interface StandardTokenizerInterface
      *
      * All internal variables are reset, the old input stream
      * <b>cannot</b> be reused (internal buffer is discarded and lost).
-     * Lexical state is set to <tt>ZZ_INITIAL</tt>.
+     * Lexical state is set to <code>{@literal ZZ_INITIAL}</code>.
      *
      * @param reader   the new input stream
      */
diff --git a/src/java/org/apache/cassandra/io/sstable/format/SSTableReader.java b/src/java/org/apache/cassandra/io/sstable/format/SSTableReader.java
index 01e30d6ee5..249c897574 100644
--- a/src/java/org/apache/cassandra/io/sstable/format/SSTableReader.java
+++ b/src/java/org/apache/cassandra/io/sstable/format/SSTableReader.java
@@ -394,7 +394,7 @@ public abstract class SSTableReader extends SSTable implements SelfRefCounted<SS
      * @param components
      * @param metadata
      * @return opened SSTableReader
-     * @throws IOException
+     * @throws CorruptSSTableException
      */
     public static SSTableReader openForBatch(Descriptor descriptor, Set<Component> components, TableMetadataRef metadata)
     {
@@ -477,7 +477,7 @@ public abstract class SSTableReader extends SSTable implements SelfRefCounted<SS
      * @param isOffline Whether we are opening this SSTable "offline", for example from an external tool or not for inclusion in queries (validations)
      *                  This stops regenerating BF + Summaries and also disables tracking of hotness for the SSTable.
      * @return {@link SSTableReader}
-     * @throws IOException
+     * @throws CorruptSSTableException
      */
     public static SSTableReader open(Descriptor descriptor,
                                      Set<Component> components,
diff --git a/src/java/org/apache/cassandra/locator/AbstractEndpointSnitch.java b/src/java/org/apache/cassandra/locator/AbstractEndpointSnitch.java
index 2e7408be20..99ee40bfe1 100644
--- a/src/java/org/apache/cassandra/locator/AbstractEndpointSnitch.java
+++ b/src/java/org/apache/cassandra/locator/AbstractEndpointSnitch.java
@@ -25,10 +25,10 @@ public abstract class AbstractEndpointSnitch implements IEndpointSnitch
     public abstract int compareEndpoints(InetAddressAndPort target, Replica r1, Replica r2);
 
     /**
-     * Sorts the <tt>Collection</tt> of node addresses by proximity to the given address
+     * Sorts the <code>{@literal Collection}</code> of node addresses by proximity to the given address
      * @param address the address to sort by proximity to
      * @param unsortedAddress the nodes to sort
-     * @return a new sorted <tt>List</tt>
+     * @return a new sorted <code>{@literal List}</code>
      */
     public <C extends ReplicaCollection<? extends C>> C sortedByProximity(final InetAddressAndPort address, C unsortedAddress)
     {
diff --git a/src/java/org/apache/cassandra/locator/IEndpointSnitch.java b/src/java/org/apache/cassandra/locator/IEndpointSnitch.java
index 381a64225c..090da2da45 100644
--- a/src/java/org/apache/cassandra/locator/IEndpointSnitch.java
+++ b/src/java/org/apache/cassandra/locator/IEndpointSnitch.java
@@ -61,7 +61,7 @@ public interface IEndpointSnitch
     }
 
     /**
-     * returns a new <tt>List</tt> sorted by proximity to the given endpoint
+     * returns a new <code>{@literal List}</code> sorted by proximity to the given endpoint
      */
     public <C extends ReplicaCollection<? extends C>> C sortedByProximity(final InetAddressAndPort address, C addresses);
 
diff --git a/src/java/org/apache/cassandra/locator/TokenMetadata.java b/src/java/org/apache/cassandra/locator/TokenMetadata.java
index cb189c8091..865c571ac5 100644
--- a/src/java/org/apache/cassandra/locator/TokenMetadata.java
+++ b/src/java/org/apache/cassandra/locator/TokenMetadata.java
@@ -57,7 +57,7 @@ public class TokenMetadata
     /** Maintains endpoint to host ID map of every node in the cluster */
     private final BiMap<InetAddressAndPort, UUID> endpointToHostIdMap;
 
-    // Prior to CASSANDRA-603, we just had <tt>Map<Range, InetAddressAndPort> pendingRanges<tt>,
+    // Prior to CASSANDRA-603, we just had <code>{@literal Map<Range, InetAddressAndPort> pendingRanges}</code>,
     // which was added to when a node began bootstrap and removed from when it finished.
     //
     // This is inadequate when multiple changes are allowed simultaneously.  For example,
@@ -70,8 +70,8 @@ public class TokenMetadata
     //
     // So, we made two changes:
     //
-    // First, we changed pendingRanges to a <tt>Multimap<Range, InetAddressAndPort></tt> (now
-    // <tt>Map<String, Multimap<Range, InetAddressAndPort>></tt>, because replication strategy
+    // First, we changed pendingRanges to a <code>{@literal Multimap<Range, InetAddressAndPort>}</code> (now
+    // <code>{@literal Map<String, Multimap<Range, InetAddressAndPort>>}</code>, because replication strategy
     // and options are per-KeySpace).
     //
     // Second, we added the bootstrapTokens and leavingEndpoints collections, so we can
diff --git a/src/java/org/apache/cassandra/metrics/KeyspaceMetrics.java b/src/java/org/apache/cassandra/metrics/KeyspaceMetrics.java
index ef3338ec98..f2c7ae82f3 100644
--- a/src/java/org/apache/cassandra/metrics/KeyspaceMetrics.java
+++ b/src/java/org/apache/cassandra/metrics/KeyspaceMetrics.java
@@ -135,7 +135,7 @@ public class KeyspaceMetrics
      */
     public final Meter confirmedRepairedInconsistencies;
     /**
-     * Incremented where an inconsistency is detected, but there are pending & uncommitted repair sessions
+     * Incremented where an inconsistency is detected, but there are pending &amp; uncommitted repair sessions
      * in play on at least one replica. This may indicate a false positive as the inconsistency could be due to
      * replicas marking the repair session as committed at slightly different times and so some consider it to
      * be part of the repaired set whilst others do not.
diff --git a/src/java/org/apache/cassandra/net/MessageOut.java b/src/java/org/apache/cassandra/net/MessageOut.java
index 834435e3bd..a6b829c61f 100644
--- a/src/java/org/apache/cassandra/net/MessageOut.java
+++ b/src/java/org/apache/cassandra/net/MessageOut.java
@@ -74,7 +74,7 @@ import static org.apache.cassandra.tracing.Tracing.isTracing;
  * encoded as two bytes, followed by the UTF-8 byte encoding of the string (see {@link java.io.DataOutput#writeUTF(java.lang.String)}).
  * The body is serialized with it's length, encoded as four bytes, followed by the bytes of the value.
  *
- * * @param <T> The type of the message payload.
+ * @param <T> The type of the message payload.
  */
 public class MessageOut<T>
 {
diff --git a/src/java/org/apache/cassandra/net/MessagingService.java b/src/java/org/apache/cassandra/net/MessagingService.java
index f5c064e57b..04b9da1854 100644
--- a/src/java/org/apache/cassandra/net/MessagingService.java
+++ b/src/java/org/apache/cassandra/net/MessagingService.java
@@ -1624,7 +1624,7 @@ public final class MessagingService implements MessagingServiceMBean
     }
 
     /**
-     * This method is used to determine the preferred IP & Port of a peer using the
+     * This method is used to determine the preferred IP &amp; Port of a peer using the
      * {@link OutboundMessagingPool} and SystemKeyspace.
      */
     public InetAddressAndPort getPreferredRemoteAddr(InetAddressAndPort to)
diff --git a/src/java/org/apache/cassandra/net/async/NettyFactory.java b/src/java/org/apache/cassandra/net/async/NettyFactory.java
index 81de5d8f95..26abb7e20f 100644
--- a/src/java/org/apache/cassandra/net/async/NettyFactory.java
+++ b/src/java/org/apache/cassandra/net/async/NettyFactory.java
@@ -359,8 +359,8 @@ public final class NettyFactory
         /**
          * {@inheritDoc}
          *
-         * To determine if we should enable TLS, we only need to check if {@link #params#encryptionOptions} is set.
-         * The logic for figuring that out is is located in {@link MessagingService#getMessagingConnection(InetAddress)};
+         * To determine if we should enable TLS, we only need to check if {@link #params}'s {@code encryptionOptions} is set.
+         * The logic for figuring that out is is located in {@link MessagingService#getMessagingConnection(InetAddressAndPort)};
          */
         public void initChannel(SocketChannel channel) throws Exception
         {
diff --git a/src/java/org/apache/cassandra/repair/consistent/ConsistentSession.java b/src/java/org/apache/cassandra/repair/consistent/ConsistentSession.java
index 03de157745..fa89347896 100644
--- a/src/java/org/apache/cassandra/repair/consistent/ConsistentSession.java
+++ b/src/java/org/apache/cassandra/repair/consistent/ConsistentSession.java
@@ -52,11 +52,11 @@ import org.apache.cassandra.tools.nodetool.RepairAdmin;
 /**
  * Base class for consistent Local and Coordinator sessions
  *
- * <p/>
+ * <br>
  * There are 4 stages to a consistent incremental repair.
  *
  * <h1>Repair prepare</h1>
- *  First, the normal {@link ActiveRepairService#prepareForRepair(UUID, InetAddressAndPort, Set, RepairOption, List)} stuff
+ *  First, the normal {@link ActiveRepairService#prepareForRepair} stuff
  *  happens, which sends out {@link PrepareMessage} and creates a {@link ActiveRepairService.ParentRepairSession}
  *  on the coordinator and each of the neighbors.
  *
@@ -68,18 +68,18 @@ import org.apache.cassandra.tools.nodetool.RepairAdmin;
  *  being repaired from the rest of the table data. When the preparation completes, the session state is set to
  *  {@code PREPARED}, and a {@link PrepareConsistentResponse} is sent to the coordinator indicating success or failure.
  *  If the pending anti-compaction fails, the local session state is set to {@code FAILED}.
- *  <p/>
+ *  <br>
  *  (see {@link LocalSessions#handlePrepareMessage(InetAddressAndPort, PrepareConsistentRequest)}
- *  <p/>
+ *  <br>
  *  Once the coordinator recieves positive {@code PrepareConsistentResponse} messages from all the participants, the
  *  coordinator begins the normal repair process.
- *  <p/>
- *  (see {@link CoordinatorSession#handlePrepareResponse(InetAddress, boolean)}
+ *  <br>
+ *  (see {@link CoordinatorSession#handlePrepareResponse}
  *
  * <h1>Repair</h1>
  *  The coordinator runs the normal data repair process against the sstables segregated in the previous step. When a
  *  node recieves a {@link ValidationRequest}, it sets it's local session state to {@code REPAIRING}.
- *  <p/>
+ *  <br>
  *
  *  If all of the RepairSessions complete successfully, the coordinator begins the {@code Finalization} process. Otherwise,
  *  it begins the {@code Failure} process.
@@ -90,37 +90,37 @@ import org.apache.cassandra.tools.nodetool.RepairAdmin;
  *  and respond with a {@link FinalizePromise} message. Once the coordinator has received promise messages from all participants,
  *  it will send a {@link FinalizeCommit} message to all of them, ending the coordinator session. When a node receives the
  *  {@code FinalizeCommit} message, it will set it's sessions state to {@code FINALIZED}, completing the {@code LocalSession}.
- *  <p/>
+ *  <br>
  *
  *  For the sake of simplicity, finalization does not immediately mark pending repair sstables repaired because of potential
  *  conflicts with in progress compactions. The sstables will be marked repaired as part of the normal compaction process.
- *  <p/>
+ *  <br>
  *
- *  On the coordinator side, see {@link CoordinatorSession#finalizePropose()}, {@link CoordinatorSession#handleFinalizePromise(InetAddress, boolean)},
- *  & {@link CoordinatorSession#finalizeCommit()}
- *  <p/>
+ *  On the coordinator side, see {@link CoordinatorSession#finalizePropose()}, {@link CoordinatorSession#handleFinalizePromise},
+ *  &amp; {@link CoordinatorSession#finalizeCommit()}
+ *  <br>
  *
  *  On the local session side, see {@link LocalSessions#handleFinalizeProposeMessage(InetAddressAndPort, FinalizePropose)}
- *  & {@link LocalSessions#handleFinalizeCommitMessage(InetAddressAndPort, FinalizeCommit)}
+ *  &amp; {@link LocalSessions#handleFinalizeCommitMessage(InetAddressAndPort, FinalizeCommit)}
  *
  * <h1>Failure</h1>
  *  If there are any failures or problems during the process above, the session will be failed. When a session is failed,
  *  the coordinator will send {@link FailSession} messages to each of the participants. In some cases (basically those not
  *  including Validation and Sync) errors are reported back to the coordinator by the local session, at which point, it
  *  will send {@code FailSession} messages out.
- *  <p/>
+ *  <br>
  *  Just as with finalization, sstables aren't immediately moved back to unrepaired, but will be demoted as part of the
  *  normal compaction process.
  *
- *  <p/>
+ *  <br>
  *  See {@link LocalSessions#failSession(UUID, boolean)} and {@link CoordinatorSession#fail()}
  *
- * <h1>Failure Recovery & Session Cleanup</h1>
+ * <h1>Failure Recovery &amp; Session Cleanup</h1>
  *  There are a few scenarios where sessions can get stuck. If a node fails mid session, or it misses a {@code FailSession}
  *  or {@code FinalizeCommit} message, it will never finish. To address this, there is a cleanup task that runs every
  *  10 minutes that attempts to complete idle sessions.
  *
- *  <p/>
+ *  <br>
  *  If a session is not completed (not {@code FINALIZED} or {@code FAILED}) and there's been no activity on the session for
  *  over an hour, the cleanup task will attempt to finish the session by learning the session state of the other participants.
  *  To do this, it sends a {@link StatusRequest} message to the other session participants. The participants respond with a
@@ -130,16 +130,16 @@ import org.apache.cassandra.tools.nodetool.RepairAdmin;
  *  it's received {@code FinalizePromise} messages from <i>all</i> participants, this is safe.
  *
  *
- *  <p/>
+ *  <br>
  *  If a session is not completed, and hasn't had any activity for over a day, the session is auto-failed.
  *
- *  <p/>
+ *  <br>
  *  Once a session has been completed for over 2 days, it's deleted.
  *
- *  <p/>
+ *  <br>
  *  Operators can also manually fail sessions with {@code nodetool repair_admin --cancel}
  *
- *  <p/>
+ *  <br>
  *  See {@link LocalSessions#cleanup()} and {@link RepairAdmin}
  *
  */
diff --git a/src/java/org/apache/cassandra/repair/consistent/LocalSessions.java b/src/java/org/apache/cassandra/repair/consistent/LocalSessions.java
index c28391a531..876176386d 100644
--- a/src/java/org/apache/cassandra/repair/consistent/LocalSessions.java
+++ b/src/java/org/apache/cassandra/repair/consistent/LocalSessions.java
@@ -91,7 +91,7 @@ import static org.apache.cassandra.repair.consistent.ConsistentSession.State.*;
 
 /**
  * Manages all consistent repair sessions a node is participating in.
- * <p/>
+ * <br>
  * Since sessions need to be loaded, and since we need to handle cases where sessions might not exist, most of the logic
  * around local sessions is implemented in this class, with the LocalSession class being treated more like a simple struct,
  * in contrast with {@link CoordinatorSession}
diff --git a/src/java/org/apache/cassandra/schema/Schema.java b/src/java/org/apache/cassandra/schema/Schema.java
index 2c2d444897..05feb00fee 100644
--- a/src/java/org/apache/cassandra/schema/Schema.java
+++ b/src/java/org/apache/cassandra/schema/Schema.java
@@ -886,7 +886,7 @@ public final class Schema
 
     /**
      * Converts the given schema version to a string. Returns {@code unknown}, if {@code version} is {@code null}
-     * or {@code "(empty)"}, if {@code version} refers to an {@link SchemaConstants#emptyVersion empty) schema.
+     * or {@code "(empty)"}, if {@code version} refers to an {@link SchemaConstants#emptyVersion} empty) schema.
      */
     public static String schemaVersionToString(UUID version)
     {
diff --git a/src/java/org/apache/cassandra/service/EmbeddedCassandraService.java b/src/java/org/apache/cassandra/service/EmbeddedCassandraService.java
index 9172eab11f..dabbffeadd 100644
--- a/src/java/org/apache/cassandra/service/EmbeddedCassandraService.java
+++ b/src/java/org/apache/cassandra/service/EmbeddedCassandraService.java
@@ -24,7 +24,6 @@ import java.io.IOException;
  * This kind of service is useful when running unit tests of
  * services using cassandra for example.
  *
- * See {@link org.apache.cassandra.service.EmbeddedCassandraServiceTest} for usage.
  * <p>
  * This is the implementation of https://issues.apache.org/jira/browse/CASSANDRA-740
  * <p>
diff --git a/src/java/org/apache/cassandra/service/StorageServiceMBean.java b/src/java/org/apache/cassandra/service/StorageServiceMBean.java
index e82d1ba401..9e09032092 100644
--- a/src/java/org/apache/cassandra/service/StorageServiceMBean.java
+++ b/src/java/org/apache/cassandra/service/StorageServiceMBean.java
@@ -362,7 +362,7 @@ public interface StorageServiceMBean extends NotificationEmitter
     /**
      * Get the status of a given parent repair session.
      * @param cmd the int reference returned when issuing the repair
-     * @return status of parent repair from enum {@link org.apache.cassandra.repair.RepairRunnable.Status}
+     * @return status of parent repair from enum {@link org.apache.cassandra.service.ActiveRepairService.ParentRepairStatus}
      * followed by final message or messages of the session
      */
     @Nullable
diff --git a/src/java/org/apache/cassandra/tools/NodeProbe.java b/src/java/org/apache/cassandra/tools/NodeProbe.java
index 197dd50552..eda4d1225e 100644
--- a/src/java/org/apache/cassandra/tools/NodeProbe.java
+++ b/src/java/org/apache/cassandra/tools/NodeProbe.java
@@ -1590,7 +1590,8 @@ public class NodeProbe implements AutoCloseable
 
     /**
      * Retrieve Proxy metrics
-     * @param connections, connectedNativeClients, connectedNativeClientsByUser, clientsByProtocolVersion
+     * @param metricName valid values include (connections, connectedNativeClients, connectedNativeClientsByUser,
+     *                   clientsByProtocolVersion)
      */
     public Object getClientMetric(String metricName)
     {
diff --git a/src/java/org/apache/cassandra/transport/frame/FrameBodyTransformer.java b/src/java/org/apache/cassandra/transport/frame/FrameBodyTransformer.java
index 0a6b22fa3e..3211843746 100644
--- a/src/java/org/apache/cassandra/transport/frame/FrameBodyTransformer.java
+++ b/src/java/org/apache/cassandra/transport/frame/FrameBodyTransformer.java
@@ -48,7 +48,7 @@ public interface FrameBodyTransformer
 
     /**
      * Returns an EnumSet of the flags that should be added to the header for any message whose frame body has been
-     * modified by the transformer. E.g. it may add perform chunking & checksumming to the frame body,
+     * modified by the transformer. E.g. it may add perform chunking &amp; checksumming to the frame body,
      * compress it, or both.
      * @return EnumSet containing the header flags to set on messages transformed
      */
diff --git a/src/java/org/apache/cassandra/utils/CoalescingStrategies.java b/src/java/org/apache/cassandra/utils/CoalescingStrategies.java
index 2f9e5bbf08..3e316a4ae4 100644
--- a/src/java/org/apache/cassandra/utils/CoalescingStrategies.java
+++ b/src/java/org/apache/cassandra/utils/CoalescingStrategies.java
@@ -100,7 +100,7 @@ public class CoalescingStrategies
      * {@link #currentCoalescingTimeNanos()}.
      * <p>
      * Note that it is expected that a call {@link #currentCoalescingTimeNanos()} will come just after a call to
-     * {@link #newArrival(Coalescable))}, as the intent of the value returned by the former method is "Given a new message, how much
+     * {@link #newArrival(Coalescable)}, as the intent of the value returned by the former method is "Given a new message, how much
      * time should I wait for more messages to arrive and be coalesced with that message". But both calls are separated
      * as one may not want to call {@link #currentCoalescingTimeNanos()} after every call to {@link #newArrival(Coalescable)}
      * and we thus save processing. How arrivals influence the coalescing time is however entirely up to the strategy and some
diff --git a/src/java/org/apache/cassandra/utils/btree/BTree.java b/src/java/org/apache/cassandra/utils/btree/BTree.java
index 6d0af6e048..aee393b485 100644
--- a/src/java/org/apache/cassandra/utils/btree/BTree.java
+++ b/src/java/org/apache/cassandra/utils/btree/BTree.java
@@ -435,7 +435,7 @@ public class BTree
 
     /**
      * Honours result semantics of {@link Arrays#binarySearch}, as though it were performed on the tree flattened into an array
-     * @return index of item in tree, or <tt>(-(<i>insertion point</i>) - 1)</tt> if not present
+     * @return index of item in tree, or <code>{@literal (-(insertion point) - 1)}</code> if not present
      */
     public static <V> int findIndex(Object[] node, Comparator<? super V> comparator, V find)
     {
@@ -801,7 +801,7 @@ public class BTree
     }
 
     /**
-     * tree index => index of key wrt all items in the tree laid out serially
+     * tree {@code index => index} of key wrt all items in the tree laid out serially
      *
      * This version of the method permits requesting out-of-bounds indexes, -1 and size
      * @param root to calculate tree index within
diff --git a/src/java/org/apache/cassandra/utils/streamhist/StreamingTombstoneHistogramBuilder.java b/src/java/org/apache/cassandra/utils/streamhist/StreamingTombstoneHistogramBuilder.java
index 9856253bf0..cac40ea145 100755
--- a/src/java/org/apache/cassandra/utils/streamhist/StreamingTombstoneHistogramBuilder.java
+++ b/src/java/org/apache/cassandra/utils/streamhist/StreamingTombstoneHistogramBuilder.java
@@ -38,11 +38,12 @@ import static org.apache.cassandra.utils.streamhist.StreamingTombstoneHistogramB
  * <ol>
  * <li>If point <i>p</i> is already exists in collection, add <i>m</i> to recorded value of point <i>p</i> </li>
  * <li>If there is no point <i>p</i> in the collection, add point <i>p</i> with weight <i>m</i> </li>
- * <li>If point was added and collection size became lorger than maxBinSize:</li>
+ * <li>If point was added and collection size became lorger than maxBinSize:
  * <ol type="a">
  * <li>Find nearest points <i>p1</i> and <i>p2</i> in the collection </li>
  * <li>Replace theese two points with one weighted point <i>p3 = (p1*m1+p2*m2)/(p1+p2)</i></li>
  * </ol>
+ * </li>
  * </ol>
  * <p>
  * There are some optimization to make histogram builder faster:
@@ -50,10 +51,10 @@ import static org.apache.cassandra.utils.streamhist.StreamingTombstoneHistogramB
  *     <li>Spool: big map that saves from excessively merging of small bin. This map can contains up to maxSpoolSize points and accumulate weight from same points.
  *     For example, if spoolSize=100, binSize=10 and there are only 50 different points. it will be only 40 merges regardless how many points will be added.</li>
  *     <li>Spool is organized as open-addressing primitive hash map where odd elements are points and event elements are values.
- *     Spool can not resize => when number of collisions became bigger than threashold or size became large that <i>array_size/2</i> Spool is drained to bin</li>
+ *     Spool can not resize when number of collisions became bigger than threashold or size became large that <i>array_size/2</i> Spool is drained to bin</li>
  *     <li>DistanceHolder - sorted collection of distances between points in Bin. It is used to find nearest points in constant time</li>
  *     <li>Distances and Bin organized as sorted arrays. It reduces garbage collection pressure and allows to find elements in log(binSize) time via binary search</li>
- *     <li>To use existing Arrays.binarySearch <i></>{point, values}</i> in bin and <i></>{distance, left_point}</i> pairs is packed in one long</li>
+ *     <li>To use existing Arrays.binarySearch <i>{point, values}</i> in bin and <i>{distance, left_point}</i> pairs is packed in one long</li>
  * </ol>
  */
 public class StreamingTombstoneHistogramBuilder
diff --git a/test/unit/org/apache/cassandra/db/compaction/CompactionStrategyManagerTest.java b/test/unit/org/apache/cassandra/db/compaction/CompactionStrategyManagerTest.java
index 73e6852eb1..a02ade03ef 100644
--- a/test/unit/org/apache/cassandra/db/compaction/CompactionStrategyManagerTest.java
+++ b/test/unit/org/apache/cassandra/db/compaction/CompactionStrategyManagerTest.java
@@ -89,7 +89,8 @@ public class CompactionStrategyManagerTest
         DatabaseDescriptor.setIncrementalBackupsEnabled(false);
         /**
          * We use byte ordered partitioner in this test to be able to easily infer an SSTable
-         * disk assignment based on its generation - See {@link this#getSSTableIndex(Integer[], SSTableReader)}
+         * disk assignment based on its generation - See
+         * {@link CompactionStrategyManagerTest#getSSTableIndex(Integer[], SSTableReader)}
          */
         originalPartitioner = StorageService.instance.setPartitionerUnsafe(ByteOrderedPartitioner.instance);
         SchemaLoader.createKeyspace(KS_PREFIX,
