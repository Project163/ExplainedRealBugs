diff --git a/CHANGES.txt b/CHANGES.txt
index 08e95ed0ee..547bb1af47 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,4 +1,5 @@
 3.0.20
+ * Avoid over-trimming of results in mixed mode clusters (CASSANDRA-15405)
  * validate value sizes in LegacyLayout (CASSANDRA-15373)
  * Ensure that tracing doesn't break connections in 3.x/4.0 mixed mode by default (CASSANDRA-15385)
  * Make sure index summary redistribution does not start when compactions are paused (CASSANDRA-15265)
diff --git a/src/java/org/apache/cassandra/db/LegacyLayout.java b/src/java/org/apache/cassandra/db/LegacyLayout.java
index c2d715dd23..42d50a1116 100644
--- a/src/java/org/apache/cassandra/db/LegacyLayout.java
+++ b/src/java/org/apache/cassandra/db/LegacyLayout.java
@@ -487,7 +487,7 @@ public abstract class LegacyLayout
      * post-query limitation are in order (see above). This will be {@code Integer.MAX_VALUE} if no such limits are
      * necessary.
      */
-    private static int maxCellsPerPartition(ReadCommand command)
+    private static int maxLiveCellsPerPartition(ReadCommand command)
     {
         if (command == null)
             return Integer.MAX_VALUE;
@@ -525,9 +525,8 @@ public abstract class LegacyLayout
         // before we use the LegacyRangeTombstoneList at all
         List<LegacyLayout.LegacyCell> cells = Lists.newArrayList(pair.right);
 
-        int maxCellsPerPartition = maxCellsPerPartition(command);
-        if (cells.size() > maxCellsPerPartition)
-            cells = cells.subList(0, maxCellsPerPartition);
+        int maxCellsPerPartition = maxLiveCellsPerPartition(command);
+        cells = maybeTrimLiveCells(cells, maxCellsPerPartition, command);
 
         // The LegacyRangeTombstoneList already has range tombstones for the single-row deletions and complex
         // deletions.  Go through our normal range tombstones and add then to the LegacyRTL so that the range
@@ -548,6 +547,26 @@ public abstract class LegacyLayout
         return new LegacyUnfilteredPartition(info.getPartitionDeletion(), rtl, cells);
     }
 
+    private static List<LegacyCell> maybeTrimLiveCells(List<LegacyCell> cells, int maxLiveCells, ReadCommand command)
+    {
+        if (null == command || maxLiveCells >= cells.size())
+            return cells;
+
+        int nowInSec = command.nowInSec();
+        int live = 0;
+        int dead = 0;
+
+        for (int i = 0; i < cells.size() && live < maxLiveCells; i++)
+        {
+            if (cells.get(i).isLive(nowInSec))
+                live++;
+            else
+                dead++;
+        }
+
+        return cells.subList(0, live + dead);
+    }
+
     public static void serializeAsLegacyPartition(ReadCommand command, UnfilteredRowIterator partition, DataOutputPlus out, int version) throws IOException
     {
         assert version < MessagingService.VERSION_30;
diff --git a/test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTest.java b/test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTest.java
index 2c7f7bc241..5a927fc007 100644
--- a/test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTest.java
@@ -18,12 +18,17 @@
 
 package org.apache.cassandra.distributed.upgrade;
 
+import java.util.Iterator;
+
+import com.google.common.collect.Iterators;
 import org.junit.Test;
 
 import org.apache.cassandra.db.ConsistencyLevel;
 import org.apache.cassandra.distributed.impl.Versions;
 import org.apache.cassandra.distributed.test.DistributedTestBase;
 
+import static junit.framework.Assert.assertEquals;
+
 public class UpgradeTest extends UpgradeTestBase
 {
 
@@ -49,4 +54,37 @@ public class UpgradeTest extends UpgradeTestBase
             }).run();
     }
 
+    @Test
+    public void mixedModePagingTest() throws Throwable
+    {
+        new TestCase()
+        .upgrade(Versions.Major.v22, Versions.Major.v30)
+        .nodes(2)
+        .nodesToUpgrade(2)
+        .setup((cluster) -> {
+            cluster.schemaChange("ALTER KEYSPACE " + DistributedTestBase.KEYSPACE + " WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}");
+            cluster.schemaChange("CREATE TABLE " + DistributedTestBase.KEYSPACE + ".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck)) with compact storage");
+            for (int i = 0; i < 100; i++)
+                for (int j = 0; j < 200; j++)
+                    cluster.coordinator(2).execute("INSERT INTO " + DistributedTestBase.KEYSPACE + ".tbl (pk, ck, v) VALUES (?, ?, 1)", ConsistencyLevel.ALL, i, j);
+            cluster.forEach((i) -> i.flush(DistributedTestBase.KEYSPACE));
+            for (int i = 0; i < 100; i++)
+                for (int j = 10; j < 30; j++)
+                    cluster.coordinator(2).execute("DELETE FROM " + DistributedTestBase.KEYSPACE + ".tbl where pk=? and ck=?", ConsistencyLevel.ALL, i, j);
+            cluster.forEach((i) -> i.flush(DistributedTestBase.KEYSPACE));
+        })
+        .runAfterClusterUpgrade((cluster) -> {
+            for (int i = 0; i < 100; i++)
+            {
+                for (int pageSize = 10; pageSize < 100; pageSize++)
+                {
+                    Iterator<Object[]> res = cluster.coordinator(1).executeWithPaging("SELECT * FROM " + DistributedTestBase.KEYSPACE + ".tbl WHERE pk = ?",
+                                                                                      ConsistencyLevel.ALL,
+                                                                                      pageSize, i);
+                    assertEquals(180, Iterators.size(res));
+                }
+            }
+        }).run();
+    }
+
 }
