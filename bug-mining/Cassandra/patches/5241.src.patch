diff --git a/CHANGES.txt b/CHANGES.txt
index d3e0b89e70..7cc960d833 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,4 +1,5 @@
 4.0-alpha3
+ * Make sure all exceptions are propagated in DebuggableThreadPoolExecutor (CASSANDRA-15332)
  * Make it possible to resize concurrent read / write thread pools at runtime (CASSANDRA-15277)
 Merged from 2.2:
  * In-JVM DTest: Set correct internode message version for upgrade test (CASSANDRA-15371)
diff --git a/src/java/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutor.java b/src/java/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutor.java
index ef0f43c469..a2de775dd7 100644
--- a/src/java/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutor.java
+++ b/src/java/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutor.java
@@ -17,7 +17,21 @@
  */
 package org.apache.cassandra.concurrent;
 
-import java.util.concurrent.*;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CancellationException;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.FutureTask;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.RejectedExecutionHandler;
+import java.util.concurrent.RunnableFuture;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -147,7 +161,7 @@ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor implements
     {
         super.execute(locals == null || command instanceof LocalSessionWrapper
                       ? command
-                      : new LocalSessionWrapper<Object>(command, locals));
+                      : LocalSessionWrapper.create(command, null, locals));
     }
 
     public void maybeExecuteImmediately(Runnable command)
@@ -160,7 +174,7 @@ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor implements
     public void execute(Runnable command)
     {
         super.execute(isTracing() && !(command instanceof LocalSessionWrapper)
-                      ? new LocalSessionWrapper<Object>(Executors.callable(command, null))
+                      ? LocalSessionWrapper.create(command)
                       : command);
     }
 
@@ -168,9 +182,9 @@ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor implements
     protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T result)
     {
         if (isTracing() && !(runnable instanceof LocalSessionWrapper))
-        {
-            return new LocalSessionWrapper<T>(Executors.callable(runnable, result));
-        }
+            return LocalSessionWrapper.create(runnable, result);
+        if (runnable instanceof RunnableFuture)
+            return new ForwardingRunnableFuture<>((RunnableFuture) runnable, result);
         return super.newTaskFor(runnable, result);
     }
 
@@ -178,9 +192,7 @@ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor implements
     protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable)
     {
         if (isTracing() && !(callable instanceof LocalSessionWrapper))
-        {
-            return new LocalSessionWrapper<T>(callable);
-        }
+            return LocalSessionWrapper.create(callable);
         return super.newTaskFor(callable);
     }
 
@@ -258,16 +270,32 @@ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor implements
      */
     public static Throwable extractThrowable(Runnable runnable)
     {
-        // Check for exceptions wrapped by FutureTask.  We do this by calling get(), which will
+        // Check for exceptions wrapped by FutureTask or tasks which wrap FutureTask (HasDelegateFuture interface)
+        Throwable throwable = null;
+        if (runnable instanceof Future<?>)
+        {
+            throwable = extractThrowable(((Future<?>) runnable));
+        }
+        if (throwable == null && runnable instanceof HasDelegateFuture)
+        {
+            throwable =  extractThrowable(((HasDelegateFuture) runnable).getDelegate());
+        }
+
+        return throwable;
+    }
+
+    private static Throwable extractThrowable(Future<?> future)
+    {
+        // Check for exceptions wrapped by Future.  We do this by calling get(), which will
         // cause it to throw any saved exception.
         //
         // Complicating things, calling get() on a ScheduledFutureTask will block until the task
         // is cancelled.  Hence, the extra isDone check beforehand.
-        if ((runnable instanceof Future<?>) && ((Future<?>) runnable).isDone())
+        if (future.isDone())
         {
             try
             {
-                ((Future<?>) runnable).get();
+                future.get();
             }
             catch (InterruptedException e)
             {
@@ -282,30 +310,65 @@ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor implements
                 return e.getCause();
             }
         }
-
         return null;
     }
 
+    /**
+     * If a task wraps a {@link Future} then it should implement this interface to expose the underlining future for
+     * {@link #extractThrowable(Runnable)} to handle.
+     */
+    private interface HasDelegateFuture
+    {
+        Future<?> getDelegate();
+    }
+
     /**
      * Used to wrap a Runnable or Callable passed to submit or execute so we can clone the ExecutorLocals and move
      * them into the worker thread.
      *
+     * The {@link DebuggableThreadPoolExecutor#afterExecute(java.lang.Runnable, java.lang.Throwable)}
+     * method is called after the runnable completes, which will then call {@link #extractThrowable(Runnable)} to
+     * attempt to get the "hidden" throwable from a task which implements {@link Future}.  The problem is that {@link LocalSessionWrapper}
+     * expects that the {@link Callable} provided to it will throw; which is not true for {@link RunnableFuture} tasks;
+     * the expected semantic in this case is to have the LocalSessionWrapper future be successful and a new implementation
+     * {@link FutureLocalSessionWrapper} is created to expose the underline {@link Future} for {@link #extractThrowable(Runnable)}.
+     *
+     * If a task is a {@link Runnable} the create family of methods should be called rather than {@link Executors#callable(Runnable)}
+     * since they will handle the case where the task is also a future, and will make sure the {@link #extractThrowable(Runnable)}
+     * is able to detect the task's underline exception.
+     *
      * @param <T>
      */
     private static class LocalSessionWrapper<T> extends FutureTask<T>
     {
         private final ExecutorLocals locals;
 
-        public LocalSessionWrapper(Callable<T> callable)
+        private LocalSessionWrapper(Callable<T> callable, ExecutorLocals locals)
         {
             super(callable);
-            locals = ExecutorLocals.create();
+            this.locals = locals;
         }
 
-        public LocalSessionWrapper(Runnable command, ExecutorLocals locals)
+        static LocalSessionWrapper<Object> create(Runnable command)
         {
-            super(command, null);
-            this.locals = locals;
+            return create(command, null, ExecutorLocals.create());
+        }
+
+        static <T> LocalSessionWrapper<T> create(Runnable command, T result)
+        {
+            return create(command, result, ExecutorLocals.create());
+        }
+
+        static <T> LocalSessionWrapper<T> create(Runnable command, T result, ExecutorLocals locals)
+        {
+            if (command instanceof RunnableFuture)
+                return new FutureLocalSessionWrapper<>((RunnableFuture) command, result, locals);
+            return new LocalSessionWrapper<>(Executors.callable(command, result), locals);
+        }
+
+        static <T> LocalSessionWrapper<T> create(Callable<T> command)
+        {
+            return new LocalSessionWrapper<>(command, ExecutorLocals.create());
         }
 
         private void setupContext()
@@ -318,4 +381,46 @@ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor implements
             ExecutorLocals.set(null);
         }
     }
+
+    private static class FutureLocalSessionWrapper<T> extends LocalSessionWrapper<T> implements HasDelegateFuture
+    {
+        private final RunnableFuture<T> delegate;
+
+        private FutureLocalSessionWrapper(RunnableFuture command, T result, ExecutorLocals locals)
+        {
+            super(() -> {
+                command.run();
+                return result;
+            }, locals);
+            this.delegate = command;
+        }
+
+        public Future<T> getDelegate()
+        {
+            return delegate;
+        }
+    }
+
+    /**
+     * Similar to {@link FutureLocalSessionWrapper}, this class wraps a {@link Future} and will be success
+     * if the underline future is marked as failed; the main difference is that this class does not setup
+     * {@link ExecutorLocals}.
+     *
+     * @param <T>
+     */
+    private static class ForwardingRunnableFuture<T> extends FutureTask<T> implements HasDelegateFuture
+    {
+        private final RunnableFuture<T> delegate;
+
+        public ForwardingRunnableFuture(RunnableFuture<T> delegate, T result)
+        {
+            super(delegate, result);
+            this.delegate = delegate;
+        }
+
+        public Future<T> getDelegate()
+        {
+            return delegate;
+        }
+    }
 }
diff --git a/src/java/org/apache/cassandra/service/CassandraDaemon.java b/src/java/org/apache/cassandra/service/CassandraDaemon.java
index d705bd75fe..24c1d6fde1 100644
--- a/src/java/org/apache/cassandra/service/CassandraDaemon.java
+++ b/src/java/org/apache/cassandra/service/CassandraDaemon.java
@@ -26,7 +26,6 @@ import java.net.URL;
 import java.net.UnknownHostException;
 import java.util.List;
 import java.util.concurrent.TimeUnit;
-import javax.management.MBeanServer;
 import javax.management.ObjectName;
 import javax.management.StandardMBean;
 import javax.management.remote.JMXConnectorServer;
@@ -225,33 +224,7 @@ public class CassandraDaemon
         // This should be the first write to SystemKeyspace (CASSANDRA-11742)
         SystemKeyspace.persistLocalMetadata();
 
-        Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler()
-        {
-            public void uncaughtException(Thread t, Throwable e)
-            {
-                StorageMetrics.uncaughtExceptions.inc();
-                logger.error("Exception in thread " + t, e);
-                Tracing.trace("Exception in thread {}", t, e);
-                for (Throwable e2 = e; e2 != null; e2 = e2.getCause())
-                {
-                    JVMStabilityInspector.inspectThrowable(e2);
-
-                    if (e2 instanceof FSError)
-                    {
-                        if (e2 != e) // make sure FSError gets logged exactly once.
-                            logger.error("Exception in thread " + t, e2);
-                        FileUtils.handleFSError((FSError) e2);
-                    }
-
-                    if (e2 instanceof CorruptSSTableException)
-                    {
-                        if (e2 != e)
-                            logger.error("Exception in thread " + t, e2);
-                        FileUtils.handleCorruptSSTable((CorruptSSTableException) e2);
-                    }
-                }
-            }
-        });
+        Thread.setDefaultUncaughtExceptionHandler(CassandraDaemon::uncaughtException);
 
         SystemKeyspaceMigrator40.migrate();
 
@@ -460,6 +433,32 @@ public class CassandraDaemon
         nativeTransportService = new NativeTransportService();
     }
 
+    @VisibleForTesting
+    public static void uncaughtException(Thread t, Throwable e)
+    {
+        StorageMetrics.uncaughtExceptions.inc();
+        logger.error("Exception in thread " + t, e);
+        Tracing.trace("Exception in thread {}", t, e);
+        for (Throwable e2 = e; e2 != null; e2 = e2.getCause())
+        {
+            JVMStabilityInspector.inspectThrowable(e2);
+
+            if (e2 instanceof FSError)
+            {
+                if (e2 != e) // make sure FSError gets logged exactly once.
+                    logger.error("Exception in thread " + t, e2);
+                FileUtils.handleFSError((FSError) e2);
+            }
+
+            if (e2 instanceof CorruptSSTableException)
+            {
+                if (e2 != e)
+                    logger.error("Exception in thread " + t, e2);
+                FileUtils.handleCorruptSSTable((CorruptSSTableException) e2);
+            }
+        }
+    }
+
     /*
      * Asynchronously load the row and key cache in one off threads and return a compound future of the result.
      * Error handling is pushed into the cache load since cache loads are allowed to fail and are handled by logging.
diff --git a/test/distributed/org/apache/cassandra/distributed/api/IInstance.java b/test/distributed/org/apache/cassandra/distributed/api/IInstance.java
index e6c705cfe4..9b58aaed2b 100644
--- a/test/distributed/org/apache/cassandra/distributed/api/IInstance.java
+++ b/test/distributed/org/apache/cassandra/distributed/api/IInstance.java
@@ -43,6 +43,16 @@ public interface IInstance extends IIsolatedExecutor
 
     int liveMemberCount();
 
+    void uncaughtException(Thread t, Throwable e);
+
+    /**
+     * Return the number of times the instance tried to call {@link System#exit(int)}.
+     *
+     * When the instance is shutdown, this state should be saved, but in case not possible should return {@code -1}
+     * to indicate "unknown".
+     */
+    long killAttempts();
+
     // these methods are not for external use, but for simplicity we leave them public and on the normal IInstance interface
     void startup(ICluster cluster);
     void receiveMessage(IMessage message);
diff --git a/test/distributed/org/apache/cassandra/distributed/impl/AbstractCluster.java b/test/distributed/org/apache/cassandra/distributed/impl/AbstractCluster.java
index 28a6a74a4e..c8bdbf10b6 100644
--- a/test/distributed/org/apache/cassandra/distributed/impl/AbstractCluster.java
+++ b/test/distributed/org/apache/cassandra/distributed/impl/AbstractCluster.java
@@ -104,6 +104,7 @@ public abstract class AbstractCluster<I extends IInstance> implements ICluster,
 
     // mutated by user-facing API
     private final MessageFilters filters;
+    private volatile Thread.UncaughtExceptionHandler previousHandler = null;
 
     protected class Wrapper extends DelegatingInvokableInstance implements IUpgradeableInstance
     {
@@ -181,6 +182,15 @@ public abstract class AbstractCluster<I extends IInstance> implements ICluster,
             throw new IllegalStateException("Cannot get live member count on shutdown instance");
         }
 
+        public long killAttempts()
+        {
+            IInvokableInstance local = delegate;
+            // if shutdown cleared the delegate, then no longer know how many kill attempts happened, so return -1
+            if (local == null)
+                return -1;
+            return local.killAttempts();
+        }
+
         @Override
         public void receiveMessage(IMessage message)
         {
@@ -203,6 +213,15 @@ public abstract class AbstractCluster<I extends IInstance> implements ICluster,
                 delegate = null;
             }
         }
+
+        public void uncaughtException(Thread thread, Throwable throwable)
+        {
+            IInvokableInstance delegate = this.delegate;
+            if (delegate != null)
+                delegate.uncaughtException(thread, throwable);
+            else
+                logger.error("uncaught exception in thread {}", thread, throwable);
+        }
     }
 
     protected AbstractCluster(File root, Versions.Version version, List<InstanceConfig> configs,
@@ -440,6 +459,8 @@ public abstract class AbstractCluster<I extends IInstance> implements ICluster,
 
     void startup()
     {
+        previousHandler = Thread.getDefaultUncaughtExceptionHandler();
+        Thread.setDefaultUncaughtExceptionHandler(this::uncaughtExceptions);
         try (AllMembersAliveMonitor monitor = new AllMembersAliveMonitor())
         {
             // Start any instances with auto_bootstrap enabled first, and in series to avoid issues
@@ -461,6 +482,19 @@ public abstract class AbstractCluster<I extends IInstance> implements ICluster,
         }
     }
 
+    private void uncaughtExceptions(Thread thread, Throwable error)
+    {
+        if (!(thread.getContextClassLoader() instanceof InstanceClassLoader))
+        {
+            Thread.UncaughtExceptionHandler handler = previousHandler;
+            if (null != handler)
+                handler.uncaughtException(thread, error);
+            return;
+        }
+        InstanceClassLoader cl = (InstanceClassLoader) thread.getContextClassLoader();
+        get(cl.getGeneration()).uncaughtException(thread, error);
+    }
+
     protected interface Factory<I extends IInstance, C extends AbstractCluster<I>>
     {
         C newCluster(File root, Versions.Version version, List<InstanceConfig> configs, ClassLoader sharedClassLoader);
@@ -692,7 +726,10 @@ public abstract class AbstractCluster<I extends IInstance> implements ICluster,
         instances.clear();
         instanceMap.clear();
         // Make sure to only delete directory when threads are stopped
-        FileUtils.deleteRecursive(root);
+        if (root.exists())
+            FileUtils.deleteRecursive(root);
+        Thread.setDefaultUncaughtExceptionHandler(previousHandler);
+        previousHandler = null;
 
         //withThreadLeakCheck(futures);
     }
diff --git a/test/distributed/org/apache/cassandra/distributed/impl/Instance.java b/test/distributed/org/apache/cassandra/distributed/impl/Instance.java
index cdc3cc819c..a8bd3ae952 100644
--- a/test/distributed/org/apache/cassandra/distributed/impl/Instance.java
+++ b/test/distributed/org/apache/cassandra/distributed/impl/Instance.java
@@ -32,7 +32,6 @@ import java.util.function.BiConsumer;
 import java.util.function.BiPredicate;
 
 import io.netty.util.concurrent.GlobalEventExecutor;
-
 import org.apache.cassandra.batchlog.BatchlogManager;
 import org.apache.cassandra.concurrent.ExecutorLocals;
 import org.apache.cassandra.concurrent.ScheduledExecutors;
@@ -67,6 +66,7 @@ import org.apache.cassandra.io.sstable.IndexSummaryManager;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.util.DataInputBuffer;
 import org.apache.cassandra.io.util.DataOutputBuffer;
+import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.MessagingService;
@@ -75,17 +75,19 @@ import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.service.ActiveRepairService;
 import org.apache.cassandra.service.CassandraDaemon;
 import org.apache.cassandra.service.ClientState;
+import org.apache.cassandra.service.DefaultFSErrorHandler;
 import org.apache.cassandra.service.PendingRangeCalculatorService;
 import org.apache.cassandra.service.QueryState;
 import org.apache.cassandra.service.StorageService;
-import org.apache.cassandra.streaming.async.StreamingInboundHandler;
 import org.apache.cassandra.streaming.StreamReceiveTask;
 import org.apache.cassandra.streaming.StreamTransferTask;
+import org.apache.cassandra.streaming.async.StreamingInboundHandler;
 import org.apache.cassandra.tracing.TraceState;
 import org.apache.cassandra.tracing.Tracing;
 import org.apache.cassandra.transport.messages.ResultMessage;
 import org.apache.cassandra.utils.ExecutorUtils;
 import org.apache.cassandra.utils.FBUtilities;
+import org.apache.cassandra.utils.JVMStabilityInspector;
 import org.apache.cassandra.utils.Throwables;
 import org.apache.cassandra.utils.concurrent.Ref;
 import org.apache.cassandra.utils.memory.BufferPool;
@@ -167,7 +169,7 @@ public class Instance extends IsolatedExecutor implements IInvokableInstance
 
     public boolean isShutdown()
     {
-        throw new UnsupportedOperationException();
+        return isolatedExecutor.isShutdown();
     }
 
     @Override
@@ -209,6 +211,11 @@ public class Instance extends IsolatedExecutor implements IInvokableInstance
         MessagingService.instance().outboundSink.add((message, to) -> cluster.filters().permit(this, cluster.get(to), message.verb().id));
     }
 
+    public void uncaughtException(Thread thread, Throwable throwable)
+    {
+        sync(CassandraDaemon::uncaughtException).accept(thread, throwable);
+    }
+
     private class MessageDeliverySink implements BiPredicate<Message<?>, InetAddressAndPort>
     {
         private final BiConsumer<InetAddressAndPort, IMessage> deliver;
@@ -299,6 +306,8 @@ public class Instance extends IsolatedExecutor implements IInvokableInstance
         sync(() -> {
             try
             {
+                FileUtils.setFSErrorHandler(new DefaultFSErrorHandler());
+
                 if (config.has(GOSSIP))
                 {
                     // TODO: hacky
@@ -354,6 +363,7 @@ public class Instance extends IsolatedExecutor implements IInvokableInstance
 //                    -- not sure what that means?  SocketFactory.instance.getClass();
                     registerMockMessaging(cluster);
                 }
+                JVMStabilityInspector.replaceKiller(new InstanceKiller());
 
                 // TODO: this is more than just gossip
                 if (config.has(GOSSIP))
@@ -530,6 +540,11 @@ public class Instance extends IsolatedExecutor implements IInvokableInstance
         }).call();
     }
 
+    public long killAttempts()
+    {
+        return callOnInstance(InstanceKiller::getKillAttempts);
+    }
+
     private static void shutdownAndWait(List<ExecutorService> executors) throws TimeoutException, InterruptedException
     {
         ExecutorUtils.shutdownNow(executors);
diff --git a/test/distributed/org/apache/cassandra/distributed/impl/InstanceClassLoader.java b/test/distributed/org/apache/cassandra/distributed/impl/InstanceClassLoader.java
index ac4730067d..5ada263180 100644
--- a/test/distributed/org/apache/cassandra/distributed/impl/InstanceClassLoader.java
+++ b/test/distributed/org/apache/cassandra/distributed/impl/InstanceClassLoader.java
@@ -81,6 +81,11 @@ public class InstanceClassLoader extends URLClassLoader
         this.id = id;
     }
 
+    public int getGeneration()
+    {
+        return generation;
+    }
+
     @Override
     public Class<?> loadClass(String name) throws ClassNotFoundException
     {
diff --git a/test/distributed/org/apache/cassandra/distributed/impl/InstanceKiller.java b/test/distributed/org/apache/cassandra/distributed/impl/InstanceKiller.java
new file mode 100644
index 0000000000..e7ca49bed7
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/distributed/impl/InstanceKiller.java
@@ -0,0 +1,50 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.impl;
+
+import java.util.concurrent.atomic.AtomicLong;
+
+import org.apache.cassandra.utils.JVMStabilityInspector;
+
+public class InstanceKiller extends JVMStabilityInspector.Killer
+{
+    private static final AtomicLong KILL_ATTEMPTS = new AtomicLong(0);
+
+    public static long getKillAttempts()
+    {
+        return KILL_ATTEMPTS.get();
+    }
+
+    public static void clear()
+    {
+        KILL_ATTEMPTS.set(0);
+    }
+
+    @Override
+    protected void killCurrentJVM(Throwable t, boolean quiet)
+    {
+        KILL_ATTEMPTS.incrementAndGet();
+        // the bad part is that System.exit kills the JVM, so all code which calls kill won't hit the
+        // next line; yet in in-JVM dtests System.exit is not desirable, so need to rely on a runtime exception
+        // as a means to try to stop execution
+        throw new InstanceShutdown();
+    }
+
+    public static final class InstanceShutdown extends RuntimeException { }
+}
diff --git a/test/distributed/org/apache/cassandra/distributed/test/FailingRepairTest.java b/test/distributed/org/apache/cassandra/distributed/test/FailingRepairTest.java
new file mode 100644
index 0000000000..25e299c0d6
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/distributed/test/FailingRepairTest.java
@@ -0,0 +1,346 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import com.google.common.util.concurrent.Uninterruptibles;
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+import org.junit.runners.Parameterized.Parameters;
+
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.ConsistencyLevel;
+import org.apache.cassandra.db.DataRange;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.PartitionPosition;
+import org.apache.cassandra.db.filter.ColumnFilter;
+import org.apache.cassandra.db.rows.UnfilteredRowIterator;
+import org.apache.cassandra.dht.AbstractBounds;
+import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.IIsolatedExecutor.SerializableRunnable;
+import org.apache.cassandra.distributed.impl.IInvokableInstance;
+import org.apache.cassandra.distributed.impl.InstanceKiller;
+import org.apache.cassandra.io.sstable.CorruptSSTableException;
+import org.apache.cassandra.io.sstable.ISSTableScanner;
+import org.apache.cassandra.io.sstable.format.ForwardingSSTableReader;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.io.sstable.format.SSTableReadsListener;
+import org.apache.cassandra.io.util.ChannelProxy;
+import org.apache.cassandra.net.Verb;
+import org.apache.cassandra.repair.RepairParallelism;
+import org.apache.cassandra.repair.messages.RepairOption;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.ActiveRepairService.ParentRepairStatus;
+import org.apache.cassandra.service.StorageService;
+
+@RunWith(Parameterized.class)
+public class FailingRepairTest extends DistributedTestBase implements Serializable
+{
+    private static Cluster CLUSTER;
+
+    private final Verb messageType;
+    private final RepairParallelism parallelism;
+    private final boolean withTracing;
+    private final SerializableRunnable setup;
+
+    public FailingRepairTest(Verb messageType, RepairParallelism parallelism, boolean withTracing, SerializableRunnable setup)
+    {
+        this.messageType = messageType;
+        this.parallelism = parallelism;
+        this.withTracing = withTracing;
+        this.setup = setup;
+    }
+
+    @Parameters(name = "{0}/{1}/{2}")
+    public static Collection<Object[]> messages()
+    {
+        List<Object[]> tests = new ArrayList<>();
+        for (RepairParallelism parallelism : RepairParallelism.values())
+        {
+            for (Boolean withTracing : Arrays.asList(Boolean.TRUE, Boolean.FALSE))
+            {
+                tests.add(new Object[]{ Verb.VALIDATION_REQ, parallelism, withTracing, failingReaders(Verb.VALIDATION_REQ, parallelism, withTracing) });
+            }
+        }
+        return tests;
+    }
+
+    private static SerializableRunnable failingReaders(Verb type, RepairParallelism parallelism, boolean withTracing)
+    {
+        return () -> {
+            String cfName = getCfName(type, parallelism, withTracing);
+            ColumnFamilyStore cf = Keyspace.open(KEYSPACE).getColumnFamilyStore(cfName);
+            cf.forceBlockingFlush();
+            Set<SSTableReader> remove = cf.getLiveSSTables();
+            Set<SSTableReader> replace = new HashSet<>();
+            if (type == Verb.VALIDATION_REQ)
+            {
+                for (SSTableReader r : remove)
+                    replace.add(new FailingSSTableReader(r));
+            }
+            else
+            {
+                throw new UnsupportedOperationException("verb: " + type);
+            }
+            cf.getTracker().removeUnsafe(remove);
+            cf.addSSTables(replace);
+        };
+    }
+
+    private static String getCfName(Verb type, RepairParallelism parallelism, boolean withTracing)
+    {
+        return type.name().toLowerCase() + "_" + parallelism.name().toLowerCase() + "_" + withTracing;
+    }
+
+    @BeforeClass
+    public static void setupCluster() throws IOException
+    {
+        // streaming requires networking ATM
+        // streaming also requires gossip or isn't setup properly
+        CLUSTER = init(Cluster.build(2)
+                    .withConfig(c -> c.with(Feature.NETWORK)
+                                      .with(Feature.GOSSIP)
+                                      .set("disk_failure_policy", "die"))
+                    .start());
+    }
+
+    @AfterClass
+    public static void teardownCluster()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Before
+    public void cleanupState()
+    {
+        for (int i = 1; i <= CLUSTER.size(); i++)
+            CLUSTER.get(i).runOnInstance(() -> InstanceKiller.clear());
+    }
+
+    @Test(timeout = 10 * 60 * 1000)
+    public void testFailingMessage() throws IOException
+    {
+        final int replica = 1;
+        final int coordinator = 2;
+        String tableName = getCfName(messageType, parallelism, withTracing);
+        String fqtn = KEYSPACE + "." + tableName;
+
+        CLUSTER.schemaChange("CREATE TABLE " + fqtn + " (k INT, PRIMARY KEY (k))");
+
+        // create data which will NOT conflict
+        int lhsOffset = 10;
+        int rhsOffset = 20;
+        int limit = rhsOffset + (rhsOffset - lhsOffset);
+
+        // setup data which is consistent on both sides
+        for (int i = 0; i < lhsOffset; i++)
+            CLUSTER.coordinator(replica)
+                   .execute("INSERT INTO " + fqtn + " (k) VALUES (?)", ConsistencyLevel.ALL, i);
+
+        // create data on LHS which does NOT exist in RHS
+        for (int i = lhsOffset; i < rhsOffset; i++)
+            CLUSTER.get(replica).executeInternal("INSERT INTO " + fqtn + " (k) VALUES (?)", i);
+
+        // create data on RHS which does NOT exist in LHS
+        for (int i = rhsOffset; i < limit; i++)
+            CLUSTER.get(coordinator).executeInternal("INSERT INTO " + fqtn + " (k) VALUES (?)", i);
+
+        // at this point, the two nodes should be out of sync, so confirm missing data
+        // node 1
+        Object[][] node1Records = toRows(IntStream.range(0, rhsOffset));
+        Object[][] node1Actuals = toNaturalOrder(CLUSTER.get(replica).executeInternal("SELECT k FROM " + fqtn));
+        Assert.assertArrayEquals(node1Records, node1Actuals);
+
+        // node 2
+        Object[][] node2Records = toRows(IntStream.concat(IntStream.range(0, lhsOffset), IntStream.range(rhsOffset, limit)));
+        Object[][] node2Actuals = toNaturalOrder(CLUSTER.get(coordinator).executeInternal("SELECT k FROM " + fqtn));
+        Assert.assertArrayEquals(node2Records, node2Actuals);
+
+        // Inject the failure
+        CLUSTER.get(replica).runOnInstance(() -> setup.run());
+
+        // run a repair which is expected to fail
+        List<String> repairStatus = CLUSTER.get(coordinator).callOnInstance(() -> {
+            // need all ranges on the host
+            String ranges = StorageService.instance.getLocalAndPendingRanges(KEYSPACE).stream()
+                                                   .map(r -> r.left + ":" + r.right)
+                                                   .collect(Collectors.joining(","));
+            Map<String, String> args = new HashMap<String, String>()
+            {{
+                put(RepairOption.PARALLELISM_KEY, parallelism.getName());
+                put(RepairOption.PRIMARY_RANGE_KEY, "false");
+                put(RepairOption.INCREMENTAL_KEY, "false");
+                put(RepairOption.TRACE_KEY, Boolean.toString(withTracing));
+                put(RepairOption.PULL_REPAIR_KEY, "false");
+                put(RepairOption.FORCE_REPAIR_KEY, "false");
+                put(RepairOption.RANGES_KEY, ranges);
+                put(RepairOption.COLUMNFAMILIES_KEY, tableName);
+            }};
+            int cmd = StorageService.instance.repairAsync(KEYSPACE, args);
+            Assert.assertFalse("repair return status was 0, expected non-zero return status, 0 indicates repair not submitted", cmd == 0);
+            List<String> status;
+            do
+            {
+                Uninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);
+                status = StorageService.instance.getParentRepairStatus(cmd);
+            } while (status == null || status.get(0).equals(ParentRepairStatus.IN_PROGRESS.name()));
+
+            return status;
+        });
+        Assert.assertEquals(repairStatus.toString(), ParentRepairStatus.FAILED, ParentRepairStatus.valueOf(repairStatus.get(0)));
+
+        // its possible that the coordinator gets the message that the replica failed before the replica completes
+        // shutting down; this then means that isKilled could be updated after the fact
+        IInvokableInstance replicaInstance = CLUSTER.get(replica);
+        while (replicaInstance.killAttempts() <= 0)
+            Uninterruptibles.sleepUninterruptibly(50, TimeUnit.MILLISECONDS);
+
+        Assert.assertEquals("replica should be killed", 1, replicaInstance.killAttempts());
+        Assert.assertEquals("coordinator should not be killed", 0, CLUSTER.get(coordinator).killAttempts());
+    }
+
+    private static Object[][] toNaturalOrder(Object[][] actuals)
+    {
+        // data is returned in token order, so rather than try to be fancy and order expected in token order
+        // convert it to natural
+        int[] values = new int[actuals.length];
+        for (int i = 0; i < values.length; i++)
+            values[i] = (Integer) actuals[i][0];
+        Arrays.sort(values);
+        return toRows(IntStream.of(values));
+    }
+
+    private static Object[][] toRows(IntStream values)
+    {
+        return values
+               .mapToObj(v -> new Object[]{ v })
+               .toArray(Object[][]::new);
+    }
+
+    private static final class FailingSSTableReader extends ForwardingSSTableReader
+    {
+
+        private FailingSSTableReader(SSTableReader delegate)
+        {
+            super(delegate);
+        }
+
+        public ISSTableScanner getScanner()
+        {
+            return new FailingISSTableScanner();
+        }
+
+        public ISSTableScanner getScanner(Collection<Range<Token>> ranges)
+        {
+            return new FailingISSTableScanner();
+        }
+
+        public ISSTableScanner getScanner(Iterator<AbstractBounds<PartitionPosition>> rangeIterator)
+        {
+            return new FailingISSTableScanner();
+        }
+
+        public ISSTableScanner getScanner(ColumnFilter columns, DataRange dataRange, SSTableReadsListener listener)
+        {
+            return new FailingISSTableScanner();
+        }
+
+        public ChannelProxy getDataChannel()
+        {
+            throw new RuntimeException();
+        }
+
+        public String toString()
+        {
+            return "FailingSSTableReader[" + super.toString() + "]";
+        }
+    }
+
+    private static final class FailingISSTableScanner implements ISSTableScanner
+    {
+        public long getLengthInBytes()
+        {
+            return 0;
+        }
+
+        public long getCompressedLengthInBytes()
+        {
+            return 0;
+        }
+
+        public long getCurrentPosition()
+        {
+            return 0;
+        }
+
+        public long getBytesScanned()
+        {
+            return 0;
+        }
+
+        public Set<SSTableReader> getBackingSSTables()
+        {
+            return Collections.emptySet();
+        }
+
+        public TableMetadata metadata()
+        {
+            return null;
+        }
+
+        public void close()
+        {
+
+        }
+
+        public boolean hasNext()
+        {
+            throw new CorruptSSTableException(new IOException("Test commands it"), "mahahahaha!");
+        }
+
+        public UnfilteredRowIterator next()
+        {
+            throw new CorruptSSTableException(new IOException("Test commands it"), "mahahahaha!");
+        }
+    }
+}
diff --git a/test/distributed/org/apache/cassandra/io/sstable/format/ForwardingSSTableReader.java b/test/distributed/org/apache/cassandra/io/sstable/format/ForwardingSSTableReader.java
new file mode 100644
index 0000000000..40adc9cdec
--- /dev/null
+++ b/test/distributed/org/apache/cassandra/io/sstable/format/ForwardingSSTableReader.java
@@ -0,0 +1,679 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.io.sstable.format;
+
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.List;
+import java.util.UUID;
+
+import com.google.common.util.concurrent.RateLimiter;
+
+import org.apache.cassandra.cache.InstrumentingCache;
+import org.apache.cassandra.cache.KeyCacheKey;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.DataRange;
+import org.apache.cassandra.db.DecoratedKey;
+import org.apache.cassandra.db.PartitionPosition;
+import org.apache.cassandra.db.RowIndexEntry;
+import org.apache.cassandra.db.Slices;
+import org.apache.cassandra.db.filter.ColumnFilter;
+import org.apache.cassandra.db.rows.EncodingStats;
+import org.apache.cassandra.db.rows.UnfilteredRowIterator;
+import org.apache.cassandra.dht.AbstractBounds;
+import org.apache.cassandra.dht.IPartitioner;
+import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.io.compress.CompressionMetadata;
+import org.apache.cassandra.io.sstable.Component;
+import org.apache.cassandra.io.sstable.ISSTableScanner;
+import org.apache.cassandra.io.sstable.SSTable;
+import org.apache.cassandra.io.sstable.metadata.StatsMetadata;
+import org.apache.cassandra.io.util.ChannelProxy;
+import org.apache.cassandra.io.util.FileDataInput;
+import org.apache.cassandra.io.util.FileHandle;
+import org.apache.cassandra.io.util.RandomAccessReader;
+import org.apache.cassandra.metrics.RestorableMeter;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.schema.TableMetadataRef;
+import org.apache.cassandra.utils.EstimatedHistogram;
+import org.apache.cassandra.utils.IFilter;
+import org.apache.cassandra.utils.concurrent.Ref;
+
+public abstract class ForwardingSSTableReader extends SSTableReader
+{
+    private final SSTableReader delegate;
+    private final Ref<SSTableReader> selfRef;
+
+    public ForwardingSSTableReader(SSTableReader delegate)
+    {
+        super(delegate.descriptor, SSTable.componentsFor(delegate.descriptor),
+              TableMetadataRef.forOfflineTools(delegate.metadata()), delegate.maxDataAge, delegate.getSSTableMetadata(),
+              delegate.openReason, delegate.header);
+        this.delegate = delegate;
+        this.first = delegate.first;
+        this.last = delegate.last;
+        this.selfRef = new Ref<>(this, new Tidy()
+        {
+            public void tidy() throws Exception
+            {
+                Ref<SSTableReader> ref = delegate.tryRef();
+                if (ref != null)
+                    ref.release();
+            }
+
+            public String name()
+            {
+                return descriptor.toString();
+            }
+        });
+    }
+
+    protected RowIndexEntry getPosition(PartitionPosition key, Operator op, boolean updateCacheAndStats, boolean permitMatchPastLast, SSTableReadsListener listener)
+    {
+        return delegate.getPosition(key, op, updateCacheAndStats, permitMatchPastLast, listener);
+    }
+
+    public UnfilteredRowIterator iterator(DecoratedKey key, Slices slices, ColumnFilter selectedColumns, boolean reversed, SSTableReadsListener listener)
+    {
+        return delegate.iterator(key, slices, selectedColumns, reversed, listener);
+    }
+
+    public UnfilteredRowIterator iterator(FileDataInput file, DecoratedKey key, RowIndexEntry indexEntry, Slices slices, ColumnFilter selectedColumns, boolean reversed)
+    {
+        return delegate.iterator(file, key, indexEntry, slices, selectedColumns, reversed);
+    }
+
+    public UnfilteredRowIterator simpleIterator(FileDataInput file, DecoratedKey key, RowIndexEntry indexEntry, boolean tombstoneOnly)
+    {
+        return delegate.simpleIterator(file, key, indexEntry, tombstoneOnly);
+    }
+
+    public ISSTableScanner getScanner()
+    {
+        return delegate.getScanner();
+    }
+
+    public ISSTableScanner getScanner(Collection<Range<Token>> ranges)
+    {
+        return delegate.getScanner(ranges);
+    }
+
+    public ISSTableScanner getScanner(Iterator<AbstractBounds<PartitionPosition>> rangeIterator)
+    {
+        return delegate.getScanner(rangeIterator);
+    }
+
+    public ISSTableScanner getScanner(ColumnFilter columns, DataRange dataRange, SSTableReadsListener listener)
+    {
+        return delegate.getScanner(columns, dataRange, listener);
+    }
+
+    public void setupOnline()
+    {
+        delegate.setupOnline();
+    }
+
+    public String getFilename()
+    {
+        return delegate.getFilename();
+    }
+
+    public boolean equals(Object that)
+    {
+        return delegate.equals(that);
+    }
+
+    public int hashCode()
+    {
+        return delegate.hashCode();
+    }
+
+    public boolean loadSummary()
+    {
+        return delegate.loadSummary();
+    }
+
+    public void saveSummary()
+    {
+        delegate.saveSummary();
+    }
+
+    public void saveBloomFilter()
+    {
+        delegate.saveBloomFilter();
+    }
+
+    public void setReplaced()
+    {
+        delegate.setReplaced();
+    }
+
+    public boolean isReplaced()
+    {
+        return delegate.isReplaced();
+    }
+
+    public void runOnClose(Runnable runOnClose)
+    {
+        delegate.runOnClose(runOnClose);
+    }
+
+    public SSTableReader cloneWithRestoredStart(DecoratedKey restoredStart)
+    {
+        return delegate.cloneWithRestoredStart(restoredStart);
+    }
+
+    public SSTableReader cloneWithNewStart(DecoratedKey newStart, Runnable runOnClose)
+    {
+        return delegate.cloneWithNewStart(newStart, runOnClose);
+    }
+
+    public SSTableReader cloneWithNewSummarySamplingLevel(ColumnFamilyStore parent, int samplingLevel) throws IOException
+    {
+        return delegate.cloneWithNewSummarySamplingLevel(parent, samplingLevel);
+    }
+
+    public RestorableMeter getReadMeter()
+    {
+        return delegate.getReadMeter();
+    }
+
+    public int getIndexSummarySamplingLevel()
+    {
+        return delegate.getIndexSummarySamplingLevel();
+    }
+
+    public long getIndexSummaryOffHeapSize()
+    {
+        return delegate.getIndexSummaryOffHeapSize();
+    }
+
+    public int getMinIndexInterval()
+    {
+        return delegate.getMinIndexInterval();
+    }
+
+    public double getEffectiveIndexInterval()
+    {
+        return delegate.getEffectiveIndexInterval();
+    }
+
+    public void releaseSummary()
+    {
+        delegate.releaseSummary();
+    }
+
+    public long getIndexScanPosition(PartitionPosition key)
+    {
+        return delegate.getIndexScanPosition(key);
+    }
+
+    public CompressionMetadata getCompressionMetadata()
+    {
+        return delegate.getCompressionMetadata();
+    }
+
+    public long getCompressionMetadataOffHeapSize()
+    {
+        return delegate.getCompressionMetadataOffHeapSize();
+    }
+
+    public void forceFilterFailures()
+    {
+        delegate.forceFilterFailures();
+    }
+
+    public IFilter getBloomFilter()
+    {
+        return delegate.getBloomFilter();
+    }
+
+    public long getBloomFilterSerializedSize()
+    {
+        return delegate.getBloomFilterSerializedSize();
+    }
+
+    public long getBloomFilterOffHeapSize()
+    {
+        return delegate.getBloomFilterOffHeapSize();
+    }
+
+    public long estimatedKeys()
+    {
+        return delegate.estimatedKeys();
+    }
+
+    public long estimatedKeysForRanges(Collection<Range<Token>> ranges)
+    {
+        return delegate.estimatedKeysForRanges(ranges);
+    }
+
+    public int getIndexSummarySize()
+    {
+        return delegate.getIndexSummarySize();
+    }
+
+    public int getMaxIndexSummarySize()
+    {
+        return delegate.getMaxIndexSummarySize();
+    }
+
+    public byte[] getIndexSummaryKey(int index)
+    {
+        return delegate.getIndexSummaryKey(index);
+    }
+
+    public Iterable<DecoratedKey> getKeySamples(Range<Token> range)
+    {
+        return delegate.getKeySamples(range);
+    }
+
+    public List<PartitionPositionBounds> getPositionsForRanges(Collection<Range<Token>> ranges)
+    {
+        return delegate.getPositionsForRanges(ranges);
+    }
+
+    public KeyCacheKey getCacheKey(DecoratedKey key)
+    {
+        return delegate.getCacheKey(key);
+    }
+
+    public void cacheKey(DecoratedKey key, RowIndexEntry info)
+    {
+        delegate.cacheKey(key, info);
+    }
+
+    public RowIndexEntry getCachedPosition(DecoratedKey key, boolean updateStats)
+    {
+        return delegate.getCachedPosition(key, updateStats);
+    }
+
+    protected RowIndexEntry getCachedPosition(KeyCacheKey unifiedKey, boolean updateStats)
+    {
+        return delegate.getCachedPosition(unifiedKey, updateStats);
+    }
+
+    public boolean isKeyCacheEnabled()
+    {
+        return delegate.isKeyCacheEnabled();
+    }
+
+    public DecoratedKey firstKeyBeyond(PartitionPosition token)
+    {
+        return delegate.firstKeyBeyond(token);
+    }
+
+    public long uncompressedLength()
+    {
+        return delegate.uncompressedLength();
+    }
+
+    public long onDiskLength()
+    {
+        return delegate.onDiskLength();
+    }
+
+    public double getCrcCheckChance()
+    {
+        return delegate.getCrcCheckChance();
+    }
+
+    public void setCrcCheckChance(double crcCheckChance)
+    {
+        delegate.setCrcCheckChance(crcCheckChance);
+    }
+
+    public void markObsolete(Runnable tidier)
+    {
+        delegate.markObsolete(tidier);
+    }
+
+    public boolean isMarkedCompacted()
+    {
+        return delegate.isMarkedCompacted();
+    }
+
+    public void markSuspect()
+    {
+        delegate.markSuspect();
+    }
+
+    public void unmarkSuspect()
+    {
+        delegate.unmarkSuspect();
+    }
+
+    public boolean isMarkedSuspect()
+    {
+        return delegate.isMarkedSuspect();
+    }
+
+    public ISSTableScanner getScanner(Range<Token> range)
+    {
+        return delegate.getScanner(range);
+    }
+
+    public FileDataInput getFileDataInput(long position)
+    {
+        return delegate.getFileDataInput(position);
+    }
+
+    public boolean newSince(long age)
+    {
+        return delegate.newSince(age);
+    }
+
+    public void createLinks(String snapshotDirectoryPath)
+    {
+        delegate.createLinks(snapshotDirectoryPath);
+    }
+
+    public boolean isRepaired()
+    {
+        return delegate.isRepaired();
+    }
+
+    public DecoratedKey keyAt(long indexPosition) throws IOException
+    {
+        return delegate.keyAt(indexPosition);
+    }
+
+    public boolean isPendingRepair()
+    {
+        return delegate.isPendingRepair();
+    }
+
+    public UUID getPendingRepair()
+    {
+        return delegate.getPendingRepair();
+    }
+
+    public long getRepairedAt()
+    {
+        return delegate.getRepairedAt();
+    }
+
+    public boolean isTransient()
+    {
+        return delegate.isTransient();
+    }
+
+    public boolean intersects(Collection<Range<Token>> ranges)
+    {
+        return delegate.intersects(ranges);
+    }
+
+    public long getBloomFilterFalsePositiveCount()
+    {
+        return delegate.getBloomFilterFalsePositiveCount();
+    }
+
+    public long getRecentBloomFilterFalsePositiveCount()
+    {
+        return delegate.getRecentBloomFilterFalsePositiveCount();
+    }
+
+    public long getBloomFilterTruePositiveCount()
+    {
+        return delegate.getBloomFilterTruePositiveCount();
+    }
+
+    public long getRecentBloomFilterTruePositiveCount()
+    {
+        return delegate.getRecentBloomFilterTruePositiveCount();
+    }
+
+    public InstrumentingCache<KeyCacheKey, RowIndexEntry> getKeyCache()
+    {
+        return delegate.getKeyCache();
+    }
+
+    public EstimatedHistogram getEstimatedPartitionSize()
+    {
+        return delegate.getEstimatedPartitionSize();
+    }
+
+    public EstimatedHistogram getEstimatedCellPerPartitionCount()
+    {
+        return delegate.getEstimatedCellPerPartitionCount();
+    }
+
+    public double getEstimatedDroppableTombstoneRatio(int gcBefore)
+    {
+        return delegate.getEstimatedDroppableTombstoneRatio(gcBefore);
+    }
+
+    public double getDroppableTombstonesBefore(int gcBefore)
+    {
+        return delegate.getDroppableTombstonesBefore(gcBefore);
+    }
+
+    public double getCompressionRatio()
+    {
+        return delegate.getCompressionRatio();
+    }
+
+    public long getMinTimestamp()
+    {
+        return delegate.getMinTimestamp();
+    }
+
+    public long getMaxTimestamp()
+    {
+        return delegate.getMaxTimestamp();
+    }
+
+    public int getMinLocalDeletionTime()
+    {
+        return delegate.getMinLocalDeletionTime();
+    }
+
+    public int getMaxLocalDeletionTime()
+    {
+        return delegate.getMaxLocalDeletionTime();
+    }
+
+    public boolean mayHaveTombstones()
+    {
+        return delegate.mayHaveTombstones();
+    }
+
+    public int getMinTTL()
+    {
+        return delegate.getMinTTL();
+    }
+
+    public int getMaxTTL()
+    {
+        return delegate.getMaxTTL();
+    }
+
+    public long getTotalColumnsSet()
+    {
+        return delegate.getTotalColumnsSet();
+    }
+
+    public long getTotalRows()
+    {
+        return delegate.getTotalRows();
+    }
+
+    public int getAvgColumnSetPerRow()
+    {
+        return delegate.getAvgColumnSetPerRow();
+    }
+
+    public int getSSTableLevel()
+    {
+        return delegate.getSSTableLevel();
+    }
+
+    public void reloadSSTableMetadata() throws IOException
+    {
+        delegate.reloadSSTableMetadata();
+    }
+
+    public StatsMetadata getSSTableMetadata()
+    {
+        return delegate.getSSTableMetadata();
+    }
+
+    public RandomAccessReader openDataReader(RateLimiter limiter)
+    {
+        return delegate.openDataReader(limiter);
+    }
+
+    public RandomAccessReader openDataReader()
+    {
+        return delegate.openDataReader();
+    }
+
+    public RandomAccessReader openIndexReader()
+    {
+        return delegate.openIndexReader();
+    }
+
+    public ChannelProxy getIndexChannel()
+    {
+        return delegate.getIndexChannel();
+    }
+
+    public FileHandle getIndexFile()
+    {
+        return delegate.getIndexFile();
+    }
+
+    public long getCreationTimeFor(Component component)
+    {
+        return delegate.getCreationTimeFor(component);
+    }
+
+    public long getKeyCacheHit()
+    {
+        return delegate.getKeyCacheHit();
+    }
+
+    public long getKeyCacheRequest()
+    {
+        return delegate.getKeyCacheRequest();
+    }
+
+    public void incrementReadCount()
+    {
+        delegate.incrementReadCount();
+    }
+
+    public EncodingStats stats()
+    {
+        return delegate.stats();
+    }
+
+    public Ref<SSTableReader> tryRef()
+    {
+        return selfRef.tryRef();
+    }
+
+    public Ref<SSTableReader> selfRef()
+    {
+        return selfRef;
+    }
+
+    public Ref<SSTableReader> ref()
+    {
+        return selfRef.ref();
+    }
+
+    void setup(boolean trackHotness)
+    {
+        delegate.setup(trackHotness);
+    }
+
+    public void overrideReadMeter(RestorableMeter readMeter)
+    {
+        delegate.overrideReadMeter(readMeter);
+    }
+
+    public void addTo(Ref.IdentityCollection identities)
+    {
+        delegate.addTo(identities);
+    }
+
+    public TableMetadata metadata()
+    {
+        return delegate.metadata();
+    }
+
+    public IPartitioner getPartitioner()
+    {
+        return delegate.getPartitioner();
+    }
+
+    public DecoratedKey decorateKey(ByteBuffer key)
+    {
+        return delegate.decorateKey(key);
+    }
+
+    public String getIndexFilename()
+    {
+        return delegate.getIndexFilename();
+    }
+
+    public String getColumnFamilyName()
+    {
+        return delegate.getColumnFamilyName();
+    }
+
+    public String getKeyspaceName()
+    {
+        return delegate.getKeyspaceName();
+    }
+
+    public List<String> getAllFilePaths()
+    {
+        return delegate.getAllFilePaths();
+    }
+
+//    protected long estimateRowsFromIndex(RandomAccessReader ifile) throws IOException
+//    {
+//        return delegate.estimateRowsFromIndex(ifile);
+//    }
+
+    public long bytesOnDisk()
+    {
+        return delegate.bytesOnDisk();
+    }
+
+    public String toString()
+    {
+        return delegate.toString();
+    }
+
+    public AbstractBounds<Token> getBounds()
+    {
+        return delegate.getBounds();
+    }
+
+    public ChannelProxy getDataChannel()
+    {
+        return delegate.getDataChannel();
+    }
+}
diff --git a/test/unit/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutorTest.java b/test/unit/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutorTest.java
index 92762488d1..58200c93a5 100644
--- a/test/unit/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutorTest.java
+++ b/test/unit/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutorTest.java
@@ -21,13 +21,25 @@ package org.apache.cassandra.concurrent;
  */
 
 
+import java.util.UUID;
+import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.RunnableFuture;
 import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
 
+import com.google.common.base.Throwables;
+import com.google.common.net.InetAddresses;
+import com.google.common.util.concurrent.ListenableFutureTask;
+import org.junit.Assert;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.locator.InetAddressAndPort;
+import org.apache.cassandra.tracing.TraceState;
+import org.apache.cassandra.tracing.TraceStateImpl;
+import org.apache.cassandra.tracing.Tracing;
 import org.apache.cassandra.utils.WrappedRunnable;
 
 public class DebuggableThreadPoolExecutorTest
@@ -65,4 +77,153 @@ public class DebuggableThreadPoolExecutorTest
         long delta = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start);
         assert delta >= 9 * 50 : delta;
     }
+
+    @Test
+    public void testExecuteFutureTaskWhileTracing()
+    {
+        LinkedBlockingQueue<Runnable> q = new LinkedBlockingQueue<Runnable>(1);
+        DebuggableThreadPoolExecutor executor = new DebuggableThreadPoolExecutor(1,
+                                                                                 Integer.MAX_VALUE,
+                                                                                 TimeUnit.MILLISECONDS,
+                                                                                 q,
+                                                                                 new NamedThreadFactory("TEST"));
+        Runnable test = () -> executor.execute(failingTask());
+        try
+        {
+            // make sure the non-tracing case works
+            Throwable cause = catchUncaughtExceptions(test);
+            Assert.assertEquals(DebuggingThrowsException.class, cause.getClass());
+
+            // tracing should have the same semantics
+            cause = catchUncaughtExceptions(() -> withTracing(test));
+            Assert.assertEquals(DebuggingThrowsException.class, cause.getClass());
+        }
+        finally
+        {
+            executor.shutdown();
+        }
+    }
+
+    @Test
+    public void testSubmitFutureTaskWhileTracing()
+    {
+        LinkedBlockingQueue<Runnable> q = new LinkedBlockingQueue<Runnable>(1);
+        DebuggableThreadPoolExecutor executor = new DebuggableThreadPoolExecutor(1,
+                                                                                 Integer.MAX_VALUE,
+                                                                                 TimeUnit.MILLISECONDS,
+                                                                                 q,
+                                                                                 new NamedThreadFactory("TEST"));
+        FailingRunnable test = () -> executor.submit(failingTask()).get();
+        try
+        {
+            // make sure the non-tracing case works
+            Throwable cause = catchUncaughtExceptions(test);
+            Assert.assertEquals(DebuggingThrowsException.class, cause.getClass());
+
+            // tracing should have the same semantics
+            cause = catchUncaughtExceptions(() -> withTracing(test));
+            Assert.assertEquals(DebuggingThrowsException.class, cause.getClass());
+        }
+        finally
+        {
+            executor.shutdown();
+        }
+    }
+
+    @Test
+    public void testSubmitWithResultFutureTaskWhileTracing()
+    {
+        LinkedBlockingQueue<Runnable> q = new LinkedBlockingQueue<Runnable>(1);
+        DebuggableThreadPoolExecutor executor = new DebuggableThreadPoolExecutor(1,
+                                                                                 Integer.MAX_VALUE,
+                                                                                 TimeUnit.MILLISECONDS,
+                                                                                 q,
+                                                                                 new NamedThreadFactory("TEST"));
+        FailingRunnable test = () -> executor.submit(failingTask(), 42).get();
+        try
+        {
+            Throwable cause = catchUncaughtExceptions(test);
+            Assert.assertEquals(DebuggingThrowsException.class, cause.getClass());
+            cause = catchUncaughtExceptions(() -> withTracing(test));
+            Assert.assertEquals(DebuggingThrowsException.class, cause.getClass());
+        }
+        finally
+        {
+            executor.shutdown();
+        }
+    }
+
+    private static void withTracing(Runnable fn)
+    {
+        TraceState state = Tracing.instance.get();
+        try {
+            Tracing.instance.set(new TraceStateImpl(InetAddressAndPort.getByAddress(InetAddresses.forString("127.0.0.1")), UUID.randomUUID(), Tracing.TraceType.NONE));
+            fn.run();
+        }
+        finally
+        {
+            Tracing.instance.set(state);
+        }
+    }
+
+    private static Throwable catchUncaughtExceptions(Runnable fn)
+    {
+        Thread.UncaughtExceptionHandler defaultHandler = Thread.getDefaultUncaughtExceptionHandler();
+        try
+        {
+            AtomicReference<Throwable> ref = new AtomicReference<>(null);
+            CountDownLatch latch = new CountDownLatch(1);
+            Thread.setDefaultUncaughtExceptionHandler((thread, cause) -> {
+                ref.set(cause);
+                latch.countDown();
+            });
+            fn.run();
+            try
+            {
+                latch.await(30, TimeUnit.SECONDS);
+            }
+            catch (InterruptedException e)
+            {
+                throw new AssertionError(e);
+            }
+            return ref.get();
+        }
+        finally
+        {
+            Thread.setDefaultUncaughtExceptionHandler(defaultHandler);
+        }
+    }
+
+    private static String failingFunction()
+    {
+        throw new DebuggingThrowsException();
+    }
+
+    private static RunnableFuture<String> failingTask()
+    {
+        return ListenableFutureTask.create(DebuggableThreadPoolExecutorTest::failingFunction);
+    }
+
+    private static final class DebuggingThrowsException extends RuntimeException {
+
+    }
+
+    // REVIEWER : I know this is the same as WrappedRunnable, but that doesn't support lambda...
+    private interface FailingRunnable extends Runnable
+    {
+        void doRun() throws Throwable;
+
+        default void run()
+        {
+            try
+            {
+                doRun();
+            }
+            catch (Throwable t)
+            {
+                Throwables.throwIfUnchecked(t);
+                throw new RuntimeException(t);
+            }
+        }
+    }
 }
