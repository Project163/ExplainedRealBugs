diff --git a/modules/accord b/modules/accord
index c2ef0643ab..1ce7122e2e 160000
--- a/modules/accord
+++ b/modules/accord
@@ -1 +1 @@
-Subproject commit c2ef0643ab671067d39e7ce688eea493e9ee018d
+Subproject commit 1ce7122e2e305f7510ec4c10c7587822c0549364
diff --git a/src/java/org/apache/cassandra/db/EmptyIterators.java b/src/java/org/apache/cassandra/db/EmptyIterators.java
index d0564d35d3..cd4979368f 100644
--- a/src/java/org/apache/cassandra/db/EmptyIterators.java
+++ b/src/java/org/apache/cassandra/db/EmptyIterators.java
@@ -136,7 +136,7 @@ public class EmptyIterators
         }
     }
 
-    private static class EmptyUnfilteredRowIterator extends EmptyBaseRowIterator<Unfiltered> implements UnfilteredRowIterator
+    public static class EmptyUnfilteredRowIterator extends EmptyBaseRowIterator<Unfiltered> implements UnfilteredRowIterator
     {
         final DeletionTime partitionLevelDeletion;
         public EmptyUnfilteredRowIterator(RegularAndStaticColumns columns, TableMetadata metadata, DecoratedKey partitionKey,
diff --git a/src/java/org/apache/cassandra/io/FSError.java b/src/java/org/apache/cassandra/io/FSError.java
index 4c06d9c61f..241c8c5585 100644
--- a/src/java/org/apache/cassandra/io/FSError.java
+++ b/src/java/org/apache/cassandra/io/FSError.java
@@ -67,6 +67,12 @@ public abstract class FSError extends IOError
         return null;
     }
 
+    @Override
+    public String getMessage()
+    {
+        return message;
+    }
+
     @Override
     public String toString()
     {
diff --git a/src/java/org/apache/cassandra/io/sstable/format/big/SSTableIterator.java b/src/java/org/apache/cassandra/io/sstable/format/big/SSTableIterator.java
index 61d6527f5c..d8fff5d95b 100644
--- a/src/java/org/apache/cassandra/io/sstable/format/big/SSTableIterator.java
+++ b/src/java/org/apache/cassandra/io/sstable/format/big/SSTableIterator.java
@@ -183,4 +183,10 @@ public class SSTableIterator extends AbstractSSTableIterator<RowIndexEntry>
             }
         }
     }
+
+    @Override
+    public String toString()
+    {
+        return sstable.toString();
+    }
 }
diff --git a/src/java/org/apache/cassandra/io/sstable/format/big/SSTableReversedIterator.java b/src/java/org/apache/cassandra/io/sstable/format/big/SSTableReversedIterator.java
index b44c0797ce..830f159933 100644
--- a/src/java/org/apache/cassandra/io/sstable/format/big/SSTableReversedIterator.java
+++ b/src/java/org/apache/cassandra/io/sstable/format/big/SSTableReversedIterator.java
@@ -463,4 +463,10 @@ public class SSTableReversedIterator extends AbstractSSTableIterator<RowIndexEnt
             return iterator.hasNext() ? next : endOfData();
         }
     }
+
+    @Override
+    public String toString()
+    {
+        return sstable.toString();
+    }
 }
diff --git a/src/java/org/apache/cassandra/service/accord/AccordJournal.java b/src/java/org/apache/cassandra/service/accord/AccordJournal.java
index e4c241f859..f98061f887 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordJournal.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordJournal.java
@@ -223,7 +223,10 @@ public class AccordJournal implements accord.api.Journal, RangeSearcher.Supplier
     public Command loadCommand(int commandStoreId, TxnId txnId, RedundantBefore redundantBefore, DurableBefore durableBefore)
     {
         Builder builder = load(commandStoreId, txnId);
-        builder.maybeCleanup(true, FULL, redundantBefore, durableBefore);
+        Cleanup cleanup = builder.maybeCleanup(true, FULL, redundantBefore, durableBefore);
+        if (cleanup == Cleanup.EXPUNGE)
+            return null;
+
         return builder.construct(redundantBefore);
     }
 
diff --git a/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java b/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java
index ffae6958ec..5b718aaa88 100644
--- a/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java
+++ b/src/java/org/apache/cassandra/service/accord/AccordJournalTable.java
@@ -67,6 +67,7 @@ import org.apache.cassandra.db.rows.UnfilteredRowIterators;
 import org.apache.cassandra.index.Index;
 import org.apache.cassandra.index.accord.OrderedRouteSerializer;
 import org.apache.cassandra.index.accord.RouteJournalIndex;
+import org.apache.cassandra.io.FSReadError;
 import org.apache.cassandra.io.sstable.ISSTableScanner;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.util.DataInputBuffer;
@@ -191,7 +192,7 @@ public class AccordJournalTable<K extends JournalKey, V> implements RangeSearche
         void read(DataInputPlus input, Version userVersion) throws IOException;
     }
 
-    private class RecordConsumerAdapter implements RecordConsumer<K>
+    private static class RecordConsumerAdapter<K> implements RecordConsumer<K>
     {
         protected final Reader reader;
 
@@ -200,18 +201,16 @@ public class AccordJournalTable<K extends JournalKey, V> implements RangeSearche
             this.reader = reader;
         }
 
-        private long prevSegment = -1;
-        private long prevPosition = -1;
+        private long prevSegment = Long.MAX_VALUE;
+        private long prevPosition = Long.MAX_VALUE;
 
         @Override
         public void accept(long segment, int position, K key, ByteBuffer buffer, int userVersion)
         {
-            Invariants.require(prevSegment == -1 || segment <= prevSegment,
-                               "Records should always be iterated over in a reverse order, but %s was seen after %s", segment, prevSegment);
-            if (prevSegment != segment)
-                prevPosition = -1;
-            Invariants.require(prevPosition == -1 || position < prevPosition,
-                               "Records should always be iterated over in a reverse order, but %s was seen after %s", position, prevPosition);
+            Invariants.require(segment <= prevSegment,
+                               "Records should always be iterated over in a reverse order, but segment %d was seen after %d while reading %s", segment, prevSegment, key);
+            Invariants.require(segment != prevSegment || position < prevPosition,
+                               "Records should always be iterated over in a reverse order, but position %d was seen after %d for segment %d while reading %s", position, prevPosition, segment, key);
             readBuffer(buffer, reader, Version.fromVersion(userVersion));
             prevSegment = segment;
             prevPosition = position;
@@ -410,18 +409,37 @@ public class AccordJournalTable<K extends JournalKey, V> implements RangeSearche
             if (view.sstables.isEmpty())
                 return;
 
-            List<UnfilteredRowIterator> iters = new ArrayList<>(view.sstables.size());
-            for (SSTableReader sstable : view.sstables)
-                if (sstable.mayContainAssumingKeyIsInRange(pk))
-                    iters.add(StorageHook.instance.makeRowIterator(cfs, sstable, pk, Slices.ALL, ColumnFilter.all(cfs.metadata()), false, NOOP_LISTENER));
+            List<UnfilteredRowIterator> iters = new ArrayList<>(Math.min(4, view.sstables.size()));
+            try
+            {
+                for (SSTableReader sstable : view.sstables)
+                {
+                    if (!sstable.mayContainAssumingKeyIsInRange(pk))
+                        continue;
+
+                    UnfilteredRowIterator iter = StorageHook.instance.makeRowIterator(cfs, sstable, pk, Slices.ALL, ColumnFilter.all(cfs.metadata()), false, NOOP_LISTENER);
+                    if (iter.getClass() != EmptyIterators.EmptyUnfilteredRowIterator.class)
+                        iters.add(iter);
+                }
 
-            if (!iters.isEmpty())
+                if (!iters.isEmpty())
+                {
+                    EntryHolder<K> into = new EntryHolder<>();
+                    try (UnfilteredRowIterator iter = UnfilteredRowIterators.merge(iters))
+                    {
+                        while (iter.hasNext()) readRow(key, iter.next(), into, onEntry);
+                    }
+                }
+            }
+            catch (Throwable t)
             {
-                EntryHolder<K> into = new EntryHolder<>();
-                try (UnfilteredRowIterator iter = UnfilteredRowIterators.merge(iters))
+                String message = "Failed to read from " + iters;
+                for (UnfilteredRowIterator iter : iters)
                 {
-                    while (iter.hasNext()) readRow(key, iter.next(), into, onEntry);
+                    try { iter.close(); }
+                    catch (Throwable t2) { t.addSuppressed(t2); }
                 }
+                throw new FSReadError(message, t);
             }
         }
     }
diff --git a/src/java/org/apache/cassandra/service/accord/serializers/TableMetadatas.java b/src/java/org/apache/cassandra/service/accord/serializers/TableMetadatas.java
index 6e24758961..cec50a0a10 100644
--- a/src/java/org/apache/cassandra/service/accord/serializers/TableMetadatas.java
+++ b/src/java/org/apache/cassandra/service/accord/serializers/TableMetadatas.java
@@ -329,6 +329,9 @@ public abstract class TableMetadatas extends AbstractList<TableId>
         @Override
         public void serialize(TableMetadata table, DataOutputPlus out) throws IOException
         {
+            if (ids.length == 1)
+                return;
+
             int i = indexOf(table);
             if (i < 0)
                 throw new IllegalStateException("TableMetadata for " + table + " not found in " + this);
@@ -346,6 +349,9 @@ public abstract class TableMetadatas extends AbstractList<TableId>
         @Override
         public TableMetadata deserialize(DataInputPlus in) throws IOException
         {
+            if (ids.length == 1)
+                return metadatas[0];
+
             int index = in.readUnsignedVInt32();
             TableMetadata metadata = metadatas[index];
             if (metadata == null)
@@ -356,6 +362,9 @@ public abstract class TableMetadatas extends AbstractList<TableId>
         @Override
         public long serializedSize(TableMetadata table)
         {
+            if (ids.length == 1)
+                return 0;
+
             int i = indexOf(table);
             if (i < 0)
                 throw new IllegalStateException("TableMetadata for " + table + " not found in " + this);
@@ -384,6 +393,7 @@ public abstract class TableMetadatas extends AbstractList<TableId>
         int count = in.readUnsignedVInt32();
         if (count == 0)
             return none();
+
         if (count == 1)
         {
             TableId id = TableId.deserializeCompactComparable(in);
@@ -392,6 +402,7 @@ public abstract class TableMetadatas extends AbstractList<TableId>
                 return new WithUnknown(new TableId[] { id}, new TableMetadata[] { null });
             return new One(metadata);
         }
+
         TableId[] ids = null;
         TableMetadata[] metadatas = new TableMetadata[count];
         int i;
diff --git a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordLoadTest.java b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordLoadTest.java
index 2a99a350b5..83bf2d295b 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/accord/AccordLoadTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/accord/AccordLoadTest.java
@@ -30,6 +30,7 @@ import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
+import java.util.concurrent.RejectedExecutionException;
 import java.util.concurrent.Semaphore;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -98,17 +99,14 @@ public class AccordLoadTest extends AccordTestBase
 
             ICoordinator coordinator = cluster.coordinator(1);
             final int repairInterval = Integer.MAX_VALUE;
-            //                 final int repairInterval = 3000;
-            final int compactionInterval = Integer.MAX_VALUE;
-//                     final int compactionInterval = 3000;
-            final int flushInterval = Integer.MAX_VALUE;
-//                     final int flushInterval = 1000;
+            final int compactionInterval = 20_000;
+            final int flushInterval = 50_000;
             final int compactionPeriodSeconds = 1;
-            final int restartInterval = 150_000_000;
+            final int restartInterval = 100_000;
             final int batchSizeLimit = 1000;
             final long batchTime = TimeUnit.SECONDS.toNanos(10);
             final int concurrency = 100;
-            final int ratePerSecond = 1000;
+            final int ratePerSecond = 2000;
             final int keyCount = 10_000;
             final float readChance = 0.33f;
             long nextRepairAt = repairInterval;
@@ -122,15 +120,12 @@ public class AccordLoadTest extends AccordTestBase
             cluster.forEach(i -> i.runOnInstance(() -> {
                 if (compactionPeriodSeconds > 0)
                     ((AccordService) AccordService.instance()).journal().compactor().updateCompactionPeriod(1, SECONDS);
-                //                     ((AccordSpec.JournalSpec)((AccordService) AccordService.instance()).journal().configuration()).segmentSize = 128 << 10;
+//                  ((AccordSpec.JournalSpec)((AccordService) AccordService.instance()).journal().configuration()).segmentSize = 128 << 10;
             }));
 
             Random random = new Random();
-            //                 CopyOnWriteArrayList<Throwable> exceptions = new CopyOnWriteArrayList<>();
             final Semaphore inFlight = new Semaphore(concurrency);
             final RateLimiter rateLimiter = RateLimiter.create(ratePerSecond);
-            //                 long testStart = System.nanoTime();
-            //                 while (NANOSECONDS.toMinutes(System.nanoTime() - testStart) < 10 && exceptions.size() < 10000)
             while (true)
             {
                 final EstimatedHistogram histogram = new EstimatedHistogram(200);
@@ -141,32 +136,40 @@ public class AccordLoadTest extends AccordTestBase
                 {
                     inFlight.acquire();
                     rateLimiter.acquire();
-                    long commandStart = System.nanoTime();
-                    int k = random.nextInt(keyCount);
-                    if (random.nextFloat() < readChance)
+                    try
                     {
-                        coordinator.executeWithResult((success, fail) -> {
-                            inFlight.release();
-                            if (fail == null) histogram.add(NANOSECONDS.toMicros(System.nanoTime() - commandStart));
-                            //                             else exceptions.add(fail);
-                        }, "SELECT * FROM " + qualifiedAccordTableName + " WHERE k = ?;", ConsistencyLevel.SERIAL, k);
-                    }
-                    else if (initialised.get(k))
-                    {
-                        coordinator.executeWithResult((success, fail) -> {
-                            inFlight.release();
-                            if (fail == null) histogram.add(NANOSECONDS.toMicros(System.nanoTime() - commandStart));
-                            //                             else exceptions.add(fail);
-                        }, "UPDATE " + qualifiedAccordTableName + " SET v += 1 WHERE k = ? IF EXISTS;", ConsistencyLevel.SERIAL, ConsistencyLevel.QUORUM, k);
+                        long commandStart = System.nanoTime();
+                        int k = random.nextInt(keyCount);
+                        if (random.nextFloat() < readChance)
+                        {
+                            coordinator.executeWithResult((success, fail) -> {
+                                inFlight.release();
+                                if (fail == null) histogram.add(NANOSECONDS.toMicros(System.nanoTime() - commandStart));
+                            }, "SELECT * FROM " + qualifiedAccordTableName + " WHERE k = ?;", ConsistencyLevel.SERIAL, k);
+                        }
+                        else if (initialised.get(k))
+                        {
+                            coordinator.executeWithResult((success, fail) -> {
+                                inFlight.release();
+                                if (fail == null) histogram.add(NANOSECONDS.toMicros(System.nanoTime() - commandStart));
+                            }, "UPDATE " + qualifiedAccordTableName + " SET v += 1 WHERE k = ? IF EXISTS;", ConsistencyLevel.SERIAL, ConsistencyLevel.QUORUM, k);
+                        }
+                        else
+                        {
+                            initialised.set(k);
+                            coordinator.executeWithResult((success, fail) -> {
+                                inFlight.release();
+                                if (fail == null) histogram.add(NANOSECONDS.toMicros(System.nanoTime() - commandStart));
+                                //                             else exceptions.add(fail);
+                            }, "UPDATE " + qualifiedAccordTableName + " SET v = 0 WHERE k = ? IF NOT EXISTS;", ConsistencyLevel.SERIAL, ConsistencyLevel.QUORUM, k);
+                        }
                     }
-                    else
+                    catch (RejectedExecutionException e)
                     {
-                        initialised.set(k);
-                        coordinator.executeWithResult((success, fail) -> {
-                            inFlight.release();
-                            if (fail == null) histogram.add(NANOSECONDS.toMicros(System.nanoTime() - commandStart));
-                            //                             else exceptions.add(fail);
-                        }, "UPDATE " + qualifiedAccordTableName + " SET v = 0 WHERE k = ? IF NOT EXISTS;", ConsistencyLevel.SERIAL, ConsistencyLevel.QUORUM, k);
+                        int index = 1 + random.nextInt(cluster.size());
+                        logger.info("Picking new coordinator ... {}", index);
+                        coordinator = cluster.coordinator(index);
+                        inFlight.release();
                     }
                     batchSize++;
                     if (System.nanoTime() >= batchEnd)
@@ -185,7 +188,8 @@ public class AccordLoadTest extends AccordTestBase
                     nextCompactionAt += compactionInterval;
                     System.out.println("compacting accord...");
                     cluster.forEach(i -> {
-                        i.nodetool("compact", "system_accord.journal");
+                        try { i.nodetool("compact", "system_accord.journal"); }
+                        catch (Throwable t) { logger.error("", t); }
                     });
                 }
 
@@ -193,16 +197,24 @@ public class AccordLoadTest extends AccordTestBase
                 {
                     nextFlushAt += flushInterval;
                     System.out.println("flushing journal...");
-                    cluster.forEach(i -> i.runOnInstance(() -> {
-                        ((AccordService) AccordService.instance()).journal().closeCurrentSegmentForTestingIfNonEmpty();
-                    }));
+                    cluster.forEach(i -> {
+                        try
+                        {
+                            i.runOnInstance(() -> {
+                                ((AccordService) AccordService.instance()).journal().closeCurrentSegmentForTestingIfNonEmpty();
+                            });
+                        }
+                        catch (Throwable t)
+                        {
+                            logger.error("", t);
+                        }
+                });
                 }
 
                 if ((nextRestartAt -= batchSize) <= 0)
                 {
                     nextRestartAt += restartInterval;
-                    int nodeIdx = random.nextInt(cluster.size());
-
+                    int nodeIdx = 1 + random.nextInt(cluster.size());
                     restartExecutor.submit(() -> {
                         System.out.printf("restarting node %d...\n", nodeIdx);
                         try
@@ -258,6 +270,7 @@ public class AccordLoadTest extends AccordTestBase
         catch (Throwable t)
         {
             t.printStackTrace();
+            System.exit(1);
         }
     }
 
