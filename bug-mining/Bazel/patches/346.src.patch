diff --git a/src/main/java/com/google/devtools/build/lib/buildtool/PostAnalysisQueryProcessor.java b/src/main/java/com/google/devtools/build/lib/buildtool/PostAnalysisQueryProcessor.java
index 75b0f1416f..a25b3c05a7 100644
--- a/src/main/java/com/google/devtools/build/lib/buildtool/PostAnalysisQueryProcessor.java
+++ b/src/main/java/com/google/devtools/build/lib/buildtool/PostAnalysisQueryProcessor.java
@@ -75,63 +75,71 @@ public abstract class PostAnalysisQueryProcessor<T> implements BuildTool.Analysi
       BlazeRuntime runtime,
       AnalysisResult analysisResult)
       throws InterruptedException, ViewCreationFailedException, ExitException {
-    // TODO: b/71905538 - this query will operate over the graph as constructed by analysis, but
-    // will also pick up any nodes that are in the graph from prior builds. This makes the results
-    // not reproducible at the level of a single command. Either tolerate, or wipe the analysis
-    // graph beforehand if this option is specified, or add another option to wipe if desired
-    // (SkyframeExecutor#handleAnalysisInvalidatingChange should be sufficient).
-    if (queryExpression != null) {
-      if (!env.getSkyframeExecutor().tracksStateForIncrementality()) {
-        throw new ExitException(
-            DetailedExitCode.of(
-                FailureDetail.newBuilder()
-                    .setMessage(
-                        "Queries based on analysis results are not allowed if incrementality state"
-                            + " is not being kept")
-                    .setQuery(Query.newBuilder().setCode(Query.Code.ANALYSIS_QUERY_PREREQ_UNMET))
-                    .build()));
-      }
+    if (queryExpression == null) {
+      return;
+    }
 
-      try (QueryRuntimeHelper queryRuntimeHelper =
-          env.getRuntime().getQueryRuntimeHelperFactory().create(env, getQueryOptions(env))) {
-        doPostAnalysisQuery(
-            request,
-            env,
-            runtime,
-            new TopLevelConfigurations(analysisResult.getTopLevelTargetsWithConfigs()),
-            analysisResult.getAspectsMap(),
-            env.getSkyframeExecutor().getTransitiveConfigurationKeys(),
-            queryRuntimeHelper,
-            queryExpression);
-      } catch (QueryException e) {
-        String errorMessage = "Error doing post analysis query";
-        if (!request.getKeepGoing()) {
-          throw new ViewCreationFailedException(errorMessage, e.getFailureDetail(), e);
-        }
-        env.getReporter().error(null, errorMessage + ": " + e.getFailureDetail().getMessage());
-      } catch (IOException e) {
-        String errorMessage = "I/O error doing post analysis query";
-        FailureDetail failureDetail =
-            FailureDetail.newBuilder()
-                .setMessage(errorMessage + ": " + e.getMessage())
-                .setQuery(Query.newBuilder().setCode(Query.Code.OUTPUT_FORMATTER_IO_EXCEPTION))
-                .build();
-        if (!request.getKeepGoing()) {
-          throw new ViewCreationFailedException(errorMessage, failureDetail, e);
-        }
-        env.getReporter().error(null, failureDetail.getMessage());
-      } catch (QueryRuntimeHelperException e) {
-        throw new ExitException(DetailedExitCode.of(e.getFailureDetail()));
-      } catch (OptionsParsingException e) {
-        throw new ExitException(
-            DetailedExitCode.of(
-                ExitCode.COMMAND_LINE_ERROR,
-                FailureDetail.newBuilder()
-                    .setMessage(e.getMessage())
-                    .setActionQuery(
-                        ActionQuery.newBuilder().setCode(ActionQuery.Code.INCORRECT_ARGUMENTS))
-                    .build()));
+    // This query will operate over the graph as constructed by analysis, but will also pick up
+    // any nodes that are in the graph from prior builds, including dirty nodes. While they can't be
+    // reached from the scope of the current build via deps, they can appear in rdeps, which results
+    // in the processor doing unnecessary work or even expecting stale keys to be present. Clean
+    // them up now, which requires ignoring the value of --version_window_for_dirty_node_gc.
+    // TODO: b/71905538 - Keeping state from previous builds around makes the results not
+    //  reproducible at the level of a single command. Either tolerate, or wipe the analysis graph
+    //  beforehand if this option is specified, or add another option to wipe if desired
+    //  (SkyframeExecutor#handleAnalysisInvalidatingChange should be sufficient).
+    env.getSkyframeExecutor().deleteOldNodes(/* versionWindowForDirtyGc= */ 0);
+    env.getSkyframeExecutor().applyInvalidation(env.getReporter());
+    if (!env.getSkyframeExecutor().tracksStateForIncrementality()) {
+      throw new ExitException(
+          DetailedExitCode.of(
+              FailureDetail.newBuilder()
+                  .setMessage(
+                      "Queries based on analysis results are not allowed if incrementality state"
+                          + " is not being kept")
+                  .setQuery(Query.newBuilder().setCode(Query.Code.ANALYSIS_QUERY_PREREQ_UNMET))
+                  .build()));
+    }
+
+    try (QueryRuntimeHelper queryRuntimeHelper =
+        env.getRuntime().getQueryRuntimeHelperFactory().create(env, getQueryOptions(env))) {
+      doPostAnalysisQuery(
+          request,
+          env,
+          runtime,
+          new TopLevelConfigurations(analysisResult.getTopLevelTargetsWithConfigs()),
+          analysisResult.getAspectsMap(),
+          env.getSkyframeExecutor().getTransitiveConfigurationKeys(),
+          queryRuntimeHelper,
+          queryExpression);
+    } catch (QueryException e) {
+      String errorMessage = "Error doing post analysis query";
+      if (!request.getKeepGoing()) {
+        throw new ViewCreationFailedException(errorMessage, e.getFailureDetail(), e);
+      }
+      env.getReporter().error(null, errorMessage + ": " + e.getFailureDetail().getMessage());
+    } catch (IOException e) {
+      String errorMessage = "I/O error doing post analysis query";
+      FailureDetail failureDetail =
+          FailureDetail.newBuilder()
+              .setMessage(errorMessage + ": " + e.getMessage())
+              .setQuery(Query.newBuilder().setCode(Query.Code.OUTPUT_FORMATTER_IO_EXCEPTION))
+              .build();
+      if (!request.getKeepGoing()) {
+        throw new ViewCreationFailedException(errorMessage, failureDetail, e);
       }
+      env.getReporter().error(null, failureDetail.getMessage());
+    } catch (QueryRuntimeHelperException e) {
+      throw new ExitException(DetailedExitCode.of(e.getFailureDetail()));
+    } catch (OptionsParsingException e) {
+      throw new ExitException(
+          DetailedExitCode.of(
+              ExitCode.COMMAND_LINE_ERROR,
+              FailureDetail.newBuilder()
+                  .setMessage(e.getMessage())
+                  .setActionQuery(
+                      ActionQuery.newBuilder().setCode(ActionQuery.Code.INCORRECT_ARGUMENTS))
+                  .build()));
     }
   }
 
diff --git a/src/main/java/com/google/devtools/build/lib/query2/PostAnalysisQueryEnvironment.java b/src/main/java/com/google/devtools/build/lib/query2/PostAnalysisQueryEnvironment.java
index 846713fca1..f6153299e3 100644
--- a/src/main/java/com/google/devtools/build/lib/query2/PostAnalysisQueryEnvironment.java
+++ b/src/main/java/com/google/devtools/build/lib/query2/PostAnalysisQueryEnvironment.java
@@ -564,9 +564,8 @@ public abstract class PostAnalysisQueryEnvironment<T> extends AbstractBlazeQuery
         Preconditions.checkState(
             dependency != null,
             "query-requested node '%s' was unavailable in the query environment graph. If you come"
-                + " across this error, please add to"
-                + " https://github.com/bazelbuild/bazel/issues/15079 or contact the bazel"
-                + " configurability team.",
+                + " across this error, please file an issue at https://github.com/bazelbuild/bazel"
+                + " or contact the bazel configurability team.",
             key);
 
         boolean implicitDep;
diff --git a/src/main/java/com/google/devtools/build/lib/skyframe/SkyframeExecutor.java b/src/main/java/com/google/devtools/build/lib/skyframe/SkyframeExecutor.java
index e58b672363..01b9d35438 100644
--- a/src/main/java/com/google/devtools/build/lib/skyframe/SkyframeExecutor.java
+++ b/src/main/java/com/google/devtools/build/lib/skyframe/SkyframeExecutor.java
@@ -3785,10 +3785,9 @@ public abstract class SkyframeExecutor implements WalkableGraphFactory {
       ExternalFilesHelper tmpExternalFilesHelper =
           externalFilesHelper.cloneWithFreshExternalFilesKnowledge();
 
-      try (SilentCloseable c =
-          Profiler.instance().profile("invalidateValuesMarkedForInvalidation")) {
-        invalidateValuesMarkedForInvalidation(eventHandler);
-      }
+      // Before running the {@link FilesystemValueChecker} ensure that all values marked for
+      // invalidation have actually been invalidated, because checking those is a waste of time.
+      applyInvalidation(eventHandler);
 
       FilesystemValueChecker fsvc =
           new FilesystemValueChecker(
@@ -3901,19 +3900,26 @@ public abstract class SkyframeExecutor implements WalkableGraphFactory {
   }
 
   /**
-   * Before running the {@link FilesystemValueChecker} ensure that all values marked for
-   * invalidation have actually been invalidated (recall that invalidation happens at the beginning
-   * of the next evaluate() call), because checking those is a waste of time.
+   * Actually invalidates values marked for invalidation.
+   *
+   * <p>Invalidation is delayed because:
+   *
+   * <ul>
+   *   <li>there may never be a next evaluation, so the work to clean up values may be wasted;
+   *   <li>invalidated values may be resurrected due to change pruning.
+   * </ul>
    */
-  protected final void invalidateValuesMarkedForInvalidation(ExtendedEventHandler eventHandler)
+  public final void applyInvalidation(ExtendedEventHandler eventHandler)
       throws InterruptedException {
-    EvaluationContext evaluationContext =
-        newEvaluationContextBuilder()
-            .setKeepGoing(false)
-            .setParallelism(DEFAULT_THREAD_COUNT)
-            .setEventHandler(eventHandler)
-            .build();
-    memoizingEvaluator.evaluate(ImmutableList.of(), evaluationContext);
+    try (SilentCloseable c = Profiler.instance().profile("applyInvalidation")) {
+      EvaluationContext evaluationContext =
+          newEvaluationContextBuilder()
+              .setKeepGoing(false)
+              .setParallelism(DEFAULT_THREAD_COUNT)
+              .setEventHandler(eventHandler)
+              .build();
+      memoizingEvaluator.evaluate(ImmutableList.of(), evaluationContext);
+    }
   }
 
   protected final Set<Root> getDiffPackageRootsUnderWhichToCheck(
diff --git a/src/test/shell/integration/configured_query_test.sh b/src/test/shell/integration/configured_query_test.sh
index 36393c68e8..fa06bee08f 100755
--- a/src/test/shell/integration/configured_query_test.sh
+++ b/src/test/shell/integration/configured_query_test.sh
@@ -1662,4 +1662,40 @@ EOF
   expect_log "//${pkg}:platform is not a valid select.. condition"
 }
 
+function test_stale_rdeps() {
+  local -r pkg=$FUNCNAME
+  mkdir -p $pkg
+  touch $pkg/dep.txt
+  touch $pkg/{1,2,3}.txt
+  cat > $pkg/BUILD <<'EOF'
+filegroup(
+    name = "dep",
+    srcs = ["dep.txt"],
+)
+
+[
+    filegroup(
+        name = "target_{}".format(txt),
+        srcs = [
+            txt,
+            ":dep",
+        ],
+    )
+    for txt in glob(["*.txt"])
+]
+EOF
+
+  bazel cquery "rdeps(//$pkg:all, //$pkg:dep)" > output 2>"$TEST_log" || fail "Unexpected failure"
+  expect_log "//$pkg:target_1.txt"
+  expect_log "//$pkg:target_2.txt"
+  expect_log "//$pkg:target_3.txt"
+
+  rm $pkg/2.txt
+  bazel cquery "rdeps(//$pkg:all, //$pkg:dep)" > output 2>"$TEST_log" || fail "Unexpected failure"
+
+  expect_log "//$pkg:target_1.txt"
+  expect_not_log "//$pkg:target_2.txt"
+  expect_log "//$pkg:target_3.txt"
+}
+
 run_suite "${PRODUCT_NAME} configured query tests"
