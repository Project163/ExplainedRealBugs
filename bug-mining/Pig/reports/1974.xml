<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 20:03:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[PIG-5318] Unit test failures on Pig on Spark with Spark 2.2</title>
                <link>https://issues.apache.org/jira/browse/PIG-5318</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;There are several failing cases when executing the unit tests with Spark 2.2:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 org.apache.pig.test.TestAssert#testNegativeWithoutFetch
 org.apache.pig.test.TestAssert#testNegative
 org.apache.pig.test.TestEvalPipeline2#testNonStandardDataWithoutFetch
 org.apache.pig.test.TestScalarAliases#testScalarErrMultipleRowsInInput
 org.apache.pig.test.TestStore#testCleanupOnFailureMultiStore
 org.apache.pig.test.TestStoreInstances#testBackendStoreCommunication
 org.apache.pig.test.TestStoreLocal#testCleanupOnFailureMultiStore
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of these are related to fixes/changes in Spark.&lt;/p&gt;

&lt;p&gt;TestAssert, TestScalarAliases and TestEvalPipeline2 failures could be fixed by asserting on the message of the exception&apos;s root cause, looks like on Spark 2.2 the exception is wrapped into an additional layer.&lt;br/&gt;
TestStore and TestStoreLocal failure are also a test related problems: looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7953&quot; title=&quot;Spark should cleanup output dir if job fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7953&quot;&gt;&lt;del&gt;SPARK-7953&lt;/del&gt;&lt;/a&gt; is fixed in Spark 2.2&lt;br/&gt;
The root cause of TestStoreInstances is yet to be found out.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13121331">PIG-5318</key>
            <summary>Unit test failures on Pig on Spark with Spark 2.2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nkollar">N&#225;ndor Koll&#225;r</assignee>
                                    <reporter username="nkollar">N&#225;ndor Koll&#225;r</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Nov 2017 14:42:40 +0000</created>
                <updated>Mon, 15 Sep 2025 11:29:02 +0000</updated>
                            <resolved>Wed, 13 Dec 2017 10:34:49 +0000</resolved>
                                                    <fixVersion>0.18.0</fixVersion>
                                    <component>spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16270990" author="nkollar" created="Wed, 29 Nov 2017 15:55:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szita&quot; class=&quot;user-hover&quot; rel=&quot;szita&quot;&gt;szita&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; could you please have review?&lt;/p&gt;</comment>
                            <comment id="16271252" author="rohini" created="Wed, 29 Nov 2017 18:05:00 +0000"  >&lt;p&gt;Few Comments:&lt;br/&gt;
  1) TestStoreBase &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Please add a isSpark2_x() method to Util.java after isHadoop1_x() and use that&lt;/li&gt;
	&lt;li&gt;mode.toString().startsWith(&quot;SPARK&quot;) -&amp;gt; Util.isSparkExecType(mode)&lt;br/&gt;
  2) Changing test case of TestStoreInstances beats the purpose of the test.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="16271998" author="kellyzly" created="Thu, 30 Nov 2017 01:45:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;:&lt;br/&gt;
thanks for working on it.&lt;br/&gt;
thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt; &apos;s comments.&lt;br/&gt;
 just quick scan. several questions&lt;br/&gt;
1. the modification for &lt;tt&gt;TestAssert&lt;/tt&gt;,&lt;tt&gt;TestEvalPipeline&lt;/tt&gt;,&lt;tt&gt;TestScalarAliases&lt;/tt&gt; suit for Pig on MR or Pig on Tez? I guess it will not hurt other engine, just want to confirm with it.&lt;br/&gt;
2. not very understand  the purpose about the modification of TestStoreInstances, are there some problems with previous code?&lt;br/&gt;
 before&lt;/p&gt;
 &lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; ArrayList&amp;lt;Tuple&amp;gt; outRows;
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; After&lt;/p&gt;
 &lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; Map&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, ArrayList&amp;lt;Tuple&amp;gt;&amp;gt; outRows = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashMap&amp;lt;&amp;gt;();
 &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; location;
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16272501" author="nkollar" created="Thu, 30 Nov 2017 10:38:38 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; for your review!&lt;br/&gt;
Hm, I think I understood the point of TestStoreInstances, and indeed, my change on that test looks pointless. I&apos;m afraid this might be a bug and not a test issue. I&apos;ll continue the investigation why it is failing, and what how to fix it, so far it looks like commitTask is not called on the correct OutputCommitterTestInstances instance, the array is empty.&lt;/p&gt;</comment>
                            <comment id="16274385" author="nkollar" created="Fri, 1 Dec 2017 13:24:17 +0000"  >&lt;p&gt;Attached &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5318&quot; title=&quot;Unit test failures on Pig on Spark with Spark 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5318&quot;&gt;&lt;del&gt;PIG-5318&lt;/del&gt;&lt;/a&gt;_2.patch, I addressed Rohini&apos;s comments there.&lt;/p&gt;

&lt;p&gt;As of &lt;tt&gt;TestStoreInstances&lt;/tt&gt; failure, it looks like Spark (unlike Tez and MapReduce) creates multiple instances from &lt;tt&gt;PigOutputFormat&lt;/tt&gt; while setting up the output committers: &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala#L74&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;setupCommitter&lt;/a&gt; is called from both &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala#L138&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;setupJob&lt;/a&gt; and from &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala#L165&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;setupTask&lt;/a&gt;, and &lt;tt&gt;setupCommitter&lt;/tt&gt; creates a new &lt;tt&gt;PigOutputFormat&lt;/tt&gt; each time, saving in a private variable. In addition, when Spark writes to files, a new &lt;tt&gt;PigOutputFormat&lt;/tt&gt; is &lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.2/core/src/main/scala/org/apache/spark/internal/io/SparkHadoopMapReduceWriter.scala#L75&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;getting created&lt;/a&gt; too, and since POStores are saved and deserialized in configuration, but StoreFuncInterface inside stores are &lt;a href=&quot;https://github.com/apache/pig/blob/trunk/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java#L53&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;transient&lt;/a&gt;, a new instance of &lt;tt&gt;STFuncCheckInstances&lt;/tt&gt; is getting created, each time, thus &lt;tt&gt;putNext&lt;/tt&gt; and &lt;tt&gt;commitTask&lt;/tt&gt; will use different array instances. Not sure if it is a bug in Pig, or in Spark, should Spark consistently use the same OutputFormat instance in this case?&lt;/p&gt;

&lt;p&gt;Making &lt;tt&gt;reduceStores&lt;/tt&gt;, &lt;tt&gt;mapStores&lt;/tt&gt;, &lt;tt&gt;currentConf&lt;/tt&gt; static inside &lt;tt&gt;TestStoreInstances&lt;/tt&gt; would solve the problem, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; what do you think about this solution?&lt;/p&gt;</comment>
                            <comment id="16274766" author="rohini" created="Fri, 1 Dec 2017 18:49:38 +0000"  >&lt;p&gt;You should just do isSpark2_x (sparkVersion.startsWith(&quot;2.&quot;)) instead of isSpark2_2_x . If Spark 2.3 gets released, then code will have to change. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Not sure if it is a bug in Pig, or in Spark, should Spark consistently use the same OutputFormat instance in this case?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  Spark should consistently use the same OutputFormat instance in this case. We should not be modifying the test case. There will be users who will be using local variables in StoreFunc for some computation at least.&lt;/p&gt;</comment>
                            <comment id="16276557" author="nkollar" created="Mon, 4 Dec 2017 09:58:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;You should just do isSpark2_x (sparkVersion.startsWith(&quot;2.&quot;)) instead of isSpark2_2_x . If Spark 2.3 gets released, then code will have to change.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You&apos;re right, but matching for 2.x is not good enough. On Spark 2.1, abortTask and abortJob is not called (see &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7953&quot; title=&quot;Spark should cleanup output dir if job fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7953&quot;&gt;&lt;del&gt;SPARK-7953&lt;/del&gt;&lt;/a&gt;), but looks like in Spark 2.2 this is fixed (at least it looks like it is fixed). I&apos;ll update the patch soon, we should match Spark 2.2+.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Spark should consistently use the same OutputFormat instance in this case&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok, so I guess this should be a new Jira for Spark, however Spark 2.2 is already released, and creates more OutputFormat instances like said before. Indeed, we shouldn&apos;t modify the test case, but how about modifying PigOutputformat, like I did in the patch (making the relevant variables static)?&lt;/p&gt;</comment>
                            <comment id="16276747" author="nkollar" created="Mon, 4 Dec 2017 13:07:19 +0000"  >&lt;p&gt;Attached &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5318&quot; title=&quot;Unit test failures on Pig on Spark with Spark 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5318&quot;&gt;&lt;del&gt;PIG-5318&lt;/del&gt;&lt;/a&gt;_4.patch, it looks like the way I wanted to tell Spark version doesn&apos;t work on Spark 1.x, using SparkContext#version instead.&lt;/p&gt;</comment>
                            <comment id="16277120" author="rohini" created="Mon, 4 Dec 2017 17:25:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;but how about modifying PigOutputformat, like I did in the patch (making the relevant variables static)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt; This cannot be done. It is hacky and will break Pig local mode and Tez. In local mode, save jvm is used to execute the whole script which can have parallel STORE statements. Tez also allows storing to multiple outputs from same vertex in a DAG - i.e multiple PigOutputFormat in the save jvm.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;isSpark2_1_minus&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  Can you make it  isSpark2_2_plus which is slightly more intuitive than 2_1_minus. Also instantiating SparkContext just to get version seems overkill. Prefer the previous logic you had. Is there any reason that could not be used?&lt;/p&gt;</comment>
                            <comment id="16277122" author="rohini" created="Mon, 4 Dec 2017 17:26:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;it looks like the way I wanted to tell Spark version doesn&apos;t work on Spark 1.x&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  Missed this earlier. If the spark-version-info.properties file is not there, you could just return false for isSpark2_2_plus which will be easier.&lt;/p&gt;</comment>
                            <comment id="16280419" author="nkollar" created="Wed, 6 Dec 2017 16:26:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt; I agree, this looks like a hacky solution, but I couldn&apos;t think of a better one, I&apos;ll try to figure out something better.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;It is hacky and will break Pig local mode and Tez.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Are you saying, that if I add a test case which stores in two different stores, similar to the existing one in TestStoreInstances but with two STORE statements, then that should pass too? I tried this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    @Test
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testBackendMultiStoreCommunication() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
        ExecType[] execTypes = { Util.getLocalTestMode() };
        PigServer pig = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;(ExecType execType : execTypes){
            Util.resetStateForExecModeSwitch();
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Starting test mode &quot;&lt;/span&gt; + execType);
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (execType == cluster.getExecType()) {
                pig = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PigServer(cluster.getExecType(),
                        cluster.getProperties());
            } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
                pig = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PigServer(execType);
            }
            &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; outFile = &lt;span class=&quot;code-quote&quot;&gt;&quot;TestStoreInst1&quot;&lt;/span&gt;;
            &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; outFile2 = &lt;span class=&quot;code-quote&quot;&gt;&quot;TestStoreInst2&quot;&lt;/span&gt;;
            Util.deleteFile(pig.getPigContext(), outFile);
            Util.deleteFile(pig.getPigContext(), outFile2);
            pig.setBatchOn();
            &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; query =
                    &lt;span class=&quot;code-quote&quot;&gt;&quot;  l1 = load &lt;span class=&quot;code-quote&quot;&gt;&apos;&quot;&lt;/span&gt; + INP_FILE_2NUMS + &lt;span class=&quot;code-quote&quot;&gt;&quot;&apos;&lt;/span&gt; as (i : &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, j : &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;);&quot;&lt;/span&gt; +
                            &lt;span class=&quot;code-quote&quot;&gt;&quot; store l1 into &lt;span class=&quot;code-quote&quot;&gt;&apos;&quot;&lt;/span&gt; + outFile + &lt;span class=&quot;code-quote&quot;&gt;&quot;&apos;&lt;/span&gt; using &quot;&lt;/span&gt; + CHECK_INSTANCE_STORE_FUNC +
                            &lt;span class=&quot;code-quote&quot;&gt;&quot;;&quot;&lt;/span&gt; +
                            &lt;span class=&quot;code-quote&quot;&gt;&quot; store l1 into &lt;span class=&quot;code-quote&quot;&gt;&apos;&quot;&lt;/span&gt; + outFile2 + &lt;span class=&quot;code-quote&quot;&gt;&quot;&apos;&lt;/span&gt; using &quot;&lt;/span&gt; + CHECK_INSTANCE_STORE_FUNC +
                            &lt;span class=&quot;code-quote&quot;&gt;&quot;;&quot;&lt;/span&gt;;
            Util.registerMultiLineQuery(pig, query);
            List&amp;lt;ExecJob&amp;gt; execJobs = pig.executeBatch();
            assertEquals(&lt;span class=&quot;code-quote&quot;&gt;&quot;num jobs&quot;&lt;/span&gt;, 2, execJobs.size());
            assertEquals(&lt;span class=&quot;code-quote&quot;&gt;&quot;status &quot;&lt;/span&gt;, JOB_STATUS.COMPLETED, execJobs.get(0).getStatus());
        }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But it failed in local mode.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can you make it isSpark2_2_plus which is slightly more intuitive than 2_1_minus. Also instantiating SparkContext just to get version seems overkill.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ok, I&apos;ll revert to the original option, and not instantiate SparkContext (agree, it is an overkill, that&apos;s why I tried an other solution first), though I think that&apos;s the most reliable way to tell the Spark version, leaving the details for Spark code. Checking for &lt;tt&gt;spark-version-info.properties&lt;/tt&gt; looks very version dependent solution.&lt;/p&gt;

&lt;p&gt;Should we open a separate Jira for fixing TestStoreInstances in spark mode? It seems that the other items are straightforward, and more test related issues, but this one seems to be something to fix in code instead of in test.&lt;/p&gt;</comment>
                            <comment id="16280635" author="rohini" created="Wed, 6 Dec 2017 18:36:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;Should we open a separate Jira for fixing TestStoreInstances in spark mode?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt; Sure. It will require more time for you to come up with a solution. We can get the other ones fixed in this jira.&lt;/p&gt;</comment>
                            <comment id="16281694" author="nkollar" created="Thu, 7 Dec 2017 11:01:18 +0000"  >&lt;p&gt;Created &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5319&quot; title=&quot;Investigate why TestStoreInstances fails with Spark 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5319&quot;&gt;PIG-5319&lt;/a&gt; to address TestStoreInstances failure. &lt;/p&gt;</comment>
                            <comment id="16281815" author="nkollar" created="Thu, 7 Dec 2017 13:04:52 +0000"  >&lt;p&gt;Attached &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5318&quot; title=&quot;Unit test failures on Pig on Spark with Spark 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5318&quot;&gt;&lt;del&gt;PIG-5318&lt;/del&gt;&lt;/a&gt;_5.patch which includes fix for TestAssert, TestScalarAliases, TestEvalPipeline2, TestStore and TestStoreLocal test cases, but doesn&apos;t fix TestStoreInstances failure. The Spark version is determined like Rohini suggested. I also noticed, that testKeepGoigFailed (fixed the typo in method name, now testKeepGoingFailed) was excluded from spark exec type, I enabled this test case, since it passed in my environment with 1.6, 2.1 and 2.2 Spark versions. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; do you remember why this was excluded? Looks like the Jira it is referring to is not yet fixed, despite this the test passes with 1.6.x Spark.&lt;/p&gt;</comment>
                            <comment id="16283023" author="kellyzly" created="Fri, 8 Dec 2017 03:56:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;:  testKeepGoingFailed is excluded because of &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7953&quot; title=&quot;Spark should cleanup output dir if job fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7953&quot;&gt;&lt;del&gt;SPARK-7953&lt;/del&gt;&lt;/a&gt;. At that time we used spark 1.3.  And after upgrading to 1.6, not enable this test again.&lt;/p&gt;</comment>
                            <comment id="16283255" author="nkollar" created="Fri, 8 Dec 2017 09:27:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; thanks for the explanation, in this case I think enabling this test is fine, and there&apos;s no need to check for Spark version, we don&apos;t support older Spark versions.&lt;/p&gt;</comment>
                            <comment id="16283321" author="nkollar" created="Fri, 8 Dec 2017 10:33:48 +0000"  >&lt;p&gt;Attached &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5318&quot; title=&quot;Unit test failures on Pig on Spark with Spark 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5318&quot;&gt;&lt;del&gt;PIG-5318&lt;/del&gt;&lt;/a&gt;_6.patch, found an universal way to tell the current Spark version, that works with both Spark 1.6.x and Spark 2.x too, and there&apos;s no need to start SparkContext. (thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gezapeti&quot; class=&quot;user-hover&quot; rel=&quot;gezapeti&quot;&gt;gezapeti&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/p&gt;</comment>
                            <comment id="16284463" author="rohini" created="Sat, 9 Dec 2017 00:26:02 +0000"  >&lt;p&gt;+1 on the patch from my side.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;found an universal way to tell the current Spark version&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;   Did not suggest that as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gezapeti&quot; class=&quot;user-hover&quot; rel=&quot;gezapeti&quot;&gt;gezapeti&lt;/a&gt; has mentioned earlier that it is internal to Spark - &lt;a href=&quot;https://issues.apache.org/jira/browse/OOZIE-2606?focusedCommentId=15528793&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15528793&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/OOZIE-2606?focusedCommentId=15528793&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15528793&lt;/a&gt;. It is ok here though as it is only for tests.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;testKeepGoingFailed is excluded because of &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7953&quot; title=&quot;Spark should cleanup output dir if job fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7953&quot;&gt;&lt;del&gt;SPARK-7953&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7953&quot; title=&quot;Spark should cleanup output dir if job fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7953&quot;&gt;&lt;del&gt;SPARK-7953&lt;/del&gt;&lt;/a&gt; still does not seem to be fixed as you mentioned. Can you try to find which jira actually fixed it and probably close &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7953&quot; title=&quot;Spark should cleanup output dir if job fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7953&quot;&gt;&lt;del&gt;SPARK-7953&lt;/del&gt;&lt;/a&gt; if it is not required anymore. Identifying what behavior change caused this might also help find other places in Pig on Spark that have to be fixed or changed for the new behavior.&lt;/p&gt;
</comment>
                            <comment id="16285663" author="nkollar" created="Mon, 11 Dec 2017 09:00:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt; indeed, it is internal, but I think checking for existence of &lt;tt&gt;spark-version-info.properties&lt;/tt&gt; and the property value inside it is also Spark&apos;s internal. The public API is &lt;tt&gt;SparkContext#version()&lt;/tt&gt;, but that means we should create a SparkContext just for telling the version, and we agreed that it is overkill.&lt;/p&gt;

&lt;p&gt;As for &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7953&quot; title=&quot;Spark should cleanup output dir if job fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7953&quot;&gt;&lt;del&gt;SPARK-7953&lt;/del&gt;&lt;/a&gt;, I think &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-18219&quot; title=&quot;Move commit protocol API from sql to core module&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-18219&quot;&gt;&lt;del&gt;SPARK-18219&lt;/del&gt;&lt;/a&gt; fixed this problem too. It looks like in Spark 2.2 they completely refactored the task and job commit protocol: they &lt;a href=&quot;https://github.com/apache/spark/commit/937af592e65f4dd878aafcabf8fe2cfe7fa3d9b3#diff-d97cfb5711116287a7655f32cd5675cb&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;moved&lt;/a&gt; the Spark SQL implementation to the Spark code module. I asked on the mentioned Jira if it is still an outstanding problem or not (maybe I missed some detail), I&apos;d like to give some time for answers before I close it.&lt;/p&gt;</comment>
                            <comment id="16289058" author="szita" created="Wed, 13 Dec 2017 10:33:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;, +1 for &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12901229/12901229_PIG-5318_6.patch&quot; title=&quot;PIG-5318_6.patch attached to PIG-5318&quot;&gt;PIG-5318_6.patch&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;, committed to trunk.&lt;br/&gt;
I think we should also upgrade the spark 2 minor version in Pig On Spark to 2.2. We don&apos;t want to maintain a 1.6.1, 2.1.1, and 2.2.0 support at the same time, rather have one minor per major.&lt;br/&gt;
Created &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5321&quot; title=&quot;Upgrade Spark 2 version to 2.2.0 for Pig on Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5321&quot;&gt;&lt;del&gt;PIG-5321&lt;/del&gt;&lt;/a&gt; to track the upgrade.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12899839" name="PIG-5318_1.patch" size="11572" author="nkollar" created="Wed, 29 Nov 2017 15:51:22 +0000"/>
                            <attachment id="12900212" name="PIG-5318_2.patch" size="12589" author="nkollar" created="Fri, 1 Dec 2017 12:38:14 +0000"/>
                            <attachment id="12900467" name="PIG-5318_3.patch" size="12642" author="nkollar" created="Mon, 4 Dec 2017 10:55:20 +0000"/>
                            <attachment id="12900486" name="PIG-5318_4.patch" size="12662" author="nkollar" created="Mon, 4 Dec 2017 13:05:45 +0000"/>
                            <attachment id="12901062" name="PIG-5318_5.patch" size="12750" author="nkollar" created="Thu, 7 Dec 2017 12:52:42 +0000"/>
                            <attachment id="12901229" name="PIG-5318_6.patch" size="12108" author="nkollar" created="Fri, 8 Dec 2017 10:30:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 49 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3nad3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>