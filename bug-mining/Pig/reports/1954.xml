<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 20:03:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[PIG-5246] Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2</title>
                <link>https://issues.apache.org/jira/browse/PIG-5246</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;in bin/pig.&lt;br/&gt;
we copy assembly jar to pig&apos;s classpath in spark1.6.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;# For spark mode:
# Please specify SPARK_HOME first so that we can locate $SPARK_HOME/lib/spark-assembly*.jar,
# we will add spark-assembly*.jar to the classpath.
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ &lt;span class=&quot;code-quote&quot;&gt;&quot;$isSparkMode&quot;&lt;/span&gt;  == &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt; ]; then
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ -z &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_HOME&quot;&lt;/span&gt; ]; then
       echo &lt;span class=&quot;code-quote&quot;&gt;&quot;Error: SPARK_HOME is not set!&quot;&lt;/span&gt;
       exit 1
    fi

    # Please specify SPARK_JAR which is the hdfs path of spark-assembly*.jar to allow YARN to cache spark-assembly*.jar on nodes so that it doesn&apos;t need to be distributed each time an application runs.
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ -z &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_JAR&quot;&lt;/span&gt; ]; then
       echo &lt;span class=&quot;code-quote&quot;&gt;&quot;Error: SPARK_JAR is not set, SPARK_JAR stands &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the hdfs location of spark-assembly*.jar. This allows YARN to cache spark-assembly*.jar on nodes so that it doesn&apos;t need to be distributed each time an application runs.&quot;&lt;/span&gt;
       exit 1
    fi

    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ -n &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_HOME&quot;&lt;/span&gt; ]; then
        echo &lt;span class=&quot;code-quote&quot;&gt;&quot;Using Spark Home: &quot;&lt;/span&gt; ${SPARK_HOME}
        SPARK_ASSEMBLY_JAR=`ls ${SPARK_HOME}/lib/spark-assembly*`
        CLASSPATH=${CLASSPATH}:$SPARK_ASSEMBLY_JAR
    fi
fi

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;after upgrade to spark2.0, we may modify it&lt;/p&gt;</description>
                <environment></environment>
        <key id="13076127">PIG-5246</key>
            <summary>Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kellyzly">liyunzhang</assignee>
                                    <reporter username="kellyzly">liyunzhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 31 May 2017 08:25:12 +0000</created>
                <updated>Tue, 25 Jul 2017 01:55:47 +0000</updated>
                            <resolved>Tue, 25 Jul 2017 01:55:47 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16032524" author="kellyzly" created="Thu, 1 Jun 2017 06:19:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szita&quot; class=&quot;user-hover&quot; rel=&quot;szita&quot;&gt;szita&lt;/a&gt;: help review &lt;br/&gt;
in spark2, spark-assembly*.jar does not exist, so we need append all jars under $SPARK_HOME/jars/ to the pig classpath.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ &lt;span class=&quot;code-quote&quot;&gt;&quot;$sparkversion&quot;&lt;/span&gt; == &lt;span class=&quot;code-quote&quot;&gt;&quot;21&quot;&lt;/span&gt; ]; then
+          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ -n &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_HOME&quot;&lt;/span&gt; ]; then
+             echo &lt;span class=&quot;code-quote&quot;&gt;&quot;Using Spark Home: &quot;&lt;/span&gt; ${SPARK_HOME}
+              &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; f in $SPARK_HOME/jars/*.jar; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt;
+                   CLASSPATH=${CLASSPATH}:$f
+              done
+          fi
+     fi
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;the way to use &lt;/p&gt;

&lt;p&gt;1. build pig with spark21&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;   ant clean -v  -Dsparkversion=21   -Dhadoopversion=2 jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;2. run pig with spark21&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  /pig -x $mode -sparkversion 21 -log4jconf $PIG_HOME/conf/log4j.properties -logfile $PIG_HOME/logs/pig.log  $PIG_HOME/bin/testJoin.pig
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="16032586" author="nkollar" created="Thu, 1 Jun 2017 07:41:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; one comment: Rohini suggested that instead of &lt;tt&gt;sparkversion=21&lt;/tt&gt; and &lt;tt&gt;sparkversion=16&lt;/tt&gt; we should use &lt;tt&gt;sparkversion=2&lt;/tt&gt; and &lt;tt&gt;sparkversion=1&lt;/tt&gt;. On &lt;a href=&quot;https://reviews.apache.org/r/59530/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;RB&lt;/a&gt; you can see that the latest patch is modified accordingly.&lt;/p&gt;</comment>
                            <comment id="16032609" author="kellyzly" created="Thu, 1 Jun 2017 07:56:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;: in &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;.1.patch, modify &lt;tt&gt;sparkversion=16&lt;/tt&gt; to &lt;tt&gt;sparkversion=1&lt;/tt&gt; and &lt;tt&gt;sparkversion=21&lt;/tt&gt; to &lt;tt&gt;sparkversion=2&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="16034284" author="kellyzly" created="Fri, 2 Jun 2017 07:37:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szita&quot; class=&quot;user-hover&quot; rel=&quot;szita&quot;&gt;szita&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffzhang&quot; class=&quot;user-hover&quot; rel=&quot;jeffzhang&quot;&gt;jeffzhang&lt;/a&gt;:&lt;br/&gt;
It is not very convenient to let users to type &lt;tt&gt;-sparkversion 2&lt;/tt&gt; when they use pig like( the default sparkversion is 1, need not type)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;./pig -x $mode -sparkversion 2 -log4jconf $PIG_HOME/conf/log4j.properties -logfile $PIG_HOME/logs/pig.log  $PIG_HOME/bin/testJoin.pig
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 
&lt;p&gt;some options to improve this&lt;br/&gt;
1. save &lt;tt&gt;sparkversion&lt;/tt&gt; in file and parse &lt;tt&gt;sparkversion&lt;/tt&gt; from the file in bin/pig&lt;br/&gt;
2. judge the spark version from spark-assembly*jar. in spark1, there is spark-assembly*jar in $SPARK_HOME/lib while in spark2, there is no  $SPARK_HOME/lib/spark-assembly*jar&lt;/p&gt;

&lt;p&gt;Please give me your opinion or you think it is acceptable to let users to specified $&lt;tt&gt;sparkversion&lt;/tt&gt; in command.&lt;/p&gt;</comment>
                            <comment id="16035045" author="rohini" created="Fri, 2 Jun 2017 17:00:53 +0000"  >&lt;p&gt;Users should not have to specify -sparkversion 1 or 2 to determine which version. You should detect that in the script. For Hadoop 1.x and 2.x it was done by checking for hadoop-core.jar. You can do same thing here. Currently we still have problem of having to compile the shims classes against different versions.&lt;/p&gt;

&lt;p&gt;There is a hack I did internally for hbase 0.94 to hbase 0.98 migration for HBaseStorage to support both HBase 0.94 and 0.98 with same pig jar during the migration. Have attached the patch for it. It is more code and slightly convoluted as each class now redirects to the shims class based on version detection. For eg: In Spark JobMetricsListener will redirect to JobMetricsListenerSpark1 or JobMetricsListenerSpark2. But for users it makes it very simple as they can use same pig installation to run against any version. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;, do you want to try this approach as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5157&quot; title=&quot;Upgrade to Spark 2.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5157&quot;&gt;&lt;del&gt;PIG-5157&lt;/del&gt;&lt;/a&gt; (Spark 2 support) and &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5191&quot; title=&quot;Pig HBase 2.0.0 support&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5191&quot;&gt;&lt;del&gt;PIG-5191&lt;/del&gt;&lt;/a&gt; (HBase 2 support) ?&lt;/p&gt;

&lt;p&gt; Similarly we can add a target to compile against all versions of both spark and hbase (and hadoop 3.0 in future if required) and create a pig.jar which will run with anything. &lt;/p&gt;
</comment>
                            <comment id="16035779" author="zjffdu" created="Sat, 3 Jun 2017 03:03:30 +0000"  >&lt;p&gt;Agree with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt;, we should not ask user to specify spark version, it should be transparent to users. &lt;br/&gt;
Actually SPARK_ASSEMBLY_JAR is not a must-have thing for spark. It is just for performance optimization. IMO, pig don&apos;t need to specify that, it is supposed to be set in spark-defaults.conf which would apply to all spark apps.&lt;/p&gt;


</comment>
                            <comment id="16036459" author="kellyzly" created="Mon, 5 Jun 2017 01:55:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt;: thanks for suggestion, for spark1 and spark2, it will be done by checking for spark-assembly.jar or other things in the script and user need not specify the version of spark.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;For eg: In Spark JobMetricsListener will redirect to JobMetricsListenerSpark1 or JobMetricsListenerSpark2. But for users it makes it very simple as they can use same pig installation to run against any version.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It will be convenient for users in that way but not sure whether there is conflicts if both jars of spark1 and spark2 in the pig classpath.&lt;br/&gt;
 &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjffdu&quot; class=&quot;user-hover&quot; rel=&quot;zjffdu&quot;&gt;zjffdu&lt;/a&gt;:  &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Actually SPARK_ASSEMBLY_JAR is not a must-have thing for spark. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  If SPARK_ASSEMBLY_JAR is not a must-have thing for spark1, how to judge spark1 or spark2?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;IMO, pig don&apos;t need to specify that, it is supposed to be set in spark-defaults.conf which would apply to all spark apps.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  Pig on Spark use spark installation and will copy $SPARK_HOME/lib/spark-assembly*jar(spark1) and $SPARK_HOME/jars/*jar to the classpath of pig. But we don&apos;t read spark-defaults.conf.  We parse pig.properties and save the configuration about spark to &lt;a href=&quot;https://github.com/apache/pig/blob/trunk/src/org/apache/pig/backend/hadoop/executionengine/spark/SparkLauncher.java#L584&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;SparkContext&lt;/a&gt;.&lt;/p&gt;

</comment>
                            <comment id="16036460" author="zjffdu" created="Mon, 5 Jun 2017 02:04:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;If SPARK_ASSEMBLY_JAR is not a must-have thing for spark1, how to judge spark1 or spark2?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There&apos;s lot of ways to judge spark1 and spark2. e.g. we can run command &apos;spark-submit --version&apos; under SPARK_HOME/bin to get the version number. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Pig on Spark use spark installation and will copy $SPARK_HOME/lib/spark-assembly*jar(spark1) and $SPARK_HOME/jars/*jar to the classpath of pig. But we don&apos;t read spark-defaults.conf. We parse pig.properties and save the configuration about spark to SparkContext.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why copying the assembly jar instead of including it in the classpath of pig ? And it is also weird to me not loading spark-defaults.conf as this would cause extra administration overhead. If I am a cluster administrator, I only want to maintenance one copy of spark configuration in spark-defaults.conf, rather than copying the same configuration from spark-defaults.conf to pig.properties.&lt;/p&gt;
</comment>
                            <comment id="16036470" author="kellyzly" created="Mon, 5 Jun 2017 02:21:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffzhang&quot; class=&quot;user-hover&quot; rel=&quot;jeffzhang&quot;&gt;jeffzhang&lt;/a&gt;: thanks for suggestion&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Why copying the assembly jar instead of including it in the classpath of pig ?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;sorry for mistake in my last comment. We just include the spark-assembly*.jar in the &lt;a href=&quot;https://github.com/apache/pig/blob/trunk/bin/pig#L415&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;classpath of pig&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;And it is also weird to me not loading spark-defaults.conf as this would cause extra administration overhead. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, i agree this can be improved by directly parsing $SPARK_HOME/spark-defaults.conf. see &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5252&quot; title=&quot;Get properties from $SPARK_HOME/conf/spark-defaults.conf not from pig.properties&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5252&quot;&gt;PIG-5252&lt;/a&gt;&lt;/p&gt;


</comment>
                            <comment id="16039087" author="nkollar" created="Tue, 6 Jun 2017 15:31:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt; sure, I can try the approach you did for HBase.&lt;/p&gt;</comment>
                            <comment id="16047604" author="kellyzly" created="Tue, 13 Jun 2017 08:56:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjffdu&quot; class=&quot;user-hover&quot; rel=&quot;zjffdu&quot;&gt;zjffdu&lt;/a&gt;:&lt;br/&gt;
in &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;_2.patch&lt;br/&gt;
use following way to judge spark version&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+    $SPARK_HOME/bin/spark-submit --version &amp;gt;/tmp/spark.version 2&amp;gt;&amp;amp;1
+    isSpark1=`grep &lt;span class=&quot;code-quote&quot;&gt;&quot;version 1&quot;&lt;/span&gt; /tmp/spark.version|wc -l`
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ &lt;span class=&quot;code-quote&quot;&gt;&quot;$isSpark1&quot;&lt;/span&gt; -eq 0 ];then 
+          sparkversion=&lt;span class=&quot;code-quote&quot;&gt;&quot;2&quot;&lt;/span&gt;
     fi
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;redirect the output of &quot;spark-submit --version&quot; to /tmp/spark.version(later will remove this file), Is there any better way to judge the version? &lt;/p&gt;</comment>
                            <comment id="16050164" author="kellyzly" created="Thu, 15 Jun 2017 08:39:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;: can you help review &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;_2.patch?&lt;/p&gt;

&lt;p&gt;in &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;_2.patch&lt;br/&gt;
use following way to judge spark version&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+    $SPARK_HOME/bin/spark-submit --version &amp;gt;/tmp/spark.version 2&amp;gt;&amp;amp;1
+    isSpark1=`grep &lt;span class=&quot;code-quote&quot;&gt;&quot;version 1&quot;&lt;/span&gt; /tmp/spark.version|wc -l`
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; [ &lt;span class=&quot;code-quote&quot;&gt;&quot;$isSpark1&quot;&lt;/span&gt; -eq 0 ];then 
+          sparkversion=&lt;span class=&quot;code-quote&quot;&gt;&quot;2&quot;&lt;/span&gt;
     fi
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;redirect the output of &quot;spark-submit --version&quot; to /tmp/spark.version(later will remove this file), Is there any better way to judge the version?&lt;/p&gt;</comment>
                            <comment id="16050250" author="nkollar" created="Thu, 15 Jun 2017 09:53:55 +0000"  >&lt;p&gt;I&apos;ve two comments:&lt;/p&gt;

&lt;p&gt;For Spark 2.x do we have to add all jar under $SPARK_HOME/jars?&lt;/p&gt;

&lt;p&gt;Could we avoid creating temp files? Instead of creating spark.version, would something like this work?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;isSpark1=`$SPARK_HOME/bin/spark-submit --version 2&amp;gt;&amp;amp;1 | grep &lt;span class=&quot;code-quote&quot;&gt;&quot;version 1&quot;&lt;/span&gt; | wc -l`
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16051474" author="kellyzly" created="Fri, 16 Jun 2017 06:48:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;For Spark 2.x do we have to add all jar under $SPARK_HOME/jars?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;some guy suggested to to add all jar under $SPARK_HOME/jars in Hive on Spark(&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-15302&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;HIVE-15302&lt;/a&gt;), It seems this is not accepted by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt;. But in &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Hive wiki&lt;/a&gt;, it is said that we need not append all jars under $SPARK_HOME/jars.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Configuring Hive
To add the Spark dependency to Hive:
Prior to Hive 2.2.0, link the spark-assembly jar to HIVE_HOME/lib.
Since Hive 2.2.0, Hive on Spark runs with Spark 2.0.0 and above, which doesn&apos;t have an assembly jar.
To run with YARN mode (either yarn-client or yarn-cluster), link the following jars to HIVE_HOME/lib.
scala-library
spark-core
spark-network-common
To run with LOCAL mode (for debugging only), link the following jars in addition to those above to HIVE_HOME/lib.
chill-java  chill  jackson-module-paranamer  jackson-module-scala  jersey-container-servlet-core
jersey-server  json4s-ast  kryo-shaded  minlog  scala-xml  spark-launcher
spark-network-shuffle  spark-unsafe  xbean-asm5-shaded
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; I don&apos;t know whether there is performance influence if we append all jar under $SPARK_HOME/jars to the pig classpath.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Could we avoid creating temp files? Instead of creating spark.version, would something like this work?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, this works, thanks for suggestion.&lt;/p&gt;</comment>
                            <comment id="16052434" author="rohini" created="Fri, 16 Jun 2017 22:01:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;$SPARK_HOME/bin/spark-submit --version &amp;gt;/tmp/spark.version 2&amp;gt;&amp;amp;1&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  This is a bad idea as it will launch a jvm which is costly. I would suggest checking for presence of spark-tags*.jar which is only present in Spark 2. If it is not present, then assume spark 1.&lt;/p&gt;

&lt;p&gt;Also instead of doing&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; SPARK_ASSEMBLY_JAR=`ls ${SPARK_HOME}/lib/spark-assembly*`
 CLASSPATH=${CLASSPATH}:$SPARK_ASSEMBLY_JAR
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;you should be able to just refer directly with wildcard&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; CLASSPATH=${CLASSPATH}:${SPARK_HOME}/lib/spark-assembly*
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16052616" author="zjffdu" created="Sat, 17 Jun 2017 01:13:55 +0000"  >&lt;p&gt;Pig don&apos;t need to load all the jars under SPARK_HOME/jars. These jars are only needed when spark-submit script is launched, not necessary to be included in pig&apos;s classpath. Pig has already specify spark dependencies in ivy.&lt;/p&gt;
</comment>
                            <comment id="16053472" author="kellyzly" created="Mon, 19 Jun 2017 04:50:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I would suggest checking for presence of spark-tags*.jar which is only present in Spark 2. If it is not present, then assume spark 1.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;thanks for suggestion.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffzhang&quot; class=&quot;user-hover&quot; rel=&quot;jeffzhang&quot;&gt;jeffzhang&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Pig don&apos;t need to load all the jars under SPARK_HOME/jars. Pig has already specify spark dependencies in ivy.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;yes, the spark dependencies in ivy is for compile, i can select jars which pig on spark really needs from $SPARK_HOME/jars. But If users use a different spark which is different from compile. Will the dependencies be different?&lt;br/&gt;
My question is: is there big performance influence if we append all jar under $SPARK_HOME/jars to the pig classpath?&lt;/p&gt;</comment>
                            <comment id="16053862" author="zjffdu" created="Mon, 19 Jun 2017 11:48:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;My question is: is there big performance influence if we append all jar under $SPARK_HOME/jars to the pig classpath?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am a little confused. My concern is why pig would need $SPARK_HOME/jars to the pig classpath. It doesn&apos;t bring any benefit including performance. &lt;/p&gt;</comment>
                            <comment id="16055961" author="rohini" created="Tue, 20 Jun 2017 15:36:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;My concern is why pig would need $SPARK_HOME/jars to the pig classpath&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;  You need to have spark jars in classpath to run pig. This is similar to picking hadoop jars from HADOOP_HOME during runtime. We do not use the bundled hadoop/spark or tez jars to run and always use the user provided installation which may be Spark 1.x or 2.x. The dependencies specified in ivy.xml are only used during compile time as Liyun mentioned. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It doesn&apos;t bring any benefit including performance.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You can cherry pick jars to include in the classpath, but it is not going to make much difference. If a new jar is added in a new version, then it will actually be a problem and pig will have to be updated to include that jar.&lt;/p&gt;</comment>
                            <comment id="16056789" author="kellyzly" created="Wed, 21 Jun 2017 01:31:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;You can cherry pick jars to include in the classpath, but it is not going to make much difference. If a new jar is added in a new version, then it will actually be a problem and pig will have to be updated to include that jar.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;thanks for explanation, that&apos;s the reason why I mentioned in previous comment &quot;But If users use a different spark which is different from compile. Will the dependencies be different?&quot;&lt;/p&gt;</comment>
                            <comment id="16057163" author="kellyzly" created="Wed, 21 Jun 2017 08:18:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=szita&quot; class=&quot;user-hover&quot; rel=&quot;szita&quot;&gt;szita&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt;,&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffzhang&quot; class=&quot;user-hover&quot; rel=&quot;jeffzhang&quot;&gt;jeffzhang&lt;/a&gt;: update &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;.3.patch&lt;br/&gt;
changes&lt;br/&gt;
1. use spark-tags*.jar to verify whether current spark is spark1 or spark2&lt;br/&gt;
2. small fix like&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SPARK_ASSEMBLY_JAR=`ls ${SPARK_HOME}/lib/spark-assembly*`
 CLASSPATH=${CLASSPATH}:$SPARK_ASSEMBLY_JAR

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;to&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;CLASSPATH=${CLASSPATH}:${SPARK_HOME}/lib/spark-assembly*
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16060829" author="zjffdu" created="Fri, 23 Jun 2017 12:43:05 +0000"  >&lt;p&gt;hmm, I just found that pig launch spark internally rather than using spark-submit script. This might cause some issues, Because spark-submit script will do some enviroment setup. e.g. I suspect pig on spark could not work in secured cluster. User can not specify keytab and principal. One approach to solve the issue is to launch pig grunt via spark-submit. In this way, pig don&apos;t need to specify any spark jars, spark-submit will pick up the jar automatically.  &lt;/p&gt;
</comment>
                            <comment id="16062773" author="kellyzly" created="Mon, 26 Jun 2017 08:35:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffzhang&quot; class=&quot;user-hover&quot; rel=&quot;jeffzhang&quot;&gt;jeffzhang&lt;/a&gt;: I don&apos;t know  pig on spark does not support secured cluster or not. But if the keytab and  principal is only transferred by the parameter of command spark-submit not by sparkContext, i guess it does not suport.&lt;/p&gt;</comment>
                            <comment id="16087057" author="kellyzly" created="Fri, 14 Jul 2017 09:00:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;:&lt;br/&gt;
changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;_4.patch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;CLASSPATH=${CLASSPATH}:${SPARK_HOME}/lib/spark-assembly*
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;       SPARK_ASSEMBLY_JAR=`ls ${SPARK_HOME}/lib/spark-assembly*`
       CLASSPATH=${CLASSPATH}:$SPARK_ASSEMBLY_JAR

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;can not use wildcard to locate the spark_assembly_jar.&lt;br/&gt;
After all unit tests pass on my local jenkins.  will close &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5157&quot; title=&quot;Upgrade to Spark 2.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5157&quot;&gt;&lt;del&gt;PIG-5157&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16087189" author="nkollar" created="Fri, 14 Jul 2017 11:12:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; does this mean, that the problem you mentioned in &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5157&quot; title=&quot;Upgrade to Spark 2.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5157&quot;&gt;&lt;del&gt;PIG-5157&lt;/del&gt;&lt;/a&gt; with the basic script skew join is now fixed?&lt;/p&gt;</comment>
                            <comment id="16089217" author="kellyzly" created="Mon, 17 Jul 2017 01:46:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;: the problem about basic script passed on yarn-client mode. now running all unit tests in local mode. &lt;/p&gt;</comment>
                            <comment id="16094066" author="kellyzly" created="Thu, 20 Jul 2017 01:37:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;: as &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5157&quot; title=&quot;Upgrade to Spark 2.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5157&quot;&gt;&lt;del&gt;PIG-5157&lt;/del&gt;&lt;/a&gt; is resolved, please help review &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;_3.patch to let users use pig on spark in spark 2. thanks!&lt;/p&gt;</comment>
                            <comment id="16098155" author="nkollar" created="Mon, 24 Jul 2017 09:44:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kellyzly&quot; class=&quot;user-hover&quot; rel=&quot;kellyzly&quot;&gt;kellyzly&lt;/a&gt; sorry for the delay in the review. I tested the &lt;a href=&quot;https://issues.apache.org/jira/browse/PIG-5246&quot; title=&quot;Modify bin/pig about SPARK_HOME, SPARK_ASSEMBLY_JAR after upgrading spark to 2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PIG-5246&quot;&gt;&lt;del&gt;PIG-5246&lt;/del&gt;&lt;/a&gt;_4.patch on my cluster both in Spark 1.x and Spark 2.x mode. Both worked fine, looks good to me!&lt;/p&gt;</comment>
                            <comment id="16099380" author="kellyzly" created="Tue, 25 Jul 2017 01:55:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;: commit to trunk, thanks for &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nkollar&quot; class=&quot;user-hover&quot; rel=&quot;nkollar&quot;&gt;nkollar&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rohini&quot; class=&quot;user-hover&quot; rel=&quot;rohini&quot;&gt;rohini&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffzhang&quot; class=&quot;user-hover&quot; rel=&quot;jeffzhang&quot;&gt;jeffzhang&lt;/a&gt; reviewing.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12871010" name="HBase9498.patch" size="184141" author="rohini" created="Fri, 2 Jun 2017 17:01:45 +0000"/>
                            <attachment id="12870752" name="PIG-5246.1.patch" size="3443" author="kellyzly" created="Thu, 1 Jun 2017 07:56:17 +0000"/>
                            <attachment id="12873829" name="PIG-5246.3.patch" size="2545" author="kellyzly" created="Wed, 21 Jun 2017 08:14:47 +0000"/>
                            <attachment id="12870746" name="PIG-5246.patch" size="3545" author="kellyzly" created="Thu, 1 Jun 2017 06:19:32 +0000"/>
                            <attachment id="12872822" name="PIG-5246_2.patch" size="2749" author="kellyzly" created="Tue, 13 Jun 2017 08:54:46 +0000"/>
                            <attachment id="12877259" name="PIG-5246_4.patch" size="2597" author="kellyzly" created="Fri, 14 Jul 2017 08:54:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 17 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3fonz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>