<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 19:49:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[PIG-545] PERFORMANCE: Sampler for order bys does not produce a good distribution</title>
                <link>https://issues.apache.org/jira/browse/PIG-545</link>
                <project id="12310730" key="PIG">Pig</project>
                    <description>&lt;p&gt;In running tests on actual data, I&apos;ve noticed that the final reduce of an order by has skewed partitions.  Some reduces finish in a few seconds while some run for 20 minutes.  Getting a better distribution should lead to much better performance for order by.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12409232">PIG-545</key>
            <summary>PERFORMANCE: Sampler for order bys does not produce a good distribution</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pkamath">Pradeep Kamath</assignee>
                                    <reporter username="gates">Alan Gates</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2008 00:52:42 +0000</created>
                <updated>Wed, 24 Mar 2010 22:04:14 +0000</updated>
                            <resolved>Wed, 18 Feb 2009 19:22:44 +0000</resolved>
                                    <version>0.2.0</version>
                                    <fixVersion>0.2.0</fixVersion>
                                    <component>impl</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                                                                <comments>
                            <comment id="12650824" author="sms" created="Wed, 26 Nov 2008 01:11:11 +0000"  >&lt;p&gt;The current sampler uses random sampling, assuming uniform distribution of sort keys. Using Poisson distribution will enable the sampler to figure out the expected value of the distribution without knowing the actual distribution. This will ensure (more) even distribution of data for the reducers.&lt;/p&gt;</comment>
                            <comment id="12665650" author="alangates" created="Wed, 21 Jan 2009 00:34:00 +0000"  >&lt;p&gt;I ran the pigmix queries L9 (order by a single column) and L10 (order by multiple columns) and found some interesting results.&lt;/p&gt;

&lt;p&gt;For L9, the total ordering job (job 3), took 587 seconds.  Min and max times for individual reducers were 92 and 589 seconds (I&apos;m not sure how 1 reducer ran 2 sec longer than total job time, but all these numbers come from the hadoop web ui).  Seven of the 40 reducers (including the 92 second one) received no records to sort.  The long running 589 second job received one key, which had 2M values.&lt;/p&gt;

&lt;p&gt;For L10, the total ordering job took 238 seconds.  Min and max times for individual reducers were 99 seconds (3 keys, 32K records) and 232 seconds (413K keys, 496K records).&lt;/p&gt;

&lt;p&gt;From this I draw a couple of conclusions:  &lt;/p&gt;

&lt;p&gt;One, our order by partitioner could be better built.  There is no reason a reducer should ever receive 0 records.  And in a job with 3 uncorrelated keys we still see a &amp;gt; 10x disparity in data distribution.  The partitioner needs to do a better job of producing even distributions of the keys to reducers.&lt;/p&gt;

&lt;p&gt;Two, just getting better sampling won&apos;t resolve the issue for order by queries that have one or a few keys with a very high number of values, such as in a zipf distribution.  Unfortunately for us, zipf is a very common data distribution.  In this case our partitioner may need to be able to detect and split large keys by round robining them to a group of reducers.&lt;/p&gt;</comment>
                            <comment id="12666234" author="sms" created="Thu, 22 Jan 2009 18:15:57 +0000"  >&lt;p&gt;&amp;lt;quote&amp;gt;&lt;br/&gt;
Two, just getting better sampling won&apos;t resolve the issue for order by queries that have one or a few keys with a very high number of values, such as in a zipf distribution. Unfortunately for us, zipf is a very common data distribution. In this case our partitioner may need to be able to detect and split large keys by round robining them to a group of reducers.&lt;br/&gt;
&amp;lt;/quote&amp;gt;&lt;/p&gt;

&lt;p&gt;Better sampling will not resolve the issue for order by. It will help in having more evenly sized partitions for the reducers. Since its sampling and not brute force approach of checking out the cardinality of each key, there will always be a non-zero probability of one reducer getting more data than the other reducers. The better sampling approach will minimize such occurrences.&lt;/p&gt;

&lt;p&gt;Secondly, post sampling, we can ensure that reducers get the right partitions by using Hadoop&apos;s ability to pick reducers based on partition functions. I am not quite sure how Pig can propose a generic partition function to achieve this.&lt;/p&gt;</comment>
                            <comment id="12670734" author="shravanmn" created="Thu, 5 Feb 2009 12:35:56 +0000"  >&lt;p&gt;This patch implements the Weighted Range Partitioner as detailed in the Dewitt et. al. paper on Practical Skew Handling in Parallel Joins. The JobControlCompiler has been modified to use the new partitioner for order by. So the old unit tests should be valid.&lt;/p&gt;

&lt;p&gt;One caveat is that we need to mention the number of reducers via the parallel keyword when doing order by. Currently, if you don&apos;t specify it by default there will just be one partition and it messes up the distribution. We need to do something about this. Another thing is when the Partitioner gets configured it reads the entire sample file from HDFS but it currently doesn&apos;t do any reporting as I could not think of a way to do it right now&lt;/p&gt;</comment>
                            <comment id="12670938" author="alangates" created="Thu, 5 Feb 2009 23:02:43 +0000"  >&lt;p&gt;I ran the pigmix L9 (order by of single field) and L10 (order by of multiple fields).  L9 went from 14 minutes to 8, so this patch holds huge promise.  But L10 went from 8 minutes to 11, so it doesn&apos;t seem to be working well in the multiple field case.  (It could also be related to the fact that L10 uses descending on one of the columns, I don&apos;t know if the new partitioner can handle that or not.)  I also ran our end to end order by tests on it, and all passed, except bigdata_1, which fails with an IndexOutOfBounds exception in the new WeightedRangePartitioner class.  &lt;/p&gt;

&lt;p&gt;As for the caveat that it needs to know the number of reducers up front, I believe in cases where the user doesn&apos;t say parallel, that we can determine the parallelism of the reduces using JobClient.getDefaultReduces().  We need to double check that this will give us the right information in both the hod and non-hod cases.&lt;/p&gt;</comment>
                            <comment id="12671177" author="shravanmn" created="Fri, 6 Feb 2009 16:05:22 +0000"  >&lt;p&gt;Thanks for running the patch Alan. I figured out the IndexOutOfBounds exception &amp;amp; fixed it. That should not happen.&lt;/p&gt;

&lt;p&gt;I was also working on the L10 issue. I tried it outside of Pig by sending it tuples(int,string) with ordering required as (desc,asc). It works fine. So I don&apos;t think there is any problem with the partitioner there. Most of the things like asc, desc &amp;amp; user comparator should be handled as I use the comparator passed to me through the jobConf.  So I checked the samples file that was generated. Its not sorted at all. The main assumption is invalid and the partitioner will definitely get messed up.&lt;/p&gt;

&lt;p&gt;I finally figured that the way we are doing the compilation of order by in MRCompiler is wrong. When we do the nested sort using the input POSort, we are converting it into &quot;order by *&quot; instead it should be &quot;order by $0, $1, $2 ...&quot;&lt;/p&gt;

&lt;p&gt;I have started L10 with the changes. WIll update with the results.&lt;/p&gt;</comment>
                            <comment id="12671222" author="shravanmn" created="Fri, 6 Feb 2009 18:00:45 +0000"  >&lt;p&gt;It worked with the changes to sort. It produced an even distribution and took about 3 mins lesser. There is still a slight tuning to be done as the first partition is not getting enough data. I will try to tweak it a bit and check if its better than the current one.&lt;/p&gt;</comment>
                            <comment id="12671828" author="shravanmn" created="Mon, 9 Feb 2009 12:34:23 +0000"  >&lt;p&gt;Ran some tests and this quantiles scheme seems to have the least deviation from perfect distribution. Also, the time took for L10 has reduced. It took 8 mins vs 7 mins for the old code. But it produces a good distribution as shown below: The patch also modifies MRCompiler to fix sort on multiple fields with different order for each column.&lt;br/&gt;
New algorithm:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;/part-00000&amp;lt;r 3&amp;gt;	396866140
/part-00001&amp;lt;r 3&amp;gt;	388565356
/part-00002&amp;lt;r 3&amp;gt;	412419093
/part-00003&amp;lt;r 3&amp;gt;	404673062
/part-00004&amp;lt;r 3&amp;gt;	407805613
/part-00005&amp;lt;r 3&amp;gt;	399685590
/part-00006&amp;lt;r 3&amp;gt;	374470156
/part-00007&amp;lt;r 3&amp;gt;	407210410
/part-00008&amp;lt;r 3&amp;gt;	392022575
/part-00009&amp;lt;r 3&amp;gt;	403592598
/part-00010&amp;lt;r 3&amp;gt;	407005509
/part-00011&amp;lt;r 3&amp;gt;	392739807
/part-00012&amp;lt;r 3&amp;gt;	407132246
/part-00013&amp;lt;r 3&amp;gt;	393974442
/part-00014&amp;lt;r 3&amp;gt;	394310422
/part-00015&amp;lt;r 3&amp;gt;	397676923
/part-00016&amp;lt;r 3&amp;gt;	408960794
/part-00017&amp;lt;r 3&amp;gt;	407120924
/part-00018&amp;lt;r 3&amp;gt;	398555578
/part-00019&amp;lt;r 3&amp;gt;	398831802
/part-00020&amp;lt;r 3&amp;gt;	381319493
/part-00021&amp;lt;r 3&amp;gt;	397961816
/part-00022&amp;lt;r 3&amp;gt;	408716378
/part-00023&amp;lt;r 3&amp;gt;	401850651
/part-00024&amp;lt;r 3&amp;gt;	394624621
/part-00025&amp;lt;r 3&amp;gt;	411533286
/part-00026&amp;lt;r 3&amp;gt;	397598333
/part-00027&amp;lt;r 3&amp;gt;	402013011
/part-00028&amp;lt;r 3&amp;gt;	412664722
/part-00029&amp;lt;r 3&amp;gt;	390615865
/part-00030&amp;lt;r 3&amp;gt;	402257701
/part-00031&amp;lt;r 3&amp;gt;	404278892
/part-00032&amp;lt;r 3&amp;gt;	408376085
/part-00033&amp;lt;r 3&amp;gt;	403230193
/part-00034&amp;lt;r 3&amp;gt;	396062725
/part-00035&amp;lt;r 3&amp;gt;	403166437
/part-00036&amp;lt;r 3&amp;gt;	396123295
/part-00037&amp;lt;r 3&amp;gt;	400208557
/part-00038&amp;lt;r 3&amp;gt;	396028297
/part-00039&amp;lt;r 3&amp;gt;	428541846
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Old Algorithm:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;/part-00000&amp;lt;r 3&amp;gt;	39703
/part-00001&amp;lt;r 3&amp;gt;	396917259
/part-00002&amp;lt;r 3&amp;gt;	388958263
/part-00003&amp;lt;r 3&amp;gt;	412109839
/part-00004&amp;lt;r 3&amp;gt;	405626251
/part-00005&amp;lt;r 3&amp;gt;	411808194
/part-00006&amp;lt;r 3&amp;gt;	385084639
/part-00007&amp;lt;r 3&amp;gt;	618796205
/part-00008&amp;lt;r 3&amp;gt;	59754649
/part-00009&amp;lt;r 3&amp;gt;	506719655
/part-00010&amp;lt;r 3&amp;gt;	403039137
/part-00011&amp;lt;r 3&amp;gt;	406540458
/part-00012&amp;lt;r 3&amp;gt;	395629722
/part-00013&amp;lt;r 3&amp;gt;	404795418
/part-00014&amp;lt;r 3&amp;gt;	394881722
/part-00015&amp;lt;r 3&amp;gt;	393959841
/part-00016&amp;lt;r 3&amp;gt;	398194260
/part-00017&amp;lt;r 3&amp;gt;	408370148
/part-00018&amp;lt;r 3&amp;gt;	334248039
/part-00019&amp;lt;r 3&amp;gt;	260118680
/part-00020&amp;lt;r 3&amp;gt;	642453106
/part-00021&amp;lt;r 3&amp;gt;	383168594
/part-00022&amp;lt;r 3&amp;gt;	364791108
/part-00023&amp;lt;r 3&amp;gt;	408601454
/part-00024&amp;lt;r 3&amp;gt;	404588449
/part-00025&amp;lt;r 3&amp;gt;	392940424
/part-00026&amp;lt;r 3&amp;gt;	413354408
/part-00027&amp;lt;r 3&amp;gt;	412538285
/part-00028&amp;lt;r 3&amp;gt;	385894942
/part-00029&amp;lt;r 3&amp;gt;	412674723
/part-00030&amp;lt;r 3&amp;gt;	392572446
/part-00031&amp;lt;r 3&amp;gt;	403012671
/part-00032&amp;lt;r 3&amp;gt;	398679596
/part-00033&amp;lt;r 3&amp;gt;	410864380
/part-00034&amp;lt;r 3&amp;gt;	405389743
/part-00035&amp;lt;r 3&amp;gt;	397248129
/part-00036&amp;lt;r 3&amp;gt;	401438264
/part-00037&amp;lt;r 3&amp;gt;	396456821
/part-00038&amp;lt;r 3&amp;gt;	402122621
/part-00039&amp;lt;r 3&amp;gt;	816408998
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12673457" author="pkamath" created="Sat, 14 Feb 2009 02:11:49 +0000"  >&lt;p&gt;Attached a revised version of the last patch with the following changes:&lt;br/&gt;
1) When parallel is not specified the code now consults jobClient to get defaultReduces() and uses 0.9 times the value as the number of reducers (and hence the number of quantiles)&lt;br/&gt;
2) There was a bug in the way order by * was handled in MRCompiler  which is now fixed&lt;br/&gt;
3) In WeightedRangePartitioner the basic idea is to first set up the quantiles array as the last element of a quantile (partition). Then the code iterates over all the sample items and if it finds an item which equals the quantile element for the partition, then there is a good chance this item may repeat in the next quantile. The occurences of such sample items in each partition are recorded to use when deciding which partition such an item in the real data should go to. The occurences in each partition over the total occurences of such an element gives the probability that such an element should go to the given partition. In the earlier version of the patch, to set this up, the code was comparing a sample item with the quantile element of the next partition instead of the quantile element of the partition in which the sample element falls (since the quantile element is the last element of the partition, it should be used in the comparison to decide if this element is likely to crossover to the next partition). This has been fixed.&lt;br/&gt;
4) The earlier patch was not handling the case where number of samples &amp;lt; quantiles - this is handled now.&lt;/p&gt;</comment>
                            <comment id="12674393" author="olgan" created="Tue, 17 Feb 2009 23:30:54 +0000"  >&lt;p&gt;The patch looks good. A couple of comments/questions:&lt;/p&gt;

&lt;p&gt;(1) One comment that I have is that MalFormedProbVecException does not follow new error handling practices. It is not derived from PigException and it does not have a way to pass error code to it.&lt;/p&gt;

&lt;p&gt;(2) My understanding is that weighted partitioner would actually add overhead to well randomly distributed data. I am fine saying that this case is not very common or that the overhead is not great enough to worry about but I wanted to check what other committers think.&lt;/p&gt;

&lt;p&gt;(3) WeightedRangePartitioner.java throws RuntimeException - this is not consistent with our new error handling.&lt;/p&gt;</comment>
                            <comment id="12674410" author="pkamath" created="Wed, 18 Feb 2009 00:19:10 +0000"  >&lt;p&gt;Attached patch which addresses observation (1) in the previous comment.&lt;/p&gt;

&lt;p&gt;Regarding (2), the differences from the current SortPartitioner are:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In the configure of the WeightedRangePartitioner the entire sample file is loaded and a hash is built for those sample elements which repeat across partition boundaries - this is more expensive than previously but one time set up&lt;/li&gt;
	&lt;li&gt;IN the getPartition() call, if the input element is present in the hash, then probabilistically a partition is assigned based on the information in the hash else (as previously), a binary search of the quantiles array is done to figure out the partition - overall this should be nearly the same as previously performance wise.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Regarding (3), getPartition() is a hadoop interface method and hence we cannot throw any other exception besides RuntimeException&lt;/p&gt;</comment>
                            <comment id="12674752" author="pkamath" created="Wed, 18 Feb 2009 19:22:44 +0000"  >&lt;p&gt;Patch committed.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12400222" name="PIG-545-v3.patch" size="61012" author="pkamath" created="Sat, 14 Feb 2009 02:11:49 +0000"/>
                            <attachment id="12400366" name="PIG-545-v4.patch" size="61478" author="pkamath" created="Wed, 18 Feb 2009 00:19:10 +0000"/>
                            <attachment id="12399562" name="WRP.patch" size="34086" author="shravanmn" created="Thu, 5 Feb 2009 12:35:55 +0000"/>
                            <attachment id="12399813" name="WRP1.patch" size="34463" author="shravanmn" created="Mon, 9 Feb 2009 12:34:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>164143</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            16 years, 41 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0glj3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>94918</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>