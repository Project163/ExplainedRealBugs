diff --git a/CHANGES.txt b/CHANGES.txt
index 0850f87e4..a88656851 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -281,6 +281,8 @@ OPTIMIZATIONS
 
 BUG FIXES
 
+PIG-2791: Pig does not work with ViewFileSystem (rohini via daijy)
+
 PIG-2833: org.apache.pig.pigunit.pig.PigServer does not initialize set default log level of pigContext (cheolsoo via jcoveney)
 
 PIG-2744: Handle Pig command line with XML special characters (lulynn_2008 via daijy)
diff --git a/build.xml b/build.xml
index c00c188c5..d194c44f9 100644
--- a/build.xml
+++ b/build.xml
@@ -486,7 +486,11 @@
     	
     	<copy file="${basedir}/test/hbase-site.xml" tofile="${test.build.classes}/hbase-site.xml"/>
    
-        <ivy:cachepath pathid="mr-apps-test.classpath" conf="test" />
+        <ivy:cachepath pathid="mr-apps-test-ivy.classpath" conf="test" />
+        <path id="mr-apps-test.classpath">
+            <pathelement path="${clover.jar}"/>
+            <path refid="mr-apps-test-ivy.classpath"/>
+        </path>
         <property name="mr-apps-classpath" refid="mr-apps-test.classpath" />
         <echo file="${test.build.classes}/mrapp-generated-classpath" message="${mr-apps-classpath}" />
     </target>
diff --git a/ivy.xml b/ivy.xml
index 323f8322e..cf8dd2fc5 100644
--- a/ivy.xml
+++ b/ivy.xml
@@ -69,6 +69,8 @@
       conf="hadoop23->master"/>
     <dependency org="commons-el" name="commons-el" rev="${commons-el.version}"
       conf="compile->master"/>
+    <dependency org="commons-io" name="commons-io" rev="${commons-io.version}"
+      conf="compile->master"/>
     <dependency org="org.apache.httpcomponents" name="httpclient" rev="${httpcomponents.version}"
       conf="compile->master"/>
     <dependency org="org.apache.httpcomponents" name="httpcore" rev="${httpcomponents.version}"
@@ -87,6 +89,12 @@
       conf="hadoop23->master"/>
     <dependency org="org.mortbay.jetty" name="jetty-util" rev="${jetty-util.version}"
       conf="hadoop23->master"/>
+    <dependency org="javax.inject" name="javax.inject" rev="${javax-inject.version}"
+      conf="hadoop23->master"/>
+    <dependency org="javax.xml.bind" name="jaxb-api" rev="${jaxb-api.version}"
+      conf="hadoop23->master"/>
+    <dependency org="com.sun.xml.bind" name="jaxb-impl" rev="${jaxb-impl.version}"
+      conf="hadoop23->master"/> 
     <dependency org="com.google.inject" name="guice" rev="${guice.version}"
       conf="hadoop23->master"/>
     <dependency org="com.google.inject.extensions" name="guice-servlet" rev="${guice-servlet.version}"
diff --git a/ivy/libraries.properties b/ivy/libraries.properties
index 9a3b074d6..55da6c6cc 100644
--- a/ivy/libraries.properties
+++ b/ivy/libraries.properties
@@ -20,6 +20,7 @@ avro.version=1.5.3
 commons-beanutils.version=1.7.0
 commons-cli.version=1.0
 commons-codec.version=1.4
+commons-io.version=2.3
 commons-el.version=1.0
 commons-logging.version=1.1.1
 commons-lang.version=2.4
@@ -36,15 +37,18 @@ guava.version=11.0
 jersey-core.version=1.8
 hadoop-core.version=1.0.0
 hadoop-test.version=1.0.0
-hadoop-common.version=0.23.1
-hadoop-hdfs.version=0.23.1
-hadoop-mapreduce.version=0.23.1
+hadoop-common.version=2.0.0-alpha
+hadoop-hdfs.version=2.0.0-alpha
+hadoop-mapreduce.version=2.0.0-alpha
 hbase.version=0.90.0
 hsqldb.version=1.8.0.10
 hive.version=0.8.0
 httpcomponents.version=4.1
-jackson.version=1.7.3
+jackson.version=1.8.8
 javacc.version=4.2
+javax-inject.version=1
+jaxb-api.version=2.2.2
+jaxb-impl.version=2.2.3-1
 jdeb.version=0.8
 jdiff.version=1.0.9
 jetty.version=6.1.26
@@ -71,8 +75,8 @@ zookeeper.version=3.3.3
 servlet.version=4.0.6
 servlet-api.version=2.5
 protobuf-java.version=2.4.0a
-guice.version=2.0
-guice-servlet.version=2.0
+guice.version=3.0
+guice-servlet.version=3.0
 aopalliance.version=1.0
 jsr311-api.version=1.1.1
 mockito.version=1.8.4
diff --git a/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java b/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
index ce7b50996..c01cf973e 100644
--- a/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
+++ b/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
@@ -20,6 +20,8 @@ package org.apache.pig.backend.hadoop.executionengine.shims;
 import java.io.IOException;
 
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapred.jobcontrol.Job;
 import org.apache.hadoop.mapred.jobcontrol.JobControl;
 import org.apache.hadoop.mapreduce.JobContext;
@@ -93,4 +95,8 @@ public class HadoopShims {
     public static JobControl newJobControl(String groupName, int timeToSleep) {
       return new PigJobControl(groupName, timeToSleep);
     }
+    
+    public static long getDefaultBlockSize(FileSystem fs, Path path) {
+        return fs.getDefaultBlockSize();
+    }
 }
diff --git a/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java b/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
index 864f6a471..ed3ba574e 100644
--- a/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
+++ b/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
@@ -20,6 +20,8 @@ package org.apache.pig.backend.hadoop.executionengine.shims;
 import java.io.IOException;
 
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapred.JobConf;
 import org.apache.hadoop.mapred.jobcontrol.Job;
 import org.apache.hadoop.mapred.jobcontrol.JobControl;
@@ -99,4 +101,8 @@ public class HadoopShims {
     public static JobControl newJobControl(String groupName, int timeToSleep) {
       return new PigJobControl(groupName, timeToSleep);
     }
+    
+    public static long getDefaultBlockSize(FileSystem fs, Path path) {
+        return fs.getDefaultBlockSize(path);
+    }
 }
diff --git a/shims/test/hadoop23/org/apache/pig/test/MiniCluster.java b/shims/test/hadoop23/org/apache/pig/test/MiniCluster.java
index b803a5010..e33db60aa 100644
--- a/shims/test/hadoop23/org/apache/pig/test/MiniCluster.java
+++ b/shims/test/hadoop23/org/apache/pig/test/MiniCluster.java
@@ -69,6 +69,9 @@ public class MiniCluster extends MiniGenericCluster {
             m_dfs = new MiniDFSCluster(config, dataNodes, true, null);
             m_fileSys = m_dfs.getFileSystem();
             m_dfs_conf = m_dfs.getConfiguration(0);
+            
+            //Create user home directory
+            m_fileSys.mkdirs(m_fileSys.getWorkingDirectory());
 
             m_mr = new MiniMRYarnCluster("PigMiniCluster", taskTrackers);
             m_mr.init(m_dfs_conf);
diff --git a/src/org/apache/pig/backend/datastorage/DataStorage.java b/src/org/apache/pig/backend/datastorage/DataStorage.java
index 423952c5b..054b8ed5e 100644
--- a/src/org/apache/pig/backend/datastorage/DataStorage.java
+++ b/src/org/apache/pig/backend/datastorage/DataStorage.java
@@ -30,7 +30,6 @@ import java.io.IOException;
 
 public interface DataStorage {
         
-        public static final String DEFAULT_REPLICATION_FACTOR_KEY = "pig.default.replication.factor";
         public static final String USED_BYTES_KEY = "pig.used.bytes";
         public static final String RAW_CAPACITY_KEY = "pig.raw.capacity.bytes";    // replication is disregarded
         public static final String RAW_USED_KEY = "pig.raw.used.capacity.bytes";   // replication is disregarded
diff --git a/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java b/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java
index e2f4952d7..8161ac229 100644
--- a/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java
+++ b/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java
@@ -74,9 +74,6 @@ public class HDataStorage implements DataStorage {
         } catch (IOException e) {
             throw new RuntimeException("Failed to create DataStorage", e);
         }
-        short defaultReplication = fs.getDefaultReplication();
-        properties.setProperty(DEFAULT_REPLICATION_FACTOR_KEY, 
-                               Short.valueOf(defaultReplication).toString());
     }
 
     public void close() throws IOException {
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
index 1c76c2487..834e93283 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
@@ -1271,8 +1271,9 @@ public class MRCompiler extends PhyPlanVisitor {
                             InputFormat inf = loader.getInputFormat();
                             List<InputSplit> splits = inf.getSplits(HadoopShims.cloneJobContext(job));
                             List<List<InputSplit>> results = MapRedUtil
-                            .getCombinePigSplits(splits, fs
-                                    .getDefaultBlockSize(), conf);
+                            .getCombinePigSplits(splits,
+                                    HadoopShims.getDefaultBlockSize(fs, path),
+                                    conf);
                             numFiles += results.size();
                         } else {
                             List<MapReduceOper> preds = MRPlan.getPredecessors(mro);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
index 6c4d7aa67..22663056c 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
@@ -225,7 +225,7 @@ public class PigInputFormat extends InputFormat<Text, Tuple> {
                 Path path = new Path(inputs.get(i).getFileName());
                                 
                 FileSystem fs;
-                
+                boolean isFsPath = true;
                 try {
                     fs = path.getFileSystem(conf);
                 } catch (Exception e) {
@@ -235,6 +235,7 @@ public class PigInputFormat extends InputFormat<Text, Tuple> {
                     // getting the file system. That's
                     // ok, we just use the dfs in that case.
                     fs = new Path("/").getFileSystem(conf);
+                    isFsPath = false;
                 }
 
                 // if the execution is against Mapred DFS, set
@@ -274,7 +275,9 @@ public class PigInputFormat extends InputFormat<Text, Tuple> {
                         HadoopShims.createJobContext(inputSpecificJob.getConfiguration(), 
                                 jobcontext.getJobID()));
                 List<InputSplit> oneInputPigSplits = getPigSplits(
-                        oneInputSplits, i, inpTargets.get(i), fs.getDefaultBlockSize(), combinable, confClone);
+                        oneInputSplits, i, inpTargets.get(i),
+                        HadoopShims.getDefaultBlockSize(fs, isFsPath? path: fs.getWorkingDirectory()),
+                        combinable, confClone);
                 splits.addAll(oneInputPigSplits);
             } catch (ExecException ee) {
                 throw ee;
diff --git a/test/org/apache/pig/test/TestBuiltin.java b/test/org/apache/pig/test/TestBuiltin.java
index f77803844..85acbb0aa 100644
--- a/test/org/apache/pig/test/TestBuiltin.java
+++ b/test/org/apache/pig/test/TestBuiltin.java
@@ -192,7 +192,7 @@ public class TestBuiltin {
     @Before
     public void setUp() throws Exception {
 
-        pigServer = new PigServer(ExecType.LOCAL, cluster.getProperties());
+        pigServer = new PigServer(ExecType.LOCAL, new Properties());
         pigServer.setValidateEachStatement(true);
         // First set up data structs for "base" SUM, MIN and MAX and AVG.
         // The allowed input and expected output data structs for
diff --git a/test/org/apache/pig/test/TestJobSubmission.java b/test/org/apache/pig/test/TestJobSubmission.java
index 89ac132dc..021662f47 100644
--- a/test/org/apache/pig/test/TestJobSubmission.java
+++ b/test/org/apache/pig/test/TestJobSubmission.java
@@ -536,7 +536,7 @@ public class TestJobSubmission {
     @Test
     public void testReducerNumEstimation() throws Exception{
         // skip this test for 23 until HBASE-4850
-        if (Util.isHadoop23())
+        if (Util.isHadoop23() || Util.isHadoop2_0())
             return;
         // use the estimation
         Configuration conf = cluster.getConfiguration();
diff --git a/test/org/apache/pig/test/TestPigRunner.java b/test/org/apache/pig/test/TestPigRunner.java
index fb8c8b178..69cd242f8 100644
--- a/test/org/apache/pig/test/TestPigRunner.java
+++ b/test/org/apache/pig/test/TestPigRunner.java
@@ -580,7 +580,7 @@ public class TestPigRunner {
     @Test
     public void classLoaderTest() throws Exception {
         // Skip in hadoop 23 test, see PIG-2449
-        if (Util.isHadoop23())
+        if (Util.isHadoop23() || Util.isHadoop2_0())
             return;
         PrintWriter w = new PrintWriter(new FileWriter(PIG_FILE));
         w.println("register test/org/apache/pig/test/data/pigtestloader.jar");
diff --git a/test/org/apache/pig/test/TestScriptUDF.java b/test/org/apache/pig/test/TestScriptUDF.java
index cf9953321..16b456392 100644
--- a/test/org/apache/pig/test/TestScriptUDF.java
+++ b/test/org/apache/pig/test/TestScriptUDF.java
@@ -159,7 +159,7 @@ public class TestScriptUDF{
     @Test
     public void testPythonNestedImport() throws Exception {
         // Skip for hadoop 23 until PIG-2433 fixed
-        if (Util.isHadoop23())
+        if (Util.isHadoop23() || Util.isHadoop2_0())
             return;
         
         String[] scriptA = {
diff --git a/test/org/apache/pig/test/Util.java b/test/org/apache/pig/test/Util.java
index 0af1eae21..ea96e694b 100644
--- a/test/org/apache/pig/test/Util.java
+++ b/test/org/apache/pig/test/Util.java
@@ -533,6 +533,14 @@ public class Util {
          } 
      }
      
+     static private String getMkDirCommandForHadoop2_0(String fileName) {
+         if (Util.isHadoop23() || Util.isHadoop2_0()) {
+             Path parentDir = new Path(fileName).getParent();
+             String mkdirCommand = parentDir.getName().isEmpty() ? "" : "fs -mkdir -p " + parentDir + "\n";
+             return mkdirCommand;
+         }
+         return "";
+     }
      
     /**
 	 * Utility method to copy a file form local filesystem to the dfs on
@@ -544,7 +552,7 @@ public class Util {
 	 */
 	static public void copyFromLocalToCluster(MiniCluster cluster, String localFileName, String fileNameOnCluster) throws IOException {
         PigServer ps = new PigServer(ExecType.MAPREDUCE, cluster.getProperties());
-        String script = "fs -put " + localFileName + " " + fileNameOnCluster;
+        String script = getMkDirCommandForHadoop2_0(fileNameOnCluster) + "fs -put " + localFileName + " " + fileNameOnCluster;
 
 	    GruntParser parser = new GruntParser(new StringReader(script));
         parser.setInteractive(false);
@@ -559,7 +567,7 @@ public class Util {
     static public void copyFromLocalToLocal(String fromLocalFileName,
             String toLocalFileName) throws IOException {
         PigServer ps = new PigServer(ExecType.LOCAL, new Properties());
-        String script = "fs -cp " + fromLocalFileName + " " + toLocalFileName;
+        String script = getMkDirCommandForHadoop2_0(toLocalFileName) + "fs -cp " + fromLocalFileName + " " + toLocalFileName;
 
         new File(toLocalFileName).deleteOnExit();
         
@@ -1180,4 +1188,11 @@ public class Util {
     private static void assertConfLong(Configuration conf, String param, long expected) {
         assertEquals("Unexpected value found in configs for " + param, expected, conf.getLong(param, -1));
     }
+
+    public static boolean isHadoop2_0() {
+        String version = org.apache.hadoop.util.VersionInfo.getVersion();
+        if (version.matches("\\b2\\.0\\..+"))
+            return true;
+        return false;
+    }
 }
