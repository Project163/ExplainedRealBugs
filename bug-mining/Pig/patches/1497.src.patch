diff --git a/CHANGES.txt b/CHANGES.txt
index ab37ce0ab..0aa32c653 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -40,6 +40,8 @@ OPTIMIZATIONS
  
 BUG FIXES
 
+PIG-4023: BigDec/Int sort is broken (ahireanup via daijy)
+
 PIG-4003: Error is thrown by JobStats.getOutputSize() when storing to a Hive table (cheolsoo)
 
 PIG-4035: Fix CollectedGroup e2e tests for tez (daijy)
diff --git a/src/org/apache/pig/backend/hadoop/BigDecimalWritable.java b/src/org/apache/pig/backend/hadoop/BigDecimalWritable.java
index 03ececf28..487fea9b4 100644
--- a/src/org/apache/pig/backend/hadoop/BigDecimalWritable.java
+++ b/src/org/apache/pig/backend/hadoop/BigDecimalWritable.java
@@ -97,8 +97,8 @@ public class BigDecimalWritable implements WritableComparable<BigDecimalWritable
         public int compare(byte[] b1, int s1, int l1,
                            byte[] b2, int s2, int l2) {
             try {
-                thisValue.readFields(new DataInputStream(new ByteArrayInputStream(b1)));
-                thatValue.readFields(new DataInputStream(new ByteArrayInputStream(b2)));
+                thisValue.readFields(new DataInputStream(new ByteArrayInputStream(b1,s1,l1)));
+                thatValue.readFields(new DataInputStream(new ByteArrayInputStream(b2,s2,l2)));
             } catch (IOException e) {
                 throw new RuntimeException("Unable to read field from byte array: " + e);
             }
diff --git a/src/org/apache/pig/backend/hadoop/BigIntegerWritable.java b/src/org/apache/pig/backend/hadoop/BigIntegerWritable.java
index 65c18ef9b..11608c1b8 100644
--- a/src/org/apache/pig/backend/hadoop/BigIntegerWritable.java
+++ b/src/org/apache/pig/backend/hadoop/BigIntegerWritable.java
@@ -97,8 +97,8 @@ public class BigIntegerWritable implements WritableComparable<BigIntegerWritable
         public int compare(byte[] b1, int s1, int l1,
                            byte[] b2, int s2, int l2) {
             try {
-                thisValue.readFields(new DataInputStream(new ByteArrayInputStream(b1)));
-                thatValue.readFields(new DataInputStream(new ByteArrayInputStream(b2)));
+                thisValue.readFields(new DataInputStream(new ByteArrayInputStream(b1,s1,l1)));
+                thatValue.readFields(new DataInputStream(new ByteArrayInputStream(b2,s2,l2)));
             } catch (IOException e) {
                 throw new RuntimeException("Unable to read field from byte array: " + e);
             }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigDecimalRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigDecimalRawComparator.java
index 025e7c6c6..15c559945 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigDecimalRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigDecimalRawComparator.java
@@ -18,6 +18,7 @@
 package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;
 
 import java.io.IOException;
+import java.math.BigDecimal;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -90,7 +91,7 @@ public class PigBigDecimalRawComparator extends WritableComparator implements Co
 
         // If either are null, handle differently.
         if (!ndw1.isNull() && !ndw2.isNull()) {
-            rc = ((Double)ndw1.getValueAsPigType()).compareTo((Double)ndw2.getValueAsPigType());
+            rc = ((BigDecimal)ndw1.getValueAsPigType()).compareTo((BigDecimal)ndw2.getValueAsPigType());
         } else {
             // For sorting purposes two nulls are equal.
             if (ndw1.isNull() && ndw2.isNull()) rc = 0;
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigIntegerRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigIntegerRawComparator.java
index 1555c31d1..dd8bedcaa 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigIntegerRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBigIntegerRawComparator.java
@@ -18,6 +18,7 @@
 package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;
 
 import java.io.IOException;
+import java.math.BigInteger;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -90,7 +91,7 @@ public class PigBigIntegerRawComparator extends WritableComparator implements Co
 
         // If either are null, handle differently.
         if (!ndw1.isNull() && !ndw2.isNull()) {
-            rc = ((Double)ndw1.getValueAsPigType()).compareTo((Double)ndw2.getValueAsPigType());
+            rc = ((BigInteger)ndw1.getValueAsPigType()).compareTo((BigInteger)ndw2.getValueAsPigType());
         } else {
             // For sorting purposes two nulls are equal.
             if (ndw1.isNull() && ndw2.isNull()) rc = 0;
diff --git a/test/org/apache/pig/builtin/TestBigTypeSort.java b/test/org/apache/pig/builtin/TestBigTypeSort.java
new file mode 100644
index 000000000..6dbf699b5
--- /dev/null
+++ b/test/org/apache/pig/builtin/TestBigTypeSort.java
@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.builtin;
+
+import static org.apache.pig.builtin.mock.Storage.resetData;
+import static org.apache.pig.builtin.mock.Storage.tuple;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+import java.math.BigDecimal;
+import java.math.BigInteger;
+import java.util.Iterator;
+import java.util.List;
+
+import org.apache.pig.ExecType;
+import org.apache.pig.PigServer;
+import org.apache.pig.builtin.mock.Storage.Data;
+import org.apache.pig.data.Tuple;
+import org.junit.Before;
+import org.junit.Test;
+
+import com.google.common.collect.Lists;
+
+public class TestBigTypeSort {
+	private static PigServer pigServer;
+
+	@Before
+	public void setUp() throws Exception {
+		pigServer = new PigServer(ExecType.LOCAL);
+	}
+
+	@Test
+	public void testBigTypeSort() throws Exception {
+		Data data = resetData(pigServer);
+
+		List<Tuple> bigtypes = Lists.newArrayList();
+		bigtypes.add(tuple("123456789012314", "123000456000789000123000456000789000123000456000789.123"));
+		bigtypes.add(tuple("123456789012334", "1.0E40"));
+		bigtypes.add(tuple("103456789012034", "123000456000780000123000456000789000123000456000789.113"));
+
+		data.set("bigtypes", bigtypes);
+
+		pigServer.registerQuery("A = LOAD 'bigtypes' USING mock.Storage() as (x:biginteger,y:bigdecimal);");
+		pigServer.registerQuery("B = ORDER A BY x ASC;");
+		pigServer.registerQuery("C = ORDER A BY y ASC;");
+
+		Iterator<Tuple> it = pigServer.openIterator("B");
+		assertTrue(it.hasNext());
+		assertEquals(new BigInteger("103456789012034"), it.next().get(0));
+		assertEquals(new BigInteger("123456789012314"), it.next().get(0));
+		assertEquals(new BigInteger("123456789012334"), it.next().get(0));
+		assertFalse(it.hasNext());
+
+		it = pigServer.openIterator("C");
+		assertTrue(it.hasNext());
+		assertEquals(new BigDecimal("1.0E40"), it.next().get(1));
+		assertEquals(new BigDecimal("123000456000780000123000456000789000123000456000789.113"), it.next().get(1));
+		assertEquals(new BigDecimal("123000456000789000123000456000789000123000456000789.123"), it.next().get(1));
+		assertFalse(it.hasNext());
+
+	}
+}
