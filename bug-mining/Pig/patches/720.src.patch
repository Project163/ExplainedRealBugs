diff --git a/CHANGES.txt b/CHANGES.txt
index 05450d752..8a67e65cf 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -196,6 +196,8 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by
 
 BUG FIXES
 
+PIG-2028: Speed up multiquery unit tests (rding)
+
 PIG-1990: support casting of complex types with empty inner schema
  to complex type with non-empty inner schema (thejas)
 
diff --git a/test/org/apache/pig/test/TestMultiQuery.java b/test/org/apache/pig/test/TestMultiQuery.java
index 932e012bd..964ce019a 100644
--- a/test/org/apache/pig/test/TestMultiQuery.java
+++ b/test/org/apache/pig/test/TestMultiQuery.java
@@ -21,19 +21,15 @@ import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 import java.io.File;
-import java.io.FileWriter;
-import java.io.IOException;
-import java.io.PrintWriter;
 import java.util.Iterator;
 import java.util.List;
-
-import junit.framework.Assert;
+import java.util.Properties;
 
 import org.apache.pig.ExecType;
 import org.apache.pig.PigServer;
 import org.apache.pig.backend.executionengine.ExecJob;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.impl.io.FileLocalizer;
+import org.apache.pig.impl.PigContext;
 import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Before;
@@ -41,972 +37,752 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
+
 @RunWith(JUnit4.class)
 public class TestMultiQuery {
 
-    private static final MiniCluster cluster = MiniCluster.buildCluster();
-
-    private PigServer myPig;
+    private static PigServer myPig;
 
     @BeforeClass
-    public static void setUpBeforeClass() throws IOException {
-        Util.copyFromLocalToCluster(cluster,
+    public static void setUpBeforeClass() throws Exception {
+        Util.copyFromLocalToLocal(
                 "test/org/apache/pig/test/data/passwd", "passwd");
-        Util.copyFromLocalToCluster(cluster,
+        Util.copyFromLocalToLocal(
                 "test/org/apache/pig/test/data/passwd2", "passwd2");
+        Properties props = new Properties();
+        props.setProperty("opt.multiquery", ""+true);
+        myPig = new PigServer(ExecType.LOCAL, props);
     }
     
     @AfterClass
-    public static void tearDownAfterClass() throws IOException {
-        Util.deleteFile(cluster, "passwd");
-        Util.deleteFile(cluster, "passwd2");
-        cluster.shutDown();
+    public static void tearDownAfterClass() throws Exception {
+        Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), "passwd");
+        Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), "passwd2");
+        deleteOutputFiles();
     }
     
     @Before
     public void setUp() throws Exception {
-        cluster.setProperty("opt.multiquery", ""+true);
-        myPig = new PigServer(ExecType.MAPREDUCE, cluster.getProperties());
         deleteOutputFiles();
     }
 
     @After
     public void tearDown() throws Exception {
-        myPig = null;
+
     }
 
     @Test
-    public void testMultiQueryJiraPig1438() {
+    public void testMultiQueryJiraPig1438() throws Exception {
 
         // test case: merge multiple distinct jobs
         
         String INPUT_FILE = "abc";
         
-        try {
-    
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("1\t2\t3");
-            w.println("2\t3\t4");
-            w.println("1\t2\t3");
-            w.println("2\t3\t4");
-            w.println("1\t2\t3");
-            w.close();
-    
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-           
-            myPig.setBatchOn();
-    
-            myPig.registerQuery("A = load '" + INPUT_FILE + "' as (col1:int, col2:int, col3:int);");
-            myPig.registerQuery("B1 = foreach A generate col1, col2;");
-            myPig.registerQuery("B2 = foreach A generate col2, col3;");
-            myPig.registerQuery("C1 = distinct B1;");
-            myPig.registerQuery("C2 = distinct B2;");
-            myPig.registerQuery("D1 = foreach C1 generate col1, col2;");
-            myPig.registerQuery("D2 = foreach C2 generate col2, col3;");
-            myPig.registerQuery("store D1 into '/tmp/output1';");
-            myPig.registerQuery("store D2 into '/tmp/output2';");            
-            
-            myPig.executeBatch();
-            
-            myPig.registerQuery("E = load '/tmp/output1' as (a:int, b:int);");            
-            Iterator<Tuple> iter = myPig.openIterator("E");
-
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "(1,2)",
-                            "(2,3)"
-                    });
-            
-            int counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
-            }
-            assertEquals(expectedResults.size(), counter);
-                        
-            myPig.registerQuery("E = load '/tmp/output2' as (a:int, b:int);");            
-            iter = myPig.openIterator("E");
-
-            expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "(2,3)",
-                            "(3,4)"
-                    });
-            
-            counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
-            }
-
-            assertEquals(expectedResults.size(), counter);
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        String[] inputData = {
+                "1\t2\t3",
+                "2\t3\t4",
+                "1\t2\t3",
+                "2\t3\t4",
+                "1\t2\t3"
+        };
+        
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+       
+        myPig.setBatchOn();
+
+        myPig.registerQuery("A = load '" + INPUT_FILE + "' as (col1:int, col2:int, col3:int);");
+        myPig.registerQuery("B1 = foreach A generate col1, col2;");
+        myPig.registerQuery("B2 = foreach A generate col2, col3;");
+        myPig.registerQuery("C1 = distinct B1;");
+        myPig.registerQuery("C2 = distinct B2;");
+        myPig.registerQuery("D1 = foreach C1 generate col1, col2;");
+        myPig.registerQuery("D2 = foreach C2 generate col2, col3;");
+        myPig.registerQuery("store D1 into 'output1';");
+        myPig.registerQuery("store D2 into 'output2';");            
+        
+        myPig.executeBatch();
+        
+        myPig.registerQuery("E = load 'output1' as (a:int, b:int);");            
+        Iterator<Tuple> iter = myPig.openIterator("E");
+
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "(1,2)",
+                        "(2,3)"
+                });
+        
+        int counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
+        }
+        assertEquals(expectedResults.size(), counter);
+                    
+        myPig.registerQuery("E = load 'output2' as (a:int, b:int);");            
+        iter = myPig.openIterator("E");
+
+        expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "(2,3)",
+                        "(3,4)"
+                });
+        
+        counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
         }
+
+        assertEquals(expectedResults.size(), counter);
     }
     
     @Test
-    public void testMultiQueryJiraPig1252() {
+    public void testMultiQueryJiraPig1252() throws Exception {
 
         // test case: Problems with secondary key optimization and multiquery
         // diamond optimization
         
         String INPUT_FILE = "abc";
         
-        try {
-    
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("1\t2\t3");
-            w.println("2\t3\t4");
-            w.println("3\t\t5");
-            w.println("5\t6\t6");
-            w.println("6\t\t7");
-            w.close();
-    
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-           
-            myPig.setBatchOn();
-    
-            myPig.registerQuery("A = load '" + INPUT_FILE + "' as (col1, col2, col3);");
-            myPig.registerQuery("B = foreach A generate (chararray) col1, " +
-            		"(chararray) ((col2 is not null) ?  " +
-            		"col2 : (col3 < 6 ? col3 : '')) as splitcond;");
-            myPig.registerQuery("split B into C if splitcond !=  '', D if splitcond == '';");
-            myPig.registerQuery("E = group C by splitcond;");
-            myPig.registerQuery("F = foreach E { orderedData = order C by $1, $0; generate flatten(orderedData); };");
-       
-            Iterator<Tuple> iter = myPig.openIterator("F");
-
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "(1,2)",
-                            "(2,3)",
-                            "(3,5)",
-                            "(5,6)"
-                    });
-            
-            int counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());                  
-            }
+        String[] inputData = {
+            "1\t2\t3",
+            "2\t3\t4",
+            "3\t\t5",
+            "5\t6\t6",
+            "6\t\t7"       
+        };
+        
+        Util.createLocalInputFile(INPUT_FILE, inputData);
 
-            assertEquals(expectedResults.size(), counter);
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        myPig.setBatchOn();
+
+        myPig.registerQuery("A = load '" + INPUT_FILE + "' as (col1, col2, col3);");
+        myPig.registerQuery("B = foreach A generate (chararray) col1, " +
+        		"(chararray) ((col2 is not null) ?  " +
+        		"col2 : (col3 < 6 ? col3 : '')) as splitcond;");
+        myPig.registerQuery("split B into C if splitcond !=  '', D if splitcond == '';");
+        myPig.registerQuery("E = group C by splitcond;");
+        myPig.registerQuery("F = foreach E { orderedData = order C by $1, $0; generate flatten(orderedData); };");
+   
+        Iterator<Tuple> iter = myPig.openIterator("F");
+
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "(1,2)",
+                        "(2,3)",
+                        "(3,5)",
+                        "(5,6)"
+                });
+        
+        int counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());                  
         }
+
+        assertEquals(expectedResults.size(), counter);
     }
 
     @Test
-    public void testMultiQueryJiraPig1169() {
+    public void testMultiQueryJiraPig1169() throws Exception {
 
         // test case: Problems with some top N queries
         
         String INPUT_FILE = "abc";
         
-        try {
-    
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("1\t2\t3");
-            w.println("2\t3\t4");
-            w.println("3\t4\t5");
-            w.println("5\t6\t7");
-            w.println("6\t7\t8");
-            w.close();
-    
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-           
-            myPig.setBatchOn();
-    
-            myPig.registerQuery("A = load '" + INPUT_FILE 
-                    + "' as (a:int, b, c);");
-            myPig.registerQuery("A1 = Order A by a desc parallel 3;");
-            myPig.registerQuery("A2 = limit A1 2;");
-            myPig.registerQuery("store A1 into '/tmp/input1';");
-            myPig.registerQuery("store A2 into '/tmp/input2';");
+        String[] inputData = {
+                "1\t2\t3",
+                "2\t3\t4",
+                "3\t4\t5",
+                "5\t6\t7",
+                "6\t7\t8"       
+        };
+        
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+       
+        myPig.setBatchOn();
 
-            myPig.executeBatch();
+        myPig.registerQuery("A = load '" + INPUT_FILE 
+                + "' as (a:int, b, c);");
+        myPig.registerQuery("A1 = Order A by a desc parallel 3;");
+        myPig.registerQuery("A2 = limit A1 2;");
+        myPig.registerQuery("store A1 into 'output1';");
+        myPig.registerQuery("store A2 into 'output2';");
 
-            myPig.registerQuery("B = load '/tmp/input2' as (a:int, b, c);");
-            
-            Iterator<Tuple> iter = myPig.openIterator("B");
+        myPig.executeBatch();
 
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "(6,7,8)",
-                            "(5,6,7)"
-                    });
-            
-            int counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
-            }
+        myPig.registerQuery("B = load 'output2' as (a:int, b, c);");
+        
+        Iterator<Tuple> iter = myPig.openIterator("B");
 
-            assertEquals(expectedResults.size(), counter);
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "(6,7,8)",
+                        "(5,6,7)"
+                });
+        
+        int counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
         }
+
+        assertEquals(expectedResults.size(), counter);
     }
   
     @Test
-    public void testMultiQueryJiraPig1171() {
+    public void testMultiQueryJiraPig1171() throws Exception {
 
         // test case: Problems with some top N queries
         
         String INPUT_FILE = "abc";
         
-        try {
-    
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("1\tapple\t3");
-            w.println("2\torange\t4");
-            w.println("3\tpersimmon\t5");
-            w.close();
-    
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-           
-            myPig.setBatchOn();
-    
-            myPig.registerQuery("A = load '" + INPUT_FILE 
-                    + "' as (a:long, b, c);");
-            myPig.registerQuery("A1 = Order A by a desc;");
-            myPig.registerQuery("A2 = limit A1 1;");
-            myPig.registerQuery("B = load '" + INPUT_FILE 
-                    + "' as (a:long, b, c);");
-            myPig.registerQuery("B1 = Order B by a desc;");
-            myPig.registerQuery("B2 = limit B1 1;");
-            
-            myPig.registerQuery("C = cross A2, B2;");
-            
-            Iterator<Tuple> iter = myPig.openIterator("C");
-
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "(3L,'persimmon',5,3L,'persimmon',5)"
-                    });
-            
-            int counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
-            }
+        String[] inputData = {
+            "1\tapple\t3",
+            "2\torange\t4",
+            "3\tpersimmon\t5"    
+        };
+        
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("A = load '" + INPUT_FILE 
+                + "' as (a:long, b, c);");
+        myPig.registerQuery("A1 = Order A by a desc;");
+        myPig.registerQuery("A2 = limit A1 1;");
+        myPig.registerQuery("B = load '" + INPUT_FILE 
+                + "' as (a:long, b, c);");
+        myPig.registerQuery("B1 = Order B by a desc;");
+        myPig.registerQuery("B2 = limit B1 1;");
+        
+        myPig.registerQuery("C = cross A2, B2;");
+        
+        Iterator<Tuple> iter = myPig.openIterator("C");
 
-            assertEquals(expectedResults.size(), counter);
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "(3L,'persimmon',5,3L,'persimmon',5)"
+                });
+        
+        int counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());      
         }
+
+        assertEquals(expectedResults.size(), counter);
     }
     
     @Test
-    public void testMultiQueryJiraPig1157() {
+    public void testMultiQueryJiraPig1157() throws Exception {
 
         // test case: Sucessive replicated joins do not generate Map Reduce plan and fails due to OOM
         
         String INPUT_FILE = "abc";
-        String INPUT_FILE_1 = "xyz";
+        String INPUT_FILE_1 = "abc";
         
-        try {
-    
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("1\tapple\t3");
-            w.println("2\torange\t4");
-            w.println("3\tpersimmon\t5");
-            w.close();
-    
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE_1);
-    
-            myPig.setBatchOn();
-    
-            myPig.registerQuery("A = load '" + INPUT_FILE 
-                    + "' as (a:long, b, c);");
-            myPig.registerQuery("A1 = FOREACH A GENERATE a;");
-            myPig.registerQuery("B = GROUP A1 BY a;");
-            myPig.registerQuery("C = load '" + INPUT_FILE_1 
-                    + "' as (x:long, y);");
-            myPig.registerQuery("D = JOIN C BY x, B BY group USING 'replicated';");  
-            myPig.registerQuery("E = JOIN A BY a, D by x USING 'replicated';");  
-            
-            Iterator<Tuple> iter = myPig.openIterator("E");
-
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "(1L,'apple',3,1L,'apple',1L,{(1L)})",
-                            "(2L,'orange',4,2L,'orange',2L,{(2L)})",
-                            "(3L,'persimmon',5,3L,'persimmon',3L,{(3L)})"
-                    });
-            
-            int counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());                  
-            }
-
-            assertEquals(expectedResults.size(), counter);
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-                Util.deleteFile(cluster, INPUT_FILE_1);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        String[] inputData = {
+                "1\tapple\t3",
+                "2\torange\t4",
+                "3\tpersimmon\t5"    
+        };
+            
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("A = load '" + INPUT_FILE 
+                + "' as (a:long, b, c);");
+        myPig.registerQuery("A1 = FOREACH A GENERATE a;");
+        myPig.registerQuery("B = GROUP A1 BY a;");
+        myPig.registerQuery("C = load '" + INPUT_FILE_1 
+                + "' as (x:long, y);");
+        myPig.registerQuery("D = JOIN C BY x, B BY group USING 'replicated';");  
+        myPig.registerQuery("E = JOIN A BY a, D by x USING 'replicated';");  
+        
+        Iterator<Tuple> iter = myPig.openIterator("E");
+
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "(1L,'apple',3,1L,'apple',1L,{(1L)})",
+                        "(2L,'orange',4,2L,'orange',2L,{(2L)})",
+                        "(3L,'persimmon',5,3L,'persimmon',3L,{(3L)})"
+                });
+        
+        int counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());                  
         }
+
+        assertEquals(expectedResults.size(), counter);
     }
     
     @Test
-    public void testMultiQueryJiraPig1068() {
+    public void testMultiQueryJiraPig1068() throws Exception {
 
         // test case: COGROUP fails with 'Type mismatch in key from map: 
         // expected org.apache.pig.impl.io.NullableText, recieved org.apache.pig.impl.io.NullableTuple'
 
         String INPUT_FILE = "pig-1068.txt";
 
-        try {
-
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("10\tapple\tlogin\tjar");
-            w.println("20\torange\tlogin\tbox");
-            w.println("30\tstrawberry\tquit\tbot");
-
-            w.close();
-
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-
-            myPig.setBatchOn();
-
-            myPig.registerQuery("logs = load '" + INPUT_FILE 
-                    + "' as (ts:int, id:chararray, command:chararray, comments:chararray);");
-            myPig.registerQuery("SPLIT logs INTO logins IF command == 'login', all_quits IF command == 'quit';");
-            myPig.registerQuery("login_info = FOREACH logins { GENERATE id as id, comments AS client; };");  
-            myPig.registerQuery("logins_grouped = GROUP login_info BY (id, client);");
-            myPig.registerQuery("count_logins_by_client = FOREACH logins_grouped "
-                    + "{ generate group.id AS id, group.client AS client, COUNT($1) AS count; };");
-            myPig.registerQuery("all_quits_grouped = GROUP all_quits BY id; ");
-            myPig.registerQuery("quits = FOREACH all_quits_grouped { GENERATE FLATTEN(all_quits); };");
-            myPig.registerQuery("joined_session_info = COGROUP quits BY id, count_logins_by_client BY id;");
-            
-            Iterator<Tuple> iter = myPig.openIterator("joined_session_info");
-
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "('apple',{},{('apple','jar',1L)})",
-                            "('orange',{},{('orange','box',1L)})",
-                            "('strawberry',{(30,'strawberry','quit','bot')},{})"
-                    });
-            
-            int counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());                
-            }
-
-            assertEquals(expectedResults.size(), counter);
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        String[] inputData = {
+            "10\tapple\tlogin\tjar",
+            "20\torange\tlogin\tbox",
+            "30\tstrawberry\tquit\tbot"    
+        };
+            
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("logs = load '" + INPUT_FILE 
+                + "' as (ts:int, id:chararray, command:chararray, comments:chararray);");
+        myPig.registerQuery("SPLIT logs INTO logins IF command == 'login', all_quits IF command == 'quit';");
+        myPig.registerQuery("login_info = FOREACH logins { GENERATE id as id, comments AS client; };");  
+        myPig.registerQuery("logins_grouped = GROUP login_info BY (id, client);");
+        myPig.registerQuery("count_logins_by_client = FOREACH logins_grouped "
+                + "{ generate group.id AS id, group.client AS client, COUNT($1) AS count; };");
+        myPig.registerQuery("all_quits_grouped = GROUP all_quits BY id; ");
+        myPig.registerQuery("quits = FOREACH all_quits_grouped { GENERATE FLATTEN(all_quits); };");
+        myPig.registerQuery("joined_session_info = COGROUP quits BY id, count_logins_by_client BY id;");
+        
+        Iterator<Tuple> iter = myPig.openIterator("joined_session_info");
+
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "('apple',{},{('apple','jar',1L)})",
+                        "('orange',{},{('orange','box',1L)})",
+                        "('strawberry',{(30,'strawberry','quit','bot')},{})"
+                });
+        
+        int counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());                
         }
+
+        assertEquals(expectedResults.size(), counter);
     }
     
     @Test
-    public void testMultiQueryJiraPig1108() {
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " 
-                    + "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("split a into plan1 if (uid > 5), plan2 if ( uid < 5);");
-            myPig.registerQuery("b = group plan1 by uname;");
-            myPig.registerQuery("c = foreach b { tmp = order plan1 by uid desc; " 
-                    + "generate flatten(group) as foo, tmp; };");
-            myPig.registerQuery("d = filter c BY foo is not null;");
-            myPig.registerQuery("store d into '/tmp/output1';");
-            myPig.registerQuery("store plan2 into '/tmp/output2';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+    public void testMultiQueryJiraPig1108() throws Exception {
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " 
+                + "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("split a into plan1 if (uid > 5), plan2 if ( uid < 5);");
+        myPig.registerQuery("b = group plan1 by uname;");
+        myPig.registerQuery("c = foreach b { tmp = order plan1 by uid desc; " 
+                + "generate flatten(group) as foo, tmp; };");
+        myPig.registerQuery("d = filter c BY foo is not null;");
+        myPig.registerQuery("store d into 'output1';");
+        myPig.registerQuery("store plan2 into 'output2';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }    
     
     @Test
-    public void testMultiQueryJiraPig1114() {
+    public void testMultiQueryJiraPig1114() throws Exception {
 
         // test case: MultiQuery optimization throws error when merging 2 level splits
 
         String INPUT_FILE = "data.txt";
 
-        try {
-
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("10\tjar");
-            w.println("20\tbox");
-            w.println("30\tbot");
-            w.close();
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-
-            myPig.setBatchOn();
-
-            myPig.registerQuery("data = load '" + INPUT_FILE
-                    + "' USING PigStorage as (id:int, name:chararray);");
-            myPig.registerQuery("ids = FOREACH data GENERATE id;");
-            myPig.registerQuery("allId = GROUP ids all;");
-            myPig.registerQuery("allIdCount = FOREACH allId GENERATE group as allId, COUNT(ids) as total;");
-            myPig.registerQuery("idGroup = GROUP ids by id;");
-            myPig.registerQuery("idGroupCount = FOREACH idGroup GENERATE group as id, COUNT(ids) as count;");
-            myPig.registerQuery("countTotal = cross idGroupCount, allIdCount;");
-            myPig.registerQuery("idCountTotal = foreach countTotal generate id, count, total, (double)count / (double)total as proportion;");
-            myPig.registerQuery("orderedCounts = order idCountTotal by count desc;");
-            myPig.registerQuery("STORE orderedCounts INTO '/tmp/output1';");
-
-            myPig.registerQuery("names = FOREACH data GENERATE name;");
-            myPig.registerQuery("allNames = GROUP names all;");
-            myPig.registerQuery("allNamesCount = FOREACH allNames GENERATE group as namesAll, COUNT(names) as total;");
-            myPig.registerQuery("nameGroup = GROUP names by name;");
-            myPig.registerQuery("nameGroupCount = FOREACH nameGroup GENERATE group as name, COUNT(names) as count;");
-            myPig.registerQuery("namesCrossed = cross nameGroupCount, allNamesCount;");
-            myPig.registerQuery("nameCountTotal = foreach namesCrossed generate name, count, total, (double)count / (double)total as proportion;");
-            myPig.registerQuery("nameCountsOrdered = order nameCountTotal by count desc;");
-            myPig.registerQuery("STORE nameCountsOrdered INTO '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        String[] inputData = {
+            "10\tjar",
+            "20\tbox",
+            "30\tbot"   
+        };
+                
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("data = load '" + INPUT_FILE
+                + "' USING PigStorage as (id:int, name:chararray);");
+        myPig.registerQuery("ids = FOREACH data GENERATE id;");
+        myPig.registerQuery("allId = GROUP ids all;");
+        myPig.registerQuery("allIdCount = FOREACH allId GENERATE group as allId, COUNT(ids) as total;");
+        myPig.registerQuery("idGroup = GROUP ids by id;");
+        myPig.registerQuery("idGroupCount = FOREACH idGroup GENERATE group as id, COUNT(ids) as count;");
+        myPig.registerQuery("countTotal = cross idGroupCount, allIdCount;");
+        myPig.registerQuery("idCountTotal = foreach countTotal generate id, count, total, (double)count / (double)total as proportion;");
+        myPig.registerQuery("orderedCounts = order idCountTotal by count desc;");
+        myPig.registerQuery("STORE orderedCounts INTO 'output1';");
+
+        myPig.registerQuery("names = FOREACH data GENERATE name;");
+        myPig.registerQuery("allNames = GROUP names all;");
+        myPig.registerQuery("allNamesCount = FOREACH allNames GENERATE group as namesAll, COUNT(names) as total;");
+        myPig.registerQuery("nameGroup = GROUP names by name;");
+        myPig.registerQuery("nameGroupCount = FOREACH nameGroup GENERATE group as name, COUNT(names) as count;");
+        myPig.registerQuery("namesCrossed = cross nameGroupCount, allNamesCount;");
+        myPig.registerQuery("nameCountTotal = foreach namesCrossed generate name, count, total, (double)count / (double)total as proportion;");
+        myPig.registerQuery("nameCountsOrdered = order nameCountTotal by count desc;");
+        myPig.registerQuery("STORE nameCountsOrdered INTO 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
         }
     }
     
     @Test
-    public void testMultiQueryJiraPig1113() {
+    public void testMultiQueryJiraPig1113() throws Exception {
 
         // test case: Diamond query optimization throws error in JOIN
 
         String INPUT_FILE_1 = "set1.txt";
         String INPUT_FILE_2 = "set2.txt";
-        try {
-
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE_1));
-            w.println("login\t0\tjar");
-            w.println("login\t1\tbox");
-            w.println("quit\t0\tmany");
-            w.close();
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE_1, INPUT_FILE_1);
-
-            PrintWriter w2 = new PrintWriter(new FileWriter(INPUT_FILE_2));
-            w2.println("apple\tlogin\t{(login)}");
-            w2.println("orange\tlogin\t{(login)}");
-            w2.println("strawberry\tquit\t{(login)}");
-            w2.close();
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE_2, INPUT_FILE_2);
-            
-            myPig.setBatchOn();
-
-            myPig.registerQuery("set1 = load '" + INPUT_FILE_1 
-                    + "' USING PigStorage as (a:chararray, b:chararray, c:chararray);");
-            myPig.registerQuery("set2 = load '" + INPUT_FILE_2
-                    + "' USING PigStorage as (a: chararray, b:chararray, c:bag{});");
-            myPig.registerQuery("set2_1 = FOREACH set2 GENERATE a as f1, b as f2, " 
-                    + "(chararray) 0 as f3;");
-            myPig.registerQuery("set2_2 = FOREACH set2 GENERATE a as f1, "
-                    + "FLATTEN((IsEmpty(c) ? null : c)) as f2, (chararray) 1 as f3;");  
-            myPig.registerQuery("all_set2 = UNION set2_1, set2_2;");
-            myPig.registerQuery("joined_sets = JOIN set1 BY (a,b), all_set2 BY (f2,f3);");
-          
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "('quit','0','many','strawberry','quit','0')",
-                            "('login','0','jar','apple','login','0')",
-                            "('login','0','jar','orange','login','0')",
-                            "('login','1','box','apple','login','1')",
-                            "('login','1','box','orange','login','1')",
-                            "('login','1','box','strawberry','login','1')"
-                    });
-            
-            Iterator<Tuple> iter = myPig.openIterator("joined_sets");
-            int count = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(count++).toString(), iter.next().toString());
-            }
-            assertEquals(expectedResults.size(), count);
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE_1).delete();
-            new File(INPUT_FILE_2).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE_1);
-                Util.deleteFile(cluster, INPUT_FILE_2);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        
+
+        String[] inputData_1 = {
+            "login\t0\tjar",
+            "login\t1\tbox",
+            "quit\t0\tmany" 
+        };
+                
+        Util.createLocalInputFile(INPUT_FILE_1, inputData_1);
+        
+        String[] inputData_2 = {
+            "apple\tlogin\t{(login)}",
+            "orange\tlogin\t{(login)}",
+            "strawberry\tquit\t{(login)}"  
+        };
+                
+        Util.createLocalInputFile(INPUT_FILE_2, inputData_2);
+            
+        myPig.setBatchOn();
+
+        myPig.registerQuery("set1 = load '" + INPUT_FILE_1 
+                + "' USING PigStorage as (a:chararray, b:chararray, c:chararray);");
+        myPig.registerQuery("set2 = load '" + INPUT_FILE_2
+                + "' USING PigStorage as (a: chararray, b:chararray, c:bag{});");
+        myPig.registerQuery("set2_1 = FOREACH set2 GENERATE a as f1, b as f2, " 
+                + "(chararray) 0 as f3;");
+        myPig.registerQuery("set2_2 = FOREACH set2 GENERATE a as f1, "
+                + "FLATTEN((IsEmpty(c) ? null : c)) as f2, (chararray) 1 as f3;");  
+        myPig.registerQuery("all_set2 = UNION set2_1, set2_2;");
+        myPig.registerQuery("joined_sets = JOIN set1 BY (a,b), all_set2 BY (f2,f3);");
+      
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "('quit','0','many','strawberry','quit','0')",
+                        "('login','0','jar','apple','login','0')",
+                        "('login','0','jar','orange','login','0')",
+                        "('login','1','box','apple','login','1')",
+                        "('login','1','box','orange','login','1')",
+                        "('login','1','box','strawberry','login','1')"
+                });
+        
+        Iterator<Tuple> iter = myPig.openIterator("joined_sets");
+        int count = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(count++).toString(), iter.next().toString());
         }
+        assertEquals(expectedResults.size(), count);
     }
  
     @Test
-    public void testMultiQueryJiraPig1060_2() {
+    public void testMultiQueryJiraPig1060_2() throws Exception {
 
         // test case: 
 
         String INPUT_FILE = "pig-1060.txt";
 
-        try {
-
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("apple\t2");
-            w.println("apple\t12");
-            w.println("orange\t3");
-            w.println("orange\t23");
-            w.println("strawberry\t10");
-            w.println("strawberry\t34");
-
-            w.close();
-
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-
-            myPig.setBatchOn();
-
-            myPig.registerQuery("data = load '" + INPUT_FILE +
-            "' as (name:chararray, gid:int);");
-            myPig.registerQuery("f1 = filter data by gid < 5;");
-            myPig.registerQuery("g1 = group f1 by name;");
-            myPig.registerQuery("p1 = foreach g1 generate group, COUNT(f1.gid);");
-            myPig.registerQuery("store p1 into '/tmp/output1';");
-
-            myPig.registerQuery("f2 = filter data by gid > 5;");
-            myPig.registerQuery("g2 = group f2 by name;");
-            myPig.registerQuery("p2 = foreach g2 generate group, COUNT(f2.gid);");
-            myPig.registerQuery("store p2 into '/tmp/output2';");
-
-            myPig.registerQuery("f3 = filter f2 by gid > 10;");
-            myPig.registerQuery("g3 = group f3 by name;");
-            myPig.registerQuery("p3 = foreach g3 generate group, COUNT(f3.gid);");
-            myPig.registerQuery("store p3 into '/tmp/output3';");
-
-            myPig.registerQuery("f4 = filter f3 by gid < 20;");
-            myPig.registerQuery("g4 = group f4 by name;");
-            myPig.registerQuery("p4 = foreach g4 generate group, COUNT(f4.gid);");
-            myPig.registerQuery("store p4 into '/tmp/output4';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertEquals(4, jobs.size());
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
+        String[] inputData = {
+            "apple\t2",
+            "apple\t12",
+            "orange\t3",
+            "orange\t23",
+            "strawberry\t10",
+            "strawberry\t34"  
+        };
+                    
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("data = load '" + INPUT_FILE +
+        "' as (name:chararray, gid:int);");
+        myPig.registerQuery("f1 = filter data by gid < 5;");
+        myPig.registerQuery("g1 = group f1 by name;");
+        myPig.registerQuery("p1 = foreach g1 generate group, COUNT(f1.gid);");
+        myPig.registerQuery("store p1 into 'output1';");
+
+        myPig.registerQuery("f2 = filter data by gid > 5;");
+        myPig.registerQuery("g2 = group f2 by name;");
+        myPig.registerQuery("p2 = foreach g2 generate group, COUNT(f2.gid);");
+        myPig.registerQuery("store p2 into 'output2';");
+
+        myPig.registerQuery("f3 = filter f2 by gid > 10;");
+        myPig.registerQuery("g3 = group f3 by name;");
+        myPig.registerQuery("p3 = foreach g3 generate group, COUNT(f3.gid);");
+        myPig.registerQuery("store p3 into 'output3';");
+
+        myPig.registerQuery("f4 = filter f3 by gid < 20;");
+        myPig.registerQuery("g4 = group f4 by name;");
+        myPig.registerQuery("p4 = foreach g4 generate group, COUNT(f4.gid);");
+        myPig.registerQuery("store p4 into 'output4';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertEquals(4, jobs.size());
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
         }
     } 
 
     @Test
-    public void testMultiQueryJiraPig920_2() {
+    public void testMultiQueryJiraPig920_2() throws Exception {
 
         // test case: execution of a query with two diamonds
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                 "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = filter a by uid < 5;");
-            myPig.registerQuery("c = filter a by gid >= 5;");
-            myPig.registerQuery("d = filter a by uid >= 5;");
-            myPig.registerQuery("e = filter a by gid < 5;");
-            myPig.registerQuery("f = cogroup c by $0, b by $0;");
-            myPig.registerQuery("f1 = foreach f generate group, COUNT(c), COUNT(b);");
-            myPig.registerQuery("store f1 into '/tmp/output1';");
-            myPig.registerQuery("g = cogroup d by $0, e by $0;");
-            myPig.registerQuery("g1 = foreach g generate group, COUNT(d), COUNT(e);");
-            myPig.registerQuery("store g1 into '/tmp/output2';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                             "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = filter a by uid < 5;");
+        myPig.registerQuery("c = filter a by gid >= 5;");
+        myPig.registerQuery("d = filter a by uid >= 5;");
+        myPig.registerQuery("e = filter a by gid < 5;");
+        myPig.registerQuery("f = cogroup c by $0, b by $0;");
+        myPig.registerQuery("f1 = foreach f generate group, COUNT(c), COUNT(b);");
+        myPig.registerQuery("store f1 into 'output1';");
+        myPig.registerQuery("g = cogroup d by $0, e by $0;");
+        myPig.registerQuery("g1 = foreach g generate group, COUNT(d), COUNT(e);");
+        myPig.registerQuery("store g1 into 'output2';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }            
     
     @Test
-    public void testMultiQueryJiraPig920_3() {
+    public void testMultiQueryJiraPig920_3() throws Exception {
 
         // test case: execution of a simple diamond query
         
         String INPUT_FILE = "pig-920.txt";
         
-        try {
-            
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("apple\tapple\t100\t10");
-            w.println("apple\tapple\t200\t20");
-            w.println("orange\torange\t100\t10");
-            w.println("orange\torange\t300\t20");
-   
-            w.close();
-            
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
-        
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load '" + INPUT_FILE +
-                                "' as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = filter a by uid < 300;");
-            myPig.registerQuery("c = filter a by gid > 10;");
-            myPig.registerQuery("d = cogroup c by $0, b by $0;");
-            myPig.registerQuery("e = foreach d generate group, COUNT(c), COUNT(b);");
-                                   
-            Iterator<Tuple> iter = myPig.openIterator("e");
-
-            List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
-                    new String[] { 
-                            "('apple',1L,2L)",
-                            "('orange',1L,1L)"
-                    });
-            
-            int counter = 0;
-            while (iter.hasNext()) {
-                assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());
-            }
-
-            assertEquals(expectedResults.size(), counter);
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
-            
+        String[] inputData = {
+            "apple\tapple\t100\t10",
+            "apple\tapple\t200\t20",
+            "orange\torange\t100\t10",
+            "orange\torange\t300\t20"  
+        };
+                        
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load '" + INPUT_FILE +
+                            "' as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = filter a by uid < 300;");
+        myPig.registerQuery("c = filter a by gid > 10;");
+        myPig.registerQuery("d = cogroup c by $0, b by $0;");
+        myPig.registerQuery("e = foreach d generate group, COUNT(c), COUNT(b);");
+                               
+        Iterator<Tuple> iter = myPig.openIterator("e");
+
+        List<Tuple> expectedResults = Util.getTuplesFromConstantTupleStrings(
+                new String[] { 
+                        "('apple',1L,2L)",
+                        "('orange',1L,1L)"
+                });
+        
+        int counter = 0;
+        while (iter.hasNext()) {
+            assertEquals(expectedResults.get(counter++).toString(), iter.next().toString());
         }
+
+        assertEquals(expectedResults.size(), counter);
     }        
 
     @Test
-    public void testMultiQueryJiraPig976() {
+    public void testMultiQueryJiraPig976() throws Exception {
 
         // test case: key ('group') isn't part of foreach output
         // and keys have the same type.
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = group a by uid;");
-            myPig.registerQuery("c = group a by gid;");
-            myPig.registerQuery("d = foreach b generate SUM(a.gid);");
-            myPig.registerQuery("e = foreach c generate group, COUNT(a);");
-            myPig.registerQuery("store d into '/tmp/output1';");
-            myPig.registerQuery("store e into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = group a by uid;");
+        myPig.registerQuery("c = group a by gid;");
+        myPig.registerQuery("d = foreach b generate SUM(a.gid);");
+        myPig.registerQuery("e = foreach c generate group, COUNT(a);");
+        myPig.registerQuery("store d into 'output1';");
+        myPig.registerQuery("store e into 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
 
     @Test
-    public void testMultiQueryJiraPig976_2() {
+    public void testMultiQueryJiraPig976_2() throws Exception {
 
         // test case: key ('group') isn't part of foreach output 
         // and keys have different types
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = group a by uname;");
-            myPig.registerQuery("c = group a by gid;");
-            myPig.registerQuery("d = foreach b generate SUM(a.gid);");
-            myPig.registerQuery("e = foreach c generate group, COUNT(a);");
-            myPig.registerQuery("store d into '/tmp/output1';");
-            myPig.registerQuery("store e into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = group a by uname;");
+        myPig.registerQuery("c = group a by gid;");
+        myPig.registerQuery("d = foreach b generate SUM(a.gid);");
+        myPig.registerQuery("e = foreach c generate group, COUNT(a);");
+        myPig.registerQuery("store d into 'output1';");
+        myPig.registerQuery("store e into 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
 
     @Test
-    public void testMultiQueryJiraPig976_3() {
+    public void testMultiQueryJiraPig976_3() throws Exception {
 
         // test case: group all and key ('group') isn't part of output
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = group a all;");
-            myPig.registerQuery("c = group a by gid;");
-            myPig.registerQuery("d = foreach b generate SUM(a.gid);");
-            myPig.registerQuery("e = foreach c generate group, COUNT(a);");
-            myPig.registerQuery("store d into '/tmp/output1';");
-            myPig.registerQuery("store e into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = group a all;");
+        myPig.registerQuery("c = group a by gid;");
+        myPig.registerQuery("d = foreach b generate SUM(a.gid);");
+        myPig.registerQuery("e = foreach c generate group, COUNT(a);");
+        myPig.registerQuery("store d into 'output1';");
+        myPig.registerQuery("store e into 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
 
     @Test
-    public void testMultiQueryJiraPig976_4() {
+    public void testMultiQueryJiraPig976_4() throws Exception {
 
         // test case: group by multi-cols and key ('group') isn't part of output
-         
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = group a by uid;");
-            myPig.registerQuery("c = group a by (uname, gid);");
-            myPig.registerQuery("d = foreach b generate SUM(a.gid);");
-            myPig.registerQuery("e = foreach c generate group.uname, group.gid, COUNT(a);");
-            myPig.registerQuery("store d into '/tmp/output1';");
-            myPig.registerQuery("store e into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+     
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = group a by uid;");
+        myPig.registerQuery("c = group a by (uname, gid);");
+        myPig.registerQuery("d = foreach b generate SUM(a.gid);");
+        myPig.registerQuery("e = foreach c generate group.uname, group.gid, COUNT(a);");
+        myPig.registerQuery("store d into 'output1';");
+        myPig.registerQuery("store e into 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
    
     @Test
-    public void testMultiQueryJiraPig976_5() {
+    public void testMultiQueryJiraPig976_5() throws Exception {
 
         // test case: key ('group') in multiple positions.
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = group a by uid;");
-            myPig.registerQuery("c = group a by (uname, gid);");
-            myPig.registerQuery("d = foreach b generate SUM(a.gid), group, group as foo;");
-            myPig.registerQuery("d1 = foreach d generate $1 + $2;");
-            myPig.registerQuery("e = foreach c generate group, COUNT(a);");
-            myPig.registerQuery("store d1 into '/tmp/output1';");
-            myPig.registerQuery("store e into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = group a by uid;");
+        myPig.registerQuery("c = group a by (uname, gid);");
+        myPig.registerQuery("d = foreach b generate SUM(a.gid), group, group as foo;");
+        myPig.registerQuery("d1 = foreach d generate $1 + $2;");
+        myPig.registerQuery("e = foreach c generate group, COUNT(a);");
+        myPig.registerQuery("store d1 into 'output1';");
+        myPig.registerQuery("store e into 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
     
     @Test
-    public void testMultiQueryJiraPig976_6() {
+    public void testMultiQueryJiraPig976_6() throws Exception {
 
         // test case: key ('group') has null values.
 
         String INPUT_FILE = "pig-976.txt";
         
-        try {
-            
-            PrintWriter w = new PrintWriter(new FileWriter(INPUT_FILE));
-            w.println("apple\tapple\t100\t10");
-            w.println("apple\tapple\t\t20");
-            w.println("orange\torange\t100\t10");
-            w.println("orange\torange\t\t20");
-            w.println("strawberry\tstrawberry\t300\t10");
-   
-            w.close();
-            
-            Util.copyFromLocalToCluster(cluster, INPUT_FILE, INPUT_FILE);
+        String[] inputData = {
+            "apple\tapple\t100\t10",
+            "apple\tapple\t\t20",
+            "orange\torange\t100\t10",
+            "orange\torange\t\t20",
+            "strawberry\tstrawberry\t300\t10"
+        };
+                            
+        Util.createLocalInputFile(INPUT_FILE, inputData);
+    
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load '" + INPUT_FILE +
+                            "' as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = group a by uid;");
+        myPig.registerQuery("c = group a by gid;");
+        myPig.registerQuery("d = foreach b generate group, SUM(a.gid);");
+        myPig.registerQuery("e = foreach c generate COUNT(a), group;");
+        myPig.registerQuery("store d into 'output1';");
+        myPig.registerQuery("store e into 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertTrue(jobs.size() == 2);
         
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load '" + INPUT_FILE +
-                                "' as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = group a by uid;");
-            myPig.registerQuery("c = group a by gid;");
-            myPig.registerQuery("d = foreach b generate group, SUM(a.gid);");
-            myPig.registerQuery("e = foreach c generate COUNT(a), group;");
-            myPig.registerQuery("store d into '/tmp/output1';");
-            myPig.registerQuery("store e into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertTrue(jobs.size() == 2);
-            
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } finally {
-            new File(INPUT_FILE).delete();
-            try {
-                Util.deleteFile(cluster, INPUT_FILE);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Assert.fail();
-            }
-            
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
         }
     }    
 
     @Test
-    public void testMultiQueryJiraPig983_2() {
+    public void testMultiQueryJiraPig983_2() throws Exception {
 
         System.out.println("===== multi-query Jira Pig-983_2 =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                 "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = filter a by uid < 5;");
-            myPig.registerQuery("c = filter a by uid >= 5;");
-            myPig.registerQuery("d = join b by uname, c by uname;");
-            myPig.registerQuery("e = group d by b::gid;");
-            myPig.registerQuery("e1 = foreach e generate group, COUNT(d.b::uid);");
-            myPig.registerQuery("store e1 into '/tmp/output1';");
-            myPig.registerQuery("f = group d by c::gid;");
-            myPig.registerQuery("f1 = foreach f generate group, SUM(d.c::uid);");
-            myPig.registerQuery("store f1 into '/tmp/output2';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-
-            assertTrue(jobs.size() == 2);
-            
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                             "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = filter a by uid < 5;");
+        myPig.registerQuery("c = filter a by uid >= 5;");
+        myPig.registerQuery("d = join b by uname, c by uname;");
+        myPig.registerQuery("e = group d by b::gid;");
+        myPig.registerQuery("e1 = foreach e generate group, COUNT(d.b::uid);");
+        myPig.registerQuery("store e1 into 'output1';");
+        myPig.registerQuery("f = group d by c::gid;");
+        myPig.registerQuery("f1 = foreach f generate group, SUM(d.c::uid);");
+        myPig.registerQuery("store f1 into 'output2';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+
+        assertTrue(jobs.size() == 2);
+        
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }     
 
     // --------------------------------------------------------------------------
     // Helper methods
 
-    private void deleteOutputFiles() {
-        try {
-            FileLocalizer.delete("/tmp/output1", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output2", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output3", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output4", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output5", myPig.getPigContext());
-        } catch (IOException e) {
-            e.printStackTrace();
-            Assert.fail();
-        }
+    private static void deleteOutputFiles() {
+        Util.deleteDirectory(new File("output1"));
+        Util.deleteDirectory(new File("output2"));
+        Util.deleteDirectory(new File("output3"));
+        Util.deleteDirectory(new File("output4"));
+        Util.deleteDirectory(new File("output5"));
     }
 }
diff --git a/test/org/apache/pig/test/TestMultiQueryBasic.java b/test/org/apache/pig/test/TestMultiQueryBasic.java
index ab67335a7..6dbc9a8fd 100644
--- a/test/org/apache/pig/test/TestMultiQueryBasic.java
+++ b/test/org/apache/pig/test/TestMultiQueryBasic.java
@@ -22,14 +22,12 @@ import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 import java.io.File;
-import java.io.FileWriter;
 import java.io.IOException;
-import java.io.PrintWriter;
-import java.io.StringReader;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
+import java.util.Properties;
 
 import junit.framework.Assert;
 
@@ -50,8 +48,7 @@ import org.apache.pig.StoreFunc;
 import org.apache.pig.backend.executionengine.ExecJob;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.impl.io.FileLocalizer;
-import org.apache.pig.tools.grunt.GruntParser;
+import org.apache.pig.impl.PigContext;
 import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Before;
@@ -59,452 +56,380 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
+
 @RunWith(JUnit4.class)
 public class TestMultiQueryBasic {
 
-    private static final MiniCluster cluster = MiniCluster.buildCluster();
-
-    private PigServer myPig;
+    private static PigServer myPig;
 
     @BeforeClass
-    public static void setUpBeforeClass() throws IOException {
-        Util.copyFromLocalToCluster(cluster,
+    public static void setUpBeforeClass() throws Exception {
+        Util.copyFromLocalToLocal(
                 "test/org/apache/pig/test/data/passwd", "passwd");
-        Util.copyFromLocalToCluster(cluster,
+        Util.copyFromLocalToLocal(
                 "test/org/apache/pig/test/data/passwd2", "passwd2");
+        Properties props = new Properties();
+        props.setProperty("opt.multiquery", ""+true);
+        myPig = new PigServer(ExecType.LOCAL, props);
     }
     
     @AfterClass
-    public static void tearDownAfterClass() throws IOException {
-        Util.deleteFile(cluster, "passwd");
-        Util.deleteFile(cluster, "passwd2");
-        cluster.shutDown();
+    public static void tearDownAfterClass() throws Exception {
+        Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), "passwd");
+        Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), "passwd2");
+        deleteOutputFiles();
     }
     
     @Before
     public void setUp() throws Exception {
-        cluster.setProperty("opt.multiquery", ""+true);
-        myPig = new PigServer(ExecType.MAPREDUCE, cluster.getProperties());
         deleteOutputFiles();
     }
 
     @After
     public void tearDown() throws Exception {
-        myPig = null;
+        
     }
     
  
     @Test
-    public void testMultiQueryWithTwoStores2() {
+    public void testMultiQueryWithTwoStores2() throws Exception {
 
         System.out.println("===== multi-query with 2 stores (2) =====");
 
-        try {
-            myPig.setBatchOn();
+        myPig.setBatchOn();
 
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
-            myPig.registerQuery("b = filter a by uid > 5;");
-            myPig.registerQuery("store b into '/tmp/output1';");
-            myPig.registerQuery("c = group b by gid;");
-            myPig.registerQuery("store c into '/tmp/output2';");
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
+        myPig.registerQuery("b = filter a by uid > 5;");
+        myPig.registerQuery("store b into 'output1';");
+        myPig.registerQuery("c = group b by gid;");
+        myPig.registerQuery("store c into 'output2';");
 
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertTrue(jobs.size() == 2);
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertTrue(jobs.size() == 2);
 
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
 
     @Test
-    public void testMultiQueryWithTwoLoads2() {
+    public void testMultiQueryWithTwoLoads2() throws Exception {
 
         System.out.println("===== multi-query with two loads (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
-            myPig.registerQuery("b = load 'passwd2' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
-            myPig.registerQuery("c = filter a by uid > 5;");
-            myPig.registerQuery("d = filter b by uid > 10;");
-            myPig.registerQuery("store c into '/tmp/output1';");
-            myPig.registerQuery("store d into '/tmp/output2';");
-            myPig.registerQuery("e = cogroup c by uid, d by uid;");
-            myPig.registerQuery("store e into '/tmp/output3';");
-
-            myPig.executeBatch();
-            myPig.discardBatch();
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
+        myPig.registerQuery("b = load 'passwd2' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
+        myPig.registerQuery("c = filter a by uid > 5;");
+        myPig.registerQuery("d = filter b by uid > 10;");
+        myPig.registerQuery("store c into 'output1';");
+        myPig.registerQuery("store d into 'output2';");
+        myPig.registerQuery("e = cogroup c by uid, d by uid;");
+        myPig.registerQuery("store e into 'output3';");
+
+        myPig.executeBatch();
+        myPig.discardBatch();
     }       
     
     @Test
-    public void testMultiQueryPhase3BaseCase2() {
+    public void testMultiQueryPhase3BaseCase2() throws Exception {
 
         System.out.println("===== multi-query phase 3 base case (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                 "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = filter a by uid < 5;");
-            myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
-            myPig.registerQuery("d = filter a by uid >= 10;");
-            myPig.registerQuery("b1 = group b by gid;");
-            myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid);");
-            myPig.registerQuery("b3 = filter b2 by $1 > 5;");
-            myPig.registerQuery("store b3 into '/tmp/output1';");
-            myPig.registerQuery("c1 = group c by gid;");
-            myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid);");
-            myPig.registerQuery("store c2 into '/tmp/output2';");
-            myPig.registerQuery("d1 = group d by gid;");
-            myPig.registerQuery("d2 = foreach d1 generate group, AVG(d.uid);");            
-            myPig.registerQuery("store d2 into '/tmp/output3';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-            
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                             "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = filter a by uid < 5;");
+        myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
+        myPig.registerQuery("d = filter a by uid >= 10;");
+        myPig.registerQuery("b1 = group b by gid;");
+        myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid);");
+        myPig.registerQuery("b3 = filter b2 by $1 > 5;");
+        myPig.registerQuery("store b3 into 'output1';");
+        myPig.registerQuery("c1 = group c by gid;");
+        myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid);");
+        myPig.registerQuery("store c2 into 'output2';");
+        myPig.registerQuery("d1 = group d by gid;");
+        myPig.registerQuery("d2 = foreach d1 generate group, AVG(d.uid);");            
+        myPig.registerQuery("store d2 into 'output3';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+        
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }         
     
     @Test
-    public void testMultiQueryPhase3WithoutCombiner2() {
+    public void testMultiQueryPhase3WithoutCombiner2() throws Exception {
 
         System.out.println("===== multi-query phase 3 without combiner (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                 "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = filter a by uid < 5;");
-            myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
-            myPig.registerQuery("d = filter a by uid >= 10;");
-            myPig.registerQuery("b1 = group b by gid;");
-            myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid) + SUM(b.uid);");
-            myPig.registerQuery("b3 = filter b2 by $1 > 5;");
-            myPig.registerQuery("store b3 into '/tmp/output1';");
-            myPig.registerQuery("c1 = group c by gid;");
-            myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid) - COUNT(c.uid);");
-            myPig.registerQuery("store c2 into '/tmp/output2';");
-            myPig.registerQuery("d1 = group d by gid;");           
-            myPig.registerQuery("d2 = foreach d1 generate group, MAX(d.uid) - MIN(d.uid);");
-            myPig.registerQuery("store d2 into '/tmp/output3';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-  
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                             "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = filter a by uid < 5;");
+        myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
+        myPig.registerQuery("d = filter a by uid >= 10;");
+        myPig.registerQuery("b1 = group b by gid;");
+        myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid) + SUM(b.uid);");
+        myPig.registerQuery("b3 = filter b2 by $1 > 5;");
+        myPig.registerQuery("store b3 into 'output1';");
+        myPig.registerQuery("c1 = group c by gid;");
+        myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid) - COUNT(c.uid);");
+        myPig.registerQuery("store c2 into 'output2';");
+        myPig.registerQuery("d1 = group d by gid;");           
+        myPig.registerQuery("d2 = foreach d1 generate group, MAX(d.uid) - MIN(d.uid);");
+        myPig.registerQuery("store d2 into 'output3';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }     
     
     @Test
-    public void testMultiQueryPhase3WithMixedCombiner2() {
+    public void testMultiQueryPhase3WithMixedCombiner2() throws Exception {
 
         System.out.println("===== multi-query phase 3 with mixed combiner (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                 "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = filter a by uid < 5;");
-            myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
-            myPig.registerQuery("d = filter a by uid >= 10;");
-            myPig.registerQuery("b1 = group b by gid;");
-            myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid);");
-            myPig.registerQuery("b3 = filter b2 by $1 > 5;");
-            myPig.registerQuery("store b3 into '/tmp/output1';");
-            myPig.registerQuery("c1 = group c by gid;");
-            myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid);");
-            myPig.registerQuery("store c2 into '/tmp/output2';");
-            myPig.registerQuery("d1 = group d by gid;");            
-            myPig.registerQuery("d2 = foreach d1 generate group, MAX(d.uid) - MIN(d.uid);");
-            myPig.registerQuery("store d2 into '/tmp/output3';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertEquals(3, jobs.size());
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                             "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = filter a by uid < 5;");
+        myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
+        myPig.registerQuery("d = filter a by uid >= 10;");
+        myPig.registerQuery("b1 = group b by gid;");
+        myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid);");
+        myPig.registerQuery("b3 = filter b2 by $1 > 5;");
+        myPig.registerQuery("store b3 into 'output1';");
+        myPig.registerQuery("c1 = group c by gid;");
+        myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid);");
+        myPig.registerQuery("store c2 into 'output2';");
+        myPig.registerQuery("d1 = group d by gid;");            
+        myPig.registerQuery("d2 = foreach d1 generate group, MAX(d.uid) - MIN(d.uid);");
+        myPig.registerQuery("store d2 into 'output3';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertEquals(3, jobs.size());
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }         
 
     @Test
-    public void testMultiQueryPhase3WithDifferentMapDataTypes2() {
+    public void testMultiQueryPhase3WithDifferentMapDataTypes2() throws Exception {
 
         System.out.println("===== multi-query phase 3 with different map datatypes (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                 "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = filter a by uid < 5;");
-            myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
-            myPig.registerQuery("d = filter a by uid >= 10;");
-            myPig.registerQuery("b1 = group b by gid;");
-            myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid);");
-            myPig.registerQuery("b3 = filter b2 by $1 > 5;");
-            myPig.registerQuery("store b3 into '/tmp/output1';");
-            myPig.registerQuery("c1 = group c by $1;");
-            myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid);");
-            myPig.registerQuery("store c2 into '/tmp/output2';");
-            myPig.registerQuery("d1 = group d by $1;");
-            myPig.registerQuery("d2 = foreach d1 generate group, COUNT(d.uid);");
-            myPig.registerQuery("store d2 into '/tmp/output3';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertEquals(3, jobs.size());
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                             "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = filter a by uid < 5;");
+        myPig.registerQuery("c = filter a by uid >= 5 and uid < 10;");
+        myPig.registerQuery("d = filter a by uid >= 10;");
+        myPig.registerQuery("b1 = group b by gid;");
+        myPig.registerQuery("b2 = foreach b1 generate group, COUNT(b.uid);");
+        myPig.registerQuery("b3 = filter b2 by $1 > 5;");
+        myPig.registerQuery("store b3 into 'output1';");
+        myPig.registerQuery("c1 = group c by $1;");
+        myPig.registerQuery("c2 = foreach c1 generate group, SUM(c.uid);");
+        myPig.registerQuery("store c2 into 'output2';");
+        myPig.registerQuery("d1 = group d by $1;");
+        myPig.registerQuery("d2 = foreach d1 generate group, COUNT(d.uid);");
+        myPig.registerQuery("store d2 into 'output3';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertEquals(3, jobs.size());
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }         
     
     @Test
-    public void testMultiQueryPhase3WithDifferentMapDataTypes3() {
+    public void testMultiQueryPhase3WithDifferentMapDataTypes3() throws Exception {
 
         System.out.println("===== multi-query phase 3 with different map datatypes (3) =====");
 
-        try {
-            myPig.setBatchOn();
-            String[] inputData = {"john\t20\t3.4",
-            		"john\t25\t3.4" ,
-            		"henry\t23\t3.9" ,
-            		"adam\t54\t2.9" ,
-            		"henry\t21\t3.9"};
-            Util.createInputFile(cluster, "queryInput.txt", inputData);
-
-            myPig.registerQuery("a = load 'queryInput.txt' " +
-                                 "as (name:chararray, age:int, gpa:double);");
-            myPig.registerQuery("b = group a all;");
-            myPig.registerQuery("c = foreach b generate group, COUNT(a);");
-            myPig.registerQuery("store c into 'foo';");
-            myPig.registerQuery("d = group a by (name, gpa);");
-            myPig.registerQuery("e = foreach d generate flatten(group), MIN(a.age);");
-            myPig.registerQuery("store e into 'bar';");
-             
-            myPig.executeBatch();
-            
-            myPig.registerQuery("a = load 'foo' as (grp:chararray, cnt:long) ;");
-            Iterator<Tuple> it = myPig.openIterator("a");
-            assertEquals(Util.getPigConstant("('all', 5l)"), it.next());
-            assertFalse(it.hasNext());
-            
-            myPig.registerQuery("a = load 'bar' as (name:chararray, gpa:double, age:int);");
-            it = myPig.openIterator("a");
-            int i = 0;
-            Map<String, Tuple> expectedResults = new HashMap<String, Tuple>();
-            expectedResults.put("john", (Tuple) Util.getPigConstant("('john',3.4,20)"));
-            expectedResults.put("adam", (Tuple) Util.getPigConstant("('adam',2.9,54)"));
-            expectedResults.put("henry", (Tuple) Util.getPigConstant("('henry',3.9,21)"));
-            while(it.hasNext()) {
-                Tuple t = it.next();
-                i++;
-                assertEquals(expectedResults.get(t.get(0)), t);
-            }
-            assertEquals(3, i);
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+        String[] inputData = {"john\t20\t3.4",
+        		"john\t25\t3.4" ,
+        		"henry\t23\t3.9" ,
+        		"adam\t54\t2.9" ,
+        		"henry\t21\t3.9"};
+        Util.createLocalInputFile("queryInput.txt", inputData);
+
+        myPig.registerQuery("a = load 'queryInput.txt' " +
+                             "as (name:chararray, age:int, gpa:double);");
+        myPig.registerQuery("b = group a all;");
+        myPig.registerQuery("c = foreach b generate group, COUNT(a);");
+        myPig.registerQuery("store c into 'output1';");
+        myPig.registerQuery("d = group a by (name, gpa);");
+        myPig.registerQuery("e = foreach d generate flatten(group), MIN(a.age);");
+        myPig.registerQuery("store e into 'output2';");
+         
+        myPig.executeBatch();
+        
+        myPig.registerQuery("a = load 'output1' as (grp:chararray, cnt:long) ;");
+        Iterator<Tuple> it = myPig.openIterator("a");
+        assertEquals(Util.getPigConstant("('all', 5l)"), it.next());
+        assertFalse(it.hasNext());
+        
+        myPig.registerQuery("a = load 'output2' as (name:chararray, gpa:double, age:int);");
+        it = myPig.openIterator("a");
+        int i = 0;
+        Map<String, Tuple> expectedResults = new HashMap<String, Tuple>();
+        expectedResults.put("john", (Tuple) Util.getPigConstant("('john',3.4,20)"));
+        expectedResults.put("adam", (Tuple) Util.getPigConstant("('adam',2.9,54)"));
+        expectedResults.put("henry", (Tuple) Util.getPigConstant("('henry',3.9,21)"));
+        while(it.hasNext()) {
+            Tuple t = it.next();
+            i++;
+            assertEquals(expectedResults.get(t.get(0)), t);
+        }
+        assertEquals(3, i);
     }         
  
     @Test
-    public void testMultiQueryPhase3StreamingInReducer2() {
+    public void testMultiQueryPhase3StreamingInReducer2() throws Exception {
 
         System.out.println("===== multi-query phase 3 with streaming in reducer (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("A = load 'passwd';");
-            myPig.registerQuery("Split A into A1 if $2 > 5, A2 if $2 >= 5;");
-            myPig.registerQuery("Split A1 into A3 if $0 > 'm', A4 if $0 >= 'm';");
-            myPig.registerQuery("B = group A3 by $2;");
-            myPig.registerQuery("C = foreach B generate flatten(A3);");
-            myPig.registerQuery("D = stream B through `cat`;");
-            myPig.registerQuery("store D into '/tmp/output1';");
-            myPig.registerQuery("E = group A4 by $2;");
-            myPig.registerQuery("F = foreach E generate group, COUNT(A4);");
-            myPig.registerQuery("store F into '/tmp/output2';");            
-            myPig.registerQuery("G = group A1 by $2;");
-            myPig.registerQuery("H = foreach G generate group, COUNT(A1);");          
-            myPig.registerQuery("store H into '/tmp/output3';");
-             
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertEquals(3, jobs.size());
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("A = load 'passwd';");
+        myPig.registerQuery("Split A into A1 if $2 > 5, A2 if $2 >= 5;");
+        myPig.registerQuery("Split A1 into A3 if $0 > 'm', A4 if $0 >= 'm';");
+        myPig.registerQuery("B = group A3 by $2;");
+        myPig.registerQuery("C = foreach B generate flatten(A3);");
+        myPig.registerQuery("D = stream B through `cat`;");
+        myPig.registerQuery("store D into 'output1';");
+        myPig.registerQuery("E = group A4 by $2;");
+        myPig.registerQuery("F = foreach E generate group, COUNT(A4);");
+        myPig.registerQuery("store F into 'output2';");            
+        myPig.registerQuery("G = group A1 by $2;");
+        myPig.registerQuery("H = foreach G generate group, COUNT(A1);");          
+        myPig.registerQuery("store H into 'output3';");
+         
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertEquals(3, jobs.size());
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }       
     
     @Test
-    public void testMultiQueryWithPigMixL12_2() {
+    public void testMultiQueryWithPigMixL12_2() throws Exception {
 
         System.out.println("===== multi-query with PigMix L12 (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname, passwd, uid, gid);");
-            myPig.registerQuery("b = foreach a generate uname, passwd, uid, gid;");
-            myPig.registerQuery("split b into c1 if uid > 5, c2 if uid <= 5 ;"); 
-            myPig.registerQuery("split c1 into d1 if gid < 5, d2 if gid >= 5;");
-            myPig.registerQuery("e = group d1 by uname;");
-            myPig.registerQuery("e1 = foreach e generate group, MAX(d1.uid);");
-            myPig.registerQuery("store e1 into '/tmp/output1';");
-            myPig.registerQuery("f = group c2 by uname;");
-            myPig.registerQuery("f1 = foreach f generate group, SUM(c2.gid);");
-            myPig.registerQuery("store f1 into '/tmp/output2';");
-            myPig.registerQuery("g = group d2 by uname;");
-            myPig.registerQuery("g1 = foreach g generate group, COUNT(d2);");
-            myPig.registerQuery("store g1 into '/tmp/output3';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertEquals(3, jobs.size());
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-            
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname, passwd, uid, gid);");
+        myPig.registerQuery("b = foreach a generate uname, passwd, uid, gid;");
+        myPig.registerQuery("split b into c1 if uid > 5, c2 if uid <= 5 ;"); 
+        myPig.registerQuery("split c1 into d1 if gid < 5, d2 if gid >= 5;");
+        myPig.registerQuery("e = group d1 by uname;");
+        myPig.registerQuery("e1 = foreach e generate group, MAX(d1.uid);");
+        myPig.registerQuery("store e1 into 'output1';");
+        myPig.registerQuery("f = group c2 by uname;");
+        myPig.registerQuery("f1 = foreach f generate group, SUM(c2.gid);");
+        myPig.registerQuery("store f1 into 'output2';");
+        myPig.registerQuery("g = group d2 by uname;");
+        myPig.registerQuery("g1 = foreach g generate group, COUNT(d2);");
+        myPig.registerQuery("store g1 into 'output3';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertEquals(3, jobs.size());
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
     
     @Test
-    public void testMultiQueryWithCoGroup_2() {
+    public void testMultiQueryWithCoGroup_2() throws Exception {
 
         System.out.println("===== multi-query with CoGroup (2) =====");
+        
+        myPig.setBatchOn();
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname, passwd, uid, gid);");
-            myPig.registerQuery("store a into '/tmp/output1' using BinStorage();");
-            myPig.registerQuery("b = load '/tmp/output1' using BinStorage() as (uname, passwd, uid, gid);"); 
-            myPig.registerQuery("c = load 'passwd2' " +
-                                "using PigStorage(':') as (uname, passwd, uid, gid);");
-            myPig.registerQuery("d = cogroup b by (uname, uid) inner, c by (uname, uid) inner;");
-            myPig.registerQuery("e = foreach d generate flatten(b), flatten(c);");
-            myPig.registerQuery("store e into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertTrue(jobs.size() == 2);
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname, passwd, uid, gid);");
+        myPig.registerQuery("store a into 'output1' using BinStorage();");
+        myPig.registerQuery("b = load 'output1' using BinStorage() as (uname, passwd, uid, gid);"); 
+        myPig.registerQuery("c = load 'passwd2' " +
+                            "using PigStorage(':') as (uname, passwd, uid, gid);");
+        myPig.registerQuery("d = cogroup b by (uname, uid) inner, c by (uname, uid) inner;");
+        myPig.registerQuery("e = foreach d generate flatten(b), flatten(c);");
+        myPig.registerQuery("store e into 'output2';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertTrue(jobs.size() == 2);
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }
  
     @Test
-    public void testMultiQueryWithFJ_2() {
+    public void testMultiQueryWithFJ_2() throws Exception {
 
         System.out.println("===== multi-query with FJ (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("b = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("c = filter a by uid > 5;");
-            myPig.registerQuery("store c into '/tmp/output1';");
-            myPig.registerQuery("d = filter b by gid > 10;");
-            myPig.registerQuery("store d into '/tmp/output2';");
-            myPig.registerQuery("e = join c by gid, d by gid using \'repl\';");
-            myPig.registerQuery("store e into '/tmp/output3';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertEquals(3, jobs.size());
-
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
+        myPig.setBatchOn();
 
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("b = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("c = filter a by uid > 5;");
+        myPig.registerQuery("store c into 'output1';");
+        myPig.registerQuery("d = filter b by gid > 10;");
+        myPig.registerQuery("store d into 'output2';");
+        myPig.registerQuery("e = join c by gid, d by gid using \'repl\';");
+        myPig.registerQuery("store e into 'output3';");
+
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertEquals(3, jobs.size());
+
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     } 
  
     @Test
-    public void testMultiQueryWithIntermediateStores_2() {
+    public void testMultiQueryWithIntermediateStores_2() throws Exception {
 
         System.out.println("===== multi-query with intermediate stores (2) =====");
 
-        try {
-            
-            myPig.setBatchOn();
-            
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
-            myPig.registerQuery("store a into '/tmp/output1';");
-            myPig.registerQuery("b = load '/tmp/output1' using PigStorage(':'); ");
-            myPig.registerQuery("store b into '/tmp/output2';");
-
-            List<ExecJob> jobs = myPig.executeBatch();
-            assertTrue(jobs.size() == 2);
+        myPig.setBatchOn();
+        
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int, gid:int);");
+        myPig.registerQuery("store a into 'output1';");
+        myPig.registerQuery("b = load 'output1' using PigStorage(':'); ");
+        myPig.registerQuery("store b into 'output2';");
 
-            for (ExecJob job : jobs) {
-                assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
-            }
+        List<ExecJob> jobs = myPig.executeBatch();
+        assertTrue(jobs.size() == 2);
 
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        for (ExecJob job : jobs) {
+            assertTrue(job.getStatus() == ExecJob.JOB_STATUS.COMPLETED);
+        }
     }         
 
     @Test
@@ -513,7 +438,7 @@ public class TestMultiQueryBasic {
         // clean up any existing dirs/files
         String[] toClean = {"tmwsimam-input.txt", "foo1", "foo2", "foo3", "foo4" };
         for (int j = 0; j < toClean.length; j++) {
-            Util.deleteFile(cluster, toClean[j]);    
+            Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), toClean[j]);    
         }
         
         // the data below is tab delimited
@@ -522,7 +447,7 @@ public class TestMultiQueryBasic {
         "2	a	b	e	f	i	j	m	n",
         "3	c	d	g	h	k	l	o	p",
         "4	c	d	g	h	k	l	o	p" };
-        Util.createInputFile(cluster, "tmwsimam-input.txt", inputData);
+        Util.createLocalInputFile("tmwsimam-input.txt", inputData);
         String query = 
         "A = LOAD 'tmwsimam-input.txt' " +
         "as (f0:chararray, f1:chararray, f2:chararray, f3:chararray, " +
@@ -579,61 +504,49 @@ public class TestMultiQueryBasic {
         }
         // cleanup
         for (int j = 0; j < toClean.length; j++) {
-            Util.deleteFile(cluster, toClean[j]);    
+            Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), toClean[j]);    
         }
         
     }
        
     @Test
-    public void testMultiQueryWithTwoStores2Execs() {
+    public void testMultiQueryWithTwoStores2Execs() throws Exception {
 
         System.out.println("===== multi-query with 2 stores execs =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
-            myPig.registerQuery("b = filter a by uid > 5;");
-            myPig.executeBatch();
-            myPig.registerQuery("store b into '/tmp/output1';");
-            myPig.executeBatch();
-            myPig.registerQuery("c = group b by gid;");
-            myPig.registerQuery("store c into '/tmp/output2';");
-
-            myPig.executeBatch();
-            myPig.discardBatch();
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
+        myPig.registerQuery("b = filter a by uid > 5;");
+        myPig.executeBatch();
+        myPig.registerQuery("store b into 'output1';");
+        myPig.executeBatch();
+        myPig.registerQuery("c = group b by gid;");
+        myPig.registerQuery("store c into 'output2';");
+
+        myPig.executeBatch();
+        myPig.discardBatch();
     }
 
     @Test
-    public void testMultiQueryWithThreeStores2() {
+    public void testMultiQueryWithThreeStores2() throws Exception {
 
         System.out.println("===== multi-query with 3 stores (2) =====");
 
-        try {
-            myPig.setBatchOn();
-
-            myPig.registerQuery("a = load 'passwd' " +
-                                "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
-            myPig.registerQuery("b = filter a by uid > 5;");
-            myPig.registerQuery("store b into '/tmp/output1';");
-            myPig.registerQuery("c = filter b by uid > 10;");
-            myPig.registerQuery("store c into '/tmp/output2';");
-            myPig.registerQuery("d = filter c by uid > 15;");
-            myPig.registerQuery("store d into '/tmp/output3';");
-
-            myPig.executeBatch();
-            myPig.discardBatch();
-
-        } catch (Exception e) {
-            e.printStackTrace();
-            Assert.fail();
-        } 
+        myPig.setBatchOn();
+
+        myPig.registerQuery("a = load 'passwd' " +
+                            "using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);");
+        myPig.registerQuery("b = filter a by uid > 5;");
+        myPig.registerQuery("store b into 'output1';");
+        myPig.registerQuery("c = filter b by uid > 10;");
+        myPig.registerQuery("store c into 'output2';");
+        myPig.registerQuery("d = filter c by uid > 15;");
+        myPig.registerQuery("store d into 'output3';");
+
+        myPig.executeBatch();
+        myPig.discardBatch();
     }
  
     /**
@@ -644,7 +557,7 @@ public class TestMultiQueryBasic {
      */
     @Test
     public void testMultiStoreWithOutputFormat() throws IOException {
-        Util.createInputFile(cluster, "input.txt", new String[] {"hello", "bye"});
+        Util.createLocalInputFile("input.txt", new String[] {"hello", "bye"});
         String query = "a = load 'input.txt';" +
         		"b = filter a by $0 < 10;" +
         		"store b into 'output1' using "+DUMMY_STORE_WITH_OUTPUTFORMAT_CLASS+"();" +
@@ -657,12 +570,12 @@ public class TestMultiQueryBasic {
         
         // check that files were created as a result of the
         // checkOutputSpecs() method of the OutputFormat being called
-        FileSystem fs = cluster.getFileSystem();
+        FileSystem fs = FileSystem.getLocal(new Configuration());
         assertEquals(true, fs.exists(new Path("output1_checkOutputSpec_test")));
         assertEquals(true, fs.exists(new Path("output2_checkOutputSpec_test")));
-        Util.deleteFile(cluster, "input.txt");
-        Util.deleteFile(cluster, "output1_checkOutputSpec_test");
-        Util.deleteFile(cluster, "output2_checkOutputSpec_test");
+ 
+        Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), "output1_checkOutputSpec_test");
+        Util.deleteFile(new PigContext(ExecType.LOCAL, new Properties()), "output2_checkOutputSpec_test");
     }
         
     private static final String DUMMY_STORE_WITH_OUTPUTFORMAT_CLASS
@@ -749,16 +662,11 @@ public class TestMultiQueryBasic {
     // --------------------------------------------------------------------------
     // Helper methods
 
-    private void deleteOutputFiles() {
-        try {
-            FileLocalizer.delete("/tmp/output1", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output2", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output3", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output4", myPig.getPigContext());
-            FileLocalizer.delete("/tmp/output5", myPig.getPigContext());
-        } catch (IOException e) {
-            e.printStackTrace();
-            Assert.fail();
-        }
+    private static void deleteOutputFiles() {
+        Util.deleteDirectory(new File("output1"));
+        Util.deleteDirectory(new File("output2"));
+        Util.deleteDirectory(new File("output3"));
+        Util.deleteDirectory(new File("output4"));
+        Util.deleteDirectory(new File("output5"));
     }
 }
diff --git a/test/org/apache/pig/test/Util.java b/test/org/apache/pig/test/Util.java
index f979163b2..0c593d0b1 100644
--- a/test/org/apache/pig/test/Util.java
+++ b/test/org/apache/pig/test/Util.java
@@ -43,6 +43,7 @@ import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
+import java.util.Properties;
 
 import junit.framework.Assert;
 
@@ -533,6 +534,24 @@ public class Util {
         }
 	}
 	
+    static public void copyFromLocalToLocal(String fromLocalFileName,
+            String toLocalFileName) throws IOException {
+        PigServer ps = new PigServer(ExecType.LOCAL, new Properties());
+        String script = "fs -cp " + fromLocalFileName + " " + toLocalFileName;
+
+        new File(toLocalFileName).deleteOnExit();
+        
+        GruntParser parser = new GruntParser(new StringReader(script));
+        parser.setInteractive(false);
+        parser.setParams(ps);
+        try {
+            parser.parseStopOnError();
+        } catch (org.apache.pig.tools.pigscript.parser.ParseException e) {
+            throw new IOException(e);
+        }
+        
+    }
+	
 	static public void copyFromClusterToLocal(MiniCluster cluster, String fileNameOnCluster, String localFileName) throws IOException {
 	    PrintWriter writer = new PrintWriter(new FileWriter(localFileName));
 	    
