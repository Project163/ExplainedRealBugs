diff --git a/CHANGES.txt b/CHANGES.txt
index dc35ff91d..c8d7e8838 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -118,6 +118,8 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by
 
 BUG FIXES
 
+PIG-1931: Integrate Macro Expansion with New Parser (rding)
+
 PIG-1933: Hints such as 'collected' and 'skewed' for "group by" or "join by" 
  should not be treated as tokens. (xuefuz via thejas)
 
diff --git a/build.xml b/build.xml
index 46dec6bbe..13eea6c74 100644
--- a/build.xml
+++ b/build.xml
@@ -314,7 +314,7 @@
 	    description="generates token parser class from an ANTLR grammar">
 	    <java classname="org.antlr.Tool"
 	      classpathref="classpath" fork="true">
-		      <arg line="-o ${src.gen.dir}/${grammar.package.dir} ${src.dir}/${grammar.package.dir}/MacroExpansion.g ${src.dir}/${grammar.package.dir}/MacroRecursion.g ${src.dir}/${grammar.package.dir}/MacroImport.g ${src.dir}/${grammar.package.dir}/${grammar.name}Parser.g"/>
+		      <arg line="-o ${src.gen.dir}/${grammar.package.dir} ${src.dir}/${grammar.package.dir}/${grammar.name}Parser.g"/>
 	    </java>
 	  </target>
 	
@@ -323,7 +323,7 @@
 	    description="generates tree parser class from an ANTLR grammar">
 	    <java classname="org.antlr.Tool"
 	      classpathref="classpath" fork="true">
-	      <arg line="-o ${src.gen.dir}/${grammar.package.dir} ${src.dir}/${grammar.package.dir}/AliasMasker.g ${src.dir}/${grammar.package.dir}/AstValidator.g ${src.dir}/${grammar.package.dir}/LogicalPlanGenerator.g"/>
+	      <arg line="-o ${src.gen.dir}/${grammar.package.dir} ${src.dir}/${grammar.package.dir}/AstPrinter.g ${src.dir}/${grammar.package.dir}/AliasMasker.g ${src.dir}/${grammar.package.dir}/AstValidator.g ${src.dir}/${grammar.package.dir}/LogicalPlanGenerator.g"/>
 	    </java>
 	  </target>
 
diff --git a/src/org/apache/pig/Main.java b/src/org/apache/pig/Main.java
index 1c20a4430..0dce49258 100644
--- a/src/org/apache/pig/Main.java
+++ b/src/org/apache/pig/Main.java
@@ -35,6 +35,7 @@ import java.util.AbstractList;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Date;
+import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -66,7 +67,6 @@ import org.apache.pig.impl.util.ObjectSerializer;
 import org.apache.pig.impl.util.PropertiesUtil;
 import org.apache.pig.impl.util.UDFContext;
 import org.apache.pig.parser.QueryParserDriver;
-import org.apache.pig.parser.ParserUtil;
 import org.apache.pig.scripting.ScriptEngine;
 import org.apache.pig.scripting.ScriptEngine.SupportedScriptLang;
 import org.apache.pig.tools.cmdline.CmdLineParser;
@@ -370,6 +370,8 @@ static int run(String args[], PigProgressNotificationListener listener) {
                 properties.setProperty("pig.jars.relative.to.dfs", "true");
             }            
             
+            scriptState.setFileName(file);
+            
             if (embedded) {
                 return runEmbeddedScript(pigContext, localFileRet.file.getPath(), engine);
             } else {
@@ -379,18 +381,28 @@ static int run(String args[], PigProgressNotificationListener listener) {
                                 .getPath(), type.name().toLowerCase());
                 }
             }
-                     
-            // run macro expansion
-            FileReader fr = new FileReader(localFileRet.file);            
-            in = ParserUtil.getExpandedMacroAsBufferedReader(fr);
                         
+            in = new BufferedReader(new FileReader(localFileRet.file));
+            
             // run parameter substitution preprocessor first
             substFile = file + ".substituted";
-            pin = runParamPreprocessor(properties, in, params, paramFiles, substFile, debug || dryrun || checkScriptOnly);
+                pin = runParamPreprocessor(properties, in, params, paramFiles,
+                        substFile, debug || dryrun || checkScriptOnly);
             if (dryrun) {
-                log.info("Dry run completed. Substituted pig script is at " + substFile);
+                QueryParserDriver driver = new QueryParserDriver(
+                        pigContext, "0", new HashMap<String, String>());
+                if (driver.dryrun(substFile)) {
+                    log.info("Dry run completed. Substituted pig script is at "
+                            + substFile
+                            + ". Expanded pig script is at "
+                            + file + ".expanded");
+                } else {
+                    log.info("Dry run completed. Substituted pig script is at "
+                                + substFile);
+                }
                 return ReturnCode.SUCCESS;
             }
+            
 
             logFileName = validateLogFile(logFileName, file);
             pigContext.getProperties().setProperty("pig.logfile", logFileName);
@@ -439,9 +451,7 @@ static int run(String args[], PigProgressNotificationListener listener) {
             
             scriptState.setScript(sb.toString());
             
-            // run macro expansion
-            StringReader sr = new StringReader(sb.toString());           
-            in = ParserUtil.getExpandedMacroAsBufferedReader(sr);
+            in = new BufferedReader(new StringReader(sb.toString()));
             
             grunt = new Grunt(in, pigContext);
             gruntCalled = true;
@@ -490,6 +500,8 @@ static int run(String args[], PigProgressNotificationListener listener) {
                 properties.setProperty("pig.jars.relative.to.dfs", "true");
             }            
 
+            scriptState.setFileName(remainders[0]);
+            
             if (embedded) {
                 return runEmbeddedScript(pigContext, localFileRet.file.getPath(), engine);
             } else {
@@ -499,16 +511,24 @@ static int run(String args[], PigProgressNotificationListener listener) {
                                 .getPath(), type.name().toLowerCase());
                 }
             }
-                       
-            // run macro expansion
-            FileReader fr = new FileReader(localFileRet.file);            
-            in = ParserUtil.getExpandedMacroAsBufferedReader(fr);
+            
+            in = new BufferedReader(new FileReader(localFileRet.file));
             
             // run parameter substitution preprocessor first
             substFile = remainders[0] + ".substituted";
             pin = runParamPreprocessor(properties, in, params, paramFiles, substFile, debug || dryrun || checkScriptOnly);
-            if (dryrun){
-                log.info("Dry run completed. Substituted pig script is at " + substFile);
+            if (dryrun) {
+                QueryParserDriver driver = new QueryParserDriver(
+                        pigContext, "0", new HashMap<String, String>());
+                if (driver.dryrun(substFile)) {
+                    log.info("Dry run completed. Substituted pig script is at "
+                            + substFile
+                            + ". Expanded pig script is at "
+                            + remainders[0] + ".expanded");
+                } else {
+                    log.info("Dry run completed. Substituted pig script is at "
+                            + substFile);
+                }
                 return ReturnCode.SUCCESS;
             }
             
diff --git a/src/org/apache/pig/parser/AliasMasker.g b/src/org/apache/pig/parser/AliasMasker.g
index 38c4f4160..e53d48199 100644
--- a/src/org/apache/pig/parser/AliasMasker.g
+++ b/src/org/apache/pig/parser/AliasMasker.g
@@ -37,36 +37,16 @@ package org.apache.pig.parser;
 
 import java.util.HashSet;
 import java.util.Set;
-
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
 }
 
 @members {
 
-private static Log log = LogFactory.getLog( AliasMasker.class );
-
-public String getErrorMessage(RecognitionException e, String[] tokenNames) {
-    String msg = e.getMessage();
-    if ( e instanceof DuplicatedSchemaAliasException ) { 
-        DuplicatedSchemaAliasException dae = (DuplicatedSchemaAliasException)e;
-        msg = "Duplicated schema alias name '"+ dae.getAlias() + "' in the schema definition";
-    } else if( e instanceof UndefinedAliasException ) { 
-        UndefinedAliasException dae = (UndefinedAliasException)e;
-        msg = "Alias '"+ dae.getAlias() + "' is not defined";
-    }   
-    
-    return msg;
-}
-
 public void setParams(Set ps, String macro, long idx) {
     params = ps; 
     macroName = macro;
     index = idx;
 }
 
-public String getResult() { return sb.toString(); }
-
 private String getMask(String alias) {
     return params.contains( alias ) 
         ? alias 
@@ -81,8 +61,6 @@ private String macroName = "";
 
 private long index = 0;
 
-private StringBuilder sb = new StringBuilder();
-
 } // End of @members
 
 @rulecatch {
@@ -95,7 +73,7 @@ query : ^( QUERY statement* )
 ;
 
 statement : general_statement
-          | split_statement { sb.append(";\n"); }
+          | split_statement
 ;
 
 split_statement : split_clause
@@ -103,16 +81,20 @@ split_statement : split_clause
 
 // For foreach statement that with complex inner plan.
 general_statement 
-    : ^( STATEMENT ( alias { sb.append(" = "); } )? 
-        op_clause parallel_clause? ) { sb.append(";\n"); }
+    : ^( STATEMENT ( alias )? 
+        op_clause parallel_clause? ) 
 ;
 
 parallel_clause 
-    : ^( PARALLEL INTEGER ) { sb.append(" ").append($PARALLEL.text).append(" ").append($INTEGER.text); }
+    : ^( PARALLEL INTEGER ) 
 ;
 
 alias 
-    : IDENTIFIER { sb.append(getMask($IDENTIFIER.text)); aliasSeen.add($IDENTIFIER.text); }
+    : IDENTIFIER 
+        { 
+            aliasSeen.add($IDENTIFIER.text); 
+            $IDENTIFIER.getToken().setText(getMask($IDENTIFIER.text)); 
+        }
 ;
 
 op_clause : define_clause 
@@ -134,81 +116,69 @@ op_clause : define_clause
 ;
 
 define_clause 
-    : ^( DEFINE IDENTIFIER { sb.append($DEFINE.text).append(" ").append($IDENTIFIER.text).append(" "); } 
-        ( cmd | func_clause ) )
+    : ^( DEFINE alias  ( cmd | func_clause ) )
 ;
 
 cmd 
-    : ^( EXECCOMMAND { sb.append($EXECCOMMAND.text); }
+    : ^( EXECCOMMAND 
         ( ship_clause | cache_caluse | input_clause | output_clause | error_clause )* )
 ;
 
 ship_clause 
-    : ^( SHIP { sb.append(" ").append($SHIP.text).append(" ("); } path_list? { sb.append(")"); } )
+    : ^( SHIP path_list? )
 ;
 
 path_list 
-    : a=QUOTEDSTRING { sb.append(" ").append($a.text); }
-        (b=QUOTEDSTRING { sb.append(", ").append($b.text); } )*
+    : QUOTEDSTRING+ 
 ;
 
 cache_caluse 
-    : ^( CACHE { sb.append(" ").append($CACHE.text).append(" ("); } path_list { sb.append(")"); } )
+    : ^( CACHE path_list )
 ;
 
 input_clause 
-    : ^( INPUT { sb.append(" ").append($INPUT.text).append("("); } 
-        stream_cmd ( { sb.append(", "); } stream_cmd)* { sb.append(")"); } )
+    : ^( INPUT stream_cmd+ )
 ;
 
 stream_cmd 
-    : ^( STDIN { sb.append($STDIN.text).append(" USING "); } func_clause? )
-    | ^( STDOUT { sb.append($STDOUT.text).append(" USING "); } func_clause? )
-    | ^( QUOTEDSTRING { sb.append($QUOTEDSTRING.text).append(" USING "); } func_clause? )
+    : ^( STDIN func_clause? )
+    | ^( STDOUT func_clause? )
+    | ^( QUOTEDSTRING func_clause? )
 ;
 
 output_clause 
-    : ^( OUTPUT  { sb.append(" ").append($OUTPUT.text).append(" ("); } 
-        stream_cmd ( { sb.append(","); } stream_cmd)* { sb.append(")"); } )
+    : ^( OUTPUT stream_cmd+ )
 ;
 
 error_clause 
-    : ^( STDERROR { sb.append(" ").append($STDERROR.text).append(" ("); }
-        ( QUOTEDSTRING { sb.append($QUOTEDSTRING.text); } (INTEGER { sb.append(" LIMIT ").append($INTEGER); } )? )? { sb.append(")"); } )
+    : ^( STDERROR ( QUOTEDSTRING INTEGER? )? )
 ;
 
 load_clause 
-    : ^( LOAD { sb.append($LOAD.text).append(" "); } filename 
-        ( { sb.append(" USING "); } func_clause)? as_clause? )
+    : ^( LOAD filename func_clause? as_clause? )
 ;
 
 filename 
-    : QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
+    : QUOTEDSTRING 
 ;
 
 as_clause
-    : ^( AS { sb.append(" ").append($AS.text).append(" "); } field_def_list )
+    : ^( AS field_def_list )
 ;
 
 field_def
-    : ^( FIELD_DEF IDENTIFIER { sb.append($IDENTIFIER.text); }  ( {sb.append(":"); }  type)? )
+    : ^( FIELD_DEF IDENTIFIER type? )
 ;
 
 field_def_list
-    : { sb.append("("); } field_def ( { sb.append(", "); } field_def )+ { sb.append(")"); }
-    | field_def
+    : field_def+ 
 ;
 
 type : simple_type | tuple_type | bag_type | map_type
 ;
 
 simple_type 
-    : INT { sb.append($INT.text); }
-    | LONG { sb.append($LONG.text); }
-    | FLOAT { sb.append($FLOAT.text); }
-    | DOUBLE { sb.append($DOUBLE.text); }
-    | CHARARRAY { sb.append($CHARARRAY.text); }
-    | BYTEARRAY { sb.append($BYTEARRAY.text); }
+    : INT | LONG | FLOAT | DOUBLE | CHARARRAY | BYTEARRAY 
 ;
 
 tuple_type 
@@ -216,94 +186,85 @@ tuple_type
 ;
 
 bag_type 
-    : ^( BAG_TYPE { sb.append("bag{"); } ( { sb.append("T:"); } tuple_type )? ) { sb.append("}"); } 
+    : ^( BAG_TYPE tuple_type? )  
 ;
 
-map_type : ^( MAP_TYPE { sb.append("map["); } type? ) { sb.append("]"); }
+map_type : ^( MAP_TYPE type? )
 ;
 
 func_clause 
     : ^( FUNC_REF func_name )
-    | ^( FUNC func_name { sb.append("("); } func_args? { sb.append(")"); } )
+    | ^( FUNC func_name func_args? )
 ;
 
 func_name 
-    : eid ( ( PERIOD { sb.append($PERIOD.text); } | DOLLAR { sb.append($DOLLAR.text); } ) eid )*
+    : eid ( ( PERIOD | DOLLAR ) eid )*
 ;
 
 func_args 
-    : a=QUOTEDSTRING { sb.append($a.text); }
-        (b=QUOTEDSTRING { sb.append(", ").append($b.text); } )*
+    : QUOTEDSTRING+ 
 ;
 
 group_clause
- : ^( ( GROUP { sb.append($GROUP.text).append(" "); } | COGROUP { sb.append($COGROUP.text).append(" "); } ) 
-      group_item ( { sb.append(", "); } group_item )* 
-      ( { sb.append(" USING "); } group_type )? 
-      partition_clause?
-    )
+    : ^( ( GROUP | COGROUP ) group_item+ group_type? partition_clause? )
 ;
 
-group_type : QUOTEDSTRING { sb.append( $QUOTEDSTRING.text ); } 
+group_type : QUOTEDSTRING 
 ;
 
 group_item
-    : rel ( join_group_by_clause 
-            | ALL { sb.append(" ").append($ALL.text); } | ANY { sb.append(" ").append($ANY.text); } ) 
-            ( INNER { sb.append(" ").append($INNER.text); } | OUTER { sb.append(" ").append($OUTER.text); } )?
+    : rel ( join_group_by_clause | ALL | ANY ) ( INNER | OUTER )?
 ;
 
 rel 
-    : alias 
-    | { sb.append(" ("); } op_clause { sb.append(") "); }
+    : alias | op_clause
 ;
 
 flatten_generated_item 
-    : ( flatten_clause | expr | STAR { sb.append(" ").append($STAR.text); } ) ( { sb.append(" AS "); } field_def_list)?
+    : ( flatten_clause | expr | STAR ) field_def_list?
 ;
 
 flatten_clause 
-    : ^( FLATTEN { sb.append($FLATTEN.text).append("("); } expr { sb.append(") "); } )
+    : ^( FLATTEN expr )
 ;
 
 store_clause 
-    : ^( STORE { sb.append($STORE.text).append(" "); } rel { sb.append(" INTO "); } filename ( { sb.append(" USING "); } func_clause)? )
+    : ^( STORE alias filename func_clause? )
 ;
 
 filter_clause 
-    : ^( FILTER { sb.append($FILTER.text).append(" "); } rel { sb.append(" BY ("); } cond { sb.append(")"); } )
+    : ^( FILTER rel cond )
 ;
 
 cond 
-    : ^( OR { sb.append("("); } cond { sb.append(") ").append($OR.text).append(" ("); } cond { sb.append(")"); } )
-    | ^( AND { sb.append("("); } cond { sb.append(") ").append($AND.text).append(" ("); } cond { sb.append(")"); } )
-    | ^( NOT { sb.append(" ").append($NOT.text).append(" ("); } cond { sb.append(")"); } )
-    | ^( NULL expr { sb.append(" IS "); } (NOT { sb.append($NOT.text).append(" "); } )?  { sb.append($NULL.text); } )
-    | ^( rel_op expr { sb.append(" ").append($rel_op.result).append(" "); } expr )
+    : ^( OR cond cond )
+    | ^( AND cond cond )
+    | ^( NOT cond )
+    | ^( NULL expr NOT? )
+    | ^( rel_op expr expr )
     | func_eval
 ;
 
 func_eval
-    : ^( FUNC_EVAL func_name { sb.append("("); } real_arg ( { sb.append(", "); } real_arg)* { sb.append(")"); } )
-    | ^( FUNC_EVAL func_name  { sb.append("()"); } )
+    : ^( FUNC_EVAL func_name real_arg* )
 ;
 
 real_arg 
-    : expr | STAR { sb.append($STAR.text); }
+    : expr | STAR
 ;
 
 expr 
-    : ^( PLUS expr { sb.append(" ").append($PLUS.text).append(" "); } expr )
-    | ^( MINUS expr { sb.append(" ").append($MINUS.text).append(" "); } expr )
-    | ^( STAR expr { sb.append(" ").append($STAR.text).append(" "); } expr )
-    | ^( DIV expr { sb.append(" ").append($DIV.text).append(" "); } expr )
-    | ^( PERCENT expr { sb.append(" ").append($PERCENT.text).append(" "); } expr )
-    | ^( CAST_EXPR { sb.append("("); } type { sb.append(")"); } expr )
+    : ^( PLUS expr expr )
+    | ^( MINUS expr expr )
+    | ^( STAR expr expr )
+    | ^( DIV expr expr )
+    | ^( PERCENT expr expr )
+    | ^( CAST_EXPR type expr )
     | const_expr
     | var_expr
-    | ^( NEG { sb.append($NEG.text); } expr )
-    | ^( CAST_EXPR { sb.append("("); } type_cast { sb.append(")"); } expr )
-    | ^( EXPR_IN_PAREN { sb.append("("); } expr { sb.append(")"); } )
+    | ^( NEG expr )
+    | ^( CAST_EXPR type_cast expr )
+    | ^( EXPR_IN_PAREN expr )
 ;
 
 type_cast 
@@ -311,12 +272,11 @@ type_cast
 ;
 
 tuple_type_cast 
-    : ^( TUPLE_TYPE_CAST { sb.append("tuple("); } type_cast ( {sb.append(", "); } type_cast)* {sb.append(")"); } )
-    | ^( TUPLE_TYPE_CAST { sb.append("tuple("); } type_cast? {sb.append(")"); } )
+    : ^( TUPLE_TYPE_CAST type_cast* )
 ;
 
 bag_type_cast 
-    : ^( BAG_TYPE_CAST { sb.append("bag{"); } tuple_type_cast? {sb.append("}"); } )
+    : ^( BAG_TYPE_CAST tuple_type_cast? )
 ;
 
 var_expr 
@@ -328,95 +288,89 @@ projectable_expr
 ;
 
 dot_proj 
-    : ^( PERIOD { sb.append(".("); } col_alias_or_index ( { sb.append(", "); } col_alias_or_index)*  { sb.append(")"); } )
+    : ^( PERIOD col_alias_or_index+ )
 ;
 
 col_alias_or_index : col_alias | col_index
 ;
 
 col_alias 
-    : GROUP { sb.append($GROUP.text); }
+    : GROUP 
     | scoped_col_alias
 ;
 
 scoped_col_alias 
-    : ^( SCOPED_ALIAS a=IDENTIFIER {          
+    : ^( SCOPED_ALIAS (a=IDENTIFIER {          
         if (aliasSeen.contains($a.text)) {
-             sb.append(getMask($a.text));
+             $a.getToken().setText(getMask($a.text));
         } else {
-            sb.append($a.text);
+            $a.getToken().setText($a.text);
         } 
-    }
-    (b=IDENTIFIER { sb.append("::").append($b.text); })* )
+    })+ )
 ;
 
 col_index 
-    : DOLLARVAR { sb.append($DOLLARVAR.text); }
+    : DOLLARVAR
 ;
 
 pound_proj 
-    : ^( POUND { sb.append($POUND.text); }
-        ( QUOTEDSTRING { sb.append($QUOTEDSTRING.text); } | NULL { sb.append($NULL.text); } ) )
+    : ^( POUND ( QUOTEDSTRING | NULL ) )
 ;
 
 bin_expr 
-    : ^( BIN_EXPR { sb.append(" ("); } cond { sb.append(" ? "); } expr { sb.append(" : "); } expr { sb.append(") "); } )     
+    : ^( BIN_EXPR cond expr expr )     
 ;
 
 limit_clause 
-    : ^( LIMIT { sb.append($LIMIT.text).append(" "); } rel 
-        ( INTEGER { sb.append(" ").append($INTEGER.text); } | LONGINTEGER { sb.append(" ").append($LONGINTEGER.text); } ) )
+    : ^( LIMIT rel ( INTEGER | LONGINTEGER ) )
 ;
 
 sample_clause 
-    : ^( SAMPLE { sb.append($SAMPLE.text).append(" "); } rel DOUBLENUMBER { sb.append(" ").append($DOUBLENUMBER.text); } )    
+    : ^( SAMPLE rel DOUBLENUMBER )    
 ;
 
 order_clause 
-    : ^( ORDER { sb.append($ORDER.text).append(" "); } rel
-        { sb.append(" BY "); } order_by_clause
-        ( { sb.append(" USING "); } func_clause )? )
+    : ^( ORDER rel order_by_clause func_clause? )
 ;
 
 order_by_clause 
-    : STAR { sb.append($STAR.text); } ( ASC { sb.append(" ").append($ASC.text); } | DESC { sb.append(" ").append($DESC.text); } )?
-    | order_col ( { sb.append(", "); } order_col)*
+    : STAR ( ASC | DESC )?
+    | order_col+
 ;
 
 order_col 
-    : col_ref ( ASC { sb.append(" ").append($ASC.text); } | DESC { sb.append(" ").append($DESC.text); } )?    
+    : col_ref ( ASC | DESC )?    
 ;
 
 distinct_clause 
-    : ^( DISTINCT { sb.append($DISTINCT.text).append(" "); } rel partition_clause? )
+    : ^( DISTINCT rel partition_clause? )
 ;
 
 partition_clause 
-    : ^( PARTITION { sb.append(" ").append($PARTITION.text).append(" BY "); } func_name )    
+    : ^( PARTITION func_name )    
 ;
 
 cross_clause 
-    : ^( CROSS { sb.append($CROSS.text).append(" "); } rel_list partition_clause? )    
+    : ^( CROSS rel_list partition_clause? )    
 ;
 
 rel_list 
-    : rel ( { sb.append(", "); } rel)*
+    : rel+
 ;
 
 join_clause
-    : ^( JOIN { sb.append($JOIN.text).append(" "); } join_sub_clause ( { sb.append(" USING "); } join_type )? 
-    ( partition_clause )? )
+    : ^( JOIN join_sub_clause join_type? partition_clause? )
 ;
 
-join_type : QUOTEDSTRING { sb.append( $QUOTEDSTRING.text ); }
+join_type : QUOTEDSTRING
 ;
 
 join_sub_clause
- : join_item ( LEFT { sb.append(" ").append($LEFT.text); }
-             | RIGHT { sb.append(" ").append($RIGHT.text); }
-             | FULL { sb.append(" ").append($FULL.text); }
-             ) (OUTER { sb.append(" ").append($OUTER.text); } )? { sb.append(", "); } join_item
- | join_item ( { sb.append(", "); } join_item )*
+    : join_item ( LEFT 
+             | RIGHT 
+             | FULL 
+             ) OUTER? join_item
+    | join_item+
 ;
 
 join_item
@@ -424,20 +378,19 @@ join_item
 ;
 
 join_group_by_clause
-    : ^( BY { sb.append(" ").append($BY.text).append(" ("); } 
-    join_group_by_expr ( { sb.append(", "); } join_group_by_expr )* { sb.append(")"); } )
+    : ^( BY join_group_by_expr+ )
 ;
 
 join_group_by_expr 
-    : expr | STAR { sb.append($STAR.text); }
+    : expr | STAR
 ;
 
 union_clause 
-    : ^( UNION { sb.append($UNION.text).append(" "); } (ONSCHEMA { sb.append($ONSCHEMA.text).append(" "); } )? rel_list )    
+    : ^( UNION ONSCHEMA? rel_list )    
 ;
 
 foreach_clause 
-    : ^( FOREACH { sb.append($FOREACH.text).append(" "); } rel foreach_plan )    
+    : ^( FOREACH rel foreach_plan )    
 ;
 
 foreach_plan 
@@ -446,17 +399,16 @@ foreach_plan
 ;
 
 nested_blk
-    : { sb.append(" { "); } (nested_command { sb.append("; "); } )* generate_clause { sb.append("; } "); }
+    : nested_command* generate_clause
 ;
 
 generate_clause 
-    : ^( GENERATE { sb.append(" ").append($GENERATE.text).append(" "); }
-        flatten_generated_item ( { sb.append(", "); } flatten_generated_item)* )    
+    : ^( GENERATE flatten_generated_item+ )    
 ;
 
 nested_command
-    : ^( NESTED_CMD IDENTIFIER { sb.append($IDENTIFIER.text).append(" = "); } nested_op )
-    | ^( NESTED_CMD_ASSI IDENTIFIER { sb.append($IDENTIFIER.text).append(" = "); } expr )
+    : ^( NESTED_CMD IDENTIFIER nested_op )
+    | ^( NESTED_CMD_ASSI IDENTIFIER expr )
 ;
 
 nested_op : nested_proj
@@ -467,71 +419,62 @@ nested_op : nested_proj
 ;
 
 nested_proj 
-    : ^( NESTED_PROJ col_ref { sb.append(".("); } col_ref ( { sb.append(", "); } col_ref)* { sb.append(")"); } )    
+    : ^( NESTED_PROJ col_ref col_ref+ )    
 ;
 
 nested_filter
-    : ^( FILTER { sb.append($FILTER.text).append(" "); } nested_op_input { sb.append(" BY "); } cond )    
+    : ^( FILTER nested_op_input cond )    
 ;
 
 nested_sort 
-    : ^( ORDER { sb.append($ORDER.text).append(" "); } nested_op_input
-        { sb.append(" BY "); } order_by_clause ( { sb.append(" USING "); } func_clause)? )    
+    : ^( ORDER nested_op_input order_by_clause func_clause? )    
 ;
 
 nested_distinct 
-    : ^( DISTINCT { sb.append($DISTINCT.text).append(" "); }  nested_op_input )    
+    : ^( DISTINCT nested_op_input )    
 ;
 
 nested_limit 
-    : ^( LIMIT { sb.append($LIMIT.text).append(" "); }  nested_op_input INTEGER { sb.append(" ").append($INTEGER.text); } )
+    : ^( LIMIT nested_op_input INTEGER )
 ;
 
 nested_op_input : col_ref | nested_proj
 ;
 
 stream_clause 
-    : ^( STREAM { sb.append($STREAM.text).append(" "); } rel { sb.append(" THROUGH "); }
-        ( EXECCOMMAND { sb.append($EXECCOMMAND.text); }
-        | IDENTIFIER { sb.append($IDENTIFIER.text); } ) as_clause? )
+    : ^( STREAM rel ( EXECCOMMAND | alias ) as_clause? )
 ;
 
 mr_clause 
-    : ^( MAPREDUCE QUOTEDSTRING { sb.append($MAPREDUCE.text).append(" ").append($QUOTEDSTRING.text).append(" "); }
-        ({ sb.append(" ("); } path_list { sb.append(") "); } )? store_clause { sb.append(" "); } load_clause
-        (EXECCOMMAND { sb.append(" ").append($EXECCOMMAND.text); } )? )
+    : ^( MAPREDUCE QUOTEDSTRING path_list? store_clause load_clause EXECCOMMAND? )
 ;
 
 split_clause 
-    : ^( SPLIT  { sb.append($SPLIT.text).append(" "); }
-        rel { sb.append(" INTO "); } split_branch ( { sb.append(", "); } split_branch)+ )
+    : ^( SPLIT rel split_branch split_branch+ )
 ;
 
 split_branch
-    : ^( SPLIT_BRANCH IDENTIFIER { sb.append($IDENTIFIER.text).append(" IF "); } cond )    
+    : ^( SPLIT_BRANCH alias cond )
 ;
 
 col_ref : alias_col_ref | dollar_col_ref
 ;
 
 alias_col_ref 
-    : GROUP { sb.append($GROUP.text); }
+    : GROUP 
     | scoped_alias_col_ref
 ;
 
 scoped_alias_col_ref 
-    : ^( SCOPED_ALIAS name=IDENTIFIER  {
+    : ^( SCOPED_ALIAS (name=IDENTIFIER  {
         if (aliasSeen.contains($name.text)) {
-            sb.append(getMask($name.text));
-        } else {
-            sb.append($name.text);
-        } }
-    (name1=IDENTIFIER { sb.append("::").append($name1.text); } 
-        )* )
+            $name.getToken().setText(getMask($name.text));
+        } 
+    } )+ )
 ;
 
 dollar_col_ref 
-    : DOLLARVAR { sb.append($DOLLARVAR.text); }
+    : DOLLARVAR
 ;
 
 const_expr : literal
@@ -540,152 +483,153 @@ const_expr : literal
 literal : scalar | map | bag | tuple
 ;
 
-scalar : num_scalar
-       | QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
-       | NULL { sb.append($NULL.text); }    
-;
-
-num_scalar : ( MINUS { sb.append( "-" ); } )?
-             ( INTEGER { sb.append($INTEGER.text); }
-             | LONGINEGER { sb.append($LONGINEGER.text); }
-             | FLOATNUMBER { sb.append($FLOATNUMBER.text); }
-             | DOUBLENUMBER { sb.append($DOUBLENUMBER.text); }
-             )
+scalar 
+    : INTEGER
+    | LONGINEGER
+    | FLOATNUMBER
+    | DOUBLENUMBER
+    | QUOTEDSTRING
+    | NULL    
 ;
 
 map 
-    : ^( MAP_VAL { sb.append("["); } keyvalue ( { sb.append(", "); } keyvalue)* { sb.append("]"); } )
-    | ^( MAP_VAL { sb.append("[]"); } )
+    : ^( MAP_VAL keyvalue* )
 ;
 
 keyvalue 
-    : ^( KEY_VAL_PAIR map_key { sb.append("#"); } const_expr )    
+    : ^( KEY_VAL_PAIR map_key const_expr )    
 ;
 
-map_key : QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
+map_key : QUOTEDSTRING
 ;
 
 bag 
-    : ^( BAG_VAL { sb.append("{"); } tuple ( { sb.append(", "); } tuple)* { sb.append("}"); } )
-    | ^( BAG_VAL { sb.append("{}"); } )
+    : ^( BAG_VAL tuple* )
 ;
 
 tuple 
-    : ^( TUPLE_VAL { sb.append("("); } literal ( { sb.append(", "); }  literal)* { sb.append(")"); } )
-    | ^( TUPLE_VAL { sb.append("()"); } )
+    : ^( TUPLE_VAL literal* )
 ;
 
 // extended identifier, handling the keyword and identifier conflicts. Ugly but there is no other choice.
 eid : rel_str_op
-    | DEFINE    { sb.append($DEFINE.text); }
-    | LOAD      { sb.append($LOAD.text); }
-    | FILTER    { sb.append($FILTER.text); }
-    | FOREACH   { sb.append($FOREACH.text); }
-    | MATCHES   { sb.append($MATCHES.text); }
-    | ORDER     { sb.append($ORDER.text); }
-    | DISTINCT  { sb.append($DISTINCT.text); }
-    | COGROUP   { sb.append($COGROUP.text); }
-    | JOIN      { sb.append($JOIN.text); }
-    | CROSS     { sb.append($CROSS.text); }
-    | UNION     { sb.append($UNION.text); }
-    | SPLIT     { sb.append($SPLIT.text); }
-    | INTO      { sb.append($INTO.text); }
-    | IF        { sb.append($IF.text); }
-    | ALL       { sb.append($ALL.text); }
-    | AS        { sb.append($AS.text); }
-    | BY        { sb.append($BY.text); }
-    | USING     { sb.append($USING.text); }
-    | INNER     { sb.append($INNER.text); }
-    | OUTER     { sb.append($OUTER.text); }
-    | PARALLEL  { sb.append($PARALLEL.text); }
-    | PARTITION { sb.append($PARTITION.text); }
-    | GROUP     { sb.append($GROUP.text); }
-    | AND       { sb.append($AND.text); }
-    | OR        { sb.append($OR.text); }
-    | NOT       { sb.append($NOT.text); }
-    | GENERATE  { sb.append($GENERATE.text); }
-    | FLATTEN   { sb.append($FLATTEN.text); }
-    | EVAL      { sb.append($EVAL.text); }
-    | ASC       { sb.append($ASC.text); }
-    | DESC      { sb.append($DESC.text); }
-    | INT       { sb.append($INT.text); }
-    | LONG      { sb.append($LONG.text); }
-    | FLOAT     { sb.append($FLOAT.text); }
-    | DOUBLE    { sb.append($DOUBLE.text); }
-    | CHARARRAY { sb.append($CHARARRAY.text); }
-    | BYTEARRAY { sb.append($BYTEARRAY.text); }
-    | BAG       { sb.append($BAG.text); }
-    | TUPLE     { sb.append($TUPLE.text); }
-    | MAP       { sb.append($MAP.text); }
-    | IS        { sb.append($IS.text); }
-    | NULL      { sb.append($NULL.text); }
-    | STREAM    { sb.append($STREAM.text); }
-    | THROUGH   { sb.append($THROUGH.text); }
-    | STORE     { sb.append($STORE.text); }
-    | MAPREDUCE { sb.append($MAPREDUCE.text); }
-    | SHIP      { sb.append($SHIP.text); }
-    | CACHE     { sb.append($CACHE.text); }
-    | INPUT     { sb.append($INPUT.text); }
-    | OUTPUT    { sb.append($OUTPUT.text); }
-    | ERROR     { sb.append($ERROR.text); }
-    | STDIN     { sb.append($STDIN.text); }
-    | STDOUT    { sb.append($STDOUT.text); }
-    | LIMIT     { sb.append($LIMIT.text); }
-    | SAMPLE    { sb.append($SAMPLE.text); }
-    | LEFT      { sb.append($LEFT.text); }
-    | RIGHT     { sb.append($RIGHT.text); }
-    | FULL      { sb.append($FULL.text); }
-    | IDENTIFIER    { sb.append($IDENTIFIER.text); }
+    | IMPORT
+    | RETURNS
+    | DEFINE
+    | LOAD
+    | FILTER
+    | FOREACH
+    | MATCHES
+    | ORDER
+    | DISTINCT
+    | COGROUP
+    | JOIN
+    | CROSS
+    | UNION
+    | SPLIT
+    | INTO
+    | IF
+    | ALL
+    | AS
+    | BY
+    | USING
+    | INNER
+    | OUTER
+    | PARALLEL
+    | PARTITION
+    | GROUP
+    | AND
+    | OR
+    | NOT
+    | GENERATE
+    | FLATTEN
+    | EVAL
+    | ASC
+    | DESC
+    | INT
+    | LONG
+    | FLOAT
+    | DOUBLE
+    | CHARARRAY
+    | BYTEARRAY
+    | BAG
+    | TUPLE
+    | MAP
+    | IS
+    | NULL
+    | STREAM
+    | THROUGH
+    | STORE
+    | MAPREDUCE
+    | SHIP
+    | CACHE
+    | INPUT
+    | OUTPUT
+    | ERROR
+    | STDIN
+    | STDOUT
+    | LIMIT
+    | SAMPLE
+    | LEFT
+    | RIGHT
+    | FULL
+    | a = IDENTIFIER {
+        if (aliasSeen.contains($a.text)) {
+            $a.getToken().setText(getMask($a.text));
+        } else {
+            $a.getToken().setText($a.text);
+        }
+    }
 ;
 
 // relational operator
-rel_op returns[String result]
-    : rel_op_eq     { $result = $rel_op_eq.result; }
-    | rel_op_ne     { $result = $rel_op_ne.result; }
-    | rel_op_gt     { $result = $rel_op_gt.result; }
-    | rel_op_gte    { $result = $rel_op_gte.result; }
-    | rel_op_lt     { $result = $rel_op_lt.result; }
-    | rel_op_lte    { $result = $rel_op_lte.result; }
-    | STR_OP_MATCHES  { $result = $STR_OP_MATCHES.text; }
+rel_op
+    : rel_op_eq
+    | rel_op_ne
+    | rel_op_gt
+    | rel_op_gte
+    | rel_op_lt
+    | rel_op_lte
+    | STR_OP_MATCHES
 ;
 
-rel_op_eq returns[String result]
-    : STR_OP_EQ { $result = $STR_OP_EQ.text; }
-    | NUM_OP_EQ { $result = $NUM_OP_EQ.text; }
+rel_op_eq
+    : STR_OP_EQ
+    | NUM_OP_EQ
 ;
 
-rel_op_ne returns[String result]
-    : STR_OP_NE { $result = $STR_OP_NE.text; }
-    | NUM_OP_NE { $result = $NUM_OP_NE.text; }
+rel_op_ne
+    : STR_OP_NE
+    | NUM_OP_NE
 ;
 
-rel_op_gt returns[String result]
-    : STR_OP_GT { $result = $STR_OP_GT.text; }
-    | NUM_OP_GT { $result = $NUM_OP_GT.text; }
+rel_op_gt
+    : STR_OP_GT
+    | NUM_OP_GT
 ;
 
-rel_op_gte returns[String result]
-    : STR_OP_GTE { $result = $STR_OP_GTE.text; }
-    | NUM_OP_GTE { $result = $NUM_OP_GTE.text; }
+rel_op_gte
+    : STR_OP_GTE
+    | NUM_OP_GTE
 ;
 
-rel_op_lt returns[String result]
-    : STR_OP_LT { $result = $STR_OP_LT.text; }
-    | NUM_OP_LT { $result = $NUM_OP_LT.text; }
+rel_op_lt
+    : STR_OP_LT
+    | NUM_OP_LT
 ;
 
-rel_op_lte returns[String result]
-    : STR_OP_LTE { $result = $STR_OP_LTE.text; }
-    | NUM_OP_LTE { $result = $NUM_OP_LTE.text; }
+rel_op_lte
+    : STR_OP_LTE
+    | NUM_OP_LTE
 ;
 
 rel_str_op
-    : STR_OP_EQ { sb.append($STR_OP_EQ.text); }
-    | STR_OP_NE { sb.append($STR_OP_NE.text); }
-    | STR_OP_GT { sb.append($STR_OP_GT.text); }
-    | STR_OP_LT { sb.append($STR_OP_LT.text); }
-    | STR_OP_GTE { sb.append($STR_OP_GTE.text); }
-    | STR_OP_LTE { sb.append($STR_OP_LTE.text); }
-    | STR_OP_MATCHES { sb.append($STR_OP_MATCHES.text); }
+    : STR_OP_EQ
+    | STR_OP_NE
+    | STR_OP_GT
+    | STR_OP_LT
+    | STR_OP_GTE
+    | STR_OP_LTE
+    | STR_OP_MATCHES
 ;
 
diff --git a/src/org/apache/pig/parser/AstPrinter.g b/src/org/apache/pig/parser/AstPrinter.g
new file mode 100644
index 000000000..4cf8c0a01
--- /dev/null
+++ b/src/org/apache/pig/parser/AstPrinter.g
@@ -0,0 +1,645 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+ 
+/**
+ * Grammar file for Pig tree parser (visitor for printing Pig script from Ast).
+ *
+ * NOTE: THIS FILE IS BASED ON QueryParser.g, SO IF YOU CHANGE THAT FILE, YOU WILL 
+ *       PROBABLY NEED TO MAKE CORRESPONDING CHANGES TO THIS FILE AS WELL.
+ */
+
+tree grammar AstPrinter;
+
+options {
+    tokenVocab=QueryParser;
+    ASTLabelType=CommonTree;
+    output=AST;
+    backtrack=true;
+}
+
+@header {
+package org.apache.pig.parser;
+}
+
+@members {
+
+public String getResult() { return sb.toString(); }
+
+private StringBuilder sb = new StringBuilder();
+
+} // End of @members
+
+@rulecatch {
+catch(RecognitionException re) {
+    throw re;
+}
+}
+
+query : ^( QUERY statement* )
+;
+
+statement : general_statement
+          | split_statement { sb.append(";\n"); }
+;
+
+split_statement : split_clause
+;
+
+// For foreach statement that with complex inner plan.
+general_statement 
+    : ^( STATEMENT ( alias { sb.append(" = "); } )? 
+        op_clause parallel_clause? ) { sb.append(";\n"); }
+;
+
+parallel_clause 
+    : ^( PARALLEL INTEGER ) { sb.append(" ").append($PARALLEL.text).append(" ").append($INTEGER.text); }
+;
+
+alias 
+    : IDENTIFIER { sb.append($IDENTIFIER.text); }
+;
+
+op_clause : define_clause 
+          | load_clause
+          | group_clause
+          | store_clause
+          | filter_clause
+          | distinct_clause
+          | limit_clause
+          | sample_clause
+          | order_clause
+          | cross_clause
+          | join_clause
+          | union_clause
+          | stream_clause
+          | mr_clause
+          | split_clause
+          | foreach_clause
+;
+
+define_clause 
+    : ^( DEFINE IDENTIFIER { sb.append($DEFINE.text).append(" ").append($IDENTIFIER.text).append(" "); } 
+        ( cmd | func_clause ) )
+;
+
+cmd 
+    : ^( EXECCOMMAND { sb.append($EXECCOMMAND.text); }
+        ( ship_clause | cache_caluse | input_clause | output_clause | error_clause )* )
+;
+
+ship_clause 
+    : ^( SHIP { sb.append(" ").append($SHIP.text).append(" ("); } path_list? { sb.append(")"); } )
+;
+
+path_list 
+    : a=QUOTEDSTRING { sb.append(" ").append($a.text); }
+        (b=QUOTEDSTRING { sb.append(", ").append($b.text); } )*
+;
+
+cache_caluse 
+    : ^( CACHE { sb.append(" ").append($CACHE.text).append(" ("); } path_list { sb.append(")"); } )
+;
+
+input_clause 
+    : ^( INPUT { sb.append(" ").append($INPUT.text).append("("); } 
+        stream_cmd ( { sb.append(", "); } stream_cmd)* { sb.append(")"); } )
+;
+
+stream_cmd 
+    : ^( STDIN { sb.append($STDIN.text).append(" USING "); } func_clause? )
+    | ^( STDOUT { sb.append($STDOUT.text).append(" USING "); } func_clause? )
+    | ^( QUOTEDSTRING { sb.append($QUOTEDSTRING.text).append(" USING "); } func_clause? )
+;
+
+output_clause 
+    : ^( OUTPUT  { sb.append(" ").append($OUTPUT.text).append(" ("); } 
+        stream_cmd ( { sb.append(","); } stream_cmd)* { sb.append(")"); } )
+;
+
+error_clause 
+    : ^( STDERROR { sb.append(" ").append($STDERROR.text).append(" ("); }
+        ( QUOTEDSTRING { sb.append($QUOTEDSTRING.text); } (INTEGER { sb.append(" LIMIT ").append($INTEGER); } )? )? { sb.append(")"); } )
+;
+
+load_clause 
+    : ^( LOAD { sb.append($LOAD.text).append(" "); } filename 
+        ( { sb.append(" USING "); } func_clause)? as_clause? )
+;
+
+filename 
+    : QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
+;
+
+as_clause
+    : ^( AS { sb.append(" ").append($AS.text).append(" "); } field_def_list )
+;
+
+field_def
+    : ^( FIELD_DEF IDENTIFIER { sb.append($IDENTIFIER.text); }  ( {sb.append(":"); }  type)? )
+;
+
+field_def_list
+    : { sb.append("("); } field_def ( { sb.append(", "); } field_def )+ { sb.append(")"); }
+    | field_def
+;
+
+type : simple_type | tuple_type | bag_type | map_type
+;
+
+simple_type 
+    : INT { sb.append($INT.text); }
+    | LONG { sb.append($LONG.text); }
+    | FLOAT { sb.append($FLOAT.text); }
+    | DOUBLE { sb.append($DOUBLE.text); }
+    | CHARARRAY { sb.append($CHARARRAY.text); }
+    | BYTEARRAY { sb.append($BYTEARRAY.text); }
+;
+
+tuple_type 
+    : ^( TUPLE_TYPE field_def_list? )
+;
+
+bag_type 
+    : ^( BAG_TYPE { sb.append("bag{"); } ( { sb.append("T:"); } tuple_type )? ) { sb.append("}"); } 
+;
+
+map_type : ^( MAP_TYPE { sb.append("map["); } type? ) { sb.append("]"); }
+;
+
+func_clause 
+    : ^( FUNC_REF func_name )
+    | ^( FUNC func_name { sb.append("("); } func_args? { sb.append(")"); } )
+;
+
+func_name 
+    : eid ( ( PERIOD { sb.append($PERIOD.text); } | DOLLAR { sb.append($DOLLAR.text); } ) eid )*
+;
+
+func_args 
+    : a=QUOTEDSTRING { sb.append($a.text); }
+        (b=QUOTEDSTRING { sb.append(", ").append($b.text); } )*
+;
+
+group_clause
+    : ^( ( GROUP { sb.append($GROUP.text).append(" "); } | COGROUP { sb.append($COGROUP.text).append(" "); } ) 
+        group_item ( { sb.append(", "); } group_item )* 
+      ( { sb.append(" USING "); } group_type )? 
+      partition_clause?
+    )
+;
+
+group_type : QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
+;
+
+group_item
+    : rel ( join_group_by_clause 
+            | ALL { sb.append(" ").append($ALL.text); } | ANY { sb.append(" ").append($ANY.text); } ) 
+            ( INNER { sb.append(" ").append($INNER.text); } | OUTER { sb.append(" ").append($OUTER.text); } )?
+;
+
+rel 
+    : alias 
+    | { sb.append(" ("); } op_clause { sb.append(") "); }
+;
+
+flatten_generated_item 
+    : ( flatten_clause | expr | STAR { sb.append(" ").append($STAR.text); } ) ( { sb.append(" AS "); } field_def_list)?
+;
+
+flatten_clause 
+    : ^( FLATTEN { sb.append($FLATTEN.text).append("("); } expr { sb.append(") "); } )
+;
+
+store_clause 
+    : ^( STORE { sb.append($STORE.text).append(" "); } rel { sb.append(" INTO "); } filename ( { sb.append(" USING "); } func_clause)? )
+;
+
+filter_clause 
+    : ^( FILTER { sb.append($FILTER.text).append(" "); } rel { sb.append(" BY ("); } cond { sb.append(")"); } )
+;
+
+cond 
+    : ^( OR { sb.append("("); } cond { sb.append(") ").append($OR.text).append(" ("); } cond { sb.append(")"); } )
+    | ^( AND { sb.append("("); } cond { sb.append(") ").append($AND.text).append(" ("); } cond { sb.append(")"); } )
+    | ^( NOT { sb.append(" ").append($NOT.text).append(" ("); } cond { sb.append(")"); } )
+    | ^( NULL expr { sb.append(" IS "); } (NOT { sb.append($NOT.text).append(" "); } )?  { sb.append($NULL.text); } )
+    | ^( rel_op expr { sb.append(" ").append($rel_op.result).append(" "); } expr )
+    | func_eval
+;
+
+func_eval
+    : ^( FUNC_EVAL func_name { sb.append("("); } real_arg ( { sb.append(", "); } real_arg)* { sb.append(")"); } )
+    | ^( FUNC_EVAL func_name  { sb.append("()"); } )
+;
+
+real_arg 
+    : expr | STAR { sb.append($STAR.text); }
+;
+
+expr 
+    : ^( PLUS expr { sb.append(" ").append($PLUS.text).append(" "); } expr )
+    | ^( MINUS expr { sb.append(" ").append($MINUS.text).append(" "); } expr )
+    | ^( STAR expr { sb.append(" ").append($STAR.text).append(" "); } expr )
+    | ^( DIV expr { sb.append(" ").append($DIV.text).append(" "); } expr )
+    | ^( PERCENT expr { sb.append(" ").append($PERCENT.text).append(" "); } expr )
+    | ^( CAST_EXPR { sb.append("("); } type { sb.append(")"); } expr )
+    | const_expr
+    | var_expr
+    | ^( NEG { sb.append($NEG.text); } expr )
+    | ^( CAST_EXPR { sb.append("("); } type_cast { sb.append(")"); } expr )
+    | ^( EXPR_IN_PAREN { sb.append("("); } expr { sb.append(")"); } )
+;
+
+type_cast 
+    : simple_type | map_type | tuple_type_cast | bag_type_cast
+;
+
+tuple_type_cast 
+    : ^( TUPLE_TYPE_CAST { sb.append("tuple("); } type_cast ( {sb.append(", "); } type_cast)* {sb.append(")"); } )
+    | ^( TUPLE_TYPE_CAST { sb.append("tuple("); } type_cast? {sb.append(")"); } )
+;
+
+bag_type_cast 
+    : ^( BAG_TYPE_CAST { sb.append("bag{"); } tuple_type_cast? {sb.append("}"); } )
+;
+
+var_expr 
+    : projectable_expr ( dot_proj | pound_proj )*
+;
+
+projectable_expr
+    : func_eval | col_ref | bin_expr
+;
+
+dot_proj 
+    : ^( PERIOD { sb.append(".("); } col_alias_or_index ( { sb.append(", "); } col_alias_or_index)*  { sb.append(")"); } )
+;
+
+col_alias_or_index : col_alias | col_index
+;
+
+col_alias 
+    : GROUP { sb.append($GROUP.text); }
+    | scoped_col_alias
+;
+
+scoped_col_alias 
+    : ^( SCOPED_ALIAS a=IDENTIFIER {          
+        sb.append($a.text);
+    }
+    (b=IDENTIFIER { sb.append("::").append($b.text); })* )
+;
+
+col_index 
+    : DOLLARVAR { sb.append($DOLLARVAR.text); }
+;
+
+pound_proj 
+    : ^( POUND { sb.append($POUND.text); }
+        ( QUOTEDSTRING { sb.append($QUOTEDSTRING.text); } | NULL { sb.append($NULL.text); } ) )
+;
+
+bin_expr 
+    : ^( BIN_EXPR { sb.append(" ("); } cond { sb.append(" ? "); } expr { sb.append(" : "); } expr { sb.append(") "); } )     
+;
+
+limit_clause 
+    : ^( LIMIT { sb.append($LIMIT.text).append(" "); } rel 
+        ( INTEGER { sb.append(" ").append($INTEGER.text); } | LONGINTEGER { sb.append(" ").append($LONGINTEGER.text); } ) )
+;
+
+sample_clause 
+    : ^( SAMPLE { sb.append($SAMPLE.text).append(" "); } rel DOUBLENUMBER { sb.append(" ").append($DOUBLENUMBER.text); } )    
+;
+
+order_clause 
+    : ^( ORDER { sb.append($ORDER.text).append(" "); } rel
+        { sb.append(" BY "); } order_by_clause
+        ( { sb.append(" USING "); } func_clause )? )
+;
+
+order_by_clause 
+    : STAR { sb.append($STAR.text); } ( ASC { sb.append(" ").append($ASC.text); } | DESC { sb.append(" ").append($DESC.text); } )?
+    | order_col ( { sb.append(", "); } order_col)*
+;
+
+order_col 
+    : col_ref ( ASC { sb.append(" ").append($ASC.text); } | DESC { sb.append(" ").append($DESC.text); } )?    
+;
+
+distinct_clause 
+    : ^( DISTINCT { sb.append($DISTINCT.text).append(" "); } rel partition_clause? )
+;
+
+partition_clause 
+    : ^( PARTITION { sb.append(" ").append($PARTITION.text).append(" BY "); } func_name )    
+;
+
+cross_clause 
+    : ^( CROSS { sb.append($CROSS.text).append(" "); } rel_list partition_clause? )    
+;
+
+rel_list 
+    : rel ( { sb.append(", "); } rel)*
+;
+
+join_clause
+    : ^( JOIN { sb.append($JOIN.text).append(" "); } join_sub_clause ( { sb.append(" USING "); } join_type )? 
+    ( partition_clause )? )
+;
+
+join_type : QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
+;
+
+join_sub_clause
+    : join_item ( LEFT { sb.append(" ").append($LEFT.text); }
+             | RIGHT { sb.append(" ").append($RIGHT.text); }
+             | FULL { sb.append(" ").append($FULL.text); }
+             ) (OUTER { sb.append(" ").append($OUTER.text); } )? { sb.append(", "); } join_item
+    | join_item ( { sb.append(", "); } join_item )*
+;
+
+join_item
+    : ^( JOIN_ITEM rel join_group_by_clause )
+;
+
+join_group_by_clause
+    : ^( BY { sb.append(" ").append($BY.text).append(" ("); } 
+    join_group_by_expr ( { sb.append(", "); } join_group_by_expr )* { sb.append(")"); } )
+;
+
+join_group_by_expr 
+    : expr | STAR { sb.append($STAR.text); }
+;
+
+union_clause 
+    : ^( UNION { sb.append($UNION.text).append(" "); } (ONSCHEMA { sb.append($ONSCHEMA.text).append(" "); } )? rel_list )    
+;
+
+foreach_clause 
+    : ^( FOREACH { sb.append($FOREACH.text).append(" "); } rel foreach_plan )    
+;
+
+foreach_plan 
+    : ^( FOREACH_PLAN_SIMPLE generate_clause )
+    | ^( FOREACH_PLAN_COMPLEX nested_blk )
+;
+
+nested_blk
+    : { sb.append(" { "); } (nested_command { sb.append("; "); } )* generate_clause { sb.append("; } "); }
+;
+
+generate_clause 
+    : ^( GENERATE { sb.append(" ").append($GENERATE.text).append(" "); }
+        flatten_generated_item ( { sb.append(", "); } flatten_generated_item)* )    
+;
+
+nested_command
+    : ^( NESTED_CMD IDENTIFIER { sb.append($IDENTIFIER.text).append(" = "); } nested_op )
+    | ^( NESTED_CMD_ASSI IDENTIFIER { sb.append($IDENTIFIER.text).append(" = "); } expr )
+;
+
+nested_op : nested_proj
+          | nested_filter
+          | nested_sort
+          | nested_distinct
+          | nested_limit
+;
+
+nested_proj 
+    : ^( NESTED_PROJ col_ref { sb.append(".("); } col_ref ( { sb.append(", "); } col_ref)* { sb.append(")"); } )    
+;
+
+nested_filter
+    : ^( FILTER { sb.append($FILTER.text).append(" "); } nested_op_input { sb.append(" BY "); } cond )    
+;
+
+nested_sort 
+    : ^( ORDER { sb.append($ORDER.text).append(" "); } nested_op_input
+        { sb.append(" BY "); } order_by_clause ( { sb.append(" USING "); } func_clause)? )    
+;
+
+nested_distinct 
+    : ^( DISTINCT { sb.append($DISTINCT.text).append(" "); }  nested_op_input )    
+;
+
+nested_limit 
+    : ^( LIMIT { sb.append($LIMIT.text).append(" "); }  nested_op_input INTEGER { sb.append(" ").append($INTEGER.text); } )
+;
+
+nested_op_input : col_ref | nested_proj
+;
+
+stream_clause 
+    : ^( STREAM { sb.append($STREAM.text).append(" "); } rel { sb.append(" THROUGH "); }
+        ( EXECCOMMAND { sb.append($EXECCOMMAND.text); }
+        | IDENTIFIER { sb.append($IDENTIFIER.text); } ) as_clause? )
+;
+
+mr_clause 
+    : ^( MAPREDUCE QUOTEDSTRING { sb.append($MAPREDUCE.text).append(" ").append($QUOTEDSTRING.text).append(" "); }
+        ({ sb.append(" ("); } path_list { sb.append(") "); } )? store_clause { sb.append(" "); } load_clause
+        (EXECCOMMAND { sb.append(" ").append($EXECCOMMAND.text); } )? )
+;
+
+split_clause 
+    : ^( SPLIT  { sb.append($SPLIT.text).append(" "); }
+        rel { sb.append(" INTO "); } split_branch ( { sb.append(", "); } split_branch)+ )
+;
+
+split_branch
+    : ^( SPLIT_BRANCH alias { sb.append(" IF "); } cond )    
+;
+
+col_ref : alias_col_ref | dollar_col_ref
+;
+
+alias_col_ref 
+    : GROUP { sb.append($GROUP.text); }
+    | scoped_alias_col_ref
+;
+
+scoped_alias_col_ref 
+    : ^( SCOPED_ALIAS name=IDENTIFIER  {
+        sb.append($name.text);
+    }
+    (name1=IDENTIFIER { sb.append("::").append($name1.text); } 
+    )* )
+;
+
+dollar_col_ref 
+    : DOLLARVAR { sb.append($DOLLARVAR.text); }
+;
+
+const_expr : literal
+;
+
+literal : scalar | map | bag | tuple
+;
+
+scalar : num_scalar
+       | QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
+       | NULL { sb.append($NULL.text); }    
+;
+
+num_scalar : ( MINUS { sb.append( "-" ); } )?
+             ( INTEGER { sb.append($INTEGER.text); }
+             | LONGINEGER { sb.append($LONGINEGER.text); }
+             | FLOATNUMBER { sb.append($FLOATNUMBER.text); }
+             | DOUBLENUMBER { sb.append($DOUBLENUMBER.text); }
+             )
+;
+
+map 
+    : ^( MAP_VAL { sb.append("["); } keyvalue ( { sb.append(", "); } keyvalue)* { sb.append("]"); } )
+    | ^( MAP_VAL { sb.append("[]"); } )
+;
+
+keyvalue 
+    : ^( KEY_VAL_PAIR map_key { sb.append("#"); } const_expr )    
+;
+
+map_key : QUOTEDSTRING { sb.append($QUOTEDSTRING.text); }
+;
+
+bag 
+    : ^( BAG_VAL { sb.append("{"); } tuple ( { sb.append(", "); } tuple)* { sb.append("}"); } )
+    | ^( BAG_VAL { sb.append("{}"); } )
+;
+
+tuple 
+    : ^( TUPLE_VAL { sb.append("("); } literal ( { sb.append(", "); }  literal)* { sb.append(")"); } )
+    | ^( TUPLE_VAL { sb.append("()"); } )
+;
+
+// extended identifier, handling the keyword and identifier conflicts. Ugly but there is no other choice.
+eid : rel_str_op
+    | IMPORT    { sb.append($IMPORT.text); }
+    | RETURNS   { sb.append($RETURNS.text); }
+    | DEFINE    { sb.append($DEFINE.text); }
+    | LOAD      { sb.append($LOAD.text); }
+    | FILTER    { sb.append($FILTER.text); }
+    | FOREACH   { sb.append($FOREACH.text); }
+    | MATCHES   { sb.append($MATCHES.text); }
+    | ORDER     { sb.append($ORDER.text); }
+    | DISTINCT  { sb.append($DISTINCT.text); }
+    | COGROUP   { sb.append($COGROUP.text); }
+    | JOIN      { sb.append($JOIN.text); }
+    | CROSS     { sb.append($CROSS.text); }
+    | UNION     { sb.append($UNION.text); }
+    | SPLIT     { sb.append($SPLIT.text); }
+    | INTO      { sb.append($INTO.text); }
+    | IF        { sb.append($IF.text); }
+    | ALL       { sb.append($ALL.text); }
+    | AS        { sb.append($AS.text); }
+    | BY        { sb.append($BY.text); }
+    | USING     { sb.append($USING.text); }
+    | INNER     { sb.append($INNER.text); }
+    | OUTER     { sb.append($OUTER.text); }
+    | PARALLEL  { sb.append($PARALLEL.text); }
+    | PARTITION { sb.append($PARTITION.text); }
+    | GROUP     { sb.append($GROUP.text); }
+    | AND       { sb.append($AND.text); }
+    | OR        { sb.append($OR.text); }
+    | NOT       { sb.append($NOT.text); }
+    | GENERATE  { sb.append($GENERATE.text); }
+    | FLATTEN   { sb.append($FLATTEN.text); }
+    | EVAL      { sb.append($EVAL.text); }
+    | ASC       { sb.append($ASC.text); }
+    | DESC      { sb.append($DESC.text); }
+    | INT       { sb.append($INT.text); }
+    | LONG      { sb.append($LONG.text); }
+    | FLOAT     { sb.append($FLOAT.text); }
+    | DOUBLE    { sb.append($DOUBLE.text); }
+    | CHARARRAY { sb.append($CHARARRAY.text); }
+    | BYTEARRAY { sb.append($BYTEARRAY.text); }
+    | BAG       { sb.append($BAG.text); }
+    | TUPLE     { sb.append($TUPLE.text); }
+    | MAP       { sb.append($MAP.text); }
+    | IS        { sb.append($IS.text); }
+    | NULL      { sb.append($NULL.text); }
+    | STREAM    { sb.append($STREAM.text); }
+    | THROUGH   { sb.append($THROUGH.text); }
+    | STORE     { sb.append($STORE.text); }
+    | MAPREDUCE { sb.append($MAPREDUCE.text); }
+    | SHIP      { sb.append($SHIP.text); }
+    | CACHE     { sb.append($CACHE.text); }
+    | INPUT     { sb.append($INPUT.text); }
+    | OUTPUT    { sb.append($OUTPUT.text); }
+    | ERROR     { sb.append($ERROR.text); }
+    | STDIN     { sb.append($STDIN.text); }
+    | STDOUT    { sb.append($STDOUT.text); }
+    | LIMIT     { sb.append($LIMIT.text); }
+    | SAMPLE    { sb.append($SAMPLE.text); }
+    | LEFT      { sb.append($LEFT.text); }
+    | RIGHT     { sb.append($RIGHT.text); }
+    | FULL      { sb.append($FULL.text); }
+    | IDENTIFIER    { sb.append($IDENTIFIER.text); }
+;
+
+// relational operator
+rel_op returns[String result]
+    : rel_op_eq     { $result = $rel_op_eq.result; }
+    | rel_op_ne     { $result = $rel_op_ne.result; }
+    | rel_op_gt     { $result = $rel_op_gt.result; }
+    | rel_op_gte    { $result = $rel_op_gte.result; }
+    | rel_op_lt     { $result = $rel_op_lt.result; }
+    | rel_op_lte    { $result = $rel_op_lte.result; }
+    | STR_OP_MATCHES  { $result = $STR_OP_MATCHES.text; }
+;
+
+rel_op_eq returns[String result]
+    : STR_OP_EQ { $result = $STR_OP_EQ.text; }
+    | NUM_OP_EQ { $result = $NUM_OP_EQ.text; }
+;
+
+rel_op_ne returns[String result]
+    : STR_OP_NE { $result = $STR_OP_NE.text; }
+    | NUM_OP_NE { $result = $NUM_OP_NE.text; }
+;
+
+rel_op_gt returns[String result]
+    : STR_OP_GT { $result = $STR_OP_GT.text; }
+    | NUM_OP_GT { $result = $NUM_OP_GT.text; }
+;
+
+rel_op_gte returns[String result]
+    : STR_OP_GTE { $result = $STR_OP_GTE.text; }
+    | NUM_OP_GTE { $result = $NUM_OP_GTE.text; }
+;
+
+rel_op_lt returns[String result]
+    : STR_OP_LT { $result = $STR_OP_LT.text; }
+    | NUM_OP_LT { $result = $NUM_OP_LT.text; }
+;
+
+rel_op_lte returns[String result]
+    : STR_OP_LTE { $result = $STR_OP_LTE.text; }
+    | NUM_OP_LTE { $result = $NUM_OP_LTE.text; }
+;
+
+rel_str_op
+    : STR_OP_EQ { sb.append($STR_OP_EQ.text); }
+    | STR_OP_NE { sb.append($STR_OP_NE.text); }
+    | STR_OP_GT { sb.append($STR_OP_GT.text); }
+    | STR_OP_LT { sb.append($STR_OP_LT.text); }
+    | STR_OP_GTE { sb.append($STR_OP_GTE.text); }
+    | STR_OP_LTE { sb.append($STR_OP_LTE.text); }
+    | STR_OP_MATCHES { sb.append($STR_OP_MATCHES.text); }
+;
+
diff --git a/src/org/apache/pig/parser/AstValidator.g b/src/org/apache/pig/parser/AstValidator.g
index ddddb775e..03bb63944 100644
--- a/src/org/apache/pig/parser/AstValidator.g
+++ b/src/org/apache/pig/parser/AstValidator.g
@@ -463,9 +463,9 @@ split_clause : ^( SPLIT rel split_branch+ )
 ;
 
 split_branch
- : ^( SPLIT_BRANCH IDENTIFIER cond )
+ : ^( SPLIT_BRANCH alias cond )
    {
-       aliases.add( $IDENTIFIER.text );
+       aliases.add( $alias.name );
    }
 ;
 
@@ -510,6 +510,8 @@ tuple : ^( TUPLE_VAL literal* )
 
 // extended identifier, handling the keyword and identifier conflicts. Ugly but there is no other choice.
 eid : rel_str_op
+    | IMPORT
+    | RETURNS
     | DEFINE
     | LOAD
     | FILTER
diff --git a/src/org/apache/pig/parser/LogicalPlanGenerator.g b/src/org/apache/pig/parser/LogicalPlanGenerator.g
index 134938a09..0ba0fd3ab 100644
--- a/src/org/apache/pig/parser/LogicalPlanGenerator.g
+++ b/src/org/apache/pig/parser/LogicalPlanGenerator.g
@@ -1243,9 +1243,9 @@ scope GScope;
     LogicalExpressionPlan splitPlan = new LogicalExpressionPlan();
     $GScope::currentOp = builder.createSplitOutputOp();
 }
- : ^( SPLIT_BRANCH IDENTIFIER cond[splitPlan] )
+ : ^( SPLIT_BRANCH alias cond[splitPlan] )
    {
-       builder.buildSplitOutputOp( (LOSplitOutput)$GScope::currentOp, $IDENTIFIER.text,
+       builder.buildSplitOutputOp( (LOSplitOutput)$GScope::currentOp, $alias.name,
            $statement::inputAlias, splitPlan );
    }
 ;
@@ -1424,6 +1424,8 @@ tuple returns[Tuple value]
 
 // extended identifier, handling the keyword and identifier conflicts. Ugly but there is no other choice.
 eid returns[String id] : rel_str_op { $id = $rel_str_op.id; }
+    | IMPORT { $id = $IMPORT.text; }
+    | RETURNS { $id = $RETURNS.text; }
     | DEFINE { $id = $DEFINE.text; }
     | LOAD { $id = $LOAD.text; }
     | FILTER { $id = $FILTER.text; }
diff --git a/src/org/apache/pig/parser/MacroExpansion.g b/src/org/apache/pig/parser/MacroExpansion.g
deleted file mode 100644
index f22ecef34..000000000
--- a/src/org/apache/pig/parser/MacroExpansion.g
+++ /dev/null
@@ -1,139 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-lexer grammar MacroExpansion;
-
-options { 
-    filter=true;
-}
-
-@header {
-package org.apache.pig.parser;
-
-import java.util.HashMap;
-import java.util.List;
-import org.apache.pig.parser.PigMacro;
-}
-
-@members {
-    private Map<String, PigMacro> memory = new HashMap<String, PigMacro>();
-    private StringBuilder sb = new StringBuilder();
-    
-    public String getResultString() { return sb.toString(); } 
-}
-
-MACRO 
-    : 'define' WS name=ALIAS WS? '(' ( params+=ALIAS (',' WS* params+=ALIAS)* )? ')' WS 'returns' WS rets+=ALIAS (',' WS* rets+=ALIAS)* WS  '{' content=BLOCK '};' 
-        {
-            PigMacro macro = new PigMacro($name.text);
-            macro.setBody($content.text, memory);
-            if ($params != null) {
-                for (Object param : $params) {
-                    macro.addParam(((Token)param).getText());
-                }
-            }
-            if ($rets != null) {
-                for (Object ret : $rets) {
-                    macro.addReturn(((Token)ret).getText());
-                }
-            }
-            String mn = $name.text;
-            // check macro name duplication
-            if (memory.containsKey(mn)) {
-                throw new RuntimeException("Macro name duplication: " + mn);
-            }
-            memory.put(mn, macro);
-        } 
-;
-
-INLINE
-    : rets+=ALIAS (',' WS* rets+=ALIAS)* WS '=' WS name=ALIAS WS? '(' ( params+=PARAMETER (',' WS* params+=PARAMETER)* )? ');'
-        {
-            String mn = $name.text;
-            PigMacro macro = memory.get(mn);
-            if (macro == null) {
-                throw new RuntimeException("Pig macro '" + mn + "' must be defined before being invoked");
-            }
-            String[] inputs = null;
-            if ($params != null) {
-                inputs = new String[$params.size()]; 
-                int i = 0;
-                for (Object param : $params) {
-                    inputs[i++] = ((Token)param).getText();
-                }
-            }   
-            String[] outputs = null;
-            if ($rets != null) {
-                outputs = new String[$rets.size()];
-                int i = 0;
-                for (Object ret : $rets) {
-                    outputs[i++] = ((Token)ret).getText();
-                }
-            }           
-            String s = macro.inline(inputs, outputs);
-            sb.append(s);
-        }
-;
-
-C
-: c=. { sb.append((char)c); }
-;
-
-fragment WS : (' '|'\n'|'\r')+  
-;
-
-fragment DIGIT : '0'..'9'
-;
-
-fragment LETTER : ('A'..'Z' | 'a'..'z')
-;
-    
-fragment SPECIALCHAR : '_'
-;
-
-fragment ALIAS : LETTER ( DIGIT | LETTER | SPECIALCHAR )*
-;
-
-fragment INTEGER: ( DIGIT )+
-;
-
-fragment PERIOD : '.'
-;
-    
-fragment FLOATINGPOINT : (INTEGER PERIOD INTEGER  | PERIOD INTEGER) 
-;
-
-fragment QUOTEDSTRING :  '\'' (   ( ~ ( '\'' | '\\' | '\n' | '\r' ) )
-                       | ( '\\' ( ( 'N' | 'T' | 'B' | 'R' | 'F' | '\\' | '\'' ) ) )
-                       | ( '\\u' ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )  )
-                     )*
-                '\''
-;
-
-fragment PARAMETER : (ALIAS | INTEGER | FLOATINGPOINT | QUOTEDSTRING)
-;
-
-fragment STMT : ~('{' | '}')+ | '{}' | '{' STMT '}'
-;
-
-fragment BLOCK : STMT+
-;
-
diff --git a/src/org/apache/pig/parser/MacroImport.g b/src/org/apache/pig/parser/MacroImport.g
deleted file mode 100644
index ee33dbcfe..000000000
--- a/src/org/apache/pig/parser/MacroImport.g
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-lexer grammar MacroImport;
-
-options { 
-    filter=true; 
-}
-
-@header {
-package org.apache.pig.parser;
-
-import java.util.HashSet;
-import java.io.FileReader;
-import java.io.BufferedReader;
-import java.io.IOException;
-
-}
-
-@members {
-    private HashSet<String> memory = new HashSet<String>();
-    private StringBuilder sb = new StringBuilder();
-    
-    public String getResultString() { return sb.toString(); }
-}
-
-IMPORT
-    : 'import' WS+ name=QUOTEDSTRING ';'
-        {
-            String fp = $name.text;
-
-            // remove quotes
-            fp = fp.substring(1, fp.length()-1);
-
-            // check file name duplication
-            if (memory.contains(fp)) {
-                throw new RuntimeException("Macro file name duplication: " + fp);
-            }
-            try {
-                BufferedReader in
-                    = ParserUtil.getImportScriptAsReader(fp);
-                String line = in.readLine();
-                while (line != null) {
-                    sb.append(line).append("\n");
-                    line = in.readLine();
-                }
-            } catch (IOException e) {
-                throw new RuntimeException("Macro import error", e);
-            }
-            memory.add(fp);
-        } 
-;
-
-C
-: c=. { sb.append((char)c); }
-;
-
-fragment WS : (' '|'\n'|'\r')+
-;
-
-fragment QUOTEDSTRING :  '\'' (   ( ~ ( '\'' | '\\' | '\n' | '\r' ) )
-                       | ( '\\' ( ( 'N' | 'T' | 'B' | 'R' | 'F' | '\\' | '\'' ) ) )
-                       | ( '\\u' ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )  )
-                     )*
-                '\''
-;
-
diff --git a/src/org/apache/pig/parser/MacroRecursion.g b/src/org/apache/pig/parser/MacroRecursion.g
deleted file mode 100644
index d45cd0c56..000000000
--- a/src/org/apache/pig/parser/MacroRecursion.g
+++ /dev/null
@@ -1,120 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-lexer grammar MacroRecursion;
-
-options { 
-    filter=true;
-}
-
-@header {
-package org.apache.pig.parser;
-
-import java.util.HashMap;
-import java.util.List;
-import org.apache.pig.parser.PigMacro;
-}
-
-@members {
-    private Map<String, PigMacro> memory = new HashMap<String, PigMacro>();
-    private StringBuilder sb = new StringBuilder();
-    private boolean isExpanded = false;
- 
-    public String getResultString() { return sb.toString(); } 
-
-    public void setMacros(Map<String, PigMacro> macros) {
-        memory = macros;
-    }
-    
-    public boolean isExpanded() { return isExpanded; }
-}
-
-INLINE
-    : rets+=ALIAS (',' WS* rets+=ALIAS)* WS '=' WS name=ALIAS WS? '(' ( params+=PARAMETER (',' WS* params+=PARAMETER)* )? ');'
-        {
-            String mn = $name.text;
-            PigMacro macro = memory.get(mn);
-            if (macro == null) {
-                throw new RuntimeException("Pig macro '" + mn + "' must be defined before being invoked");
-            }
-            String[] inputs = null;
-            if ($params != null) {
-                inputs = new String[$params.size()]; 
-                int i = 0;
-                for (Object param : $params) {
-                    inputs[i++] = ((Token)param).getText();
-                }
-            }   
-            String[] outputs = null;
-            if ($rets != null) {
-                outputs = new String[$rets.size()];
-                int i = 0;
-                for (Object ret : $rets) {
-                    outputs[i++] = ((Token)ret).getText();
-                }
-            }           
-            String s = macro.substituteParams(inputs, outputs);
-            sb.append(s);
-            
-            isExpanded = true;
-        }
-;
-
-C
-: c=. { sb.append((char)c); }
-;
-
-fragment WS : (' '|'\n'|'\r')+  
-;
-
-fragment DIGIT : '0'..'9'
-;
-
-fragment LETTER : ('A'..'Z' | 'a'..'z')
-;
-    
-fragment SPECIALCHAR : '_'
-;
-
-fragment ALIAS 
-    : LETTER ( DIGIT | LETTER | SPECIALCHAR )*
-    | '$'  LETTER ( DIGIT | LETTER | SPECIALCHAR )*
-;
-
-fragment INTEGER: ( DIGIT )+
-;
-
-fragment PERIOD : '.'
-;
-    
-fragment FLOATINGPOINT : (INTEGER PERIOD INTEGER  | PERIOD INTEGER) 
-;
-
-fragment QUOTEDSTRING :  '\'' (   ( ~ ( '\'' | '\\' | '\n' | '\r' ) )
-                       | ( '\\' ( ( 'N' | 'T' | 'B' | 'R' | 'F' | '\\' | '\'' ) ) )
-                       | ( '\\u' ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )
-                                 ( '0'..'9' | 'A'..'F' )  )
-                     )*
-                '\''
-;
-
-fragment PARAMETER : (ALIAS | INTEGER | FLOATINGPOINT | QUOTEDSTRING)
-;
-
diff --git a/src/org/apache/pig/parser/ParserUtil.java b/src/org/apache/pig/parser/ParserUtil.java
deleted file mode 100644
index 67fce5fcf..000000000
--- a/src/org/apache/pig/parser/ParserUtil.java
+++ /dev/null
@@ -1,93 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.pig.parser;
-
-import java.io.BufferedReader;
-import java.io.File;
-import java.io.FileNotFoundException;
-import java.io.FileReader;
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.antlr.runtime.ANTLRReaderStream;
-import org.antlr.runtime.Token;
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
-import org.apache.pig.tools.pigstats.ScriptState;
-
-public abstract class ParserUtil {
-
-    private static final Log LOG = LogFactory.getLog(ParserUtil.class);
-
-    public static String expandMacros(Reader rd) throws IOException {
-        // import macro files
-        ANTLRReaderStream input1 = new ANTLRReaderStream(rd);
-        MacroImport importer = new MacroImport(input1);
-        Token token = Token.EOF_TOKEN;
-        while ((token = importer.nextToken()) != Token.EOF_TOKEN);
-        
-        String ret1 = importer.getResultString();
-        LOG.info("Macro imported script:\n" + ret1);
-        
-        // expand macros
-        StringReader srd = new StringReader(ret1);
-        ANTLRReaderStream input2 = new ANTLRReaderStream(srd);
-        MacroExpansion expander = new MacroExpansion(input2);
-        while ((token = expander.nextToken()) != Token.EOF_TOKEN);
-        
-        String ret2 = expander.getResultString();
-        LOG.info("Macro expanded script:\n" + ret2);
-        
-        return ret2;
-    }
-    
-    public static BufferedReader getImportScriptAsReader(String scriptPath)
-            throws FileNotFoundException {
-        File f = new File(scriptPath);
-        if (f.exists() || f.isAbsolute() || scriptPath.startsWith("./")
-                || scriptPath.startsWith("../")) {
-            return new BufferedReader(new FileReader(f));
-        }
-
-        ScriptState state = ScriptState.get();
-        if (state != null && state.getPigContext() != null) {
-            String srchPath = state.getPigContext().getProperties()
-                    .getProperty("pig.import.search.path");
-            if (srchPath != null) {
-                String[] paths = srchPath.split(",");
-                for (String path : paths) {
-                    File f1 = new File(path + File.separator + scriptPath);
-                    if (f1.exists()) {
-                        return new BufferedReader(new FileReader(f1));
-                    }
-                }
-            }
-        }
-        
-        throw new FileNotFoundException("Can't find the Specified file " + scriptPath );
-    }
-    
-    public static BufferedReader getExpandedMacroAsBufferedReader(Reader rd)
-            throws IOException {
-        return new BufferedReader(new StringReader(expandMacros(rd)));
-    }
-
-}
-
diff --git a/src/org/apache/pig/parser/PigMacro.java b/src/org/apache/pig/parser/PigMacro.java
index f6c0b58cd..46b05bab1 100644
--- a/src/org/apache/pig/parser/PigMacro.java
+++ b/src/org/apache/pig/parser/PigMacro.java
@@ -28,21 +28,21 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import org.antlr.runtime.ANTLRReaderStream;
 import org.antlr.runtime.CharStream;
 import org.antlr.runtime.CommonTokenStream;
-import org.antlr.runtime.Token;
+import org.antlr.runtime.RecognitionException;
+import org.antlr.runtime.tree.CommonTree;
 import org.antlr.runtime.tree.CommonTreeNodeStream;
 import org.antlr.runtime.tree.Tree;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.pig.tools.parameters.ParameterSubstitutionPreprocessor;
-import org.apache.pig.tools.parameters.ParseException;
 
 public class PigMacro {
 
     private static final Log LOG = LogFactory.getLog(PigMacro.class);
 
+    private String fileName;
     private String name;
     private String body;
     private List<String> params;
@@ -54,13 +54,16 @@ public class PigMacro {
         this.name = name;
         this.params = new ArrayList<String>();
         this.rets = new ArrayList<String>();
-        LOG.info("Macro '" + name + "' is defined");
+        LOG.debug("Macro '" + name + "' is defined");
     }
 
+    public void setFile(String file) {
+        this.fileName = file;
+    }
+    
     public void setBody(String body, Map<String, PigMacro> seen) {
         this.body = body;
         this.seen = new HashMap<String, PigMacro>(seen);
-        expandBody();
     }
     
     public void addParam(String param) {
@@ -73,39 +76,42 @@ public class PigMacro {
 
     public String getName() { return name; }
 
-    public String getBody() { return body; }
-
-    public List<String> getParams() { return params; }
-
-    public List<String> getReturns() { return rets; }
-
-    public String inline(String[] inputs, String[] outputs) {
-        String in = substituteParams(inputs, outputs);
+    public CommonTree inline(String[] inputs, String[] outputs, int lineNumber,
+            String file) throws ParserException {
+        String in = substituteParams(inputs, outputs, lineNumber, file);
+        
         Set<String> masks = new HashSet<String>();
         if (inputs != null) {
             for (String s : inputs) {
                 masks.add(s);
             }
         }
+        
         for (String s : outputs) {
             masks.add(s);
         }
-        return maskAlias(in, masks);
+ 
+        return maskAlias(in, masks, lineNumber, file);
     }
     
-    public String substituteParams(String[] inputs, String[] outputs) {
+    private String substituteParams(String[] inputs, String[] outputs,
+            int line, String file) throws ParserException {
         if ((inputs == null && !params.isEmpty())
                 || (inputs != null && inputs.length != params.size())) {
-            throw new RuntimeException("Failed to expand macro '" + name
-                    + "': expected number of parameters: " + params.size()
-                    + " actual number of inputs: "
-                    + ((inputs == null) ? 0 : inputs.length));
+            String msg = getErrorMessage(file, line,
+                    "Failed to expand macro '" + name + "'",
+                    "Expected number of parameters: " + params.size()
+                            + " actual number of inputs: "
+                            + ((inputs == null) ? 0 : inputs.length));
+            throw new RuntimeException(msg);
         }
         if (outputs == null || outputs.length != rets.size()) {
-            throw new RuntimeException("Failed to expand macro '" + name
-                    + "': expected number of return aliases: " + rets.size()
-                    + " actual number of return values: "
-                    + ((outputs == null) ? 0 : outputs.length));
+            String msg = getErrorMessage(file, line, "Failed to expand macro '"
+                    + name + "'",
+                    "Expected number of return aliases: " + rets.size()
+                            + " actual number of return values: "
+                            + ((outputs == null) ? 0 : outputs.length));
+            throw new ParserException(msg);
         }
         
         String[] args = new String[params.size() + rets.size()];
@@ -125,66 +131,172 @@ public class PigMacro {
             ParameterSubstitutionPreprocessor psp = new ParameterSubstitutionPreprocessor(
                     50);
             psp.genSubstitutedFile(in, writer, args, null);
-        } catch (ParseException e) {
-            throw new RuntimeException(
-                    "Parameter substitution failed for macro " + name, e);
-        }
+        } catch (Exception e) {
+            // catch both ParserException and RuntimeException
+            String msg = getErrorMessage(file, line,
+                    "Macro inline failed for macro '" + name + "'",
+                    e.getMessage() + "\n Macro content: " + body);
+            throw new ParserException(msg);
+        } 
         
         LOG.debug("--- after substition:\n" + writer.toString());
         
         return writer.toString();
     }
-    
-    public String maskAlias(String in, Set<String> masks) {
-        String resultString = "";
+        
+    private CommonTree maskAlias(String in, Set<String> masks, int line,
+            String file) throws ParserException {
+        CharStream input = null;
         try {
-            CharStream input = new QueryParserStringStream(in);
-            QueryLexer lex = new QueryLexer(input);
-            CommonTokenStream tokens = new  CommonTokenStream(lex);
-
-            QueryParser parser = new QueryParser(tokens);
-            QueryParser.query_return result = parser.query();
-
-            Tree ast = (Tree)result.getTree();
+            // parse macro body into ast 
+            input = new QueryParserStringStream(in);
+        } catch (IOException e) {
+            String msg = getErrorMessage(file, line, "Failed to inline macro '"
+                    + name + "'", e.getMessage() + "\nmacro content: " + in);
+            throw new ParserException(msg);
+        }
+        
+        QueryLexer lex = new QueryLexer(input);
+        CommonTokenStream tokens = new  CommonTokenStream(lex);
             
-            LOG.debug(ast.toStringTree());
-
-            CommonTreeNodeStream nodes = new CommonTreeNodeStream(ast);
-            AliasMasker walker = new AliasMasker(nodes);
-            walker.setParams(masks, name, idx++);
+        QueryParser.query_return result = null;
+        QueryParser parser = QueryParserUtils.createParser(tokens);
+        
+        try {
+            result = parser.query();
+        } catch (RecognitionException e) {
+            String msg = (fileName == null) ? parser.getErrorHeader(e)
+                    : QueryParserUtils.generateErrorHeader(e, fileName);
+            msg += " " + parser.getErrorMessage(e, parser.getTokenNames());
+            String msg2 = getErrorMessage(file, line, "Failed to parse macro '"
+                    + name + "'", msg + "\nmacro content: " + in);
+            throw new ParserException(msg2);
+        }
 
-            walker.query();
+        CommonTree ast = (CommonTree)result.getTree();
+        
+        LOG.debug("AST for macro '" + name + "':\n" + ast.toStringTree());
+            
+        List<CommonTree> macroDefNodes = new ArrayList<CommonTree>();
+        traverseMacro(ast, macroDefNodes, "MACRO_DEF");
+        if (!macroDefNodes.isEmpty()) {
+            String fname = ((PigParserNode)ast).getFileName();
+            String msg = getErrorMessage(fname, ast.getLine(),
+                    "Invalide macro definition", "macro '" + name
+                            + "' contains macro definition.\nmacro content: "
+                            + body);
+            throw new ParserException(msg);
+        }
+         
+        // recursively expand the inline macros
+        List<CommonTree> inlineNodes = new ArrayList<CommonTree>();
+        traverseMacro(ast, inlineNodes, "MACRO_INLINE");
 
-            LOG.debug("--- walk: \n" + walker.getResult());
+        for (CommonTree t : inlineNodes) {
+            CommonTree newTree = macroInline(t,
+                    new ArrayList<PigMacro>(seen.values()));
+            QueryParserUtils.replaceNodeWithNodeList(t, newTree, null);
+        }
+        
+        // mask the aliases in the inlined macro 
+        CommonTreeNodeStream nodes = new CommonTreeNodeStream(ast);
+        AliasMasker walker = new AliasMasker(nodes);
+        walker.setParams(masks, name, idx++);
 
-            resultString = walker.getResult();
-        } catch (Exception e) {
-            throw new RuntimeException(
-                    "Query parsing failed for macro " + name, e);
+        AliasMasker.query_return result2 = null;
+        CommonTree commonTree = null;
+        
+        try {
+            result2 = walker.query();
+        } catch (RecognitionException e) {
+            String msg = walker.getErrorHeader(e) + " "
+                    + walker.getErrorMessage(e, walker.getTokenNames());
+            String msg2 = getErrorMessage(file, line, "Failed to mask macro '"
+                    + name + "'", msg + "\nmacro content: " + in);
+            throw new ParserException(msg2);
         }
+        
+        commonTree = result2.tree;
 
-        return resultString;
+        LOG.debug("AST for masked macro '" + name + "':\n"
+                + commonTree.toStringTree());
+ 
+        return commonTree;
     }
     
-    private void expandBody() {
-        // expand macros
-        boolean done = false;
-        
-        while (!done) {
-            StringReader srd = new StringReader(body);
-            ANTLRReaderStream input;
-            try {
-                input = new ANTLRReaderStream(srd);
-            } catch (IOException e) {
-                throw new RuntimeException("Failed to read ", e);
+    private static void traverseMacro(Tree t, List<CommonTree> nodes,
+            String nodeType) {
+        if (t.getText().equals(nodeType)) {
+            nodes.add((CommonTree) t);
+        }
+        int n = t.getChildCount();
+        for (int i = 0; i < n; i++) {
+            Tree t0 = t.getChild(i);
+            traverseMacro(t0, nodes, nodeType);
+        }
+    }
+     
+    /*
+     * Macro inline nodes have the following form:
+     * 
+     * (MACRO_INLINE <name> (RETURN_VAL <values>) (PARAMS <values>)) 
+     * 
+     * Child nodes:
+     *      0: macro name
+     *      1: list of return values
+     *      2: list of parameters
+     */
+    static CommonTree macroInline(CommonTree t, List<PigMacro> macroDefs)
+            throws ParserException {
+        // get name
+        String mn = t.getChild(0).getText();
+
+        // get macroDef
+        PigMacro macro = null;
+        for (PigMacro pm : macroDefs) {
+            if (pm.getName().equals(mn)) {
+                macro = pm;
+                break;
             }
-            MacroRecursion expander = new MacroRecursion(input);
-            expander.setMacros(seen);
-            Token token = Token.EOF_TOKEN;
-            while ((token = expander.nextToken()) != Token.EOF_TOKEN);
+        }
+
+        String file = ((PigParserNode)t).getFileName();
         
-            body = expander.getResultString();
-            done = !expander.isExpanded();
+        if (macro == null) {
+            String msg = getErrorMessage(file, t.getLine(),
+                    "Cannot expand macro '" + mn + "'",
+                    "Macro must be defined before expansion.");
+            throw new ParserException(msg);
+        }
+
+        // get return values
+        int n = t.getChild(1).getChildCount();
+        String[] rets = new String[n];
+        for (int i = 0; i < n; i++) {
+            rets[i] = t.getChild(1).getChild(i).getText();
+        }
+
+        // get parameters
+        int m = t.getChild(2).getChildCount();
+        String[] params = new String[m];
+        for (int i = 0; i < m; i++) {
+            params[i] = t.getChild(2).getChild(i).getText();
+        }
+
+        return macro.inline(params, rets, t.getLine(), file);
+    }
+  
+    private static String getErrorMessage(String file, int line, String header,
+            String reason) {
+        StringBuilder sb = new StringBuilder();
+        sb.append("<");
+        if (file != null) {
+            sb.append("at ").append(file).append(", ");
+        }
+        sb.append("line ").append(line).append("> ").append(header);
+        if (reason != null) {
+            sb.append(". Reason: ").append(reason);
         }
+        return sb.toString();
     }
 }
diff --git a/src/org/apache/pig/parser/PigParserNode.java b/src/org/apache/pig/parser/PigParserNode.java
new file mode 100644
index 000000000..0f1d3dc52
--- /dev/null
+++ b/src/org/apache/pig/parser/PigParserNode.java
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.parser;
+
+import org.antlr.runtime.Token;
+import org.antlr.runtime.tree.CommonTree;
+import org.antlr.runtime.tree.Tree;
+
+public class PigParserNode extends CommonTree {
+    
+    // the script file this node belongs to
+    private String fileName = null;
+    
+    public PigParserNode(Token t) {
+        super(t);
+    }
+
+    public PigParserNode(PigParserNode node) {
+        super(node);
+        this.setFileName(node.getFileName());
+    }
+
+
+    public Tree dupNode() {
+        return new PigParserNode(this);
+    }
+
+    public void setFileName(String fileName) {
+        this.fileName = fileName;
+    }
+
+    public String getFileName() {
+        return fileName;
+    }
+
+    
+}
diff --git a/src/org/apache/pig/parser/PigParserNodeAdaptor.java b/src/org/apache/pig/parser/PigParserNodeAdaptor.java
new file mode 100644
index 000000000..80aae07e5
--- /dev/null
+++ b/src/org/apache/pig/parser/PigParserNodeAdaptor.java
@@ -0,0 +1,30 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.parser;
+
+import org.antlr.runtime.Token;
+import org.antlr.runtime.tree.CommonTreeAdaptor;
+
+public class PigParserNodeAdaptor extends CommonTreeAdaptor {
+    
+    @Override
+    public Object create(Token t) {
+        return new PigParserNode(t);
+    }
+    
+}
diff --git a/src/org/apache/pig/parser/QueryLexer.g b/src/org/apache/pig/parser/QueryLexer.g
index 07e1b7935..f7edd0c58 100644
--- a/src/org/apache/pig/parser/QueryLexer.g
+++ b/src/org/apache/pig/parser/QueryLexer.g
@@ -57,6 +57,12 @@ public String getErrorHeader(RecognitionException ex) {
 
 } // End of members.
 
+IMPORT  : 'IMPORT'
+;
+
+RETURNS : 'RETURNS'
+;
+
 DEFINE : 'DEFINE'
 ;
 
@@ -389,4 +395,3 @@ MINUS : '-'
 QMARK : '?'
 ;
 
-    
\ No newline at end of file
diff --git a/src/org/apache/pig/parser/QueryParser.g b/src/org/apache/pig/parser/QueryParser.g
index bf48b0c5d..6682e6343 100644
--- a/src/org/apache/pig/parser/QueryParser.g
+++ b/src/org/apache/pig/parser/QueryParser.g
@@ -60,18 +60,29 @@ tokens {
     SCOPED_ALIAS;
     TUPLE_TYPE_CAST;
     BAG_TYPE_CAST;
+    PARAMS;
+    RETURN_VAL;
+    MACRO_DEF;
+    MACRO_BODY;
+    MACRO_INLINE;
 }
 
 @header {
 package org.apache.pig.parser;
 
+import java.util.Set;
+import java.util.HashSet;
+import java.util.Collections;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.pig.parser.PigMacro;
 }
 
 @members {
 private static Log log = LogFactory.getLog( QueryParser.class );
 
+private Set<String> memory = new HashSet<String>();
+
 @Override
 protected Object recoverFromMismatchedToken(IntStream input, int ttype, BitSet follow) 
 throws RecognitionException {
@@ -129,7 +140,15 @@ query : statement*
 statement : SEMI_COLON!
           | general_statement
           | foreach_statement
-          | split_statement          
+          | split_statement  
+          | inline_statement        
+          | import_statement
+;
+
+import_statement : import_clause SEMI_COLON!
+;
+
+inline_statement : inline_clause SEMI_COLON!
 ;
 
 split_statement : split_clause SEMI_COLON!
@@ -155,6 +174,16 @@ foreach_statement : ( alias EQUAL )? foreach_clause_complex SEMI_COLON?
 alias : IDENTIFIER
 ;
 
+parameter 
+    : IDENTIFIER 
+    | INTEGER 
+    | DOUBLENUMBER
+    | QUOTEDSTRING
+;
+
+content : LEFT_CURLY ( content | ~(LEFT_CURLY | RIGHT_CURLY) )* RIGHT_CURLY
+;
+
 op_clause : define_clause 
           | load_clause
           | group_clause
@@ -171,7 +200,38 @@ op_clause : define_clause
           | mr_clause
 ;
 
-define_clause : DEFINE^ alias ( cmd | func_clause )
+macro_param_clause : LEFT_PAREN ( alias (COMMA alias)* )? RIGHT_PAREN
+    -> ^(PARAMS alias*)
+;
+
+macro_return_clause : RETURNS alias (COMMA alias)*
+    -> ^(RETURN_VAL alias+)
+;
+
+macro_body_clause : content
+    -> ^(MACRO_BODY { new PigParserNode(new CommonToken(1, $content.text)) } )
+;
+
+macro_clause : macro_param_clause macro_return_clause macro_body_clause
+    -> ^(MACRO_DEF macro_param_clause macro_return_clause macro_body_clause)
+;
+
+inline_return_clause : alias (COMMA alias)*
+    -> ^(RETURN_VAL alias+)
+;
+
+inline_param_clause : LEFT_PAREN ( parameter (COMMA parameter)* )? RIGHT_PAREN
+    -> ^(PARAMS parameter*)
+;
+
+inline_clause : inline_return_clause EQUAL alias inline_param_clause
+    -> ^(MACRO_INLINE alias inline_return_clause inline_param_clause)
+;
+
+import_clause : IMPORT^ QUOTEDSTRING
+;
+
+define_clause : DEFINE^ alias ( cmd | func_clause | macro_clause)
 ;
 
 cmd : EXECCOMMAND^ ( ship_clause | cache_caluse | input_clause | output_clause | error_clause )*
@@ -516,7 +576,7 @@ nested_limit : LIMIT^ nested_op_input INTEGER
 nested_op_input : col_ref | nested_proj
 ;
 
-stream_clause : STREAM^ rel THROUGH! ( EXECCOMMAND | IDENTIFIER ) as_clause?
+stream_clause : STREAM^ rel THROUGH! ( EXECCOMMAND | alias ) as_clause?
 ;
 
 mr_clause : MAPREDUCE^ QUOTEDSTRING ( LEFT_PAREN! path_list RIGHT_PAREN! )? store_clause load_clause EXECCOMMAND?
@@ -526,8 +586,8 @@ split_clause : SPLIT rel INTO split_branch ( COMMA split_branch )+
             -> ^( SPLIT rel split_branch+ )
 ;
 
-split_branch : IDENTIFIER IF cond
-            -> ^( SPLIT_BRANCH IDENTIFIER cond )
+split_branch : alias IF cond
+            -> ^( SPLIT_BRANCH alias cond )
 ;
 
 col_ref : alias_col_ref | dollar_col_ref
@@ -583,6 +643,8 @@ tuple : LEFT_PAREN ( literal ( COMMA literal )* )? RIGHT_PAREN
 
 // extended identifier, handling the keyword and identifier conflicts. Ugly but there is no other choice.
 eid : rel_str_op
+    | IMPORT
+    | RETURNS
     | DEFINE
     | LOAD
     | FILTER
diff --git a/src/org/apache/pig/parser/QueryParserDriver.java b/src/org/apache/pig/parser/QueryParserDriver.java
index 92ee6d0e5..d191c7107 100644
--- a/src/org/apache/pig/parser/QueryParserDriver.java
+++ b/src/org/apache/pig/parser/QueryParserDriver.java
@@ -18,31 +18,55 @@
 
 package org.apache.pig.parser;
 
+import java.io.BufferedReader;
+import java.io.BufferedWriter;
+import java.io.FileNotFoundException;
+import java.io.FileReader;
+import java.io.FileWriter;
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
 import java.util.Map;
+import java.util.Set;
 
 import org.antlr.runtime.BaseRecognizer;
 import org.antlr.runtime.CharStream;
 import org.antlr.runtime.CommonTokenStream;
 import org.antlr.runtime.RecognitionException;
+import org.antlr.runtime.tree.CommonTree;
 import org.antlr.runtime.tree.CommonTreeNodeStream;
 import org.antlr.runtime.tree.Tree;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.newplan.Operator;
 import org.apache.pig.newplan.logical.relational.LogicalPlan;
+import org.apache.pig.tools.pigstats.ScriptState;
 
 public class QueryParserDriver {
     public static ClassLoader classloader = QueryParserDriver.class.getClassLoader();
     
+    private static final Log LOG = LogFactory.getLog(QueryParserDriver.class);
+    
+    private static final String MACRO_DEF = "MACRO_DEF";
+    private static final String MACRO_INLINE = "MACRO_INLINE";
+    private static final String IMPORT_DEF = "import";
+    
     private PigContext pigContext;
     private String scope;
     private Map<String, String>fileNameMap;
     private Map<String, Operator> operators;
+    private Set<String> importSeen;
+    private Set<String> macroSeen;
     
     public QueryParserDriver(PigContext pigContext, String scope, Map<String, String> fileNameMap) {
         this.pigContext = pigContext;
         this.scope = scope;
         this.fileNameMap = fileNameMap;
+        importSeen = new HashSet<String>();
+        macroSeen = new HashSet<String>();        
     }
 
     public LogicalPlan parse(String query) throws ParserException {
@@ -55,7 +79,9 @@ public class QueryParserDriver {
             ast = parse( tokenStream );
         } catch(RuntimeException ex) {
             throw new ParserException( ex.getMessage() );
-        }
+        }          
+         
+        ast = expandMacro(ast);
 
         try{       
             ast = validateAst( ast );
@@ -76,6 +102,44 @@ public class QueryParserDriver {
         return plan;
     }
     
+    public boolean dryrun(String scriptFile) throws ParserException, IOException, RecognitionException {
+        BufferedReader rd = new BufferedReader(new FileReader(scriptFile));
+        StringBuilder sb = new StringBuilder();
+        String line = rd.readLine();
+        while (line != null) {
+            sb.append(line).append("\n");
+            line = rd.readLine();
+        }
+        
+        CommonTokenStream tokenStream = tokenize(sb.toString());
+        Tree ast = null;
+            
+        try {
+            ast = parse( tokenStream );
+        } catch(RuntimeException ex) {
+            throw new ParserException( ex.getMessage() );
+        }          
+        
+        List<CommonTree> importNodes = new ArrayList<CommonTree>();
+        List<CommonTree> macroNodes = new ArrayList<CommonTree>();
+        List<CommonTree> inlineNodes = new ArrayList<CommonTree>();
+        
+        traverseImport(ast, importNodes);
+        traverse(ast, macroNodes, inlineNodes);
+        
+        if (importNodes.isEmpty() && macroNodes.isEmpty()
+                && inlineNodes.isEmpty()) {
+            return false;
+        }
+
+        ast = expandMacro(ast);
+
+        String expandedFile = scriptFile.replace(".substituted", ".expanded");
+        dryrun(ast, expandedFile);
+        
+        return true;
+    }
+    
     public Map<String, Operator> getOperators() {
         return operators;
     }
@@ -83,39 +147,52 @@ public class QueryParserDriver {
     private static CommonTokenStream tokenize(String query) throws ParserException {
         CharStream input;
         try {
-            input = new QueryParserStringStream( query );
-        } catch(IOException ex) {
-            throw new ParserException( "Unexpected IOException: " + ex.getMessage() );
+            input = new QueryParserStringStream(query);
+        } catch (IOException ex) {
+            throw new ParserException("Unexpected IOException: "
+                    + ex.getMessage());
         }
-        QueryLexer lexer = new QueryLexer( input );
-        CommonTokenStream tokens = new CommonTokenStream( lexer );
-        checkError( lexer );
+        QueryLexer lexer = new QueryLexer(input);
+        CommonTokenStream tokens = new CommonTokenStream(lexer);
+        checkError(lexer);
         return tokens;
     }
     
-    private static void checkError(BaseRecognizer recognizer) throws ParserException {
+    private static void checkError(BaseRecognizer recognizer)
+            throws ParserException {
         int errorCount = recognizer.getNumberOfSyntaxErrors();
-        if( 0 < errorCount )
-            throw new ParserException( "Encountered " + errorCount + " parsing errors in the query" );
+        if (0 < errorCount)
+            throw new ParserException("Encountered " + errorCount
+                    + " parsing errors in the query");
     }
 
-    private static Tree parse(CommonTokenStream tokens) throws ParserException  {
-        QueryParser parser = new QueryParser( tokens );
-      
+    private static Tree parse(CommonTokenStream tokens) throws ParserException {
+        QueryParser parser = QueryParserUtils.createParser(tokens);
+
         QueryParser.query_return result = null;
         try {
             result = parser.query();
         } catch (RecognitionException e) {
-            String msg = parser.getErrorHeader(e) + " " + parser.getErrorMessage(e, parser.getTokenNames() );
-            throw new ParserException( msg );
+            String msg = parser.getErrorHeader(e) + " "
+                    + parser.getErrorMessage(e, parser.getTokenNames());
+            throw new ParserException(msg);
         }
-        
-        Tree ast = (Tree)result.getTree();
-        checkError( parser );
-        
+
+        Tree ast = (Tree) result.getTree();
+        checkError(parser);
+
         return ast;
     }
     
+    private static void dryrun(Tree ast, String scriptFile) throws RecognitionException, IOException {
+        CommonTreeNodeStream nodes = new CommonTreeNodeStream( ast );
+        AstPrinter walker = new AstPrinter( nodes );
+        walker.query();
+        BufferedWriter fw = new BufferedWriter(new FileWriter(scriptFile));
+        fw.append(walker.getResult());
+        fw.close();
+    }
+    
     private static Tree validateAst(Tree ast) throws RecognitionException, ParserException {
         CommonTreeNodeStream nodes = new CommonTreeNodeStream( ast );
         AstValidator walker = new AstValidator( nodes );
@@ -126,5 +203,232 @@ public class QueryParserDriver {
         
         return newAst;
     }
+    
+    private Tree expandMacro(Tree ast) throws ParserException {
+        LOG.debug("Original macro AST:\n" + ast.toStringTree() + "\n");
+
+        ScriptState ss = ScriptState.get();
+        if (ss != null) {
+            QueryParserUtils.recursiveSetFileName((PigParserNode) ast,
+                    ss.getFileName());
+        }
+        
+        // first insert the import files
+        while (expandImport(ast))
+            ;
+
+        LOG.debug("macro AST after import:\n" + ast.toStringTree() + "\n");
+
+        List<CommonTree> macroNodes = new ArrayList<CommonTree>();
+        List<CommonTree> inlineNodes = new ArrayList<CommonTree>();
+
+        // find all macro def/inline nodes
+        traverse(ast, macroNodes, inlineNodes);
+
+        Map<String, PigMacro> seen = new HashMap<String, PigMacro>();
+        List<PigMacro> macroDefs = new ArrayList<PigMacro>();
+
+        // gether all the def nodes
+        for (CommonTree t : macroNodes) {
+            macroDefs.add(makeMacroDef(t, seen));
+        }
+
+        // inline macros
+        inlineMacro(inlineNodes, macroDefs);
+
+        LOG.debug("Resulting macro AST:\n" + ast.toStringTree() + "\n");
+
+        return ast;
+    }
+     
+    private void inlineMacro(List<CommonTree> inlineNodes,
+            List<PigMacro> macroDefs) throws ParserException {
+        for (CommonTree t : inlineNodes) {
+            CommonTree newTree = PigMacro.macroInline(t, macroDefs);
+            
+            List<CommonTree> nodes = new ArrayList<CommonTree>();
+            traverseInline(newTree, nodes);
+   
+            if (nodes.isEmpty()) {
+                QueryParserUtils.replaceNodeWithNodeList(t, newTree, null);
+            } else {
+                inlineMacro(nodes, macroDefs);
+            }
+        }
+    }
+    
+    private void traverseInline(Tree t, List<CommonTree> nodes) {
+        if (t.getText().equals(MACRO_INLINE)) {
+            nodes.add((CommonTree)t);
+        }
+        int n = t.getChildCount();
+        for (int i = 0; i < n; i++) {
+            Tree t0 = t.getChild(i);
+            traverseInline(t0, nodes);
+        }       
+    }
+    
+    private boolean expandImport(Tree ast) throws ParserException {
+        List<CommonTree> nodes = new ArrayList<CommonTree>();
+        traverseImport(ast, nodes);
+        if (nodes.isEmpty()) return false;
+        
+        for (CommonTree t : nodes) {
+            macroImport(t);
+        }
+        
+        return true;
+    }
+    
+    private void traverseImport(Tree t, List<CommonTree> nodes) {
+        if (t.getText().equalsIgnoreCase(IMPORT_DEF)) {
+            nodes.add((CommonTree)t);
+        }
+        int n = t.getChildCount();
+        for (int i = 0; i < n; i++) {
+            Tree t0 = t.getChild(i);
+            traverseImport(t0, nodes);
+        }
+    }
+    
+    private void traverse(Tree t, List<CommonTree> macroNodes,
+            List<CommonTree> inlineNodes) {
+        if (t.getText().equals(MACRO_DEF)) {
+            macroNodes.add((CommonTree) t.getParent());  
+        } else if (t.getText().equals(MACRO_INLINE)) {
+            inlineNodes.add((CommonTree) t);
+        }
+        int n = t.getChildCount();
+        for (int i = 0; i < n; i++) {
+            Tree t0 = t.getChild(i);
+            traverse(t0, macroNodes, inlineNodes);
+        }
+    }
+    
+    /*
+     * MacroDef node has two child nodes:
+     *      1. name
+     *      2. MACRO_DEF (PARAMS, RETURN_VAL, MACRO_BODY)
+     */
+    private PigMacro makeMacroDef(CommonTree t, Map<String, PigMacro> seen)
+            throws ParserException {
+        String mn = t.getChild(0).getText();
+ 
+        if (!macroSeen.add(mn)) {
+            String msg = getErrorMessage(null, t,
+                    "Duplicated macro name '" + mn + "'", null);
+            throw new ParserException(msg);
+        }
+
+        if (seen != null) {
+            for (String s : seen.keySet()) {
+                macroSeen.add(s);
+            }
+        }
+        
+        PigMacro pm = new PigMacro(mn);
+        
+        String fname = ((PigParserNode)t).getFileName();
+        pm.setFile(fname);
+
+        Tree defNode = t.getChild(1);
+
+        // get parameter markers
+        Tree paramNode = defNode.getChild(0);
+        int n = paramNode.getChildCount();
+        for (int i = 0; i < n; i++) {
+            pm.addParam(paramNode.getChild(i).getText());
+        }
+
+        // get return alias markers
+        Tree retNode = defNode.getChild(1);
+        int m = retNode.getChildCount();
+        for (int i = 0; i < m; i++) {
+            pm.addReturn(retNode.getChild(i).getText());
+        }
+
+        // get macro body
+        Tree bodyNode = defNode.getChild(2);
+        String body = bodyNode.getChild(0).getText();
+
+        body = body.substring(1, body.length() - 1);
+
+        pm.setBody(body, seen);
+
+        seen.put(mn, pm);
 
+        // delete this node
+        Tree defineNode = t.getParent();
+        Tree stmtNode = defineNode.getParent();
+        stmtNode.deleteChild(defineNode.getChildIndex());
+
+        return pm;
+    }
+        
+    private void macroImport(CommonTree t) throws ParserException {
+        // remove quote
+        String fname = t.getChild(0).getText();
+        fname = QueryParserUtils.removeQuotes(fname);
+        if (!importSeen.add(fname)) {
+            String msg = getErrorMessage(fname, t,
+                    ": Duplicated import file '" + fname + "'", null);
+            throw new ParserException(msg);
+        }
+        
+        
+        BufferedReader in = null;
+        try {
+            in = QueryParserUtils.getImportScriptAsReader(fname);
+        } catch (FileNotFoundException e) {
+            String msg = getErrorMessage(fname, t,
+                    "Failed to import file '" + fname + "'", e.getMessage());
+            throw new ParserException(msg);
+        }
+        
+        StringBuilder sb = new StringBuilder();
+        String line = null;
+        try {
+            line = in.readLine();
+            while (line != null) {
+                sb.append(line).append("\n");
+                line = in.readLine();
+            }
+        } catch (IOException e) {
+            String msg = getErrorMessage(fname, t,
+                    "Failed to read file '" + fname + "'", e.getMessage());
+            throw new ParserException(msg);
+        }
+        
+        // parse
+        CommonTokenStream tokenStream = tokenize(sb.toString());
+        
+        Tree ast = null;
+        try {
+            ast = parse( tokenStream );
+        } catch(RuntimeException ex) {
+            throw new ParserException( ex.getMessage() );
+        } 
+        
+        QueryParserUtils.replaceNodeWithNodeList(t, (CommonTree)ast, fname);
+    }
+    
+    private String getErrorMessage(String importFile,
+            CommonTree t, String header, String reason) {
+        StringBuilder sb = new StringBuilder();
+        PigParserNode node = (PigParserNode)t;
+        String file = node.getFileName();
+        sb.append("<");
+        if (file == null) {
+            ScriptState ss = ScriptState.get();
+            if (ss != null) file = ss.getFileName();
+        }
+        if (file != null && !file.equals(importFile)) {
+            sb.append("at ").append(file).append(", ");
+        }
+        sb.append("line ").append(t.getLine()).append("> ").append(header);
+        if (reason != null) {
+            sb.append(". Reason: ").append(reason);
+        }
+        return sb.toString();
+    }
 }
diff --git a/src/org/apache/pig/parser/QueryParserUtils.java b/src/org/apache/pig/parser/QueryParserUtils.java
index 4b36b3491..d179b2b8d 100644
--- a/src/org/apache/pig/parser/QueryParserUtils.java
+++ b/src/org/apache/pig/parser/QueryParserUtils.java
@@ -18,12 +18,21 @@
 
 package org.apache.pig.parser;
 
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileReader;
 import java.io.IOException;
 import java.net.URI;
 import java.net.URISyntaxException;
+import java.util.ArrayList;
 import java.util.HashSet;
+import java.util.List;
 import java.util.Set;
 
+import org.antlr.runtime.tree.CommonTree;
+import org.antlr.runtime.tree.Tree;
+import org.antlr.runtime.CommonTokenStream;
 import org.antlr.runtime.RecognitionException;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -40,11 +49,12 @@ import org.apache.pig.impl.logicalLayer.FrontendException;
 import org.apache.pig.newplan.Operator;
 import org.apache.pig.newplan.logical.relational.LOStore;
 import org.apache.pig.newplan.logical.relational.LogicalPlan;
+import org.apache.pig.tools.pigstats.ScriptState;
 
 public class QueryParserUtils {
     private static Log log = LogFactory.getLog( LogicalPlanGenerator.class );
 
-    private static String removeQuotes(String str) {
+	public static String removeQuotes(String str) {
         if (str.startsWith("\u005c'") && str.endsWith("\u005c'"))
             return str.substring(1, str.length() - 1);
         else
@@ -164,4 +174,84 @@ public class QueryParserUtils {
          return "<line " + ex.line +", column " + ex.charPositionInLine + ">";
      }
 
+    static String generateErrorHeader(RecognitionException ex, String fname) {
+        StringBuilder sb = new StringBuilder();
+        sb.append("<At ").append(fname).append(", line ")
+                .append(ex.line).append(", column ")
+                .append(ex.charPositionInLine).append(">");
+        return sb.toString();
+    }
+    
+    @SuppressWarnings({ "unchecked", "rawtypes" })
+    static void replaceNodeWithNodeList(Tree oldNode, CommonTree newTree,
+            String fileName) {
+        int idx = oldNode.getChildIndex();
+
+        CommonTree parent = (CommonTree) oldNode.getParent();
+        int count = parent.getChildCount();
+
+        List childList = new ArrayList(parent.getChildren());
+        List macroList = newTree.getChildren();
+        
+        // set file name
+        for (Object obj : macroList) {
+            PigParserNode node = (PigParserNode)obj;
+            recursiveSetFileName(node, fileName);
+        }
+
+        while (parent.getChildCount() > 0) {
+            parent.deleteChild(0);
+        }
+
+        for (int i = 0; i < count; i++) {
+            if (i == idx) {
+                parent.addChildren(macroList);
+            } else {
+                parent.addChild((Tree) childList.get(i));
+            }
+        }
+    }
+
+    static void recursiveSetFileName(PigParserNode node, String fname) {
+        int n = node.getChildCount();
+        for (int i = 0; i < n; i++) {
+            Tree t = node.getChild(i);
+            recursiveSetFileName((PigParserNode)t, fname);
+        }
+        node.setFileName(fname);
+    }
+
+    static BufferedReader getImportScriptAsReader(String scriptPath)
+            throws FileNotFoundException {
+        File f = new File(scriptPath);
+        if (f.exists() || f.isAbsolute() || scriptPath.startsWith("./")
+                || scriptPath.startsWith("../")) {
+            return new BufferedReader(new FileReader(f));
+        }
+
+        ScriptState state = ScriptState.get();
+        if (state != null && state.getPigContext() != null) {
+            String srchPath = state.getPigContext().getProperties()
+                    .getProperty("pig.import.search.path");
+            if (srchPath != null) {
+                String[] paths = srchPath.split(",");
+                for (String path : paths) {
+                    File f1 = new File(path + File.separator + scriptPath);
+                    if (f1.exists()) {
+                        return new BufferedReader(new FileReader(f1));
+                    }
+                }
+            }
+        }
+
+        throw new FileNotFoundException("Can't find the Specified file "
+                + scriptPath);
+    }
+    
+    static QueryParser createParser(CommonTokenStream tokens) {
+        QueryParser parser = new QueryParser(tokens);
+        PigParserNodeAdaptor adaptor = new PigParserNodeAdaptor();
+        parser.setTreeAdaptor(adaptor);
+        return parser;
+    }
 }
diff --git a/src/org/apache/pig/scripting/Pig.java b/src/org/apache/pig/scripting/Pig.java
index 9f732102b..6f02927bd 100644
--- a/src/org/apache/pig/scripting/Pig.java
+++ b/src/org/apache/pig/scripting/Pig.java
@@ -33,7 +33,6 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.fs.FsShell;
 import org.apache.pig.PigServer;
 import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
-import org.apache.pig.parser.ParserUtil;
 import org.apache.pig.tools.parameters.ParameterSubstitutionPreprocessor;
 
 /**
@@ -158,10 +157,7 @@ public class Pig {
         ScriptPigContext ctx = getScriptContext();
         StringBuilder sb = new StringBuilder();
         sb.append(getRegisterScriptUDFClauses()).append(getDefineClauses());
-        
-        StringReader rd = new StringReader(pl);
-        String newPl = ParserUtil.expandMacros(rd);
-        sb.append(newPl).append("\n");
+        sb.append(pl).append("\n");
         return new Pig(sb.toString(), ctx, name);
     }
 
diff --git a/src/org/apache/pig/tools/parameters/PigFileParser.jj b/src/org/apache/pig/tools/parameters/PigFileParser.jj
index c5c4cb5a9..495221806 100644
--- a/src/org/apache/pig/tools/parameters/PigFileParser.jj
+++ b/src/org/apache/pig/tools/parameters/PigFileParser.jj
@@ -37,6 +37,7 @@ package org.apache.pig.tools.parameters;
 import java.io.IOException;
 import java.io.PrintWriter;
 import java.util.Hashtable;
+import java.util.Stack;
 import java.io.Writer;
 import java.lang.StringBuilder;
 
@@ -67,11 +68,168 @@ public class PigFileParser {
 
 PARSER_END(PigFileParser)
 
+
+TOKEN_MGR_DECLS : {
+    int pigBlockLevel = 0;
+    int funcBlockLevel = 0;
+    int tupleSchemaLevel = 0;
+    int bagSchemaLevel = 0;
+    int bagConstantLevel = 0;
+    int prevState = DEFAULT;
+
+    Stack<Integer> stack = new Stack<Integer>();
+
+    public int getState(int state) {
+        if(!stack.empty()) return stack.pop();
+        return state;
+    }
+
+    public void saveState(int state) {
+        stack.push(state);
+    }
+
+}
+
+<DEFAULT> MORE :
+{
+    <"define" (<WS>)+ <IDENTIFIER> (<WS>)* "(" > : PIG_START
+}
+
+<PIG_START> MORE :
+{
+    <"'"> {prevState = PIG_START;} : IN_STRING
+|   <"`"> {prevState = PIG_START;} : IN_COMMAND
+|   <(" " | "\t")+["A","a"]["S","s"](" " | "\t")+ > {prevState = PIG_START;} : SCHEMA_DEFINITION
+|   <(" " | "\t")+["G","g"]["E","e"]["N","n"]["E","e"]["R","r"]["A","a"]["T","t"]["E","e"](" " | "\t")+ > {prevState = PIG_START;} : GENERATE
+|   <"{"> {pigBlockLevel = 1;} : IN_BLOCK
+|   <"}"> {if (true) throw new TokenMgrError("Unmatched '}'", TokenMgrError.LEXICAL_ERROR);}
+|   <";"> : PIG_END
+|   <"--"> {prevState = PIG_START;} : SINGLE_LINE_COMMENT
+|   <"/*"> {prevState = PIG_START;} : MULTI_LINE_COMMENT
+|   <("\n" | "\r" | "\r\n")> 
+|   <(~[])> 
+}
+
+<SINGLE_LINE_COMMENT> MORE :
+{
+    <("\n" | "\r" | "\r\n")> {SwitchTo(prevState);}
+|   <(~[])>
+}
+
+<MULTI_LINE_COMMENT> MORE :
+{
+    <"*/"> {SwitchTo(prevState);}
+|   <("\n" | "\r" | "\r\n")> 
+|   <(~[])>
+}
+
+<IN_STRING> MORE :
+{
+    <"\\'">
+|   <"'"> { SwitchTo(prevState);}
+|   <("\n" | "\r" | "\r\n")> 
+|   <(~[])>
+}
+
+<IN_COMMAND> MORE :
+{
+    <"\\`">
+|   <"`"> { SwitchTo(prevState);}
+|   <("\n" | "\r" | "\r\n")> 
+|   <(~[])>
+}
+
+<GENERATE> MORE :
+{
+    <"{"> 
+    {
+        bagConstantLevel++; 
+        prevState = getState(prevState);
+        saveState(prevState);
+        prevState = GENERATE;
+    } : BAG_CONSTANT
+|   <(" " | "\t")+["A","a"]["S","s"](" " | "\t")+> 
+    {
+        prevState = getState(prevState);
+        saveState(prevState);
+        prevState = GENERATE; 
+     } : SCHEMA_DEFINITION
+|   <";"> 
+    {
+        prevState = getState(prevState);
+        if(prevState == PIG_START) {
+            input_stream.backup(1);
+            image.deleteCharAt(image.length()-1);
+        }
+        SwitchTo(prevState);
+    }
+|   <("\n" | "\r" | "\r\n")> 
+|   <(~[])> 
+}
+
+<SCHEMA_DEFINITION> MORE :
+{
+    <"("> {tupleSchemaLevel++;}
+|   <")"> {tupleSchemaLevel--; if ((tupleSchemaLevel == 0) && (bagSchemaLevel == 0)) SwitchTo(prevState); }
+|   <"{"> {bagSchemaLevel++;}
+|   <"}"> {bagSchemaLevel--; if ((tupleSchemaLevel == 0) && (bagSchemaLevel == 0)) SwitchTo(prevState); }
+|   <("," | ";" )> 
+    {
+        if ((tupleSchemaLevel == 0) && (bagSchemaLevel == 0)) {
+            input_stream.backup(1);
+            image.deleteCharAt(image.length()-1);
+            SwitchTo(prevState);
+        }
+    }
+|   <("\n" | "\r" | "\r\n")> 
+|   <(~[])>
+}
+
+<BAG_CONSTANT> MORE :
+{
+    <"{"> {bagConstantLevel++;}
+|   <"}"> {bagConstantLevel--; if (bagConstantLevel == 0) SwitchTo(prevState);}
+|   <("\n" | "\r" | "\r\n")> 
+|   <(~[])>
+}
+
+<IN_BLOCK> MORE :
+{
+    <"\""> {prevState = IN_BLOCK;} : IN_DOUBLE_QUOTED_STRING
+|   <(" " | "\t")+["A","a"]["S","s"](" " | "\t")+ > {prevState = IN_BLOCK;} : SCHEMA_DEFINITION
+|   <(" " | "\t")+["G","g"]["E","e"]["N","n"]["E","e"]["R","r"]["A","a"]["T","t"]["E","e"](" " | "\t")+> {prevState = IN_BLOCK;} : GENERATE
+|   <"{"> {pigBlockLevel++;}
+|       <"}"(";")?> {pigBlockLevel--; if (pigBlockLevel == 0) SwitchTo(PIG_END);}
+|   <"'"> {prevState = IN_BLOCK;} : IN_STRING
+|   <"`"> {prevState = IN_BLOCK;} : IN_COMMAND
+|   <"--"> {prevState = IN_BLOCK;} : SINGLE_LINE_COMMENT
+|   <"/*"> {prevState = IN_BLOCK;} : MULTI_LINE_COMMENT
+|   <("\n" | "\r" | "\r\n")> 
+|       <(~[])>
+}
+
+<IN_DOUBLE_QUOTED_STRING> MORE :
+{
+    <"\\\"">
+|   <"\""> { SwitchTo(prevState);}
+|   <("\n" | "\r" | "\r\n")>
+|   <(~[])>
+}
+
+<PIG_END> TOKEN :
+{
+    <PIG: ""> {
+        matchedToken.image = image.toString();
+    }: DEFAULT
+}
+
 TOKEN : 
 {
     <NEWLINE: "\n" | "\r">
     |    
     <SPACE: " " | "\t">
+    |
+    <WS: "\n" | "\r" | " " | "\t">
 }
 
 // comments(single line and multi-line)
@@ -132,7 +290,12 @@ void input() throws IOException  :
     Token strTok;
 }
 {
-
+    strTok = <PIG>
+    {
+        //System.out.println("Pig image: \n" + strTok.image); 
+        out.append(strTok.image );
+    }
+    |
     <DECLARE> 
     (
         param_value(true) // overwrite=true
@@ -167,9 +330,9 @@ void param_value(boolean overwrite) throws IOException:
     Token strTok;
 }
 {
-    (ignore_toks_nonewline())*         
+    (ignore_toks_nonewline())*
     id=<IDENTIFIER>
-    (ignore_toks_nonewline())*               
+    (ignore_toks_nonewline())*
         (
             s=others() (ignore_toks_nonewline())* write_newline() { pc.processOrdLine(id.image , s, overwrite);}
             |
@@ -247,7 +410,7 @@ String paramString() throws IOException :
     str = others()
     {
         return str;
-    }    
+    }
     |
     t=<LITERAL>
     {
@@ -257,7 +420,7 @@ String paramString() throws IOException :
     t = <SHELLCMD>{}
     {
         return t.image;
-    }    
+    }
 }
 
 // write the newlines,spaces and comments to preserve formatting
diff --git a/src/org/apache/pig/tools/pigscript/parser/PigScriptParser.jj b/src/org/apache/pig/tools/pigscript/parser/PigScriptParser.jj
index a26bea9a7..4f847ac2f 100644
--- a/src/org/apache/pig/tools/pigscript/parser/PigScriptParser.jj
+++ b/src/org/apache/pig/tools/pigscript/parser/PigScriptParser.jj
@@ -174,7 +174,7 @@ TOKEN: {<BRIEF: "-brief">}
 TOKEN: {<SCRIPT_DONE: "scriptDone">}
 
 // Define pig command as 
-// (1) Starting with "split"/"define"/"store" or assignment (A=) followed by
+// (1) Starting with "split"/"define"/"store"/"import" or assignment (A=) or multi-assignment (A, B, ...=) followed by
 // (2) Single statement followed by ; and newline or
 // (3) Block of statements enclosed in
 
@@ -214,7 +214,9 @@ TOKEN_MGR_DECLS : {
     <"split"> : PIG_START
 |   <"define"> : PIG_START
 |	<"store"> : PIG_START
+|	<"import"> : PIG_START
 | 	<(["a"-"z", "A"-"Z"])+(["a"-"z", "A"-"Z"] | ["0"-"9"] | "_")*(" " | "\t")*"="> : PIG_START
+| 	< <IDENTIFIER> (" " | "\t")* ("," (" " | "\t")* <IDENTIFIER> )* (" " | "\t")* "="> : PIG_START
 }
 
 <PIG_START> MORE :
diff --git a/src/org/apache/pig/tools/pigstats/ScriptState.java b/src/org/apache/pig/tools/pigstats/ScriptState.java
index d6c8a04b5..fb7cabe9d 100644
--- a/src/org/apache/pig/tools/pigstats/ScriptState.java
+++ b/src/org/apache/pig/tools/pigstats/ScriptState.java
@@ -172,6 +172,7 @@ public class ScriptState {
     
     private String script;
     private String commandLine;
+    private String fileName;
     
     private String pigVersion;
     private String hodoopVersion;
@@ -367,6 +368,12 @@ public class ScriptState {
         return (pigVersion == null) ? "" : pigVersion;
     }
         
+    public String getFileName() { return fileName; }
+    
+    public void setFileName(String fileName) {
+        this.fileName = fileName;
+    }
+    
     String getId() { return id; }
         
     private String getCommandLine() {
diff --git a/test/org/apache/pig/parser/ParserTestingUtils.java b/test/org/apache/pig/parser/ParserTestingUtils.java
index f9ccf3c55..a14ed1e48 100644
--- a/test/org/apache/pig/parser/ParserTestingUtils.java
+++ b/test/org/apache/pig/parser/ParserTestingUtils.java
@@ -40,7 +40,7 @@ public class ParserTestingUtils {
 
     public static Tree parse(String query) throws IOException, RecognitionException, ParsingFailureException  {
         CommonTokenStream tokens = tokenize( query );
-        QueryParser parser = new QueryParser( tokens );
+        QueryParser parser = QueryParserUtils.createParser( tokens );
         QueryParser.query_return result = parser.query();
         Tree ast = (Tree)result.getTree();
         TreePrinter.printTree( (CommonTree)ast, 0 );
diff --git a/test/org/apache/pig/parser/TestAstValidator.java b/test/org/apache/pig/parser/TestAstValidator.java
index 41c563d5b..03e5dc8e4 100644
--- a/test/org/apache/pig/parser/TestAstValidator.java
+++ b/test/org/apache/pig/parser/TestAstValidator.java
@@ -41,7 +41,7 @@ public class TestAstValidator {
         QueryLexer lex = new QueryLexer(input);
         CommonTokenStream tokens = new  CommonTokenStream(lex);
 
-        QueryParser parser = new QueryParser(tokens);
+        QueryParser parser = QueryParserUtils.createParser(tokens);
         QueryParser.query_return result = parser.query();
 
         Tree ast = (Tree)result.getTree();
diff --git a/test/org/apache/pig/parser/TestQueryParser.java b/test/org/apache/pig/parser/TestQueryParser.java
index 8deb1a84d..0ba753171 100644
--- a/test/org/apache/pig/parser/TestQueryParser.java
+++ b/test/org/apache/pig/parser/TestQueryParser.java
@@ -269,7 +269,7 @@ public class TestQueryParser {
         QueryLexer lexer = new QueryLexer(input);
         CommonTokenStream tokens = new  CommonTokenStream(lexer);
 
-        QueryParser parser = new QueryParser(tokens);
+        QueryParser parser = QueryParserUtils.createParser(tokens);
         QueryParser.query_return result = parser.query();
 
         Tree ast = (Tree)result.getTree();
diff --git a/test/org/apache/pig/test/TestMacroExpansion.java b/test/org/apache/pig/test/TestMacroExpansion.java
index 26106cec5..b8639bf34 100644
--- a/test/org/apache/pig/test/TestMacroExpansion.java
+++ b/test/org/apache/pig/test/TestMacroExpansion.java
@@ -18,37 +18,42 @@
 
 package org.apache.pig.test;
 
-
 import static org.junit.Assert.assertTrue;
 
 import java.io.BufferedReader;
 import java.io.File;
+import java.io.FileReader;
 import java.io.FileWriter;
-import java.io.StringReader;
-import java.util.Properties;
-
-import junit.framework.Assert;
 
-import org.apache.pig.ExecType;
 import org.apache.pig.PigRunner;
-import org.apache.pig.impl.PigContext;
-import org.apache.pig.parser.NonProjectExpressionException;
-import org.apache.pig.parser.ParserTestingUtils;
-import org.apache.pig.parser.ParserUtil;
-import org.apache.pig.tools.grunt.Grunt;
 import org.apache.pig.tools.pigstats.PigStats;
 import org.junit.After;
 import org.junit.AfterClass;
+import org.junit.Assert;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 public class TestMacroExpansion {
-
+    
     private static final MiniCluster cluster = MiniCluster.buildCluster();
     
+    static File command;
+    
     @BeforeClass
     public static void setUpBeforeClass() throws Exception {
+        // Perl script 
+        String[] script = 
+            new String[] {
+                          "#!/usr/bin/perl",
+                          "open(INFILE,  $ARGV[0]) or die \"Can't open \".$ARGV[0].\"!: $!\";",
+                          "while (<INFILE>) {",
+                          "  chomp $_;",
+                          "  print STDOUT \"$_\n\";",
+                          "  print STDERR \"STDERR: $_\n\";",
+                          "}",
+                         };
+        command = Util.createInputFile("script", "pl", script);
     }
 
     @AfterClass
@@ -65,7 +70,7 @@ public class TestMacroExpansion {
     }
     
     @Test 
-    public void firstTest() throws Throwable {
+    public void firstTest() throws Exception {
         String macro = "define group_and_count (A,group_key) returns B {\n" +
             "    D = group $A by $group_key partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 50;\n" +
             "    $B = foreach D generate group, COUNT($A);\n" +
@@ -77,26 +82,21 @@ public class TestMacroExpansion {
             "delta = group_and_count (alpha, age);\n" +
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
-        
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
+                
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "macro_group_and_count_D_0 = group alpha by (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 50;\n" +
-            "gamma = foreach macro_group_and_count_D_0 generate group, COUNT(alpha);\n\n" +
+            "gamma = foreach macro_group_and_count_D_0 generate group, COUNT(alpha);\n" +
             "macro_group_and_count_D_1 = group alpha by (age) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 50;\n" +
-            "delta = foreach macro_group_and_count_D_1 generate group, COUNT(alpha);\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
-
-        Assert.assertEquals(expected, s);
+            "delta = foreach macro_group_and_count_D_1 generate group, COUNT(alpha);\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
+        
+        verify(macro + script, expected);
     }
     
     @Test
-    public void distinctTest() throws Throwable {
+    public void distinctTest() throws Exception {
         String macro = "define group_and_count (A,group_key, reducers) returns B {\n" +
             "    $B = distinct $A partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "};\n";
@@ -108,23 +108,18 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
-        String expected = 
-            "\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n\n" +
-            "delta = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 32;\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
+        String expected =
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n" +
+            "delta = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 32;\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }   
     
     @Test
-    public void limitTest() throws Throwable {
+    public void limitTest() throws Exception {
         String macro = "define group_and_count (A,group_key, size) returns B {\n" +
             "    $B = limit $A $size;\n" +
             "};\n";
@@ -136,23 +131,18 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = limit alpha 20;\n\n" +
-            "delta = limit alpha 39;\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = limit alpha 20;\n" +
+            "delta = limit alpha 39;\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }   
     
     @Test
-    public void sampleTest() throws Throwable {
+    public void sampleTest() throws Exception {
         String macro = "define group_and_count (A, rate) returns B {\n" +
             "    $B = sample $A $rate;\n" +
             "};\n";
@@ -164,23 +154,18 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
-        String expected = 
-            "\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = sample alpha 0.01;\n\n" +
-            "delta = sample alpha 0.002;\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
+        String expected =
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = sample alpha 0.01;\n" +
+            "delta = sample alpha 0.002;\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void orderbyTest() throws Throwable {
+    public void orderbyTest() throws Exception {
         String macro = "define group_and_count (A,f1,f2) returns B {\n" +
             "    $B = ORDER $A BY $f1 ASC, $f2 DESC PARALLEL 3;\n" +
             "    C = ORDER $A BY * ASC PARALLEL 3;\n" +
@@ -193,25 +178,20 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "gamma = ORDER alpha BY user ASC, age DESC PARALLEL 3;\n" +
-            "macro_group_and_count_C_0 = ORDER alpha BY * ASC PARALLEL 3;\n\n" +
+            "macro_group_and_count_C_0 = ORDER alpha BY * ASC PARALLEL 3;\n" +
             "delta = ORDER alpha BY age ASC, zip DESC PARALLEL 3;\n" +
-            "macro_group_and_count_C_1 = ORDER alpha BY * ASC PARALLEL 3;\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
+            "macro_group_and_count_C_1 = ORDER alpha BY * ASC PARALLEL 3;\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void crossTest() throws Throwable {
+    public void crossTest() throws Exception {
         String macro = "define group_and_count (A,C) returns B {\n" +
             "    $B = CROSS $A, $C partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
             "};\n";
@@ -224,24 +204,19 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "beta = load 'links' as (user, page, view);\n" +
-            "gamma = CROSS alpha, beta partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n\n" +
-            "delta = CROSS beta, alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
+            "gamma = CROSS alpha, beta partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
+            "delta = CROSS beta, alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void loadTest() throws Throwable {
+    public void loadTest() throws Exception {
         String macro = "define group_and_count (path) returns B {\n" +
             "    D = load 'myfile.txt' using PigStorage('\t') AS (name:chararray, age:int, gpa:float);\n" +   
             "    $B = load '$path' using PigStorage('\t') AS (F:tuple(f1:int,f2:int,f3:int),T:tuple(t1:chararray,t2:int));\n" +
@@ -255,28 +230,23 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-                
-        String expected =
-            "\nmacro_group_and_count_D_0 = load 'myfile.txt' USING PigStorage('\t') AS (name:chararray, age:int, gpa:float);\n" +
+        String expected = 
+            "macro_group_and_count_D_0 = load 'myfile.txt' USING PigStorage('\t') AS (name:chararray, age:int, gpa:float);\n" +
             "gamma = load 'myfile' USING PigStorage('\t') AS (F:(f1:int, f2:int, f3:int), T:(t1:chararray, t2:int));\n" +
             "macro_group_and_count_E_0 = load 'myfile.txt' USING org.apache.pig.builtin.PigStorage('\t') AS B:bag{T:(t1:int, t2:int, t3:int)};\n" +
-            "macro_group_and_count_F_0 = load 'myfile.txt' USING org.apache.pig.builtin.PigStorage('\t') AS (T1:(f1:int, f2:int), B:bag{T:(t1:float, t2:float)}, M:map[]);\n\n" +
+            "macro_group_and_count_F_0 = load 'myfile.txt' USING org.apache.pig.builtin.PigStorage('\t') AS (T1:(f1:int, f2:int), B:bag{T:(t1:float, t2:float)}, M:map[]);\n" +
             "macro_group_and_count_D_1 = load 'myfile.txt' USING PigStorage('\t') AS (name:chararray, age:int, gpa:float);\n" +
             "delta = load 'mydir' USING PigStorage('\t') AS (F:(f1:int, f2:int, f3:int), T:(t1:chararray, t2:int));\n" +
             "macro_group_and_count_E_1 = load 'myfile.txt' USING org.apache.pig.builtin.PigStorage('\t') AS B:bag{T:(t1:int, t2:int, t3:int)};\n" +
-            "macro_group_and_count_F_1 = load 'myfile.txt' USING org.apache.pig.builtin.PigStorage('\t') AS (T1:(f1:int, f2:int), B:bag{T:(t1:float, t2:float)}, M:map[]);\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
-
-        Assert.assertEquals(expected, s);
+            "macro_group_and_count_F_1 = load 'myfile.txt' USING org.apache.pig.builtin.PigStorage('\t') AS (T1:(f1:int, f2:int), B:bag{T:(t1:float, t2:float)}, M:map[]);\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
+        
+        verify(macro + script, expected);
     }
     
     @Test
-    public void storeTest() throws Throwable {
+    public void storeTest() throws Exception {
         String macro = "define group_and_count (A,C) returns B {\n" +
             "    $B = CROSS $A, $C partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
             "    STORE $A INTO 'myoutput' USING PigStorage ('*');\n" +
@@ -290,26 +260,21 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "beta = load 'links' as (user, page, view);\n" +
             "gamma = CROSS alpha, beta partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
-            "STORE alpha INTO 'myoutput' USING PigStorage('*');\n\n" +
+            "STORE alpha INTO 'myoutput' USING PigStorage('*');\n" +
             "delta = CROSS beta, alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
-            "STORE beta INTO 'myoutput' USING PigStorage('*');\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store delta into 'byage';\n";
-
-        Assert.assertEquals(expected, s);
+            "STORE beta INTO 'myoutput' USING PigStorage('*');\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
+        
+        verify(macro + script, expected);
     }
     
     @Test
-    public void streamTest() throws Throwable {
+    public void streamTest() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
             "    $B = STREAM $A THROUGH `stream.pl -n 5`;\n" +
             "    DEFINE mycmd `stream.pl -n 5`;\n" +
@@ -321,23 +286,18 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = STREAM alpha THROUGH `stream.pl -n 5`;\n" +
-            "DEFINE mycmd `stream.pl -n 5`;\n" +
-            "gamma = STREAM alpha THROUGH mycmd;\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = STREAM alpha THROUGH `stream.pl -n 5`;\n" + 
+            "DEFINE macro_group_and_count_mycmd_0 `stream.pl -n 5`;\n" + 
+            "gamma = STREAM alpha THROUGH macro_group_and_count_mycmd_0;\n" +
+            "store gamma INTO 'byuser';\n";
+        
+        verify(macro + script, expected);
     }
     
     @Test 
-    public void defineTest() throws Throwable {
+    public void defineTest() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
             "    DEFINE CMD `perl PigStreaming.pl - nameMap` input(stdin using PigStreaming(',')) output(stdout using PigStreaming(','));\n" +            
             "    DEFINE mycmd `stream_cmd input file.dat`;\n" +
@@ -352,28 +312,23 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
+        String expected = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "DEFINE macro_group_and_count_CMD_0 `perl PigStreaming.pl - nameMap` input(stdin USING PigStreaming(',')) output (stdout USING PigStreaming(','));\n" +
+            "DEFINE macro_group_and_count_mycmd_0 `stream_cmd input file.dat`;\n" +
+            "DEFINE macro_group_and_count_Z_0 `stream.pl` stderr ('<dir>' LIMIT 100);\n" +
+            "gamma = STREAM alpha THROUGH macro_group_and_count_CMD_0;\n" +
+            "macro_group_and_count_D_0 = STREAM alpha THROUGH macro_group_and_count_mycmd_0;\n" +
+            "macro_group_and_count_F_0 = STREAM alpha THROUGH macro_group_and_count_Z_0;\n" +
+            "store gamma INTO 'byuser';\n";
         
-        String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
-            "DEFINE CMD `perl PigStreaming.pl - nameMap` input(stdin USING PigStreaming(',')) output (stdout USING PigStreaming(','));\n" +
-            "DEFINE mycmd `stream_cmd input file.dat`;\n" +
-            "DEFINE Z `stream.pl` stderr ('<dir>' LIMIT 100);\n" +
-            "gamma = STREAM alpha THROUGH CMD;\n" +
-            "macro_group_and_count_D_0 = STREAM alpha THROUGH mycmd;\n" +
-            "macro_group_and_count_F_0 = STREAM alpha THROUGH Z;\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test 
-    public void defineTest2() throws Throwable {
+    public void defineTest2() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
-            "    DEFINE CMD `stream.pl data.gz` SHIP('/work/stream.pl') CACHE('/input/data.gz#data.gz');\n" +
+            "    DEFINE CMD `stream.pl data.gz` SHIP('"+Util.encodeEscape(command.toString())+"') CACHE('"+Util.encodeEscape(command.toString())+"');\n" +
             "    $B = STREAM $A THROUGH CMD;\n" +
             "};\n";
         
@@ -382,20 +337,11 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
-            "DEFINE CMD `stream.pl data.gz` SHIP ( '/work/stream.pl') CACHE ( '/input/data.gz#data.gz');\n" +
-            "gamma = STREAM alpha THROUGH CMD;\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+        verify(macro + script);
     }
     
     @Test
-    public void groupTest() throws Throwable {
+    public void groupTest() throws Exception {
         String macro = "define group_and_count (A,group_key) returns B {\n" +
             "    D = group $A by $group_key parallel 50;\n" +
             "    $B = foreach D generate group, COUNT($A);\n" +
@@ -409,25 +355,20 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha, user);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "macro_group_and_count_D_0 = group alpha by (user) parallel 50;\n" +
             "gamma = foreach macro_group_and_count_D_0 generate group, COUNT(alpha);\n" +
             "macro_group_and_count_X_0 = GROUP alpha BY (user) USING 'collected';\n" +
             "macro_group_and_count_Y_0 = GROUP alpha BY (user, age) USING 'merge';\n" +
-            "macro_group_and_count_Z_0 = GROUP alpha ALL;\n\n" +
-            "store gamma into 'byuser';\n";
+            "macro_group_and_count_Z_0 = GROUP alpha ALL;\n" + 
+            "store gamma INTO 'byuser';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void cogroupTest() throws Throwable {
+    public void cogroupTest() throws Exception {
         String macro = "define group_and_count (A,C) returns B {\n" +
             "    D = cogroup $A by user, $C by user parallel 50;\n" +
             "    $B = cogroup $A by user inner, $C by user inner parallel 50;\n" +
@@ -440,24 +381,19 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha, beta);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "beta = load 'links' as (user, page, view);\n" +
             "macro_group_and_count_D_0 = cogroup alpha by (user), beta by (user) parallel 50;\n" +
             "gamma = cogroup alpha by (user) inner, beta by (user) inner parallel 50;\n" +
-            "macro_group_and_count_Y_0 = COGROUP alpha BY (user, age), beta by (user, view) USING 'merge';\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "macro_group_and_count_Y_0 = COGROUP alpha BY (user, age), beta by (user, view) USING 'merge';\n" +
+            "store gamma INTO 'byuser';\n";
+        
+        verify(macro + script, expected);
     }
     
     @Test
-    public void unionTest() throws Throwable {
+    public void unionTest() throws Exception {
         String macro = "define group_and_count (A,C) returns B {\n" +
             "    D = union $A, $C;\n" +
             "    $B = union onschema $A, $C;\n" +
@@ -469,23 +405,18 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha, beta);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
-        String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+        String expected = 
+            "alpha = load 'users' as (user, age, zip);\n" +
             "beta = load 'links' as (user, page, view);\n" +
             "macro_group_and_count_D_0 = union alpha, beta;\n" +
-            "gamma = union onschema alpha, beta;\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "gamma = union onschema alpha, beta;\n" +
+            "store gamma INTO 'byuser';\n";
+        
+        verify(macro + script, expected);
     }
     
     @Test
-    public void splitTest() throws Throwable {
+    public void splitTest() throws Exception {
         String macro = "define group_and_count (A,key) returns B {\n" +
             "    SPLIT $A INTO $B IF $key<7, Y IF $key==5, Z IF ($key<6 OR $key>6);\n" +
             "};\n";
@@ -495,21 +426,16 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha, age);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
+        String expected = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "SPLIT alpha INTO gamma IF age < 7, macro_group_and_count_Y_0 IF age == 5, macro_group_and_count_Z_0 IF (age < 6) OR (age > 6);\n" +
+            "store gamma INTO 'byuser';\n";
         
-        String expected =
-             "\nalpha = load 'users' as (user, age, zip);\n" +
-            "SPLIT alpha INTO gamma IF age < 7, Y IF age == 5, Z IF (age < 6) OR (age > 6);\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void mapreduceTest() throws Throwable {
+    public void mapreduceTest() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
             "    $B = MAPREDUCE 'wordcount.jar' STORE $A INTO 'inputDir' LOAD 'outputDir' " + 
             "AS (word:chararray, count: int) `org.myorg.WordCount inputDir outputDir`;\n" +
@@ -520,21 +446,16 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-             "\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = MAPREDUCE 'wordcount.jar' STORE alpha INTO 'inputDir' LOAD 'outputDir' AS (word:chararray, count:int) `org.myorg.WordCount inputDir outputDir`;\n\n" +
-            "store gamma into 'byuser';\n";
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = MAPREDUCE 'wordcount.jar' STORE alpha INTO 'inputDir' LOAD 'outputDir' AS (word:chararray, count:int) `org.myorg.WordCount inputDir outputDir`;\n" +
+            "store gamma INTO 'byuser';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void joinTest() throws Throwable {
+    public void joinTest() throws Exception {
         String macro = "define group_and_count (A,C) returns B {\n" +
             "    $B = JOIN $A BY user, $C BY user using 'replicated' partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
             "    $B = JOIN $A BY $0, $C BY $1 using 'skewed' parallel 5;\n" +
@@ -546,23 +467,18 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha,beta);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "beta = load 'links' as (user, link, view);\n" +
             "gamma = JOIN alpha BY (user), beta BY (user) USING 'replicated' partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
-            "gamma = JOIN alpha BY ($0), beta BY ($1) USING 'skewed' parallel 5;\n\n" +
-            "store gamma into 'byuser';\n";
+            "gamma = JOIN alpha BY ($0), beta BY ($1) USING 'skewed' parallel 5;\n" +
+            "store gamma INTO 'byuser';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void multiOutputsTest() throws Throwable {
+    public void multiOutputsTest() throws Exception {
         String macro = "define group_and_count (A,C) returns B, D {\n" +
             "    $B = JOIN $A BY user, $C BY user using 'replicated' partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
             "    $D = JOIN $A BY $0, $C BY $1 using 'skewed' parallel 5;\n" +
@@ -575,24 +491,46 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store sigma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "beta = load 'links' as (user, link, view);\n" +
             "gamma = JOIN alpha BY (user), beta BY (user) USING 'replicated' partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
-            "sigma = JOIN alpha BY ($0), beta BY ($1) USING 'skewed' parallel 5;\n\n" +
-            "store gamma into 'byuser';\n" +
-            "store sigma into 'byuser';\n";
+            "sigma = JOIN alpha BY ($0), beta BY ($1) USING 'skewed' parallel 5;\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store sigma INTO 'byuser';\n";
+        
+        verify(macro + script, expected);
+    }
+    
+    @Test
+    public void parameterSubstitutionTest() throws Exception {
+        String macro = "define group_and_count (A,C) returns B, D {\n" +
+            "    $B = JOIN $A BY user, $C BY user using 'replicated' partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
+            "    $D = JOIN $A BY $0, $C BY $1 using 'skewed' parallel 5;\n" +
+            "};\n";
+        
+        String script = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "beta = load 'links' as (user, link, view);\n" +
+            "gamma, sigma = group_and_count (alpha,beta);\n" +
+            "store gamma into '$output1';\n" +
+            "store sigma into '$output2';\n";
+        
+        File f1 = new File("myscript.pig");
+        f1.deleteOnExit();
+        
+        FileWriter fw1 = new FileWriter(f1);
+        fw1.append(macro).append(script);
+        fw1.close();
         
-        Assert.assertEquals(expected, s);
+        String[] args = { "-x", "local", "-p", "output1=byuser", "-p", "output2=byage", "-c", "myscript.pig" };
+        PigStats stats = PigRunner.run(args, null);
+ 
+        assertTrue(stats.isSuccessful());
     }
     
     @Test 
-    public void outerTest() throws Throwable {
+    public void outerTest() throws Exception {
         String macro = "define group_and_count (A,C) returns B {\n" +
             "    $B = JOIN $A BY user right outer, $C BY user partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
             "    D = JOIN $A BY user LEFT, $C BY user;\n" +
@@ -604,23 +542,18 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha,beta);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
-        String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+        String expected = 
+            "alpha = load 'users' as (user, age, zip);\n" +
             "beta = load 'links' as (user, link, view);\n" +
             "gamma = JOIN alpha BY (user) right outer, beta BY (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 5;\n" +
-            "macro_group_and_count_D_0 = JOIN alpha BY (user) LEFT, beta BY (user);\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "macro_group_and_count_D_0 = JOIN alpha BY (user) LEFT, beta BY (user);\n" +
+            "store gamma INTO 'byuser';\n";
+        
+        verify(macro + script, expected);
     }
     
     @Test
-    public void filterTest() throws Throwable {
+    public void filterTest() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
             "    $B = FILTER $A BY ($1 == 8) OR (NOT ($0+$2 > $1));\n" +
             "};\n";
@@ -630,21 +563,16 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
+        String expected = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = FILTER alpha BY (($1 == 8) OR ( NOT ($0 + $2 > $1)));\n" +
+            "store gamma INTO 'byuser';\n";
         
-        String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = FILTER alpha BY (($1 == 8) OR ( NOT ($0 + $2 > $1)));\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test 
-    public void foreachTest() throws Throwable {
+    public void foreachTest() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
             "    $B = foreach $A generate $0, $2;\n" +
             "    C = group $A by $0;\n" +
@@ -659,26 +587,21 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age:int, zip:int);\n" +
+            "alpha = load 'users' as (user, age:int, zip:int);\n" +
             "gamma = foreach alpha generate $0, $2;\n" +
             "macro_group_and_count_C_0 = group alpha by ($0);\n" +
             "macro_group_and_count_X_0 = FOREACH macro_group_and_count_C_0 GENERATE group, SUM(alpha.($1));\n" +
             "macro_group_and_count_Y_0 = FOREACH macro_group_and_count_C_0 GENERATE group, FLATTEN(alpha) ;\n" +
             "macro_group_and_count_Z_0 = FOREACH macro_group_and_count_C_0 GENERATE FLATTEN(alpha.($1, $2)) , FLATTEN(alpha.(age)) ;\n" +
-            "macro_group_and_count_X_0 = FOREACH alpha GENERATE $1 + $2 AS f1:int;\n\n" +
-            "store gamma into 'byuser';\n";
-        
-        Assert.assertEquals(expected, s);
+            "macro_group_and_count_X_0 = FOREACH alpha GENERATE $1 + $2 AS f1:int;\n" +
+            "store gamma INTO 'byuser';\n";
+            
+        verify(macro + script, expected);
     }
     
     @Test
-    public void nestedTest() throws Throwable {
+    public void nestedTest() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
             "    C = group $A by $0;\n" +
             "    $B = FOREACH C { \n" +
@@ -694,22 +617,17 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "macro_group_and_count_C_0 = group alpha by ($0);\n" +
-            "gamma = FOREACH macro_group_and_count_C_0 { FA = FILTER alpha BY user == 'www.xyz.org'; PA = FA.(age); DA = DISTINCT PA;  GENERATE group, COUNT(DA); } ;\n\n" +
-            "store gamma into 'byuser';\n";
+            "gamma = FOREACH macro_group_and_count_C_0 { FA = FILTER alpha BY user == 'www.xyz.org'; PA = FA.(age); DA = DISTINCT PA;  GENERATE group, COUNT(DA); } ;\n" +
+            "store gamma INTO 'byuser';\n";
         
-        Assert.assertEquals(expected, s);
+        verify(macro + script, expected);
     }
     
     @Test
-    public void bincondTest() throws Throwable {
+    public void bincondTest() throws Exception {
         String macro = "define group_and_count (A) returns B {\n" +
             "    X = FOREACH $A GENERATE f1, f2, f1%f2;\n" +
             "    Y = FOREACH $A GENERATE f2, (f2==1?1:COUNT(B));\n" +
@@ -722,24 +640,19 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
-        String expected =
-            "\nalpha = LOAD 'data' AS (f1:chararray, f2:int, B:bag{T:tuple(t1:int,t2:int)});\n" +
+        String expected = 
+            "alpha = LOAD 'data' AS (f1:chararray, f2:int, B:bag{T:(t1:int, t2:int)});\n" +
             "macro_group_and_count_X_0 = FOREACH alpha GENERATE f1, f2, f1 % f2;\n" +
             "macro_group_and_count_Y_0 = FOREACH alpha GENERATE f2,  (f2 == 1 ? 1 : COUNT(B)) ;\n" +
             "macro_group_and_count_Z_0 = FILTER alpha BY (f1 IS not null);\n" +
-            "gamma = FILTER alpha BY (f1 matches '.*apache.*');\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "gamma = FILTER alpha BY (f1 matches '.*apache.*');\n" +
+            "store gamma INTO 'byuser';\n";
+            
+        verify(macro + script, expected);
     }
     
-    @Test(expected = RuntimeException.class)  
-    public void duplicationTest() throws Throwable {
+    @Test(expected = java.lang.AssertionError.class)  
+    public void duplicationTest() throws Exception {
         String macro = "define group_and_count (A,group_key, reducers) returns B {\n" +
             "    $B = distinct $A partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "};\n";
@@ -751,14 +664,11 @@ public class TestMacroExpansion {
             "store gamma into 'byuser';\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
+        verify(macro + macro + script);
     }
     
     @Test
-    public void simpleImportTest() throws Throwable {
+    public void simpleImportTest() throws Exception {
         String macro = "define group_and_count (A,group_key, reducers) returns B {\n" +
             "    $B = distinct $A partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "};\n";
@@ -776,21 +686,16 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha, user, 23);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\n\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n" +
+            "store gamma INTO 'byuser';\n";
+            
+        verify(script, expected);
     }
     
-    @Test
-    public void importUsingSearchPathTest() throws Throwable {
+    @Test 
+    public void importUsingSearchPathTest() throws Exception {
         String macro = "define group_and_count (A,group_key, reducers) returns B {\n" +
             "    $B = distinct $A partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "};\n";
@@ -822,7 +727,7 @@ public class TestMacroExpansion {
     }
     
     @Test
-    public void negtiveUsingSearchPathTest() throws Throwable {
+    public void negtiveUsingSearchPathTest() throws Exception {
         String macro = "define group_and_count (A,group_key, reducers) returns B {\n" +
             "    $B = distinct $A partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "};\n";
@@ -842,7 +747,7 @@ public class TestMacroExpansion {
         
         File f1 = new File("myscript.pig");
         f1.deleteOnExit();
-        
+                
         FileWriter fw1 = new FileWriter(f1);
         fw1.append(script);
         fw1.close();
@@ -854,7 +759,7 @@ public class TestMacroExpansion {
     }
     
     @Test
-    public void importTwoMacrosTest() throws Throwable {
+    public void importTwoMacrosTest() throws Exception {
         String macro = "define group_and_count (A, reducers) returns B {\n" +
             "    $B = distinct $A partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "};\n" +
@@ -877,23 +782,18 @@ public class TestMacroExpansion {
             "store beta into 'byage';\n" +
             "store gamma into 'byuser';\n";
 
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        validate(s);
-
-        String expected =
-            "\n\n\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n\n" +
-            "beta = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 32;\n\n" +
-            "store beta into 'byage';\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+        String expected = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n" +
+            "beta = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 32;\n" +
+            "store beta INTO 'byage';\n" +
+            "store gamma INTO 'byuser';\n";
+            
+        verify(script, expected);
     }
     
     @Test
-    public void importTwoFilesTest() throws Throwable {
+    public void importTwoFilesTest() throws Exception {
         String macro1 = "define group_and_count (A, reducers) returns B {\n" +
             "    $B = distinct $A partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "};\n";
@@ -925,23 +825,18 @@ public class TestMacroExpansion {
             "store beta into 'byage';\n" +
             "store gamma into 'byuser';\n";
 
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        validate(s);
-
-        String expected =
-            "\n\n\n\nalpha = load 'users' as (user, age, zip);\n" +
-            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n\n" +
-            "beta = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 32;\n\n" +
-            "store beta into 'byage';\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+        String expected = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n" +
+            "beta = distinct alpha partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 32;\n" +
+            "store beta INTO 'byage';\n" +
+            "store gamma INTO 'byuser';\n";
+            
+        verify(script, expected);
     }
     
     @Test
-    public void noParamTest() throws Throwable {
+    public void noParamTest() throws Exception {
         String macro = "define group_and_count() returns B {\n" +
             "    D = load 'myfile.txt' using PigStorage('\t') AS (a0:int, a1:int, a2:int);\n" +   
             "    $B = FILTER D BY ($1 == 8) OR (NOT ($0+$2 > $1));\n" +
@@ -951,21 +846,16 @@ public class TestMacroExpansion {
             "delta = group_and_count();\n" +
             "store delta into 'byage';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nmacro_group_and_count_D_0 = load 'myfile.txt' USING PigStorage('\t') AS (a0:int, a1:int, a2:int);\n" +
-            "delta = FILTER macro_group_and_count_D_0 BY (($1 == 8) OR ( NOT ($0 + $2 > $1)));\n\n" +
-            "store delta into 'byage';\n";
-
-        Assert.assertEquals(expected, s);
+            "macro_group_and_count_D_0 = load 'myfile.txt' USING PigStorage('\t') AS (a0:int, a1:int, a2:int);\n" +
+            "delta = FILTER macro_group_and_count_D_0 BY (($1 == 8) OR ( NOT ($0 + $2 > $1)));\n" +
+            "store delta INTO 'byage';\n";
+            
+        verify(macro + script, expected);
     }
     
     @Test
-    public void noReturnTest() throws Throwable {
+    public void noReturnTest() throws Exception {
         String macro = "define group_and_count() returns void {\n" +
             "    D = load 'myfile.txt' using PigStorage() AS (a0:int, a1:int, a2:int);\n" +   
             "    store D into 'myoutput';\n" +
@@ -974,42 +864,33 @@ public class TestMacroExpansion {
         String script = 
             "dummy = group_and_count();\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-        
         String expected =
-            "\nmacro_group_and_count_D_0 = load 'myfile.txt' USING PigStorage() AS (a0:int, a1:int, a2:int);\n" +
-            "store macro_group_and_count_D_0 INTO 'myoutput';\n\n";
-
-        Assert.assertEquals(expected, s);
+            "macro_group_and_count_D_0 = load 'myfile.txt' USING PigStorage() AS (a0:int, a1:int, a2:int);\n" +
+            "store macro_group_and_count_D_0 INTO 'myoutput';\n";
+            
+        verify(macro + script, expected);
     }
     
     @Test
-    public void noReturnTest2() throws Throwable {
-        String macro = "define group_and_count(input, output) returns void {\n" +
-            "    D = load '$input';\n" +   
-            "    store D into '$output';\n" +
+    public void noReturnTest2() throws Exception {
+        String macro = "define group_and_count(myinput, myoutput) returns void {\n" +
+            "    D = load '$myinput';\n" +   
+            "    store D into '$myoutput';\n" +
             "};\n";
         
         String script = 
             "dummy = group_and_count('myfile.txt', '/tmp/myoutput');\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
-       
         String expected =
-            "\nmacro_group_and_count_D_0 = load 'myfile.txt';\n" +
-            "store macro_group_and_count_D_0 INTO '/tmp/myoutput';\n\n";
-
-        Assert.assertEquals(expected, s);
+            "macro_group_and_count_D_0 = load 'myfile.txt';\n" +
+            "store macro_group_and_count_D_0 INTO '/tmp/myoutput';\n";
+            
+        verify(macro + script, expected);
     }
     
-    @Test(expected = RuntimeException.class)  
-    public void negativeTest() throws Throwable {
+    // missing inline parameters
+    @Test(expected = java.lang.AssertionError.class)  
+    public void negativeTest() throws Exception {
         String macro = "define group_and_count (A,group_key, size) returns B {\n" +
             "    $B = limit $A $size;\n" +
             "};\n";
@@ -1019,14 +900,12 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha, 20);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
+        verify(macro + script);
     }   
     
-    @Test(expected = RuntimeException.class)  
-    public void negativeTest2() throws Throwable {
+    // missing inline parameters 
+    @Test(expected = java.lang.AssertionError.class)  
+    public void negativeTest2() throws Exception {
         String macro = "define group_and_count (A,group_key, size) returns B {\n" +
             "    $B = limit $A $size;\n" +
             "};\n";
@@ -1036,14 +915,12 @@ public class TestMacroExpansion {
             "gamma = group_and_count ();\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
-        
-        validate(s);
+        verify(macro + script);
     }   
     
-    @Test(expected = RuntimeException.class)
-    public void negativeTest3() throws Throwable {
+    // missing inline return values
+    @Test(expected = java.lang.AssertionError.class)
+    public void negativeTest3() throws Exception {
         String macro = "define group_and_count (A,C) returns B, D {\n" +
             "    $B = JOIN $A BY user, $C BY user;\n" +
             "    $D = JOIN $A BY $0, $C BY $1 using 'skewed' parallel 5;\n" +
@@ -1055,14 +932,28 @@ public class TestMacroExpansion {
             "gamma = group_and_count (alpha,beta);\n" +
             "store gamma into 'byuser';\n";
         
-        StringReader rd = new StringReader(macro + script);
-        String s = ParserUtil.expandMacros(rd);
+        verify(macro + script);
+    }
+    
+    // macro contains another macro def
+    @Test(expected = java.lang.AssertionError.class)
+    public void negativeTest4() throws Exception {
+        String macro = "define group_and_count (A,C) returns B {\n" +
+            "    $B = JOIN $A BY user, $C BY user;\n" +
+            "    define test_macro() returns dummy { a = load '1.txt'; };\n" +
+            "};\n";
+        
+        String script = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "beta = load 'links' as (user, link, view);\n" +
+            "gamma = group_and_count (alpha,beta);\n" +
+            "store gamma into 'byuser';\n";
         
-        validate(s);
+        verify(macro + script);
     }
     
     @Test
-    public void recursiveMacrosTest() throws Throwable {
+    public void recursiveMacrosTest() throws Exception {
         String macro1 = "define group_and_partition (A, group_key, reducers) returns B {\n" +
             "    C = group $A by $group_key partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "    $B = foreach_count(C, $A);" +
@@ -1078,22 +969,17 @@ public class TestMacroExpansion {
             "gamma = group_and_partition (alpha, user, 23);\n" +
             "store gamma into 'byuser';\n";
 
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        validate(s);
-
         String expected =
-            "\n\nalpha = load 'users' as (user, age, zip);\n" +
+            "alpha = load 'users' as (user, age, zip);\n" +
             "macro_group_and_partition_C_0 = group alpha by (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 23;\n" +
-            "gamma = foreach macro_group_and_partition_C_0 generate group, COUNT(alpha);\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "gamma = foreach macro_group_and_partition_C_0 generate group, COUNT(alpha);\n" +
+            "store gamma INTO 'byuser';\n";
+            
+        verify(script, expected);
     }
     
     @Test
-    public void recursiveMacrosTest2() throws Throwable {
+    public void recursiveMacrosTest2() throws Exception {
         String macro1 = "define foreach_count(A, C) returns B {\n" +
         "    $B = foreach $A generate group, COUNT($C);\n" +
         "};\n";
@@ -1112,22 +998,17 @@ public class TestMacroExpansion {
             "gamma = load_and_group ();\n" +
             "store gamma into 'byuser';\n";
 
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        validate(s);
-
         String expected =
-            "\n\n\nmacro_load_and_group_alpha_0 = load 'users' as (user, age, zip);\n" +
-            "macro_load_and_group_C_0 = group macro_load_and_group_alpha_0 by (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 30;\n" +
-            "gamma = foreach macro_load_and_group_C_0 generate group, COUNT(macro_load_and_group_alpha_0);\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "macro_load_and_group_alpha_0 = load 'users' as (user, age, zip);\n" +
+            "macro_load_and_group_macro_group_and_partition_C_0_0 = group macro_load_and_group_alpha_0 by (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 30;\n" +
+            "gamma = foreach macro_load_and_group_macro_group_and_partition_C_0_0 generate group, COUNT(macro_load_and_group_alpha_0);\n" +
+            "store gamma INTO 'byuser';\n";
+        
+        verify(script, expected);
     }
     
     @Test
-    public void sequenceMacrosTest() throws Throwable {
+    public void sequenceMacrosTest() throws Exception {
         String macro1 = "define foreach_count(A, C) returns B {\n" +
         "    $B = foreach $A generate group, COUNT($C);\n" +
         "};\n";
@@ -1142,22 +1023,17 @@ public class TestMacroExpansion {
             "gamma = foreach_count(beta, alpha);\n" +
             "store gamma into 'byuser';\n";
 
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        validate(s);
-
         String expected =
-            "\n\nalpha = load 'users' as (user, age, zip);\n" +
-            "beta = group alpha by (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 20;\n\n" +
-            "gamma = foreach beta generate group, COUNT(alpha);\n\n" +
-            "store gamma into 'byuser';\n";
-
-        Assert.assertEquals(expected, s);
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "beta = group alpha by (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 20;\n" +
+            "gamma = foreach beta generate group, COUNT(alpha);\n" +
+            "store gamma INTO 'byuser';\n";
+            
+        verify(script, expected);
     }
     
-    @Test(expected = RuntimeException.class)
-    public void selfRecursiveTest() throws Throwable {
+    @Test(expected = java.lang.AssertionError.class)
+    public void selfRecursiveTest() throws Exception {
         String macro1 = "define group_and_partition (A, group_key, reducers) returns B {\n" +
             "    C = group $A by $group_key partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "    $B = group_and_partition(C, age, 34);" +
@@ -1168,14 +1044,11 @@ public class TestMacroExpansion {
             "gamma = group_and_partition (alpha, user, 23);\n" +
             "store gamma into 'byuser';\n";
 
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        validate(s);
+        verify(script);
     }
     
-    @Test(expected = RuntimeException.class)
-    public void cyclicRecursiveTest() throws Throwable {
+    @Test(expected = java.lang.AssertionError.class)
+    public void cyclicRecursiveTest() throws Exception {
         String macro1 = "define group_and_partition (A, group_key, reducers) returns B {\n" +
             "    C = group $A by $group_key partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel $reducers;\n" +
             "    $B = foreach_count(C, $A);" +
@@ -1185,211 +1058,53 @@ public class TestMacroExpansion {
             "    $B = foreach $A generate group, COUNT($C);\n" +
             "    D = group_and_partition($C, age, 23);" +
             "};\n";
-        
-        
+               
         String script = macro2 + macro1 +
             "alpha = load 'users' as (user, age, zip);\n" +
             "gamma = group_and_partition (alpha, user, 23);\n" +
             "store gamma into 'byuser';\n";
 
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        validate(s);
+        verify(script);
     }
     
     @Test
-    public void typecastTest() throws Throwable {
+    public void typecastTest() throws Exception {
         String macro = 
             "a = load '1.txt' as (a0);" +
             "b = foreach a generate flatten( (bag{tuple(map[])})a0 ) as b0:map[];" +
             "c = foreach b generate (long)b0#'key1';";
         
-        testMacro(macro);
-    }
-    
-    @Test
-    public void test17() throws Throwable {
-        String macro = 
-            "a = load '/user/pig/tests/data/singlefile/studentnulltab10k' as (name:chararray, age:int, gpa:double);" +
-            "b = foreach a generate (int)((int)gpa/((int)gpa - 1)) as norm_gpa:int;" + 
-            "c = foreach b generate (norm_gpa is not null? norm_gpa: 0);" +
-            "store c into '/user/pig/out/jianyong.1297229709/Types_37.out';";
+        String expected =
+            "macro_mymacro_a_0 = load '1.txt' as a0;\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate flatten((bag{tuple(map[])})a0)  AS b0:map[];\n" +
+            "macro_mymacro_c_0 = foreach macro_mymacro_b_0 generate (long)b0#'key1';\n";
             
-        testMacro(macro);
+        testMacro(macro, expected);
     }
     
     @Test
-    public void test18() throws Throwable {
-        String macro = "define mymacro() returns dummy {" +
-            "a = load '/user/pig/tests/data/singlefile/studenttab10k';" +
-            "b = group a by $0;" +
-            "c = foreach b {c1 = order $1 by * using org.apache.pig.test.udf.orderby.OrdDesc; generate flatten(c1); };" +
-            "store c into '/user/pig/out/jianyong.1297305352/Order_15.out';};";
-            
-        String script = macro +
-            "dummy = mymacro();\n";
-        
-
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
-
-        //validate(s);
-        String expected =
-            "macro_mymacro_a_0 = load '/user/pig/tests/data/singlefile/studenttab10k';\n" +
-            "macro_mymacro_b_0 = group macro_mymacro_a_0 by ($0);\n" +
-            "macro_mymacro_c_0 = foreach macro_mymacro_b_0 { c1 = order $1 BY * USING org.apache.pig.test.udf.orderby.OrdDesc;  generate flatten(c1) ; } ;\n" +
-            "store macro_mymacro_c_0 INTO '/user/pig/out/jianyong.1297305352/Order_15.out';\n\n";
-        
-        Assert.assertEquals(expected, s);
-    }
-    
-    @Test
-    public void test19() throws Throwable {
-        String macro = 
-            "a = load '/user/pig/tests/data/singlefile/studenttab10k';" +
-            "b = group a by $0;" +
-            "c = foreach b {c1 = order $1 by $1; generate flatten(c1), MAX($1.$1); };" +
-            "store c into '/user/pig/out/jianyong.1297305352/Order_17.out';";
-            
-        testMacro(macro);
-    }
-    
-    @Test
-    public void test20() throws Throwable {
-        String macro = 
-            "a = load 'x' as (u,v);" +
-            "b = load 'y' as (u,w);" +
-            "c = join a by u, b by u;" +
-            "d = foreach c generate a::u, b::u, w;";
-            
-        testMacro(macro);
-    }
-    
-    @Test
-    public void test21() throws Throwable {
-        String macro = 
-        "a = load '1.txt' as ( u, v, w : int );" +
-        "b = foreach a generate * as ( x, y, z ), flatten( u ) as ( r, s ), flatten( v ) as d, w + 5 as e:int;";
-            
-        testMacro(macro);
-    }
-    
-    @Test
-    public void test22() throws Throwable {
-        String macro =
-            "a = load '1.txt' as ( u : bag{}, v : bag{tuple(x, y)} );" +
-            "b = load '2.x' as ( t : {}, u : {(r,s)}, v : bag{ T : tuple( x, y ) }, w : bag{(z1, z2)} );" +
-            "c = load '3.x' as p : int;";
-            
-        testMacro(macro);
-    }
-
-    @Test
-    public void test23() throws Throwable {
-        String macro = 
-        "a = load '1.txt' as ( u, v, w : int );" +
-        "b = foreach a generate * as ( x, y, z ), flatten( u ) as ( r, s ), flatten( v ) as d, w + 5 as e:int;";
-            
-        testMacro(macro);
-    }
-    
-    @Test
-    public void test24() throws Throwable {
-        String macro = 
-        "A = load 'x' as ( u:bag{tuple(x, y)}, v:long, w:bytearray); " + 
-        "B = foreach A generate u.(x, y), v, w; " +
-        "C = store B into 'output';";
-            
-        testMacro(macro);
-    }
-    
-    @Test
-    public void test25() throws Throwable {
-        String macro = 
-        "A = load 'x' as ( a : bag{ T:tuple(u, v) }, c : int, d : long );" +
-        "B = foreach A { R = a; P = c * 2; Q = P + d; S = R.u; T = limit S 100; generate Q, R, S, T, c + d/5; };" +
-        "store B into 'y';";
-            
-        testMacro(macro);
-    }
-    
-    @Test
-    public void test26() throws Throwable {
-        String content =
-        "A = load 'x' as ( u:bag{tuple(x, y)}, v:long, w:bytearray); " + 
-        "B = foreach A generate u.(x, $1), $1, w; " +
-        "C = store B into 'output';";
-            
-        testMacro(content);
-    }
-    
-    @Test
-    public void test27() throws Throwable {
-        String content =
-            "A = load 'x' as ( u:bag{} ); " + 
-            "B = foreach A generate u.$100; " +
-            "C = store B into 'output';";
-            
-        testMacro(content);
-    }
-    
-    @Test
-    public void test28() throws Throwable {
-        String content =
-            "A = load 'x'; " + 
-            "B = foreach A generate $1, $1000; " +
-            "C = store B into 'output';";
-            
-        testMacro(content);
-    }
-    
-    @Test
-    public void test29() throws Throwable {
-        String content =
-            "A = load 'x'; " + 
-            "B = load 'y' as ( u : int, v : chararray );" +
-            "C = foreach A generate B.$1, $0; " +
-            "D = store C into 'output';";
-            
-        testMacro(content);
-    }
-    
-    @Test
-    public void test30() throws Throwable {
-        String content =
-            "A = load 'x'; " + 
-            "B = load 'y' as ( u : int, v : chararray );" +
-            "C = foreach A generate B.$1, $0; " +
-            "D = store C into 'output';";
-            
-        testMacro(content);
-    }
-    
-    @Test
-    public void test31() throws Throwable {
-        String content =
-            "A = load 'x'; " + 
-            "B = load 'y' as ( u : int, v : chararray );" +
-            "C = foreach A generate B.v, $0; " +
-            "D = store C into 'output';";
-            
-        testMacro(content);
-    }
-    
-    public void test1() throws Throwable {
+    public void test1() throws Exception {
         String query = "A = load 'x' as ( u:int, v:long, w:bytearray); " + 
                        "B = limit A 100; " +
                        "C = filter B by 2 > 1; " +
                        "D = load 'y' as (d1, d2); " +
                        "E = join C by ( $0, $1 ), D by ( d1, d2 ) using 'replicated' parallel 16; " +
                        "F = store E into 'output';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (u:int, v:long, w:bytearray);\n" +
+            "macro_mymacro_B_0 = limit macro_mymacro_A_0 100;\n" +
+            "macro_mymacro_C_0 = filter macro_mymacro_B_0 BY (2 > 1);\n" +
+            "macro_mymacro_D_0 = load 'y' as (d1, d2);\n" +
+            "macro_mymacro_E_0 = join macro_mymacro_C_0 by ($0, $1), macro_mymacro_D_0 by (d1, d2) USING 'replicated' parallel 16;\n" +
+            "macro_mymacro_F_0 = store macro_mymacro_E_0 INTO 'output';\n";
+            
+        testMacro( query, expected );
 
     }
 
-    //@Test
-    public void test2() throws Throwable {
+    @Test
+    public void test2() throws Exception {
         String query = "A = load 'x' as ( u:int, v:long, w:bytearray); " + 
                        "B = distinct A partition by org.apache.pig.Identity; " +
                        "C = sample B 0.49; " +
@@ -1400,21 +1115,40 @@ public class TestMacroExpansion {
                        "H = cross F, G; " +
                        "split H into I if 10 > 5, J if 'world' eq 'hello', K if 77 <= 200; " +
                        "L = store J into 'output';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (u:int, v:long, w:bytearray);\n" +
+            "macro_mymacro_B_0 = distinct macro_mymacro_A_0 partition BY org.apache.pig.Identity;\n" +
+            "macro_mymacro_C_0 = sample macro_mymacro_B_0 0.49;\n" +
+            "macro_mymacro_D_0 = order macro_mymacro_C_0 BY $0, $1;\n" +
+            "macro_mymacro_E_0 = load 'y' as (d1, d2);\n" + 
+            "macro_mymacro_F_0 = union onschema macro_mymacro_D_0, macro_mymacro_E_0;\n" +
+            "macro_mymacro_G_0 = load 'z' as (g1:int, g2:(g21, g22));\n" +
+            "macro_mymacro_H_0 = cross macro_mymacro_F_0, macro_mymacro_G_0;\n" +
+            "split macro_mymacro_H_0 INTO macro_mymacro_I_0 IF 10 > 5, macro_mymacro_J_0 IF 'world' eq 'hello', macro_mymacro_K_0 IF 77 <= 200;\n" + 
+            "macro_mymacro_L_0 = store macro_mymacro_J_0 INTO 'output';\n";
+        
+        testMacro( query, expected );
     }
 
     @Test
-    public void test3() throws Throwable {
+    public void test3() throws Exception {
         String query = "a = load '1.txt'  as (name, age, gpa);" + 
                        "b = group a by name PARTITION BY org.apache.pig.test.utils.SimpleCustomPartitioner2;" +
                        "c = foreach b generate group, COUNT(a.age);" +
                        "store c into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_a_0 = load '1.txt' as (name, age, gpa);\n" +
+            "macro_mymacro_b_0 = group macro_mymacro_a_0 by (name) PARTITION BY org.apache.pig.test.utils.SimpleCustomPartitioner2;\n" +
+            "macro_mymacro_c_0 = foreach macro_mymacro_b_0 generate group, COUNT(macro_mymacro_a_0.(age));\n" +
+            "store macro_mymacro_c_0 INTO 'y';\n";
+            
+        testMacro( query, expected );
     }
-    
 
     @Test
-    public void test4() throws Throwable {
+    public void test4() throws Exception {
         String query = "A = load 'x'; " + 
                        "B = mapreduce '" + "myjar.jar" + "' " +
                            "Store A into 'table_testNativeMRJobSimple_input' "+
@@ -1423,70 +1157,119 @@ public class TestMacroExpansion {
                            "table_testNativeMRJobSimple_input table_testNativeMRJobSimple_output " +
                            "stopworld.file" + "`;" +
                         "C = Store B into 'output';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x';\n" + 
+            "macro_mymacro_B_0 = mapreduce 'myjar.jar' Store macro_mymacro_A_0 INTO 'table_testNativeMRJobSimple_input' Load 'table_testNativeMRJobSimple_output' `org.apache.pig.test.utils.WordCount -files file table_testNativeMRJobSimple_input table_testNativeMRJobSimple_output stopworld.file`;\n" +
+            "macro_mymacro_C_0 = Store macro_mymacro_B_0 INTO 'output';\n";
+            
+        testMacro( query, expected );
     }
 
     // Test define function.
     @Test
-    public void test5() throws Throwable {
+    public void test5() throws Exception {
         String query = "define myudf org.apache.pig.builtin.PigStorage( ',' );" +
                        "A = load 'x' using myudf;" +
                        "store A into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "define macro_mymacro_myudf_0 org.apache.pig.builtin.PigStorage(',');\n" +
+            "macro_mymacro_A_0 = load 'x' USING macro_mymacro_myudf_0;\n" +
+            "store macro_mymacro_A_0 INTO 'y';\n";
+            
+        testMacro( query, expected );
     }
 
     @Test
-    public void test6() throws Throwable {
+    public void test6() throws Exception {
         String query = "A = load 'x' as ( a : int, b, c : chararray );" +
                        "B = group A by ( a, $2 );" +
                        "store B into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (a:int, b, c:chararray);\n" +
+            "macro_mymacro_B_0 = group macro_mymacro_A_0 by (a, $2);\n" + 
+            "store macro_mymacro_B_0 INTO 'y';\n";
+        
+        testMacro( query, expected );
     }
 
     @Test
-    public void test7() throws Throwable {
+    public void test7() throws Exception {
         String query = "A = load 'x' as ( a : int, b, c : chararray );" +
                        "B = foreach A generate a, $2;" +
                        "store B into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (a:int, b, c:chararray);\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 generate a, $2;\n" +
+            "store macro_mymacro_B_0 INTO 'y';\n";
+            
+        testMacro( query, expected );
     }
 
     @Test
-    public void test8() throws Throwable {
+    public void test8() throws Exception {
         String query = "A = load 'x' as ( a : int, b, c : chararray );" +
                        "B = group A by a;" +
                        "C = foreach B { S = A.b; generate S; };" +
                        "store C into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (a:int, b, c:chararray);\n" +
+            "macro_mymacro_B_0 = group macro_mymacro_A_0 by (a);\n" + 
+            "macro_mymacro_C_0 = foreach macro_mymacro_B_0 { S = macro_mymacro_A_0.(b);  generate S; } ;\n" +
+            "store macro_mymacro_C_0 INTO 'y';\n";
+            
+        testMacro( query, expected );
     }
     
     @Test
-    public void test9() throws Throwable {
+    public void test9() throws Exception {
         String query = "A = load 'x' as ( a : bag{ T:tuple(u, v) }, c : int, d : long );" +
                        "B = foreach A { R = a; S = R.u; T = limit S 100; generate S, T, c + d/5; };" +
                        "store B into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (a:bag{T:(u, v)}, c:int, d:long);\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 { R = a; S = R.(u); T = limit S 100;  generate S, T, c + d / 5; } ;\n" +
+            "store macro_mymacro_B_0 INTO 'y';\n";
+            
+        testMacro( query, expected );
     }
 
     @Test
-    public void test10() throws Throwable {
+    public void test10() throws Exception {
         String query = "A = load 'x' as ( a : bag{ T:tuple(u, v) }, c : int, d : long );" +
                        "B = foreach A { S = a; T = limit S 100; generate T; };" +
                        "store B into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (a:bag{T:(u, v)}, c:int, d:long);\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 { S = a; T = limit S 100;  generate T; } ;\n" +
+            "store macro_mymacro_B_0 INTO 'y';\n";
+            
+        testMacro( query, expected );
     }
 
     @Test
-    public void test11() throws Throwable {
+    public void test11() throws Exception {
         String query = "A = load 'x' as ( a : bag{ T:tuple(u, v) }, c : int, d : long );" +
                        "B = foreach A { T = limit a 100; generate T; };" +
                        "store B into 'y';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (a:bag{T:(u, v)}, c:int, d:long);\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 { T = limit a 100;  generate T; } ;\n" +
+            "store macro_mymacro_B_0 INTO 'y';\n";
+            
+        testMacro( query, expected );
     }
 
-    //@Test
-    public void test12() throws Throwable {
-        String query = "define CMD `perl GroupBy.pl '\t' 0 1` ship('/homes/jianyong/pig_harness/libexec/PigTest/GroupBy.pl');" +
+    @Test
+    public void test12() throws Exception {
+        String query = "define CMD `perl GroupBy.pl '\t' 0 1` ship('"+Util.encodeEscape(command.toString())+"');" +
                        "A = load '/user/pig/tests/data/singlefile/studenttab10k';" +
                        "B = group A by $0;" +
                        "C = foreach B {" +
@@ -1498,9 +1281,9 @@ public class TestMacroExpansion {
         testMacro( query );
     }
     
-    //@Test
-    public void test13() throws Throwable {
-        String query = "define CMD `perl PigStreaming.pl` ship('/homes/jianyong/pig_harness/libexec/PigTest/PigStreaming.pl') stderr('CMD');" +
+    @Test
+    public void test13() throws Exception {
+        String query = "define CMD `perl PigStreaming.pl` ship('"+Util.encodeEscape(command.toString())+"') stderr('CMD');" +
                        "A = load '/user/pig/tests/data/singlefile/studenttab10k';" +
                        "C = stream A through CMD;" +
                        "store C into '/user/pig/out/jianyong.1297238871/StreamingPerformance_1.out';";
@@ -1508,18 +1291,27 @@ public class TestMacroExpansion {
     }
     
     @Test
-    public void test14() throws Throwable {
+    public void test14() throws Exception {
         String query = "a = load '/user/pig/tests/data/singlefile/studenttab10k' using PigStorage() as (name, age:int, gpa);" +
                        "b = load '/user/pig/tests/data/singlefile/votertab10k' as (name, age, registration, contributions);" +
                        "e = cogroup a by name, b by name parallel 8;" +
                        "f = foreach e generate group,  SUM(a.age) as s;" +
                        "g = filter f by s>0;" +
                        "store g into '/user/pig/out/jianyong.1297323675/Accumulator_1.out';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_a_0 = load '/user/pig/tests/data/singlefile/studenttab10k' USING PigStorage() as (name, age:int, gpa);\n" +
+            "macro_mymacro_b_0 = load '/user/pig/tests/data/singlefile/votertab10k' as (name, age, registration, contributions);\n" +
+            "macro_mymacro_e_0 = cogroup macro_mymacro_a_0 by (name), macro_mymacro_b_0 by (name) parallel 8;\n" +
+            "macro_mymacro_f_0 = foreach macro_mymacro_e_0 generate group, SUM(macro_mymacro_a_0.(age)) AS s;\n" +
+            "macro_mymacro_g_0 = filter macro_mymacro_f_0 BY (s > 0);\n" +
+            "store macro_mymacro_g_0 INTO '/user/pig/out/jianyong.1297323675/Accumulator_1.out';\n";
+        
+        testMacro( query, expected );
     }
     
     @Test
-    public void test15() throws Throwable {
+    public void test15() throws Exception {
         String query = "a = load '/user/pig/tests/data/singlefile/studenttab10k' using PigStorage() as (name, age, gpa);" +
                        "b = group a all;" +
                        "c = foreach b generate AVG(a.age) as avg; " +
@@ -1528,94 +1320,442 @@ public class TestMacroExpansion {
                        "f = foreach e generate AVG(d.age) as avg;" +
                        "y = foreach a generate age/c.avg, age/f.avg;" +
                        "store y into '/user/pig/out/jianyong.1297323675/Scalar_4.out';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_a_0 = load '/user/pig/tests/data/singlefile/studenttab10k' USING PigStorage() as (name, age, gpa);\n" +
+            "macro_mymacro_b_0 = group macro_mymacro_a_0 all;\n" + 
+            "macro_mymacro_c_0 = foreach macro_mymacro_b_0 generate AVG(macro_mymacro_a_0.(age)) AS avg;\n" + 
+            "macro_mymacro_d_0 = load '/user/pig/tests/data/singlefile/votertab10k' USING PigStorage() as (name, age, registration, contributions);\n" +
+            "macro_mymacro_e_0 = group macro_mymacro_d_0 all;\n" + 
+            "macro_mymacro_f_0 = foreach macro_mymacro_e_0 generate AVG(macro_mymacro_d_0.(age)) AS avg;\n" +
+            "macro_mymacro_y_0 = foreach macro_mymacro_a_0 generate age / macro_mymacro_c_0.(avg), age / macro_mymacro_f_0.(avg);\n" +
+            "store macro_mymacro_y_0 INTO '/user/pig/out/jianyong.1297323675/Scalar_4.out';\n";
+        
+        testMacro( query, expected );
     }
     
     @Test
-    public void test16() throws Throwable {
+    public void test16() throws Exception {
         String query = "AA = load '/user/pig/tests/data/singlefile/studenttab10k';" +
                        "A = foreach (group (filter AA by $0 > 0) all) generate flatten($1);" +
                        "store A into '/user/pig/out/jianyong.1297323675/Scalar_4.out';";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_AA_0 = load '/user/pig/tests/data/singlefile/studenttab10k';\n" +
+            "macro_mymacro_A_0 = foreach  (group  (filter macro_mymacro_AA_0 BY ($0 > 0))  all)  generate flatten($1) ;\n" +
+            "store macro_mymacro_A_0 INTO '/user/pig/out/jianyong.1297323675/Scalar_4.out';\n";
+            
+        testMacro( query, expected );
     }
 
+    
     @Test
-    public void testFilter() throws Throwable {
+    public void test17() throws Exception {
+        String macro = 
+            "a = load '/user/pig/tests/data/singlefile/studentnulltab10k' as (name:chararray, age:int, gpa:double);" +
+            "b = foreach a generate (int)((int)gpa/((int)gpa - 1)) as norm_gpa:int;" + 
+            "c = foreach b generate (norm_gpa is not null? norm_gpa: 0);" +
+            "store c into '/user/pig/out/jianyong.1297229709/Types_37.out';";
+            
+        String expected =
+            "macro_mymacro_a_0 = load '/user/pig/tests/data/singlefile/studentnulltab10k' as (name:chararray, age:int, gpa:double);\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate (int)((int)gpa / ((int)gpa - 1)) AS norm_gpa:int;\n" +
+            "macro_mymacro_c_0 = foreach macro_mymacro_b_0 generate  (norm_gpa IS not null ? norm_gpa : 0) ;\n" +
+            "store macro_mymacro_c_0 INTO '/user/pig/out/jianyong.1297229709/Types_37.out';\n";
+            
+        testMacro(macro, expected);
+    }
+    
+    @Test
+    public void test18() throws Exception {
+        String macro = "define mymacro() returns dummy {" +
+            "a = load '/user/pig/tests/data/singlefile/studenttab10k';" +
+            "b = group a by $0;" +
+            "c = foreach b {c1 = order $1 by *; generate flatten(c1); };" +
+            "store c into '/user/pig/out/jianyong.1297305352/Order_15.out';};";
+            
+        String script = macro +
+            "dummy = mymacro();\n";
+        
+        String expected =
+            "macro_mymacro_a_0 = load '/user/pig/tests/data/singlefile/studenttab10k';\n" +
+            "macro_mymacro_b_0 = group macro_mymacro_a_0 by ($0);\n" +
+            "macro_mymacro_c_0 = foreach macro_mymacro_b_0 { c1 = order $1 BY *;  generate flatten(c1) ; } ;\n" +
+            "store macro_mymacro_c_0 INTO '/user/pig/out/jianyong.1297305352/Order_15.out';\n";
+        
+        verify(script, expected);
+    }
+    
+    @Test
+    public void test19() throws Exception {
+        String macro = 
+            "a = load '/user/pig/tests/data/singlefile/studenttab10k';" +
+            "b = group a by $0;" +
+            "c = foreach b {c1 = order $1 by $1; generate flatten(c1), MAX($1.$1); };" +
+            "store c into '/user/pig/out/jianyong.1297305352/Order_17.out';";
+            
+        String expected =
+            "macro_mymacro_a_0 = load '/user/pig/tests/data/singlefile/studenttab10k';\n" +
+            "macro_mymacro_b_0 = group macro_mymacro_a_0 by ($0);\n" +
+            "macro_mymacro_c_0 = foreach macro_mymacro_b_0 { c1 = order $1 BY $1;  generate flatten(c1) , MAX($1.($1)); } ;\n" +
+            "store macro_mymacro_c_0 INTO '/user/pig/out/jianyong.1297305352/Order_17.out';\n";
+            
+        testMacro(macro, expected);
+    }
+    
+    @Test
+    public void test20() throws Exception {
+        String macro = 
+            "a = load 'x' as (u,v);" +
+            "b = load 'y' as (u,w);" +
+            "c = join a by u, b by u;" +
+            "d = foreach c generate a::u, b::u, w;";
+            
+        String expected =
+            "macro_mymacro_a_0 = load 'x' as (u, v);\n" +
+            "macro_mymacro_b_0 = load 'y' as (u, w);\n" +
+            "macro_mymacro_c_0 = join macro_mymacro_a_0 by (u), macro_mymacro_b_0 by (u);\n" +
+            "macro_mymacro_d_0 = foreach macro_mymacro_c_0 generate macro_mymacro_a_0::u, macro_mymacro_b_0::u, w;\n";
+        
+        testMacro(macro, expected);
+    }
+    
+    @Test
+    public void test21() throws Exception {
+        String macro = 
+            "a = load '1.txt' as ( u, v, w : int );" +
+            "b = foreach a generate * as ( x, y, z ), flatten( u ) as ( r, s ), flatten( v ) as d, w + 5 as e:int;";
+            
+        String expected =
+            "macro_mymacro_a_0 = load '1.txt' as (u, v, w:int);\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate  * AS (x, y, z), flatten(u)  AS (r, s), flatten(v)  AS d, w + 5 AS e:int;\n";
+        
+        testMacro(macro, expected);
+    }
+    
+    @Test
+    public void test22() throws Exception {
+        String macro =
+            "a = load '1.txt' as ( u : bag{}, v : bag{tuple(x, y)} );" +
+            "b = load '2.x' as ( t : {}, u : {(r,s)}, v : bag{ T : tuple( x, y ) }, w : bag{(z1, z2)} );" +
+            "c = load '3.x' as p : int;";
+            
+        String expected =
+            "macro_mymacro_a_0 = load '1.txt' as (u:bag{}, v:bag{T:(x, y)});\n" +
+            "macro_mymacro_b_0 = load '2.x' as (t:bag{}, u:bag{T:(r, s)}, v:bag{T:(x, y)}, w:bag{T:(z1, z2)});\n" +
+            "macro_mymacro_c_0 = load '3.x' as p:int;\n";
+        
+        testMacro(macro, expected);
+    }
+
+    @Test
+    public void test23() throws Exception {
+        String macro = 
+            "a = load '1.txt' as ( u, v, w : int );" +
+            "b = foreach a generate * as ( x, y, z ), flatten( u ) as ( r, s ), flatten( v ) as d, w + 5 as e:int;";
+            
+        String expected =
+            "macro_mymacro_a_0 = load '1.txt' as (u, v, w:int);\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate  * AS (x, y, z), flatten(u)  AS (r, s), flatten(v)  AS d, w + 5 AS e:int;\n";
+        
+        testMacro(macro, expected);
+    }
+    
+    @Test
+    public void test24() throws Exception {
+        String macro = 
+            "A = load 'x' as ( u:bag{tuple(x, y)}, v:long, w:bytearray); " + 
+            "B = foreach A generate u.(x, y), v, w; " +
+            "C = store B into 'output';";
+            
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (u:bag{T:(x, y)}, v:long, w:bytearray);\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 generate u.(x, y), v, w;\n" +
+            "macro_mymacro_C_0 = store macro_mymacro_B_0 INTO 'output';\n";
+        
+        testMacro(macro, expected);
+    }
+    
+    @Test
+    public void test25() throws Exception {
+        String macro = 
+            "A = load 'x' as ( a : bag{ T:tuple(u, v) }, c : int, d : long );" +
+            "B = foreach A { R = a; P = c * 2; Q = P + d; S = R.u; T = limit S 100; generate Q, R, S, T, c + d/5; };" +
+            "store B into 'y';";
+            
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (a:bag{T:(u, v)}, c:int, d:long);\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 { R = a; P = c * 2; Q = P + d; S = R.(u); T = limit S 100;  generate Q, R, S, T, c + d / 5; } ;\n" +
+            "store macro_mymacro_B_0 INTO 'y';\n";
+        
+        testMacro(macro, expected);
+    }
+    
+    @Test
+    public void test26() throws Exception {
+        String content =
+            "A = load 'x' as ( u:bag{tuple(x, y)}, v:long, w:bytearray); " + 
+            "B = foreach A generate u.(x, $1), $1, w; " +
+            "C = store B into 'output';";
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (u:bag{T:(x, y)}, v:long, w:bytearray);\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 generate u.(x, $1), $1, w;\n" +
+            "macro_mymacro_C_0 = store macro_mymacro_B_0 INTO 'output';\n";
+            
+        testMacro(content, expected);
+    }
+    
+    @Test
+    public void test27() throws Exception {
+        String content =
+            "A = load 'x' as ( u:bag{} ); " + 
+            "B = foreach A generate u.$100; " +
+            "C = store B into 'output';";
+            
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as u:bag{};\n" +
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 generate u.($100);\n" +
+            "macro_mymacro_C_0 = store macro_mymacro_B_0 INTO 'output';\n";
+        
+        testMacro(content, expected);
+    }
+    
+    @Test
+    public void test28() throws Exception {
+        String content =
+            "A = load 'x'; " + 
+            "B = foreach A generate $1, $1000; " +
+            "C = store B into 'output';";
+            
+        String expected =
+            "macro_mymacro_A_0 = load 'x';\n" + 
+            "macro_mymacro_B_0 = foreach macro_mymacro_A_0 generate $1, $1000;\n" +
+            "macro_mymacro_C_0 = store macro_mymacro_B_0 INTO 'output';\n";
+        
+        testMacro(content, expected);
+    }
+    
+    @Test
+    public void test29() throws Exception {
+        String content =
+            "A = load 'x'; " + 
+            "B = load 'y' as ( u : int, v : chararray );" +
+            "C = foreach A generate B.$1, $0; " +
+            "D = store C into 'output';";
+            
+        String expected =
+            "macro_mymacro_A_0 = load 'x';\n" + 
+            "macro_mymacro_B_0 = load 'y' as (u:int, v:chararray);\n" +
+            "macro_mymacro_C_0 = foreach macro_mymacro_A_0 generate macro_mymacro_B_0.($1), $0;\n" +
+            "macro_mymacro_D_0 = store macro_mymacro_C_0 INTO 'output';\n";
+        
+        testMacro(content, expected);
+    }
+    
+    @Test
+    public void test30() throws Exception {
+        String content =
+            "A = load 'x'; " + 
+            "B = load 'y' as ( u : int, v : chararray );" +
+            "C = foreach A generate B.$1, $0; " +
+            "D = store C into 'output';";
+            
+        String expected =
+            "macro_mymacro_A_0 = load 'x';\n" +
+            "macro_mymacro_B_0 = load 'y' as (u:int, v:chararray);\n" +
+            "macro_mymacro_C_0 = foreach macro_mymacro_A_0 generate macro_mymacro_B_0.($1), $0;\n" +
+            "macro_mymacro_D_0 = store macro_mymacro_C_0 INTO 'output';\n";
+        
+        testMacro(content, expected);
+    }
+    
+    @Test
+    public void test31() throws Exception {
+        String content =
+            "A = load 'x'; " + 
+            "B = load 'y' as ( u : int, v : chararray );" +
+            "C = foreach A generate B.v, $0; " +
+            "D = store C into 'output';";
+            
+        String expected =
+            "macro_mymacro_A_0 = load 'x';\n" +
+            "macro_mymacro_B_0 = load 'y' as (u:int, v:chararray);\n" +
+            "macro_mymacro_C_0 = foreach macro_mymacro_A_0 generate macro_mymacro_B_0.(v), $0;\n" +
+            "macro_mymacro_D_0 = store macro_mymacro_C_0 INTO 'output';\n";
+        
+        testMacro(content, expected);
+    }
+    
+    @Test
+    public void testFilter() throws Exception {
         String query = "A = load 'x' as ( u:int, v:long, w:bytearray); " + 
                        "B = filter A by 2 > 1; ";
-        testMacro( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (u:int, v:long, w:bytearray);\n" +
+            "macro_mymacro_B_0 = filter macro_mymacro_A_0 BY (2 > 1);\n";
+        
+        testMacro( query, expected );
     }
 
     @Test
-    public void testScopedAlias() throws Throwable {
+    public void testScopedAlias() throws Exception {
         String query = "A = load 'x' as ( u:int, v:long, w:bytearray);" + 
                        "B = load 'y' as ( u:int, x:int, y:chararray);" +
                        "C = join A by u, B by u;" +
                        "D = foreach C generate A::u, B::u, v, x;" +
                        "store D into 'z';";
-        testMacro ( query );
+        
+        String expected =
+            "macro_mymacro_A_0 = load 'x' as (u:int, v:long, w:bytearray);\n" +
+            "macro_mymacro_B_0 = load 'y' as (u:int, x:int, y:chararray);\n" +
+            "macro_mymacro_C_0 = join macro_mymacro_A_0 by (u), macro_mymacro_B_0 by (u);\n" +
+            "macro_mymacro_D_0 = foreach macro_mymacro_C_0 generate macro_mymacro_A_0::u, macro_mymacro_B_0::u, v, x;\n" +
+            "store macro_mymacro_D_0 INTO 'z';\n";
+        
+        testMacro ( query, expected );
     }
 
     @Test
-    public void test32() throws Throwable {
+    public void test32() throws Exception {
         String query = "a = load 'testSimpleMapKeyLookup' as (m:map[int]);" + 
                        "b = foreach a generate m#'key';";
         
-        testMacro( query );
+        String expected =
+            "macro_mymacro_a_0 = load 'testSimpleMapKeyLookup' as m:map[int];\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate m#'key';\n";
+        
+        testMacro( query, expected );
     }
     
     @Test
-    public void test33() throws Throwable {
+    public void test33() throws Exception {
         String query = "a = load 'testSimpleMapCast' as (m);" + 
                        "b = foreach a generate ([int])m;";
         
-        testMacro( query );
+        String expected =
+            "macro_mymacro_a_0 = load 'testSimpleMapCast' as m;\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate (map[int])m;\n";
+        
+        testMacro( query, expected );
     }
     
     @Test
-    public void test34() throws Throwable {
+    public void test34() throws Exception {
         String query = "a = load 'testComplexLoad' as (m:map[bag{(i:int,j:int)}]);";
         
-        testMacro( query );
+        String expected =
+            "macro_mymacro_a_0 = load 'testComplexLoad' as m:map[bag{T:(i:int, j:int)}];\n";
+        
+        testMacro( query, expected );
     }
     
     @Test
-    public void test35() throws Throwable {
+    public void test35() throws Exception {
         String query = "a = load 'testComplexCast' as (m);" +
                        "b = foreach a generate ([{(i:int,j:int)}])m;";
         
-        testMacro( query );
+        String expected =
+            "macro_mymacro_a_0 = load 'testComplexCast' as m;\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate (map[bag{T:(i:int, j:int)}])m;\n";
+        
+        testMacro( query, expected );
+    }
+    
+    @Test
+    public void testCommentInMacro() throws Exception {
+        String query = "a = load 'testComplexCast' as (m);\n" +
+                       " /* this is a test } and \n" +
+                       " and test ***/\n" +
+                       " -- this is another test } \n" +
+                       "b = foreach a generate ([{(i:int,j:int)}])m;";
+        
+        String expected =
+            "macro_mymacro_a_0 = load 'testComplexCast' as m;\n" +
+            "macro_mymacro_b_0 = foreach macro_mymacro_a_0 generate (map[bag{T:(i:int, j:int)}])m;\n";
+
+        testMacro( query, expected );
+    }
+    
+    @Test 
+    public void caseInsensitiveTest() throws Exception {
+        String macro = "DEFINE group_and_count (A,group_key) RETURNS B {\n" +
+            "    D = group $A by $group_key partition by org.apache.pig.test.utils.SimpleCustomPartitioner parallel 50;\n" +
+            "    $B = foreach D generate group, COUNT($A);\n" +
+            "};\n";
+        
+        String script = 
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "gamma = group_and_count (alpha, user);\n" +
+            "delta = group_and_count (alpha, age);\n" +
+            "store gamma into 'byuser';\n" +
+            "store delta into 'byage';\n";
+                
+        String expected =
+            "alpha = load 'users' as (user, age, zip);\n" +
+            "macro_group_and_count_D_0 = group alpha by (user) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 50;\n" +
+            "gamma = foreach macro_group_and_count_D_0 generate group, COUNT(alpha);\n" +
+            "macro_group_and_count_D_1 = group alpha by (age) partition BY org.apache.pig.test.utils.SimpleCustomPartitioner parallel 50;\n" +
+            "delta = foreach macro_group_and_count_D_1 generate group, COUNT(alpha);\n" +
+            "store gamma INTO 'byuser';\n" +
+            "store delta INTO 'byage';\n";
+        
+        verify(macro + script, expected);
     }
     
     //-------------------------------------------------------------------------
     
-    private void testMacro(String content) throws Throwable {
+    private void testMacro(String content) throws Exception {
+        testMacro(content, null);
+    }
+    
+    private void testMacro(String content, String expected) throws Exception {
         String macro = "define mymacro() returns dummy {" +
             content + "};";
             
         String script = macro +
             "dummy = mymacro();\n";
         
-        StringReader rd = new StringReader(script);
-        String s = ParserUtil.expandMacros(rd);
+        verify(script, expected);
+    }
 
-        System.out.println("result:\n" + s);
-      
-        validate(s);
+    private void verify(String s) throws Exception {
+        verify(s, null);
     }
     
-    private void validate(String s) throws Throwable {
-        PigContext pigContext = new PigContext(ExecType.LOCAL, new Properties());
-        BufferedReader br = new BufferedReader(new StringReader(s));
-        Grunt grunt = new Grunt(br, pigContext);
+    private void verify(String s, String expected) throws Exception {
+        File f1 = new File("myscript.pig");
+        f1.deleteOnExit();
         
-        File f = new File("macro_expansion.txt");
-        FileWriter w = new FileWriter(f);
-        w.append(s);
-        w.close();
+        FileWriter fw1 = new FileWriter(f1);
+        fw1.append(s);
+        fw1.close();
+        
+        String[] args = { "-Dpig.import.search.path=/tmp", "-x", "local", "-c", "myscript.pig" };
+        PigStats stats = PigRunner.run(args, null);
+ 
+        assertTrue(stats.isSuccessful());
         
-        grunt.checkScript("macro_expansion.txt");
-        f.delete();
+        String[] args2 = { "-Dpig.import.search.path=/tmp", "-x", "local", "-r", "myscript.pig" };
+        PigRunner.run(args2, null);
+        
+        File f2 = new File("myscript.pig.expanded");
+        BufferedReader br = new BufferedReader(new FileReader(f2));
+        StringBuilder sb = new StringBuilder();
+        String line = br.readLine();
+        
+        while (line != null) {
+            sb.append(line).append("\n");
+            line = br.readLine();
+        }
+        
+        f2.delete();
+        
+        if (expected != null) {
+            Assert.assertEquals(expected, sb.toString());
+        } else {
+            System.out.println("Result:\n" + sb.toString());
+        }
     }
-
 }
diff --git a/test/org/apache/pig/test/TestParamSubPreproc.java b/test/org/apache/pig/test/TestParamSubPreproc.java
index 1c7a790fe..849379a93 100644
--- a/test/org/apache/pig/test/TestParamSubPreproc.java
+++ b/test/org/apache/pig/test/TestParamSubPreproc.java
@@ -1482,4 +1482,50 @@ public class TestParamSubPreproc extends TestCase {
         log.info("Done");
     }
 
+    @Test
+    public void testMacroDef() throws Exception{
+        log.info("Starting test testMacroDef() ...");
+        try {
+            ParameterSubstitutionPreprocessor ps = new ParameterSubstitutionPreprocessor(50);
+            pigIStream = new BufferedReader(new FileReader(basedir + "/input6.pig"));
+            pigOStream = new FileWriter(basedir + "/output1.pig");
+
+            String[] arg = {"date=20080228"};
+            String[] argFiles = null;
+            ps.genSubstitutedFile(pigIStream , pigOStream , arg , argFiles);
+
+            FileInputStream pigResultStream = new FileInputStream(basedir + "/output1.pig");
+            pigExResultStream = new FileInputStream(basedir + "/ExpectedResult6.pig");
+            BufferedReader inExpected = new BufferedReader(new InputStreamReader(pigExResultStream));
+            BufferedReader inResult = new BufferedReader(new InputStreamReader(pigResultStream));
+
+            String exLine;
+            String resLine;
+            int lineNum=0;
+
+            while (true) {
+                lineNum++;
+                exLine = inExpected.readLine();
+                resLine = inResult.readLine();
+                if (exLine==null || resLine==null)
+                    break;
+                assertEquals("Command line parameter substitution failed. " + "Expected : "+exLine+" , but got : "+resLine+" in line num : "+lineNum ,exLine.trim(), resLine.trim());
+            }
+            if (!(exLine==null && resLine==null)) {
+                fail ("Command line parameter substitution failed. " + "Expected : "+exLine+" , but got : "+resLine+" in line num : "+lineNum);
+            }
+
+            inExpected.close();
+            inResult.close();
+        } catch (ParseException e) {
+            fail ("Got ParseException : " + e.getMessage());
+        } catch (RuntimeException e) {
+            fail ("Got RuntimeException : " + e.getMessage());
+        } catch (Error e) {
+            fail ("Got error : " + e.getMessage());
+        }
+
+        log.info("Done");
+
+    }
 }
diff --git a/test/org/apache/pig/test/data/ExpectedResult6.pig b/test/org/apache/pig/test/data/ExpectedResult6.pig
new file mode 100644
index 000000000..bcf86b5e7
--- /dev/null
+++ b/test/org/apache/pig/test/data/ExpectedResult6.pig
@@ -0,0 +1,15 @@
+define mymacro1(A, rate) returns B {
+    C = group $A by $0 parallel $rate;
+    B = foreach C generate group, COUNT($A);
+};
+
+aa = load '/data/intermediate/pow/elcarobootstrap/account/full/weekly/data/20080228' using PigStorage('\x01');
+bb = filter aa by (ARITY == '16') and ( $4 eq '' or $4 eq 'NULL' or $4 eq 'ss') parallel 400;
+a = foreach bb generate $0,$12,$7;
+
+--generate inactive accts
+inactiveAccounts = filter a by ($1 neq '') and ($1 == '2') parallel 400;
+store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct';
+grpInactiveAcct = group inactiveAccounts all;
+countInactiveAcct = foreach grpInactiveAcct { generate COUNT( inactiveAccounts ); }
+store countInactiveAcct into '/user/kaleidoscope/pow_stats/20080228/acct_stats/InactiveAcctCount';
diff --git a/test/org/apache/pig/test/data/input6.pig b/test/org/apache/pig/test/data/input6.pig
new file mode 100644
index 000000000..aff504efe
--- /dev/null
+++ b/test/org/apache/pig/test/data/input6.pig
@@ -0,0 +1,15 @@
+define mymacro1(A, rate) returns B { 
+    C = group $A by $0 parallel $rate;
+    B = foreach C generate group, COUNT($A);
+};
+
+aa = load '/data/intermediate/pow/elcarobootstrap/account/full/weekly/data/$date' using PigStorage('\x01');
+bb = filter aa by (ARITY == '16') and ( $4 eq '' or $4 eq 'NULL' or $4 eq 'ss') parallel 400;
+a = foreach bb generate $0,$12,$7;
+
+--generate inactive accts
+inactiveAccounts = filter a by ($1 neq '') and ($1 == '2') parallel 400;
+store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct';
+grpInactiveAcct = group inactiveAccounts all;
+countInactiveAcct = foreach grpInactiveAcct { generate COUNT( inactiveAccounts ); }
+store countInactiveAcct into '/user/kaleidoscope/pow_stats/20080228/acct_stats/InactiveAcctCount';
diff --git a/test/org/apache/pig/test/data/output1.pig b/test/org/apache/pig/test/data/output1.pig
index d8ab6a67a..694f30a53 100644
--- a/test/org/apache/pig/test/data/output1.pig
+++ b/test/org/apache/pig/test/data/output1.pig
@@ -1,17 +1,14 @@
--- %declare date '20080228'
--- l = load '$xyz';
+define mymacro1(A, rate) returns B { 
+    C = group $A by $0 parallel $rate;
+    B = foreach C generate group, COUNT($A);
+};
 
-/* comment */ 
-
-/* l = load '$zxv';
-   store l into '$zxcv';
-*/
 aa = load '/data/intermediate/pow/elcarobootstrap/account/full/weekly/data/20080228' using PigStorage('\x01');
 bb = filter aa by (ARITY == '16') and ( $4 eq '' or $4 eq 'NULL' or $4 eq 'ss') parallel 400;
-a = foreach bb generate /* $col 1 */ $0,$12,$7;  
-/* $date /* */
+a = foreach bb generate $0,$12,$7;
+
 --generate inactive accts
-inactiveAccounts = filter a by ($1 neq '') and ($1 == '2') parallel 400; -- testing $comment
+inactiveAccounts = filter a by ($1 neq '') and ($1 == '2') parallel 400;
 store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct';
 grpInactiveAcct = group inactiveAccounts all;
 countInactiveAcct = foreach grpInactiveAcct { generate COUNT( inactiveAccounts ); }
