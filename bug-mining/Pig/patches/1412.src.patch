diff --git a/CHANGES.txt b/CHANGES.txt
index 793b7fc19..c4754a3f9 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -105,6 +105,8 @@ PIG-3882: Multiquery off mode execution is not done in batch and very inefficien
  
 BUG FIXES
 
+PIG-3888: Direct fetch doesn't differentiate between frontend and backend sides (lbendig via daijy)
+
 PIG-3887: TestMRJobStats is broken in trunk (cheolsoo)
 
 PIG-3868: Fix Iterator_1 e2e test on windows (ssvinarchukhorton via rohini)
diff --git a/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java b/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
index 444b5f943..50eca6906 100644
--- a/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
+++ b/shims/src/hadoop20/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
@@ -119,4 +119,14 @@ public class HadoopShims {
     public static void unsetConf(Configuration conf, String key) {
         // Not supported in Hadoop 0.20/1.x
     }
+    
+    /**
+     * Fetch mode needs to explicitly set the task id which is otherwise done by Hadoop 
+     * @param conf
+     * @param taskAttemptID
+     */
+    public static void setTaskAttemptId(Configuration conf, TaskAttemptID taskAttemptID) {
+        conf.set("mapred.task.id", taskAttemptID.toString());
+    }
+    
 }
diff --git a/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java b/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
index 7ff4eb76b..b06b90189 100644
--- a/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
+++ b/shims/src/hadoop23/org/apache/pig/backend/hadoop/executionengine/shims/HadoopShims.java
@@ -119,4 +119,14 @@ public class HadoopShims {
     public static void unsetConf(Configuration conf, String key) {
         conf.unset(key);
     }
+    
+    /**
+     * Fetch mode needs to explicitly set the task id which is otherwise done by Hadoop 
+     * @param conf
+     * @param taskAttemptID
+     */
+    public static void setTaskAttemptId(Configuration conf, TaskAttemptID taskAttemptID) {
+        conf.setInt("mapreduce.job.application.attempt.id", taskAttemptID.getId());
+    }
+    
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/fetch/FetchLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/fetch/FetchLauncher.java
index 689e4248e..6ba466fe9 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/fetch/FetchLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/fetch/FetchLauncher.java
@@ -21,6 +21,7 @@ import java.io.IOException;
 import java.io.PrintStream;
 
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.mapreduce.TaskAttemptID;
 import org.apache.pig.PigException;
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
@@ -34,6 +35,7 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.Physica
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStore;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStream;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.util.PlanHelper;
+import org.apache.pig.backend.hadoop.executionengine.shims.HadoopShims;
 import org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil;
 import org.apache.pig.data.SchemaTupleBackend;
 import org.apache.pig.impl.PigContext;
@@ -70,17 +72,22 @@ public class FetchLauncher {
      * @throws IOException
      */
     public PigStats launchPig(PhysicalPlan pp) throws IOException {
-        POStore poStore = (POStore) pp.getLeaves().get(0);
-        init(pp, poStore);
-
-        // run fetch
-        runPipeline(poStore);
-
-        UDFFinishVisitor udfFinisher = new UDFFinishVisitor(pp,
-                new DependencyOrderWalker<PhysicalOperator, PhysicalPlan>(pp));
-        udfFinisher.visit();
-
-        return PigStats.start(new EmptyPigStats(pigContext, poStore));
+        try {
+            POStore poStore = (POStore) pp.getLeaves().get(0);
+            init(pp, poStore);
+
+            // run fetch
+            runPipeline(poStore);
+            
+            UDFFinishVisitor udfFinisher = new UDFFinishVisitor(pp,
+                    new DependencyOrderWalker<PhysicalOperator, PhysicalPlan>(pp));
+            udfFinisher.visit();
+            
+            return PigStats.start(new EmptyPigStats(pigContext, poStore));
+        }
+        finally {
+            UDFContext.getUDFContext().addJobConf(null);
+        }
     }
 
     /**
@@ -112,6 +119,10 @@ public class FetchLauncher {
 
         poStore.setStoreImpl(new FetchPOStoreImpl(pigContext));
         poStore.setUp();
+
+        TaskAttemptID taskAttemptID = HadoopShims.getNewTaskAttemptID();
+        HadoopShims.setTaskAttemptId(conf, taskAttemptID);
+        
         if (!PlanHelper.getPhysicalOperators(pp, POStream.class).isEmpty()) {
             MapRedUtil.setupStreamingDirsConfSingle(poStore, pigContext, conf);
         }
