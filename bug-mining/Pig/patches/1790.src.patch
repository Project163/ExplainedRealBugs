diff --git a/CHANGES.txt b/CHANGES.txt
index 6bec99c07..8b3f21a1f 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -81,6 +81,8 @@ PIG-4639: Add better parser for Apache HTTPD access log (nielsbasjes via daijy)
 
 BUG FIXES
 
+PIG-4737: Check and fix clone implementation for all classes extending PhysicalOperator (rohini)
+
 PIG-4770: OOM with POPartialAgg in some cases (rohini)
 
 PIG-4773: [Pig on Tez] Secondary key descending sort in nested foreach after union does ascending instead (rohini)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java
index 65df3cc3e..6c492b2b4 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java
@@ -31,6 +31,7 @@ import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
+import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.Operator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
@@ -67,6 +68,8 @@ public abstract class PhysicalOperator extends Operator<PhyPlanVisitor> implemen
     protected static final long serialVersionUID = 1L;
     protected static final Result RESULT_EMPTY = new Result(POStatus.STATUS_NULL, null);
     protected static final Result RESULT_EOP = new Result(POStatus.STATUS_EOP, null);
+    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
+    protected static final BagFactory mBagFactory = BagFactory.getInstance();
 
     // The degree of parallelism requested
     protected int requestedParallelism;
@@ -289,7 +292,7 @@ public abstract class PhysicalOperator extends Operator<PhyPlanVisitor> implemen
         try {
             if (input == null && (inputs == null || inputs.size() == 0)) {
                 // log.warn("No inputs found. Signaling End of Processing.");
-                return new Result(POStatus.STATUS_EOP, null);
+                return RESULT_EOP;
             }
 
             // Should be removed once the model is clear
@@ -458,8 +461,11 @@ public abstract class PhysicalOperator extends Operator<PhyPlanVisitor> implemen
     }
 
     /**
-     * Make a deep copy of this operator. This function is blank, however,
+     * Make a copy of this operator. This function is blank, however,
      * we should leave a place holder so that the subclasses can clone
+     * to make deep copy as this one creates a shallow copy of
+     * non-primitive types (objects, arrays and lists)
+     *
      * @throws CloneNotSupportedException
      */
     @Override
@@ -472,6 +478,14 @@ public abstract class PhysicalOperator extends Operator<PhyPlanVisitor> implemen
         originalLocations.addAll(op.originalLocations);
     }
 
+    protected static List<PhysicalPlan> clonePlans(List<PhysicalPlan> origPlans) throws CloneNotSupportedException {
+        List<PhysicalPlan> clonePlans = new ArrayList<PhysicalPlan>(origPlans.size());
+        for (PhysicalPlan plan : origPlans) {
+            clonePlans.add(plan.clone());
+        }
+        return clonePlans;
+    }
+
     /**
      * @param physicalPlan
      */
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java
index 8cdc56e53..7dbfc682d 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java
@@ -27,12 +27,10 @@ import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.SingleTupleBag;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
@@ -51,10 +49,6 @@ public class POProject extends ExpressionOperator {
      */
     private static final long serialVersionUID = 1L;
 
-    private static TupleFactory tupleFactory = TupleFactory.getInstance();
-
-    protected static final BagFactory bagFactory = BagFactory.getInstance();
-
     private boolean resultSingleTupleBag = false;
 
     //The column to project
@@ -191,7 +185,7 @@ public class POProject extends ExpressionOperator {
             for(int col : columns) {
                 addColumn(objList, inpValue, col);
             }
-            ret = tupleFactory.newTupleNoCopy(objList);
+            ret = mTupleFactory.newTupleNoCopy(objList);
         }
         res.result = ret;
         illustratorMarkup(inpValue, res.result, -1);
@@ -277,20 +271,20 @@ public class POProject extends ExpressionOperator {
                     for (int col : columns) {
                         addColumn(objList, tuple, col);
                     }
-                    outBag = new SingleTupleBag( tupleFactory.newTupleNoCopy(objList) );
+                    outBag = new SingleTupleBag( mTupleFactory.newTupleNoCopy(objList) );
                 }else {
                     Tuple tmpTuple = getRangeTuple(tuple);
                     outBag = new SingleTupleBag(tmpTuple);
                 }
             } else {
-                outBag = bagFactory.newDefaultBag();
+                outBag = mBagFactory.newDefaultBag();
                 for (Tuple tuple : inpBag) {
                     if(!isProjectToEnd){
                         ArrayList<Object> objList = new ArrayList<Object>(columns.size());
                         for (int col : columns) {
                             addColumn(objList, tuple, col);
                         }
-                        outBag.add( tupleFactory.newTupleNoCopy(objList) );
+                        outBag.add( mTupleFactory.newTupleNoCopy(objList) );
                     }else{
                         Tuple outTuple = getRangeTuple(tuple);
                         outBag.add(outTuple);
@@ -321,14 +315,14 @@ public class POProject extends ExpressionOperator {
         Tuple outTuple;
         if(isRangeInvalid(lastColIdx)){
             //invalid range - return empty tuple
-            outTuple = tupleFactory.newTuple();
+            outTuple = mTupleFactory.newTuple();
         }
         else {
             ArrayList<Object> objList = new ArrayList<Object>(lastColIdx - startCol + 1);
             for(int i = startCol; i <= lastColIdx ; i++){
                 addColumn(objList, tuple, i);
             }
-            outTuple = tupleFactory.newTupleNoCopy(objList);
+            outTuple = mTupleFactory.newTupleNoCopy(objList);
         }
         return outTuple;
     }
@@ -451,7 +445,7 @@ public class POProject extends ExpressionOperator {
                         objList.add(null);
                     }
                 }
-                ret = tupleFactory.newTuple(objList);
+                ret = mTupleFactory.newTuple(objList);
                 res.result = (Tuple)ret;
                 return res;
             }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java
index ab2bdb093..317111bc2 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryComparisonOperator.java
@@ -19,13 +19,12 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 
 import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.plan.OperatorKey;
-import org.apache.pig.impl.util.IdentityHashSet;
 
 /**
  * This is a base class for all unary comparison operators. Supports the
  * use of operand type instead of result type as the result type is
  * always boolean.
- * 
+ *
  */
 public abstract class UnaryComparisonOperator extends UnaryExpressionOperator
         implements ComparisonOperator {
@@ -35,7 +34,7 @@ public abstract class UnaryComparisonOperator extends UnaryExpressionOperator
     //The result will be comunicated using the Status object.
     //This is a slight abuse of the status object.
     protected byte operandType;
-    
+
     public UnaryComparisonOperator(OperatorKey k) {
         this(k,-1);
     }
@@ -44,14 +43,16 @@ public abstract class UnaryComparisonOperator extends UnaryExpressionOperator
         super(k, rp);
     }
 
+    @Override
     public byte getOperandType() {
         return operandType;
     }
 
+    @Override
     public void setOperandType(byte operandType) {
         this.operandType = operandType;
     }
-    
+
     @Override
     public Tuple illustratorMarkup(Object in, Object out, int eqClassIndex) {
         if(illustrator != null) {
@@ -59,4 +60,9 @@ public abstract class UnaryComparisonOperator extends UnaryExpressionOperator
         }
         return null;
     }
+
+    protected void cloneHelper(UnaryComparisonOperator op) {
+        super.cloneHelper(op);
+        this.operandType = op.operandType;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCounter.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCounter.java
index b343d1802..e4d554fa3 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCounter.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCounter.java
@@ -28,7 +28,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlan
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.pen.util.ExampleTuple;
@@ -69,8 +68,6 @@ public class POCounter extends PhysicalOperator {
      **/
     private boolean isRowNumber = false;
 
-    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
-
     /**
      * Local counter for tuples on the same task.
      **/
@@ -321,4 +318,14 @@ public class POCounter extends PhysicalOperator {
     public String getOperationID() {
         return operationID;
     }
+
+    @Override
+    public POCounter clone() throws CloneNotSupportedException {
+        POCounter clone = (POCounter)super.clone();
+        clone.localCount = new Long(localCount);
+        clone.taskID = new Integer(taskID);
+        // counterPlans and mAscCols unused. Not cloning them
+        return clone;
+    }
+
 }
\ No newline at end of file
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCross.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCross.java
index cf16cca80..eb5e22481 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCross.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCross.java
@@ -25,7 +25,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
@@ -37,20 +36,20 @@ import org.apache.pig.pen.util.LineageTracer;
 
 /**
  * Recover this class for nested cross operation.
- * 
- * 
+ *
+ *
  */
 public class POCross extends PhysicalOperator {
 
     private static final long serialVersionUID = 1L;
 
-    protected DataBag[] inputBags;
+    protected transient DataBag[] inputBags;
 
-    protected Tuple[] data;
+    protected transient Tuple[] data;
 
     protected transient Iterator<Tuple>[] its;
-    
-    protected Tuple tupleOfLastBag;
+
+    protected transient Tuple tupleOfLastBag;
 
     public POCross(OperatorKey k) {
         super(k);
@@ -197,7 +196,7 @@ public class POCross extends PhysicalOperator {
         its = new Iterator[length];
         for (int i = 0; i < length; ++i) {
             PhysicalOperator op = inputs.get(i);
-            DataBag bag = BagFactory.getInstance().newDefaultBag();
+            DataBag bag = mBagFactory.newDefaultBag();
             inputBags[count] = bag;
             for (Result res = op.getNextTuple(); res.returnStatus != POStatus.STATUS_EOP; res = op
                     .getNextTuple()) {
@@ -226,7 +225,7 @@ public class POCross extends PhysicalOperator {
 
         return illustratorMarkup(out, out, 0);
     }
-    
+
     private boolean loadLastBag() throws ExecException {
         Result resOfLastBag = null;
         int index = inputs.size() - 1;
@@ -247,7 +246,7 @@ public class POCross extends PhysicalOperator {
                     "Error accumulating data in the local Cross operator");
         }
     }
-    
+
     private void clearMemory() {
         // reset inputBags, its, data and tupleOfLastBag to null so that in the
         // next round of getNext, the new input data will be loaded.
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
index 16e6f4d5b..6cd185ee8 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
@@ -30,7 +30,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.InternalDistinctBag;
@@ -49,9 +48,8 @@ import org.apache.pig.impl.plan.VisitorException;
 public class PODistinct extends PhysicalOperator implements Cloneable {
     private static final Log log = LogFactory.getLog(PODistinct.class);
     private static final long serialVersionUID = 1L;
-    private boolean inputsAccumulated = false;
-    private DataBag distinctBag = null;
-
+    private transient boolean inputsAccumulated;
+    private transient DataBag distinctBag;
     private transient boolean initialized;
     private transient boolean useDefaultBag;
     private transient Iterator<Tuple> it;
@@ -102,7 +100,7 @@ public class PODistinct extends PhysicalOperator implements Cloneable {
                      }
                  }
              }
-             distinctBag = useDefaultBag ? BagFactory.getInstance().newDistinctBag()
+             distinctBag = useDefaultBag ? mBagFactory.newDistinctBag()
                      : new InternalDistinctBag(3);
 
             Result in = processInput();
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java
index b6a654ba0..894cda7fc 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java
@@ -46,7 +46,6 @@ import org.apache.pig.data.SchemaTupleBackend;
 import org.apache.pig.data.SchemaTupleClassGenerator.GenContext;
 import org.apache.pig.data.SchemaTupleFactory;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.impl.io.FileSpec;
 import org.apache.pig.impl.logicalLayer.schema.Schema;
@@ -70,6 +69,7 @@ import org.apache.pig.impl.plan.VisitorException;
 public class POFRJoin extends PhysicalOperator {
     private static final Log log = LogFactory.getLog(POFRJoin.class);
     private static final long serialVersionUID = 1L;
+
     // The number in the input list which denotes the fragmented input
     protected int fragment;
     // There can be n inputs each being a List<PhysicalPlan>
@@ -85,18 +85,7 @@ public class POFRJoin extends PhysicalOperator {
     protected ConstantExpression[] constExps;
     // Used to produce the cross product of various bags
     protected POForEach fe;
-    // The array of Hashtables one per replicated input. replicates[fragment] =
-    // null
-    // fragment is the input which is fragmented and not replicated.
-    protected TupleToMapKey replicates[];
-    // varaible which denotes whether we are returning tuples from the foreach
-    // operator
-    protected boolean processingPlan;
-    // A dummy tuple
-    protected Tuple dumTup = TupleFactory.getInstance().newTuple(1);
-    // An instance of tuple factory
-    protected transient TupleFactory mTupleFactory;
-    protected boolean setUp;
+
     // A Boolean variable which denotes if this is a LeftOuter Join or an Inner
     // Join
     protected boolean isLeftOuterJoin;
@@ -106,6 +95,16 @@ public class POFRJoin extends PhysicalOperator {
     protected Schema[] inputSchemas;
     protected Schema[] keySchemas;
 
+    // The array of Hashtables one per replicated input. replicates[fragment] =
+    // null fragment is the input which is fragmented and not replicated.
+    protected transient TupleToMapKey replicates[];
+    // varaible which denotes whether we are returning tuples from the foreach
+    // operator
+    protected transient boolean processingPlan;
+    // A dummy tuple
+    protected transient Tuple dumTup;
+    protected transient boolean setUp;
+
     public POFRJoin(OperatorKey k, int rp, List<PhysicalOperator> inp,
             List<List<PhysicalPlan>> ppLists, List<List<Byte>> keyTypes,
             FileSpec[] replFiles, int fragment, boolean isLeftOuter,
@@ -126,12 +125,10 @@ public class POFRJoin extends PhysicalOperator {
         this.fragment = fragment;
         this.keyTypes = keyTypes;
         this.replFiles = replFiles;
-        replicates = new TupleToMapKey[ppLists.size()];
+
         LRs = new POLocalRearrange[ppLists.size()];
         constExps = new ConstantExpression[ppLists.size()];
         createJoinPlans(k);
-        processingPlan = false;
-        mTupleFactory = TupleFactory.getInstance();
         List<Tuple> tupList = new ArrayList<Tuple>();
         tupList.add(nullTuple);
         nullBag = new NonSpillableDataBag(tupList);
@@ -159,7 +156,6 @@ public class POFRJoin extends PhysicalOperator {
         this.fe = copy.fe;
         this.constExps = copy.constExps;
         this.processingPlan = copy.processingPlan;
-        this.mTupleFactory = copy.mTupleFactory;
         this.nullBag = copy.nullBag;
         this.isLeftOuterJoin = copy.isLeftOuterJoin;
         this.inputSchemas = copy.inputSchemas;
@@ -173,7 +169,7 @@ public class POFRJoin extends PhysicalOperator {
 
     /**
      * Configures the Local Rearrange operators & the foreach operator
-     * 
+     *
      * @param old
      * @throws ExecException
      */
@@ -238,6 +234,8 @@ public class POFRJoin extends PhysicalOperator {
         Result res = null;
         Result inp = null;
         if (!setUp) {
+            replicates = new TupleToMapKey[phyPlanLists.size()];
+            dumTup = mTupleFactory.newTuple(1);
             setUpHashMap();
             setUp = true;
         }
@@ -254,7 +252,7 @@ public class POFRJoin extends PhysicalOperator {
                 if (res.returnStatus == POStatus.STATUS_EOP) {
                     // We have completed all cross-products now its time to move
                     // to next tuple of left side
-                    processingPlan = false;                    
+                    processingPlan = false;
                     break;
                 }
                 if (res.returnStatus == POStatus.STATUS_ERR) {
@@ -284,7 +282,7 @@ public class POFRJoin extends PhysicalOperator {
                 return new Result();
             }
             Tuple lrOutTuple = (Tuple) lrOut.result;
-            Tuple key = TupleFactory.getInstance().newTuple(1);
+            Tuple key = mTupleFactory.newTuple(1);
             key.set(0, lrOutTuple.get(1));
             Tuple value = getValueTuple(lr, lrOutTuple);
             lr.detachInput();
@@ -390,9 +388,9 @@ public class POFRJoin extends PhysicalOperator {
 
             POLoad ld = new POLoad(new OperatorKey("Repl File Loader", 1L),
                     replFile);
-            
+
             Properties props = ConfigurationUtil.getLocalFSProperties();
-            PigContext pc = new PigContext(ExecType.LOCAL, props);   
+            PigContext pc = new PigContext(ExecType.LOCAL, props);
             ld.setPc(pc);
             // We use LocalRearrange Operator to seperate Key and Values
             // eg. ( a, b, c ) would generate a, ( a, b, c )
@@ -437,11 +435,10 @@ public class POFRJoin extends PhysicalOperator {
         }
         return false;
     }
-    
+
     private void readObject(ObjectInputStream is) throws IOException,
             ClassNotFoundException, ExecException {
         is.defaultReadObject();
-        mTupleFactory = TupleFactory.getInstance();
         // setUpHashTable();
     }
 
@@ -531,4 +528,28 @@ public class POFRJoin extends PhysicalOperator {
         // no op: all handled by the preceding POForEach
         return null;
     }
+
+    @Override
+    public POFRJoin clone() throws CloneNotSupportedException {
+        POFRJoin clone = (POFRJoin) super.clone();
+        // Not doing deep copy of nullBag, nullBag, inputSchemas, keySchemas
+        // as they are read only
+        clone.phyPlanLists = new ArrayList<List<PhysicalPlan>>(phyPlanLists.size());
+        for (List<PhysicalPlan> ppLst : phyPlanLists) {
+            clone.phyPlanLists.add(clonePlans(ppLst));
+        }
+
+        clone.LRs = new POLocalRearrange[phyPlanLists.size()];
+        clone.constExps = new ConstantExpression[phyPlanLists.size()];
+        try {
+            clone.createJoinPlans(getOperatorKey());
+        } catch (ExecException e) {
+            CloneNotSupportedException cnse = new CloneNotSupportedException("Problem with setting plans of " + this.getClass().getSimpleName());
+            cnse.initCause(e);
+            throw cnse;
+        }
+        return clone;
+    }
+
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFilter.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFilter.java
index bec37119d..198f68c19 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFilter.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFilter.java
@@ -49,17 +49,16 @@ public class POFilter extends PhysicalOperator {
     private static final long serialVersionUID = 1L;
 
     // The expression plan
-    PhysicalPlan plan;
+    private PhysicalPlan plan;
 
     // The root comparison operator of the expression plan
-//    ComparisonOperator comOp;
-    PhysicalOperator comOp;
-
+    // ComparisonOperator comOp;
+    private PhysicalOperator comOp;
 
     // The operand type for the comparison operator needed
     // to call the comparison operators getNext with the
     // appropriate type
-    byte compOperandType;
+    // private byte compOperandType;
 
     public POFilter(OperatorKey k) {
         this(k, -1, null);
@@ -205,8 +204,7 @@ public class POFilter extends PhysicalOperator {
 
     @Override
     public PhysicalOperator clone() throws CloneNotSupportedException {
-        Object o = super.clone();
-        POFilter opClone = (POFilter)o;
+        POFilter opClone = (POFilter) super.clone();
         opClone.setPlan(plan.clone());
         return opClone;
     }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java
index cb450f947..7621fe7ef 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java
@@ -57,26 +57,13 @@ public class POForEach extends PhysicalOperator {
     private static final long serialVersionUID = 1L;
 
     protected List<PhysicalPlan> inputPlans;
-    protected List<PhysicalOperator> opsToBeReset;
-    //Since the plan has a generate, this needs to be maintained
-    //as the generate can potentially return multiple tuples for
-    //same call.
-    protected boolean processingPlan = false;
-
-    //its holds the iterators of the databags given by the input expressions which need flattening.
-    transient protected Iterator<Tuple> [] its = null;
 
-    //This holds the outputs given out by the input expressions of any datatype
-    protected Object [] bags = null;
+    protected List<PhysicalOperator> opsToBeReset;
 
-    //This is the template whcih contains tuples and is flattened out in createTuple() to generate the final output
-    protected Object[] data = null;
+    protected PhysicalOperator[] planLeafOps;
 
     // store result types of the plan leaves
-    protected byte[] resultTypes = null;
-
-    // store whether or not an accumulative UDF has terminated early
-    protected BitSet earlyTermination = null;
+    protected byte[] resultTypes;
 
     // array version of isToBeFlattened - this is purely
     // for optimization - instead of calling isToBeFlattened.get(i)
@@ -85,16 +72,33 @@ public class POForEach extends PhysicalOperator {
     // so we can also save on the Boolean.booleanValue() calls
     protected boolean[] isToBeFlattenedArray;
 
-    ExampleTuple tIn = null;
     protected int noItems;
 
-    protected PhysicalOperator[] planLeafOps = null;
+    //Since the plan has a generate, this needs to be maintained
+    //as the generate can potentially return multiple tuples for
+    //same call.
+    protected transient boolean processingPlan;
+
+    //its holds the iterators of the databags given by the input expressions which need flattening.
+    protected transient Iterator<Tuple> [] its = null;
+
+    //This holds the outputs given out by the input expressions of any datatype
+    protected transient Object[] bags ;
+
+    //This is the template whcih contains tuples and is flattened out in createTuple() to generate the final output
+    protected transient Object[] data;
+
+    // store whether or not an accumulative UDF has terminated early
+    protected transient BitSet earlyTermination;
+
+    protected transient ExampleTuple tIn;
+
 
     protected transient AccumulativeTupleBuffer buffer;
 
-    protected Tuple inpTuple;
+    protected transient Tuple inpTuple;
 
-    protected boolean endOfAllInputProcessed = false;
+    protected transient boolean endOfAllInputProcessed;
 
     // Indicate the foreach statement can only in map side
     // Currently only used in MR cross (See PIG-4175)
@@ -372,7 +376,7 @@ public class POForEach extends PhysicalOperator {
 
         if(its == null) {
             if (endOfAllInputProcessed) {
-                return new Result(POStatus.STATUS_EOP, null);
+                return RESULT_EOP;
             }
             //getNext being called for the first time OR starting with a set of new data from inputs
             its = new Iterator[noItems];
@@ -688,6 +692,8 @@ public class POForEach extends PhysicalOperator {
         clone.setOpsToBeReset(ops);
         clone.setResultType(getResultType());
         clone.addOriginalLocation(alias, getOriginalLocations());
+        clone.endOfAllInputProcessing = endOfAllInputProcessing;
+        clone.mapSideOnly = mapSideOnly;
         return clone;
     }
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLimit.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLimit.java
index 72ed7bf3b..17fc07bbd 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLimit.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLimit.java
@@ -27,7 +27,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlan
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.pen.util.ExampleTuple;
@@ -38,14 +37,14 @@ public class POLimit extends PhysicalOperator {
      */
     private static final long serialVersionUID = 1L;
 
-    // Counts for outputs processed
-    private long soFar = 0;
-
     // Number of limited outputs
-    long mLimit;
+    private long mLimit;
 
     // The expression plan
-    PhysicalPlan expressionPlan;
+    private PhysicalPlan expressionPlan;
+
+    // Counts for outputs processed
+    private transient long soFar = 0;
 
     public POLimit(OperatorKey k) {
         this(k, -1, null);
@@ -159,15 +158,11 @@ public class POLimit extends PhysicalOperator {
 
     @Override
     public POLimit clone() throws CloneNotSupportedException {
-        POLimit newLimit = new POLimit(new OperatorKey(this.mKey.scope,
-            NodeIdGenerator.getGenerator().getNextNodeId(this.mKey.scope)),
-            this.requestedParallelism, this.inputs);
-        newLimit.mLimit = this.mLimit;
+        POLimit clone = (POLimit) super.clone();
         if (this.expressionPlan != null) {
-            newLimit.expressionPlan = this.expressionPlan.clone();
+            clone.expressionPlan = this.expressionPlan.clone();
         }
-        newLimit.addOriginalLocation(alias, getOriginalLocations());
-        return newLimit;
+        return clone;
     }
 
     @Override
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java
index ffa58dbd6..4e39beb8b 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java
@@ -35,9 +35,7 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlan
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.io.PigNullableWritable;
-import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.PlanException;
 import org.apache.pig.impl.plan.VisitorException;
@@ -57,8 +55,6 @@ public class POLocalRearrange extends PhysicalOperator {
      */
     protected static final long serialVersionUID = 1L;
 
-    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
-
     private static final Result ERR_RESULT = new Result();
 
     protected List<PhysicalPlan> plans;
@@ -82,8 +78,6 @@ public class POLocalRearrange extends PhysicalOperator {
 
     protected boolean isCross = false;
 
-    protected Result inp;
-
     // map to store mapping of projected columns to
     // the position in the "Key" where these will be projected to.
     // We use this information to strip off these columns
@@ -133,6 +127,8 @@ public class POLocalRearrange extends PhysicalOperator {
     // By default, we strip keys from the value.
     private boolean stripKeyFromValue = true;
 
+    protected transient Result inp;
+
     public POLocalRearrange(OperatorKey k) {
         this(k, -1, null);
     }
@@ -709,32 +705,18 @@ public class POLocalRearrange extends PhysicalOperator {
      */
     @Override
     public POLocalRearrange clone() throws CloneNotSupportedException {
-        POLocalRearrange clone = new POLocalRearrange(new OperatorKey(
-            mKey.scope,
-            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
-            requestedParallelism);
-        deepCopyTo(clone);
-        return clone;
-    }
-
-    protected void deepCopyTo(POLocalRearrange clone)
-            throws CloneNotSupportedException {
-
-        clone.setParentPlan(parentPlan);
-        clone.index = index;
-        if (useSecondaryKey) {
-            clone.keyType = mainKeyType;
-        } else {
-            clone.keyType = keyType;
-        }
-        clone.setUseSecondaryKey(useSecondaryKey);
+        POLocalRearrange clone = (POLocalRearrange) super.clone();
+        // Constructor
+        clone.leafOps = new ArrayList<ExpressionOperator>();
+        clone.secondaryLeafOps = new ArrayList<ExpressionOperator>();
         // Needs to be called as setDistinct so that the fake index tuple gets
         // created.
         clone.setDistinct(mIsDistinct);
-        clone.setCross(isCross);
-        clone.addOriginalLocation(alias, getOriginalLocations());
-        clone.setStripKeyFromValue(stripKeyFromValue);
-
+        // Set the keyType to mainKeyType. setSecondaryPlans will calculate
+        // based on that and set keyType to the final value
+        if (useSecondaryKey) {
+            clone.keyType = mainKeyType;
+        }
         try {
             clone.setPlans(clonePlans(plans));
             if (secondaryPlans != null) {
@@ -745,14 +727,7 @@ public class POLocalRearrange extends PhysicalOperator {
             cnse.initCause(pe);
             throw cnse;
         }
-    }
-
-    private List<PhysicalPlan> clonePlans(List<PhysicalPlan> origPlans) throws CloneNotSupportedException {
-        List<PhysicalPlan> clonePlans = new ArrayList<PhysicalPlan>(origPlans.size());
-        for (PhysicalPlan plan : origPlans) {
-            clonePlans.add(plan.clone());
-        }
-        return clonePlans;
+        return clone;
     }
 
     public boolean isCross() {
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POOptimizedForEach.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POOptimizedForEach.java
index d9767e110..35d599fd2 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POOptimizedForEach.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POOptimizedForEach.java
@@ -17,22 +17,16 @@
  */
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators;
 
-import java.util.ArrayList;
 import java.util.List;
-import java.util.LinkedList;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
+import org.apache.pig.data.DataType;
 import org.apache.pig.impl.plan.OperatorKey;
-import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
-import org.apache.pig.pen.util.ExampleTuple;
-import org.apache.pig.pen.util.LineageTracer;
-import org.apache.pig.impl.util.IdentityHashSet;
 
 /**
  * A specialized version of POForeach with the difference
@@ -45,10 +39,10 @@ import org.apache.pig.impl.util.IdentityHashSet;
 public class POOptimizedForEach extends POForEach {
 
     /**
-     * 
+     *
      */
     private static final long serialVersionUID = 1L;
-    
+
     public POOptimizedForEach(OperatorKey k) {
         this(k,-1,null,null);
     }
@@ -64,7 +58,7 @@ public class POOptimizedForEach extends POForEach {
     public POOptimizedForEach(OperatorKey k, List inp) {
         this(k,-1,inp,null);
     }
-    
+
     public POOptimizedForEach(OperatorKey k, int rp, List<PhysicalPlan> inp, List<Boolean>  isToBeFlattened){
         super(k, rp);
         setUpFlattens(isToBeFlattened);
@@ -82,7 +76,7 @@ public class POOptimizedForEach extends POForEach {
         String fString = getFlatStr();
         return "Optimized For Each" + "(" + fString + ")" + "[" + DataType.findTypeName(resultType) + "]" +" - " + mKey.toString();
     }
-    
+
     /**
      * Calls getNext on the generate operator inside the nested
      * physical plan and returns it maintaining an additional state
@@ -120,40 +114,25 @@ public class POOptimizedForEach extends POForEach {
         //nested plan processing on the input tuple
         //read
         while (true) {
-            
-            // we know that input has been attached 
+
+            // we know that input has been attached
             attachInputToPlans(input);
             detachInput();
             res = processPlan();
-            
+
             processingPlan = true;
-            
+
             return res;
         }
     }
 
-    
+
     /**
-     * Make a deep copy of this operator.  
+     * Make a deep copy of this operator.
      * @throws CloneNotSupportedException
      */
     @Override
     public POOptimizedForEach clone() throws CloneNotSupportedException {
-        List<PhysicalPlan> plans = new
-            ArrayList<PhysicalPlan>(inputPlans.size());
-        for (PhysicalPlan plan : inputPlans) {
-            plans.add(plan.clone());
-        }
-        List<Boolean> flattens = null;
-        if(isToBeFlattenedArray != null ) {
-            flattens = new 
-            ArrayList<Boolean>(isToBeFlattenedArray.length);
-            for (boolean b : isToBeFlattenedArray) {
-                flattens.add(b);
-            }
-        }
-        return new POOptimizedForEach(new OperatorKey(mKey.scope, 
-            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
-            requestedParallelism, plans, flattens);
+        return (POOptimizedForEach) super.clone();
     }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
index ebe25c8f1..cb85a5c83 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
@@ -30,13 +30,11 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.util.AccumulatorOptimizerUtil;
 import org.apache.pig.data.AccumulativeBag;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.InternalCachedBag;
 import org.apache.pig.data.ReadOnceBag;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.io.NullableTuple;
 import org.apache.pig.impl.io.PigNullableWritable;
 import org.apache.pig.impl.plan.NodeIdGenerator;
@@ -74,9 +72,6 @@ public class POPackage extends PhysicalOperator {
     //key, no value.
     protected int numInputs;
 
-    protected static final BagFactory mBagFactory = BagFactory.getInstance();
-    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
-
     private boolean lastBagReadOnly = true;
 
     protected Packager pkgr;
@@ -240,8 +235,7 @@ public class POPackage extends PhysicalOperator {
 
                 // create bag to pull all tuples out of iterator
                 for (int i = 0; i < numInputs; i++) {
-                    dbs[i] = useDefaultBag ? BagFactory.getInstance()
-                            .newDefaultBag()
+                    dbs[i] = useDefaultBag ? mBagFactory.newDefaultBag()
                             // In a very rare case if there is a POStream after this
                             // POPackage in the pipeline and is also blocking the
                             // pipeline;
@@ -259,7 +253,7 @@ public class POPackage extends PhysicalOperator {
                     if (index == numInputs - 1) {
                         if (pkgr.getUseSecondaryKey()) {
                             if (dbs[index] == null) {
-                                dbs[index] = useDefaultBag ? BagFactory.getInstance()
+                                dbs[index] = useDefaultBag ? mBagFactory
                                         .newDefaultBag() : new InternalCachedBag(numInputs);
                             }
                         } else {
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartialAgg.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartialAgg.java
index 4a103226e..47f62b264 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartialAgg.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartialAgg.java
@@ -41,7 +41,6 @@ import org.apache.pig.data.DataType;
 import org.apache.pig.data.InternalCachedBag;
 import org.apache.pig.data.SelfSpillBag.MemoryLimits;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.impl.util.GroupingSpillable;
@@ -92,8 +91,6 @@ public class POPartialAgg extends PhysicalOperator implements Spillable, Groupin
 
     private static final WeakHashMap<POPartialAgg, Byte> ALL_POPARTS = new WeakHashMap<POPartialAgg, Byte>();
 
-    private static final TupleFactory TF = TupleFactory.getInstance();
-
     private PhysicalPlan keyPlan;
     private ExpressionOperator keyLeaf;
     private List<PhysicalPlan> valuePlans;
@@ -496,7 +493,7 @@ public class POPartialAgg extends PhysicalOperator implements Spillable, Groupin
     }
 
     private Tuple createValueTuple(Object key, List<Tuple> inpTuples) throws ExecException {
-        Tuple valueTuple = TF.newTuple(valuePlans.size() + 1);
+        Tuple valueTuple = mTupleFactory.newTuple(valuePlans.size() + 1);
         valueTuple.set(0, key);
 
         for (int i = 0; i < valuePlans.size(); i++) {
@@ -576,7 +573,7 @@ public class POPartialAgg extends PhysicalOperator implements Spillable, Groupin
      * @throws ExecException
      */
     private Result getOutput(Object key, Tuple value) throws ExecException {
-        Tuple output = TF.newTuple(valuePlans.size() + 1);
+        Tuple output = mTupleFactory.newTuple(valuePlans.size() + 1);
         output.set(0, key);
 
         for (int i = 0; i < valuePlans.size(); i++) {
@@ -657,4 +654,14 @@ public class POPartialAgg extends PhysicalOperator implements Spillable, Groupin
         return avgTupleSize * (numRecsInProcessedMap + numRecsInRawMap);
     }
 
+    @Override
+    public PhysicalOperator clone() throws CloneNotSupportedException {
+        POPartialAgg clone = (POPartialAgg) super.clone();
+        clone.setKeyPlan(keyPlan.clone());
+        clone.setValuePlans(clonePlans(valuePlans));
+        return clone;
+    }
+
+
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java
index 5b3a32158..9181a7b78 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java
@@ -30,7 +30,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.ExpressionOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
@@ -39,8 +38,6 @@ import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.util.Pair;
 import org.apache.pig.impl.util.Utils;
 
-import com.google.common.collect.Maps;
-
 /**
  * The partition rearrange operator is a part of the skewed join
  * implementation. It has an embedded physical plan that
@@ -50,12 +47,11 @@ import com.google.common.collect.Maps;
 public class POPartitionRearrange extends POLocalRearrange {
 
     private static final long serialVersionUID = 1L;
-    private static final BagFactory mBagFactory = BagFactory.getInstance();
 
-    private Integer totalReducers = -1;
+    private transient Integer totalReducers;
     // ReducerMap will store the tuple, max reducer index & min reducer index
-    private Map<Object, Pair<Integer, Integer> > reducerMap = Maps.newHashMap();
-    private boolean inited;
+    private transient Map<Object, Pair<Integer, Integer> > reducerMap;
+    private transient boolean inited;
 
     private PigContext pigContext;
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPoissonSample.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPoissonSample.java
index 32f28263f..bf76dcd51 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPoissonSample.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPoissonSample.java
@@ -23,7 +23,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOpera
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.builtin.PoissonSampleLoader;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
@@ -32,51 +31,43 @@ public class POPoissonSample extends PhysicalOperator {
 
     private static final long serialVersionUID = 1L;
 
-    private static final TupleFactory tf = TupleFactory.getInstance();
-    private static Result eop = new Result(POStatus.STATUS_EOP, null);
+    // 17 is not a magic number. It can be obtained by using a poisson
+    // cumulative distribution function with the mean set to 10 (empirically,
+    // minimum number of samples) and the confidence set to 95%
+    public static final int DEFAULT_SAMPLE_RATE = 17;
+
+    private int sampleRate = 0;
+
+    private float heapPerc = 0f;
+
+    private Long totalMemory;
+
+    private transient boolean initialized;
 
     // num of rows sampled so far
-    private int numRowsSampled = 0;
+    private transient int numRowsSampled;
 
     // average size of tuple in memory, for tuples sampled
-    private long avgTupleMemSz = 0;
+    private transient long avgTupleMemSz;
 
     // current row number
-    private long rowNum = 0;
+    private transient long rowNum;
 
     // number of tuples to skip after each sample
-    private long skipInterval = -1;
+    private transient long skipInterval;
 
     // bytes in input to skip after every sample.
     // divide this by avgTupleMemSize to get skipInterval
-    private long memToSkipPerSample = 0;
+    private transient long memToSkipPerSample;
 
     // has the special row with row number information been returned
-    private boolean numRowSplTupleReturned = false;
-
-    // 17 is not a magic number. It can be obtained by using a poisson
-    // cumulative distribution function with the mean set to 10 (empirically,
-    // minimum number of samples) and the confidence set to 95%
-    public static final int DEFAULT_SAMPLE_RATE = 17;
-
-    private int sampleRate = 0;
-
-    private float heapPerc = 0f;
-
-    private long totalMemory = Runtime.getRuntime().maxMemory();
+    private transient boolean numRowSplTupleReturned;
 
     // new Sample result
-    private Result newSample = null;
+    private transient Result newSample;
 
     public POPoissonSample(OperatorKey k, int rp, int sr, float hp, long tm) {
         super(k, rp, null);
-        numRowsSampled = 0;
-        avgTupleMemSz = 0;
-        rowNum = 0;
-        skipInterval = -1;
-        memToSkipPerSample = 0;
-        numRowSplTupleReturned = false;
-        newSample = null;
         sampleRate = sr;
         heapPerc = hp;
         if (tm != -1) {
@@ -97,10 +88,22 @@ public class POPoissonSample extends PhysicalOperator {
 
     @Override
     public Result getNextTuple() throws ExecException {
+        if (!initialized) {
+            numRowsSampled = 0;
+            avgTupleMemSz = 0;
+            rowNum = 0;
+            skipInterval = -1;
+            memToSkipPerSample = 0;
+            if (totalMemory == null) {
+                // Initialize in backend to get memory of task
+                totalMemory = Runtime.getRuntime().maxMemory();
+            }
+            initialized = true;
+        }
         if (numRowSplTupleReturned) {
             // row num special row has been returned after all inputs
             // were read, nothing more to read
-            return eop;
+            return RESULT_EOP;
         }
 
         Result res = null;
@@ -216,7 +219,7 @@ public class POPoissonSample extends PhysicalOperator {
      */
     private Result createNumRowTuple(Tuple sample) throws ExecException {
         int sz = (sample == null) ? 0 : sample.size();
-        Tuple t = tf.newTuple(sz + 2);
+        Tuple t = mTupleFactory.newTuple(sz + 2);
 
         if (sample != null) {
             for (int i=0; i<sample.size(); i++){
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPreCombinerLocalRearrange.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPreCombinerLocalRearrange.java
index 1c996b3dc..a13a902fa 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPreCombinerLocalRearrange.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPreCombinerLocalRearrange.java
@@ -29,12 +29,10 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.ExpressionOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.SingleTupleBag;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 
@@ -53,9 +51,6 @@ public class POPreCombinerLocalRearrange extends PhysicalOperator {
 
     protected static final long serialVersionUID = 1L;
 
-    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
-    protected static BagFactory mBagFactory = BagFactory.getInstance();
-
     private static final Result ERR_RESULT = new Result();
 
     protected List<PhysicalPlan> plans;
@@ -223,4 +218,12 @@ public class POPreCombinerLocalRearrange extends PhysicalOperator {
     public Tuple illustratorMarkup(Object in, Object out, int eqClassIndex) {
         return null;
     }
+
+    @Override
+    public POPreCombinerLocalRearrange clone() throws CloneNotSupportedException {
+        POPreCombinerLocalRearrange clone = (POPreCombinerLocalRearrange) super.clone();
+        clone.leafOps = new ArrayList<ExpressionOperator>();
+        clone.setPlans(clonePlans(plans));
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PORank.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PORank.java
index 4cd316050..c4ae9bb3f 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PORank.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PORank.java
@@ -32,7 +32,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlan
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.pen.util.ExampleTuple;
@@ -55,8 +54,6 @@ public class PORank extends PhysicalOperator {
     private List<Boolean> mAscCols;
     private List<Byte> ExprOutputTypes;
 
-    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
-
     /**
      * Unique identifier that links POCounter and PORank,
      * through the global counter labeled with it.
@@ -230,4 +227,11 @@ public class PORank extends PhysicalOperator {
     public String getOperationID() {
         return operationID;
     }
+
+    @Override
+    public PORank clone() throws CloneNotSupportedException {
+        PORank clone = (PORank)super.clone();
+        // rankPlans, mAscCols, ExprOutputTypes are unused. Not cloning them
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POReservoirSample.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POReservoirSample.java
index 71d5a6f76..38093482d 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POReservoirSample.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POReservoirSample.java
@@ -26,31 +26,28 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOpera
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.builtin.PoissonSampleLoader;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class POReservoirSample extends PhysicalOperator {
 
-    private static final TupleFactory tf = TupleFactory.getInstance();
-
     private static final long serialVersionUID = 1L;
 
     // number of samples to be sampled
     protected int numSamples;
 
-    private transient int nextSampleIdx= 0;
+    private transient int nextSampleIdx = 0;
 
-    private int rowProcessed = 0;
+    private transient int rowProcessed = 0;
 
-    private boolean sampleCollectionDone = false;
+    private transient boolean sampleCollectionDone = false;
 
     //array to store the result
     private transient Result[] samples = null;
 
     // last sample result
-    private Result lastSample = null;
+    private transient Result lastSample = null;
 
     public POReservoirSample(OperatorKey k) {
         this(k, -1, null);
@@ -170,14 +167,12 @@ public class POReservoirSample extends PhysicalOperator {
             }
             Result res = samples[nextSampleIdx++];
             if (res == null) { // Input data has lesser rows than numSamples
-                return new Result(POStatus.STATUS_NULL, null);
+                return RESULT_EMPTY;
             }
             return res;
         }
         else{
-            Result res;
-            res = new Result(POStatus.STATUS_EOP, null);
-            return res;
+            return RESULT_EOP;
         }
     }
 
@@ -203,7 +198,7 @@ public class POReservoirSample extends PhysicalOperator {
      */
     private Result createNumRowTuple(Tuple sample) throws ExecException {
         int sz = (sample == null) ? 0 : sample.size();
-        Tuple t = tf.newTuple(sz + 2);
+        Tuple t = mTupleFactory.newTuple(sz + 2);
 
         if (sample != null) {
             for (int i=0; i<sample.size(); i++){
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
index a7598574b..4319598db 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
@@ -36,12 +36,10 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOpe
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserComparisonFunc;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.InternalSortedBag;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 
@@ -74,11 +72,11 @@ public class POSort extends PhysicalOperator {
 	private POUserComparisonFunc mSortFunc;
 	private Comparator<Tuple> mComparator;
 
-	private boolean inputsAccumulated = false;
 	private long limit;
 	public boolean isUDFComparatorUsed = false;
-	private DataBag sortedBag;
 
+	private transient boolean inputsAccumulated = false;
+	private transient DataBag sortedBag;
     private transient Iterator<Tuple> it;
     private transient boolean initialized;
     private transient boolean useDefaultBag;
@@ -95,22 +93,22 @@ public class POSort extends PhysicalOperator {
 		this.sortPlans = sortPlans;
 		this.mAscCols = mAscCols;
         this.limit = -1;
-		this.mSortFunc = mSortFunc;
-		if (mSortFunc == null) {
+        setSortFunc(mSortFunc);
+	}
+
+	private void setSortFunc(POUserComparisonFunc mSortFunc) {
+	    this.mSortFunc = mSortFunc;
+        if (mSortFunc == null) {
             mComparator = new SortComparator();
-			/*sortedBag = BagFactory.getInstance().newSortedBag(
-					new SortComparator());*/
-			ExprOutputTypes = new ArrayList<Byte>(sortPlans.size());
+            ExprOutputTypes = new ArrayList<Byte>(sortPlans.size());
 
-			for(PhysicalPlan plan : sortPlans) {
-				ExprOutputTypes.add(plan.getLeaves().get(0).getResultType());
-			}
-		} else {
-			/*sortedBag = BagFactory.getInstance().newSortedBag(
-					new UDFSortComparator());*/
+            for(PhysicalPlan plan : sortPlans) {
+                ExprOutputTypes.add(plan.getLeaves().get(0).getResultType());
+            }
+        } else {
             mComparator = new UDFSortComparator();
-			isUDFComparatorUsed = true;
-		}
+            isUDFComparatorUsed = true;
+        }
 	}
 
 	public POSort(OperatorKey k, int rp, List inp) {
@@ -271,7 +269,7 @@ public class POSort extends PhysicalOperator {
             }
 			// by default, we create InternalSortedBag, unless user configures
             // explicitly to use old bag
-            sortedBag = useDefaultBag ? BagFactory.getInstance().newSortedBag(mComparator)
+            sortedBag = useDefaultBag ? mBagFactory.newSortedBag(mComparator)
                     : new InternalSortedBag(3, mComparator);
 
             while (res.returnStatus != POStatus.STATUS_EOP) {
@@ -363,23 +361,19 @@ public class POSort extends PhysicalOperator {
 
     @Override
     public POSort clone() throws CloneNotSupportedException {
-        List<PhysicalPlan> clonePlans = new
-            ArrayList<PhysicalPlan>(sortPlans.size());
-        for (PhysicalPlan plan : sortPlans) {
-            clonePlans.add(plan.clone());
+        POSort clone = (POSort) super.clone();
+        clone.sortPlans = clonePlans(sortPlans);
+        if (mSortFunc == null) {
+            setSortFunc(null);
+        } else {
+            setSortFunc(mSortFunc.clone());
         }
         List<Boolean> cloneAsc = new ArrayList<Boolean>(mAscCols.size());
         for (Boolean b : mAscCols) {
             cloneAsc.add(b);
         }
-        POUserComparisonFunc cloneFunc = null;
-        if (mSortFunc != null) {
-            cloneFunc = mSortFunc.clone();
-        }
-        // Don't set inputs as PhysicalPlan.clone will take care of that
-        return new POSort(new OperatorKey(mKey.scope,
-            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
-            requestedParallelism, null, clonePlans, cloneAsc, cloneFunc);
+        clone.mAscCols = cloneAsc;
+        return clone;
     }
 
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSplit.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSplit.java
index a9f67baa4..2fc771d59 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSplit.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSplit.java
@@ -89,9 +89,7 @@ public class POSplit extends PhysicalOperator {
 
     private BitSet processedSet = new BitSet();
 
-    private static Result empty = new Result(POStatus.STATUS_NULL, null);
-
-    private boolean inpEOP = false;
+    private transient boolean inpEOP = false;
 
     /**
      * Constructs an operator with the specified key
@@ -243,7 +241,7 @@ public class POSplit extends PhysicalOperator {
             }
         }
 
-        return (res.returnStatus == POStatus.STATUS_OK) ? res : empty;
+        return (res.returnStatus == POStatus.STATUS_OK) ? res : RESULT_EMPTY;
     }
 
     private Result runPipeline(PhysicalOperator leaf) throws ExecException {
@@ -321,13 +319,9 @@ public class POSplit extends PhysicalOperator {
 
     @Override
     public POSplit clone() throws CloneNotSupportedException {
-        Object o = super.clone();
-        POSplit opClone = (POSplit)o;
+        POSplit opClone = (POSplit) super.clone();
         opClone.processedSet = new BitSet();
-        opClone.myPlans = new ArrayList<PhysicalPlan>(myPlans.size());
-        for (PhysicalPlan plan : myPlans) {
-            opClone.myPlans.add(plan.clone());
-        }
+        opClone.myPlans = clonePlans(myPlans);
         return opClone;
     }
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java
index 387554c71..3b85086a6 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStore.java
@@ -50,7 +50,6 @@ import org.apache.pig.tools.pigstats.PigStatsUtil;
 public class POStore extends PhysicalOperator {
 
     private static final long serialVersionUID = 1L;
-    protected static Result empty = new Result(POStatus.STATUS_NULL, null);
     transient private StoreFuncInterface storer;
     transient private StoreFuncDecorator sDecorator;
     transient private POStoreImpl impl;
@@ -117,7 +116,7 @@ public class POStore extends PhysicalOperator {
     public void setUp() throws IOException{
         if (impl != null) {
             try{
-                storer = impl.createStoreFunc(this); 
+                storer = impl.createStoreFunc(this);
                 if (!isTmpStore && !disableCounter && impl instanceof MapReducePOStoreImpl) {
                     counterName = PigStatsUtil.getMultiStoreCounterName(this);
                     if (counterName != null) {
@@ -165,7 +164,7 @@ public class POStore extends PhysicalOperator {
                     sDecorator.putNext((Tuple) res.result);
                 } else
                     illustratorMarkup(res.result, res.result, 0);
-                res = empty;
+                res = RESULT_EMPTY;
 
                 if (counterName != null) {
                     ((MapReducePOStoreImpl) impl).incrRecordCounter(counterName, 1);
@@ -256,19 +255,19 @@ public class POStore extends PhysicalOperator {
         }
         return storer;
     }
-    
+
     void setStoreFuncDecorator(StoreFuncDecorator sDecorator) {
         this.sDecorator = sDecorator;
     }
 
     /**
-     * 
+     *
      * @return The {@link StoreFuncDecorator} used to write Tuples
      */
     public StoreFuncDecorator getStoreFuncDecorator() {
         return sDecorator;
     }
-    
+
     /**
      * @param sortInfo the sortInfo to set
      */
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStream.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStream.java
index ba729b63c..b7858c636 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStream.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POStream.java
@@ -43,22 +43,21 @@ import org.apache.pig.pen.util.ExampleTuple;
 public class POStream extends PhysicalOperator {
     private static final long serialVersionUID = 2L;
 
-    private static final Result EOP_RESULT = new Result(POStatus.STATUS_EOP, null);
-
     private String executableManagerStr;            // String representing ExecutableManager to use
-    transient private ExecutableManager executableManager;    // ExecutableManager to use
     private StreamingCommand command;               // Actual command to be run
     private Properties properties;
 
-    private boolean initialized = false;
-
     protected BlockingQueue<Result> binaryOutputQueue = new ArrayBlockingQueue<Result>(1);
 
     protected BlockingQueue<Result> binaryInputQueue = new ArrayBlockingQueue<Result>(1);
 
-    protected boolean allInputFromPredecessorConsumed = false;
+    private transient ExecutableManager executableManager;    // ExecutableManager to use
+
+    private transient boolean initialized = false;
+
+    protected transient boolean allInputFromPredecessorConsumed = false;
 
-    protected boolean allOutputFromBinaryProcessed = false;
+    protected transient boolean allOutputFromBinaryProcessed = false;
 
     /**
      * This flag indicates whether streaming is done through fetching. If set,
@@ -143,7 +142,7 @@ public class POStream extends PhysicalOperator {
             // The "allOutputFromBinaryProcessed" flag is set when we see
             // an EOS (End of Stream output) from streaming binary
             if(allOutputFromBinaryProcessed) {
-                return EOP_RESULT;
+                return RESULT_EOP;
             }
 
             // if we are here AFTER all map() calls have been completed
@@ -158,7 +157,7 @@ public class POStream extends PhysicalOperator {
                     // So we can send an EOP to the successor in
                     // the pipeline and also note this condition
                     // for future calls
-                    r = EOP_RESULT;
+                    r = RESULT_EOP;
                     allOutputFromBinaryProcessed = true;
                 } else if (r.returnStatus == POStatus.STATUS_OK) {
                     illustratorMarkup(r.result, r.result, 0);
@@ -191,7 +190,7 @@ public class POStream extends PhysicalOperator {
                             // So we can send an EOP to the successor in
                             // the pipeline and also note this condition
                             // for future calls
-                            r = EOP_RESULT;
+                            r = RESULT_EOP;
                             allOutputFromBinaryProcessed = true;
                         }
                     }
@@ -202,7 +201,7 @@ public class POStream extends PhysicalOperator {
                     // So we can send an EOP to the successor in
                     // the pipeline and also note this condition
                     // for future calls
-                    r = EOP_RESULT;
+                    r = RESULT_EOP;
                     allOutputFromBinaryProcessed = true;
                 } else if (r.returnStatus == POStatus.STATUS_OK) {
                   illustratorMarkup(r.result, r.result, 0);
@@ -218,7 +217,7 @@ public class POStream extends PhysicalOperator {
                     // So we can send an EOP to the successor in
                     // the pipeline and also note this condition
                     // for future calls
-                    r = EOP_RESULT;
+                    r = RESULT_EOP;
                     allOutputFromBinaryProcessed  = true;
                 } else if (r.returnStatus == POStatus.STATUS_OK) {
                     illustratorMarkup(r.result, r.result, 0);
@@ -297,8 +296,9 @@ public class POStream extends PhysicalOperator {
 
                         // wait for either input to be available
                         // or output to be consumed
-                        while(binaryOutputQueue.isEmpty() && !binaryInputQueue.isEmpty())
+                        while(binaryOutputQueue.isEmpty() && !binaryInputQueue.isEmpty()) {
                             wait();
+                        }
 
                     }
                 }
@@ -382,4 +382,13 @@ public class POStream extends PhysicalOperator {
         this.isFetchable = isFetchable;
     }
 
+    @Override
+    public PhysicalOperator clone() throws CloneNotSupportedException {
+        POStream clone = (POStream)super.clone();
+        clone.binaryOutputQueue = new ArrayBlockingQueue<Result>(1);
+        clone.binaryInputQueue = new ArrayBlockingQueue<Result>(1);
+        //Not cloning StreamingCommand as it is read only
+        return clone;
+    }
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezCompiler.java
index d03f982cf..2e96bff2e 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezCompiler.java
@@ -653,6 +653,7 @@ public class TezCompiler extends PhyPlanVisitor {
     public void visitCounter(POCounter op) throws VisitorException {
         // Refer visitRank(PORank) for more details
         try{
+            curTezOp.markRankCounter();
             POCounterTez counterTez = new POCounterTez(op);
             nonBlocking(counterTez);
             phyToTezOpMap.put(op, curTezOp);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java
index e20732de1..4f42fe138 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/TezOperator.java
@@ -179,7 +179,9 @@ public class TezOperator extends Operator<TezOpPlanVisitor> {
         // Indicate if this job is a distinct job
         DISTINCT,
         // Indicate if this job is a native job
-        NATIVE;
+        NATIVE,
+        // Indicate if this job does rank counter
+        RANK_COUNTER;
     };
 
     // Features in the job/vertex. Mostly will be only one feature.
@@ -442,6 +444,14 @@ public class TezOperator extends Operator<TezOpPlanVisitor> {
         feature.set(OPER_FEATURE.NATIVE.ordinal());
     }
 
+    public boolean isRankCounter() {
+        return feature.get(OPER_FEATURE.RANK_COUNTER.ordinal());
+    }
+
+    public void markRankCounter() {
+        feature.set(OPER_FEATURE.RANK_COUNTER.ordinal());
+    }
+
     public void copyFeatures(TezOperator copyFrom, List<OPER_FEATURE> excludeFeatures) {
         for (OPER_FEATURE opf : OPER_FEATURE.values()) {
             if (excludeFeatures != null && excludeFeatures.contains(opf)) {
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POCounterStatsTez.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POCounterStatsTez.java
index 8d4ff432b..5985b83c0 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POCounterStatsTez.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POCounterStatsTez.java
@@ -35,7 +35,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlan
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezInput;
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezOutput;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.tez.runtime.api.LogicalInput;
@@ -152,7 +151,7 @@ public class POCounterStatsTez extends PhysicalOperator implements TezInput, Tez
                 prevTasksCount += counterRecords.get(i);
             }
 
-            Tuple tuple = TupleFactory.getInstance().newTuple(1);
+            Tuple tuple = mTupleFactory.newTuple(1);
             tuple.set(0, counterOffsets);
             writer.write(POValueOutputTez.EMPTY_KEY, tuple);
             finished = true;
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java
index dec86863b..cb33684d4 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POFRJoinTez.java
@@ -215,4 +215,10 @@ public class POFRJoinTez extends POFRJoin implements TezInput {
     public List<String> getInputKeys() {
         return inputKeys;
     }
+
+    @Override
+    public POFRJoinTez clone() throws CloneNotSupportedException {
+        return (POFRJoinTez) super.clone();
+    }
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POLocalRearrangeTez.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POLocalRearrangeTez.java
index fc77d4073..0f0748350 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POLocalRearrangeTez.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POLocalRearrangeTez.java
@@ -34,7 +34,6 @@ import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.io.NullablePartitionWritable;
 import org.apache.pig.impl.io.NullableTuple;
 import org.apache.pig.impl.io.PigNullableWritable;
-import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.tez.runtime.api.LogicalOutput;
 import org.apache.tez.runtime.library.api.KeyValueWriter;
@@ -49,11 +48,11 @@ public class POLocalRearrangeTez extends POLocalRearrange implements TezOutput {
     private static final Log LOG = LogFactory.getLog(POLocalRearrangeTez.class);
 
     protected String outputKey;
-    protected transient KeyValueWriter writer;
-
     protected boolean connectedToPackage = true;
     protected boolean isSkewedJoin = false;
 
+    protected transient KeyValueWriter writer;
+
     public POLocalRearrangeTez(OperatorKey k) {
         super(k);
     }
@@ -172,20 +171,9 @@ public class POLocalRearrangeTez extends POLocalRearrange implements TezOutput {
         return inp;
     }
 
-    /**
-     * Make a deep copy of this operator.
-     * @throws CloneNotSupportedException
-     */
     @Override
     public POLocalRearrangeTez clone() throws CloneNotSupportedException {
-        POLocalRearrangeTez clone = new POLocalRearrangeTez(new OperatorKey(
-                mKey.scope, NodeIdGenerator.getGenerator().getNextNodeId(
-                        mKey.scope)), requestedParallelism);
-        deepCopyTo(clone);
-        clone.isSkewedJoin = isSkewedJoin;
-        clone.connectedToPackage = connectedToPackage;
-        clone.setOutputKey(outputKey);
-        return clone;
+        return (POLocalRearrangeTez) super.clone();
     }
 
     @Override
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POPartitionRearrangeTez.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POPartitionRearrangeTez.java
index 96579eec1..95034924d 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POPartitionRearrangeTez.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POPartitionRearrangeTez.java
@@ -33,16 +33,13 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOpe
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.ObjectCache;
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.PigProcessor;
-import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.builtin.PartitionSkewedKeys;
 import org.apache.pig.impl.io.NullablePartitionWritable;
 import org.apache.pig.impl.io.NullableTuple;
 import org.apache.pig.impl.io.PigNullableWritable;
-import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.util.Pair;
 
@@ -58,13 +55,11 @@ public class POPartitionRearrangeTez extends POLocalRearrangeTez {
     private static final long serialVersionUID = 1L;
 
     private static final Log LOG = LogFactory.getLog(POPartitionRearrangeTez.class);
-    private static final TupleFactory tf = TupleFactory.getInstance();
-    private static final BagFactory mBagFactory = BagFactory.getInstance();
 
     // ReducerMap will store the tuple, max reducer index & min reducer index
-    private Map<Object, Pair<Integer, Integer>> reducerMap = Maps.newHashMap();
-    private Integer totalReducers = -1;
-    private boolean inited = false;
+    private transient Map<Object, Pair<Integer, Integer>> reducerMap;
+    private transient Integer totalReducers;
+    private transient boolean inited;
 
     public POPartitionRearrangeTez(OperatorKey k) {
         this(k, -1);
@@ -202,6 +197,8 @@ public class POPartitionRearrangeTez extends POLocalRearrangeTez {
         }
 
         Map<String, Object> distMap = null;
+        totalReducers = -1;
+        reducerMap = Maps.newHashMap();
         if (PigProcessor.sampleMap != null) {
             // We've already collected sampleMap in PigProcessor
             distMap = PigProcessor.sampleMap;
@@ -233,7 +230,7 @@ public class POPartitionRearrangeTez extends POLocalRearrangeTez {
                 if (idxTuple.size() > 3) {
                 // remove the last 2 fields of the tuple, i.e: minIndex
                 // and maxIndex and store it in the reducer map
-                Tuple keyTuple = tf.newTuple();
+                Tuple keyTuple = mTupleFactory.newTuple();
                 for (int i=0; i < idxTuple.size() - 2; i++) {
                     keyTuple.append(idxTuple.get(i));
                 }
@@ -259,13 +256,6 @@ public class POPartitionRearrangeTez extends POLocalRearrangeTez {
 
     @Override
     public POPartitionRearrangeTez clone() throws CloneNotSupportedException {
-        POPartitionRearrangeTez clone = new POPartitionRearrangeTez(new OperatorKey(
-                mKey.scope, NodeIdGenerator.getGenerator().getNextNodeId(
-                        mKey.scope)), requestedParallelism);
-        deepCopyTo(clone);
-        clone.isSkewedJoin = isSkewedJoin;
-        clone.connectedToPackage = connectedToPackage;
-        clone.setOutputKey(outputKey);
-        return clone;
+        return (POPartitionRearrangeTez) super.clone();
     }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java
index bb88af4a2..717808874 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffleTezLoad.java
@@ -170,7 +170,7 @@ public class POShuffleTezLoad extends POPackage implements TezInput {
                 if (Boolean.valueOf(conf.get(JobControlCompiler.END_OF_INP_IN_MAP, "false"))) {
                     this.parentPlan.endOfAllInput = true;
                 }
-                return new Result(POStatus.STATUS_EOP, null);
+                return RESULT_EOP;
             }
 
             key = pkgr.getKey(min);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java
index cdde2d163..9e0efe5ed 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POShuffledValueInputTez.java
@@ -38,7 +38,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezInput;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.tez.runtime.api.LogicalInput;
@@ -57,7 +56,6 @@ public class POShuffledValueInputTez extends PhysicalOperator implements TezInpu
     private transient boolean finished = false;
     private transient Iterator<KeyValueReader> readers;
     private transient KeyValueReader currentReader;
-    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
     private transient Configuration conf;
 
     public POShuffledValueInputTez(OperatorKey k) {
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueInputTez.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueInputTez.java
index d33ad419e..9f29a4af8 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueInputTez.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueInputTez.java
@@ -33,7 +33,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezInput;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.tez.runtime.api.LogicalInput;
@@ -58,7 +57,6 @@ public class POValueInputTez extends PhysicalOperator implements TezInput {
     private transient KeyValuesReader shuffleReader;
     private transient boolean shuffleInput;
     private transient boolean hasNext;
-    protected static final TupleFactory mTupleFactory = TupleFactory.getInstance();
 
     public POValueInputTez(OperatorKey k) {
         super(k);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java
index 24168343e..94a94967e 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/operator/POValueOutputTez.java
@@ -39,7 +39,6 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlan
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezOutput;
 import org.apache.pig.backend.hadoop.executionengine.tez.runtime.TezTaskConfigurable;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.tez.runtime.api.LogicalOutput;
@@ -51,8 +50,6 @@ public class POValueOutputTez extends PhysicalOperator implements TezOutput, Tez
     private static final long serialVersionUID = 1L;
     private static final Log LOG = LogFactory.getLog(POValueOutputTez.class);
 
-    private static final TupleFactory tupleFactory = TupleFactory.getInstance();
-
     private boolean scalarOutput;
     private transient Object scalarValue;
     private boolean taskIndexWithRecordIndexAsKey;
@@ -171,7 +168,7 @@ public class POValueOutputTez extends PhysicalOperator implements TezOutput, Tez
                 }
             }
             if (taskIndexWithRecordIndexAsKey) {
-                Tuple tuple = tupleFactory.newTuple(2);
+                Tuple tuple = mTupleFactory.newTuple(2);
                 tuple.set(0, taskIndex);
                 tuple.set(1, count++);
                 key = tuple;
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java
index 3f84a152a..f47140bcf 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/plan/optimizer/UnionOptimizer.java
@@ -110,6 +110,12 @@ public class UnionOptimizer extends TezOpPlanVisitor {
         if((tezOp.isLimit() || tezOp.isLimitAfterSort()) && tezOp.getRequestedParallelism() == 1) {
             return false;
         }
+        // Two vertices separately ranking with 1 to n and writing to output directly
+        // will make each rank repeate twice which is wrong. Rank always needs to be
+        // done from single vertex to have the counting correct.
+        if (tezOp.isRankCounter()) {
+            return false;
+        }
         if (supportedStoreFuncs != null || unsupportedStoreFuncs != null) {
             List<POStoreTez> stores = PlanHelper.getPhysicalOperators(tezOp.plan, POStoreTez.class);
             for (POStoreTez store : stores) {
diff --git a/test/e2e/pig/tests/multiquery.conf b/test/e2e/pig/tests/multiquery.conf
index 7bf45d5d5..7eee17fcf 100644
--- a/test/e2e/pig/tests/multiquery.conf
+++ b/test/e2e/pig/tests/multiquery.conf
@@ -573,71 +573,11 @@ $cfg = {
         {
         'name' => 'MultiQuery_Union',
         'tests' => [
-            { 
-            # Multiple levels of union + join
-            'num' => 1,
-            'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa:float);
-b = load ':INPATH:/singlefile/studentcolon10k' using PigStorage(':') as (name, age, gpa:float);
-c = filter a by gpa >= 4;
-c1 = foreach c generate *;
-c2 = foreach c generate *;
-c3 = union c1, c2;
-d = filter a by gpa < 4;
-d1 = foreach d generate *;
-d2 = foreach d generate *;
-d3 = union d1, d2;
-a1 = union c3, d3;
-e = join a1 by name, b by name;
-store e into ':OUTPATH:';\,
-            },
-            {
-            # Union + Replicate Join left
-            'num' => 2,
-            'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
-a1 = filter a by gpa >= 3.9;
-a2 = filter a by gpa < 2;
-c = union a1, a2;
-d = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);
-e = join c by name, d by name using 'replicated';
-store e into ':OUTPATH:';\,
-            },
-            {
-            # Union + Replicate Join right
-            'num' => 3,
-            'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
-a1 = filter a by gpa >= 3.9;
-a2 = filter a by gpa < 2;
-c = union a1, a2;
-d = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);
-e = join d by name, c by name using 'replicated';
-store e into ':OUTPATH:';\,
-            },
-            {
-            # Union + Skewed Join left
-            'num' => 4,
-            'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
-a1 = filter a by gpa >= 3.9;
-a2 = filter a by gpa < 2;
-c = union a1, a2;
-d = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);
-e = join c by name, d by name using 'skewed' PARALLEL 3;
-store e into ':OUTPATH:';\,
-            },
-            {
-            # Union + Skewed Join right
-            'num' => 5,
-            'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
-a1 = filter a by gpa >= 3.9;
-a2 = filter a by gpa < 2;
-c = union a1, a2;
-d = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);
-e = join d by name, c by name using 'skewed' PARALLEL 3;
-store e into ':OUTPATH:';\,
-            },
             { 
             # Union + Groupby + Combiner
-            'num' => 6,
+            'num' => 1,
             'floatpostprocess' => 1,
+            'java_params' => ['-Dpig.exec.mapPartAgg=false'], 
             'delimiter' => '    ',
             'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
 a1 = filter a by gpa >= 3.9;
@@ -647,34 +587,87 @@ d = group c by name;
 e = foreach d generate group, SUM(c.age);
 store e into ':OUTPATH:';\,
             },
-            {
-            # Union + Groupby + Secondary key partitioner
-            'num' => 7,
+            { 
+            # Union + Groupby + Combiner + POPartialAgg
+            'num' => 2,
             'floatpostprocess' => 1,
+            'java_params' => ['-Dpig.exec.mapPartAgg=true'], 
             'delimiter' => '    ',
             'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
 a1 = filter a by gpa >= 3.9;
 a2 = filter a by gpa < 2;
 c = union a1, a2;
 d = group c by name;
-e = foreach d { f = order c by $1,$2; generate group, f; };
+e = foreach d generate group, SUM(c.age);
 store e into ':OUTPATH:';\,
             },
             {
-            # Union + Orderby
-            'num' => 8,
-            'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
-a1 = filter a by gpa >= 3.9;
+            # Union + Replicate Join left outer + Stream + Group by + Secondary Key Partitioner
+            'num' => 3,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age:int, gpa:float);
+a1 = filter a by gpa is null or gpa >= 3.9;
 a2 = filter a by gpa < 2;
-c = union a1, a2;
-d = order c by name PARALLEL 3;
+b = union a1, a2;
+c = load ':INPATH:/singlefile/voternulltab10k' as (name, age, registration, contributions);
+d = join b by name left outer, c by name using 'replicated';
+e = stream d through `cat` as (name, age, gpa, name1, age1, registration, contributions);
+f = foreach e generate name, age, gpa, registration, contributions;
+g = group f by name;
+g1 = group f by name; -- Two separate groupbys to ensure secondary key partitioner
+h = foreach g { 
+    inner1 = order f by age, gpa, registration, contributions;
+    inner2 = limit inner1 1;
+    generate inner2, SUM(f.age); };
+i = foreach g1 {
+    inner1 = order f by age asc, gpa desc, registration asc, contributions desc;
+    inner2 = limit inner1 1;
+    generate inner2, SUM(f.age); };
+store h into ':OUTPATH:.1';
+store i into ':OUTPATH:.2';\,
+            },
+            {
+            # Union + Replicate Join inner + Order by
+            'num' => 4,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age:int, gpa:float);
+a1 = filter a by gpa is null or gpa >= 3.9;
+a2 = filter a by gpa < 1;
+b = union a1, a2;
+b1 = filter b by age < 30;
+b2 = foreach b generate name, age, FLOOR(gpa) as gpa;
+c = load ':INPATH:/singlefile/voternulltab10k' as (name, age, registration, contributions);
+d = join b2 by name, c by name using 'replicated';
+e = foreach d generate b2::name as name, b2::age as age, gpa, registration, contributions;
+f = order e by name, age DESC;
+store f into ':OUTPATH:';\,
+            'sortArgs' => ['-t', '	', '-k', '1,1', '-k', '2,2nr'],
+            },
+            {
+            # Union + Replicate Join right input
+            'num' => 5,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age, gpa);
+a1 = filter a by gpa is null or gpa <= 3.9;
+a2 = filter a by gpa < 2;
+b = union a1, a2;
+c = load ':INPATH:/singlefile/voternulltab10k' as (name, age, registration, contributions);
+d = join c by name, b by name using 'replicated';
 store d into ':OUTPATH:';\,
-            'sortArgs' => ['-t', '	', '-k', '1,1'],
             },
             {
-            # Multiple Split + Union + Join
-            'num' => 9,
-            'pig' => q\a = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
+            # Union + Left outer Join
+            'num' => 6,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age, gpa:float);
+a1 = filter a by gpa is null or gpa >= 3.9;
+a2 = filter a by gpa < 1;
+b = union a1, a2;
+c = load ':INPATH:/singlefile/voternulltab10k' as (name, age, registration, contributions);
+d = join b by name left outer, c by name;
+e = foreach d generate b::name as name, b::age as age, gpa, registration, contributions;
+store e into ':OUTPATH:';\,
+            },
+            {
+            # Multiple levels of union + Skewed join Right outer
+            'num' => 7,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age, gpa:float);
 b = filter a by gpa >= 3.9;
 b1 = foreach b generate *;
 b2 = foreach b generate *;
@@ -685,9 +678,55 @@ c2 = foreach c generate *;
 c3 = union onschema c1, c2;
 a1 = union onschema b3, c3;
 store a1 into ':OUTPATH:.1';
-d = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);
-e = join a1 by name, d by name using 'skewed' PARALLEL 3;
+d = load ':INPATH:/singlefile/voternulltab10k' as (name, age, registration, contributions);
+e = join a1 by name right outer, d by name using 'skewed' PARALLEL 3;
+store e into ':OUTPATH:.2';\,
+            },
+            {
+            # Union + Skewed Join right input
+            'num' => 8,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age, gpa);
+a1 = filter a by gpa >= 3.9;
+a2 = filter a by gpa < 2;
+b = union a1, a2;
+c = load ':INPATH:/singlefile/voternulltab10k' as (name, age, registration, contributions);
+d = join c by name, b by name using 'skewed' PARALLEL 3;
+store d into ':OUTPATH:';\,
+            },
+            {
+            # Union + CROSS
+            'num' => 9,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age, gpa:float);
+a1 = filter a by gpa == 0.00;
+a2 = filter a by gpa == 4.00;
+b = union a1, a2;
+c = load ':INPATH:/singlefile/voternulltab10k' as (name, age, registration, contributions);
+d = CROSS b, c;
+store d into ':OUTPATH:';\,
+            },
+            {
+            # Union + Rank
+            'num' => 10,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age, gpa:float);
+a1 = filter a by gpa is null or gpa >= 3.9;
+a2 = filter a by gpa < 1;
+b = union a1, a2;
+c = rank b;  
+-- Ordering is not guaranteed with union and ranking will differ. So just test rank and column separately
+d = foreach c generate $0;
+e = foreach c generate $1, $2, $3;
+store d into ':OUTPATH:.1';
 store e into ':OUTPATH:.2';\,
+            },
+            {
+            # Union + Rank dense
+            'num' => 11,
+            'pig' => q\a = load ':INPATH:/singlefile/studentnulltab10k' as (name, age, gpa:float);
+a1 = filter a by gpa is null or gpa >= 3.9;
+a2 = filter a by gpa < 1;
+b = union a1, a2;
+c = rank b by name ASC, age DESC DENSE;  
+store c into ':OUTPATH:';\,
             },
             ] # end of tests
         },
diff --git a/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-13.gld b/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-13.gld
index faa0f58fb..ad642e037 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-13.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-13.gld
@@ -28,21 +28,21 @@ Tez vertex scope-35
 # Plan on vertex
 a: Split - scope-46
 |   |
-|   e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-48	->	 scope-34
+|   e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-55	->	 scope-34
 |   |
 |   |---e: FRJoin[tuple] - scope-47	<-	 scope-45
 |       |   |
-|       |   Project[int][0] - scope-26
+|       |   Project[int][0] - scope-48
 |       |   |
-|       |   Project[int][0] - scope-27
+|       |   Project[int][0] - scope-49
 |   |
-|   e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-50	->	 scope-34
+|   e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-64	->	 scope-34
 |   |
-|   |---e: FRJoin[tuple] - scope-49	<-	 scope-45
+|   |---e: FRJoin[tuple] - scope-56	<-	 scope-45
 |       |   |
-|       |   Project[int][0] - scope-26
+|       |   Project[int][0] - scope-57
 |       |   |
-|       |   Project[int][0] - scope-27
+|       |   Project[int][0] - scope-58
 |       |
 |       |---b: Filter[bag] - scope-13
 |           |   |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2-OPTOFF.gld b/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2-OPTOFF.gld
index a6222c162..9f4df9113 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2-OPTOFF.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2-OPTOFF.gld
@@ -4,84 +4,84 @@
 #--------------------------------------------------
 # TEZ DAG plan: pig-0_scope-1
 #--------------------------------------------------
-Tez vertex scope-101	->	Tez vertex scope-103,
-Tez vertex scope-102	->	Tez vertex scope-103,
-Tez vertex scope-103	->	Tez vertex scope-107,
-Tez vertex scope-107
+Tez vertex scope-103	->	Tez vertex scope-105,
+Tez vertex scope-104	->	Tez vertex scope-105,
+Tez vertex scope-105	->	Tez vertex scope-109,
+Tez vertex scope-109
 
-Tez vertex scope-101
+Tez vertex scope-103
 # Plan on vertex
-POValueOutputTez - scope-105	->	 [scope-103]
+POValueOutputTez - scope-107	->	 [scope-105]
 |
-|---a: New For Each(false,false)[bag] - scope-79
+|---a: New For Each(false,false)[bag] - scope-81
     |   |
-    |   Cast[int] - scope-74
+    |   Cast[int] - scope-76
     |   |
-    |   |---Project[bytearray][0] - scope-73
+    |   |---Project[bytearray][0] - scope-75
     |   |
-    |   Cast[int] - scope-77
+    |   Cast[int] - scope-79
     |   |
-    |   |---Project[bytearray][1] - scope-76
+    |   |---Project[bytearray][1] - scope-78
     |
-    |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-72
-Tez vertex scope-102
+    |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-74
+Tez vertex scope-104
 # Plan on vertex
-POValueOutputTez - scope-106	->	 [scope-103]
+POValueOutputTez - scope-108	->	 [scope-105]
 |
-|---c: New For Each(false,false)[bag] - scope-87
+|---c: New For Each(false,false)[bag] - scope-89
     |   |
-    |   Cast[int] - scope-82
+    |   Cast[int] - scope-84
     |   |
-    |   |---Project[bytearray][1] - scope-81
+    |   |---Project[bytearray][1] - scope-83
     |   |
-    |   Cast[int] - scope-85
+    |   Cast[int] - scope-87
     |   |
-    |   |---Project[bytearray][0] - scope-84
+    |   |---Project[bytearray][0] - scope-86
     |
-    |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-80
-Tez vertex scope-103
+    |---b: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-82
+Tez vertex scope-105
 # Plan on vertex
-d: Local Rearrange[tuple]{int}(false) - scope-120	->	 scope-107
+d: Local Rearrange[tuple]{int}(false) - scope-122	->	 scope-109
 |   |
-|   Project[int][0] - scope-122
+|   Project[int][0] - scope-124
 |
-|---e: New For Each(false,false)[bag] - scope-108
+|---e: New For Each(false,false)[bag] - scope-110
     |   |
-    |   Project[int][0] - scope-109
+    |   Project[int][0] - scope-111
     |   |
-    |   POUserFunc(org.apache.pig.builtin.AlgebraicMathBase$Initial)[tuple] - scope-110
+    |   POUserFunc(org.apache.pig.builtin.AlgebraicMathBase$Initial)[tuple] - scope-112
     |   |
-    |   |---Project[bag][1] - scope-111
+    |   |---Project[bag][1] - scope-113
     |       |
-    |       |---Project[bag][1] - scope-112
+    |       |---Project[bag][1] - scope-114
     |
-    |---Pre Combiner Local Rearrange[tuple]{Unknown} - scope-123
+    |---Pre Combiner Local Rearrange[tuple]{Unknown} - scope-125
         |
-        |---POShuffledValueInputTez - scope-104	<-	 [scope-101, scope-102]
-Tez vertex scope-107
-# Combine plan on edge <scope-103>
-d: Local Rearrange[tuple]{int}(false) - scope-124	->	 scope-107
+        |---POShuffledValueInputTez - scope-106	<-	 [scope-103, scope-104]
+Tez vertex scope-109
+# Combine plan on edge <scope-105>
+d: Local Rearrange[tuple]{int}(false) - scope-126	->	 scope-109
 |   |
-|   Project[int][0] - scope-126
+|   Project[int][0] - scope-128
 |
-|---e: New For Each(false,false)[bag] - scope-113
+|---e: New For Each(false,false)[bag] - scope-115
     |   |
-    |   Project[int][0] - scope-114
+    |   Project[int][0] - scope-116
     |   |
-    |   POUserFunc(org.apache.pig.builtin.LongSum$Intermediate)[tuple] - scope-115
+    |   POUserFunc(org.apache.pig.builtin.LongSum$Intermediate)[tuple] - scope-117
     |   |
-    |   |---Project[bag][1] - scope-116
+    |   |---Project[bag][1] - scope-118
     |
-    |---d: Package(CombinerPackager)[tuple]{int} - scope-119
+    |---d: Package(CombinerPackager)[tuple]{int} - scope-121
 # Plan on vertex
-e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-100
+e: Store(file:///tmp/output:org.apache.pig.builtin.PigStorage) - scope-102
 |
-|---e: New For Each(false,false)[bag] - scope-99
+|---e: New For Each(false,false)[bag] - scope-101
     |   |
-    |   Project[int][0] - scope-93
+    |   Project[int][0] - scope-95
     |   |
-    |   POUserFunc(org.apache.pig.builtin.LongSum$Final)[long] - scope-97
+    |   POUserFunc(org.apache.pig.builtin.LongSum$Final)[long] - scope-99
     |   |
-    |   |---Project[bag][1] - scope-117
+    |   |---Project[bag][1] - scope-119
     |
-    |---d: Package(CombinerPackager)[tuple]{int} - scope-90
+    |---d: Package(CombinerPackager)[tuple]{int} - scope-92
diff --git a/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2.gld b/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2.gld
index e006a017b..5b8bb32c0 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/tez/TEZC-Union-2.gld
@@ -40,21 +40,21 @@ d: Local Rearrange[tuple]{int}(false) - scope-61	->	 scope-35
             |---a: Load(file:///tmp/input:org.apache.pig.builtin.PigStorage) - scope-0
 Tez vertex scope-30
 # Plan on vertex
-d: Local Rearrange[tuple]{int}(false) - scope-69	->	 scope-35
+d: Local Rearrange[tuple]{int}(false) - scope-70	->	 scope-35
 |   |
-|   Project[int][0] - scope-70
+|   Project[int][0] - scope-71
 |
-|---e: New For Each(false,false)[bag] - scope-68
+|---e: New For Each(false,false)[bag] - scope-69
     |   |
-    |   Project[int][0] - scope-64
+    |   Project[int][0] - scope-65
     |   |
-    |   POUserFunc(org.apache.pig.builtin.AlgebraicMathBase$Initial)[tuple] - scope-65
+    |   POUserFunc(org.apache.pig.builtin.AlgebraicMathBase$Initial)[tuple] - scope-66
     |   |
-    |   |---Project[bag][1] - scope-66
+    |   |---Project[bag][1] - scope-67
     |       |
-    |       |---Project[bag][1] - scope-67
+    |       |---Project[bag][1] - scope-68
     |
-    |---Pre Combiner Local Rearrange[tuple]{Unknown} - scope-71
+    |---Pre Combiner Local Rearrange[tuple]{Unknown} - scope-72
         |
         |---c: New For Each(false,false)[bag] - scope-15
             |   |
