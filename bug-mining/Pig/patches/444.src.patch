diff --git a/CHANGES.txt b/CHANGES.txt
index 49bf73b5f..5898cbbcf 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -70,7 +70,9 @@ PIG-1309: Map-side Cogroup (ashutoshc)
 
 BUG FIXES
 
-PIG-1359: bin/pig script does not pick up correct jar libraries
+PIG-1419: Remove "user.name" from JobConf (daijy)
+
+PIG-1359: bin/pig script does not pick up correct jar libraries (zjffdu)
 
 PIG-566: Dump and store outputs do not match for PigStorage (azaroth via daijy)
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java b/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java
index 3f3426a5f..5ccc988cf 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java
@@ -396,7 +396,10 @@ public class HExecutionEngine implements ExecutionEngine {
             while (propertiesIter.hasMoreElements()) {
                 String key = (String) propertiesIter.nextElement();
                 String val = properties.getProperty(key);
-                hadoopProperties.put(key, val);
+
+                // We do not put user.name, See PIG-1419
+                if (!key.equals("user.name"))
+                    hadoopProperties.put(key, val);
             }
             
             //clear user defined properties and re-populate
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index c1f6a1fbe..180b19bd4 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -336,8 +336,6 @@ public class JobControlCompiler{
         
         //Set the User Name for this job. This will be
         //used as the working directory
-        String user = System.getProperty("user.name");        
-        conf.set("user.name", (user != null ? user : "Pigster"));
         if (pigContext.defaultParallel > 0)
             conf.set("mapred.reduce.tasks", ""+pigContext.defaultParallel);
  
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
index 7fbe5a188..1b1427f59 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
@@ -230,7 +230,7 @@ public class PigInputFormat extends InputFormat<Text, Tuple> {
                 // if the execution is against Mapred DFS, set
                 // working dir to /user/<userid>
                 if(pigContext.getExecType() == ExecType.MAPREDUCE) {
-                    fs.setWorkingDirectory(new Path("/user", conf.get("user.name")));
+                    fs.setWorkingDirectory(jobcontext.getWorkingDirectory());
                 }
                 
                 // first pass input location to the loader - for this send a 
diff --git a/src/org/apache/pig/tools/grunt/GruntParser.java b/src/org/apache/pig/tools/grunt/GruntParser.java
index cc437b0f8..b45b05483 100644
--- a/src/org/apache/pig/tools/grunt/GruntParser.java
+++ b/src/org/apache/pig/tools/grunt/GruntParser.java
@@ -57,6 +57,7 @@ import org.apache.pig.backend.datastorage.ElementDescriptor;
 import org.apache.pig.backend.executionengine.ExecJob;
 import org.apache.pig.backend.executionengine.ExecutionEngine;
 import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
+import org.apache.pig.backend.hadoop.datastorage.HDataStorage;
 import org.apache.pig.backend.hadoop.executionengine.HExecutionEngine;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.util.LogUtils;
@@ -562,7 +563,7 @@ public class GruntParser extends PigScriptParser {
         if(mExplain == null) { // process only if not in "explain" mode
             try {
                 if (path == null) {
-                    container = mDfs.asContainer("/user/" + System.getProperty("user.name"));
+                    container = mDfs.asContainer(((HDataStorage)mDfs).getHFS().getHomeDirectory().toString());
                     mDfs.setActiveContainer(container);
                 }
                 else
@@ -582,7 +583,7 @@ public class GruntParser extends PigScriptParser {
             }
             catch (DataStorageException e) {
                 throw new IOException("Failed to change working directory to " + 
-                                      ((path == null) ? ("/user/" + System.getProperty("user.name")) 
+                                      ((path == null) ? (((HDataStorage)mDfs).getHFS().getHomeDirectory().toString()) 
                                                          : (path)), e);
             }
         } else {
