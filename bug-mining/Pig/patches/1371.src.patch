diff --git a/CHANGES.txt b/CHANGES.txt
index 46431c5a8..7ee9a4855 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -95,6 +95,8 @@ OPTIMIZATIONS
  
 BUG FIXES
 
+PIG-3754: InputSizeReducerEstimator.getTotalInputFileSize reports incorrect size (aniket486)
+
 PIG-3679: e2e StreamingPythonUDFs_10 fails in trunk (cheolsoo)
 
 PIG-3776: Conflicting versions of jline is present in trunk (cheolsoo)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java
index afbb00711..6f4af448f 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java
@@ -97,33 +97,35 @@ public class InputSizeReducerEstimator implements PigReducerEstimator {
      * their size nor can pig look that up itself are excluded from this size.
      */
     static long getTotalInputFileSize(Configuration conf,
-                                      List<POLoad> lds, Job job) throws IOException {
+            List<POLoad> lds, Job job) throws IOException {
         long totalInputFileSize = 0;
-        boolean foundSize = false;
         for (POLoad ld : lds) {
             long size = getInputSizeFromLoader(ld, job);
-            if (size > -1) { foundSize = true; }
-            if (size > 0) {
+            if (size > -1) {
                 totalInputFileSize += size;
                 continue;
-            }
-            // the input file location might be a list of comma separated files,
-            // separate them out
-            for (String location : LoadFunc.getPathStrings(ld.getLFile().getFileName())) {
-                if (UriUtil.isHDFSFileOrLocalOrS3N(location)) {
-                    Path path = new Path(location);
-                    FileSystem fs = path.getFileSystem(conf);
-                    FileStatus[] status = fs.globStatus(path);
-                    if (status != null) {
-                        for (FileStatus s : status) {
-                            totalInputFileSize += MapRedUtil.getPathLength(fs, s);
-                            foundSize = true;
+            } else {
+
+                // the input file location might be a list of comma separated files,
+                // separate them out
+                for (String location : LoadFunc.getPathStrings(ld.getLFile().getFileName())) {
+                    if (UriUtil.isHDFSFileOrLocalOrS3N(location)) {
+                        Path path = new Path(location);
+                        FileSystem fs = path.getFileSystem(conf);
+                        FileStatus[] status = fs.globStatus(path);
+                        if (status != null) {
+                            for (FileStatus s : status) {
+                                totalInputFileSize += MapRedUtil.getPathLength(fs, s);
+                            }
                         }
+                    } else {
+                        // If we cannot estimate size of a location, we should report -1
+                        return -1;
                     }
                 }
             }
         }
-        return foundSize ? totalInputFileSize : -1;
+        return totalInputFileSize;
     }
 
     /**
diff --git a/test/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/TestInputSizeReducerEstimator.java b/test/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/TestInputSizeReducerEstimator.java
index 0a5f016f9..b0d219305 100644
--- a/test/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/TestInputSizeReducerEstimator.java
+++ b/test/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/TestInputSizeReducerEstimator.java
@@ -17,16 +17,20 @@
  */
 package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;
 
-import com.google.common.collect.Lists;
+import java.util.Collections;
+
 import org.apache.hadoop.conf.Configuration;
 import org.apache.pig.LoadFunc;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad;
 import org.apache.pig.builtin.PigStorage;
+import org.apache.pig.impl.io.FileSpec;
 import org.apache.pig.test.PigStorageWithStatistics;
 import org.apache.pig.test.TestJobControlCompiler;
 import org.junit.Assert;
 import org.junit.Test;
 
+import com.google.common.collect.Lists;
+
 public class TestInputSizeReducerEstimator {
 
     private static final Configuration CONF = new Configuration(false);
@@ -48,6 +52,15 @@ public class TestInputSizeReducerEstimator {
                 Lists.newArrayList(
                         createPOLoadWithSize(size, new PigStorage()),
                         createPOLoadWithSize(size, new PigStorageWithStatistics())),
+                        new org.apache.hadoop.mapreduce.Job(CONF)));
+
+        // Negative test - PIG-3754
+        POLoad poLoad = createPOLoadWithSize(size, new PigStorage());
+        poLoad.setLFile(new FileSpec("hbase://users", null));
+
+        Assert.assertEquals(-1, InputSizeReducerEstimator.getTotalInputFileSize(
+                CONF,
+                Collections.singletonList(poLoad),
                 new org.apache.hadoop.mapreduce.Job(CONF)));
     }
 
