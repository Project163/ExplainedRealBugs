diff --git a/CHANGES.txt b/CHANGES.txt
index 8110c5fa9..daf64d81f 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -299,6 +299,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)
 
 BUG FIXES
 
+PIG-1831: Indeterministic behavior in local mode due to static variable PigMapReduce.sJobConf (daijy)
+
 PIG-1841: TupleSize implemented incorrectly (laukik via daijy)
 
 PIG-1843: NPE in schema generation (daijy)
diff --git a/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/string/LookupInFiles.java b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/string/LookupInFiles.java
index fd368a328..82086be20 100644
--- a/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/string/LookupInFiles.java
+++ b/contrib/piggybank/java/src/main/java/org/apache/pig/piggybank/evaluation/string/LookupInFiles.java
@@ -77,7 +77,7 @@ public class LookupInFiles extends EvalFunc<Integer> {
         }
         else
         {
-            Properties props = ConfigurationUtil.toProperties(PigMapReduce.sJobConf);
+            Properties props = ConfigurationUtil.toProperties(PigMapReduce.sJobConfInternal.get());
             for (int i = 0; i < mFiles.size(); ++i) {
                 // Files contain only 1 column with the key. No Schema. All keys
                 // separated by new line.
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
index 0302ec81c..547b577c6 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
@@ -107,7 +107,7 @@ public abstract class PigMapBase extends Mapper<Text, Tuple, PigNullableWritable
             return;
         }
             
-        if(PigMapReduce.sJobConf.get(JobControlCompiler.END_OF_INP_IN_MAP, "false").equals("true")) {
+        if(PigMapReduce.sJobConfInternal.get().get(JobControlCompiler.END_OF_INP_IN_MAP, "false").equals("true")) {
             // If there is a stream in the pipeline or if this map job belongs to merge-join we could 
             // potentially have more to process - so lets
             // set the flag stating that all map input has been sent
@@ -156,6 +156,7 @@ public abstract class PigMapBase extends Mapper<Text, Tuple, PigNullableWritable
         Configuration job = context.getConfiguration();
         SpillableMemoryManager.configure(ConfigurationUtil.toProperties(job));
         PigMapReduce.sJobContext = context;
+        PigMapReduce.sJobConfInternal.set(context.getConfiguration());
         PigMapReduce.sJobConf = context.getConfiguration();
         inIllustrator = (context instanceof IllustratorContext);
         
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
index 536baef6f..328228d61 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
@@ -97,10 +97,10 @@ public class PigMapReduce {
      * the job's {@link Configuration}:
      * <pre>UdfContext.getUdfContext().getJobConf()</pre>
      */
-    // This is used by internal pig code - it is deprecated for user code but is
-    // used by Pig internal code to set up UDFContext's conf among other things.
     @Deprecated
     public static Configuration sJobConf = null;
+    
+    public static final ThreadLocal<Configuration> sJobConfInternal = new ThreadLocal<Configuration>();
     private final static Tuple DUMMYTUPLE = null;
     
     public static class Map extends PigMapBase {
@@ -310,6 +310,7 @@ public class PigMapReduce {
             Configuration jConf = context.getConfiguration();
             SpillableMemoryManager.configure(ConfigurationUtil.toProperties(jConf));
             sJobContext = context;
+            sJobConfInternal.set(context.getConfiguration());
             sJobConf = context.getConfiguration();
             try {
                 PigContext.setPackageImportList((ArrayList<String>)ObjectSerializer.deserialize(jConf.get("udf.import.list")));
@@ -502,7 +503,7 @@ public class PigMapReduce {
                 return;
             }
             
-            if(PigMapReduce.sJobConf.get("pig.stream.in.reduce", "false").equals("true")) {
+            if(PigMapReduce.sJobConfInternal.get().get("pig.stream.in.reduce", "false").equals("true")) {
                 // If there is a stream in the pipeline we could 
                 // potentially have more to process - so lets
                 // set the flag stating that all map input has been sent
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java
index 5f580e573..51db16b97 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/partitioners/SkewedPartitioner.java
@@ -103,6 +103,7 @@ public class SkewedPartitioner extends Partitioner<PigNullableWritable, Writable
     @Override
     public void setConf(Configuration job) {
         conf = job;
+        PigMapReduce.sJobConfInternal.set(conf);
         PigMapReduce.sJobConf = conf;
         String keyDistFile = job.get("pig.keyDistFile", "");
         if (keyDistFile.length() == 0)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCollectedGroup.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCollectedGroup.java
index 2c0c18055..de65ce515 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCollectedGroup.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCollectedGroup.java
@@ -176,8 +176,8 @@ public class POCollectedGroup extends PhysicalOperator {
             // the first time, just create a new buffer and continue.
             if (prevKey == null && outputBag == null) {
 
-                if (PigMapReduce.sJobConf != null) {
-                    String bagType = PigMapReduce.sJobConf.get("pig.cachedbag.type");
+                if (PigMapReduce.sJobConfInternal.get() != null) {
+                    String bagType = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.type");
                     if (bagType != null && bagType.equalsIgnoreCase("default")) {
                         useDefaultBag = true;
                     }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCombinerPackage.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCombinerPackage.java
index 886d21a33..f5f269216 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCombinerPackage.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POCombinerPackage.java
@@ -119,8 +119,8 @@ public class POCombinerPackage extends POPackage {
 
     private DataBag createDataBag(int numBags) {
     	String bagType = null;
-        if (PigMapReduce.sJobConf != null) {
-   			bagType = PigMapReduce.sJobConf.get("pig.cachedbag.type");       			
+        if (PigMapReduce.sJobConfInternal.get() != null) {
+   			bagType = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.type");       			
    	    }
                 		          	           		
     	if (bagType != null && bagType.equalsIgnoreCase("default")) {
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
index 55ffe0d51..c5795c23e 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
@@ -89,8 +89,8 @@ public class PODistinct extends PhysicalOperator implements Cloneable {
             // by default, we create InternalSortedBag, unless user configures
 			// explicitly to use old bag
            	String bagType = null;
-            if (PigMapReduce.sJobConf != null) {
-       			bagType = PigMapReduce.sJobConf.get("pig.cachedbag.distinct.type");       			
+            if (PigMapReduce.sJobConfInternal.get() != null) {
+       			bagType = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.distinct.type");       			
        	    }            
             if (bagType != null && bagType.equalsIgnoreCase("default")) {        	    	
             	distinctBag = BagFactory.getInstance().newDistinctBag();    			
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POJoinPackage.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POJoinPackage.java
index 20eb9dad8..cfa077fec 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POJoinPackage.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POJoinPackage.java
@@ -107,8 +107,8 @@ public class POJoinPackage extends POPackage {
         
         if(firstTime){
             firstTime = false;
-            if (PigMapReduce.sJobConf != null) {
-                String bagType = PigMapReduce.sJobConf.get("pig.cachedbag.type");
+            if (PigMapReduce.sJobConfInternal.get() != null) {
+                String bagType = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.type");
                 if (bagType != null && bagType.equalsIgnoreCase("default")) {
                     useDefaultBag = true;
                 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeCogroup.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeCogroup.java
index f7a7af1c9..eea840a24 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeCogroup.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeCogroup.java
@@ -341,7 +341,7 @@ public class POMergeCogroup extends PhysicalOperator {
 
             LoadFunc loadfunc = (LoadFunc)PigContext.instantiateFuncFromSpec(sidFuncSpecs.get(i));
             loadfunc.setUDFContextSignature(loaderSignatures.get(i));
-            Job dummyJob = new Job(new Configuration(PigMapReduce.sJobConf));
+            Job dummyJob = new Job(new Configuration(PigMapReduce.sJobConfInternal.get()));
             loadfunc.setLocation(sideFileSpecs.get(i), dummyJob);
             ((IndexableLoadFunc)loadfunc).initialize(dummyJob.getConfiguration());
             sideLoaders.add(loadfunc);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeJoin.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeJoin.java
index 2b5460ad7..7de558d55 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeJoin.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POMergeJoin.java
@@ -405,7 +405,7 @@ public class POMergeJoin extends PhysicalOperator {
         // Pass signature of the loader to rightLoader
         // make a copy of the conf to use in calls to rightLoader.
         rightLoader.setUDFContextSignature(signature);
-        Job job = new Job(new Configuration(PigMapReduce.sJobConf));
+        Job job = new Job(new Configuration(PigMapReduce.sJobConfInternal.get()));
         rightLoader.setLocation(rightInputFileName, job);
         ((IndexableLoadFunc)rightLoader).initialize(job.getConfiguration());
         ((IndexableLoadFunc)rightLoader).seekNear(
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
index 51c33fcff..464c7fac6 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
@@ -220,8 +220,8 @@ public class POPackage extends PhysicalOperator {
         
         if(firstTime){
             firstTime = false;
-            if (PigMapReduce.sJobConf != null) {
-                String bagType = PigMapReduce.sJobConf.get("pig.cachedbag.type");
+            if (PigMapReduce.sJobConfInternal.get() != null) {
+                String bagType = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.type");
                 if (bagType != null && bagType.equalsIgnoreCase("default")) {
                     useDefaultBag = true;
                 }
@@ -458,8 +458,8 @@ public class POPackage extends PhysicalOperator {
         @SuppressWarnings("unchecked")
         public POPackageTupleBuffer() {    		
             batchSize = 20000;
-            if (PigMapReduce.sJobConf != null) {
-                String size = PigMapReduce.sJobConf.get("pig.accumulative.batchsize");
+            if (PigMapReduce.sJobConfInternal.get() != null) {
+                String size = PigMapReduce.sJobConfInternal.get().get("pig.accumulative.batchsize");
                 if (size != null) {
                     batchSize = Integer.parseInt(size);
                 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java
index b109358c5..6629e4757 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPartitionRearrange.java
@@ -81,7 +81,7 @@ public class POPartitionRearrange extends POLocalRearrange {
 
     /* Loads the key distribution file obtained from the sampler */
     private void loadPartitionFile() throws RuntimeException {
-        String keyDistFile = PigMapReduce.sJobConf.get("pig.keyDistFile", "");
+        String keyDistFile = PigMapReduce.sJobConfInternal.get().get("pig.keyDistFile", "");
         if (keyDistFile.isEmpty()) {
             throw new RuntimeException(
             "Internal error: missing key distribution file property.");
@@ -89,9 +89,9 @@ public class POPartitionRearrange extends POLocalRearrange {
 
         boolean tmpFileCompression = Utils.tmpFileCompression(pigContext);
         if (tmpFileCompression) {
-            PigMapReduce.sJobConf.setBoolean("pig.tmpfilecompression", true);
+            PigMapReduce.sJobConfInternal.get().setBoolean("pig.tmpfilecompression", true);
             try {
-                PigMapReduce.sJobConf.set("pig.tmpfilecompression.codec", Utils.tmpFileCompressionCodec(pigContext));
+                PigMapReduce.sJobConfInternal.get().set("pig.tmpfilecompression.codec", Utils.tmpFileCompressionCodec(pigContext));
             } catch (Exception e) {
                 throw new RuntimeException(e);
             }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
index 64a25e1ff..5f337e0a5 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
@@ -261,8 +261,8 @@ public class POSort extends PhysicalOperator {
 			// by default, we create InternalSortedBag, unless user configures
 			// explicitly to use old bag
 			String bagType = null;
-	        if (PigMapReduce.sJobConf != null) {
-	   			bagType = PigMapReduce.sJobConf.get("pig.cachedbag.sort.type");
+	        if (PigMapReduce.sJobConfInternal.get() != null) {
+	   			bagType = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.sort.type");
 	   	    }
             if (bagType != null && bagType.equalsIgnoreCase("default")) {
             	sortedBag = BagFactory.getInstance().newSortedBag(mComparator);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java b/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java
index 90dad9176..bce411660 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java
@@ -86,19 +86,19 @@ public class MapRedUtil {
         // use local file system to get the keyDistFile
         Configuration conf = new Configuration(false);            
         
-        if (PigMapReduce.sJobConf.get("fs.file.impl")!=null)
-            conf.set("fs.file.impl", PigMapReduce.sJobConf.get("fs.file.impl"));
-        if (PigMapReduce.sJobConf.get("fs.hdfs.impl")!=null)
-            conf.set("fs.hdfs.impl", PigMapReduce.sJobConf.get("fs.hdfs.impl"));
-        if (PigMapReduce.sJobConf.getBoolean("pig.tmpfilecompression", false))
+        if (PigMapReduce.sJobConfInternal.get().get("fs.file.impl")!=null)
+            conf.set("fs.file.impl", PigMapReduce.sJobConfInternal.get().get("fs.file.impl"));
+        if (PigMapReduce.sJobConfInternal.get().get("fs.hdfs.impl")!=null)
+            conf.set("fs.hdfs.impl", PigMapReduce.sJobConfInternal.get().get("fs.hdfs.impl"));
+        if (PigMapReduce.sJobConfInternal.get().getBoolean("pig.tmpfilecompression", false))
         {
             conf.setBoolean("pig.tmpfilecompression", true);
-            if (PigMapReduce.sJobConf.get("pig.tmpfilecompression.codec")!=null)
-                conf.set("pig.tmpfilecompression.codec", PigMapReduce.sJobConf.get("pig.tmpfilecompression.codec"));
+            if (PigMapReduce.sJobConfInternal.get().get("pig.tmpfilecompression.codec")!=null)
+                conf.set("pig.tmpfilecompression.codec", PigMapReduce.sJobConfInternal.get().get("pig.tmpfilecompression.codec"));
         }
         conf.set(MapRedUtil.FILE_SYSTEM_NAME, "file:///");
 
-        ReadToEndLoader loader = new ReadToEndLoader(Utils.getTmpFileStorageObject(PigMapReduce.sJobConf), conf, 
+        ReadToEndLoader loader = new ReadToEndLoader(Utils.getTmpFileStorageObject(PigMapReduce.sJobConfInternal.get()), conf, 
                 keyDistFile, 0);
         DataBag partitionList;
         Tuple t = loader.getNext();
diff --git a/src/org/apache/pig/backend/hadoop/streaming/HadoopExecutableManager.java b/src/org/apache/pig/backend/hadoop/streaming/HadoopExecutableManager.java
index e903195b0..dc7acbd22 100644
--- a/src/org/apache/pig/backend/hadoop/streaming/HadoopExecutableManager.java
+++ b/src/org/apache/pig/backend/hadoop/streaming/HadoopExecutableManager.java
@@ -86,7 +86,7 @@ public class HadoopExecutableManager extends ExecutableManager {
         }
         
         // Save a copy of the JobConf
-        job = PigMapReduce.sJobConf;
+        job = PigMapReduce.sJobConfInternal.get();
         
         // Save the output directory for the Pig Script
         scriptOutputDir = job.get("pig.streaming.task.output.dir");
diff --git a/src/org/apache/pig/builtin/Distinct.java b/src/org/apache/pig/builtin/Distinct.java
index 3a8befc18..a03bd54a2 100644
--- a/src/org/apache/pig/builtin/Distinct.java
+++ b/src/org/apache/pig/builtin/Distinct.java
@@ -117,8 +117,8 @@ public class Distinct  extends EvalFunc<DataBag> implements Algebraic {
     	// by default, we create InternalSortedBag, unless user configures
 		// explicitly to use old bag
     	String bagType = null;
-        if (PigMapReduce.sJobConf != null) {     
-   			bagType = PigMapReduce.sJobConf.get("pig.cachedbag.distinct.type");       			
+        if (PigMapReduce.sJobConfInternal.get() != null) {     
+   			bagType = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.distinct.type");       			
    	    }
                       
     	if (bagType != null && bagType.equalsIgnoreCase("default")) {        	    	
diff --git a/src/org/apache/pig/data/InternalCachedBag.java b/src/org/apache/pig/data/InternalCachedBag.java
index 6226854be..86af00071 100644
--- a/src/org/apache/pig/data/InternalCachedBag.java
+++ b/src/org/apache/pig/data/InternalCachedBag.java
@@ -57,8 +57,8 @@ public class InternalCachedBag extends DefaultAbstractBag {
     public InternalCachedBag(int bagCount) {       
         float percent = 0.2F;
         
-    	if (PigMapReduce.sJobConf != null) {
-    		String usage = PigMapReduce.sJobConf.get("pig.cachedbag.memusage");
+    	if (PigMapReduce.sJobConfInternal.get() != null) {
+    		String usage = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.memusage");
     		if (usage != null) {
     			percent = Float.parseFloat(usage);
     		}
diff --git a/src/org/apache/pig/data/InternalDistinctBag.java b/src/org/apache/pig/data/InternalDistinctBag.java
index e69bb0d44..db185b799 100644
--- a/src/org/apache/pig/data/InternalDistinctBag.java
+++ b/src/org/apache/pig/data/InternalDistinctBag.java
@@ -82,8 +82,8 @@ public class InternalDistinctBag extends SortedSpillBag {
     public InternalDistinctBag(int bagCount, double percent) {        
         if (percent < 0) {
         	percent = 0.2F;            
-        	if (PigMapReduce.sJobConf != null) {
-        		String usage = PigMapReduce.sJobConf.get("pig.cachedbag.memusage");
+        	if (PigMapReduce.sJobConfInternal.get() != null) {
+        		String usage = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.memusage");
         		if (usage != null) {
         			percent = Float.parseFloat(usage);
         		}
diff --git a/src/org/apache/pig/data/InternalSortedBag.java b/src/org/apache/pig/data/InternalSortedBag.java
index 2b3cd4e8c..bcaebf734 100644
--- a/src/org/apache/pig/data/InternalSortedBag.java
+++ b/src/org/apache/pig/data/InternalSortedBag.java
@@ -99,8 +99,8 @@ public class InternalSortedBag extends SortedSpillBag{
     public InternalSortedBag(int bagCount, double percent, Comparator<Tuple> comp) {
     	if (percent < 0) {
         	percent = 0.2F;            
-        	if (PigMapReduce.sJobConf != null) {
-        		String usage = PigMapReduce.sJobConf.get("pig.cachedbag.memusage");
+        	if (PigMapReduce.sJobConfInternal.get() != null) {
+        		String usage = PigMapReduce.sJobConfInternal.get().get("pig.cachedbag.memusage");
         		if (usage != null) {
         			percent = Float.parseFloat(usage);
         		}
diff --git a/src/org/apache/pig/impl/builtin/DefaultIndexableLoader.java b/src/org/apache/pig/impl/builtin/DefaultIndexableLoader.java
index 0ca276193..e2d3b86ee 100644
--- a/src/org/apache/pig/impl/builtin/DefaultIndexableLoader.java
+++ b/src/org/apache/pig/impl/builtin/DefaultIndexableLoader.java
@@ -194,7 +194,7 @@ public class DefaultIndexableLoader extends LoadFunc implements IndexableLoadFun
     
     private void initRightLoader(int [] splitsToBeRead) throws IOException{
         PigContext pc = (PigContext) ObjectSerializer
-                .deserialize(PigMapReduce.sJobConf.get("pig.pigContext"));
+                .deserialize(PigMapReduce.sJobConfInternal.get().get("pig.pigContext"));
         
         Configuration conf = ConfigurationUtil.toConfiguration(pc.getProperties());
         
diff --git a/src/org/apache/pig/impl/io/FileLocalizer.java b/src/org/apache/pig/impl/io/FileLocalizer.java
index bbd9d30d0..4f41ef215 100644
--- a/src/org/apache/pig/impl/io/FileLocalizer.java
+++ b/src/org/apache/pig/impl/io/FileLocalizer.java
@@ -156,7 +156,7 @@ public class FileLocalizer {
      * @throws IOException
      */
     public static InputStream openDFSFile(String fileName) throws IOException {
-        Configuration conf = PigMapReduce.sJobConf;
+        Configuration conf = PigMapReduce.sJobConfInternal.get();
         if (conf == null) {
             throw new RuntimeException(
                     "can't open DFS file while executing locally");
@@ -173,7 +173,7 @@ public class FileLocalizer {
     }
     
     public static long getSize(String fileName) throws IOException {
-    	Configuration conf = PigMapReduce.sJobConf;
+    	Configuration conf = PigMapReduce.sJobConfInternal.get();
 
     	if (conf == null) {
     		throw new RuntimeException(
diff --git a/test/org/apache/pig/test/TestFRJoin.java b/test/org/apache/pig/test/TestFRJoin.java
index e65f9b8ac..b3908dfe0 100644
--- a/test/org/apache/pig/test/TestFRJoin.java
+++ b/test/org/apache/pig/test/TestFRJoin.java
@@ -139,7 +139,7 @@ public class TestFRJoin extends TestCase{
         private void setUpHashTable() throws IOException {
             FileSpec replFile = new FileSpec(repl,new FuncSpec(PigStorage.class.getName()+"()"));
             POLoad ld = new POLoad(new OperatorKey("Repl File Loader", 1L), replFile);
-            PigContext pc = new PigContext(ExecType.MAPREDUCE,ConfigurationUtil.toProperties(PigMapReduce.sJobConf));
+            PigContext pc = new PigContext(ExecType.MAPREDUCE,ConfigurationUtil.toProperties(PigMapReduce.sJobConfInternal.get()));
             try {
                 pc.connect();
             
diff --git a/test/org/apache/pig/test/TestFinish.java b/test/org/apache/pig/test/TestFinish.java
index f169e5955..d213a1d9a 100644
--- a/test/org/apache/pig/test/TestFinish.java
+++ b/test/org/apache/pig/test/TestFinish.java
@@ -73,7 +73,7 @@ public class TestFinish {
         @Override
         public void finish() {
             try {
-                FileSystem fs = FileSystem.get(PigMapReduce.sJobConf);
+                FileSystem fs = FileSystem.get(PigMapReduce.sJobConfInternal.get());
                 fs.create(new Path(expectedFileName));
             } catch (IOException e) {
                 throw new RuntimeException("Unable to create file:" + expectedFileName);
diff --git a/test/org/apache/pig/test/TestPruneColumn.java b/test/org/apache/pig/test/TestPruneColumn.java
index f5f73f97e..93b45e16a 100644
--- a/test/org/apache/pig/test/TestPruneColumn.java
+++ b/test/org/apache/pig/test/TestPruneColumn.java
@@ -1901,7 +1901,7 @@ public class TestPruneColumn extends TestCase {
         pigServer.registerQuery("store D into '" + Util.generateURI(output2.toString(), pigServer.getPigContext()) + "';");
         pigServer.executeBatch();
 
-        BufferedReader reader1 = new BufferedReader(new InputStreamReader(FileLocalizer.openDFSFile(output1.toString())));
+        BufferedReader reader1 = new BufferedReader(new InputStreamReader(FileLocalizer.openDFSFile(output1.toString(), pigServer.getPigContext().getProperties())));
         String line = reader1.readLine();
         assertTrue(line.equals("1\t2\t3"));
         
@@ -1910,7 +1910,7 @@ public class TestPruneColumn extends TestCase {
         
         assertTrue(reader1.readLine()==null);
         
-        BufferedReader reader2 = new BufferedReader(new InputStreamReader(FileLocalizer.openDFSFile(output2.toString())));
+        BufferedReader reader2 = new BufferedReader(new InputStreamReader(FileLocalizer.openDFSFile(output2.toString(), pigServer.getPigContext().getProperties())));
         line = reader2.readLine();
         assertTrue(line.equals("3"));
         
diff --git a/test/org/apache/pig/test/utils/FILTERFROMFILE.java b/test/org/apache/pig/test/utils/FILTERFROMFILE.java
index e34ba7261..9bcc64625 100644
--- a/test/org/apache/pig/test/utils/FILTERFROMFILE.java
+++ b/test/org/apache/pig/test/utils/FILTERFROMFILE.java
@@ -63,7 +63,7 @@ public class FILTERFROMFILE extends FilterFunc{
 	    
 		lookupTable = new HashMap<String, Boolean>();
 		
-		Properties props = ConfigurationUtil.toProperties(PigMapReduce.sJobConf);
+		Properties props = ConfigurationUtil.toProperties(PigMapReduce.sJobConfInternal.get());
 		InputStream is = FileLocalizer.openDFSFile(FilterFileName, props);
 
 		BufferedReader reader = new BufferedReader(new InputStreamReader(is));
