diff --git a/CHANGES.txt b/CHANGES.txt
index 3b6f4cffc..10257605f 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -32,8 +32,6 @@ PIG-2726: Handling legitimate NULL values in Cube operator (prasanth_j via dvrya
 
 PIG-2808: Add *.project to .gitignore (azaroth)
 
-PIG-2806: Fix merge join test regression (jcoveney)
-
 PIG-2787: change the module name in ivy to lowercase to match the maven repo (julien)
 
 PIG-2632: Create a SchemaTuple which generates efficient Tuples via code gen (jcoveney)
@@ -196,6 +194,10 @@ OPTIMIZATIONS
 
 BUG FIXES
 
+PIG-2813: Fix test regressions from PIG-2632 (jcoveney)
+
+PIG-2806: Fix merge join test regression from PIG-2632 (jcoveney)
+
 PIG-2809: TestUDFContext broken by PIG-2699 (julienledem via daijy)
 
 PIG-2807: TestParser TestPigStorage TestNewPlanOperatorPlan broken by PIG-2699 (julienledem via daijy)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java
index c1c1bd41c..58a889259 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POFRJoin.java
@@ -55,8 +55,6 @@ import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.PlanException;
 import org.apache.pig.impl.plan.VisitorException;
 
-import com.google.common.collect.Lists;
-
 /**
  * The operator models the join keys using the Local Rearrange operators which
  * are configured with the plan specified by the user. It also sets up one
@@ -109,8 +107,8 @@ public class POFRJoin extends PhysicalOperator {
 
     // This list contains nullTuples according to schema of various inputs 
     private DataBag nullBag;
-    private List<Schema> inputSchemas;
-    private List<Schema> keySchemas;
+    private Schema[] inputSchemas;
+    private Schema[] keySchemas;
 
     public POFRJoin(OperatorKey k, int rp, List<PhysicalOperator> inp,
             List<List<PhysicalPlan>> ppLists, List<List<Byte>> keyTypes,
@@ -123,8 +121,8 @@ public class POFRJoin extends PhysicalOperator {
             List<List<PhysicalPlan>> ppLists, List<List<Byte>> keyTypes,
             FileSpec[] replFiles, int fragment, boolean isLeftOuter,
             Tuple nullTuple,
-            List<Schema> inputSchemas,
-            List<Schema> keySchemas)
+            Schema[] inputSchemas,
+            Schema[] keySchemas)
             throws ExecException {
         super(k, rp, inp);
 
@@ -145,18 +143,12 @@ public class POFRJoin extends PhysicalOperator {
         if (inputSchemas != null) {
             this.inputSchemas = inputSchemas;
         } else {
-            this.inputSchemas = Lists.newArrayListWithCapacity(replFiles.length);
-            for (int i = 0; i < replFiles.length; i++) {
-                this.inputSchemas.add(null);
-            }
+            this.inputSchemas = new Schema[replFiles == null ? 0 : replFiles.length];
         }
-        if (inputSchemas != null) {
+        if (keySchemas != null) {
             this.keySchemas = keySchemas;
         } else {
-            this.keySchemas = Lists.newArrayListWithCapacity(replFiles.length);
-            for (int i = 0; i < replFiles.length; i++) {
-                this.keySchemas.add(null);
-            }
+            this.keySchemas = new Schema[replFiles == null ? 0 : replFiles.length];
         }
     }
 
@@ -357,18 +349,18 @@ public class POFRJoin extends PhysicalOperator {
      * @throws ExecException
      */
     private void setUpHashMap() throws ExecException {
-        List<SchemaTupleFactory> inputSchemaTupleFactories = Lists.newArrayListWithCapacity(inputSchemas.size());
-        List<SchemaTupleFactory> keySchemaTupleFactories = Lists.newArrayListWithCapacity(inputSchemas.size());
-        for (int i = 0; i < inputSchemas.size(); i++) {
-            Schema schema = inputSchemas.get(i);
+        SchemaTupleFactory[] inputSchemaTupleFactories = new SchemaTupleFactory[inputSchemas.length];
+        SchemaTupleFactory[] keySchemaTupleFactories = new SchemaTupleFactory[inputSchemas.length];
+        for (int i = 0; i < inputSchemas.length; i++) {
+            Schema schema = inputSchemas[i];
             if (schema != null) {
                 log.debug("Using SchemaTuple for FR Join Schema: " + schema);
-                inputSchemaTupleFactories.add(SchemaTupleBackend.newSchemaTupleFactory(schema, false, GenContext.FR_JOIN));
+                inputSchemaTupleFactories[i] = SchemaTupleBackend.newSchemaTupleFactory(schema, false, GenContext.FR_JOIN);
             }
-            schema = keySchemas.get(i);
+            schema = keySchemas[i];
             if (schema != null) {
                 log.debug("Using SchemaTuple for FR Join key Schema: " + schema);
-                keySchemaTupleFactories.add(SchemaTupleBackend.newSchemaTupleFactory(schema, false, GenContext.FR_JOIN));
+                keySchemaTupleFactories[i] = SchemaTupleBackend.newSchemaTupleFactory(schema, false, GenContext.FR_JOIN);
             }
         }
 
@@ -377,8 +369,8 @@ public class POFRJoin extends PhysicalOperator {
         for (FileSpec replFile : replFiles) {
             ++i;
 
-            SchemaTupleFactory inputSchemaTupleFactory = inputSchemaTupleFactories.get(i);
-            SchemaTupleFactory keySchemaTupleFactory = keySchemaTupleFactories.get(i);
+            SchemaTupleFactory inputSchemaTupleFactory = inputSchemaTupleFactories[i];
+            SchemaTupleFactory keySchemaTupleFactory = keySchemaTupleFactories[i];
 
             if (i == fragment) {
                 replicates[i] = null;
diff --git a/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java b/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
index 055f36f27..127ab7a16 100644
--- a/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
+++ b/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
@@ -91,8 +91,6 @@ import org.apache.pig.newplan.logical.expression.LogicalExpressionPlan;
 import org.apache.pig.newplan.logical.expression.ProjectExpression;
 import org.apache.pig.parser.SourceLocation;
 
-import com.google.common.collect.Lists;
-
 public class LogToPhyTranslationVisitor extends LogicalRelationalNodesVisitor {
     private static final Log LOG = LogFactory.getLog(LogToPhyTranslationVisitor.class);
     
@@ -962,14 +960,18 @@ public class LogToPhyTranslationVisitor extends LogicalRelationalNodesVisitor {
             logToPhyMap.put(loj, skj);
         }
         else if(loj.getJoinType() == LOJoin.JOINTYPE.REPLICATED) {
-            List<Schema> inputSchemas = Lists.newArrayListWithCapacity(inputs.size());
-            List<Schema> keySchemas = Lists.newArrayListWithCapacity(inputs.size());
+            Schema[] inputSchemas = new Schema[inputs.size()];
+            Schema[] keySchemas = new Schema[inputs.size()];
 
             outer: for (int i = 0; i < inputs.size(); i++) {
-                Schema toGen = Schema.getPigSchema(new ResourceSchema(((LogicalRelationalOperator)inputs.get(i)).getSchema()));
+                LogicalSchema logicalSchema = ((LogicalRelationalOperator)inputs.get(i)).getSchema();
+                if (logicalSchema == null) {
+                    continue;
+                }
+                Schema toGen = Schema.getPigSchema(new ResourceSchema(logicalSchema));
                 // This registers the value piece
                 SchemaTupleFrontend.registerToGenerateIfPossible(toGen, false, GenContext.FR_JOIN);
-                inputSchemas.add(toGen);
+                inputSchemas[i] = toGen;
 
                 Schema keyToGen = new Schema();
                 for (Byte byt : keyTypes.get(i)) {
@@ -981,7 +983,7 @@ public class LogToPhyTranslationVisitor extends LogicalRelationalNodesVisitor {
                 }
 
                 SchemaTupleFrontend.registerToGenerateIfPossible(keyToGen, false, GenContext.FR_JOIN);
-                keySchemas.add(keyToGen);
+                keySchemas[i] = keyToGen;
             }
             
             int fragment = 0;
diff --git a/test/org/apache/pig/data/TestSchemaTuple.java b/test/org/apache/pig/data/TestSchemaTuple.java
index f19b63d38..9cfbcccb5 100644
--- a/test/org/apache/pig/data/TestSchemaTuple.java
+++ b/test/org/apache/pig/data/TestSchemaTuple.java
@@ -43,7 +43,6 @@ import java.util.Random;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapreduce.InputSplit;
-import org.apache.hadoop.mapreduce.TaskAttemptContext;
 import org.apache.hadoop.mapreduce.TaskAttemptID;
 import org.apache.hadoop.mapreduce.lib.input.FileSplit;
 import org.apache.pig.ExecType;
@@ -482,7 +481,7 @@ public class TestSchemaTuple {
         InputSplit is = new FileSplit(new Path(temp.getAbsolutePath()), 0, temp.length(), null);
 
         InterRecordReader reader = new InterRecordReader();
-        reader.initialize(is, new TaskAttemptContext(conf, taskId));
+        reader.initialize(is, HadoopShims.createTaskAttemptContext(conf, taskId));
 
         for (int i = 0; i < sz; i++) {
             assertTrue(reader.nextKeyValue());
