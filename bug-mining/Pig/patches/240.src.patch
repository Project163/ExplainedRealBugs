diff --git a/CHANGES.txt b/CHANGES.txt
index 57e3771b1..9c96934e9 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -28,6 +28,7 @@ OPTIMIZATIONS
 
 BUG FIXES
 
+PIG-660: Integration with Hadoop 20 (sms via olgan)
 PIG-962: Skewed join creates 3 map reduce jobs (sriranjan via olgan)
 
 Release 0.4.0 - Unreleased
diff --git a/bin/pig b/bin/pig
index 20b057a42..97fc64995 100755
--- a/bin/pig
+++ b/bin/pig
@@ -34,7 +34,7 @@
 #
 #     PIG_ROOT_LOGGER The root appender. Default is INFO,console
 #
-#     PIG_HADOOP_VERSION Version of hadoop to run with.    Default is 18 (0.18).
+#     PIG_HADOOP_VERSION Version of hadoop to run with.    Default is 20 (0.20).
 
 cygwin=false
 case "`uname`" in
@@ -136,7 +136,7 @@ for f in $PIG_HOME/build/pig-*-core.jar; do
 done
 
 # Set the version for Hadoop, default to 17
-PIG_HADOOP_VERSION="${PIG_HADOOP_VERSION:-18}"
+PIG_HADOOP_VERSION="${PIG_HADOOP_VERSION:-20}"
 # add libs to CLASSPATH.    There can be more than one version of the hadoop
 # libraries in the lib dir, so don't blindly add them all.    Only add the one
 # that matche PIG_HADOOP_VERSION.
diff --git a/build.xml b/build.xml
index cd0b762b7..1a10bc674 100644
--- a/build.xml
+++ b/build.xml
@@ -47,14 +47,14 @@
     <!-- property name="build.encoding" value="ISO-8859-1" / -->
     <property name="build.encoding" value="UTF8" />
     <!-- TODO with only one version of hadoop in the lib folder we do not need that anymore -->
-    <property name="hadoop.jarfile" value="hadoop18.jar" />
+    <property name="hadoop.jarfile" value="hadoop20.jar" />
     <property name="hbase.jarfile" value="hbase-0.18.1.jar" />
     <property name="hbase.test.jarfile" value="hbase-0.18.1-test.jar" />
 
     <!-- javac properties -->
     <property name="javac.debug" value="on" />
     <property name="javac.optimize" value="on" />
-    <property name="javac.deprecation" value="on" />
+    <property name="javac.deprecation" value="off" />
     <property name="javac.version" value="1.5" />
     <property name="javac.args" value="" />
     <!-- default warnings option -->
@@ -74,7 +74,7 @@
     <property name="test.build.dir" value="${build.dir}/test" />
     <property name="test.build.classes" value="${test.build.dir}/classes" />
     <property name="test.log.dir" value="${test.build.dir}/logs" />
-    <property name="test.timeout" value="900000" />
+    <property name="test.timeout" value="2700000" />
     <property name="test.junit.output.format" value="plain" />
 
     <!-- test configuration, use ${user.home}/build.properties to configure values  -->
@@ -452,6 +452,7 @@
                     <!-- Excluded under Windows.-->
                     <exclude name="**/TestHBaseStorage.java" if="isWindows" />
                     <!-- Excluced because we don't want to run them -->
+                    <exclude name="**/TestHBaseStorage.java" />
                     <exclude name="**/PigExecTestCase.java" />
                     <exclude name="**/TypeCheckingTestUtil.java" />
                     <exclude name="**/TypeGraphPrinter.java" />
diff --git a/lib/hadoop20.jar b/lib/hadoop20.jar
new file mode 100644
index 000000000..25c381a64
Binary files /dev/null and b/lib/hadoop20.jar differ
diff --git a/src/org/apache/pig/backend/hadoop/datastorage/HConfiguration.java b/src/org/apache/pig/backend/hadoop/datastorage/HConfiguration.java
index c89686e1e..b1e8ae7b0 100644
--- a/src/org/apache/pig/backend/hadoop/datastorage/HConfiguration.java
+++ b/src/org/apache/pig/backend/hadoop/datastorage/HConfiguration.java
@@ -23,7 +23,6 @@ import java.util.Map;
 import java.util.Enumeration;
 
 import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.mapred.JobConf;
 
 import java.util.Properties;
 
diff --git a/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java b/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java
index 9a76bccb1..19a985675 100644
--- a/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java
+++ b/src/org/apache/pig/backend/hadoop/datastorage/HDataStorage.java
@@ -30,7 +30,7 @@ import java.util.HashMap;
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.dfs.DistributedFileSystem;
+import org.apache.hadoop.hdfs.DistributedFileSystem;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.pig.PigException;
 import org.apache.pig.backend.datastorage.ContainerDescriptor;
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
index b9d0799cb..8f7217ec9 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
@@ -31,6 +31,7 @@ import java.util.Set;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.mapred.JobConf;
 import org.apache.pig.FuncSpec;
 import org.apache.pig.PigException;
 import org.apache.pig.PigWarning;
@@ -1955,10 +1956,10 @@ public class MRCompiler extends PhyPlanVisitor {
             ExecutionEngine eng = pigContext.getExecutionEngine();
             if(eng instanceof HExecutionEngine){
                 try {
-                    val = Math.round(0.9f * ((HExecutionEngine)eng).getJobClient().getDefaultReduces());
+                    val = ((JobConf)((HExecutionEngine)eng).getJobClient().getConf()).getNumReduceTasks();
                     if(val<=0)
                         val = 1;
-                } catch (IOException e) {
+                } catch (Exception e) {
                     int errCode = 6015;
                     String msg = "Problem getting the default number of reduces from the Job Client.";
                     throw new MRCompilerException(msg, errCode, PigException.REMOTE_ENVIRONMENT, e);
diff --git a/src/org/apache/pig/impl/io/NullableBytesWritable.java b/src/org/apache/pig/impl/io/NullableBytesWritable.java
index ac46da306..66bc77a4d 100644
--- a/src/org/apache/pig/impl/io/NullableBytesWritable.java
+++ b/src/org/apache/pig/impl/io/NullableBytesWritable.java
@@ -39,6 +39,6 @@ public class NullableBytesWritable extends PigNullableWritable {
 
     public Object getValueAsPigType() {
         BytesWritable bw = (BytesWritable)mValue;
-        return isNull() ? null : new DataByteArray(bw.get(), 0, bw.getSize());
+        return isNull() ? null : new DataByteArray(bw.getBytes(), 0, bw.getLength());
     }
 }
diff --git a/src/org/apache/pig/tools/pigstats/PigStats.java b/src/org/apache/pig/tools/pigstats/PigStats.java
index d8acd1f80..10cd2521e 100644
--- a/src/org/apache/pig/tools/pigstats/PigStats.java
+++ b/src/org/apache/pig/tools/pigstats/PigStats.java
@@ -154,12 +154,12 @@ public class PigStats {
                     if (counters!=null)
                     {
                         Counters.Group taskgroup = counters.getGroup("org.apache.hadoop.mapred.Task$Counter");
-                        Counters.Group hdfsgroup = counters.getGroup("org.apache.hadoop.mapred.Task$FileSystemCounter");
+                        Counters.Group hdfsgroup = counters.getGroup("FileSystemCounters");
                         jobStats.put("PIG_STATS_MAP_INPUT_RECORDS", (Long.valueOf(taskgroup.getCounterForName("MAP_INPUT_RECORDS").getCounter())).toString());
                         jobStats.put("PIG_STATS_MAP_OUTPUT_RECORDS", (Long.valueOf(taskgroup.getCounterForName("MAP_OUTPUT_RECORDS").getCounter())).toString());
                         jobStats.put("PIG_STATS_REDUCE_INPUT_RECORDS", (Long.valueOf(taskgroup.getCounterForName("REDUCE_INPUT_RECORDS").getCounter())).toString());
                         jobStats.put("PIG_STATS_REDUCE_OUTPUT_RECORDS", (Long.valueOf(taskgroup.getCounterForName("REDUCE_OUTPUT_RECORDS").getCounter())).toString());
-                        jobStats.put("PIG_STATS_BYTES_WRITTEN", (Long.valueOf(hdfsgroup.getCounterForName("HDFS_WRITE").getCounter())).toString());
+                        jobStats.put("PIG_STATS_BYTES_WRITTEN", (Long.valueOf(hdfsgroup.getCounterForName("HDFS_BYTES_WRITTEN").getCounter())).toString());
                     }
                     else
                     {
diff --git a/test/org/apache/pig/test/MiniCluster.java b/test/org/apache/pig/test/MiniCluster.java
index daab464d8..545cc05aa 100644
--- a/test/org/apache/pig/test/MiniCluster.java
+++ b/test/org/apache/pig/test/MiniCluster.java
@@ -20,7 +20,7 @@ package org.apache.pig.test;
 import java.io.*;
 import java.util.Properties;
 
-import org.apache.hadoop.dfs.MiniDFSCluster;
+import org.apache.hadoop.hdfs.MiniDFSCluster;
 import org.apache.hadoop.mapred.MiniMRCluster;
 
 import org.apache.hadoop.conf.Configuration;
@@ -68,7 +68,7 @@ public class MiniCluster {
             m_conf.setInt("mapred.submit.replication", 2);
             m_conf.set("dfs.datanode.address", "0.0.0.0:0");
             m_conf.set("dfs.datanode.http.address", "0.0.0.0:0");
-            m_conf.write(new FileOutputStream(conf_file));
+            m_conf.writeXml(new FileOutputStream(conf_file));
             
             // Set the system properties needed by Pig
             System.setProperty("cluster", m_conf.get("mapred.job.tracker"));
