diff --git a/CHANGES.txt b/CHANGES.txt
index 10c96dc97..dec5faed6 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -42,6 +42,8 @@ OPTIMIZATIONS
  
 BUG FIXES
 
+PIG-2689: JsonStorage fails to find schema when LimitAdjuster runs (rohini)
+
 PIG-4056: Remove PhysicalOperator.setAlias (rohini)
 
 PIG-4058: Use single config in Tez for input and output (rohini)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LimitAdjuster.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LimitAdjuster.java
index c43683721..be6eb5b88 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LimitAdjuster.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LimitAdjuster.java
@@ -42,7 +42,7 @@ import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.impl.util.Utils;
 
 public class LimitAdjuster extends MROpPlanVisitor {
-    ArrayList<MapReduceOper> opsToAdjust = new ArrayList<MapReduceOper>();  
+    ArrayList<MapReduceOper> opsToAdjust = new ArrayList<MapReduceOper>();
     PigContext pigContext;
     NodeIdGenerator nig;
     private String scope;
@@ -70,7 +70,7 @@ public class LimitAdjuster extends MROpPlanVisitor {
             opsToAdjust.add(mr);
         }
     }
-    
+
     public void adjust() throws IOException, PlanException
     {
         for (MapReduceOper mr:opsToAdjust)
@@ -78,7 +78,7 @@ public class LimitAdjuster extends MROpPlanVisitor {
             if (mr.reducePlan.isEmpty()) continue;
             List<PhysicalOperator> mpLeaves = mr.reducePlan.getLeaves();
             if (mpLeaves.size() != 1) {
-                int errCode = 2024; 
+                int errCode = 2024;
                 String msg = "Expected reduce to have single leaf. Found " + mpLeaves.size() + " leaves.";
                 throw new MRCompilerException(msg, errCode, PigException.BUG);
             }
@@ -93,7 +93,7 @@ public class LimitAdjuster extends MROpPlanVisitor {
             }
             FileSpec oldSpec = ((POStore)mpLeaf).getSFile();
             boolean oldIsTmpStore = ((POStore)mpLeaf).isTmpStore();
-            
+
             FileSpec fSpec = new FileSpec(FileLocalizer.getTemporaryPath(pigContext).toString(),
                     new FuncSpec(Utils.getTmpFileCompressorName(pigContext)));
             POStore storeOp = (POStore) mpLeaf;
@@ -116,35 +116,36 @@ public class LimitAdjuster extends MROpPlanVisitor {
             // 2nd: From POLimit to leaves(POStore), duplicate POLimit
             // The reason for doing that:
             // 1. We need to have two map-reduce job, otherwise, we will end up with
-            //    N*M records, N is number of reducer, M is limit constant. We need 
+            //    N*M records, N is number of reducer, M is limit constant. We need
             //    one extra mapreduce job with 1 reducer
             // 2. We don't want to move operator after POLimit into the first mapreduce
             //    job, because:
             //    * Foreach will shift the key type for second mapreduce job, see PIG-461
-            //    * Foreach flatten may generating more than M records, which get cut 
+            //    * Foreach flatten may generating more than M records, which get cut
             //      by POLimit, see PIG-2231
             splitReducerForLimit(limitAdjustMROp, mr);
 
-            if (mr.isGlobalSort()) 
+            if (mr.isGlobalSort())
             {
                 limitAdjustMROp.setLimitAfterSort(true);
                 limitAdjustMROp.setSortOrder(mr.getSortOrder());
             }
-            
+
             POStore st = new POStore(new OperatorKey(scope,nig.getNextNodeId(scope)));
             st.setSFile(oldSpec);
             st.setIsTmpStore(oldIsTmpStore);
             st.setSchema(((POStore)mpLeaf).getSchema());
             st.setSignature(((POStore)mpLeaf).getSignature());
-            
+            st.copyAliasFrom(mpLeaf);
+
             limitAdjustMROp.reducePlan.addAsLeaf(st);
             limitAdjustMROp.requestedParallelism = 1;
             limitAdjustMROp.setLimitOnly(true);
-            
+
             List<MapReduceOper> successorList = mPlan.getSuccessors(mr);
             MapReduceOper successors[] = null;
-            
-            // Save a snapshot for successors, since we will modify MRPlan, 
+
+            // Save a snapshot for successors, since we will modify MRPlan,
             // use the list directly will be problematic
             if (successorList!=null && successorList.size()>0)
             {
@@ -153,17 +154,17 @@ public class LimitAdjuster extends MROpPlanVisitor {
                 for (MapReduceOper op:successorList)
                     successors[i++] = op;
             }
-            
+
             // Process UDFs
             for (String udf : mr.UDFs) {
                 if (!limitAdjustMROp.UDFs.contains(udf)) {
                     limitAdjustMROp.UDFs.add(udf);
                 }
             }
-            
+
             mPlan.add(limitAdjustMROp);
             mPlan.connect(mr, limitAdjustMROp);
-            
+
             if (successors!=null)
             {
                 for (int i=0;i<successors.length;i++)
@@ -171,22 +172,22 @@ public class LimitAdjuster extends MROpPlanVisitor {
                     MapReduceOper nextMr = successors[i];
                     if (nextMr!=null)
                         mPlan.disconnect(mr, nextMr);
-                    
+
                     if (nextMr!=null)
-                        mPlan.connect(limitAdjustMROp, nextMr);                        
+                        mPlan.connect(limitAdjustMROp, nextMr);
                 }
             }
         }
     }
-    
-    // Move all operators between POLimit and POStore in reducer plan 
+
+    // Move all operators between POLimit and POStore in reducer plan
     // from firstMROp to the secondMROp
     private void splitReducerForLimit(MapReduceOper secondMROp,
             MapReduceOper firstMROp) throws PlanException, VisitorException {
-                    
+
         PhysicalOperator op = firstMROp.reducePlan.getRoots().get(0);
         assert(op instanceof POPackage);
-        
+
         while (true) {
             List<PhysicalOperator> succs = firstMROp.reducePlan
                     .getSuccessors(op);
@@ -198,7 +199,7 @@ public class LimitAdjuster extends MROpPlanVisitor {
                 break;
             }
         }
-        
+
         POLimit pLimit2 = new POLimit(new OperatorKey(scope,nig.getNextNodeId(scope)));
         pLimit2.setLimit(firstMROp.limit);
         pLimit2.setLimitPlan(firstMROp.limitPlan);
@@ -210,17 +211,17 @@ public class LimitAdjuster extends MROpPlanVisitor {
             List<PhysicalOperator> succs = firstMROp.reducePlan
                     .getSuccessors(op);
             op = succs.get(0);
-            
+
             firstMROp.reducePlan.removeAndReconnect(opToMove);
             secondMROp.reducePlan.addAsLeaf(opToMove);
-            
+
         }
     }
-    
+
     private void connectMapToReduceLimitedSort(MapReduceOper mro, MapReduceOper sortMROp) throws PlanException, VisitorException
     {
         POLocalRearrange slr = (POLocalRearrange)sortMROp.mapPlan.getLeaves().get(0);
-        
+
         POLocalRearrange lr = null;
         try {
             lr = slr.clone();
@@ -229,9 +230,9 @@ public class LimitAdjuster extends MROpPlanVisitor {
             String msg = "Error cloning POLocalRearrange for limit after sort";
             throw new MRCompilerException(msg, errCode, PigException.BUG, e);
         }
-        
+
         mro.mapPlan.addAsLeaf(lr);
-        
+
         POPackage spkg = (POPackage)sortMROp.reducePlan.getRoots().get(0);
 
         POPackage pkg = null;
diff --git a/test/org/apache/pig/test/TestJsonLoaderStorage.java b/test/org/apache/pig/test/TestJsonLoaderStorage.java
index 61903d67e..38a329098 100644
--- a/test/org/apache/pig/test/TestJsonLoaderStorage.java
+++ b/test/org/apache/pig/test/TestJsonLoaderStorage.java
@@ -17,33 +17,32 @@
  */
 package org.apache.pig.test;
 
-import org.apache.pig.ExecType;
-import org.apache.pig.PigServer;
-import org.apache.pig.backend.executionengine.ExecJob.JOB_STATUS;
-import org.apache.pig.data.DataByteArray;
-import org.apache.pig.data.Tuple;
-import org.apache.pig.data.DataBag;
-import org.apache.pig.test.Util;
+import static org.apache.pig.builtin.mock.Storage.tuple;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
 
+import java.io.BufferedReader;
 import java.io.File;
-import java.io.FileWriter;
 import java.io.FileReader;
-import java.io.BufferedReader;
+import java.io.FileWriter;
 import java.io.IOException;
-
-import java.util.Iterator;
-import java.util.Map;
-
 import java.math.BigDecimal;
 import java.math.BigInteger;
+import java.util.Iterator;
+import java.util.Map;
 
+import org.apache.pig.ExecType;
+import org.apache.pig.PigServer;
+import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.builtin.mock.Storage;
+import org.apache.pig.builtin.mock.Storage.Data;
+import org.apache.pig.data.DataBag;
+import org.apache.pig.data.DataByteArray;
+import org.apache.pig.data.Tuple;
 import org.joda.time.DateTime;
-
+import org.junit.Before;
 import org.junit.Test;
 
-import static junit.framework.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
 public class TestJsonLoaderStorage {
 
   private static final String schema =
@@ -116,28 +115,26 @@ public class TestJsonLoaderStorage {
   private static final String jsonOutput =
     "{\"f1\":\"18\",\"count\":3}";
 
-  private Iterator<Tuple> loadJson(String input) throws IOException {
+  private PigServer pigServer;
+
+  @Before
+  public void setup() throws ExecException {
+    pigServer = new PigServer(ExecType.LOCAL);
+  }
+
+  private String getTempOutputPath() throws IOException {
     File tempFile = File.createTempFile("json", null);
+    tempFile.delete();
     tempFile.deleteOnExit();
 
-    FileWriter writer = new FileWriter(tempFile);
-    writer.write(input);
-    writer.close();
     String path = tempFile.getAbsolutePath();
-    if (Util.WINDOWS){
-      path = path.replace('\\','/');
+    if (Util.WINDOWS) {
+      path = path.replace('\\', '/');
     }
-    PigServer pigServer = new PigServer(ExecType.LOCAL);
-    pigServer.registerQuery("data = load '" + path
-        + "' using JsonLoader('" + schema + "');");
-
-    return pigServer.openIterator("data");
+    return path;
   }
 
-  private BufferedReader storeJson(String input) throws IOException {
-    File tempJsonFile = File.createTempFile("json", "");
-    tempJsonFile.delete();
-
+  private String createInput(String input) throws IOException {
     File tempInputFile = File.createTempFile("input", null);
     tempInputFile.deleteOnExit();
 
@@ -145,25 +142,35 @@ public class TestJsonLoaderStorage {
     w.write(input);
     w.close();
     String pathInputFile = tempInputFile.getAbsolutePath();
-    String pathJsonFile = tempJsonFile.getAbsolutePath();
-    if (Util.WINDOWS){
-      pathInputFile = pathInputFile.replace('\\','/');
-      pathJsonFile = pathJsonFile.replace('\\','/');
+    if (Util.WINDOWS) {
+      pathInputFile = pathInputFile.replace('\\', '/');
     }
-    PigServer pigServer = new PigServer(ExecType.LOCAL);
+    return pathInputFile;
+  }
+
+  private Iterator<Tuple> loadJson(String input) throws IOException {
+    String path = createInput(input);
+    pigServer.registerQuery("data = load '" + path
+        + "' using JsonLoader('" + schema + "');");
+
+    return pigServer.openIterator("data");
+  }
+
+  private BufferedReader storeJson(String input) throws IOException {
+    String pathInputFile = createInput(input);
+    String pathJsonFile = getTempOutputPath();
     pigServer.registerQuery("data = load '" + pathInputFile
         + "' as (" + schema + ");");
     pigServer.registerQuery("store data into '" + pathJsonFile
         + "' using JsonStorage();");
 
-    tempJsonFile.deleteOnExit();
-
-    FileReader r = new FileReader(tempJsonFile.getAbsolutePath() + "/part-m-00000");
+    FileReader r = new FileReader(pathJsonFile + "/part-m-00000");
     BufferedReader br = new BufferedReader(r);
 
     return br;
   }
 
+  @SuppressWarnings("rawtypes")
   @Test
   public void testJsonLoader() throws IOException {
     Iterator<Tuple> tuples = loadJson(json);
@@ -273,28 +280,11 @@ public class TestJsonLoaderStorage {
 
   @Test
   public void testJsonLoaderStorage() throws IOException {
-    File tempJsonFile = File.createTempFile("json", "");
-    tempJsonFile.delete();
-
-    File tempJson2File = File.createTempFile("json2", "");
-    tempJson2File.delete();
-
-    File tempInputFile = File.createTempFile("input", null);
-    tempInputFile.deleteOnExit();
 
-    FileWriter w = new FileWriter(tempInputFile);
-    w.write(rawInput);
-    w.close();
-    String pattInputFile = tempInputFile.getAbsolutePath();
-    String pattJsonFile = tempJsonFile.getAbsolutePath();
-    String pattJson2File = tempJson2File.getAbsolutePath();
-    if(Util.WINDOWS){
-       pattInputFile = pattInputFile.replace('\\','/');
-       pattJsonFile = pattJsonFile.replace('\\','/');
-       pattJson2File = pattJson2File.replace('\\','/');
-    }
+    String pattInputFile = createInput(rawInput);
+    String pattJsonFile = getTempOutputPath();
+    String pattJson2File = getTempOutputPath();
 
-    PigServer pigServer = new PigServer(ExecType.LOCAL);
     pigServer.registerQuery("data = load '" + pattInputFile
         + "' as (" + schema + ");");
     pigServer.registerQuery("store data into '" + pattJsonFile
@@ -304,10 +294,7 @@ public class TestJsonLoaderStorage {
     pigServer.registerQuery("store json into '" + pattJson2File
         + "' using JsonStorage();");
 
-    tempJsonFile.deleteOnExit();
-    tempJson2File.deleteOnExit();
-
-    FileReader r = new FileReader(tempJson2File.getAbsolutePath() + "/part-m-00000");
+    FileReader r = new FileReader(pattJson2File + "/part-m-00000");
 
     BufferedReader br = new BufferedReader(r);
     String data = br.readLine();
@@ -325,9 +312,33 @@ public class TestJsonLoaderStorage {
     br.close();
   }
 
+  @Test
+  public void testJsonStorageLimit() throws Exception {
+    String outPath = getTempOutputPath();
+    Data data = Storage.resetData(pigServer);
+    data.set("foo", tuple(1), tuple(2), tuple(3), tuple(4));
+    pigServer.registerQuery("data = load 'foo' using mock.Storage() as (id:int);");
+    pigServer.registerQuery("data = order data by id;");
+    pigServer.registerQuery("data = limit data 2;");
+    pigServer.registerQuery("store data into '" + outPath + "' using JsonStorage();");
+
+    FileReader r = new FileReader(outPath + "/part-r-00000");
+
+    BufferedReader br = new BufferedReader(r);
+
+    String line = null;
+    int count = 0;
+    while ((line = br.readLine()) != null) {
+      count++;
+      assertEquals("{\"id\":" + count + "}", line);
+    }
+    assertEquals(2, count);
+
+    br.close();
+  }
+
   @Test
   public void testSimpleMapSideStreaming() throws Exception {
-    PigServer pigServer = new PigServer(ExecType.LOCAL);
     File input = Util.createInputFile("tmp", "", new String [] {"1,2,3;4,5,6,7,8",
         "1,2,3;4,5,6,7,9",
         "1,2,3;4,5,6,7,18"});
@@ -373,4 +384,5 @@ public class TestJsonLoaderStorage {
     br.close();
     tempJsonFile.deleteOnExit();
   }
+
 }
