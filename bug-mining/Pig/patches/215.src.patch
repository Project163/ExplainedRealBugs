diff --git a/CHANGES.txt b/CHANGES.txt
index f2fbfa328..1348f7d62 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -40,6 +40,8 @@ OPTIMIZATIONS
 
 BUG FIXES
 
+    PIG-881: Pig should ship load udfs to the backend (daijy)
+
     PIG-876: limit changes order of order-by to ascending (daijy)
 
     PIG-851: Map type used as return type in UDFs not recognized at all times
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
index 5415770f2..4023a1121 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
@@ -333,6 +333,11 @@ public class MRCompiler extends PhyPlanVisitor {
             //operator op. Also this should be added to the MRPlan.
             curMROp = getMROp();
             curMROp.mapPlan.add(op);
+            if (op !=null && op instanceof POLoad)
+            {
+                if (((POLoad)op).getLFile()!=null && ((POLoad)op).getLFile().getFuncSpec()!=null)
+                    curMROp.UDFs.add(((POLoad)op).getLFile().getFuncSpec().toString());
+            }
             MRPlan.add(curMROp);
             return;
         }
diff --git a/src/org/apache/pig/impl/util/JarManager.java b/src/org/apache/pig/impl/util/JarManager.java
index 4571cc369..f2226e24c 100644
--- a/src/org/apache/pig/impl/util/JarManager.java
+++ b/src/org/apache/pig/impl/util/JarManager.java
@@ -39,13 +39,15 @@ import java.util.jar.JarOutputStream;
 import java.util.zip.ZipEntry;
 
 //import org.apache.pig.backend.hadoop.executionengine.mapreduceExec.PigMapReduce;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce;
 
 
 public class JarManager {
 
-
+    private static Log log = LogFactory.getLog(JarManager.class);
     /**
      * A container class to track the Jar files that need to be merged together to submit to Hadoop.
      */
@@ -104,9 +106,9 @@ public class JarManager {
         for (String func: funcs) {
             Class clazz = pigContext.getClassForAlias(func);
             if (clazz != null) {
-                if (pigClassLoader == clazz.getClassLoader()) {
+                /*if (pigClassLoader == clazz.getClassLoader()) {
                     continue;
-                }
+                }*/
                 addContainingJar(jarList, clazz, null, pigContext);
             }
         }
@@ -236,7 +238,11 @@ public class JarManager {
         if (pigContext.skipJars.contains(jar) && prefix == null)
             return;
         if (jar == null)
-            throw new RuntimeException("Couldn't find the jar for " + clazz.getName());
+        {
+            //throw new RuntimeException("Couldn't find the jar for " + clazz.getName());
+            log.warn("Couldn't find the jar for " + clazz.getName() + ", skip it");
+            return;
+        }
         JarListEntry jarListEntry = new JarListEntry(jar, prefix);
         if (!jarList.contains(jarListEntry))
             jarList.add(jarListEntry);
