diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/Launcher.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/Launcher.java
index cf43c01f4..e818274a2 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/Launcher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/Launcher.java
@@ -85,13 +85,13 @@ public abstract class Launcher {
         return (int)(Math.ceil(prog)) == (int)1;
     }
     
-    protected void getStats(Job job, JobClient jobClient) throws IOException{
+    protected void getStats(Job job, JobClient jobClient, boolean errNotDbg) throws IOException{
         JobID MRJobID = job.getAssignedJobID();
         TaskReport[] mapRep = jobClient.getMapTaskReports(MRJobID);
-        getErrorMessages(mapRep, "map");
+        getErrorMessages(mapRep, "map", errNotDbg);
         totalHadoopTimeSpent += computeTimeSpent(mapRep);
         TaskReport[] redRep = jobClient.getReduceTaskReports(MRJobID);
-        getErrorMessages(redRep, "reduce");
+        getErrorMessages(redRep, "reduce", errNotDbg);
         totalHadoopTimeSpent += computeTimeSpent(mapRep);
     }
     
@@ -103,13 +103,18 @@ public abstract class Launcher {
         return timeSpent;
     }
     
-    protected void getErrorMessages(TaskReport reports[], String type)
+    protected void getErrorMessages(TaskReport reports[], String type, boolean errNotDbg)
     {
         for (int i = 0; i < reports.length; i++) {
             String msgs[] = reports[i].getDiagnostics();
             for (int j = 0; j < msgs.length; j++) {
-                log.error("Error message from task (" + type + ") " +
-                    reports[i].getTaskID() + msgs[j]);
+                if (errNotDbg) {
+                    log.error("Error message from task (" + type + ") " +
+                        reports[i].getTaskID() + msgs[j]);
+                } else {
+                    log.debug("Error message from task (" + type + ") " +
+                        reports[i].getTaskID() + msgs[j]);
+                }
             }
         }
     }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java
index d4e76ec0f..f0aaf1aaf 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java
@@ -20,6 +20,7 @@ import org.apache.pig.impl.PigContext;
 import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MROperPlan;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MRPrinter;
+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MRStreamHandler;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.impl.plan.PlanException;
 import org.apache.pig.impl.plan.VisitorException;
@@ -70,15 +71,16 @@ public class LocalLauncher extends Launcher{
             log.error("Map reduce job failed");
             for (Job fj : failedJobs) {
                 log.error(fj.getMessage());
-                getStats(fj, jobClient);
+                getStats(fj, jobClient, true);
             }
+            jc.stop(); 
             return false;
         }
 
         List<Job> succJobs = jc.getSuccessfulJobs();
         if(succJobs!=null)
             for(Job job : succJobs){
-                getStats(job,jobClient);
+                getStats(job,jobClient, false);
             }
 
         jc.stop(); 
@@ -111,6 +113,11 @@ public class LocalLauncher extends Launcher{
             CombinerOptimizer co = new CombinerOptimizer(plan);
             co.visit();
         }
+
+        // check whether stream operator is present
+        MRStreamHandler checker = new MRStreamHandler(plan);
+        checker.visit();
+        
         // figure out the type of the key for the map plan
         // this is needed when the key is null to create
         // an appropriate NullableXXXWritable object
@@ -168,13 +175,13 @@ public class LocalLauncher extends Launcher{
                 throw new ExecException(
                         "Something terribly wrong with Job Control.");
             for (Job job : failedJobs) {
-                getStats(job, jobClient);
+                getStats(job, jobClient, true);
             }
         }
         List<Job> succJobs = jc.getSuccessfulJobs();
         if (succJobs != null)
             for (Job job : succJobs) {
-                getStats(job, jobClient);
+                getStats(job, jobClient, false);
             }
 
         jc.stop();
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
index 148aaad2a..114af6980 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
@@ -88,15 +88,16 @@ public class MapReduceLauncher extends Launcher{
             log.error("Map reduce job failed");
             for (Job fj : failedJobs) {
                 log.error(fj.getMessage());
-                getStats(fj, jobClient);
+                getStats(fj, jobClient, true);
             }
+            jc.stop(); 
             return false;
         }
 
         List<Job> succJobs = jc.getSuccessfulJobs();
         if(succJobs!=null)
             for(Job job : succJobs){
-                getStats(job,jobClient);
+                getStats(job,jobClient, false);
             }
 
         jc.stop(); 
