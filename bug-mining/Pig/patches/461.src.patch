diff --git a/CHANGES.txt b/CHANGES.txt
index 69b57cc9d..202887c26 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -98,6 +98,8 @@ PIG-1309: Map-side Cogroup (ashutoshc)
 
 BUG FIXES
 
+PIG-1490: Make Pig storers work with remote HDFS in secure mode (rding)
+
 PIG-1469: DefaultDataBag assumes ArrayList as default List type (azaroth via dvryaboy)
 
 PIG-1467: order by fail when set "fs.file.impl.disable.cache" to true (daijy)
diff --git a/src/org/apache/pig/StoreFunc.java b/src/org/apache/pig/StoreFunc.java
index 411d131d2..4173fbdb9 100644
--- a/src/org/apache/pig/StoreFunc.java
+++ b/src/org/apache/pig/StoreFunc.java
@@ -166,9 +166,9 @@ public abstract class StoreFunc implements StoreFuncInterface {
      * @throws IOException
      */
     public static void cleanupOnFailureImpl(String location, Job job) 
-    throws IOException {
-        FileSystem fs = FileSystem.get(job.getConfiguration());
+    throws IOException {        
         Path path = new Path(location);
+        FileSystem fs = path.getFileSystem(job.getConfiguration());
         if(fs.exists(path)){
             fs.delete(path, true);
         }    
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
index de5e9deed..15c074eaa 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
@@ -485,9 +485,9 @@ public class MapReduceLauncher extends Launcher{
     }
     
     private void createSuccessFile(Job job, POStore store) throws IOException {
-        if(shouldMarkOutputDir(job)) {
-            FileSystem fs = FileSystem.get(job.getJobConf());
+        if(shouldMarkOutputDir(job)) {            
             Path outputPath = new Path(store.getSFile().getFileName());
+            FileSystem fs = outputPath.getFileSystem(job.getJobConf());
             if(fs.exists(outputPath)){
                 // create a file in the folder to mark it
                 Path filePath = new Path(outputPath, SUCCEEDED_FILE_NAME);
diff --git a/src/org/apache/pig/impl/logicalLayer/parser/QueryParser.jjt b/src/org/apache/pig/impl/logicalLayer/parser/QueryParser.jjt
index 89f0504d2..4b9436b47 100644
--- a/src/org/apache/pig/impl/logicalLayer/parser/QueryParser.jjt
+++ b/src/org/apache/pig/impl/logicalLayer/parser/QueryParser.jjt
@@ -504,6 +504,41 @@ public class QueryParser {
 	     return result;
 	 }
 
+    void setHdfsServers(String absolutePath, PigContext pigContext) throws URISyntaxException {
+        // Get native host
+        String defaultFS = (String)pigContext.getProperties().get("fs.default.name");
+        URI defaultFSURI = new URI(defaultFS);
+        String defaultHost = defaultFSURI.getHost();
+        if (defaultHost == null) defaultHost = "";
+                
+        defaultHost = defaultHost.toLowerCase();
+    
+        Set<String> remoteHosts = getRemoteHosts(absolutePath, defaultHost);
+                    
+        String hdfsServersString = (String)pigContext.getProperties().get("mapreduce.job.hdfs-servers");
+        if (hdfsServersString == null) hdfsServersString = "";
+        String hdfsServers[] = hdfsServersString.split(",");
+                    
+        for (String remoteHost : remoteHosts) {
+            boolean existing = false;
+            for (String hdfsServer : hdfsServers) {
+                if (hdfsServer.equals(remoteHost)) {
+                    existing = true;
+                }
+            }
+            if (!existing) {
+                if (!hdfsServersString.isEmpty()) {
+                    hdfsServersString = hdfsServersString + ",";
+                }
+                hdfsServersString = hdfsServersString + remoteHost;
+            }
+        }
+    
+        if (!hdfsServersString.isEmpty()) {
+            pigContext.getProperties().setProperty("mapreduce.job.hdfs-servers", hdfsServersString);
+        }
+    }
+    
      // Check and set files to be automatically shipped for the given StreamingCommand
      // Auto-shipping rules:
      // 1. If the command begins with either perl or python assume that the 
@@ -1409,36 +1444,8 @@ LogicalOperator LoadClause(LogicalPlan lp) :
                 absolutePath = loFunc.relativeToAbsolutePath(filename, getCurrentDir(pigContext));
                 
                 if (absolutePath!=null) {
-	                // Get native host
-	                String defaultFS = (String)pigContext.getProperties().get("fs.default.name");
-	                URI defaultFSURI = new URI(defaultFS);
-	                String defaultHost = defaultFSURI.getHost();
-	                if (defaultHost==null)
-	                    defaultHost="";
-	                defaultHost = defaultHost.toLowerCase();
-	
-	                Set<String> remoteHosts = getRemoteHosts(absolutePath, defaultHost);
-	                
-	                String hdfsServersString = (String)pigContext.getProperties().get("mapreduce.job.hdfs-servers");
-	                if (hdfsServersString==null) hdfsServersString="";
-	                String hdfsServers[] = hdfsServersString.split(",");
-	                
-	                for (String remoteHost : remoteHosts) {
-	                    boolean existing = false;
-	                    for (String hdfsServer:hdfsServers) {
-	                        if (hdfsServer.equals(remoteHost))
-	                            existing = true;
-	                    }
-	                    if (!existing) {
-	                        if (!hdfsServersString.isEmpty())
-	                            hdfsServersString = hdfsServersString + ",";
-	                        hdfsServersString = hdfsServersString + remoteHost;
-	                    }
-	                }
-	
-	                if (!hdfsServersString.isEmpty())
-	                    pigContext.getProperties().setProperty("mapreduce.job.hdfs-servers", hdfsServersString);
-	            }
+                    setHdfsServers(absolutePath, pigContext);
+                }
                 fileNameMap.put(constructFileNameSignature(filename, funcSpec), absolutePath);
             }
             lo = new LOLoad(lp, new OperatorKey(scope, getNextId()), new FileSpec(absolutePath, funcSpec),
@@ -2578,6 +2585,9 @@ LogicalOperator StoreClause(LogicalPlan lp) : {LogicalOperator lo; Token t; Stri
         String absolutePath = fileNameMap.get(constructFileNameSignature(fileName, funcSpec));
         if (absolutePath == null) {
             absolutePath = stoFunc.relToAbsPathForStoreLocation(fileName, getCurrentDir(pigContext));
+            if (absolutePath != null) {
+                setHdfsServers(absolutePath, pigContext);
+            }
             fileNameMap.put(constructFileNameSignature(fileName, funcSpec), absolutePath);   
         }
         LogicalOperator store = new LOStore(lp, new OperatorKey(scope, getNextId()),
diff --git a/test/org/apache/pig/test/TestParser.java b/test/org/apache/pig/test/TestParser.java
index 3f646d6ab..3848c8caf 100644
--- a/test/org/apache/pig/test/TestParser.java
+++ b/test/org/apache/pig/test/TestParser.java
@@ -119,4 +119,37 @@ protected final Log log = LogFactory.getLog(getClass());
         } catch (IOException io) {
         }
     }
+    
+    @Test
+    public void testRemoteServerList2() throws ExecException, IOException {
+        try {
+            Properties pigProperties = pigServer.getPigContext().getProperties();
+
+            pigServer.setBatchOn();
+            
+            pigServer.registerQuery("a = load '/user/pig/1.txt';");
+            pigServer.registerQuery("store a into '/user/pig/1.txt';");
+            
+            System.out.println("hdfs-servers: " + pigProperties.getProperty("mapreduce.job.hdfs-servers"));
+            assertTrue(pigProperties.getProperty("mapreduce.job.hdfs-servers")==null);
+                       
+            pigServer.registerQuery("store a into 'hdfs://b.com/user/pig/1.txt';");
+            System.out.println("hdfs-servers: " + pigProperties.getProperty("mapreduce.job.hdfs-servers"));
+            assertTrue(pigProperties.getProperty("mapreduce.job.hdfs-servers")!=null &&
+                    pigProperties.getProperty("mapreduce.job.hdfs-servers").contains("hdfs://b.com"));
+                        
+            pigServer.registerQuery("store a into 'har://hdfs-c.com:8020/user/pig/1.txt';");
+            System.out.println("hdfs-servers: " + pigProperties.getProperty("mapreduce.job.hdfs-servers"));
+            assertTrue(pigProperties.getProperty("mapreduce.job.hdfs-servers")!=null &&
+                    pigProperties.getProperty("mapreduce.job.hdfs-servers").contains("hdfs://c.com:8020"));
+                        
+            pigServer.registerQuery("store a into 'hdfs://d.com:8020/user/pig/1.txt';");
+            System.out.println("hdfs-servers: " + pigProperties.getProperty("mapreduce.job.hdfs-servers"));
+            assertTrue(pigProperties.getProperty("mapreduce.job.hdfs-servers")!=null &&
+                    pigProperties.getProperty("mapreduce.job.hdfs-servers").contains("hdfs://d.com:8020"));
+
+        } catch (IOException io) {
+            fail(io.getMessage());
+        }
+    }
 }
