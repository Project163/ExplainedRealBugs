diff --git a/CHANGES.txt b/CHANGES.txt
index 113ed4961..b5f72634f 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -153,6 +153,8 @@ INCOMPATIBLE CHANGES
 
 IMPROVEMENTS
 
+PIG-1270: Push limit into loader (daijy)
+
 PIG-2589: Additional e2e test for 0.10 new features (daijy)
 
 PIG-2182: Add more append support to DataByteArray (gsingers via daijy)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index 60a7faf08..2172b5bc6 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -341,6 +341,7 @@ public class JobControlCompiler{
         ArrayList<FileSpec> inp = new ArrayList<FileSpec>();
         ArrayList<List<OperatorKey>> inpTargets = new ArrayList<List<OperatorKey>>();
         ArrayList<String> inpSignatureLists = new ArrayList<String>();
+        ArrayList<Long> inpLimits = new ArrayList<Long>();
         ArrayList<POStore> storeLocations = new ArrayList<POStore>();
         Path tmpLocation = null;
         
@@ -401,6 +402,7 @@ public class JobControlCompiler{
                     }
                     inpTargets.add(ldSucKeys);
                     inpSignatureLists.add(ld.getSignature());
+                    inpLimits.add(ld.getLimit());
                     //Remove the POLoad from the plan
                     if (!pigContext.inIllustrator)
                         mro.mapPlan.remove(ld);
@@ -430,6 +432,7 @@ public class JobControlCompiler{
             conf.set("pig.inputs", ObjectSerializer.serialize(inp));
             conf.set("pig.inpTargets", ObjectSerializer.serialize(inpTargets));
             conf.set("pig.inpSignatures", ObjectSerializer.serialize(inpSignatureLists));
+            conf.set("pig.inpLimits", ObjectSerializer.serialize(inpLimits));
             conf.set("pig.pigContext", ObjectSerializer.serialize(pigContext));
             conf.set("udf.import.list", ObjectSerializer.serialize(PigContext.getPackageImportList()));
             // this is for unit tests since some don't create PigServer
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
index 873e8f0bc..6c4d7aa67 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
@@ -116,7 +116,11 @@ public class PigInputFormat extends InputFormat<Text, Tuple> {
         
         InputFormat inputFormat = loadFunc.getInputFormat();
         
-        return new PigRecordReader(inputFormat, pigSplit, loadFunc, context);
+        List<Long> inpLimitLists = 
+                (ArrayList<Long>)ObjectSerializer.deserialize(
+                        conf.get("pig.inpLimits"));
+        
+        return new PigRecordReader(inputFormat, pigSplit, loadFunc, context, inpLimitLists.get(pigSplit.getInputIndex()));
     }
     
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigRecordReader.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigRecordReader.java
index c52cf1a01..b9800116f 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigRecordReader.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigRecordReader.java
@@ -84,6 +84,10 @@ public class PigRecordReader extends RecordReader<Text, Tuple> {
     
     private TaskAttemptContext context;
     
+    private final long limit;
+
+    private long recordCount = 0;
+    
     /**
      * the Configuration object with data specific to the input the underlying
      * RecordReader will process (this is obtained after a 
@@ -97,7 +101,7 @@ public class PigRecordReader extends RecordReader<Text, Tuple> {
      * 
      */
     public PigRecordReader(InputFormat inputformat, PigSplit pigSplit, 
-            LoadFunc loadFunc, TaskAttemptContext context) throws IOException, InterruptedException {
+            LoadFunc loadFunc, TaskAttemptContext context, long limit) throws IOException, InterruptedException {
         this.inputformat = inputformat;
         this.pigSplit = pigSplit; 
         this.loadfunc = loadFunc;
@@ -106,6 +110,7 @@ public class PigRecordReader extends RecordReader<Text, Tuple> {
         curReader = null;
         progress = 0;
         idx = 0;
+        this.limit = limit;
         initNextRecordReader();
     }
     
@@ -184,11 +189,14 @@ public class PigRecordReader extends RecordReader<Text, Tuple> {
 
     @Override
     public boolean nextKeyValue() throws IOException, InterruptedException {
+        if (limit != -1 && recordCount >= limit)
+            return false;
         while ((curReader == null) || (curValue = loadfunc.getNext()) == null) {
             if (!initNextRecordReader()) {
               return false;
             }
         }
+        recordCount++;
         return true;
     }
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/SampleOptimizer.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/SampleOptimizer.java
index 4d9d8a381..4d2f00a4c 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/SampleOptimizer.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/SampleOptimizer.java
@@ -211,6 +211,7 @@ public class SampleOptimizer extends MROpPlanVisitor {
         FileSpec fs = new FileSpec(predFs.getFileName(),new FuncSpec(loadFunc, rslargs));
         POLoad newLoad = new POLoad(load.getOperatorKey(),load.getRequestedParallelism(), fs);
         newLoad.setSignature(predLoad.getSignature());
+        newLoad.setLimit(predLoad.getLimit());
         try {
             mr.mapPlan.replace(load, newLoad);
             
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java
index b22719b11..605c14f4d 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLoad.java
@@ -62,6 +62,8 @@ public class POLoad extends PhysicalOperator {
     // Alias for the POLoad
     private String signature;
     
+    private long limit=-1;
+    
     public POLoad(OperatorKey k) {
         this(k,-1, null);
     }
@@ -229,4 +231,12 @@ public class POLoad extends PhysicalOperator {
         } else
           return (Tuple) out;
     }
+
+    public long getLimit() {
+        return limit;
+    }
+
+    public void setLimit(long limit) {
+        this.limit = limit;
+    }
 }
diff --git a/src/org/apache/pig/newplan/logical/relational/LOLoad.java b/src/org/apache/pig/newplan/logical/relational/LOLoad.java
index c19505ea7..447be50ef 100644
--- a/src/org/apache/pig/newplan/logical/relational/LOLoad.java
+++ b/src/org/apache/pig/newplan/logical/relational/LOLoad.java
@@ -49,6 +49,7 @@ public class LOLoad extends LogicalRelationalOperator {
     private LogicalSchema uidOnlySchema;
     private String schemaFile = null;
     private String signature = null;
+    private long limit = -1;
 
     /**
      * 
@@ -282,4 +283,12 @@ public class LOLoad extends LogicalRelationalOperator {
     public LogicalSchema getScriptSchema() {
         return scriptSchema;
     }
+
+    public long getLimit() {
+        return limit;
+    }
+
+    public void setLimit(long limit) {
+        this.limit = limit;
+    }
 }
diff --git a/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java b/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
index df328ad54..ecaa5d35f 100644
--- a/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
+++ b/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
@@ -127,6 +127,7 @@ public class LogToPhyTranslationVisitor extends LogicalRelationalNodesVisitor {
         load.setPc(pc);
         load.setResultType(DataType.BAG);
         load.setSignature(loLoad.getSignature());
+        load.setLimit(loLoad.getLimit());
         currentPlan.add(load);
         logToPhyMap.put(loLoad, load);
 
diff --git a/src/org/apache/pig/newplan/logical/rules/LimitOptimizer.java b/src/org/apache/pig/newplan/logical/rules/LimitOptimizer.java
index cdb30db1b..500111a15 100644
--- a/src/org/apache/pig/newplan/logical/rules/LimitOptimizer.java
+++ b/src/org/apache/pig/newplan/logical/rules/LimitOptimizer.java
@@ -75,8 +75,7 @@ public class LimitOptimizer extends Rule {
 
             // Limit cannot be pushed up
             if (pred instanceof LOCogroup || pred instanceof LOFilter
-                    || pred instanceof LOLoad || pred instanceof LOSplit
-                    || pred instanceof LODistinct || pred instanceof LOJoin) {
+                    || pred instanceof LOSplit || pred instanceof LODistinct || pred instanceof LOJoin) {
                 return false;
             }
 
@@ -173,6 +172,14 @@ public class LimitOptimizer extends Rule {
 
                 // remove the limit
                 currentPlan.removeAndReconnect(limit);
+            } else if (pred instanceof LOLoad) {
+                // Push limit to load
+                LOLoad load = (LOLoad) pred;
+                if (load.getLimit() == -1)
+                    load.setLimit(limit.getLimit());
+                else
+                    load.setLimit(load.getLimit() < limit.getLimit() ? load
+                            .getLimit() : limit.getLimit());
             } else if (pred instanceof LOLimit) {
                 // Limit is merged into another LOLimit
                 LOLimit beforeLimit = (LOLimit) pred;
diff --git a/test/org/apache/pig/test/TestOptimizeLimit.java b/test/org/apache/pig/test/TestOptimizeLimit.java
index b004fdfcc..2134b8e6f 100644
--- a/test/org/apache/pig/test/TestOptimizeLimit.java
+++ b/test/org/apache/pig/test/TestOptimizeLimit.java
@@ -25,6 +25,7 @@ import java.util.*;
 import org.apache.pig.ExecType;
 import org.apache.pig.PigServer;
 import org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer;
+import org.apache.pig.newplan.logical.relational.LOLoad;
 import org.apache.pig.newplan.logical.relational.LOForEach;
 import org.apache.pig.newplan.logical.relational.LOLimit;
 import org.apache.pig.newplan.logical.relational.LOStore;
@@ -104,6 +105,7 @@ public class TestOptimizeLimit {
 	    LogicalPlan newLogicalPlan = Util.buildLp(pigServer, query);;
 	    optimizePlan(newLogicalPlan);
 	    compareWithGoldenFile(newLogicalPlan, FILE_BASE_LOCATION + "new-optlimitplan2.dot");
+        Assert.assertTrue(((LOLoad) newLogicalPlan.getSources().get(0)).getLimit() == 10);
 	}
 
 	@Test
@@ -138,6 +140,7 @@ public class TestOptimizeLimit {
 	    LogicalPlan newLogicalPlan = Util.buildLp(pigServer, query);;
 	    optimizePlan(newLogicalPlan);
         compareWithGoldenFile(newLogicalPlan, FILE_BASE_LOCATION + "new-optlimitplan5.dot");
+        Assert.assertTrue(((LOLoad) newLogicalPlan.getSources().get(0)).getLimit() == 100);
     }
 	
     @Test
@@ -150,6 +153,7 @@ public class TestOptimizeLimit {
 	    LogicalPlan newLogicalPlan = Util.buildLp(pigServer, query);;
 	    optimizePlan(newLogicalPlan);
 	    compareWithGoldenFile(newLogicalPlan, FILE_BASE_LOCATION + "new-optlimitplan6.dot");
+        Assert.assertTrue(((LOLoad) newLogicalPlan.getSources().get(0)).getLimit() == 20);
 	}
     
     @Test
@@ -194,6 +198,7 @@ public class TestOptimizeLimit {
 	    LogicalPlan newLogicalPlan = Util.buildLp(pigServer, query);;
 	    optimizePlan(newLogicalPlan);
         compareWithGoldenFile(newLogicalPlan, FILE_BASE_LOCATION + "new-optlimitplan10.dot");
+        Assert.assertTrue(((LOLoad) newLogicalPlan.getSources().get(0)).getLimit() == 100);
     }
 
     @Test
