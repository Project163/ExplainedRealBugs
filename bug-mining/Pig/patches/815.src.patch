diff --git a/CHANGES.txt b/CHANGES.txt
index b431573f6..41900c36d 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -132,6 +132,8 @@ PIG-2011: Speed up TestTypedMap.java (dvryaboy)
 
 BUG FIXES
 
+PIG-2115: Fix Pig HBaseStorage configuration and setup issues (gbowyer@fastmail.co.uk via dvryaboy)
+
 PIG-2193: Using HBaseStorage to scan 2 tables in the same Map job produces bad data (rangadi via dvryaboy)
 
 PIG-2232: "declare" document contains a typo (daijy)
diff --git a/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java b/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java
index 6c11faf03..caa06fd62 100644
--- a/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java
+++ b/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java
@@ -77,6 +77,7 @@ import org.apache.pig.ResourceSchema.ResourceFieldSchema;
 import org.apache.pig.StoreFuncInterface;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigSplit;
 import org.apache.pig.backend.hadoop.hbase.HBaseTableInputFormat.HBaseTableIFBuilder;
+import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
 import org.apache.pig.builtin.Utf8StorageConverter;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
@@ -530,14 +531,7 @@ public class HBaseStorage extends LoadFunc implements StoreFuncInterface, LoadPu
     @Override
     public void setLocation(String location, Job job) throws IOException {
         job.getConfiguration().setBoolean("pig.noSplitCombination", true);
-        m_conf = job.getConfiguration();
-        HBaseConfiguration.addHbaseResources(m_conf);
-
-        // Make sure the HBase, ZooKeeper, and Guava jars get shipped.
-        TableMapReduceUtil.addDependencyJars(job.getConfiguration(), 
-            org.apache.hadoop.hbase.client.HTable.class,
-            com.google.common.collect.Lists.class,
-            org.apache.zookeeper.ZooKeeper.class);
+        m_conf = initialiseHBaseClassLoaderResources(job);
 
         String tablename = location;
         if (location.startsWith("hbase://")){
@@ -574,6 +568,24 @@ public class HBaseStorage extends LoadFunc implements StoreFuncInterface, LoadPu
         m_conf.set(TableInputFormat.SCAN, convertScanToString(scan));
     }
 
+    private Configuration initialiseHBaseClassLoaderResources(Job job) throws IOException {
+        Configuration hbaseConfig = initialiseHBaseConfig(job.getConfiguration());
+
+        // Make sure the HBase, ZooKeeper, and Guava jars get shipped.
+        TableMapReduceUtil.addDependencyJars(job.getConfiguration(),
+            org.apache.hadoop.hbase.client.HTable.class,
+            com.google.common.collect.Lists.class,
+            org.apache.zookeeper.ZooKeeper.class);
+
+        return hbaseConfig;
+    }
+
+    private Configuration initialiseHBaseConfig(Configuration conf) {
+        Configuration hbaseConfig = HBaseConfiguration.create();
+        ConfigurationUtil.mergeConf(hbaseConfig, conf);
+        return hbaseConfig;
+    }
+
     @Override
     public String relativeToAbsolutePath(String location, Path curDir)
     throws IOException {
@@ -610,7 +622,7 @@ public class HBaseStorage extends LoadFunc implements StoreFuncInterface, LoadPu
     public OutputFormat getOutputFormat() throws IOException {
         if (outputFormat == null) {
             this.outputFormat = new TableOutputFormat();
-            HBaseConfiguration.addHbaseResources(m_conf);
+            m_conf = initialiseHBaseConfig(m_conf);
             this.outputFormat.setConf(m_conf);            
         }
         return outputFormat;
@@ -751,7 +763,7 @@ public class HBaseStorage extends LoadFunc implements StoreFuncInterface, LoadPu
             schema_ = (ResourceSchema) ObjectSerializer.deserialize(serializedSchema);
         }
 
-        m_conf = HBaseConfiguration.addHbaseResources(job.getConfiguration());
+        m_conf = initialiseHBaseClassLoaderResources(job);
     }
 
     @Override
