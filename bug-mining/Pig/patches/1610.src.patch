diff --git a/CHANGES.txt b/CHANGES.txt
index 428bf9636..740aa88c8 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -105,6 +105,8 @@ OPTIMIZATIONS
  
 BUG FIXES
 
+PIG-4241: Auto local mode mistakenly converts large jobs to local mode when using with Hive tables (cheolsoo)
+
 PIG-4184: UDF backward compatibility issue after POStatus.STATUS_NULL refactory (daijy)
 
 PIG-4238: Property 'pig.job.converted.fetch' should be unset when fetch finishes (lbendig)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java
index 6b400649e..2cedde949 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/InputSizeReducerEstimator.java
@@ -92,12 +92,27 @@ public class InputSizeReducerEstimator implements PigReducerEstimator {
         return reducers;
     }
 
+    static long getTotalInputFileSize(Configuration conf,
+            List<POLoad> lds, Job job) throws IOException {
+        return getTotalInputFileSize(conf, lds, job, Long.MAX_VALUE);
+    }
+
     /**
      * Get the input size for as many inputs as possible. Inputs that do not report
      * their size nor can pig look that up itself are excluded from this size.
+     * 
+     * @param conf Configuration
+     * @param lds List of POLoads
+     * @param job Job
+     * @param max Maximum value of total input size that will trigger exit. Many
+     * times we're only interested whether the total input size is greater than
+     * X or not. In such case, we can exit the function early as soon as the max
+     * is reached.
+     * @return
+     * @throws IOException
      */
     static long getTotalInputFileSize(Configuration conf,
-            List<POLoad> lds, Job job) throws IOException {
+            List<POLoad> lds, Job job, long max) throws IOException {
         long totalInputFileSize = 0;
         for (POLoad ld : lds) {
             long size = getInputSizeFromLoader(ld, job);
@@ -115,8 +130,14 @@ public class InputSizeReducerEstimator implements PigReducerEstimator {
                         FileStatus[] status = fs.globStatus(path);
                         if (status != null) {
                             for (FileStatus s : status) {
-                                totalInputFileSize += MapRedUtil.getPathLength(fs, s);
+                                totalInputFileSize += MapRedUtil.getPathLength(fs, s, max);
+                                if (totalInputFileSize > max) {
+                                    break;
+                                }
                             }
+                        } else {
+                            // If file is not found, we should report -1
+                            return -1;
                         }
                     } else {
                         // If we cannot estimate size of a location, we should report -1
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index d8243bb3c..d61a9129e 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -445,8 +445,8 @@ public class JobControlCompiler{
             return false;
         }
 
-        long totalInputFileSize = InputSizeReducerEstimator.getTotalInputFileSize(conf, lds, job);
         long inputByteMax = conf.getLong(PigConfiguration.PIG_AUTO_LOCAL_INPUT_MAXBYTES, 100*1000*1000l);
+        long totalInputFileSize = InputSizeReducerEstimator.getTotalInputFileSize(conf, lds, job, inputByteMax);
         log.info("Size of input: " + totalInputFileSize +" bytes. Small job threshold: " + inputByteMax );
         if (totalInputFileSize < 0 || totalInputFileSize > inputByteMax) {
             return false;
@@ -1819,6 +1819,8 @@ public class JobControlCompiler{
             ArrayList<String> replicatedPath = new ArrayList<String>();
 
             FileSpec[] newReplFiles = new FileSpec[replFiles.length];
+            long maxSize = Long.valueOf(pigContext.getProperties().getProperty(
+                    PigConfiguration.PIG_JOIN_REPLICATED_MAX_BYTES, "1000000000"));
 
             // the first input is not replicated
             long sizeOfReplicatedInputs = 0;
@@ -1838,7 +1840,7 @@ public class JobControlCompiler{
                         Path path = new Path(replFiles[i].getFileName());
                         FileSystem fs = path.getFileSystem(conf);
                         sizeOfReplicatedInputs +=
-                                MapRedUtil.getPathLength(fs, fs.getFileStatus(path));
+                                MapRedUtil.getPathLength(fs, fs.getFileStatus(path), maxSize);
                     }
                     newReplFiles[i] = new FileSpec(symlink,
                             (replFiles[i] == null ? null : replFiles[i].getFuncSpec()));
@@ -1846,9 +1848,7 @@ public class JobControlCompiler{
 
                 join.setReplFiles(newReplFiles);
 
-                String maxSize = pigContext.getProperties().getProperty(
-                        PigConfiguration.PIG_JOIN_REPLICATED_MAX_BYTES, "1000000000");
-                if (sizeOfReplicatedInputs > Long.parseLong(maxSize)){
+                if (sizeOfReplicatedInputs > maxSize) {
                     throw new VisitorException("Replicated input files size: "
                             + sizeOfReplicatedInputs + " exceeds " +
                             PigConfiguration.PIG_JOIN_REPLICATED_MAX_BYTES + ": " + maxSize);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java b/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java
index f3c5ad7fb..66c049f18 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/util/MapRedUtil.java
@@ -293,11 +293,25 @@ public class MapRedUtil {
         }
     };
 
+    public static long getPathLength(FileSystem fs, FileStatus status)
+            throws IOException{
+        return getPathLength(fs, status, Long.MAX_VALUE);
+    }
+
     /**
-     * Returns the total number of bytes for this file,
-     * or if a directory all files in the directory.
+     * Returns the total number of bytes for this file, or if a directory all
+     * files in the directory.
+     * 
+     * @param fs FileSystem
+     * @param status FileStatus
+     * @param max Maximum value of total length that will trigger exit. Many
+     * times we're only interested whether the total length of files is greater
+     * than X or not. In such case, we can exit the function early as soon as
+     * the max is reached.
+     * @return
+     * @throws IOException
      */
-    public static long getPathLength(FileSystem fs, FileStatus status)
+    public static long getPathLength(FileSystem fs, FileStatus status, long max)
             throws IOException {
         if (!status.isDir()) {
             return status.getLen();
@@ -306,7 +320,8 @@ public class MapRedUtil {
                     status.getPath(), hiddenFileFilter);
             long size = 0;
             for (FileStatus child : children) {
-                size += getPathLength(fs, child);
+                size += getPathLength(fs, child, max);
+                if (size > max) return size;
             }
             return size;
         }
