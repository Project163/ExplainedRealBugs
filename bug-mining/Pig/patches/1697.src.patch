diff --git a/CHANGES.txt b/CHANGES.txt
index 117a33bd1..2760566a1 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -58,6 +58,8 @@ PIG-4333: Split BigData tests into multiple groups (rohini)
  
 BUG FIXES
 
+PIG-4491: Streaming Python Bytearray Bugs (jeremykarn via daijy)
+
 PIG-4487: Pig on Tez gives wrong success message on failure in case of multiple outputs (rohini)
 
 PIG-4483: Pig on Tez output statistics shows storing to same directory twice for union (rohini)
diff --git a/src/org/apache/pig/impl/streaming/OutputHandler.java b/src/org/apache/pig/impl/streaming/OutputHandler.java
index d5afd9b95..eb73730c7 100644
--- a/src/org/apache/pig/impl/streaming/OutputHandler.java
+++ b/src/org/apache/pig/impl/streaming/OutputHandler.java
@@ -153,9 +153,15 @@ public abstract class OutputHandler {
             recordDelimLength = recordDelimBa.length - 1; //Ignore trailing \n
             recordDelimStr = new String(recordDelimBa, 0, recordDelimLength,  Charsets.UTF_8);
         }
-        if (recordDelimLength == 0 || currValue.getLength() < recordDelimLength) {
+
+        if (recordDelimLength == 0) {
             return true;
         }
+        //If our current section is less than the delim length, then its not the end of the row.
+        if (currValue.getLength() < recordDelimLength) {
+            return false;
+        }
+
         return currValue.find(recordDelimStr, currValue.getLength() - recordDelimLength) >= 0;
     }
     
diff --git a/src/python/streaming/controller.py b/src/python/streaming/controller.py
index 6d77da823..74b4e022d 100644
--- a/src/python/streaming/controller.py
+++ b/src/python/streaming/controller.py
@@ -125,7 +125,12 @@ class PythonStreamingController:
                 try:
                     func_output = func(*inputs)
                     if should_log:
-                        log_message("Row %s: UDF Output: %s" % (self.input_count, unicode(func_output)))
+                        try:
+                            log_message("Row %s: UDF Output: %s" % (self.input_count, unicode(func_output)))
+                        except:
+                            #This is probably an error with unicoding the output.  Calling unicode on bytearray will
+                            #throw an exception.  Since its just a log statement, just skip and carry on.
+                            logging.exception("Couldn't log output.  Try to continue.")
                 except:
                     #These errors should always be caused by user code.
                     write_user_exception(module_name, self.stream_error, NUM_LINES_OFFSET_TRACE)
diff --git a/test/org/apache/pig/impl/builtin/TestStreamingUDF.java b/test/org/apache/pig/impl/builtin/TestStreamingUDF.java
index 289a07e48..888be28d0 100644
--- a/test/org/apache/pig/impl/builtin/TestStreamingUDF.java
+++ b/test/org/apache/pig/impl/builtin/TestStreamingUDF.java
@@ -29,6 +29,7 @@ import java.util.List;
 import org.apache.pig.PigServer;
 import org.apache.pig.builtin.mock.Storage.Data;
 import org.apache.pig.data.DataBag;
+import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.test.MiniGenericCluster;
@@ -46,6 +47,7 @@ import org.junit.runner.RunWith;
 @RunWith(OrderedJUnit4Runner.class)
 @TestOrder({
     "testPythonUDF_onCluster",
+    "testPythonUDF_withBytearrayAndBytes_onCluster",
     "testPythonUDF__allTypes",
     "testPythonUDF__withBigDecimal",
     "testPythonUDF",
@@ -111,6 +113,41 @@ public class TestStreamingUDF {
         assertEquals(expected0, actual0);
         assertEquals(expected1, actual1);
     }
+    
+    @Test
+    public void testPythonUDF_withBytearrayAndBytes_onCluster() throws Exception {
+        pigServerMapReduce = new PigServer(cluster.getExecType(), cluster.getProperties());
+
+        
+        String[] pythonScript = {
+            "from pig_util import outputSchema",
+            "import os",
+            "@outputSchema('f:bytearray')",
+            "def foo(bar):",
+            "    return bytearray(os.urandom(1000))"
+        };
+        
+        Util.createLocalInputFile( "pyfilewBaB.py", pythonScript);
+
+        String[] input = {
+            "field1"
+        };
+        Util.createLocalInputFile("testTupleBaB", input);
+        Util.copyFromLocalToCluster(cluster, "testTupleBaB", "testTupleBaB");
+
+        pigServerMapReduce.registerQuery("REGISTER 'pyfilewBaB.py' USING streaming_python AS pf;");
+        pigServerMapReduce.registerQuery("A = LOAD 'testTupleBaB' as (b:chararray);");
+        pigServerMapReduce.registerQuery("B = FOREACH A generate pf.foo(b);");
+
+        Iterator<Tuple> iter = pigServerMapReduce.openIterator("B");
+        assertTrue(iter.hasNext());
+        Object result = iter.next().get(0);
+
+        //Mostly we're happy we got a result w/o throwing an exception, but we'll
+        //do a basic check.
+        assertTrue(result instanceof DataByteArray);
+        assertEquals(1000, ((DataByteArray)result).size());
+    }
 
     @Test
     public void testPythonUDF() throws Exception {
@@ -159,7 +196,6 @@ public class TestStreamingUDF {
         };
         Util.createLocalInputFile( "pyfileNL.py", pythonScript);
 
-        
         Data data = resetData(pigServerLocal);
         Tuple t0 = tf.newTuple(2);
         t0.set(0, "field10");
diff --git a/test/org/apache/pig/impl/streaming/TestStreamingUDFOutputHandler.java b/test/org/apache/pig/impl/streaming/TestStreamingUDFOutputHandler.java
index 9f7adfd0b..c5978711c 100644
--- a/test/org/apache/pig/impl/streaming/TestStreamingUDFOutputHandler.java
+++ b/test/org/apache/pig/impl/streaming/TestStreamingUDFOutputHandler.java
@@ -65,6 +65,20 @@ public class TestStreamingUDFOutputHandler {
         Assert.assertEquals(tf.newTuple("abc\ndef\nghi\njkl"), t);
     }
     
+    @Test
+    public void testGetValue__earlyNewLine() throws Exception{
+        FieldSchema fs = new FieldSchema("", DataType.CHARARRAY);
+        String data = "\na|_\n";
+        
+        PigStreamingUDF deserializer = new PigStreamingUDF(fs);
+        OutputHandler outty = new StreamingUDFOutputHandler(deserializer);
+        outty.bindTo(null, getIn(data), 0, 0);
+        
+        Tuple t = outty.getNext();
+        
+        Assert.assertEquals(tf.newTuple("\na"), t);
+    }
+    
     private BufferedPositionedInputStream getIn(String input) throws UnsupportedEncodingException {
         InputStream stream = new ByteArrayInputStream(input.getBytes("UTF-8"));
         BufferedPositionedInputStream result = new BufferedPositionedInputStream(stream);
