diff --git a/CHANGES.txt b/CHANGES.txt
index 1c0706aaa..162591506 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -24,6 +24,8 @@ INCOMPATIBLE CHANGES
 
 IMPROVEMENTS
 
+PIG-3108: HBaseStorage returns empty maps when mixing wildcard with other columns (christoph.bauer via billgraham)
+
 PIG-3178: Print a stacktrace when ExecutableManager hits an OOM (knoguchi via rohini)
 
 PIG-3160: GFCross uses unnecessary loop (sandyr via cheolsoo)
diff --git a/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java b/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java
index 817c5668b..537fca62a 100644
--- a/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java
+++ b/src/org/apache/pig/backend/hadoop/hbase/HBaseStorage.java
@@ -441,21 +441,33 @@ public class HBaseStorage extends LoadFunc implements StoreFuncInterface, LoadPu
      * addFamily on the scan
      */
     private void addFiltersWithoutColumnPrefix(List<ColumnInfo> columnInfos) {
-        for (ColumnInfo columnInfo : columnInfos) {
-            if (columnInfo.columnName != null) {
-                if (LOG.isDebugEnabled()) {
-                    LOG.debug("Adding column to scan via addColumn with cf:name = " +
-                            Bytes.toString(columnInfo.getColumnFamily()) + ":" +
-                            Bytes.toString(columnInfo.getColumnName()));
+        // Need to check for mixed types in a family, so we don't call addColumn 
+        // after addFamily on the same family
+        Map<String, List<ColumnInfo>> groupedMap = groupByFamily(columnInfos);
+        for (Entry<String, List<ColumnInfo>> entrySet : groupedMap.entrySet()) {
+            boolean onlyColumns = true;
+            for (ColumnInfo columnInfo : entrySet.getValue()) {
+                if (columnInfo.isColumnMap()) {
+                    onlyColumns = false;
+                    break;
                 }
-                scan.addColumn(columnInfo.getColumnFamily(), columnInfo.getColumnName());
             }
-            else {
+            if (onlyColumns) {
+                for (ColumnInfo columnInfo : entrySet.getValue()) {
+                    if (LOG.isDebugEnabled()) {
+                        LOG.debug("Adding column to scan via addColumn with cf:name = "
+                                + Bytes.toString(columnInfo.getColumnFamily()) + ":"
+                                + Bytes.toString(columnInfo.getColumnName()));
+                    }
+                    scan.addColumn(columnInfo.getColumnFamily(), columnInfo.getColumnName());                    
+                }
+            } else {
+                String family = entrySet.getKey();
                 if (LOG.isDebugEnabled()) {
-                    LOG.debug("Adding column family to scan via addFamily with cf:name = " +
-                            Bytes.toString(columnInfo.getColumnFamily()));
+                    LOG.debug("Adding column family to scan via addFamily with cf:name = "
+                            + family);
                 }
-                scan.addFamily(columnInfo.getColumnFamily());
+                scan.addFamily(Bytes.toBytes(family));                
             }
         }
     }
@@ -703,18 +715,8 @@ public class HBaseStorage extends LoadFunc implements StoreFuncInterface, LoadPu
             // update columnInfo_
             pushProjection((RequiredFieldList) ObjectSerializer.deserialize(projectedFields));
         }
+        addFiltersWithoutColumnPrefix(columnInfo_);
 
-        for (ColumnInfo columnInfo : columnInfo_) {
-            // do we have a column family, or a column?
-            if (columnInfo.isColumnMap()) {
-                scan.addFamily(columnInfo.getColumnFamily());
-            }
-            else {
-                scan.addColumn(columnInfo.getColumnFamily(),
-                               columnInfo.getColumnName());
-            }
-
-        }
         if (requiredFieldList != null) {
             Properties p = UDFContext.getUDFContext().getUDFProperties(this.getClass(),
                     new String[] {contextSignature});
diff --git a/test/org/apache/pig/test/TestHBaseStorage.java b/test/org/apache/pig/test/TestHBaseStorage.java
index 43c5f9509..75bc4306d 100644
--- a/test/org/apache/pig/test/TestHBaseStorage.java
+++ b/test/org/apache/pig/test/TestHBaseStorage.java
@@ -435,6 +435,51 @@ public class TestHBaseStorage {
         LOG.info("LoadFromHBase done");
     }
 
+    /**
+     *     * Test Load from hbase with map parameters and with a
+     *     static column in different order
+     *
+     */
+    @Test
+    public void testLoadOrderWithFixedAndPrefixedCols() throws IOException {
+        prepareTable(TESTTABLE_1, true, DataFormat.UTF8PlainText);
+
+        pig.registerQuery("a = load 'hbase://"
+                + TESTTABLE_1
+                + "' using "
+                + "org.apache.pig.backend.hadoop.hbase.HBaseStorage('"
+                + "pig:col_* pig:prefixed_col_d"
+                + "','-loadKey') as (rowKey:chararray, cols:map[], prefixed_col_d:chararray);");
+        pig.registerQuery("b = load 'hbase://"
+                + TESTTABLE_1
+                + "' using "
+                + "org.apache.pig.backend.hadoop.hbase.HBaseStorage('"
+                + "pig:prefixed_col_d pig:col_*"
+                + "','-loadKey') as (rowKey:chararray, prefixed_col_d:chararray, cols:map[]);");
+        Iterator<Tuple> it = pig.openIterator("a");
+        Iterator<Tuple> it2 = pig.openIterator("b");
+        int count = 0;
+        LOG.info("LoadFromHBase Starting");
+        while (it.hasNext() && it2.hasNext()) {
+            Tuple t = it.next();
+            Tuple t2 = it2.next();
+            LOG.info("LoadFromHBase a:" + t);
+            LOG.info("LoadFromHBase b:" + t2);
+            String rowKey = (String) t.get(0);
+            String rowKey2 = (String) t2.get(0);
+            Assert.assertEquals(rowKey, rowKey2);
+            Assert.assertEquals(t.size(), t2.size());
+            @SuppressWarnings("rawtypes")
+            Map cols_a = (Map) t.get(1);
+            @SuppressWarnings("rawtypes")
+            Map cols_b = (Map) t2.get(2);
+            Assert.assertEquals(cols_a.size(), cols_b.size());
+            count++;
+        }
+        Assert.assertEquals(TEST_ROW_COUNT, count);
+        LOG.info("LoadFromHBase done");
+    }
+
     /**
      * load from hbase test
      *
