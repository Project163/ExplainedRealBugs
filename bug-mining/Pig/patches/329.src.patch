diff --git a/CHANGES.txt b/CHANGES.txt
index f419ffdf3..3b774f5af 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -291,6 +291,9 @@ PIG-1142: Got NullPointerException merge join with pruning (daijy)
 
 PIG-1155: Need to make sure existing loaders work "as is" (daijy)
 
+PIG-1144: set default_parallelism construct does not set the number of
+reducers correctly (daijy)
+
 Release 0.5.0
 
 INCOMPATIBLE CHANGES
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
index 65172721d..0860e26db 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
@@ -31,6 +31,7 @@ import java.util.Set;
 
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.mapred.JobConf;
+import org.apache.pig.ExecType;
 import org.apache.pig.FuncSpec;
 import org.apache.pig.IndexableLoadFunc;
 import org.apache.pig.LoadFunc;
@@ -2046,10 +2047,13 @@ public class MRCompiler extends PhyPlanVisitor {
         int val = rp;
         if(val<=0){
             ExecutionEngine eng = pigContext.getExecutionEngine();
-            if(eng instanceof HExecutionEngine){
+            if(pigContext.getExecType() != ExecType.LOCAL){
                 try {
-                    val = ((JobConf)((HExecutionEngine)eng).getJobClient().getConf()).getNumReduceTasks();
                     if(val<=0)
+                        val = pigContext.defaultParallel;
+                    if (val<=0)
+                        val = ((JobConf)((HExecutionEngine)eng).getJobClient().getConf()).getNumReduceTasks();
+                    if (val<=0)
                         val = 1;
                 } catch (Exception e) {
                     int errCode = 6015;
diff --git a/test/org/apache/pig/test/TestJobSubmission.java b/test/org/apache/pig/test/TestJobSubmission.java
index 1296fefa3..8e8a85b11 100644
--- a/test/org/apache/pig/test/TestJobSubmission.java
+++ b/test/org/apache/pig/test/TestJobSubmission.java
@@ -501,6 +501,69 @@ public class TestJobSubmission extends junit.framework.TestCase{
         
         pc.defaultParallel = -1;        
     }
+    
+    @Test
+    public void testDefaultParallelInSort() throws Throwable {
+        pc.defaultParallel = 100;
+        
+        LogicalPlanTester planTester = new LogicalPlanTester() ;
+        planTester.buildPlan("a = load 'input';");
+        LogicalPlan lp = planTester.buildPlan("b = order a by $0;");
+        PhysicalPlan pp = Util.buildPhysicalPlan(lp, pc);
+        POStore store = GenPhyOp.dummyPigStorageOp();
+        pp.addAsLeaf(store);
+        MROperPlan mrPlan = Util.buildMRPlan(pp, pc);
+
+        ExecutionEngine exe = pc.getExecutionEngine();
+        ConfigurationValidator.validatePigProperties(exe.getConfiguration());
+        Configuration conf = ConfigurationUtil.toConfiguration(exe.getConfiguration());
+        JobControlCompiler jcc = new JobControlCompiler(pc, conf);
+        
+        // Get the sort job
+        JobControl jobControl = jcc.compile(mrPlan, "Test");
+        jcc.updateMROpPlan(new ArrayList<Job>());
+        jobControl = jcc.compile(mrPlan, "Test");
+        jcc.updateMROpPlan(new ArrayList<Job>());
+        jobControl = jcc.compile(mrPlan, "Test");
+        Job job = jobControl.getWaitingJobs().get(0);
+        int parallel = job.getJobConf().getNumReduceTasks();
+
+        assertTrue(parallel==100);
+        
+        pc.defaultParallel = -1;        
+    }
+    
+    @Test
+    public void testDefaultParallelInSkewJoin() throws Throwable {
+        pc.defaultParallel = 100;
+        
+        LogicalPlanTester planTester = new LogicalPlanTester() ;
+        planTester.buildPlan("a = load 'input';");
+        planTester.buildPlan("b = load 'input';");
+        LogicalPlan lp = planTester.buildPlan("c = join a by $0, b by $0 using \"skewed\";");
+        PhysicalPlan pp = Util.buildPhysicalPlan(lp, pc);
+        POStore store = GenPhyOp.dummyPigStorageOp();
+        pp.addAsLeaf(store);
+        MROperPlan mrPlan = Util.buildMRPlan(pp, pc);
+
+        ExecutionEngine exe = pc.getExecutionEngine();
+        ConfigurationValidator.validatePigProperties(exe.getConfiguration());
+        Configuration conf = ConfigurationUtil.toConfiguration(exe.getConfiguration());
+        JobControlCompiler jcc = new JobControlCompiler(pc, conf);
+        
+        // Get the skew join job
+        JobControl jobControl = jcc.compile(mrPlan, "Test");
+        jcc.updateMROpPlan(new ArrayList<Job>());
+        jobControl = jcc.compile(mrPlan, "Test");
+        jcc.updateMROpPlan(new ArrayList<Job>());
+        jobControl = jcc.compile(mrPlan, "Test");
+        Job job = jobControl.getWaitingJobs().get(0);
+        int parallel = job.getJobConf().getNumReduceTasks();
+
+        assertTrue(parallel==100);
+        
+        pc.defaultParallel = -1;        
+    }
 
     private void submit() throws Exception{
         assertEquals(true, FileLocalizer.fileExists(hadoopLdFile, pc));
