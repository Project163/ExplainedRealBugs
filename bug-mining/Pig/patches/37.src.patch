diff --git a/src/org/apache/pig/FuncSpec.java b/src/org/apache/pig/FuncSpec.java
index 7858b0b49..69f0daa2f 100644
--- a/src/org/apache/pig/FuncSpec.java
+++ b/src/org/apache/pig/FuncSpec.java
@@ -32,7 +32,7 @@ import org.apache.pig.impl.logicalLayer.schema.Schema;
 /**
  *
  */
-public class FuncSpec implements Serializable{
+public class FuncSpec implements Serializable, Cloneable {
 
     private static final long serialVersionUID = 2L;
     String className = null;
@@ -195,5 +195,20 @@ public class FuncSpec implements Serializable{
     public void setInputArgsSchema(Schema inputArgsSchema) {
         this.inputArgsSchema = inputArgsSchema;
     }
+
+    @Override
+    public FuncSpec clone() throws CloneNotSupportedException {
+        String[] args = null;
+        if (ctorArgs != null) {
+            args = new String[ctorArgs.length];
+            for (int i = 0; i < ctorArgs.length; i++) {
+                // Can use the same strings, they're immutable
+                args[i] = ctorArgs[i];
+            }
+        }
+        Schema s = null;
+        if (inputArgsSchema != null) s = inputArgsSchema.clone();
+        return new FuncSpec(className, args, s);
+    }
     
 }
diff --git a/src/org/apache/pig/backend/executionengine/util/ExecTools.java b/src/org/apache/pig/backend/executionengine/util/ExecTools.java
new file mode 100644
index 000000000..2ecfd4d6d
--- /dev/null
+++ b/src/org/apache/pig/backend/executionengine/util/ExecTools.java
@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.pig.backend.executionengine.util;
+
+import org.apache.pig.FuncSpec;
+import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStore;
+import org.apache.pig.builtin.BinStorage;
+import org.apache.pig.impl.PigContext;
+import org.apache.pig.impl.io.FileLocalizer;
+import org.apache.pig.impl.io.FileSpec;
+import org.apache.pig.impl.plan.NodeIdGenerator;
+import org.apache.pig.impl.plan.OperatorKey;
+
+/**
+ * A collection of static methods for use by the executionengine
+ * implementations.  A way to share common code.
+ */
+public class ExecTools {
+
+    public static FileSpec checkLeafIsStore(
+            PhysicalPlan plan,
+            PigContext pigContext) throws ExecException {
+        try {
+            PhysicalOperator leaf = (PhysicalOperator)plan.getLeaves().get(0);
+            FileSpec spec = null;
+            if(!(leaf instanceof POStore)){
+                String scope = leaf.getOperatorKey().getScope();
+                POStore str = new POStore(new OperatorKey(scope,
+                    NodeIdGenerator.getGenerator().getNextNodeId(scope)));
+                str.setPc(pigContext);
+                spec = new FileSpec(FileLocalizer.getTemporaryPath(null,
+                    pigContext).toString(),
+                    new FuncSpec(BinStorage.class.getName()));
+                str.setSFile(spec);
+                plan.addAsLeaf(str);
+            } else{
+                spec = ((POStore)leaf).getSFile();
+            }
+            return spec;
+        } catch (Exception e) {
+            throw new ExecException(e);
+        }
+    }
+
+
+}
+
+
diff --git a/src/org/apache/pig/backend/hadoop/HDataType.java b/src/org/apache/pig/backend/hadoop/HDataType.java
index 131bea77e..e1ed0fd0d 100644
--- a/src/org/apache/pig/backend/hadoop/HDataType.java
+++ b/src/org/apache/pig/backend/hadoop/HDataType.java
@@ -53,45 +53,35 @@ public class HDataType {
     static Map<Byte, String> typeToName = null;
 
     public static WritableComparable getWritableComparableTypes(Object o) throws ExecException{
-        WritableComparable wcKey = null;
-        if (typeToName == null) typeToName = DataType.genTypeToNameMap();
         byte type = DataType.findType(o);
         switch (type) {
         case DataType.BAG:
-            wcKey = (DataBag) o;
-            break;
+            return (DataBag)o;
+
         case DataType.BOOLEAN:
-            boolWrit.set((Boolean)o);
-            wcKey = boolWrit;
-            break;
+            return new BooleanWritable((Boolean)o);
+
         case DataType.BYTEARRAY:
-            byte[] dbaBytes = ((DataByteArray) o).get();
-            bytesWrit.set(dbaBytes,0,dbaBytes.length);
-            wcKey = bytesWrit;
-            break;
+            return new BytesWritable(((DataByteArray)o).get());
+            
         case DataType.CHARARRAY:
-            stringWrit.set((String) o);
-            wcKey = stringWrit;
-            break;
+            return new Text((String)o);
+            
         case DataType.DOUBLE:
-            doubleWrit.set((Double) o);
-            wcKey = doubleWrit;
-            break;
+            return new DoubleWritable((Double)o);
+           
         case DataType.FLOAT:
-            floatWrit.set((Float) o);
-            wcKey = floatWrit;
-            break;
+            return new FloatWritable((Float)o);
+            
         case DataType.INTEGER:
-            intWrit.set((Integer) o);
-            wcKey = intWrit;
-            break;
+            return new IntWritable((Integer)o);
+           
         case DataType.LONG:
-            longWrit.set((Long) o);
-            wcKey = longWrit;
-            break;
+            return new LongWritable((Long)o);
+          
         case DataType.TUPLE:
-            wcKey = (Tuple) o;
-            break;
+            return (Tuple) o;
+         
 //        case DataType.MAP:
             // Hmm, This is problematic
             // Need a deep clone to convert a Map into
@@ -99,16 +89,15 @@ public class HDataType {
             // wcKey = new MapWritable();
 //            break;
         default:
+            if (typeToName == null) typeToName = DataType.genTypeToNameMap();
             throw new ExecException("The type "
                     + typeToName.get(type)
                     + " cannot be collected as a Key type");
         }
-        return wcKey;
     }
     
     public static WritableComparable getWritableComparableTypes(byte type) throws ExecException{
         WritableComparable wcKey = null;
-        if (typeToName == null) typeToName = DataType.genTypeToNameMap();
          switch (type) {
         case DataType.BAG:
             wcKey = defDB;
@@ -144,6 +133,7 @@ public class HDataType {
             // wcKey = new MapWritable();
 //            break;
         default:
+            if (typeToName == null) typeToName = DataType.genTypeToNameMap();
             throw new ExecException("The type "
                     + typeToName.get(type)
                     + " cannot be collected as a Key type");
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java b/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java
index 08e087771..22cef924d 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/HExecutionEngine.java
@@ -54,6 +54,7 @@ import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.executionengine.ExecJob;
 import org.apache.pig.backend.executionengine.ExecPhysicalOperator;
 import org.apache.pig.backend.executionengine.ExecutionEngine;
+import org.apache.pig.backend.executionengine.util.ExecTools;
 import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
 import org.apache.pig.backend.hadoop.datastorage.HDataStorage;
 import org.apache.pig.builtin.BinStorage;
@@ -251,25 +252,7 @@ public class HExecutionEngine implements ExecutionEngine {
     public ExecJob execute(PhysicalPlan plan,
                            String jobName) throws ExecException {
         try {
-            FileSpec spec = checkLeafIsStore(plan);
-            /*
-            PhysicalOperator leaf = (PhysicalOperator)plan.getLeaves().get(0);
-            FileSpec spec = null;
-            if(!(leaf instanceof POStore)){
-                String scope = leaf.getOperatorKey().getScope();
-                POStore str = new POStore(new OperatorKey(scope,
-                    NodeIdGenerator.getGenerator().getNextNodeId(scope)));
-                str.setPc(pigContext);
-                spec = new FileSpec(FileLocalizer.getTemporaryPath(null,
-                    pigContext).toString(),
-                    new FuncSpec(BinStorage.class.getName()));
-                str.setSFile(spec);
-                plan.addAsLeaf(str);
-            }
-            else{
-                spec = ((POStore)leaf).getSFile();
-            }
-            */
+            FileSpec spec = ExecTools.checkLeafIsStore(plan, pigContext);
 
             MapReduceLauncher launcher = new MapReduceLauncher();
             boolean success = launcher.launchPig(plan, jobName, pigContext);
@@ -298,7 +281,7 @@ public class HExecutionEngine implements ExecutionEngine {
             printer.visit();
             stream.println();
 
-            checkLeafIsStore(plan);
+            ExecTools.checkLeafIsStore(plan, pigContext);
 
             MapReduceLauncher launcher = new MapReduceLauncher();
             launcher.explain(plan, pigContext, stream);
@@ -551,6 +534,7 @@ public class HExecutionEngine implements ExecutionEngine {
         return p;
     }
 
+    /*
     private FileSpec checkLeafIsStore(PhysicalPlan plan) throws ExecException {
         try {
             PhysicalOperator leaf = (PhysicalOperator)plan.getLeaves().get(0);
@@ -573,6 +557,8 @@ public class HExecutionEngine implements ExecutionEngine {
             throw new ExecException(e);
         }
     }
+    */
+
     private void deleteDir(String server, String dir) {
         if (server.equals(LOCAL)){
             File path = new File(dir);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/CombinerOptimizer.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/CombinerOptimizer.java
new file mode 100644
index 000000000..b747e413a
--- /dev/null
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/CombinerOptimizer.java
@@ -0,0 +1,428 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
+import org.apache.pig.data.DataType;
+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MROperPlan;
+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MROpPlanVisitor;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PODistinct;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POFilter;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPostCombinerPackage;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort;
+import org.apache.pig.impl.plan.DepthFirstWalker;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
+import org.apache.pig.impl.plan.PlanException;
+import org.apache.pig.impl.plan.VisitorException;
+import org.apache.pig.impl.util.Pair;
+
+/**
+ * Optimize map reduce plans to use the combiner where possible.
+ * Currently Foreach is copied to the combiner phase if it does not contain a
+ * nested plan and all UDFs in the generate statement are algebraic.
+ * The version of the foreach in the combiner
+ * stage will use the initial function, and the version in the reduce stage
+ * will be changed to use the final function.
+ *
+ * Major areas for enhancement:
+ * 1) Currently, scripts such as:
+ *     B = group A by $0;
+ *     C = foreach B {
+ *         C1 = distinct A;
+ *         generate group, COUNT(C1);
+ *     }
+ * do not use the combiner.  The issue is being able to properly decompose
+ * the expression in the UDF's plan.  The current code just takes whatever is
+ * the argument to the algebraic UDF and replaces it with a project.  This
+ * works for things like generate group, SUM(A.$1 + 1).  But it fails for
+ * things like the above.  Certain types of inner plans will never be
+ * movable (like filters).  But distinct or order by in the inner plan
+ * should be moble.  And, things like:
+ *      C = cogroup A by $0, B by $0;
+ *      D = foreach C {
+ *          D1 = distinct A;
+ *          D2 = distinct B;
+ *          generate UDF(D1 + D2);
+ *      }
+ * make it even harder.  The first step is probably just to handle queries
+ * like the first above, as they will probably be the most common.
+ *
+ * 2) Scripts such as:
+ *     B = group A by $0;
+ *     C = foreach B generate algebraic(A), nonalgebraic(A);
+ * currently aren't moved into the combiner, even though they could be.
+ * Again, the trick here is properly decomposing the plan since A may be more
+ * than a simply projection.
+ *
+ * #2 should probably be the next area of focus.
+ *
+ */
+public class CombinerOptimizer extends MROpPlanVisitor {
+
+    private Log log = LogFactory.getLog(getClass());
+
+    private enum ExprType { SIMPLE_PROJECT, ALGEBRAIC, NOT_ALGEBRAIC,
+        DISTINCT };
+
+    private int mKeyField = -1;
+
+    private byte mKeyType = 0;
+
+    public CombinerOptimizer(MROperPlan plan) {
+        super(plan, new DepthFirstWalker<MapReduceOper, MROperPlan>(plan));
+    }
+
+    @Override
+    public void visitMROp(MapReduceOper mr) throws VisitorException {
+        log.trace("Entering CombinerOptimizer.visitMROp");
+        if (mr.reducePlan.isEmpty()) return;
+
+        // Find the POLocalRearrange in the map.  I'll need it later.
+        List<PhysicalOperator> mapLeaves = mr.mapPlan.getLeaves();
+        if (mapLeaves == null || mapLeaves.size() != 1) {
+            log.warn("Expected map to have single leaf!");
+            return;
+        }
+        PhysicalOperator mapLeaf = mapLeaves.get(0);
+        if (!(mapLeaf instanceof POLocalRearrange)) {
+            return;
+        }
+        POLocalRearrange rearrange = (POLocalRearrange)mapLeaf;
+
+        List<PhysicalOperator> reduceRoots = mr.reducePlan.getRoots();
+        if (reduceRoots.size() != 1) {
+            log.warn("Expected reduce to have single leaf");
+            return;
+        }
+
+        // I expect that the first root should always be a POPackage.  If
+        // not, I don't know what's going on, so I'm out of here.
+        PhysicalOperator root = reduceRoots.get(0);
+        if (!(root instanceof POPackage)) {
+            log.warn("Expected reduce root to be a POPackage");
+            return;
+        }
+        POPackage pack = (POPackage)root;
+
+        List<PhysicalOperator> packSuccessors =
+            mr.reducePlan.getSuccessors(root);
+        if (packSuccessors == null || packSuccessors.size() != 1) return;
+        PhysicalOperator successor = packSuccessors.get(0);
+
+        // Need to check if this is a distinct.
+        if (successor instanceof POFilter) {
+            /*
+               Later
+            POFilter filter = (POFilter)successor;
+            PhysicalPlan filterInner = filter.getPlan();
+            if (onKeysOnly(filterInner)) {
+                // TODO move filter to combiner
+                // TODO Patch up projects of filter successor
+                // Call ourselves again, as we may be able to move the next
+                // operator too.
+                visitMROp(mr);
+            } else if (algebraic(filterInner)) {
+                // TODO Duplicate filter to combiner
+            }
+            */
+        } else if (successor instanceof POForEach) {
+            POForEach foreach = (POForEach)successor;
+            List<PhysicalPlan> feInners = foreach.getInputPlans();
+            List<ExprType> ap = algebraic(feInners, foreach.getToBeFlattened());
+            if (ap != null) {
+                log.info("Choosing to move algebraic foreach to combiner");
+
+                // Need to insert a foreach in the combine plan.  It will
+                // have one inner plan for each inner plan in the foreach
+                // we're duplicating.  For projections, the plan will be
+                // the same.  For algebraic udfs, the plan will have the
+                // initial version of the function.  The reduce plan will
+                // be changed to have the final version.
+                if (mr.combinePlan.getRoots().size() != 0) {
+                    log.warn("Wasn't expecting to find anything already "
+                        + "in the combiner!");
+                    return;
+                }
+                mr.combinePlan = new PhysicalPlan();
+                try {
+                    // If we haven't already found the key (and thus the
+                    // key type) we need to figure out the key type now.
+                    if (mKeyType == 0) {
+                        mKeyType = rearrange.getKeyType();
+                    }
+                    POPackage cp = pack.clone();
+                    mr.combinePlan.add(cp);
+                    POForEach cfe = foreach.clone();
+                    fixUpForeachs(cfe, foreach, ap);
+                    mr.combinePlan.add(cfe);
+                    mr.combinePlan.connect(cp, cfe);
+                    // No need to connect projections in cfe to cp, because
+                    // PigCombiner directly attaches output from package to
+                    // root of remaining plan.
+                    POLocalRearrange clr = rearrange.clone();
+                    fixUpRearrange(clr);
+                    mr.combinePlan.add(clr);
+                    mr.combinePlan.connect(cfe, clr);
+
+                    // Use the ExprType list returned from algebraic to tell
+                    // POPostCombinerPackage which fields need projected and
+                    // which placed in bags.
+                    int numFields = (mKeyField >= ap.size()) ? mKeyField + 1 :
+                        ap.size();
+                    boolean[] bags = new boolean[numFields];
+                    for (int i = 0; i < ap.size(); i++) {
+                        if (ap.get(i) == ExprType.SIMPLE_PROJECT) bags[i] = false;
+                        else bags[i] = true;
+                    }
+                    bags[mKeyField] = false;
+                    // Change the package operator in the reduce plan to
+                    // be the post combiner package, as it needs to act
+                    // differently than the regular package operator.
+                    POPostCombinerPackage newPack =
+                        new POPostCombinerPackage(pack, bags);
+                    mr.reducePlan.replace(pack, newPack);
+                } catch (Exception e) {
+                    throw new VisitorException(e);
+                }
+            }
+        }
+    }
+
+    /*
+    private boolean onKeysOnly(PhysicalPlan pp) {
+        // TODO
+        return false;
+    }
+    */
+
+    // At some point in the future we can expand to deconstructing
+    // non-algebraic expressions to find an algebraic or projected root.  For
+    // example, given a query: 
+    // foreach b generate group, algebraic(a), nonalgebraic(a)
+    // this could be transformed to:
+    // combiner: foreach group, initial(a), a
+    // reducer: foreach group, final(a), nonalgebraic(a)
+    // This code doesn't do this now, because deconstructing expressions is
+    // tricky.
+    private List<ExprType> algebraic(
+            List<PhysicalPlan> plans,
+            List<Boolean> flattens) throws VisitorException {
+        List<ExprType> types = new ArrayList<ExprType>(plans.size());
+        boolean atLeastOneAlgebraic = false;
+        boolean noNonAlgebraics = true;
+        for (int i = 0; i < plans.size(); i++) {
+            ExprType t = algebraic(plans.get(i), flattens.get(i), i);
+            types.add(t);
+            atLeastOneAlgebraic |= (t == ExprType.ALGEBRAIC);
+            noNonAlgebraics &= (t != ExprType.NOT_ALGEBRAIC);
+        }
+        if (!atLeastOneAlgebraic || !noNonAlgebraics) return null;
+        else return types;
+    }
+
+    private ExprType algebraic(
+            PhysicalPlan pp,
+            Boolean toBeFlattened,
+            int field) throws VisitorException {
+        // A plan will be considered algebraic if
+        // each element is a single field OR an algebraic UDF  
+        List<PhysicalOperator> leaves = pp.getLeaves();
+        if (leaves == null || leaves.size() != 1) {
+            // Don't know what this is, but it isn't algebraic
+            return ExprType.NOT_ALGEBRAIC;
+        }
+
+        // Check that it doesn't have anything in the nested plan that I
+        // can't make algebraic.  At this point this is just filters and
+        // foreach.  Filters are left out because they are not necessarily
+        // algebraic.  Foreach is left out because it's difficult to patch
+        // up the plan properly around them.  This is an area for future
+        // enhancement.
+        AlgebraicPlanChecker apc = new AlgebraicPlanChecker(pp);
+        apc.visit();
+        if (apc.sawNonAlgebraic) return ExprType.NOT_ALGEBRAIC;
+
+        PhysicalOperator leaf = leaves.get(0);
+        if (leaf instanceof POProject) {
+            POProject proj = (POProject)leaf;
+            // Check that it's a simple project.  We can't currently handle
+            // things like group.$0, because that requires resetting types on
+            // the reduce side.
+            if (pp.getPredecessors(proj) != null) return ExprType.NOT_ALGEBRAIC;
+
+            // Check to see if this is a projection of the grouping column.
+            // If so, it will be a projection of col 0 and will have no
+            // predecessors (to avoid things like group.$0, which isn't what we
+            // want).
+            List<Integer> cols = proj.getColumns();
+            if (cols != null && cols.size() == 1 && cols.get(0) == 0 &&
+                    pp.getPredecessors(proj) == null) {
+                mKeyField = field;
+                mKeyType = proj.getResultType();
+            } else {
+                // It can't be a flatten except on the grouping column
+                if (toBeFlattened) return ExprType.NOT_ALGEBRAIC;
+            }
+            return ExprType.SIMPLE_PROJECT;
+        } else if (leaf instanceof POUserFunc) {
+            return ((POUserFunc)leaf).combinable() ? ExprType.ALGEBRAIC :
+                ExprType.NOT_ALGEBRAIC;
+        } else {
+            return ExprType.NOT_ALGEBRAIC;
+        }
+    }
+
+    // Returns number of fields that this will project, including the added
+    // key field if that is necessary
+    private void fixUpForeachs(
+            POForEach cfe, // combiner foreach
+            POForEach rfe, // reducer foreach
+            List<ExprType> exprs) throws PlanException {
+        List<PhysicalPlan> cPlans = cfe.getInputPlans();
+        List<PhysicalPlan> rPlans = rfe.getInputPlans();
+        for (int i = 0; i < exprs.size(); i++) {
+            if (exprs.get(i) == ExprType.ALGEBRAIC) {
+                changeFunc(cfe, cPlans.get(i), POUserFunc.INITIAL);
+                changeFunc(rfe, rPlans.get(i), POUserFunc.FINAL);
+            }
+        }
+
+        // Set flattens for combiner ForEach to false
+        List<Boolean> cfeFlattens = new ArrayList<Boolean>(cPlans.size());
+        for (int i = 0; i < cPlans.size(); i++) {
+            cfeFlattens.add(false);
+        }
+        cfe.setToBeFlattened(cfeFlattens);
+
+        // If the key field isn't in the project of the combiner foreach, add
+        // it to the end.
+        if (mKeyField == -1) {
+            PhysicalPlan newPlan = new PhysicalPlan();
+            String scope = cfe.getOperatorKey().scope;
+            POProject proj = new POProject(new OperatorKey(scope, 
+                NodeIdGenerator.getGenerator().getNextNodeId(scope)), -1, 0);
+            proj.setResultType(mKeyType);
+            newPlan.add(proj);
+            cfe.addInputPlan(newPlan, false);
+            mKeyField = cPlans.size() - 1;
+        }
+
+        // Change the plans on the reduce foreach to project from the column
+        // they are in.  UDFs will be left the same but their
+        // inputs altered.  Any straight projections will also be altered.
+        for (int i = 0; i < rPlans.size(); i++) {
+            List<PhysicalOperator> leaves = rPlans.get(i).getLeaves();
+            if (leaves == null || leaves.size() != 1) {
+                throw new RuntimeException("Expected to find plan with single leaf!");
+            }
+            PhysicalOperator leaf = leaves.get(0);
+
+            // Leaf should be either a projection or a UDF
+            if (leaf instanceof POProject) {
+                ((POProject)leaf).setColumn(i);
+            } else if (leaf instanceof POUserFunc) {
+                String scope = leaf.getOperatorKey().scope;
+                POProject proj = new POProject(new OperatorKey(scope, 
+                    NodeIdGenerator.getGenerator().getNextNodeId(scope)),
+                    leaf.getRequestedParallelism(), i);
+                proj.setResultType(DataType.BAG);
+                // Remove old connections and elements from the plan
+                rPlans.get(i).trimAbove(leaf);
+                rPlans.get(i).add(proj);
+                rPlans.get(i).connect(proj, leaf);
+                List<PhysicalOperator> inputs =
+                    new ArrayList<PhysicalOperator>(1);
+                inputs.add(proj);
+                leaf.setInputs(inputs);
+            }
+        }
+    }
+
+    private void changeFunc(POForEach fe, PhysicalPlan plan, byte type) {
+        List<PhysicalOperator> leaves = plan.getLeaves();
+        if (leaves == null || leaves.size() != 1) {
+            throw new RuntimeException("Expected to find plan with single leaf!");
+        }
+
+        PhysicalOperator leaf = leaves.get(0);
+        if (!(leaf instanceof POUserFunc)) {
+            throw new RuntimeException("Expected to find plan with UDF leaf!");
+        }
+        POUserFunc func = (POUserFunc)leaf;
+        func.setAlgebraicFunction(type);
+    }
+
+    private void fixUpRearrange(POLocalRearrange rearrange) {
+        // Set the projection to be the key
+        PhysicalPlan newPlan = new PhysicalPlan();
+        String scope = rearrange.getOperatorKey().scope;
+        POProject proj = new POProject(new OperatorKey(scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(scope)), -1,
+            mKeyField);
+        proj.setResultType(mKeyType);
+        newPlan.add(proj);
+        List<PhysicalPlan> plans = new ArrayList<PhysicalPlan>(1);
+        plans.add(newPlan);
+        rearrange.setPlans(plans);
+        rearrange.setIndex(mKeyField);
+    }
+
+    private class AlgebraicPlanChecker extends PhyPlanVisitor {
+        boolean sawNonAlgebraic = false;
+
+        AlgebraicPlanChecker(PhysicalPlan plan) {
+            super(plan, new DepthFirstWalker<PhysicalOperator, PhysicalPlan>(plan));
+        }
+
+        @Override
+        public void visitDistinct(PODistinct distinct) throws VisitorException {
+            sawNonAlgebraic = true;
+        }
+
+        @Override
+        public void visitFilter(POFilter filter) throws VisitorException {
+            sawNonAlgebraic = true;
+        }
+
+        @Override
+        public void visitPOForEach(POForEach fe) throws VisitorException {
+            sawNonAlgebraic = true;
+        }
+
+        @Override
+        public void visitSort(POSort sort) throws VisitorException {
+            sawNonAlgebraic = true;
+        }
+
+    }
+
+}
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index 5a49f1ffd..db3bca83f 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -32,7 +32,6 @@ import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.io.BooleanWritable;
 import org.apache.hadoop.io.BytesWritable;
-import org.apache.pig.FuncSpec;
 import org.apache.hadoop.io.FloatWritable;
 import org.apache.hadoop.io.IntWritable;
 import org.apache.hadoop.io.LongWritable;
@@ -44,7 +43,9 @@ import org.apache.hadoop.mapred.JobConf;
 import org.apache.hadoop.mapred.jobcontrol.Job;
 import org.apache.hadoop.mapred.jobcontrol.JobControl;
 
+import org.apache.pig.FuncSpec;
 import org.apache.pig.backend.hadoop.HDataType;
+import org.apache.pig.backend.hadoop.DoubleWritable;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MROperPlan;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
@@ -331,13 +332,11 @@ public class JobControlCompiler{
         }
     }
 
-    /*
     public static class PigDoubleWritableComparator extends PigWritableComparator {
         public PigDoubleWritableComparator() {
-            super(Double.class);
+            super(DoubleWritable.class);
         }
     }
-    */
 
     public static class PigCharArrayWritableComparator extends PigWritableComparator {
         public PigCharArrayWritableComparator() {
@@ -396,9 +395,8 @@ public class JobControlCompiler{
                 break;
 
             case DataType.DOUBLE:
-                //jobConf.setOutputKeyComparatorClass(PigDoubleWritableComparator.class);
-                log.error("Waiting for Hadoop to support DoubleWritable");
-                throw new JobCreationException("Waiting for Hadoop to support DoubleWritable");
+                jobConf.setOutputKeyComparatorClass(PigDoubleWritableComparator.class);
+                break;
 
             case DataType.CHARARRAY:
                 jobConf.setOutputKeyComparatorClass(PigCharArrayWritableComparator.class);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java
index 73a091b27..9ec3174aa 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/LocalLauncher.java
@@ -12,8 +12,10 @@ import org.apache.hadoop.mapred.JobClient;
 import org.apache.hadoop.mapred.JobConf;
 import org.apache.hadoop.mapred.jobcontrol.Job;
 import org.apache.hadoop.mapred.jobcontrol.JobControl;
+
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.executionengine.ExecutionEngine;
+import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MROperPlan;
@@ -28,16 +30,14 @@ public class LocalLauncher extends Launcher{
     private static final Log log = LogFactory.getLog(LocalLauncher.class);
     
     @Override
-    public boolean launchPig(PhysicalPlan php,
-                             String grpName,
-                             PigContext pc) throws PlanException,
-                                                   VisitorException,
-                                                   IOException,
-                                                   ExecException,
-                                                   JobCreationException {
+    public boolean launchPig(
+            PhysicalPlan php,
+            String grpName,
+            PigContext pc) throws PlanException, VisitorException,
+                                  IOException, ExecException,
+                                  JobCreationException {
         long sleepTime = 500;
-        MRCompiler comp = new MRCompiler(php, pc);
-        comp.compile();
+        MROperPlan mrp = compile(php, pc);
         
         ExecutionEngine exe = pc.getExecutionEngine();
         Properties validatedProperties = ConfigurationValidator.getValidatedProperties(exe.getConfiguration());
@@ -45,7 +45,6 @@ public class LocalLauncher extends Launcher{
         conf.set("mapred.job.tracker", "local");
         JobClient jobClient = new JobClient(new JobConf(conf));
 
-        MROperPlan mrp = comp.getMRPlan();
         JobControlCompiler jcc = new JobControlCompiler();
         
         JobControl jc = jcc.compile(mrp, grpName, conf, pc);
@@ -89,19 +88,32 @@ public class LocalLauncher extends Launcher{
     }
 
     @Override
-    public void explain(PhysicalPlan php,
-                        PigContext pc,
-                        PrintStream ps) throws PlanException,
-                                               VisitorException,
-                                               IOException {
-        MRCompiler comp = new MRCompiler(php, pc);
-        comp.compile();
-        MROperPlan mrp = comp.getMRPlan();
+    public void explain(
+            PhysicalPlan php,
+            PigContext pc,
+            PrintStream ps) throws PlanException, VisitorException,
+                                   IOException {
+        log.trace("Entering LocalLauncher.explain");
+        MROperPlan mrp = compile(php, pc);
 
         MRPrinter printer = new MRPrinter(ps, mrp);
         printer.visit();
     }
  
+    private MROperPlan compile(
+            PhysicalPlan php,
+            PigContext pc) throws PlanException, IOException, VisitorException {
+        MRCompiler comp = new MRCompiler(php, pc);
+        comp.compile();
+        MROperPlan plan = comp.getMRPlan();
+        String prop = System.getProperty("pig.exec.nocombiner");
+        if (!("true".equals(prop)))  {
+            CombinerOptimizer co = new CombinerOptimizer(plan);
+            co.visit();
+        }
+        return plan;
+    }
+
     //A purely testing method. Not to be used elsewhere
     public boolean launchPigWithCombinePlan(PhysicalPlan php,
             String grpName, PigContext pc, PhysicalPlan combinePlan) throws PlanException,
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
index de0f40ccd..f5dda3776 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
@@ -771,6 +771,7 @@ public class MRCompiler extends PhyPlanVisitor {
             lr.setKeyType(DataType.TUPLE);
             lr.setPlans(eps);
             lr.setResultType(DataType.TUPLE);
+            lr.setDistinct(true);
             if(!mro.isMapDone()){
                 mro.mapPlan.addAsLeaf(lr);
             }
@@ -782,7 +783,7 @@ public class MRCompiler extends PhyPlanVisitor {
             
             POPackage pkg = new POPackage(new OperatorKey(scope,nig.getNextNodeId(scope)));
             pkg.setKeyType(DataType.TUPLE);
-            pkg.setNumInps(1);
+            pkg.setNumInps(0);
             boolean[] inner = {false}; 
             pkg.setInner(inner);
             curMROp.reducePlan.add(pkg);
@@ -797,7 +798,7 @@ public class MRCompiler extends PhyPlanVisitor {
             prj1.setOverloaded(false);
             ep1.add(prj1);
             eps1.add(ep1);
-            flat1.add(false);
+            flat1.add(true);
             POForEach nfe1 = new POForEach(new OperatorKey(scope, nig
                     .getNextNodeId(scope)), op.getRequestedParallelism(), eps1,
                     flat1);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
index e6ae8185f..84c3ed5e7 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MapReduceLauncher.java
@@ -1,3 +1,20 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
 package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;
 
 import java.io.IOException;
@@ -39,15 +56,13 @@ public class MapReduceLauncher extends Launcher{
                                                    ExecException,
                                                    JobCreationException {
         long sleepTime = 500;
-        MRCompiler comp = new MRCompiler(php, pc);
-        comp.compile();
+        MROperPlan mrp = compile(php, pc);
         
         ExecutionEngine exe = pc.getExecutionEngine();
         ConfigurationValidator.validatePigProperties(exe.getConfiguration());
         Configuration conf = ConfigurationUtil.toConfiguration(exe.getConfiguration());
         JobClient jobClient = ((HExecutionEngine)exe).getJobClient();
 
-        MROperPlan mrp = comp.getMRPlan();
         JobControlCompiler jcc = new JobControlCompiler();
         
         JobControl jc = jcc.compile(mrp, grpName, conf, pc);
@@ -90,17 +105,30 @@ public class MapReduceLauncher extends Launcher{
     }
 
     @Override
-    public void explain(PhysicalPlan php,
-                        PigContext pc,
-                        PrintStream ps) throws PlanException,
-                                               VisitorException,
-                                               IOException {
-        MRCompiler comp = new MRCompiler(php, pc);
-        comp.compile();
-        MROperPlan mrp = comp.getMRPlan();
+    public void explain(
+            PhysicalPlan php,
+            PigContext pc,
+            PrintStream ps) throws PlanException, VisitorException,
+                                   IOException {
+        log.trace("Entering MapReduceLauncher.explain");
+        MROperPlan mrp = compile(php, pc);
 
         MRPrinter printer = new MRPrinter(ps, mrp);
         printer.visit();
     }
+
+    private MROperPlan compile(
+            PhysicalPlan php,
+            PigContext pc) throws PlanException, IOException, VisitorException {
+        MRCompiler comp = new MRCompiler(php, pc);
+        comp.compile();
+        MROperPlan plan = comp.getMRPlan();
+        String prop = System.getProperty("pig.exec.nocombiner");
+        if (!("true".equals(prop)))  {
+            CombinerOptimizer co = new CombinerOptimizer(plan);
+            co.visit();
+        }
+        return plan;
+    }
  
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java
index 444455351..cd5c52ce4 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java
@@ -48,18 +48,18 @@ import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.util.ObjectSerializer;
 
 /**
- * This class is the static Mapper & Reducer classes that
+ * This class is the static Mapper &amp; Reducer classes that
  * are used by Pig to execute Pig Map Reduce jobs. Since
  * there is a reduce phase, the leaf is bound to be a 
  * POLocalRearrange. So the map phase has to separate the
  * key and indexed tuple and collect it into the output
  * collector.
  * 
- * The shuffle and sort phase sorts these key & indexed tuples
- * and creates key, List<IndexedTuple> and passes the key and
+ * The shuffle and sort phase sorts these key &amp; indexed tuples
+ * and creates key, List&lt;IndexedTuple&gt; and passes the key and
  * iterator to the list. The deserialized POPackage operator
- * is used to package the key, List<IndexedTuple> into pigKey, 
- * Bag<Tuple> where pigKey is of the appropriate pig type and
+ * is used to package the key, List&lt;IndexedTuple&gt; into pigKey, 
+ * Bag&lt;Tuple&gt; where pigKey is of the appropriate pig type and
  * then the result of the package is attached to the reduce
  * plan which is executed if its not empty. Either the result 
  * of the reduce plan or the package res is collected into
@@ -154,7 +154,6 @@ public class PigCombiner {
                         Result redRes = leaf.getNext(t);
                         
                         if(redRes.returnStatus==POStatus.STATUS_OK){
-//                            oc.collect(null, (Tuple)redRes.result);
                             Tuple tuple = (Tuple)redRes.result;
                             Object combKey = tuple.get(0);
                             IndexedTuple it = (IndexedTuple)tuple.get(1);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java
index ea96bcf2e..adc39dd1a 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/PhysicalOperator.java
@@ -20,6 +20,9 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer;
 import java.util.List;
 import java.util.Map;
 
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
@@ -53,10 +56,9 @@ import org.apache.pig.impl.plan.VisitorException;
  * only those types that are supported.
  *
  */
-public abstract class PhysicalOperator extends
-        Operator<PhyPlanVisitor> {
+public abstract class PhysicalOperator extends Operator<PhyPlanVisitor> implements Cloneable {
 
-//    private Log log = LogFactory.getLog(getClass());
+    private Log log = LogFactory.getLog(getClass());
 
     protected static final long serialVersionUID = 1L;
 
@@ -274,4 +276,22 @@ public abstract class PhysicalOperator extends
         PhysicalOperator.reporter = reporter;
     }
 
+    /**
+     * Make a deep copy of this operator.  This is declared here to make it
+     * public for all physical operators.  However, the default
+     * implementation is to throw an exception.  Operators we expect to clone
+     * need to implement this method.
+     * @throws CloneNotSupportedException
+     */
+    @Override
+    public PhysicalOperator clone() throws CloneNotSupportedException {
+        String s = new String("This physical operator does not " +
+            "implement clone.");
+        log.error(s);
+        throw new CloneNotSupportedException(s);
+    }
+
+    protected void cloneHelper(PhysicalOperator op) {
+        resultType = op.resultType;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Add.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Add.java
index e0abf1ee0..210c6df03 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Add.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Add.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class Add extends BinaryExpressionOperator {
@@ -141,6 +142,14 @@ public class Add extends BinaryExpressionOperator {
         res.result = new Long(left + right);
         return res;
     }
+
+    @Override
+    public Add clone() throws CloneNotSupportedException {
+        Add clone = new Add(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
     
 
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryComparisonOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryComparisonOperator.java
index 350102416..13339b5f4 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryComparisonOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryComparisonOperator.java
@@ -31,11 +31,6 @@ import org.apache.pig.impl.plan.OperatorKey;
  */
 public abstract class BinaryComparisonOperator extends BinaryExpressionOperator
         implements ComparisonOperator {
-    //The result type for comparison operators is always
-    //Boolean. So the plans evaluating these should consider
-    //the type of the operands instead of the result.
-    //The result will be comunicated using the Status object.
-    //This is a slight abuse of the status object.
     protected byte operandType;
 
     // Default instances of true and false, used so that all the equality
@@ -66,4 +61,9 @@ public abstract class BinaryComparisonOperator extends BinaryExpressionOperator
         trueRef = new Boolean(true);
         falseRef = new Boolean(false);
     }
+
+    protected void cloneHelper(BinaryComparisonOperator op) {
+        operandType = op.operandType;
+        super.cloneHelper(op);
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryExpressionOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryExpressionOperator.java
index af53d5331..fd098c6cf 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryExpressionOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/BinaryExpressionOperator.java
@@ -60,4 +60,12 @@ public abstract class BinaryExpressionOperator extends ExpressionOperator {
     public void setRhs(ExpressionOperator rhs) {
         this.rhs = rhs;
     }
+
+    protected void cloneHelper(BinaryExpressionOperator op) {
+        // Don't clone these, as they are just references to things already in
+        // the plan.
+        lhs = op.lhs;
+        rhs = op.rhs;
+        super.cloneHelper(op);
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ConstantExpression.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ConstantExpression.java
index 21416b160..0e8e5b954 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ConstantExpression.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ConstantExpression.java
@@ -20,14 +20,15 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 import java.util.Map;
 
 import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 
@@ -184,4 +185,14 @@ public class ConstantExpression extends ExpressionOperator {
         res.result = (Map)value;
         return res;
     }
+
+    @Override
+    public ConstantExpression clone() throws CloneNotSupportedException {
+        ConstantExpression clone =
+            new ConstantExpression(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.value = value;
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Divide.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Divide.java
index f8ebb2cf4..6ad5dd736 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Divide.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Divide.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class Divide extends BinaryExpressionOperator {
@@ -141,6 +142,14 @@ public class Divide extends BinaryExpressionOperator {
         res.result = new Long(left / right);
         return res;
     }
+
+    @Override
+    public Divide clone() throws CloneNotSupportedException {
+        Divide clone = new Divide(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
     
 
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/EqualToExpr.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/EqualToExpr.java
index 79c01a6e3..451e27fc3 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/EqualToExpr.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/EqualToExpr.java
@@ -19,14 +19,16 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.pig.data.DataByteArray;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
+
+import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.data.DataByteArray;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
-import org.apache.pig.backend.executionengine.ExecException;
 
 public class EqualToExpr extends BinaryComparisonOperator {
 
@@ -117,4 +119,12 @@ public class EqualToExpr extends BinaryComparisonOperator {
         }
         return left;
     }
+
+    @Override
+    public EqualToExpr clone() throws CloneNotSupportedException {
+        EqualToExpr clone = new EqualToExpr(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ExpressionOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ExpressionOperator.java
index b985e15a3..55cd7c2d6 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ExpressionOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/ExpressionOperator.java
@@ -18,6 +18,9 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.Tuple;
@@ -36,6 +39,7 @@ import org.apache.pig.impl.plan.VisitorException;
 
 public abstract class ExpressionOperator extends PhysicalOperator {
     private static final long serialVersionUID = 1L;
+    private Log log = LogFactory.getLog(getClass());
     
     public ExpressionOperator(OperatorKey k) {
         this(k,-1);
@@ -56,4 +60,19 @@ public abstract class ExpressionOperator extends PhysicalOperator {
     }
     
     public abstract void visit(PhyPlanVisitor v) throws VisitorException;
+
+    /**
+     * Make a deep copy of this operator.  This is declared here to make it
+     * possible to call clone on ExpressionOperators.
+     * @throws CloneNotSupportedException
+     */
+    @Override
+    public ExpressionOperator clone() throws CloneNotSupportedException {
+        String s = new String("This expression operator does not " +
+            "implement clone.");
+        log.error(s);
+        throw new CloneNotSupportedException(s);
+    }
+
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GTOrEqualToExpr.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GTOrEqualToExpr.java
index 660275984..3d3f065ef 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GTOrEqualToExpr.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GTOrEqualToExpr.java
@@ -19,14 +19,16 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.pig.data.DataByteArray;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
+
+import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.data.DataByteArray;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
-import org.apache.pig.backend.executionengine.ExecException;
 
 public class GTOrEqualToExpr extends BinaryComparisonOperator {
 
@@ -117,4 +119,12 @@ public class GTOrEqualToExpr extends BinaryComparisonOperator {
         }
         return left;
     }
+
+    @Override
+    public GTOrEqualToExpr clone() throws CloneNotSupportedException {
+        GTOrEqualToExpr clone = new GTOrEqualToExpr(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GreaterThanExpr.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GreaterThanExpr.java
index d75734c4b..3503fcdf3 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GreaterThanExpr.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/GreaterThanExpr.java
@@ -19,14 +19,16 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.pig.data.DataByteArray;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
+
+import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.data.DataByteArray;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
-import org.apache.pig.backend.executionengine.ExecException;
 
 public class GreaterThanExpr extends BinaryComparisonOperator {
 
@@ -117,4 +119,12 @@ public class GreaterThanExpr extends BinaryComparisonOperator {
         }
         return left;
     }
+
+    @Override
+    public GreaterThanExpr clone() throws CloneNotSupportedException {
+        GreaterThanExpr clone = new GreaterThanExpr(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LTOrEqualToExpr.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LTOrEqualToExpr.java
index f4ad9d82d..174cc3dca 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LTOrEqualToExpr.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LTOrEqualToExpr.java
@@ -19,14 +19,16 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.pig.data.DataByteArray;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
+
+import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.data.DataByteArray;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
-import org.apache.pig.backend.executionengine.ExecException;
 
 public class LTOrEqualToExpr extends BinaryComparisonOperator {
 
@@ -117,4 +119,12 @@ public class LTOrEqualToExpr extends BinaryComparisonOperator {
         }
         return left;
     }
+
+    @Override
+    public LTOrEqualToExpr clone() throws CloneNotSupportedException {
+        LTOrEqualToExpr clone = new LTOrEqualToExpr(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LessThanExpr.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LessThanExpr.java
index ecaa24847..ccb0960f5 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LessThanExpr.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/LessThanExpr.java
@@ -19,12 +19,14 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.pig.data.DataByteArray;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
+
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.data.DataByteArray;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.backend.executionengine.ExecException;
 
@@ -117,4 +119,12 @@ public class LessThanExpr extends BinaryComparisonOperator {
         }
         return left;
     }
+
+    @Override
+    public LessThanExpr clone() throws CloneNotSupportedException {
+        LessThanExpr clone = new LessThanExpr(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Mod.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Mod.java
index 387dc8204..055762eca 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Mod.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Mod.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class Mod extends BinaryExpressionOperator {
@@ -96,4 +97,12 @@ public class Mod extends BinaryExpressionOperator {
         return res;
     }
 
+    @Override
+    public Mod clone() throws CloneNotSupportedException {
+        Mod clone = new Mod(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Multiply.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Multiply.java
index b5e438822..aa7df9904 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Multiply.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Multiply.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class Multiply extends BinaryExpressionOperator {
@@ -141,6 +142,14 @@ public class Multiply extends BinaryExpressionOperator {
         res.result = new Long(left * right);
         return res;
     }
+
+    @Override
+    public Multiply clone() throws CloneNotSupportedException {
+        Multiply clone = new Multiply(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
     
     
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/NotEqualToExpr.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/NotEqualToExpr.java
index 6a66a870d..b696f8300 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/NotEqualToExpr.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/NotEqualToExpr.java
@@ -19,14 +19,16 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.pig.data.DataByteArray;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
+
+import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.data.DataByteArray;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
-import org.apache.pig.backend.executionengine.ExecException;
 
 public class NotEqualToExpr extends BinaryComparisonOperator {
 
@@ -117,4 +119,12 @@ public class NotEqualToExpr extends BinaryComparisonOperator {
         }
         return left;
     }
+
+    @Override
+    public NotEqualToExpr clone() throws CloneNotSupportedException {
+        NotEqualToExpr clone = new NotEqualToExpr(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POAnd.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POAnd.java
index 0e5fa7b36..dd79a808b 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POAnd.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POAnd.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 /**
@@ -69,4 +70,12 @@ public class POAnd extends BinaryComparisonOperator {
         // return, error, null, true, or false.
         return rhs.getNext(dummyBool);
     }
+
+    @Override
+    public POAnd clone() throws CloneNotSupportedException {
+        POAnd clone = new POAnd(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POBinCond.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POBinCond.java
index fc658be96..72ff5174a 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POBinCond.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POBinCond.java
@@ -20,14 +20,15 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 import java.util.Map;
 
 import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class POBinCond extends ExpressionOperator {
@@ -37,7 +38,6 @@ public class POBinCond extends ExpressionOperator {
     
     public POBinCond(OperatorKey k) {
         super(k);
-        // TODO Auto-generated constructor stub
     }
     
     public POBinCond(OperatorKey k, int rp) {
@@ -51,12 +51,6 @@ public class POBinCond extends ExpressionOperator {
         this.rhs = rhs;
     }
     
-    /*private Result getNext() throws ExecException {
-        
-        Result res = cond.processInput();
-        return ((Boolean)res.result) == true ? lhs.processInput() : rhs.processInput();
-    }*/
-
     @Override
     public Result getNext(Boolean b) throws ExecException {
         Result res = cond.getNext(b);
@@ -162,4 +156,15 @@ public class POBinCond extends ExpressionOperator {
         return true;
     }
 
+    @Override
+    public POBinCond clone() throws CloneNotSupportedException {
+        POBinCond clone = new POBinCond(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        clone.cond = cond.clone();
+        clone.lhs = lhs.clone();
+        clone.rhs = rhs.clone();
+        return clone;
+    }
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POCast.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POCast.java
index 937f5673f..e20574183 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POCast.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POCast.java
@@ -25,16 +25,17 @@ import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.pig.LoadFunc;
 import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.impl.plan.OperatorKey;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 /**
@@ -742,6 +743,16 @@ public class POCast extends ExpressionOperator {
         is.defaultReadObject();
         instantiateFunc();
     }
+
+    @Override
+    public POCast clone() throws CloneNotSupportedException {
+        POCast clone = new POCast(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        clone.loadFSpec = loadFSpec;
+        clone.instantiateFunc();
+        return clone;
+    }
     
 
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POIsNull.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POIsNull.java
index 4a5c641fb..89f036a86 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POIsNull.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POIsNull.java
@@ -20,15 +20,16 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 import java.util.Map;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
-import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
+import org.apache.pig.impl.plan.VisitorException;
 
 public class POIsNull extends UnaryComparisonOperator {
 
@@ -49,7 +50,7 @@ public class POIsNull extends UnaryComparisonOperator {
 
     @Override
     public void visit(PhyPlanVisitor v) throws VisitorException {
-        //v.visitIsNull(this);
+        v.visitIsNull(this);
     }
 
     @Override
@@ -187,4 +188,12 @@ public class POIsNull extends UnaryComparisonOperator {
         }
         return res;
     }
+
+    @Override
+    public POIsNull clone() throws CloneNotSupportedException {
+        POIsNull clone = new POIsNull(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POMapLookUp.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POMapLookUp.java
index ae0a87aa3..f800acf8e 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POMapLookUp.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POMapLookUp.java
@@ -20,14 +20,15 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 import java.util.Map;
 
 import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.plan.OperatorKey;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class POMapLookUp extends ExpressionOperator {
@@ -149,6 +150,14 @@ public class POMapLookUp extends ExpressionOperator {
 	public Result getNext(Tuple t) throws ExecException {
 		return getNext();
 	}
+
+    @Override
+    public POMapLookUp clone() throws CloneNotSupportedException {
+        POMapLookUp clone = new POMapLookUp(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)), -1, key);
+        clone.cloneHelper(this);
+        return clone;
+    }
 	
 	
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONegative.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONegative.java
index e15c76fe1..b6c74f0e1 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONegative.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONegative.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class PONegative extends UnaryExpressionOperator {
@@ -88,4 +89,12 @@ public class PONegative extends UnaryExpressionOperator {
         }
         return res;
     }
+
+    @Override
+    public PONegative clone() throws CloneNotSupportedException {
+        PONegative clone = new PONegative(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONot.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONot.java
index cadaa53fc..bbf4ef168 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONot.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PONot.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 /**
@@ -74,4 +75,12 @@ public class PONot extends UnaryComparisonOperator {
         if (((Boolean)res.result).booleanValue()) return falseRes;
         else return trueRes;
     }
+
+    @Override
+    public PONot clone() throws CloneNotSupportedException {
+        PONot clone = new PONot(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POOr.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POOr.java
index 7719c9ea2..5cb34d444 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POOr.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POOr.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 /**
@@ -69,4 +70,12 @@ public class POOr extends BinaryComparisonOperator {
         // return, error, null, true, or false.
         return rhs.getNext(dummyBool);
     }
+
+    @Override
+    public POOr clone() throws CloneNotSupportedException {
+        POOr clone = new POOr(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java
index 1e3e268f6..de87fd2ae 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POProject.java
@@ -32,6 +32,8 @@ import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.data.Tuple;
@@ -316,6 +318,22 @@ public class POProject extends ExpressionOperator {
     public void setStar(boolean star) {
         this.star = star;
     }
+
+    @Override
+    public POProject clone() throws CloneNotSupportedException {
+        ArrayList<Integer> cols = new ArrayList<Integer>(columns.size());
+        // Can resuse the same Integer objects, as they are immutable
+        for (Integer i : columns) {
+            cols.add(i);
+        }
+        POProject clone = new POProject(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
+            requestedParallelism, cols);
+        clone.cloneHelper(this);
+        clone.star = star;
+        clone.overloaded = overloaded;
+        return clone;
+    }
     
     private Result processInputBag() throws ExecException {
         
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PORegexp.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PORegexp.java
index 8174f03bf..3c5ed5e1c 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PORegexp.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/PORegexp.java
@@ -20,11 +20,12 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOp
 import java.util.regex.PatternSyntaxException;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class PORegexp extends BinaryComparisonOperator {
@@ -71,4 +72,12 @@ public class PORegexp extends BinaryComparisonOperator {
         }
         return left;
     }
+
+    @Override
+    public PORegexp clone() throws CloneNotSupportedException {
+        PORegexp clone = new PORegexp(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserComparisonFunc.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserComparisonFunc.java
index 61a21f2ce..33295e20a 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserComparisonFunc.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserComparisonFunc.java
@@ -10,16 +10,17 @@ import org.apache.commons.logging.LogFactory;
 import org.apache.pig.ComparisonFunc;
 import org.apache.pig.FuncSpec;
 import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 
 public class POUserComparisonFunc extends ExpressionOperator {
 
@@ -150,4 +151,18 @@ public class POUserComparisonFunc extends ExpressionOperator {
         return funcSpec;
     }
 
+    @Override
+    public POUserComparisonFunc clone() throws CloneNotSupportedException {
+        FuncSpec cloneFs = null;
+        if (funcSpec != null) {
+            cloneFs = funcSpec.clone();
+        }
+        POUserComparisonFunc clone =
+            new POUserComparisonFunc(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
+            requestedParallelism, null, cloneFs);
+        clone.cloneHelper(this);
+        return clone;
+    }
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java
index 4d31187ce..ab5205ab1 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/POUserFunc.java
@@ -42,6 +42,8 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class POUserFunc extends ExpressionOperator {
@@ -59,18 +61,26 @@ public class POUserFunc extends ExpressionOperator {
 	public static final byte INTERMEDIATE = 1;
 	public static final byte FINAL = 2;
 
-	public POUserFunc(OperatorKey k, int rp, List inp) {
+	public POUserFunc(OperatorKey k, int rp, List<PhysicalOperator> inp) {
 		super(k, rp);
 		inputs = inp;
 
 	}
 
-	public POUserFunc(OperatorKey k, int rp, List inp, FuncSpec funcSpec) {
+	public POUserFunc(
+            OperatorKey k,
+            int rp,
+            List<PhysicalOperator> inp,
+            FuncSpec funcSpec) {
 		this(k, rp, inp, funcSpec, null);
 	}
 	
-	public POUserFunc(OperatorKey k, int rp, List inp, FuncSpec funcSpec, EvalFunc func) {
-//		super(k, rp, inp);
+	public POUserFunc(
+            OperatorKey k,
+            int rp,
+            List<PhysicalOperator> inp,
+            FuncSpec funcSpec,
+            EvalFunc func) {
         super(k, rp);
         super.setInputs(inp);
 		this.funcSpec = funcSpec;
@@ -170,7 +180,8 @@ public class POUserFunc extends ExpressionOperator {
 			return result;
 			
 		} catch (IOException e1) {
-			log.error(e1);
+			log.error("Caught error from UDF " + funcSpec.getClassName() + 
+                "[" + e1.getMessage() + "]");
 		}
 		
 		
@@ -235,7 +246,7 @@ public class POUserFunc extends ExpressionOperator {
 		return getNext();
 	}
 
-	public void setAlgebraicFunction(Byte Function) {
+	public void setAlgebraicFunction(byte Function) {
 		// This will only be used by the optimizer for putting correct functions
 		// in the mapper,
 		// combiner and reduce. This helps in maintaining the physical plan as
@@ -265,10 +276,11 @@ public class POUserFunc extends ExpressionOperator {
 		if (func instanceof Algebraic) {
 			return ((Algebraic) func).getInitial();
 		} else {
-			log
-					.error("Attempt to run a non-algebraic function as an algebraic function");
+			String msg = new String("Attempt to run a non-algebraic function"
+                + " as an algebraic function");
+            log.error(msg);
+            throw new RuntimeException(msg);
 		}
-		return null;
 	}
 
 	public String getIntermed() {
@@ -276,10 +288,11 @@ public class POUserFunc extends ExpressionOperator {
 		if (func instanceof Algebraic) {
 			return ((Algebraic) func).getIntermed();
 		} else {
-			log
-					.error("Attempt to run a non-algebraic function as an algebraic function");
+			String msg = new String("Attempt to run a non-algebraic function"
+                + " as an algebraic function");
+            log.error(msg);
+            throw new RuntimeException(msg);
 		}
-		return null;
 	}
 
 	public String getFinal() {
@@ -287,10 +300,11 @@ public class POUserFunc extends ExpressionOperator {
 		if (func instanceof Algebraic) {
 			return ((Algebraic) func).getFinal();
 		} else {
-			log
-					.error("Attempt to run a non-algebraic function as an algebraic function");
+			String msg = new String("Attempt to run a non-algebraic function"
+                + " as an algebraic function");
+            log.error(msg);
+            throw new RuntimeException(msg);
 		}
-		return null;
 	}
 
 	public Type getReturnType() {
@@ -335,6 +349,20 @@ public class POUserFunc extends ExpressionOperator {
     public FuncSpec getFuncSpec() {
         return funcSpec;
     }
+
+    public boolean combinable() {
+        return (func instanceof Algebraic);
+    }
+
+    @Override
+    public POUserFunc clone() throws CloneNotSupportedException {
+        // Inputs will be patched up later by PhysicalPlan.clone()
+        POUserFunc clone = new POUserFunc(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
+            requestedParallelism, null, funcSpec.clone());
+        clone.setResultType(resultType);
+        return clone;
+    }
     
     private void readObject(ObjectInputStream is) throws IOException, ClassNotFoundException{
         is.defaultReadObject();
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Subtract.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Subtract.java
index e629fc594..53d2fe721 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Subtract.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/Subtract.java
@@ -18,11 +18,12 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators;
 
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.DataType;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.DataType;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class Subtract extends BinaryExpressionOperator {
@@ -142,4 +143,12 @@ public class Subtract extends BinaryExpressionOperator {
         return res;
     }
 
+    @Override
+    public Subtract clone() throws CloneNotSupportedException {
+        Subtract clone = new Subtract(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.cloneHelper(this);
+        return clone;
+    }
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryExpressionOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryExpressionOperator.java
index 94a76a814..6b6966335 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryExpressionOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/expressionOperators/UnaryExpressionOperator.java
@@ -65,4 +65,12 @@ public abstract class UnaryExpressionOperator extends ExpressionOperator {
     public ExpressionOperator getExpr() { 
         return expr;
     }
+
+    protected void cloneHelper(UnaryExpressionOperator op) {
+        // Don't clone this, as it is just a reference to something already in
+        // the plan.
+        expr = op.expr;
+        resultType = op.getResultType();
+    }
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhyPlanVisitor.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhyPlanVisitor.java
index 128ce87a9..496806acb 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhyPlanVisitor.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhyPlanVisitor.java
@@ -20,42 +20,8 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans;
 import java.util.List;
 
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Add;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.ConstantExpression;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Divide;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.EqualToExpr;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.GTOrEqualToExpr;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.GreaterThanExpr;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.LTOrEqualToExpr;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.LessThanExpr;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Mod;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Multiply;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.NotEqualToExpr;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POAnd;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POBinCond;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POMapLookUp;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.PONegative;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.PONot;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POOr;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.PORegexp;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserComparisonFunc;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Subtract;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PODistinct;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POFilter;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POGlobalRearrange;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLimit;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.PORead;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSplit;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStore;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POUnion;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.*;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.*;
 import org.apache.pig.impl.plan.PlanVisitor;
 import org.apache.pig.impl.plan.PlanWalker;
 import org.apache.pig.impl.plan.VisitorException;
@@ -99,7 +65,7 @@ public class PhyPlanVisitor extends PlanVisitor<PhysicalOperator,PhysicalPlan> {
             visit();
         }
     }
-    
+
     public void visitGlobalRearrange(POGlobalRearrange gr) throws VisitorException{
         //do nothing
     }
@@ -176,6 +142,9 @@ public class PhyPlanVisitor extends PlanVisitor<PhysicalOperator,PhysicalPlan> {
     public void visitRegexp(PORegexp re) throws VisitorException{
         //do nothing
     }
+
+    public void visitIsNull(POIsNull isNull) throws VisitorException {
+    }
     
     public void visitAdd(Add add) throws VisitorException{
         //do nothing
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhysicalPlan.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhysicalPlan.java
index 64dabe2c4..791f67df9 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhysicalPlan.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/plans/PhysicalPlan.java
@@ -20,7 +20,11 @@ package org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.OutputStream;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
 import java.util.List;
+import java.util.Map;
 
 import org.apache.pig.data.Tuple;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
@@ -34,7 +38,7 @@ import org.apache.pig.impl.plan.VisitorException;
  * This extends the Operator Plan.
  *
  */
-public class PhysicalPlan extends OperatorPlan<PhysicalOperator> {
+public class PhysicalPlan extends OperatorPlan<PhysicalOperator> implements Cloneable {
 
     /**
      * 
@@ -117,6 +121,77 @@ public class PhysicalPlan extends OperatorPlan<PhysicalOperator> {
         // TODO Auto-generated method stub
         return super.equals(obj);
     }
+
+    @Override
+    public PhysicalPlan clone() throws CloneNotSupportedException {
+        PhysicalPlan clone = new PhysicalPlan();
+
+        // Get all the nodes in this plan, and clone them.  As we make
+        // clones, create a map between clone and original.  Then walk the
+        // connections in this plan and create equivalent connections in the
+        // clone.
+        Map<PhysicalOperator, PhysicalOperator> matches = 
+            new HashMap<PhysicalOperator, PhysicalOperator>(mOps.size());
+        for (PhysicalOperator op : mOps.keySet()) {
+            PhysicalOperator c = op.clone();
+            clone.add(c);
+            matches.put(op, c);
+        }
+
+        // Build the edges
+        for (PhysicalOperator op : mFromEdges.keySet()) {
+            PhysicalOperator cloneFrom = matches.get(op);
+            if (cloneFrom == null) {
+                String msg = new String("Unable to find clone for op "
+                    + op.name());
+                log.error(msg);
+                throw new RuntimeException(msg);
+            }
+            Collection<PhysicalOperator> toOps = mFromEdges.get(op);
+            for (PhysicalOperator toOp : toOps) {
+                PhysicalOperator cloneTo = matches.get(toOp);
+                if (cloneTo == null) {
+                    String msg = new String("Unable to find clone for op "
+                        + toOp.name());
+                    log.error(msg);
+                    throw new RuntimeException(msg);
+                }
+                try {
+                    clone.connect(cloneFrom, cloneTo);
+                } catch (PlanException pe) {
+                    throw new RuntimeException(pe);
+                }
+            }
+        }
+
+        // Fix up all the inputs in the operators themselves.
+        for (PhysicalOperator op : mOps.keySet()) {
+            List<PhysicalOperator> inputs = op.getInputs();
+            if (inputs == null || inputs.size() == 0) continue;
+            List<PhysicalOperator> newInputs = 
+                new ArrayList<PhysicalOperator>(inputs.size());
+            PhysicalOperator cloneOp = matches.get(op);
+            if (cloneOp == null) {
+                String msg = new String("Unable to find clone for op "
+                    + cloneOp.name());
+                log.error(msg);
+                throw new RuntimeException(msg);
+            }
+            for (PhysicalOperator iOp : inputs) {
+                PhysicalOperator cloneIOp = matches.get(iOp);
+                if (cloneIOp == null) {
+                    String msg = new String("Unable to find clone for op "
+                        + cloneIOp.name());
+                    log.error(msg);
+                    throw new RuntimeException(msg);
+                }
+                newInputs.add(cloneIOp);
+            }
+            cloneOp.setInputs(newInputs);
+        }
+
+        return clone;
+    }
     
     
     
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
index 4485faf1f..df42ba567 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/PODistinct.java
@@ -24,18 +24,19 @@ import java.util.List;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.plan.OperatorKey;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
-import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.impl.plan.VisitorException;
 
 /**
+ * Find the distinct set of tuples in a bag.
  * This is a blocking operator. All the input is put in the hashset implemented
  * in DistinctDataBag which also provides the other DataBag interfaces.
  * 
@@ -50,27 +51,22 @@ public class PODistinct extends PhysicalOperator {
 
     public PODistinct(OperatorKey k, int rp, List<PhysicalOperator> inp) {
         super(k, rp, inp);
-        // TODO Auto-generated constructor stub
     }
 
     public PODistinct(OperatorKey k, int rp) {
         super(k, rp);
-        // TODO Auto-generated constructor stub
     }
 
     public PODistinct(OperatorKey k, List<PhysicalOperator> inp) {
         super(k, inp);
-        // TODO Auto-generated constructor stub
     }
 
     public PODistinct(OperatorKey k) {
         super(k);
-        // TODO Auto-generated constructor stub
     }
 
     @Override
     public boolean isBlocking() {
-        // TODO Auto-generated method stub
         return true;
     }
 
@@ -111,25 +107,21 @@ public class PODistinct extends PhysicalOperator {
 
     @Override
     public String name() {
-        // TODO Auto-generated method stub
         return "PODistinct" + "[" + DataType.findTypeName(resultType) + "]" +" - " + mKey.toString();
     }
 
     @Override
     public boolean supportsMultipleInputs() {
-        // TODO Auto-generated method stub
         return false;
     }
 
     @Override
     public boolean supportsMultipleOutputs() {
-        // TODO Auto-generated method stub
         return false;
     }
 
     @Override
     public void visit(PhyPlanVisitor v) throws VisitorException {
-        // TODO Auto-generated method stub
         v.visitDistinct(this);
     }
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java
index 37f9d52d8..62205a955 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POForEach.java
@@ -1,5 +1,6 @@
 package org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators;
 
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
@@ -19,6 +20,7 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 public class POForEach extends PhysicalOperator {
@@ -308,7 +310,7 @@ public class POForEach extends PhysicalOperator {
         for(int i = 0; i < data.length; ++i) {
             Object in = data[i];
             
-            if(in instanceof Tuple) {
+            if(isToBeFlattened.get(i) && in instanceof Tuple) {
                 Tuple t = (Tuple)in;
                 for(int j = 0; j < t.size(); ++j) {
                     out.append(t.get(j));
@@ -345,9 +347,42 @@ public class POForEach extends PhysicalOperator {
         getLeaves();
     }
 
+    public void addInputPlan(PhysicalPlan plan, boolean flatten) {
+        inputPlans.add(plan);
+        planLeaves.add(plan.getLeaves().get(0));
+        isToBeFlattened.add(flatten);
+    }
+
     public void setToBeFlattened(List<Boolean> flattens) {
         isToBeFlattened = flattens;
     }
 
+    public List<Boolean> getToBeFlattened() {
+        return isToBeFlattened;
+    }
+
+    /**
+     * Make a deep copy of this operator.  
+     * @throws CloneNotSupportedException
+     */
+    @Override
+    public POForEach clone() throws CloneNotSupportedException {
+        List<PhysicalPlan> plans = new
+            ArrayList<PhysicalPlan>(inputPlans.size());
+        for (PhysicalPlan plan : inputPlans) {
+            plans.add(plan.clone());
+        }
+        List<Boolean> flattens = new
+            ArrayList<Boolean>(isToBeFlattened.size());
+        for (Boolean b : isToBeFlattened) {
+            // Boolean is immutable, so using same reference is ok
+            flattens.add(b);
+        }
+        return new POForEach(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
+            requestedParallelism, plans, flattens);
+    }
+
+
 
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java
index f1bad7d1c..ffee196c7 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POLocalRearrange.java
@@ -34,6 +34,7 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOpe
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 /**
@@ -49,6 +50,8 @@ public class POLocalRearrange extends PhysicalOperator {
      */
     private static final long serialVersionUID = 1L;
 
+    private static TupleFactory mTupleFactory = TupleFactory.getInstance();
+
     private Log log = LogFactory.getLog(getClass());
 
     List<PhysicalPlan> plans;
@@ -60,6 +63,15 @@ public class POLocalRearrange extends PhysicalOperator {
     
     byte keyType;
 
+    private boolean mIsDistinct = false;
+
+    // A place holder IndexedTuple used in distinct case where we really don't
+    // have any value to pass through.  But hadoop gets cranky if we pass a
+    // null, so we'll just create one instance of this empty indexed tuple and
+    // pass it for every row.  We only get around to actually creating it if
+    // mIsDistinct is set to true.
+    private IndexedTuple mFakeIndexedTuple = null;
+
     public POLocalRearrange(OperatorKey k) {
         this(k, -1, null);
     }
@@ -85,7 +97,9 @@ public class POLocalRearrange extends PhysicalOperator {
 
     @Override
     public String name() {
-        return "Local Rearrange" + "[" + DataType.findTypeName(resultType) + "]" + "{" + DataType.findTypeName(keyType) + "}" +" - " + mKey.toString();
+        return "Local Rearrange" + "[" + DataType.findTypeName(resultType) +
+            "]" + "{" + DataType.findTypeName(keyType) + "}" + "(" +
+            mIsDistinct + ") - " + mKey.toString();
     }
 
     @Override
@@ -105,6 +119,17 @@ public class POLocalRearrange extends PhysicalOperator {
     public void setIndex(int index) {
         this.index = index;
     }
+
+    public boolean isDistinct() { 
+        return mIsDistinct;
+    }
+
+    public void setDistinct(boolean isDistinct) {
+        mIsDistinct = isDistinct;
+        if (mIsDistinct) {
+            mFakeIndexedTuple = new IndexedTuple(mTupleFactory.newTuple(), 0);
+        }
+    }
     
     /**
      * Overridden since the attachment of the new input should cause the old
@@ -184,7 +209,7 @@ public class POLocalRearrange extends PhysicalOperator {
         //Construct key
         Object key;
         if(resLst.size()>1){
-            Tuple t = TupleFactory.getInstance().newTuple(resLst.size());
+            Tuple t = mTupleFactory.newTuple(resLst.size());
             int i=-1;
             for(Result res : resLst)
                 t.set(++i, res.result);
@@ -194,16 +219,25 @@ public class POLocalRearrange extends PhysicalOperator {
             key = resLst.get(0).result;
         }
         
-        //Create the indexed tuple out of the value
-        //that is remaining in the input tuple
-        IndexedTuple it = new IndexedTuple(value, index);
-        
-        //Put the key and the indexed tuple
-        //in a tuple and return
-        Tuple outPut = TupleFactory.getInstance().newTuple(2);
-        outPut.set(0,key);
-        outPut.set(1,it);
-        return outPut;
+        Tuple outPut = mTupleFactory.newTuple(2);
+        if (mIsDistinct) {
+
+            //Put the key and the indexed tuple
+            //in a tuple and return
+            outPut.set(0,key);
+            outPut.set(1, mFakeIndexedTuple);
+            return outPut;
+        } else {
+            //Create the indexed tuple out of the value
+            //that is remaining in the input tuple
+            IndexedTuple it = new IndexedTuple(value, index);
+
+            //Put the key and the indexed tuple
+            //in a tuple and return
+            outPut.set(0,key);
+            outPut.set(1,it);
+            return outPut;
+        }
     }
 
     public byte getKeyType() {
@@ -225,4 +259,30 @@ public class POLocalRearrange extends PhysicalOperator {
             leafOps.add((ExpressionOperator)plan.getLeaves().get(0));
         }
     }
+
+    /**
+     * Make a deep copy of this operator.  
+     * @throws CloneNotSupportedException
+     */
+    @Override
+    public POLocalRearrange clone() throws CloneNotSupportedException {
+        List<PhysicalPlan> clonePlans = new
+            ArrayList<PhysicalPlan>(plans.size());
+        for (PhysicalPlan plan : plans) {
+            clonePlans.add(plan.clone());
+        }
+        POLocalRearrange clone = new POLocalRearrange(new OperatorKey(
+            mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
+            requestedParallelism);
+        clone.setPlans(clonePlans);
+        clone.keyType = keyType;
+        clone.index = index;
+        // Needs to be called as setDistinct so that the fake index tuple gets
+        // created.
+        clone.setDistinct(mIsDistinct);
+        return clone;
+    }
+
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
index e44e7ab7c..6485bf97e 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPackage.java
@@ -30,6 +30,7 @@ import org.apache.pig.data.IndexedTuple;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
@@ -66,7 +67,8 @@ public class POPackage extends PhysicalOperator {
     byte keyType;
 
     //The number of inputs to this
-    //co-group
+    //co-group.  0 indicates a distinct, which means there will only be a
+    //key, no value.
     int numInputs;
     
     //Denotes if inner is specified
@@ -75,6 +77,9 @@ public class POPackage extends PhysicalOperator {
     
     private final Log log = LogFactory.getLog(getClass());
 
+    protected static BagFactory mBagFactory = BagFactory.getInstance();
+    protected static TupleFactory mTupleFactory = TupleFactory.getInstance();
+
     public POPackage(OperatorKey k) {
         this(k, -1, null);
     }
@@ -154,16 +159,13 @@ public class POPackage extends PhysicalOperator {
      */
     @Override
     public Result getNext(Tuple t) throws ExecException {
-        //Should be removed once we start integration/perf testing
-        if(indTupIter==null){
-            throw new ExecException("Incorrect usage of the Package operator. " +
-                    "No input has been attached.");
-        }
-        
         //Create numInputs bags
-        DataBag[] dbs = new DataBag[numInputs];
-        for (int i = 0; i < numInputs; i++) {
-            dbs[i] = BagFactory.getInstance().newDefaultBag();
+        DataBag[] dbs = null;
+        if (numInputs > 0) {
+            dbs = new DataBag[numInputs];
+            for (int i = 0; i < numInputs; i++) {
+                dbs[i] = mBagFactory.newDefaultBag();
+            }
         }
         
         //For each indexed tup in the inp, sort them
@@ -171,7 +173,7 @@ public class POPackage extends PhysicalOperator {
         //on the index
         while (indTupIter.hasNext()) {
             IndexedTuple it = indTupIter.next();
-            dbs[it.index].add(it.toTuple());
+            if (numInputs > 0) dbs[it.index].add(it.toTuple());
             if(reporter!=null) reporter.progress();
         }
         
@@ -179,19 +181,21 @@ public class POPackage extends PhysicalOperator {
         //the key and all the above constructed bags
         //and return it.
         Tuple res;
-        res = TupleFactory.getInstance().newTuple(numInputs+1);
+        res = mTupleFactory.newTuple(numInputs+1);
         res.set(0,key);
-        int i=-1;
-        for (DataBag bag : dbs) {
-            if(inner[++i]){
-                if(bag.size()==0){
-                    detachInput();
-                    Result r = new Result();
-                    r.returnStatus = POStatus.STATUS_NULL;
-                    return r;
+        if (numInputs > 0) {
+            int i=-1;
+            for (DataBag bag : dbs) {
+                if(inner[++i]){
+                    if(bag.size()==0){
+                        detachInput();
+                        Result r = new Result();
+                        r.returnStatus = POStatus.STATUS_NULL;
+                        return r;
+                    }
                 }
+                res.set(i+1,bag);
             }
-            res.set(i+1,bag);
         }
         detachInput();
         Result r = new Result();
@@ -207,4 +211,24 @@ public class POPackage extends PhysicalOperator {
     public void setKeyType(byte keyType) {
         this.keyType = keyType;
     }
+
+    /**
+     * Make a deep copy of this operator.  
+     * @throws CloneNotSupportedException
+     */
+    @Override
+    public POPackage clone() throws CloneNotSupportedException {
+        POPackage clone = new POPackage(new OperatorKey(mKey.scope,
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)));
+        clone.resultType = resultType;
+        clone.keyType = keyType;
+        clone.numInputs = numInputs;
+        clone.inner = new boolean[inner.length];
+        for (int i = 0; i < inner.length; i++) {
+            clone.inner[i] = inner[i];
+        }
+        return clone;
+    }
+
+
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPostCombinerPackage.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPostCombinerPackage.java
new file mode 100644
index 000000000..6b42b4650
--- /dev/null
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POPostCombinerPackage.java
@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators;
+
+import java.util.Iterator;
+import java.util.List;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlanVisitor;
+import org.apache.pig.data.BagFactory;
+import org.apache.pig.data.DataBag;
+import org.apache.pig.data.DataType;
+import org.apache.pig.data.IndexedTuple;
+import org.apache.pig.data.Tuple;
+import org.apache.pig.data.TupleFactory;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
+import org.apache.pig.impl.plan.VisitorException;
+/**
+ * The package operator that packages the globally rearranged tuples into
+ * output format after the combiner stage.  It differs from POPackage in that
+ * instead of using the index in the IndexedTuple to find the bag to put a
+ * tuple in, it instead uses the index to find the key.  All other inputs are
+ * put in a bag corresponding to their offset in the tuple.
+ */
+public class POPostCombinerPackage extends POPackage {
+    /**
+     * 
+     */
+    private static final long serialVersionUID = 1L;
+
+    private final Log log = LogFactory.getLog(getClass());
+
+    private static BagFactory mBagFactory = BagFactory.getInstance();
+    private static TupleFactory mTupleFactory = TupleFactory.getInstance();
+
+    private boolean[] mBags; // For each field, indicates whether or not it
+                             // needs to be put in a bag.
+
+    /**
+     * A new POPostCombinePackage will be constructed as a near clone of the
+     * provided POPackage.
+     * @param pkg POPackage to clone.
+     * @param numFields Number of fields in each input tuple
+     */
+    public POPostCombinerPackage(POPackage pkg, boolean[] bags) {
+        super(new OperatorKey(pkg.getOperatorKey().scope,
+            NodeIdGenerator.getGenerator().getNextNodeId(pkg.getOperatorKey().scope)),
+            pkg.getRequestedParallelism(), pkg.getInputs());
+        resultType = pkg.getResultType();
+        keyType = pkg.keyType;
+        numInputs = 1;
+        inner = new boolean[1];
+        for (int i = 0; i < pkg.inner.length; i++) {
+            inner[i] = true;
+        }
+        mBags = bags;
+    }
+
+    @Override
+    public String name() {
+        return "PostCombinerPackage" + "[" + DataType.findTypeName(resultType) + "]" + "{" + DataType.findTypeName(keyType) + "}" +" - " + mKey.toString();
+    }
+
+    /**
+     * From the inputs, constructs the output tuple
+     * for this co-group in the required format which
+     * is (key, {bag of tuples from input 1}, {bag of tuples from input 2}, ...)
+     */
+    @Override
+    public Result getNext(Tuple t) throws ExecException {
+        int keyField = -1;
+        //Create numInputs bags
+        Object[] fields = new Object[mBags.length];
+        for (int i = 0; i < mBags.length; i++) {
+            if (mBags[i]) fields[i] = mBagFactory.newDefaultBag();
+        }
+        
+        // For each indexed tup in the inp, split them up and place their
+        // fields into the proper bags.  If the given field isn't a bag, just
+        // return set the value as is.
+        while (indTupIter.hasNext()) {
+            IndexedTuple it = indTupIter.next();
+            Tuple tup = it.toTuple();
+            for (int i = 0; i < tup.size(); i++) {
+                if (mBags[i]) ((DataBag)fields[i]).add((Tuple)tup.get(i));
+                else fields[i] = tup.get(i);
+            }
+        }
+        
+        //Construct the output tuple by appending
+        //the key and all the above constructed bags
+        //and return it.
+        Tuple res;
+        res = mTupleFactory.newTuple(mBags.length);
+        for (int i = 0; i < mBags.length; i++) res.set(i, fields[i]);
+        Result r = new Result();
+        r.result = res;
+        r.returnStatus = POStatus.STATUS_OK;
+        return r;
+
+    }
+
+}
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
index 0d6cf2960..049978a56 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POSort.java
@@ -26,12 +26,6 @@ import java.util.List;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.pig.backend.executionengine.ExecException;
-import org.apache.pig.data.BagFactory;
-import org.apache.pig.data.DataBag;
-import org.apache.pig.data.DataType;
-import org.apache.pig.data.Tuple;
-import org.apache.pig.data.TupleFactory;
-import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.Result;
@@ -40,6 +34,13 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhyPlan
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.ExpressionOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserComparisonFunc;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc;
+import org.apache.pig.data.BagFactory;
+import org.apache.pig.data.DataBag;
+import org.apache.pig.data.DataType;
+import org.apache.pig.data.Tuple;
+import org.apache.pig.data.TupleFactory;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.VisitorException;
 
 /**
@@ -74,8 +75,13 @@ public class POSort extends PhysicalOperator {
 	private DataBag sortedBag;
 	transient Iterator<Tuple> it;
 
-	public POSort(OperatorKey k, int rp, List inp, List<PhysicalPlan> sortPlans,
-			List<Boolean> mAscCols, POUserComparisonFunc mSortFunc) {
+	public POSort(
+            OperatorKey k,
+            int rp,
+            List inp,
+            List<PhysicalPlan> sortPlans,
+			List<Boolean> mAscCols,
+            POUserComparisonFunc mSortFunc) {
 		super(k, rp, inp);
 		//this.mSortCols = mSortCols;
 		this.sortPlans = sortPlans;
@@ -329,4 +335,27 @@ public class POSort extends PhysicalOperator {
     	return (limit!=-1);
     }
 
+    @Override
+    public POSort clone() throws CloneNotSupportedException {
+        List<PhysicalPlan> clonePlans = new
+            ArrayList<PhysicalPlan>(sortPlans.size());
+        for (PhysicalPlan plan : sortPlans) {
+            clonePlans.add(plan.clone());
+        }
+        List<Boolean> cloneAsc = new ArrayList<Boolean>(mAscCols.size());
+        for (Boolean b : mAscCols) {
+            cloneAsc.add(b);
+        }
+        POUserComparisonFunc cloneFunc = null;
+        if (mSortFunc != null) {
+            cloneFunc = mSortFunc.clone();
+        }
+        // Don't set inputs as PhysicalPlan.clone will take care of that
+        return new POSort(new OperatorKey(mKey.scope, 
+            NodeIdGenerator.getGenerator().getNextNodeId(mKey.scope)),
+            requestedParallelism, null, clonePlans, cloneAsc, cloneFunc);
+    }
+
+
+
 }
diff --git a/src/org/apache/pig/backend/local/executionengine/LocalExecutionEngine.java b/src/org/apache/pig/backend/local/executionengine/LocalExecutionEngine.java
index 75f236ab4..28d04a4bb 100644
--- a/src/org/apache/pig/backend/local/executionengine/LocalExecutionEngine.java
+++ b/src/org/apache/pig/backend/local/executionengine/LocalExecutionEngine.java
@@ -39,6 +39,7 @@ import org.apache.pig.backend.executionengine.ExecJob;
 import org.apache.pig.backend.executionengine.ExecJob.JOB_STATUS;
 import org.apache.pig.backend.executionengine.ExecScopedLogicalOperator;
 import org.apache.pig.backend.executionengine.ExecPhysicalPlan;
+import org.apache.pig.backend.executionengine.util.ExecTools;
 import org.apache.pig.backend.hadoop.executionengine.HJob;
 import org.apache.pig.builtin.BinStorage;
 import org.apache.pig.impl.io.FileLocalizer;
@@ -147,9 +148,9 @@ public class LocalExecutionEngine implements ExecutionEngine {
             LocalLauncher launcher = new LocalLauncher();
             boolean success = launcher.launchPig(plan, jobName, pigContext);
             if(success)
-                return new HJob(ExecJob.JOB_STATUS.COMPLETED, pigContext, spec);
+                return new LocalJob(ExecJob.JOB_STATUS.COMPLETED, pigContext, spec);
             else
-                return new HJob(ExecJob.JOB_STATUS.FAILED, pigContext, null);
+                return new LocalJob(ExecJob.JOB_STATUS.FAILED, pigContext, null);
         } catch (Exception e) {
             // There are a lot of exceptions thrown by the launcher.  If this
             // is an ExecException, just let it through.  Else wrap it.
@@ -169,6 +170,8 @@ public class LocalExecutionEngine implements ExecutionEngine {
             printer.visit();
             stream.println();
 
+            ExecTools.checkLeafIsStore(plan, pigContext);
+
             LocalLauncher launcher = new LocalLauncher();
             launcher.explain(plan, pigContext, stream);
         } catch (Exception ve) {
diff --git a/src/org/apache/pig/backend/local/executionengine/LocalJob.java b/src/org/apache/pig/backend/local/executionengine/LocalJob.java
index ae32b6dac..18d8cfe8b 100644
--- a/src/org/apache/pig/backend/local/executionengine/LocalJob.java
+++ b/src/org/apache/pig/backend/local/executionengine/LocalJob.java
@@ -19,23 +19,37 @@
 package org.apache.pig.backend.local.executionengine;
 
 import java.io.OutputStream;
+import java.io.InputStream;
 import java.util.Iterator;
-import java.util.Properties;
 import java.util.Map;
+import java.util.Properties;
 
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.executionengine.ExecJob;
 import org.apache.pig.data.Tuple;
-import org.apache.pig.data.DataBag;
+import org.apache.pig.impl.PigContext;
+import org.apache.pig.impl.io.FileSpec;
+import org.apache.pig.LoadFunc;
+import org.apache.pig.impl.io.FileLocalizer;
+import org.apache.pig.impl.io.BufferedPositionedInputStream;
+
 
 public class LocalJob implements ExecJob {
 
-    protected DataBag results;
+    private final Log log = LogFactory.getLog(getClass());
+    
     protected JOB_STATUS status;
+    protected PigContext pigContext;
+    protected FileSpec outFileSpec;
     
-    public LocalJob(DataBag results, JOB_STATUS status) {
-        this.results = results;
+    public LocalJob(JOB_STATUS status,
+                PigContext pigContext,
+                FileSpec outFileSpec) {
         this.status = status;
+        this.pigContext = pigContext;
+        this.outFileSpec = outFileSpec;
     }
     
     public JOB_STATUS getStatus() {
@@ -47,7 +61,60 @@ public class LocalJob implements ExecJob {
     }
     
     public Iterator<Tuple> getResults() throws ExecException {
-        return this.results.iterator();
+        final LoadFunc p;
+        
+        try{
+             p = (LoadFunc)PigContext.instantiateFuncFromSpec(outFileSpec.getFuncSpec());
+
+             InputStream is = FileLocalizer.open(outFileSpec.getFileName(), pigContext);
+
+             p.bindTo(outFileSpec.getFileName(), new BufferedPositionedInputStream(is), 0, Long.MAX_VALUE);
+
+        }catch (Exception e){
+            throw new ExecException("Unable to get results for " + outFileSpec, e);
+        }
+        
+        return new Iterator<Tuple>() {
+            Tuple   t;
+            boolean atEnd;
+
+            public boolean hasNext() {
+                if (atEnd)
+                    return false;
+                try {
+                    if (t == null)
+                        t = p.getNext();
+                    if (t == null)
+                        atEnd = true;
+                } catch (Exception e) {
+                    log.error(e);
+                    t = null;
+                    atEnd = true;
+                }
+                return !atEnd;
+            }
+
+            public Tuple next() {
+                Tuple next = t;
+                if (next != null) {
+                    t = null;
+                    return next;
+                }
+                try {
+                    next = p.getNext();
+                } catch (Exception e) {
+                    log.error(e);
+                }
+                if (next == null)
+                    atEnd = true;
+                return next;
+            }
+
+            public void remove() {
+                throw new RuntimeException("Removal not supported");
+            }
+
+        };
     }
 
     public Properties getContiguration() {
diff --git a/src/org/apache/pig/builtin/COUNT.java b/src/org/apache/pig/builtin/COUNT.java
index 6f7ba3db5..7938ed144 100644
--- a/src/org/apache/pig/builtin/COUNT.java
+++ b/src/org/apache/pig/builtin/COUNT.java
@@ -29,6 +29,7 @@ import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.logicalLayer.schema.Schema;
+import org.apache.pig.impl.util.WrappedIOException;
 
 /**
  * Generates the count of the values of the first field of a tuple. This class is Algebraic in
@@ -42,9 +43,7 @@ public class COUNT extends EvalFunc<Long> implements Algebraic{
         try {
             return count(input);
         } catch (ExecException ee) {
-            IOException oughtToBeEE = new IOException();
-            oughtToBeEE.initCause(ee);
-            throw oughtToBeEE;
+            throw WrappedIOException.wrap("Caught exception in COUNT", ee);
         }
     }
 
@@ -67,9 +66,8 @@ public class COUNT extends EvalFunc<Long> implements Algebraic{
             try {
                 return mTupleFactory.newTuple(count(input));
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap(
+                    "Caught exception in COUNT.Initial", ee);
             }
         }
     }
@@ -81,9 +79,8 @@ public class COUNT extends EvalFunc<Long> implements Algebraic{
             try {
                 return mTupleFactory.newTuple(count(input));
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap(
+                    "Caught exception in COUNT.Intermed", ee);
             }
         }
     }
@@ -94,9 +91,8 @@ public class COUNT extends EvalFunc<Long> implements Algebraic{
             try {
                 return sum(input);
             } catch (Exception ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap(
+                    "Caught exception in COUNT.Final", ee);
             }
         }
     }
diff --git a/src/org/apache/pig/builtin/FloatSum.java b/src/org/apache/pig/builtin/FloatSum.java
index 1aa6a2d16..6dd61a30b 100644
--- a/src/org/apache/pig/builtin/FloatSum.java
+++ b/src/org/apache/pig/builtin/FloatSum.java
@@ -28,6 +28,7 @@ import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.logicalLayer.schema.Schema;
+import org.apache.pig.impl.util.WrappedIOException;
 
 
 /**
@@ -40,9 +41,7 @@ public class FloatSum extends EvalFunc<Double> implements Algebraic {
         try {
             return sum(input);
         } catch (ExecException ee) {
-            IOException oughtToBeEE = new IOException();
-            oughtToBeEE.initCause(ee);
-            throw oughtToBeEE;
+            throw WrappedIOException.wrap("Caught exception in FloatSum", ee);
         }
     }
 
@@ -66,9 +65,7 @@ public class FloatSum extends EvalFunc<Double> implements Algebraic {
             try {
                 return tfact.newTuple(sum(input));
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap("Caught exception in FloatSum.Initial", ee);
             }
         }
     }
@@ -76,11 +73,39 @@ public class FloatSum extends EvalFunc<Double> implements Algebraic {
         @Override
         public Double exec(Tuple input) throws IOException {
             try {
-                return sum(input);
+                // Can't just call sum, because the intermediate results are
+                // now Doubles insteads of Floats.
+                DataBag values = (DataBag)input.get(0);
+        
+                // if we were handed an empty bag, return NULL
+                // this is in compliance with SQL standard
+                if(values.size() == 0) {
+                    return null;
+                }
+
+                long sum = 0;
+                boolean sawNonNull = false;
+                for (Iterator<Tuple> it = values.iterator(); it.hasNext();) {
+                    Tuple t = (Tuple) it.next();
+                    try {
+                        Double d = (Double)(t.get(0));
+                        if (d == null) continue;
+                        sawNonNull = true;
+                        sum += d;
+                    }catch(RuntimeException exp) {
+                        throw WrappedIOException.wrap(
+                            "Caught exception in FloatSum.Final", exp);
+                    }
+                }
+        
+                
+                if(sawNonNull) {
+                    return new Double(sum);
+                } else {
+                    return null;
+                }
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap("Caught exception in FloatSum.Final", ee);
             }
         }
     }
diff --git a/src/org/apache/pig/builtin/IntSum.java b/src/org/apache/pig/builtin/IntSum.java
index 6d651cf72..9ba5e1549 100644
--- a/src/org/apache/pig/builtin/IntSum.java
+++ b/src/org/apache/pig/builtin/IntSum.java
@@ -28,7 +28,7 @@ import org.apache.pig.data.DataType;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.logicalLayer.schema.Schema;
-
+import org.apache.pig.impl.util.WrappedIOException;
 
 /**
  * Generates the sum of the Integer in the first field of a tuple.
@@ -40,9 +40,7 @@ public class IntSum extends EvalFunc<Long> implements Algebraic {
         try {
             return sum(input);
         } catch (ExecException ee) {
-            IOException oughtToBeEE = new IOException();
-            oughtToBeEE.initCause(ee);
-            throw oughtToBeEE;
+            throw WrappedIOException.wrap("Caught exception in IntSum", ee);
         }
     }
 
@@ -66,9 +64,7 @@ public class IntSum extends EvalFunc<Long> implements Algebraic {
             try {
                 return tfact.newTuple(sum(input));
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap("Caught exception in IntSum.Initial", ee);
             }
         }
     }
@@ -76,11 +72,39 @@ public class IntSum extends EvalFunc<Long> implements Algebraic {
         @Override
         public Long exec(Tuple input) throws IOException {
             try {
-                return sum(input);
+                // Can't just call sum, because the intermediate results are
+                // now Longs insteads of Integers.
+                DataBag values = (DataBag)input.get(0);
+        
+                // if we were handed an empty bag, return NULL
+                // this is in compliance with SQL standard
+                if(values.size() == 0) {
+                    return null;
+                }
+
+                long sum = 0;
+                boolean sawNonNull = false;
+                for (Iterator<Tuple> it = values.iterator(); it.hasNext();) {
+                    Tuple t = (Tuple) it.next();
+                    try {
+                        Long l = (Long)(t.get(0));
+                        if (l == null) continue;
+                        sawNonNull = true;
+                        sum += l;
+                    }catch(RuntimeException exp) {
+                        throw WrappedIOException.wrap(
+                            "Caught exception in IntSum.Final", exp);
+                    }
+                }
+        
+                
+                if(sawNonNull) {
+                    return new Long(sum);
+                } else {
+                    return null;
+                }
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap("Caught exception in IntSum.Final", ee);
             }
         }
     }
diff --git a/src/org/apache/pig/builtin/SUM.java b/src/org/apache/pig/builtin/SUM.java
index 899d59c19..e6d4c8782 100644
--- a/src/org/apache/pig/builtin/SUM.java
+++ b/src/org/apache/pig/builtin/SUM.java
@@ -32,6 +32,7 @@ import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.logicalLayer.FrontendException;
 import org.apache.pig.impl.logicalLayer.schema.Schema;
+import org.apache.pig.impl.util.WrappedIOException;
 
 
 /**
@@ -44,9 +45,7 @@ public class SUM extends EvalFunc<Double> implements Algebraic {
         try {
             return sum(input);
         } catch (ExecException ee) {
-            IOException oughtToBeEE = new IOException();
-            oughtToBeEE.initCause(ee);
-            throw oughtToBeEE;
+            throw WrappedIOException.wrap("Caught exception in SUM", ee);
         }
     }
 
@@ -70,9 +69,7 @@ public class SUM extends EvalFunc<Double> implements Algebraic {
             try {
                 return tfact.newTuple(sum(input));
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap("Caught exception in SUM.Initial", ee);
             }
         }
     }
@@ -82,9 +79,7 @@ public class SUM extends EvalFunc<Double> implements Algebraic {
             try {
                 return sum(input);
             } catch (ExecException ee) {
-                IOException oughtToBeEE = new IOException();
-                oughtToBeEE.initCause(ee);
-                throw oughtToBeEE;
+                throw WrappedIOException.wrap("Caught exception in SUM.Final", ee);
             }
         }
     }
diff --git a/src/org/apache/pig/impl/logicalLayer/schema/Schema.java b/src/org/apache/pig/impl/logicalLayer/schema/Schema.java
index d698e25ab..b0ed81b99 100644
--- a/src/org/apache/pig/impl/logicalLayer/schema/Schema.java
+++ b/src/org/apache/pig/impl/logicalLayer/schema/Schema.java
@@ -35,11 +35,11 @@ import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.logicalLayer.FrontendException;
 
 
-public class Schema implements Serializable {
+public class Schema implements Serializable, Cloneable {
 
     private static final long serialVersionUID = 2L;
 
-    public static class FieldSchema implements Serializable{
+    public static class FieldSchema implements Serializable, Cloneable {
         /**
          * 
          */
diff --git a/src/org/apache/pig/impl/plan/OperatorPlan.java b/src/org/apache/pig/impl/plan/OperatorPlan.java
index 9581cf031..f3286ed27 100644
--- a/src/org/apache/pig/impl/plan/OperatorPlan.java
+++ b/src/org/apache/pig/impl/plan/OperatorPlan.java
@@ -35,7 +35,18 @@ import org.apache.commons.logging.LogFactory;
 //import org.apache.commons.collections.map.MultiValueMap;
 
 /**
- * A generic graphing class for use by LogicalPlan, PhysicalPlan, etc.
+ * A generic graphing class for use by LogicalPlan, PhysicalPlan, etc.  One
+ * important aspect of this package is that it guarantees that once a graph is
+ * constructed, manipulations on that graph will maintain the ordering of
+ * inputs and outputs for a given node.  That is, if a node has two inputs, 0
+ * and 1, it is guaranteed that everytime it asks for its inputs, it will
+ * receive them in the same order.  This allows operators that need to
+ * distinguish their inputs (such as binary operators that need to know left
+ * from right) to work without needing to store their inputs themselves.  This
+ * is an extra burden on the graph package and not in line with the way graphs
+ * are generally understood mathematically.  But it greatly reducing the need
+ * for graph manipulators (such as the validators and optimizers) to
+ * understand the internals of various nodes.
  */
 public abstract class OperatorPlan<E extends Operator> implements Iterable, Serializable {
     protected Map<E, OperatorKey> mOps;
@@ -156,7 +167,7 @@ public abstract class OperatorPlan<E extends Operator> implements Iterable, Seri
         if (mToEdges.get(to) != null &&
                 !to.supportsMultipleInputs()) {
             PlanException pe =  new PlanException("Attempt to give operator of type " +
-                from.getClass().getName() + " multiple inputs.  This operator does "
+                to.getClass().getName() + " multiple inputs.  This operator does "
                 + "not support multiple inputs.");
             log.error(pe.getMessage());
             throw pe;
@@ -199,6 +210,47 @@ public abstract class OperatorPlan<E extends Operator> implements Iterable, Seri
         mKeys.remove(op.getOperatorKey());
     }
 
+    /**
+     * Trim everything below a given operator.  The specified operator will
+     * NOT be removed.
+     * @param op Operator to trim everything after.
+     */
+    public void trimBelow(E op) {
+        trimBelow(getSuccessors(op));
+    }
+
+    private void trimBelow(List<E> ops) {
+        if (ops != null) {
+            // Make a copy because we'll be messing with the underlying list.
+            List<E> copy = new ArrayList<E>(ops);
+            for (E op : copy) {
+                trimBelow(getSuccessors(op));
+                remove(op);
+            }
+        }
+    }
+
+    /**
+     * Trim everything above a given operator.  The specified operator will
+     * NOT be removed.
+     * @param op Operator to trim everything before.
+     */
+    public void trimAbove(E op) {
+        trimAbove(getPredecessors(op));
+    }
+
+    private void trimAbove(List<E> ops) {
+        if (ops != null) {
+            // Make a copy because we'll be messing with the underlying list.
+            List<E> copy = new ArrayList<E>(ops);
+            for (E op : copy) {
+                trimAbove(getPredecessors(op));
+                remove(op);
+            }
+        }
+    }
+
+
     /**
      * Find all of the nodes that have edges to the indicated node from
      * themselves.
@@ -394,6 +446,51 @@ public abstract class OperatorPlan<E extends Operator> implements Iterable, Seri
         return false;
     }
 
+    /**
+     * Replace an existing node in the graph with a new node.  The new node
+     * will be connected to all the nodes the old node was.  The old node will
+     * be removed.
+     * @param oldNode Node to be replaced
+     * @param newNode Node to add in place of oldNode
+     * @throws PlanException
+     */
+    public void replace(E oldNode, E newNode) throws PlanException {
+        checkInPlan(oldNode);
+        add(newNode);
+        mToEdges = generateNewMap(oldNode, newNode, mToEdges);
+        mFromEdges = generateNewMap(oldNode, newNode, mFromEdges);
+        remove(oldNode);
+    }
+
+    private MultiMap<E, E> generateNewMap(
+            E oldNode,
+            E newNode,
+            MultiMap<E, E> mm) {
+        // First, replace the key
+        Collection<E> targets = mm.get(oldNode);
+        if (targets != null) {
+            mm.removeKey(oldNode);
+            mm.put(newNode, targets);
+        }
+
+        // We can't just do a remove and add in the map because of our
+        // guarantee of not changing orders.  So we need to walk the lists and
+        // put the new node in the same slot as the old.
+
+        // Walk all the other keys and replace any references to the oldNode
+        // in their targets.
+        MultiMap<E, E> newMap = new MultiMap<E, E>(mm.size());
+        for (E key : mm.keySet()) {
+            Collection<E> c = mm.get(key);
+            ArrayList<E> al = new ArrayList<E>(c);
+            for (int i = 0; i < al.size(); i++) {
+                if (al.get(i) == oldNode) al.set(i, newNode);
+            }
+            newMap.put(key, al);
+        }
+        return newMap;
+    }
+
     /**
      * Remove a node in a way that connects the node's predecessor (if any)
      * with the node's successor (if any).  This function does not handle the
diff --git a/src/org/apache/pig/impl/util/MultiMap.java b/src/org/apache/pig/impl/util/MultiMap.java
index ba9be3800..36d1573eb 100644
--- a/src/org/apache/pig/impl/util/MultiMap.java
+++ b/src/org/apache/pig/impl/util/MultiMap.java
@@ -38,7 +38,18 @@ import java.util.Set;
  */
 public class MultiMap<K, V> implements Serializable {
 
-    private HashMap<K, ArrayList<V>> mMap = new HashMap<K, ArrayList<V>>();
+    private HashMap<K, ArrayList<V>> mMap = null;
+
+    public MultiMap() {
+        mMap = new HashMap<K, ArrayList<V>>();
+    }
+
+    /**
+     * @param size Initial size of the map
+     */
+    public MultiMap(int size) {
+        mMap = new HashMap<K, ArrayList<V>>(size);
+    }
 
     /**
      * Add an element to the map.
@@ -149,7 +160,27 @@ public class MultiMap<K, V> implements Serializable {
         return values;
     }
 
+    /**
+     * Get the number of entries in the map.
+     * @return number of entries.
+     */
+    public int size() {
+        return mMap.size();
+    }
+
+    public boolean isEmpty() {
+        return mMap.isEmpty();
+    }
 
+    public void clear() {
+        mMap.clear();
+    }
 
+    public boolean containsKey(K key) {
+        return mMap.containsKey(key);
+    }
 
+    public boolean containsValue(V val) {
+        return mMap.containsValue(val);
+    }
 }
diff --git a/src/org/apache/pig/impl/util/Pair.java b/src/org/apache/pig/impl/util/Pair.java
new file mode 100644
index 000000000..6ed4f05df
--- /dev/null
+++ b/src/org/apache/pig/impl/util/Pair.java
@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.impl.util;
+
+import java.io.Serializable;
+
+/**
+ * Copy of C++ STL pair container.
+ */
+public class Pair<T, U> implements Serializable {
+    public T first;
+    public U second;
+
+    /**
+     * @param f First element in pair.
+     * @param s Second element in pair.
+     */
+    public Pair(T f, U s) {
+        first = f;
+        second = s;
+    }
+}
diff --git a/test/org/apache/pig/test/TestEvalPipeline.java b/test/org/apache/pig/test/TestEvalPipeline.java
index fc401acf1..82d14e04b 100644
--- a/test/org/apache/pig/test/TestEvalPipeline.java
+++ b/test/org/apache/pig/test/TestEvalPipeline.java
@@ -386,10 +386,10 @@ public class TestEvalPipeline extends TestCase {
         while(iter.hasNext()){
             Tuple t = iter.next();
             assertEquals((Integer)numIdentity, (Integer)t.get(0));
-            assertEquals((Long)5L, (Long)t.get(3));
-            assertEquals(LOOP_COUNT*2.0, (Double)t.get(4), 0.01);
-            assertEquals(8.0, (Double)t.get(6), 0.01);
-            assertEquals(7, t.size());
+            assertEquals((Long)5L, (Long)t.get(2));
+            assertEquals(LOOP_COUNT*2.0, (Double)t.get(3), 0.01);
+            assertEquals(8.0, (Double)t.get(5), 0.01);
+            assertEquals(6, t.size());
             ++numIdentity;
         }
         assertEquals(LOOP_COUNT, numIdentity);
diff --git a/test/org/apache/pig/test/TestLogToPhyCompiler.java b/test/org/apache/pig/test/TestLogToPhyCompiler.java
index 3d7dcc8b7..61be268dc 100644
--- a/test/org/apache/pig/test/TestLogToPhyCompiler.java
+++ b/test/org/apache/pig/test/TestLogToPhyCompiler.java
@@ -185,6 +185,7 @@ public class TestLogToPhyCompiler extends junit.framework.TestCase {
     }
     
     public void testCogroup() throws VisitorException, IOException {
+        System.out.println("testCogroup");
     	String query = "cogroup (load 'a') by ($0 + $1, $0 - $1), (load 'b') by ($0 + $1, $0 - $1);";
     	LogicalPlan plan = buildPlan(query);
     	PhysicalPlan pp = buildPhysicalPlan(plan);
@@ -211,7 +212,7 @@ public class TestLogToPhyCompiler extends junit.framework.TestCase {
         System.out.println(compiledPlan);
         System.out.println("-------------");
         //System.out.println(compiledPlan.compareTo(goldenPlan)==0);
-        assertEquals(true, compiledPlan.compareTo(goldenPlan) == 0);
+        assertEquals(compiledPlan, goldenPlan);
     }
     
     public void testArithmetic() throws VisitorException, IOException, ExecException {
diff --git a/test/org/apache/pig/test/TestOperatorPlan.java b/test/org/apache/pig/test/TestOperatorPlan.java
index ad9fb8e70..aa8470778 100644
--- a/test/org/apache/pig/test/TestOperatorPlan.java
+++ b/test/org/apache/pig/test/TestOperatorPlan.java
@@ -834,6 +834,50 @@ public class TestOperatorPlan extends junit.framework.TestCase {
         assertFalse(transformer.mTransformed);
     }
 
+    @Test
+    public void testReplace() throws Exception {
+        // Build a plan
+        TPlan plan = new TPlan();
+        TOperator[] ops = new TOperator[6];
+        ops[0] = new MultiOperator("1");
+        plan.add(ops[0]);
+        ops[1] = new MultiOperator("2");
+        plan.add(ops[1]);
+        ops[2] = new MultiOperator("3");
+        plan.add(ops[2]);
+        ops[3] = new MultiOperator("4");
+        plan.add(ops[3]);
+        ops[4] = new MultiOperator("5");
+        plan.add(ops[4]);
+        plan.connect(ops[0], ops[2]);
+        plan.connect(ops[1], ops[2]);
+        plan.connect(ops[2], ops[3]);
+        plan.connect(ops[2], ops[4]);
+        ops[5] = new MultiOperator("6");
+        plan.replace(ops[2], ops[5]);
+
+        assertEquals("Nodes: 1 2 4 5 6 FromEdges: 1->6 2->6 6->4 6->5 ToEdges: 4->6 5->6 6->1 6->2 ", plan.display());
+    }
+
+    @Test
+    public void testReplaceNoConnections() throws Exception {
+        // Build a plan
+        TPlan plan = new TPlan();
+        TOperator[] ops = new TOperator[4];
+        ops[0] = new MultiOperator("1");
+        plan.add(ops[0]);
+        ops[1] = new MultiOperator("2");
+        plan.add(ops[1]);
+        ops[2] = new MultiOperator("3");
+        plan.add(ops[2]);
+        plan.connect(ops[0], ops[2]);
+        ops[3] = new MultiOperator("4");
+        plan.replace(ops[1], ops[3]);
+
+        assertEquals("Nodes: 1 3 4 FromEdges: 1->3 ToEdges: 3->1 ", plan.display());
+    }
+
+
 
 
 }
diff --git a/test/org/apache/pig/test/data/GoldenFiles/Cogroup.gld b/test/org/apache/pig/test/data/GoldenFiles/Cogroup.gld
index 5bb8f8d1a..6823a6f1d 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/Cogroup.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/Cogroup.gld
@@ -2,7 +2,7 @@ Package[tuple]{tuple} - Test-Plan-Builder-45
 |
 |---Global Rearrange[tuple] - Test-Plan-Builder-44
     |
-    |---Local Rearrange[tuple]{tuple} - Test-Plan-Builder-46
+    |---Local Rearrange[tuple]{tuple}(false) - Test-Plan-Builder-46
     |   |   |
     |   |   Add[Unknown] - Test-Plan-Builder-49
     |   |   |
@@ -18,7 +18,7 @@ Package[tuple]{tuple} - Test-Plan-Builder-45
     |   |
     |   |---Load(a:org.apache.pig.builtin.PigStorage) - Test-Plan-Builder-42
     |
-    |---Local Rearrange[tuple]{tuple} - Test-Plan-Builder-53
+    |---Local Rearrange[tuple]{tuple}(false) - Test-Plan-Builder-53
         |   |
         |   Add[Unknown] - Test-Plan-Builder-56
         |   |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC1.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC1.gld
index ffff694f3..a881b35cc 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC1.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC1.gld
@@ -4,7 +4,7 @@ MapReduce(-1) - -78:
 |   |---Filter[tuple] - --5177745552827005198
 |       |
 |       |---Package[tuple]{Unknown} - --6430355428631435461
-|   Local Rearrange[tuple]{Unknown} - -8729990799028586395
+|   Local Rearrange[tuple]{Unknown}(false) - -8729990799028586395
 |   |
 |   |---Load(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -77
 |
@@ -12,6 +12,6 @@ MapReduce(-1) - -78:
     |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -76
     |   |
     |   |---Package[tuple]{Unknown} - -4721502244557927278
-    |   Local Rearrange[tuple]{Unknown} - --7681398237172009051
+    |   Local Rearrange[tuple]{Unknown}(false) - --7681398237172009051
     |   |
     |   |---Load(DummyFil:DummyLdr) - -6620645493024302760
\ No newline at end of file
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC10.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC10.gld
index 92d818e53..ba8855f70 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC10.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC10.gld
@@ -16,11 +16,11 @@ Reduce Plan Empty
 |   |       |---Package[tuple]{Unknown} - -3527883492192621891
 |   |   Union[tuple] - -3
 |   |   |
-|   |   |---Local Rearrange[tuple]{Unknown} - --2655303127943013956
+|   |   |---Local Rearrange[tuple]{Unknown}(false) - --2655303127943013956
 |   |   |   |
 |   |   |   |---Load(DummyFil:DummyLdr) - --3833933141637499382
 |   |   |
-|   |   |---Local Rearrange[tuple]{Unknown} - -7473175511145418837
+|   |   |---Local Rearrange[tuple]{Unknown}(false) - -7473175511145418837
 |   |       |
 |   |       |---Filter[tuple] - --6402314745592504008
 |   |           |
@@ -37,20 +37,20 @@ Reduce Plan Empty
     |---MapReduce(30) - -4:
     |   |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -8
     |   |   |
-    |   |   |---Local Rearrange[tuple]{Unknown} - --5623550231721294978
+    |   |   |---Local Rearrange[tuple]{Unknown}(false) - --5623550231721294978
     |   |       |
     |   |       |---Package[tuple]{Unknown} - --6259721534861268730
-    |   |   Local Rearrange[tuple]{Unknown} - --7212359720440714287
+    |   |   Local Rearrange[tuple]{Unknown}(false) - --7212359720440714287
     |   |   |
     |   |   |---Load(DummyFil:DummyLdr) - -6748240903696823165
     |
     |---MapReduce(20) - -5:
         |   Store(/tmp/temp-1456742965/tmp-26634357:org.apache.pig.builtin.BinStorage) - -10
         |   |
-        |   |---Local Rearrange[tuple]{Unknown} - -5679595123645092366
+        |   |---Local Rearrange[tuple]{Unknown}(false) - -5679595123645092366
         |       |
         |       |---Package[tuple]{Unknown} - -8345455294066939854
-        |   Local Rearrange[tuple]{Unknown} - -2043312794799763441
+        |   Local Rearrange[tuple]{Unknown}(false) - -2043312794799763441
         |   |
         |   |---Filter[tuple] - -6520791719738296531
         |       |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC11.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC11.gld
index fae3cb67d..c359c6502 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC11.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC11.gld
@@ -16,13 +16,13 @@ Reduce Plan Empty
 |   |       |---Package[tuple]{Unknown} - -3943647700946858188
 |   |   Union[tuple] - -19
 |   |   |
-|   |   |---Local Rearrange[tuple]{Unknown} - -2833954415250116776
+|   |   |---Local Rearrange[tuple]{Unknown}(false) - -2833954415250116776
 |   |   |   |
 |   |   |   |---Filter[tuple] - --4083686173685839766
 |   |   |       |
 |   |   |       |---Load(DummyFil:DummyLdr) - --5733160635931065595
 |   |   |
-|   |   |---Local Rearrange[tuple]{Unknown} - -4962214768762054129
+|   |   |---Local Rearrange[tuple]{Unknown}(false) - -4962214768762054129
 |   |       |
 |   |       |---Load(DummyFil:DummyLdr) - --1115934782004129477
 |
@@ -34,7 +34,7 @@ Reduce Plan Empty
     |   |
     |   |---Load(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -24
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - -7490898804471997380
+    |   |---Local Rearrange[tuple]{Unknown}(false) - -7490898804471997380
     |       |
     |       |---Filter[tuple] - -3720949273928245639
     |           |
@@ -44,6 +44,6 @@ Reduce Plan Empty
         |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -25
         |   |
         |   |---Package[tuple]{Unknown} - --8723304958939002625
-        |   Local Rearrange[tuple]{Unknown} - -689137294940608050
+        |   Local Rearrange[tuple]{Unknown}(false) - -689137294940608050
         |   |
         |   |---Load(DummyFil:DummyLdr) - -3742910951635599848
\ No newline at end of file
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC12.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC12.gld
index de687cf56..b21ba6bc9 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC12.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC12.gld
@@ -4,13 +4,13 @@ MapReduce(-1) - -37:
 |   |---Package[tuple]{Unknown} - --1008013035164995818
 |   Union[tuple] - -38
 |   |
-|   |---Local Rearrange[tuple]{Unknown} - -3900012572437255236
+|   |---Local Rearrange[tuple]{Unknown}(false) - -3900012572437255236
 |   |   |
 |   |   |---Filter[tuple] - -7391599663069134339
 |   |       |
 |   |       |---Load(/tmp/temp-1456742965/tmp-586682361:org.apache.pig.builtin.BinStorage) - -33
 |   |
-|   |---Local Rearrange[tuple]{Unknown} - -8760996681222683693
+|   |---Local Rearrange[tuple]{Unknown}(false) - -8760996681222683693
 |       |
 |       |---Filter[tuple] - -956528893337238225
 |           |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC13.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC13.gld
index 4cdd42945..0794929cd 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC13.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC13.gld
@@ -18,13 +18,13 @@ Reduce Plan Empty
     |   |---Package[tuple]{Unknown} - --1596982214453270401
     |   Union[tuple] - -46
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - --6728652914243238289
+    |   |---Local Rearrange[tuple]{Unknown}(false) - --6728652914243238289
     |   |   |
     |   |   |---Filter[tuple] - --3509976263222494134
     |   |       |
     |   |       |---Load(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -41
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - --4071762447953696591
+    |   |---Local Rearrange[tuple]{Unknown}(false) - --4071762447953696591
     |       |
     |       |---Filter[tuple] - -7123161826157220327
     |           |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC14.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC14.gld
index c64e9d825..2a0f9e76c 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC14.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC14.gld
@@ -18,19 +18,19 @@ Reduce Plan Empty
     |   |---Package[tuple]{Unknown} - -8067897495211048679
     |   Union[tuple] - -68
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - --8754957318949788629
+    |   |---Local Rearrange[tuple]{Unknown}(false) - --8754957318949788629
     |   |   |
     |   |   |---Filter[tuple] - -551977918718096509
     |   |       |
     |   |       |---Load(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -58
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - -6411189422016119355
+    |   |---Local Rearrange[tuple]{Unknown}(false) - -6411189422016119355
     |   |   |
     |   |   |---Filter[tuple] - -2056844330428347996
     |   |       |
     |   |       |---Load(/tmp/temp-1456742965/tmp-26634357:org.apache.pig.builtin.BinStorage) - -63
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - -7225341208466719305
+    |   |---Local Rearrange[tuple]{Unknown}(false) - -7225341208466719305
     |       |
     |       |---Filter[tuple] - --7987250529196129674
     |           |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC15.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC15.gld
index e770624d9..130d72cc0 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC15.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC15.gld
@@ -8,7 +8,7 @@ MapReduce(1,GFCross) - -156:
 |       |   |---Project[tuple][*] - -7128285064986147947
 |       |
 |       |---Package[tuple]{Unknown} - --885269774183211482
-|   Local Rearrange[tuple]{Unknown} - --776319888013965510
+|   Local Rearrange[tuple]{Unknown}(false) - --776319888013965510
 |   |
 |   |---Load(/tmp/temp-1456742965/tmp-586682361:org.apache.pig.builtin.BinStorage) - -155
 |
@@ -22,7 +22,7 @@ MapReduce(1,GFCross) - -156:
     |       |   |---Project[tuple][*] - -31712229583931650
     |       |
     |       |---Package[tuple]{Unknown} - --7335024873119453444
-    |   Local Rearrange[tuple]{Unknown} - -4589138876054328603
+    |   Local Rearrange[tuple]{Unknown}(false) - -4589138876054328603
     |   |
     |   |---Load(/tmp/temp-1456742965/tmp-26634357:org.apache.pig.builtin.BinStorage) - -152
     |
@@ -44,7 +44,7 @@ MapReduce(1,GFCross) - -156:
         |           |   Project[bag][1] - -149
         |           |
         |           |---Package[tuple]{tuple} - -148
-        |   Local Rearrange[tuple]{tuple} - -147
+        |   Local Rearrange[tuple]{tuple}(false) - -147
         |   |   |
         |   |   Project[tuple][*] - -146
         |   |
@@ -70,7 +70,7 @@ MapReduce(1,GFCross) - -156:
             |           |   |---Project[tuple][1] - -136
             |           |
             |           |---Package[tuple]{chararray} - -135
-            |   Local Rearrange[tuple]{chararray} - -134
+            |   Local Rearrange[tuple]{chararray}(false) - -134
             |   |   |
             |   |   Constant(all) - -133
             |   |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC16.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC16.gld
index 32f4e0c8b..f7a8761b1 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC16.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC16.gld
@@ -1,12 +1,12 @@
 MapReduce(-1) - -170:
 |   Store(DummyFil:DummyLdr) - -7973970339130605847
 |   |
-|   |---New For Each(false)[bag] - -173
+|   |---New For Each(true)[bag] - -173
 |       |   |
 |       |   Project[tuple][0] - -172
 |       |
 |       |---Package[tuple]{tuple} - -171
-|   Local Rearrange[tuple]{tuple} - -167
+|   Local Rearrange[tuple]{tuple}(true) - -167
 |   |   |
 |   |   Project[tuple][*] - -166
 |   |
@@ -16,19 +16,19 @@ MapReduce(-1) - -170:
     |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -168
     |   |
     |   |---Package[tuple]{Unknown} - -2082992246427879202
-    |   Local Rearrange[tuple]{Unknown} - --3148893660811981376
+    |   Local Rearrange[tuple]{Unknown}(false) - --3148893660811981376
     |   |
     |   |---Load(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -164
     |
     |---MapReduce(-1) - -157:
         |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -163
         |   |
-        |   |---New For Each(false)[bag] - -162
+        |   |---New For Each(true)[bag] - -162
         |       |   |
         |       |   Project[tuple][0] - -161
         |       |
         |       |---Package[tuple]{tuple} - -160
-        |   Local Rearrange[tuple]{tuple} - -159
+        |   Local Rearrange[tuple]{tuple}(true) - -159
         |   |   |
         |   |   Project[tuple][*] - -158
         |   |
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC2.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC2.gld
index 1b7f2edcf..b37b94b1e 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC2.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC2.gld
@@ -12,7 +12,7 @@ Reduce Plan Empty
 |   |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -83
 |   |   |
 |   |   |---Package[tuple]{Unknown} - -370083002387034672
-|   |   Local Rearrange[tuple]{Unknown} - -6305091296204163466
+|   |   Local Rearrange[tuple]{Unknown}(false) - -6305091296204163466
 |   |   |
 |   |   |---Load(DummyFil:DummyLdr) - -1236980712440527800
 |
@@ -20,6 +20,6 @@ Reduce Plan Empty
     |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -85
     |   |
     |   |---Package[tuple]{Unknown} - -7123718043666602037
-    |   Local Rearrange[tuple]{Unknown} - --6380139708906526553
+    |   Local Rearrange[tuple]{Unknown}(false) - --6380139708906526553
     |   |
     |   |---Load(DummyFil:DummyLdr) - --2136667002319908593
\ No newline at end of file
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC3.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC3.gld
index 7c7d228db..6172cddd0 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC3.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC3.gld
@@ -16,7 +16,7 @@ Reduce Plan Empty
 |   |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -91
 |   |   |
 |   |   |---Package[tuple]{Unknown} - --6061281703859425960
-|   |   Local Rearrange[tuple]{Unknown} - --1158897849427419546
+|   |   Local Rearrange[tuple]{Unknown}(false) - --1158897849427419546
 |   |   |
 |   |   |---Load(DummyFil:DummyLdr) - -3709512757404691843
 |
@@ -24,6 +24,6 @@ Reduce Plan Empty
     |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -93
     |   |
     |   |---Package[tuple]{Unknown} - --2057425961601007773
-    |   Local Rearrange[tuple]{Unknown} - --8361563503038121624
+    |   Local Rearrange[tuple]{Unknown}(false) - --8361563503038121624
     |   |
     |   |---Load(DummyFil:DummyLdr) - -7506868571066332964
\ No newline at end of file
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC4.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC4.gld
index 7c7d228db..6172cddd0 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC4.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC4.gld
@@ -16,7 +16,7 @@ Reduce Plan Empty
 |   |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -91
 |   |   |
 |   |   |---Package[tuple]{Unknown} - --6061281703859425960
-|   |   Local Rearrange[tuple]{Unknown} - --1158897849427419546
+|   |   Local Rearrange[tuple]{Unknown}(false) - --1158897849427419546
 |   |   |
 |   |   |---Load(DummyFil:DummyLdr) - -3709512757404691843
 |
@@ -24,6 +24,6 @@ Reduce Plan Empty
     |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -93
     |   |
     |   |---Package[tuple]{Unknown} - --2057425961601007773
-    |   Local Rearrange[tuple]{Unknown} - --8361563503038121624
+    |   Local Rearrange[tuple]{Unknown}(false) - --8361563503038121624
     |   |
     |   |---Load(DummyFil:DummyLdr) - -7506868571066332964
\ No newline at end of file
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC6.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC6.gld
index 6851b1508..666dc44a2 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC6.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC6.gld
@@ -9,19 +9,19 @@ MapReduce(-1) - -99:
 |---MapReduce(-1) - -97:
 |   |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -101
 |   |   |
-|   |   |---Local Rearrange[tuple]{Unknown} - --3671186819751472084
+|   |   |---Local Rearrange[tuple]{Unknown}(false) - --3671186819751472084
 |   |       |
 |   |       |---Package[tuple]{Unknown} - -3737603423295312892
-|   |   Local Rearrange[tuple]{Unknown} - --2325244147060806375
+|   |   Local Rearrange[tuple]{Unknown}(false) - --2325244147060806375
 |   |   |
 |   |   |---Load(DummyFil:DummyLdr) - --8240903279973257769
 |
 |---MapReduce(-1) - -98:
     |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -103
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - --3008031181120208412
+    |   |---Local Rearrange[tuple]{Unknown}(false) - --3008031181120208412
     |       |
     |       |---Package[tuple]{Unknown} - --1194577301115518934
-    |   Local Rearrange[tuple]{Unknown} - --2626287810923037076
+    |   Local Rearrange[tuple]{Unknown}(false) - --2626287810923037076
     |   |
     |   |---Load(DummyFil:DummyLdr) - --5768272326302808468
\ No newline at end of file
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC7.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC7.gld
index cdbb93a6b..16e5ba10b 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC7.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC7.gld
@@ -15,19 +15,19 @@ MapReduce(-1) - -107:
 |---MapReduce(-1) - -104:
 |   |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -110
 |   |   |
-|   |   |---Local Rearrange[tuple]{Unknown} - --1036765666284482668
+|   |   |---Local Rearrange[tuple]{Unknown}(false) - --1036765666284482668
 |   |       |
 |   |       |---Package[tuple]{Unknown} - --5111685507913827932
-|   |   Local Rearrange[tuple]{Unknown} - -3719468117239527682
+|   |   Local Rearrange[tuple]{Unknown}(false) - -3719468117239527682
 |   |   |
 |   |   |---Load(DummyFil:DummyLdr) - -1761200043915140459
 |
 |---MapReduce(-1) - -106:
     |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -112
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - -7127277012934370361
+    |   |---Local Rearrange[tuple]{Unknown}(false) - -7127277012934370361
     |       |
     |       |---Package[tuple]{Unknown} - --8622295867288126988
-    |   Local Rearrange[tuple]{Unknown} - -810744320494301308
+    |   Local Rearrange[tuple]{Unknown}(false) - -810744320494301308
     |   |
     |   |---Load(DummyFil:DummyLdr) - -7860460526876129822
\ No newline at end of file
diff --git a/test/org/apache/pig/test/data/GoldenFiles/MRC8.gld b/test/org/apache/pig/test/data/GoldenFiles/MRC8.gld
index 05f3bdceb..1285c7752 100644
--- a/test/org/apache/pig/test/data/GoldenFiles/MRC8.gld
+++ b/test/org/apache/pig/test/data/GoldenFiles/MRC8.gld
@@ -19,19 +19,19 @@ MapReduce(-1) - -117:
 |---MapReduce(-1) - -113:
 |   |   Store(/tmp/temp-1456742965/tmp-1456742965:org.apache.pig.builtin.BinStorage) - -120
 |   |   |
-|   |   |---Local Rearrange[tuple]{Unknown} - --3347320220748403847
+|   |   |---Local Rearrange[tuple]{Unknown}(false) - --3347320220748403847
 |   |       |
 |   |       |---Package[tuple]{Unknown} - --203604194309414000
-|   |   Local Rearrange[tuple]{Unknown} - --7092666336106039025
+|   |   Local Rearrange[tuple]{Unknown}(false) - --7092666336106039025
 |   |   |
 |   |   |---Load(DummyFil:DummyLdr) - --2465563180022385815
 |
 |---MapReduce(-1) - -115:
     |   Store(/tmp/temp-1456742965/tmp2077335416:org.apache.pig.builtin.BinStorage) - -122
     |   |
-    |   |---Local Rearrange[tuple]{Unknown} - -6693653468874366867
+    |   |---Local Rearrange[tuple]{Unknown}(false) - -6693653468874366867
     |       |
     |       |---Package[tuple]{Unknown} - -8554221887998033529
-    |   Local Rearrange[tuple]{Unknown} - -913122466036599874
+    |   Local Rearrange[tuple]{Unknown}(false) - -913122466036599874
     |   |
     |   |---Load(DummyFil:DummyLdr) - -8515950928528386562
\ No newline at end of file
