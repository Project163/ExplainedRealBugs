diff --git a/CHANGES.txt b/CHANGES.txt
index d12db4f67..4e41e2df5 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -373,4 +373,6 @@ Trunk (unreleased changes)
 
     PIG-628: misc performance improvements (pradeepk via olgan)
     
-    PIG-589: error handling, phase 1-2 (sms via olgan):wq
+    PIG-589: error handling, phase 1-2 (sms via olgan)
+
+    PIG-615: Wrong number of jobs with limit (shravanmn via sms)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
index 9435a35b3..5a23dc670 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/MRCompiler.java
@@ -1562,7 +1562,7 @@ public class MRCompiler extends PhyPlanVisitor {
             // Look for map reduce operators which contains limit operator.
             // If so and the requestedParallelism > 1, add one additional map-reduce
             // operator with 1 reducer into the original plan
-            if (mr.limit!=-1 && mr.requestedParallelism>1)
+            if (mr.limit!=-1 && mr.requestedParallelism!=1)
             {
                 opsToAdjust.add(mr);
             }
diff --git a/test/org/apache/pig/test/TestMRCompiler.java b/test/org/apache/pig/test/TestMRCompiler.java
index 2ba69f041..698c0aa48 100644
--- a/test/org/apache/pig/test/TestMRCompiler.java
+++ b/test/org/apache/pig/test/TestMRCompiler.java
@@ -41,6 +41,7 @@ import org.apache.pig.impl.logicalLayer.LogicalPlan;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompilerException;
+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceOper;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.plans.MROperPlan;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
@@ -828,7 +829,54 @@ public class TestMRCompiler extends junit.framework.TestCase {
     		assertTrue(mrce.getErrorCode() == 2025);
     	}
     }
+
+    /**
+     * Test to ensure that the order by without parallel followed by a limit, i.e., top k
+     * always produces the correct number of map reduce jobs
+     */
+    @Test
+    public void testNumReducersInLimit() throws Exception {
+    	planTester.buildPlan("a = load 'input';");
+    	planTester.buildPlan("b = order a by $0;");
+    	planTester.buildPlan("c = limit b 10;");
+    	LogicalPlan lp = planTester.buildPlan("store c into '/tmp';");
+    	
+    	PhysicalPlan pp = Util.buildPhysicalPlan(lp, pc);
+    	MROperPlan mrPlan = Util.buildMRPlan(pp, pc);
+    	MapReduceOper mrOper = mrPlan.getRoots().get(0);
+    	int count = 1;
+    	
+    	while(mrPlan.getSuccessors(mrOper) != null) {
+    		mrOper = mrPlan.getSuccessors(mrOper).get(0);
+    		++count;
+    	}        
+    	assertTrue(count == 4);
+    }
     
+    /**
+     * Test to ensure that the order by with parallel followed by a limit, i.e., top k
+     * always produces the correct number of map reduce jobs
+     */
+    @Test
+    public void testNumReducersInLimitWithParallel() throws Exception {
+    	planTester.buildPlan("a = load 'input';");
+    	planTester.buildPlan("b = order a by $0 parallel 2;");
+    	planTester.buildPlan("c = limit b 10;");
+    	LogicalPlan lp = planTester.buildPlan("store c into '/tmp';");
+    	
+    	PhysicalPlan pp = Util.buildPhysicalPlan(lp, pc);
+    	MROperPlan mrPlan = Util.buildMRPlan(pp, pc);
+    	MapReduceOper mrOper = mrPlan.getRoots().get(0);
+    	int count = 1;
+    	
+    	while(mrPlan.getSuccessors(mrOper) != null) {
+    		mrOper = mrPlan.getSuccessors(mrOper).get(0);
+    		++count;
+    	}        
+    	assertTrue(count == 4);
+    }
+
+
     public static class WeirdComparator extends ComparisonFunc {
 
         @Override
