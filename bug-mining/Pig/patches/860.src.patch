diff --git a/CHANGES.txt b/CHANGES.txt
index 87b960545..268b23519 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -190,6 +190,8 @@ PIG-2228: support partial aggregation in map task (thejas)
 
 BUG FIXES
 
+PIG-2391: Bzip_2 test is broken (xutingz via daijy)
+
 PIG-2358: JobStats.getHadoopCounters() is never set and always returns null (xutingz via daijy)
 
 PIG-2184: Not able to provide positional reference to macro invocations (xutingz via daijy)
diff --git a/src/org/apache/pig/builtin/PigStorage.java b/src/org/apache/pig/builtin/PigStorage.java
index 45b5a33c5..6620ca27a 100644
--- a/src/org/apache/pig/builtin/PigStorage.java
+++ b/src/org/apache/pig/builtin/PigStorage.java
@@ -33,8 +33,10 @@ import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.io.Text;
+import org.apache.hadoop.io.compress.BZip2Codec;
 import org.apache.hadoop.io.compress.CompressionCodec;
 import org.apache.hadoop.io.compress.CompressionCodecFactory;
+import org.apache.hadoop.io.compress.GzipCodec;
 import org.apache.hadoop.mapreduce.InputFormat;
 import org.apache.hadoop.mapreduce.Job;
 import org.apache.hadoop.mapreduce.OutputFormat;
@@ -380,13 +382,15 @@ LoadPushDown, LoadMetadata, StoreMetadata {
     }
 
     private void setCompression(Path path, Job job) {
-        CompressionCodecFactory codecFactory = new CompressionCodecFactory(job.getConfiguration());
-        CompressionCodec codec = codecFactory.getCodec(path);
-        if (codec != null) {
+     	String location=path.getName();
+        if (location.endsWith(".bz2") || location.endsWith(".bz")) {
             FileOutputFormat.setCompressOutput(job, true);
-            FileOutputFormat.setOutputCompressorClass(job, codec.getClass());
-        }else {
-            FileOutputFormat.setCompressOutput(job, false);  
+            FileOutputFormat.setOutputCompressorClass(job,  BZip2Codec.class);
+        }  else if (location.endsWith(".gz")) {
+            FileOutputFormat.setCompressOutput(job, true);
+            FileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);
+        } else {
+            FileOutputFormat.setCompressOutput( job, false);
         }
     }
 
diff --git a/test/org/apache/pig/test/TestBZip.java b/test/org/apache/pig/test/TestBZip.java
index 7eb94cba3..29adde6b0 100644
--- a/test/org/apache/pig/test/TestBZip.java
+++ b/test/org/apache/pig/test/TestBZip.java
@@ -181,6 +181,55 @@ public class TestBZip {
         out.delete();
     }
 
+    //see PIG-2391
+    @Test
+    public void testBz2() throws Exception {
+        String[] inputData = new String[] {
+                "1\t2\r3\t4", // '\r' case - this will be split into two tuples
+                "5\t6\r", // '\r\n' case
+                "7\t8", // '\n' case
+                "9\t10\r" // '\r\n' at the end of file
+        };
+        
+        // bzip compressed input
+        File in = File.createTempFile("junit", ".bz2");
+        String compressedInputFileName = in.getAbsolutePath();
+        in.deleteOnExit();
+        
+        try {
+            CBZip2OutputStream cos = 
+                new CBZip2OutputStream(new FileOutputStream(in));
+            for (int i = 0; i < inputData.length; i++) {
+                StringBuffer sb = new StringBuffer();
+                sb.append(inputData[i]).append("\n");
+                byte bytes[] = sb.toString().getBytes();
+                cos.write(bytes);
+            }
+            cos.close();
+            
+            Util.copyFromLocalToCluster(cluster, compressedInputFileName,
+                    compressedInputFileName);
+            
+            // pig script to read compressed input
+            PigServer pig = new PigServer(ExecType.MAPREDUCE, cluster
+                    .getProperties());
+            
+            // pig script to read compressed input
+            String script ="a = load '" + compressedInputFileName +"';";
+            pig.registerQuery(script);
+            
+            pig.registerQuery("store a into 'intermediate.bz';");
+            pig.registerQuery("b = load 'intermediate.bz';");
+            Iterator<Tuple> it2 = pig.openIterator("b");
+			while (it2.hasNext()) {
+				it2.next();
+			}
+        } finally {
+            in.delete();
+            Util.deleteFile(cluster, "intermediate.bz");
+            Util.deleteFile(cluster, "final.bz");
+        }
+    }
     /** 
      * Tests that '\n', '\r' and '\r\n' are treated as record delims when using
      * bzip just like they are when using uncompressed text
