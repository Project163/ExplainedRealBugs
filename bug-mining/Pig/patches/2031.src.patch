diff --git a/CHANGES.txt b/CHANGES.txt
index 967c833f8..c5ad5d404 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -36,6 +36,8 @@ PIG-5457: Upgrade Zookeeper to 3.7.2 (from 3.5.7)  (knoguchi)
 OPTIMIZATIONS
  
 BUG FIXES
+PIG-5449: TestEmptyInputDir failing on pig-on-spark3 (knoguchi)
+
 PIG-5459: Jython_Checkin_3 e2e failing with NoClassDefFoundError (hadoop3) (knoguchi)
 
 PIG-5416: Spark unit tests failing randomly with "java.lang.RuntimeException: Unexpected job execution status RUNNING" (knoguchi)
diff --git a/src/org/apache/pig/tools/pigstats/spark/SparkJobStats.java b/src/org/apache/pig/tools/pigstats/spark/SparkJobStats.java
index f01241b4f..5532c8a22 100644
--- a/src/org/apache/pig/tools/pigstats/spark/SparkJobStats.java
+++ b/src/org/apache/pig/tools/pigstats/spark/SparkJobStats.java
@@ -21,6 +21,8 @@ package org.apache.pig.tools.pigstats.spark;
 import java.util.List;
 import java.util.Map;
 
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.mapred.Counters;
 import org.apache.pig.PigWarning;
@@ -42,6 +44,7 @@ import org.apache.spark.executor.TaskMetrics;
 import com.google.common.collect.Maps;
 
 public class SparkJobStats extends JobStats {
+    private static final Log LOG = LogFactory.getLog(SparkJobStats.class);
 
     private int jobId;
     private Map<String, Long> stats = Maps.newLinkedHashMap();
@@ -106,9 +109,10 @@ public class SparkJobStats extends JobStats {
         if (jobStatisticCollector != null) {
             Map<String, List<TaskMetrics>> taskMetrics = jobStatisticCollector.getJobMetric(jobId);
             if (taskMetrics == null) {
-                throw new RuntimeException("No task metrics available for jobId " + jobId);
+                LOG.warn("No task metrics available for jobId " + jobId);
+            } else {
+                stats = combineTaskMetrics(taskMetrics);
             }
-            stats = combineTaskMetrics(taskMetrics);
         }
     }
 
