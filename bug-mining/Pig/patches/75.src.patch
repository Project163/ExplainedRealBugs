diff --git a/CHANGES.txt b/CHANGES.txt
index d5d8632ed..952465485 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -183,3 +183,9 @@ Trunk (unreleased changes)
     PIG-398: Expressions not allowed inside foreach (sms via olgan)
 
     PIG-418: divide by 0 problem
+
+    PIG-402: order by with user comparator (shravanmn via olgan)
+
+    PIG-415: problem with comparators (shravanmn via olgan)
+
+
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index b3283fdf2..d778ab335 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -287,7 +287,7 @@ public class JobControlCompiler{
                     op.setParentPlan(plans[i]);                
                 }    
             }
-            
+            POPackage pack = null;
             if(mro.reducePlan.isEmpty()){
                 //MapOnly Job
                 jobConf.setMapperClass(PigMapOnly.Map.class);
@@ -310,7 +310,7 @@ public class JobControlCompiler{
                     jobConf.set("pig.combinePlan", ObjectSerializer.serialize(mro.combinePlan));
                     jobConf.set("pig.combine.package", ObjectSerializer.serialize(combPack));
                 }
-                POPackage pack = (POPackage)mro.reducePlan.getRoots().get(0);
+                pack = (POPackage)mro.reducePlan.getRoots().get(0);
                 mro.reducePlan.remove(pack);
                 jobConf.setMapperClass(PigMapReduce.Map.class);
                 jobConf.setReducerClass(PigMapReduce.Reduce.class);
@@ -345,6 +345,10 @@ public class JobControlCompiler{
                     String compFuncSpec = mro.UDFs.get(0);
                     Class comparator = PigContext.resolveClassName(compFuncSpec);
                     if(ComparisonFunc.class.isAssignableFrom(comparator)) {
+                        jobConf.setMapperClass(PigMapReduce.MapWithComparator.class);
+                        pack.setKeyType(DataType.TUPLE);
+                        jobConf.set("pig.reduce.package", ObjectSerializer.serialize(pack));
+                        jobConf.setOutputKeyClass(TupleFactory.getInstance().tupleClass());
                         jobConf.setOutputKeyComparatorClass(comparator);
                     }
                 } else {
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBytesRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBytesRawComparator.java
index 085501571..0fa375dce 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBytesRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigBytesRawComparator.java
@@ -66,7 +66,7 @@ public class PigBytesRawComparator extends BytesWritable.Comparator implements C
         // If either are null, handle differently.
         if (b1[s1] == NullableBytesWritable.NOTNULL &&
                 b2[s2] == NullableBytesWritable.NOTNULL) {
-            rc = super.compare(b1, s1 + 1, l1, b2, s2 + 1, l2);
+            rc = super.compare(b1, s1 + 1, l1-1, b2, s2 + 1, l2-1);
         } else {
             // For sorting purposes two nulls are equal.
             if (b1[s1] == NullableBytesWritable.NULL &&
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigDoubleRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigDoubleRawComparator.java
index a8c5d80bd..60de93211 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigDoubleRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigDoubleRawComparator.java
@@ -65,7 +65,7 @@ public class PigDoubleRawComparator extends DoubleWritable.Comparator implements
         // If either are null, handle differently.
         if (b1[s1] == NullableDoubleWritable.NOTNULL &&
                 b2[s2] == NullableDoubleWritable.NOTNULL) {
-            rc = super.compare(b1, s1 + 1, l1, b2, s2 + 1, l2);
+            rc = super.compare(b1, s1 + 1, l1-1, b2, s2 + 1, l2-1);
         } else {
             // For sorting purposes two nulls are equal.
             if (b1[s1] == NullableDoubleWritable.NULL &&
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigFloatRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigFloatRawComparator.java
index 43b8857a7..0c8541c0a 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigFloatRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigFloatRawComparator.java
@@ -66,7 +66,7 @@ public class PigFloatRawComparator extends FloatWritable.Comparator implements C
         // If either are null, handle differently.
         if (b1[s1] == NullableFloatWritable.NOTNULL &&
                 b2[s2] == NullableFloatWritable.NOTNULL) {
-            rc = super.compare(b1, s1 + 1, l1, b2, s2 + 1, l2);
+            rc = super.compare(b1, s1 + 1, l1-1, b2, s2 + 1, l2-1);
         } else {
             // For sorting purposes two nulls are equal.
             if (b1[s1] == NullableFloatWritable.NULL &&
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigIntRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigIntRawComparator.java
index 35566924b..a05d4b863 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigIntRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigIntRawComparator.java
@@ -66,7 +66,7 @@ public class PigIntRawComparator extends IntWritable.Comparator implements Confi
         // If either are null, handle differently.
         if (b1[s1] == NullableIntWritable.NOTNULL &&
                 b2[s2] == NullableIntWritable.NOTNULL) {
-            rc = super.compare(b1, s1 + 1, l1, b2, s2 + 1, l2);
+            rc = super.compare(b1, s1 + 1, l1-1, b2, s2 + 1, l2-1);
         } else {
             // For sorting purposes two nulls are equal.
             if (b1[s1] == NullableIntWritable.NULL &&
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigLongRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigLongRawComparator.java
index 6aee57da7..aa39d7907 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigLongRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigLongRawComparator.java
@@ -66,7 +66,7 @@ public class PigLongRawComparator extends LongWritable.Comparator implements Con
         // If either are null, handle differently.
         if (b1[s1] == NullableLongWritable.NOTNULL &&
                 b2[s2] == NullableLongWritable.NOTNULL) {
-            rc = super.compare(b1, s1 + 1, l1, b2, s2 + 1, l2);
+            rc = super.compare(b1, s1 + 1, l1-1, b2, s2 + 1, l2-1);
         } else {
             // For sorting purposes two nulls are equal.
             if (b1[s1] == NullableLongWritable.NULL &&
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
index f1729f853..ae5b70dd9 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
@@ -16,6 +16,7 @@ import org.apache.hadoop.mapred.Reporter;
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.data.TargetedTuple;
 import org.apache.pig.data.Tuple;
+import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
@@ -27,12 +28,13 @@ import org.apache.pig.impl.util.SpillableMemoryManager;
 
 public abstract class PigMapBase extends MapReduceBase{
     private final Log log = LogFactory.getLog(getClass());
-
+    
     protected byte keyType;
     
     
     //Map Plan
     protected PhysicalPlan mp;
+    protected TupleFactory tf = TupleFactory.getInstance();
     
     OutputCollector<WritableComparable, Writable> outputCollector;
     
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
index 331de4acc..6887ca054 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
@@ -83,6 +83,20 @@ public class PigMapReduce {
             oc.collect(wcKey, it);
         }
     }
+    
+    public static class MapWithComparator extends PigMapBase implements
+            Mapper<Text, TargetedTuple, WritableComparable, Writable> {
+
+        @Override
+        public void collect(OutputCollector<WritableComparable, Writable> oc,
+                Tuple tuple) throws ExecException, IOException {
+            Object key = tuple.get(0);
+            Tuple keyTuple = tf.newTuple(1);
+            keyTuple.set(0, key);
+            IndexedTuple it = (IndexedTuple) tuple.get(1);
+            oc.collect(keyTuple, it);
+        }
+    }
 
     public static class Reduce extends MapReduceBase
             implements
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigTextRawComparator.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigTextRawComparator.java
index 863a832c9..e0702e5ae 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigTextRawComparator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigTextRawComparator.java
@@ -66,7 +66,7 @@ public class PigTextRawComparator extends Text.Comparator implements Configurabl
         // If either are null, handle differently.
         if (b1[s1] == NullableText.NOTNULL &&
                 b2[s2] == NullableText.NOTNULL) {
-            rc = super.compare(b1, s1 + 1, l1, b2, s2 + 1, l2);
+            rc = super.compare(b1, s1 + 1, l1-1, b2, s2 + 1, l2-1);
         } else {
             // For sorting purposes two nulls are equal.
             if (b1[s1] == NullableText.NULL &&
diff --git a/test/org/apache/pig/test/TestEvalPipeline.java b/test/org/apache/pig/test/TestEvalPipeline.java
index c80465f81..e409129ae 100644
--- a/test/org/apache/pig/test/TestEvalPipeline.java
+++ b/test/org/apache/pig/test/TestEvalPipeline.java
@@ -34,6 +34,7 @@ import java.util.StringTokenizer;
 import org.junit.Before;
 import org.junit.Test;
 
+import org.apache.pig.ComparisonFunc;
 import org.apache.pig.EvalFunc;
 import org.apache.pig.ExecType;
 import org.apache.pig.PigServer;
@@ -61,6 +62,7 @@ public class TestEvalPipeline extends TestCase {
     public void setUp() throws Exception{
         FileLocalizer.setR(new Random());
         pigServer = new PigServer(ExecType.MAPREDUCE, cluster.getProperties());
+//        pigServer = new PigServer(ExecType.LOCAL);
     }
     
     static public class MyBagFunction extends EvalFunc<DataBag>{
@@ -306,16 +308,29 @@ public class TestEvalPipeline extends TestCase {
     
     @Test
     public void testSort() throws Exception{
-        testSortDistinct(false);
+        testSortDistinct(false, false);
+    }
+    
+    @Test
+    public void testSortWithUDF() throws Exception{
+        testSortDistinct(false, true);
     }
     
 
     @Test
     public void testDistinct() throws Exception{
-        testSortDistinct(true);
+        testSortDistinct(true, false);
     }
+    
+    public static class TupComp extends ComparisonFunc {
 
-    private void testSortDistinct(boolean eliminateDuplicates) throws Exception{
+        @Override
+        public int compare(Tuple t1, Tuple t2) {
+            return t1.compareTo(t2);
+        }
+    }
+
+    private void testSortDistinct(boolean eliminateDuplicates, boolean useUDF) throws Exception{
         int LOOP_SIZE = 1024*16;
         File tmpFile = File.createTempFile("test", "txt");
         PrintStream ps = new PrintStream(new FileOutputStream(tmpFile));
@@ -330,7 +345,10 @@ public class TestEvalPipeline extends TestCase {
         if (eliminateDuplicates){
             pigServer.registerQuery("B = DISTINCT (FOREACH A GENERATE $0) PARALLEL 10;");
         }else{
-            pigServer.registerQuery("B = ORDER A BY $0 PARALLEL 10;");
+            if(!useUDF)
+                pigServer.registerQuery("B = ORDER A BY $0 PARALLEL 10;");
+            else
+                pigServer.registerQuery("B = ORDER A BY $0 using " + TupComp.class.getName() + ";");
         }
         pigServer.store("B", tmpOutputFile);
         
@@ -355,7 +373,7 @@ public class TestEvalPipeline extends TestCase {
         
     }
     
-    public void testNestedPlan() throws Exception{
+    /*public void testNestedPlan() throws Exception{
         int LOOP_COUNT = 10;
         File tmpFile = File.createTempFile("test", "txt");
         PrintStream ps = new PrintStream(new FileOutputStream(tmpFile));
@@ -464,7 +482,7 @@ public class TestEvalPipeline extends TestCase {
             ++numIdentity;
         }
         assertEquals(5, numIdentity);
-    }
+    }*/
     
 
 }
