diff --git a/contrib/zebra/CHANGES.txt b/contrib/zebra/CHANGES.txt
index e670009b1..288570f75 100644
--- a/contrib/zebra/CHANGES.txt
+++ b/contrib/zebra/CHANGES.txt
@@ -66,6 +66,8 @@ Trunk (unreleased changes)
 
   BUG FIXES
 
+    PIG-1269 Restrict schema definition for collection (xuefuz via yanz)
+
     PIG-1253: make map/reduce test cases run on real cluster (chaow via yanz)
 
     PIG-1276: Pig resource schema interface changed, so Zebra needs to catch exception thrown from the new interfaces. (xuefuz via yanz)
diff --git a/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/Schema.java b/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/Schema.java
index e83ae1266..cb0372f40 100644
--- a/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/Schema.java
+++ b/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/Schema.java
@@ -929,6 +929,8 @@ public class Schema implements Comparable<Schema>, Writable {
         if (fs.type != ColumnType.RECORD && fs.type != ColumnType.COLLECTION)
           throw new ParseException(name
               + " is not of type RECORD or COLLECTION");
+        else if( fs.type == ColumnType.COLLECTION ) 
+		  throw new ParseException( name + "Projection within COLLECTION is not supported" );
         currentName = currentName.substring(fieldIndex + 1);
         if (currentName.length() == 0)
           throw new ParseException("Column " + name
diff --git a/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/SchemaParser.jjt b/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/SchemaParser.jjt
index fceeb6f84..9fb88cfa8 100644
--- a/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/SchemaParser.jjt
+++ b/contrib/zebra/src/java/org/apache/hadoop/zebra/schema/SchemaParser.jjt
@@ -205,17 +205,14 @@ Schema.ColumnSchema SchemaCollection() throws ParseException :
 
 Schema.ColumnSchema SchemaCollectionEntry(String id) throws ParseException :
 {
-	Schema s = null;
 	Schema.ColumnSchema fs = null;
 }
 {
   (
-  s= RecordSchemaInternal()
-| fs = AnonymousColumnSchema()
+  	fs = AnonymousSchemaRecord() | fs = SchemaRecord()
   )
-	{ if (s == null) s = new Schema(fs);
-    fs = new Schema.ColumnSchema(id, s, ColumnType.COLLECTION);
-    return fs;
+  {
+    return new Schema.ColumnSchema(id, new Schema(fs), ColumnType.COLLECTION);
   }
 }
 
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableMapSplits.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableMapSplits.java
index 88a6f8c7a..09cbd9720 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableMapSplits.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableMapSplits.java
@@ -51,7 +51,7 @@ import org.junit.Test;
  * 
  */
 public class TestBasicTableMapSplits {
-  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(f13:double, f14:float, f15:bytes)";
+  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(record(f13:double, f14:float, f15:bytes))";
   final static String STR_STORAGE = "[r.f12, f1, m#{b}]; [m#{a}, r.f11]";
   private static Configuration conf;
   private static Path path;
@@ -104,7 +104,7 @@ public class TestBasicTableMapSplits {
     tuple.set(2, map);
 
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(3).getSchema();
+    Schema schColl = schema.getColumn(3).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableSplits.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableSplits.java
index 35b52d207..3c4ed9d39 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableSplits.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestBasicTableSplits.java
@@ -50,7 +50,7 @@ import org.junit.Test;
  * 
  */
 public class TestBasicTableSplits {
-  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(f13:double, f14:float, f15:bytes)";
+  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(record(f13:double, f14:float, f15:bytes))";
   // TODO: try map hash split later
   final static String STR_STORAGE = "[r.f12, f1]; [m]";
   private static Configuration conf;
@@ -106,7 +106,7 @@ public class TestBasicTableSplits {
     tuple.set(2, map);
 
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(3).getSchema();
+    Schema schColl = schema.getColumn(3).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestCollection.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestCollection.java
index 41562d52d..e9f810f79 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestCollection.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestCollection.java
@@ -16,20 +16,11 @@
  */
 package org.apache.hadoop.zebra.io;
 
-import java.io.ByteArrayOutputStream;
 import java.io.IOException;
-import java.io.PrintWriter;
-import java.lang.reflect.Array;
-import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.StringTokenizer;
 
 import junit.framework.Assert;
-import junit.framework.TestCase;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
@@ -42,10 +33,8 @@ import org.apache.hadoop.zebra.io.TableInserter;
 import org.apache.hadoop.zebra.io.TableScanner;
 import org.apache.hadoop.zebra.io.BasicTable.Reader.RangeSplit;
 import org.apache.hadoop.zebra.parser.ParseException;
-import org.apache.hadoop.zebra.types.Projection;
 import org.apache.hadoop.zebra.schema.Schema;
 import org.apache.hadoop.zebra.types.TypesUtils;
-import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.Tuple;
@@ -60,7 +49,7 @@ import org.junit.Test;
  */
 public class TestCollection {
 
-  final static String STR_SCHEMA = "c:collection(a:double, b:float, c:bytes),c2:collection(r1:record(f1:int, f2:string), d:string),c3:collection(c3_1:collection(e:int,f:bool))";
+  final static String STR_SCHEMA = "c:collection(record(a:double, b:float, c:bytes)),c2:collection(record(r1:record(f1:int, f2:string), d:string)),c3:collection(record(c3_1:collection(record(e:int,f:bool))))";
   final static String STR_STORAGE = "[c]";
   private static Configuration conf;
   private static Path path;
@@ -92,12 +81,12 @@ public class TestCollection {
     TableInserter inserter = writer1.getInserter("part" + part, true);
     TypesUtils.resetTuple(tuple);
     DataBag bag1 = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(0).getSchema();
+    Schema schColl = schema.getColumn(0).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
 
     DataBag bag2 = TypesUtils.createBag();
-    Schema schColl2 = schema.getColumn(1).getSchema();
+    Schema schColl2 = schema.getColumn(1).getSchema().getColumn(0).getSchema();
     Tuple tupColl2_1 = TypesUtils.createTuple(schColl2);
     Tuple tupColl2_2 = TypesUtils.createTuple(schColl2);
     Tuple collRecord1;
@@ -117,7 +106,6 @@ public class TestCollection {
 
     // c3:collection(c3_1:collection(e:int,f:bool))
     DataBag bag3 = TypesUtils.createBag();
-    Schema schColl3 = schema.getColumn(2).getSchema();
     DataBag bag3_1 = TypesUtils.createBag();
     DataBag bag3_2 = TypesUtils.createBag();
 
@@ -502,156 +490,19 @@ public class TestCollection {
     reader.close();
   }
 
-  // read, should support project to 2nd level
+  // Negative test case. Projection on fields in collection is not supported.
   @Test
-  public void testRead5() throws IOException, ParseException {
-    String projection = new String("c.a");
-    BasicTable.Reader reader = new BasicTable.Reader(path, conf);
-    reader.setProjection(projection);
-    List<RangeSplit> splits = reader.rangeSplit(1);
-    TableScanner scanner = reader.getScanner(splits.get(0), true);
-    BytesWritable key = new BytesWritable();
-    Tuple RowValue = TypesUtils.createTuple(scanner.getSchema());
-
-    scanner.getKey(key);
-    // Assert.assertEquals(key, new BytesWritable("k11".getBytes()));
-    scanner.getValue(RowValue);
-    System.out.println("test read 5: row: " + RowValue.toString());
-    // test read 5: row: ({(3.1415926),(123.456789)})
-    Iterator<Tuple> it = ((DataBag) RowValue.get(0)).iterator();
-    int list = 0;
-    while (it.hasNext()) {
-      Tuple cur = it.next();
-      System.out.println(cur.get(0));
-      list++;
-      if (list == 1) {
-        Assert.assertEquals(3.1415926, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-
-      }
-      if (list == 2) {
-        Assert.assertEquals(123.456789, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-    scanner.advance();
-    scanner.getValue(RowValue);
-    Iterator<Tuple> it2 = ((DataBag) RowValue.get(0)).iterator();
-    int list2 = 0;
-    while (it2.hasNext()) {
-      Tuple cur = it2.next();
-      System.out.println(cur.get(0));
-      list2++;
-      if (list2 == 1) {
-        Assert.assertEquals(7654.321, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-      if (list2 == 2) {
-        Assert.assertEquals(0.123456789, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-
-    reader.close();
-  }
-
-  // read, should support project to 2nd level
-  // final static String STR_SCHEMA =
-  // "c:collection(a:double, b:float, c:bytes),c2:collection(r1:record(f1:int, f2:string), d:string),c3:collection(c3_1:collection(e:int,f:bool))";
-  @Test
-  public void testRead6() throws IOException, ParseException {
-    String projection = new String("c2.r1");
-    BasicTable.Reader reader = new BasicTable.Reader(path, conf);
-    reader.setProjection(projection);
-    List<RangeSplit> splits = reader.rangeSplit(1);
-    TableScanner scanner = reader.getScanner(splits.get(0), true);
-    BytesWritable key = new BytesWritable();
-    Tuple RowValue = TypesUtils.createTuple(scanner.getSchema());
-
-    scanner.getKey(key);
-    // Assert.assertEquals(key, new BytesWritable("k11".getBytes()));
-    scanner.getValue(RowValue);
-    System.out.println("test read 6 :row: " + RowValue.toString());
-    // test read 6 :row: ({((1,record1_string1)),((2,record2_string1))})
-    Iterator<Tuple> it = ((DataBag) RowValue.get(0)).iterator();
-    int list = 0;
-    while (it.hasNext()) {
-      Tuple cur = it.next();
-      System.out.println(cur.get(0));
-      list++;
-      if (list == 1) {
-        Assert.assertEquals(1, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record1_string1", ((Tuple) cur.get(0)).get(1));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-
-      }
-      if (list == 2) {
-        Assert.assertEquals(2, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record2_string1", ((Tuple) cur.get(0)).get(1));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-    scanner.advance();
-    scanner.getValue(RowValue);
-    Iterator<Tuple> it2 = ((DataBag) RowValue.get(0)).iterator();
-    int list2 = 0;
-    while (it2.hasNext()) {
-      Tuple cur = it2.next();
-      System.out.println(cur.get(0));
-      list2++;
-      if (list2 == 1) {
-        Assert.assertEquals(3, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record1_string2", ((Tuple) cur.get(0)).get(1));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-      if (list2 == 2) {
-        Assert.assertEquals(4, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record2_string2", ((Tuple) cur.get(0)).get(1));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-
-    reader.close();
+  public void testRead5() throws IOException {
+	  try {
+		  String projection = new String("c.a");
+		  BasicTable.Reader reader = new BasicTable.Reader(path, conf);
+		  reader.setProjection(projection);
+	  } catch(ParseException ex) {
+		  System.out.println( "caught expected exception: " + ex );
+		  return;
+	  }
+	  
+	  Assert.fail( "Test case failure: projection on collection field or record field is not supported." );
   }
 
   // read, should support project to 3rd level TODO: construct scanner failed
@@ -816,159 +667,6 @@ public class TestCollection {
     reader.close();
   }
 
-  // read stitch simple + record stitch
-  // final static String STR_SCHEMA =
-  // "c:collection(a:double, b:float, c:bytes),c2:collection(r1:record(f1:int, f2:string), d:string),c3:collection(c3_1:collection(e:int,f:bool))";
-  @Test
-  public void testRead9() throws IOException, ParseException {
-    String projection = new String("c.a, c2.r1");
-    BasicTable.Reader reader = new BasicTable.Reader(path, conf);
-    reader.setProjection(projection);
-    List<RangeSplit> splits = reader.rangeSplit(1);
-    TableScanner scanner = reader.getScanner(splits.get(0), true);
-    BytesWritable key = new BytesWritable();
-    Tuple RowValue = TypesUtils.createTuple(scanner.getSchema());
-
-    scanner.getKey(key);
-    // Assert.assertEquals(key, new BytesWritable("k11".getBytes()));
-    scanner.getValue(RowValue);
-    System.out.println("read 9: " + RowValue.toString());
-    // read 9:
-    // ({(3.1415926),(123.456789)},{((1,record1_string1)),((2,record2_string1))})
-    Iterator<Tuple> it = ((DataBag) RowValue.get(0)).iterator();
-    int list = 0;
-    while (it.hasNext()) {
-      Tuple cur = it.next();
-      System.out.println(cur.get(0));
-      list++;
-      if (list == 1) {
-        Assert.assertEquals(3.1415926, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-      if (list == 2) {
-        Assert.assertEquals(123.456789, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-    Iterator<Tuple> it2 = ((DataBag) RowValue.get(1)).iterator();
-    list = 0;
-    while (it2.hasNext()) {
-      Tuple cur = it2.next();
-      System.out.println(cur.get(0));
-      list++;
-      if (list == 1) {
-        Assert.assertEquals(1, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record1_string1", ((Tuple) cur.get(0)).get(1));
-        try {
-          ((Tuple) cur.get(0)).get(2);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-      if (list == 2) {
-        Assert.assertEquals(2, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record2_string1", ((Tuple) cur.get(0)).get(1));
-        try {
-          ((Tuple) cur.get(0)).get(2);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-    scanner.advance();
-    scanner.getValue(RowValue);
-    Iterator<Tuple> it3 = ((DataBag) RowValue.get(0)).iterator();
-    while (it3.hasNext()) {
-      Tuple cur = it3.next();
-      System.out.println(cur.get(0));
-      list++;
-      if (list == 1) {
-        Assert.assertEquals(7654.321, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-      if (list == 2) {
-        Assert.assertEquals(0.123456789, cur.get(0));
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-
-    Iterator<Tuple> it4 = ((DataBag) RowValue.get(1)).iterator();
-    list = 0;
-    while (it4.hasNext()) {
-      Tuple cur = it4.next();
-      System.out.println(cur.get(0));
-      list++;
-      if (list == 1) {
-        Assert.assertEquals(3, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record1_string2", ((Tuple) cur.get(0)).get(1));
-        try {
-          ((Tuple) cur.get(0)).get(2);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-      if (list == 2) {
-        Assert.assertEquals(4, ((Tuple) cur.get(0)).get(0));
-        Assert.assertEquals("record2_string2", ((Tuple) cur.get(0)).get(1));
-        try {
-          ((Tuple) cur.get(0)).get(2);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-        try {
-          cur.get(1);
-          Assert.fail("Should throw index out of bounds exception");
-        } catch (Exception e) {
-          System.out.println(e);
-        }
-      }
-    }
-
-    reader.close();
-  }
-
   // Negative should not support 2nd level collection split
   @Test
   public void testSplit1() throws IOException, ParseException {
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnGroupSplits.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnGroupSplits.java
index 9e34a9028..b64082f7c 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnGroupSplits.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnGroupSplits.java
@@ -22,7 +22,6 @@ import java.util.Iterator;
 import java.util.Map;
 
 import junit.framework.Assert;
-import junit.framework.TestCase;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
@@ -52,7 +51,7 @@ import org.junit.Test;
  */
 public class TestColumnGroupSplits {
   final static String outputFile = "TestColumnGroupSplits";
-  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(f13:double, f14:float, f15:bytes)";
+  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(record(f13:double, f14:float, f15:bytes))";
   final static private Configuration conf = new Configuration();
   static private FileSystem fs;
   static private Path path;
@@ -85,7 +84,7 @@ public class TestColumnGroupSplits {
     // schema for "r:record..."
     Schema schRecord = writer.getSchema().getColumn(1).getSchema();
     Tuple tupRecord = TypesUtils.createTuple(schRecord);
-    Schema schColl = schema.getColumn(3).getSchema();
+    Schema schColl = schema.getColumn(3).getSchema().getColumn(0).getSchema();
     DataBag bagColl = TypesUtils.createBag();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
@@ -395,132 +394,6 @@ public class TestColumnGroupSplits {
     reader.close();
   }
 
-  @Test
-  // normal one collection column projection
-  public void testOneCollectionColumnProjection() throws Exception {
-    System.out.println("testOneCollectionColumnProjection");
-    ColumnGroup.Reader reader = new ColumnGroup.Reader(path, conf);
-    reader.setProjection("c.f13, f1, c.XYZ");
-
-    Tuple row = TypesUtils.createTuple(reader.getSchema());
-    TableScanner scanner = reader.getScanner(null, false);
-    BytesWritable key = new BytesWritable();
-
-    scanner.getKey(key);
-    Assert.assertEquals(key, new BytesWritable("k1".getBytes()));
-    scanner.getValue(row);
-    DataBag bagColl = (DataBag) row.get(0);
-
-    boolean f1 = (Boolean) (row.get(1));
-    Assert.assertEquals(true, f1);
-
-    Iterator<Tuple> itorColl = bagColl.iterator();
-    Tuple tupColl = itorColl.next();
-    Assert.assertEquals(3.1415926, tupColl.get(0));
-    try {
-      Object obj = tupColl.get(1);
-      Assert.fail("Failed to catch 'out of boundary' exceptions.");
-    } catch (IndexOutOfBoundsException e) {
-      // no op, expecting out of bounds exceptions
-    }
-    tupColl = itorColl.next();
-    Assert.assertEquals(123.456789, tupColl.get(0));
-    Assert.assertNull(row.get(2));
-    try {
-      row.get(3);
-      Assert.fail("Failed to catch 'out of boundary' exceptions.");
-    } catch (IndexOutOfBoundsException e) {
-      // no op, expecting out of bounds exceptions
-    }
-
-    scanner.advance();
-    scanner.getKey(key);
-    Assert.assertEquals(key, new BytesWritable("k2".getBytes()));
-    TypesUtils.resetTuple(row);
-    scanner.getValue(row);
-
-    f1 = (Boolean) row.get(1);
-    Assert.assertEquals(false, f1);
-
-    bagColl.clear();
-    bagColl = (DataBag) row.get(0);
-    itorColl = bagColl.iterator();
-    tupColl = itorColl.next();
-    Assert.assertEquals(7654.321, tupColl.get(0));
-    tupColl = itorColl.next();
-    Assert.assertEquals(0.123456789, tupColl.get(0));
-    Assert.assertNull(row.get(2));
-
-    scanner.close();
-    reader.close();
-  }
-
-  // test columns from different types of columns in random order
-  @Test
-  @SuppressWarnings("unchecked")
-  public void testMixedColumnProjection() throws Exception {
-    System.out.println("testMixedColumnProjection");
-    ColumnGroup.Reader reader = new ColumnGroup.Reader(path, conf);
-    // TODO: add map field later
-    reader.setProjection("c.f14, f1, r.f11, XYZ");
-
-    Tuple row = TypesUtils.createTuple(reader.getSchema());
-    TableScanner scanner = reader.getScanner(null, false);
-    BytesWritable key = new BytesWritable();
-
-    scanner.getKey(key);
-    Assert.assertEquals(key, new BytesWritable("k1".getBytes()));
-    scanner.getValue(row);
-    DataBag bagColl = (DataBag) row.get(0);
-    Iterator<Tuple> itorColl = bagColl.iterator();
-    Tuple tupColl = itorColl.next();
-    Assert.assertEquals(1.6, tupColl.get(0));
-    // make sure only 1 element returned in the collection
-    try {
-      Object obj = tupColl.get(1);
-      Assert.fail("Failed to catch 'out of boundary' exceptions.");
-    } catch (IndexOutOfBoundsException e) {
-      // no op, expecting out of bounds exceptions
-    }
-    tupColl = itorColl.next();
-    Assert.assertEquals(100, tupColl.get(0));
-    try {
-      Object obj = tupColl.get(1);
-      Assert.fail("Failed to catch 'out of boundary' exceptions.");
-    } catch (IndexOutOfBoundsException e) {
-      // no op, expecting out of bounds exceptions
-    }
-    Assert.assertFalse(itorColl.hasNext());
-    Assert.assertEquals(true, row.get(1));
-    Assert.assertEquals(1, row.get(2));
-    Assert.assertNull(row.get(3));
-    try {
-      Object obj = row.get(4);
-      Assert.fail("Failed to catch 'out of boundary' exceptions.");
-    } catch (IndexOutOfBoundsException e) {
-      // no op, expecting out of bounds exceptions
-    }
-
-    scanner.advance();
-    scanner.getKey(key);
-    Assert.assertEquals(key, new BytesWritable("k2".getBytes()));
-    TypesUtils.resetTuple(row);
-    scanner.getValue(row);
-    bagColl.clear();
-    bagColl = (DataBag) row.get(0);
-    itorColl = bagColl.iterator();
-    tupColl = itorColl.next();
-    Assert.assertEquals(0.0001, tupColl.get(0));
-    tupColl = itorColl.next();
-    Assert.assertEquals(0.3333, tupColl.get(0));
-    Assert.assertEquals(false, row.get(1));
-    Assert.assertEquals(2, row.get(2));
-    Assert.assertNull(row.get(3));
-
-    scanner.close();
-    reader.close();
-  }
-
   @Test
   @SuppressWarnings("unchecked")
   // normal one collection column projection
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnName.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnName.java
index af7b3b611..ce87e6336 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnName.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestColumnName.java
@@ -51,11 +51,11 @@ import org.junit.Test;
  */
 public class TestColumnName {
 	final static String STR_SCHEMA = 
-		"f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(f13:double, f14:float, f15:bytes)";
+		"f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(record(f13:double, f14:float, f15:bytes))";
 	final static String STR_STORAGE = "[r.f12, f1, m#{b}]; [m#{_a}, r.f11]";
 
 	final static String INVALID_STR_SCHEMA = 
-		"_f1:bool, _r:record(f11:int, _f12:long), _m:map(string), _c:collection(_f13:double, _f14:float, _f15:bytes)";
+		"_f1:bool, _r:record(f11:int, _f12:long), _m:map(string), _c:collection(record(_f13:double, _f14:float, _f15:bytes))";
 	final static String INVALID_STR_STORAGE = "[_r.f12, _f1, _m#{b}]; [_m#{_a}, _r.f11]";
 
 	private static Configuration conf = new Configuration();
@@ -104,7 +104,7 @@ public class TestColumnName {
 		tuple.set(2, map);
 
 		DataBag bagColl = TypesUtils.createBag();
-		Schema schColl = schema.getColumn(3).getSchema();
+		Schema schColl = schema.getColumn(3).getSchema().getColumn(0).getSchema();
 		Tuple tupColl1 = TypesUtils.createTuple(schColl);
 		Tuple tupColl2 = TypesUtils.createTuple(schColl);
 		byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestDropColumnGroup.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestDropColumnGroup.java
index 047900e75..c77a878ae 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestDropColumnGroup.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestDropColumnGroup.java
@@ -185,218 +185,6 @@ public class TestDropColumnGroup {
     BasicTable.drop(path, conf);
   }
 
-  @Test
-  public void testDropColumnGroupsMixedTypes() throws IOException,
-      ParseException {
-
-    String mixedSchema = /* roughly borrowed from testMixedType1.java */
-    "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, "
-        + "r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)),"
-        + "m1:map(string),m2:map(map(int)), "
-        + "c:collection(f13:double, f14:float, f15:bytes)";
-    // [s1, s2]; [m1#{a}]; [r1.f1]; [s3, s4, r2.r3.f3]; [s5, s6, m2#{x|y}];
-    // [r1.f2, m1#{b}]; [r2.r3.f4, m2#{z}]";
-    String mixedStorageHint = "[s1, s2]                      as simpleCG; "
-        + "[m1#{a}, s3]                  as mapCG; "
-        + "[s4, r2.r3.f3, r1.f1]         as recordCG; "
-        + "[c]                           as collectionCG; "  
-        + "[r1.f2, m1#{b}, m2#{z}]       as mapRecordCG; ";
-
-    //Path path = new Path(TestBasicTable.rootPath, "DropCGTest");
-    Configuration conf = TestBasicTable.conf;
-    conf.set("fs.default.name", "file:///");
-    if (fs.exists(path)) {
-      BasicTable.drop(path, conf);
-    }
-    
-    // first write the table :
-    BasicTable.Writer writer = new BasicTable.Writer(path, mixedSchema,
-        mixedStorageHint, conf);
-    writer.finish();
-
-    Schema schema = writer.getSchema();
-    Tuple tuple = TypesUtils.createTuple(schema);
-    BasicTable.Writer writer1 = new BasicTable.Writer(path, conf);
-    int part = 0;
-    TableInserter inserter = writer1.getInserter("part" + part, true);
-    TypesUtils.resetTuple(tuple);
-
-    Tuple tupRecord1 = TypesUtils.createTuple(schema.getColumnSchema("r1")
-        .getSchema());
-    Tuple tupRecord2 = TypesUtils.createTuple(schema.getColumnSchema("r2")
-        .getSchema());
-
-    Tuple tupRecord3 = TypesUtils.createTuple(new Schema("f3:float, f4"));
-
-    // row 1
-    tuple.set(0, true); // bool
-    tuple.set(1, 1); // int
-    tuple.set(2, 1001L); // long
-    tuple.set(3, 1.1); // float
-    tuple.set(4, "hello world 1"); // string
-    tuple.set(5, new DataByteArray("hello byte 1")); // byte
-
-    // r1:record(f1:int, f2:long
-    tupRecord1.set(0, 1);
-    tupRecord1.set(1, 1001L);
-    tuple.set(6, tupRecord1);
-
-    // r2:record(r3:record(f3:float, f4))
-    tupRecord2.set(0, tupRecord3);
-    tupRecord3.set(0, 1.3);
-    tupRecord3.set(1, new DataByteArray("r3 row 1 byte array "));
-    tuple.set(7, tupRecord2);
-
-    // m1:map(string)
-    Map<String, String> m1 = new HashMap<String, String>();
-    m1.put("a", "A");
-    m1.put("b", "B");
-    m1.put("c", "C");
-    tuple.set(8, m1);
-
-    // m2:map(map(int))
-    HashMap<String, Map<String, Integer>> m2 = new HashMap<String, Map<String, Integer>>();
-    Map<String, Integer> m3 = new HashMap<String, Integer>();
-    m3.put("m311", 311);
-    m3.put("m321", 321);
-    m3.put("m331", 331);
-    Map<String, Integer> m4 = new HashMap<String, Integer>();
-    m4.put("m411", 411);
-    m4.put("m421", 421);
-    m4.put("m431", 431);
-    m2.put("x", m3);
-    m2.put("y", m4);
-    tuple.set(9, m2);
-
-    // c:collection(f13:double, f14:float, f15:bytes)
-    DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(10).getSchema();
-    Tuple tupColl1 = TypesUtils.createTuple(schColl);
-    Tuple tupColl2 = TypesUtils.createTuple(schColl);
-    byte[] abs1 = new byte[3];
-    byte[] abs2 = new byte[4];
-    tupColl1.set(0, 3.1415926);
-    tupColl1.set(1, 1.6);
-    abs1[0] = 11;
-    abs1[1] = 12;
-    abs1[2] = 13;
-    tupColl1.set(2, new DataByteArray(abs1));
-    bagColl.add(tupColl1);
-    tupColl2.set(0, 123.456789);
-    tupColl2.set(1, 100);
-    abs2[0] = 21;
-    abs2[1] = 22;
-    abs2[2] = 23;
-    abs2[3] = 24;
-    tupColl2.set(2, new DataByteArray(abs2));
-    bagColl.add(tupColl2);
-    tuple.set(10, bagColl);
-
-    int row = 0;
-    inserter.insert(new BytesWritable(String.format("k%d%d", part + 1, row + 1)
-        .getBytes()), tuple);
-    // row 2
-    row++;
-    TypesUtils.resetTuple(tuple);
-    TypesUtils.resetTuple(tupRecord1);
-    TypesUtils.resetTuple(tupRecord2);
-    TypesUtils.resetTuple(tupRecord3);
-    m1.clear();
-    m2.clear();
-    m3.clear();
-    m4.clear();
-    tuple.set(0, false);
-    tuple.set(1, 2); // int
-    tuple.set(2, 1002L); // long
-    tuple.set(3, 3.1); // float
-    tuple.set(4, "hello world 2"); // string
-    tuple.set(5, new DataByteArray("hello byte 2")); // byte
-
-    // r1:record(f1:int, f2:long
-    tupRecord1.set(0, 2);
-
-    tupRecord1.set(1, 1002L);
-    tuple.set(6, tupRecord1);
-
-    // r2:record(r3:record(f3:float, f4))
-    tupRecord2.set(0, tupRecord3);
-    tupRecord3.set(0, 2.3);
-    tupRecord3.set(1, new DataByteArray("r3 row2  byte array"));
-    tuple.set(7, tupRecord2);
-
-    // m1:map(string)
-    m1.put("a2", "A2");
-    m1.put("b2", "B2");
-    m1.put("c2", "C2");
-    tuple.set(8, m1);
-
-    // m2:map(map(int))
-    m3.put("m321", 321);
-    m3.put("m322", 322);
-    m3.put("m323", 323);
-    m2.put("z", m3);
-    tuple.set(9, m2);
-
-    // c:collection(f13:double, f14:float, f15:bytes)
-    bagColl.clear();
-    TypesUtils.resetTuple(tupColl1);
-    TypesUtils.resetTuple(tupColl2);
-    tupColl1.set(0, 7654.321);
-    tupColl1.set(1, 0.0001);
-    abs1[0] = 31;
-    abs1[1] = 32;
-    abs1[2] = 33;
-    tupColl1.set(2, new DataByteArray(abs1));
-    bagColl.add(tupColl1);
-    tupColl2.set(0, 0.123456789);
-    tupColl2.set(1, 0.3333);
-    abs2[0] = 41;
-    abs2[1] = 42;
-    abs2[2] = 43;
-    abs2[3] = 44;
-    tupColl2.set(2, new DataByteArray(abs2));
-    bagColl.add(tupColl2);
-    tuple.set(10, bagColl);
-
-    // Write same row 10 times:
-    for (int i = 0; i < 10; i++) {
-      inserter.insert(new BytesWritable(String.format("k%d%d", part + 1 + i,
-          row + 1 + i).getBytes()), tuple);
-    }
-
-    inserter.close();
-    writer1.finish();
-
-    writer.close();
-
-    int numRows = 11;
-    // drop mapCG: removes [m1#{a}, s3]
-    BasicTable.dropColumnGroup(path, conf, "mapCG");
-
-    verifyScanner(path, conf, "m1", new boolean[] { false }, numRows);
-
-    verifyScanner(path, conf, "s1, m1#{a}, m1#{b}, s3, s4", new boolean[] {
-        false, true, false, true, false }, numRows);
-
-    // drop simpleCG : removes [s1, s2]
-    BasicTable.dropColumnGroup(path, conf, "simpleCG");
-    verifyScanner(path, conf, "s1, m1#{a}, s2, m1#{b}", new boolean[] { true,
-        true, true, false }, numRows);
-
-    // drop mapRecordCG : removes [r1.f2, m1#{b}, m2#{z}];\
-    BasicTable.dropColumnGroup(path, conf, "mapRecordCG");
-    verifyScanner(path, conf, "r1.f1, r1.f2, m1#{a}, s5, m1#{b}",
-        new boolean[] { false, true, true, false, true }, numRows);
-
-    // drop collectionCG : removes c;\
-    BasicTable.dropColumnGroup(path, conf, "collectionCG");
-    verifyScanner(path, conf, "c.f1, c.f2, c.f3", new boolean[] { true, true,
-        true }, numRows);
-
-    // clean up the table
-    BasicTable.drop(path, conf);
-  }
-
   @Test
   public void test2() throws IOException, ParseException {
     /*
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMapSplitSchemaStorageColumnOutOfOrder.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMapSplitSchemaStorageColumnOutOfOrder.java
index 31019ce71..a5f1d8b6b 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMapSplitSchemaStorageColumnOutOfOrder.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMapSplitSchemaStorageColumnOutOfOrder.java
@@ -47,7 +47,7 @@ import org.junit.Test;
  * 
  */
 public class TestMapSplitSchemaStorageColumnOutOfOrder {
-  final static String STR_SCHEMA = "column1:bytes,column2:bytes, column3:bytes,column4:bytes,column5:map(String),column6:map(String),column7:map(String),column8:collection(f1:map(String))";   
+  final static String STR_SCHEMA = "column1:bytes,column2:bytes, column3:bytes,column4:bytes,column5:map(String),column6:map(String),column7:map(String),column8:collection(record(f1:map(String)))";   
   final static String STR_STORAGE = "[column1,column2,column3,column4];[column5#{key51|key52|key53|key54|key55|key56},column7#{key71|key72|key73|key74|key75}];[column5,column7,column6];[column8]";
   private static Configuration conf;
   private static Path path;
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMixedType1.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMixedType1.java
index 26d9126cc..2b5b8ee32 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMixedType1.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestMixedType1.java
@@ -53,7 +53,7 @@ import org.junit.Test;
  * 
  */
 public class TestMixedType1 {
-  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(f13:double, f14:float, f15:bytes)";
+  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(record(f13:double, f14:float, f15:bytes))";
   final static String STR_STORAGE = "[s1, s2]; [m1#{a}]; [r1.f1]; [s3, s4, r2.r3.f3]; [s5, s6, m2#{x|y}]; [r1.f2, m1#{b}]; [r2.r3.f4, m2#{z}]";
   private static Configuration conf;
   private static Path path;
@@ -152,7 +152,7 @@ public class TestMixedType1 {
 
     // c:collection(f13:double, f14:float, f15:bytes)
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(10).getSchema();
+    Schema schColl = schema.getColumn(10).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestSortedBasicTableSplits.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestSortedBasicTableSplits.java
index 38ce99eb4..9c2b64f8d 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestSortedBasicTableSplits.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestSortedBasicTableSplits.java
@@ -50,7 +50,7 @@ import org.junit.Test;
  * 
  */
 public class TestSortedBasicTableSplits {
-  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(f13:double, f14:float, f15:bytes)";
+  final static String STR_SCHEMA = "f1:bool, r:record(f11:int, f12:long), m:map(string), c:collection(record(f13:double, f14:float, f15:bytes))";
   // TODO: try map hash split later
   final static String STR_STORAGE = "[r.f12, f1]; [m]";
   private static Configuration conf;
@@ -106,7 +106,7 @@ public class TestSortedBasicTableSplits {
     tuple.set(2, map);
 
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(3).getSchema();
+    Schema schColl = schema.getColumn(3).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestWrite.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestWrite.java
index f5d2a2631..1b98e58b3 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestWrite.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/io/TestWrite.java
@@ -53,7 +53,7 @@ import org.junit.Test;
  * 
  */
 public class TestWrite {
-  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(f13:double, f14:float, f15:bytes)";
+  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(record(f13:double, f14:float, f15:bytes))";
   final static String STR_STORAGE = "[s1, s2]; [m1#{a}]; [r1.f1]; [s3, s4, r2.r3.f3]; [s5, s6, m2#{x|y}]; [r1.f2, m1#{b}]; [r2.r3.f4, m2#{z}]";
   private static Configuration conf;
   private static Path path;
@@ -152,7 +152,7 @@ public class TestWrite {
 
     // c:collection(f13:double, f14:float, f15:bytes)
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(10).getSchema();
+    Schema schColl = schema.getColumn(10).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollection.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollection.java
index 38e7a6dfe..b19b8c302 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollection.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollection.java
@@ -64,7 +64,7 @@ import org.junit.Test;
  */
 public class TestCollection {
 
-  final static String STR_SCHEMA = "c:collection(a:double, b:float, c:bytes)";
+  final static String STR_SCHEMA = "c:collection(record(a:double, b:float, c:bytes))";
   final static String STR_STORAGE = "[c]";
   private static Configuration conf;
   private static FileSystem fs;
@@ -148,7 +148,7 @@ public class TestCollection {
     TableInserter inserter = writer1.getInserter("part" + part, true);
     TypesUtils.resetTuple(tuple);
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(0).getSchema();
+    Schema schColl = schema.getColumn(0).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableLoader.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableLoader.java
index 676ed6de6..f3e5ce3cc 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableLoader.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableLoader.java
@@ -22,8 +22,6 @@ import java.io.File;
 import java.io.IOException;
 import java.util.Iterator;
 
-import junit.framework.TestCase;
-
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
@@ -39,9 +37,7 @@ import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataByteArray;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.test.MiniCluster;
-import org.junit.After;
 import org.junit.AfterClass;
-import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -74,7 +70,7 @@ public class TestCollectionTableLoader {
     BasicTable.drop(pathTable, conf);
 
     BasicTable.Writer writer = new BasicTable.Writer(pathTable,
-        "c:collection(a:double, b:float, c:bytes)", "[c]", conf);
+        "c:collection(record(a:double, b:float, c:bytes))", "[c]", conf);
     Schema schema = writer.getSchema();
     Tuple tuple = TypesUtils.createTuple(schema);
 
@@ -90,7 +86,7 @@ public class TestCollectionTableLoader {
         TypesUtils.resetTuple(tuple);
 
         DataBag bagColl = TypesUtils.createBag();
-        Schema schColl = schema.getColumn(0).getSchema();
+        Schema schColl = schema.getColumn(0).getSchema().getColumn(0).getSchema();
         Tuple tupColl1 = TypesUtils.createTuple(schColl);
         Tuple tupColl2 = TypesUtils.createTuple(schColl);
         byte[] abs1 = new byte[3];
@@ -138,4 +134,5 @@ public class TestCollectionTableLoader {
       System.out.println(cur);
     }
   }
+
 }
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableStorer.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableStorer.java
index 0b4085793..eaacd010a 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableStorer.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestCollectionTableStorer.java
@@ -76,7 +76,7 @@ public class TestCollectionTableStorer {
 
     System.out.println("table path=" + pathTable);
     BasicTable.Writer writer = new BasicTable.Writer(pathTable,
-        "c:collection(a:double, b:float, c:bytes)", "[c]", conf);
+        "c:collection(record(a:double, b:float, c:bytes))", "[c]", conf);
     Schema schema = writer.getSchema();
     Tuple tuple = TypesUtils.createTuple(schema);
 
@@ -92,7 +92,7 @@ public class TestCollectionTableStorer {
         TypesUtils.resetTuple(tuple);
 
         DataBag bagColl = TypesUtils.createBag();
-        Schema schColl = schema.getColumn(0).getSchema();
+        Schema schColl = schema.getColumn(0).getSchema().getColumn(0).getSchema();
         Tuple tupColl1 = TypesUtils.createTuple(schColl);
         Tuple tupColl2 = TypesUtils.createTuple(schColl);
         byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestLoaderWithCollection.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestLoaderWithCollection.java
index 0f955514b..1b47897dd 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestLoaderWithCollection.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestLoaderWithCollection.java
@@ -63,7 +63,7 @@ public class TestLoaderWithCollection {
         BasicTable.drop(pathTable, conf);
 
         BasicTable.Writer writer = new BasicTable.Writer(pathTable,
-                "c:collection(a:double)", "[c]", conf);
+                "c:collection(record(a:double))", "[c]", conf);
         Schema schema = writer.getSchema();
         Tuple tuple = TypesUtils.createTuple(schema);
 
@@ -79,7 +79,7 @@ public class TestLoaderWithCollection {
                 TypesUtils.resetTuple(tuple);
 
                 DataBag bagColl = TypesUtils.createBag();
-                Schema schColl = schema.getColumn(0).getSchema();
+                Schema schColl = schema.getColumn(0).getSchema().getColumn(0).getSchema();
                 Tuple tupColl1 = TypesUtils.createTuple(schColl);
                 Tuple tupColl2 = TypesUtils.createTuple(schColl);
                 tupColl1.set(0, 3.1415926);
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestMixedType1.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestMixedType1.java
index ad58e228f..26fde0520 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestMixedType1.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestMixedType1.java
@@ -59,7 +59,7 @@ import org.junit.Test;
  * 
  */
 public class TestMixedType1 {
-  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(f13:double, f14:float, f15:bytes)";
+  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(record(f13:double, f14:float, f15:bytes))";
   final static String STR_STORAGE = "[s1, s2]; [m1#{a}]; [r1.f1]; [s3, s4, r2.r3.f3]; [s5, s6, m2#{x|y}]; [r1.f2, m1#{b}]; [r2.r3.f4, m2#{z}]";
   private static Configuration conf;
   private static FileSystem fs;
@@ -171,7 +171,7 @@ public class TestMixedType1 {
 
     // c:collection(f13:double, f14:float, f15:bytes)
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(10).getSchema();
+    Schema schColl = schema.getColumn(10).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestUnionMixedTypes.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestUnionMixedTypes.java
index ad85a096c..29132abe3 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestUnionMixedTypes.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/pig/TestUnionMixedTypes.java
@@ -65,9 +65,9 @@ public class TestUnionMixedTypes {
   protected static PigServer pigServer;
   private static Path pathWorking, pathTable1, pathTable2;
   private static Configuration conf;
-  final static String STR_SCHEMA1 = "a:collection(a:string, b:string),b:map(string),c:record(f1:string, f2:string),d";
+  final static String STR_SCHEMA1 = "a:collection(record(a:string, b:string)),b:map(string),c:record(f1:string, f2:string),d";
   final static String STR_STORAGE1 = "[a,d];[b#{k1|k2}];[c]";
-  final static String STR_SCHEMA2 = "a:collection(a:string, b:string),b:map(string),c:record(f1:string, f2:string),e";
+  final static String STR_SCHEMA2 = "a:collection(record(a:string, b:string)),b:map(string),c:record(f1:string, f2:string),e";
   final static String STR_STORAGE2 = "[a,e];[b#{k1}];[c.f1]";
 
   @BeforeClass
@@ -106,7 +106,7 @@ public class TestUnionMixedTypes {
 
     TypesUtils.resetTuple(tuple);
     DataBag bag1 = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(0).getSchema();
+    Schema schColl = schema.getColumn(0).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
 
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaAnonymousCollection.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaAnonymousCollection.java
index 4762396c0..3f3b02e3a 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaAnonymousCollection.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaAnonymousCollection.java
@@ -31,7 +31,7 @@ import org.junit.Test;
 public class TestSchemaAnonymousCollection {
   @Test
   public void testSchemaValid1() throws ParseException {
-    String strSch = "c1:collection(f1:int, f2:int), c2:collection(collection(record(f3:float, f4)))";
+    String strSch = "c1:collection(Record(f1:int, f2:int)), c2:collection(record(f5:collection(record(f3:float, f4))))";
     TableSchemaParser parser;
     Schema schema;
 
@@ -50,22 +50,22 @@ public class TestSchemaAnonymousCollection {
 
     // test 2nd level schema;
     Schema f1Schema = f1.getSchema();
-    ColumnSchema f11 = f1Schema.getColumn(0);
+    ColumnSchema f11 = f1Schema.getColumn(0).getSchema().getColumn(0);
     Assert.assertEquals("f1", f11.getName());
     Assert.assertEquals(ColumnType.INT, f11.getType());
-    ColumnSchema f12 = f1Schema.getColumn(1);
+    ColumnSchema f12 = f1Schema.getColumn(0).getSchema().getColumn(1);
     Assert.assertEquals("f2", f12.getName());
     Assert.assertEquals(ColumnType.INT, f12.getType());
 
     Schema f2Schema = f2.getSchema();
     ColumnSchema f21 = f2Schema.getColumn(0);
     Assert.assertNull(f21.getName());
-    Assert.assertEquals(ColumnType.COLLECTION, f21.getType());
+    Assert.assertEquals(ColumnType.RECORD, f21.getType());
 
     // test 3rd level schema;
     Schema f21Schema = f21.getSchema();
     ColumnSchema f211 = f21Schema.getColumn(0);
-    Assert.assertNull(f211.getName());
+    Assert.assertTrue(f211.getName().equals("f5"));
     Assert.assertEquals(ColumnType.COLLECTION, f211.getType());
     Schema f211Schema = f211.getSchema();
     
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaCollection.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaCollection.java
index 1819708b6..5f2abc16c 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaCollection.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestSchemaCollection.java
@@ -31,7 +31,7 @@ import org.junit.Test;
 public class TestSchemaCollection {
   @Test
   public void testSchemaValid1() throws ParseException {
-    String strSch = "c1:collection(f1:int, f2:int), c2:collection(c3:collection(f3:float, f4))";
+    String strSch = "c1:collection(record(f1:int, f2:int)), c2:collection(record(c3:collection(record(f3:float, f4))))";
     TableSchemaParser parser;
     Schema schema;
 
@@ -50,24 +50,24 @@ public class TestSchemaCollection {
 
     // test 2nd level schema;
     Schema f1Schema = f1.getSchema();
-    ColumnSchema f11 = f1Schema.getColumn(0);
+    ColumnSchema f11 = f1Schema.getColumn(0).getSchema().getColumn(0);
     Assert.assertEquals("f1", f11.getName());
     Assert.assertEquals(ColumnType.INT, f11.getType());
-    ColumnSchema f12 = f1Schema.getColumn(1);
+    ColumnSchema f12 = f1Schema.getColumn(0).getSchema().getColumn(1);
     Assert.assertEquals("f2", f12.getName());
     Assert.assertEquals(ColumnType.INT, f12.getType());
 
     Schema f2Schema = f2.getSchema();
-    ColumnSchema f21 = f2Schema.getColumn(0);
+    ColumnSchema f21 = f2Schema.getColumn(0).getSchema().getColumn(0);
     Assert.assertEquals("c3", f21.getName());
     Assert.assertEquals(ColumnType.COLLECTION, f21.getType());
 
     // test 3rd level schema;
     Schema f21Schema = f21.getSchema();
-    ColumnSchema f211 = f21Schema.getColumn(0);
+    ColumnSchema f211 = f21Schema.getColumn(0).getSchema().getColumn(0);
     Assert.assertEquals("f3", f211.getName());
     Assert.assertEquals(ColumnType.FLOAT, f211.getType());
-    ColumnSchema f212 = f21Schema.getColumn(1);
+    ColumnSchema f212 = f21Schema.getColumn(0).getSchema().getColumn(1);
     Assert.assertEquals("f4", f212.getName());
     Assert.assertEquals(ColumnType.BYTES, f212.getType());
   }
@@ -75,7 +75,7 @@ public class TestSchemaCollection {
   @Test
   public void testSchemaInvalid1() throws ParseException, Exception {
     try {
-      String strSch = "c1:collection(f1:int, f2:int), c2:collection(c3:collection(f3:float, f4)))";
+      String strSch = "c1:collection(record(f1:int, f2:int)), c2:collection(record(c3:collection(record(f3:float, f4)))))";
       TableSchemaParser parser;
       Schema schema;
 
@@ -84,10 +84,41 @@ public class TestSchemaCollection {
       System.out.println(schema);
     } catch (Exception e) {
       String errMsg = e.getMessage();
-      String str = "Encountered \" \")\" \") \"\" at line 1, column 74.";
+      String str = "Encountered \" \")\" \") \"\" at line 1, column 98.";
       System.out.println(errMsg);
       System.out.println(str);
       Assert.assertEquals(errMsg.startsWith(str), true);
     }
   }
-}
\ No newline at end of file
+  
+  @Test
+  public void testInvalidCollectionSchema() throws ParseException {
+	    String[] strSchs = { "c0:int, c1:collection(f1:int, f2:string)",
+	    		             "c0:int, c1:collection(f1:int)",
+	    		             "c0:int, c1:collection(int)" };
+	    for( String strSch : strSchs ) {
+		    TableSchemaParser parser = new TableSchemaParser( new StringReader( strSch ) );
+		    try {
+		    	parser.RecordSchema(null);
+		    } catch(ParseException ex) {
+		    	System.out.println( "Catch expected exception for schema: " + strSch );
+		    	
+		    	continue;
+		    }
+		    Assert.fail( "Exception expected for invalid schemes: "+  strSch );
+	    }
+  }
+  
+//  private void printSchema(Schema schema, int indent) {
+//	    for( int i = 0; i < schema.getNumColumns(); i++ ) {
+//	    	ColumnSchema cs = schema.getColumn( i );
+//	    	for( int j = 0; j < indent; j++ )
+//	    		System.out.print( "\t" );
+//	    	System.out.println( cs.getName() + ": " + cs.getType().toString() );
+//	    	if( cs.getSchema() != null )
+//	    		printSchema( cs.getSchema(), indent + 1 );
+//	    }
+//	  
+//  }
+  
+}
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageCollection.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageCollection.java
index 85b51119e..efddb3ad6 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageCollection.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageCollection.java
@@ -35,7 +35,7 @@ import org.junit.Before;
 import org.junit.Test;
 
 public class TestStorageCollection {
-  String strSch = "c1:collection(f1:int, f2:int), c2:collection(c3:collection(f3:float, f4))";
+  String strSch = "c1:collection(record(f1:int, f2:int)), c2:collection(record(c3:collection(record(f3:float, f4))))";
   TableSchemaParser parser;
   Schema schema;
 
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageGrammar.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageGrammar.java
index cdea351cf..1d7bc288c 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageGrammar.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageGrammar.java
@@ -52,7 +52,7 @@ import org.junit.Test;
  */
 public class TestStorageGrammar {
 
-  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(f13:double, f14:float, f15:bytes),s7:string, s8:string, s9:string, s10:string, s11:string, s12:string, s13:string, s14:string, s15:string, s16:string, s17:string, s18:string, s19:string, s20:string, s21:string, s22:string, s23:string";
+  final static String STR_SCHEMA = "s1:bool, s2:int, s3:long, s4:float, s5:string, s6:bytes, r1:record(f1:int, f2:long), r2:record(r3:record(f3:float, f4)), m1:map(string),m2:map(map(int)), c:collection(record(f13:double, f14:float, f15:bytes)),s7:string, s8:string, s9:string, s10:string, s11:string, s12:string, s13:string, s14:string, s15:string, s16:string, s17:string, s18:string, s19:string, s20:string, s21:string, s22:string, s23:string";
   static String STR_STORAGE = null;
   final private static Configuration conf = new Configuration();
   private static Path path;
@@ -210,7 +210,7 @@ public class TestStorageGrammar {
 
     // c:collection(f13:double, f14:float, f15:bytes)
     DataBag bagColl = TypesUtils.createBag();
-    Schema schColl = schema.getColumn(10).getSchema();
+    Schema schColl = schema.getColumn(10).getSchema().getColumn(0).getSchema();
     Tuple tupColl1 = TypesUtils.createTuple(schColl);
     Tuple tupColl2 = TypesUtils.createTuple(schColl);
     byte[] abs1 = new byte[3];
@@ -395,7 +395,7 @@ public class TestStorageGrammar {
 
   @Test
   public void test4() throws IOException, ParseException {
-    String schema = "s3:string, s4:string, r2:record(r3:record(f3:float, f4)), c:collection(f13:double, f14:float, f15:bytes)";
+    String schema = "s3:string, s4:string, r2:record(r3:record(f3:float, f4)), c:collection(record(f13:double, f14:float, f15:bytes))";
     String storage = "[s3, s4, r2.r3.f3, c] SERIALIZE BY pig SECURE BY uid:"
         + user + " gid:" + group + " perm:777 COMPRESS BY gz";
     Path path1 = new Path(path.toString() + "4");
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageMisc3.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageMisc3.java
index 8c6852b59..22c2f0401 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageMisc3.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestStorageMisc3.java
@@ -35,7 +35,7 @@ import org.junit.Before;
 import org.junit.Test;
 
 public class TestStorageMisc3 {
-  String strSch = "c:collection(r:record(f1:int, f2:int)), m1:map(int)";
+  String strSch = "c:collection(record(f1:int, f2:int)), m1:map(int)";
   TableSchemaParser parser;
   Schema schema;
 
diff --git a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestZebraTupleTostring.java b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestZebraTupleTostring.java
index aea601d02..4eb6df39e 100644
--- a/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestZebraTupleTostring.java
+++ b/contrib/zebra/src/test/org/apache/hadoop/zebra/types/TestZebraTupleTostring.java
@@ -127,7 +127,7 @@ public class TestZebraTupleTostring {
   @Test
   public void testCollection() throws IOException, ParseException {
     String STR_SCHEMA = 
-      "c1:collection(a:double, b:float, c:bytes),c2:collection(r1:record(f1:int, f2:string), d:string),c3:collection(c3_1:collection(e:int,f:bool))";
+      "c1:collection(record(a:double, b:float, c:bytes)),c2:collection(record(r1:record(f1:int, f2:string), d:string)),c3:collection(record(c3_1:collection(record(e:int,f:bool))))";
     Schema schema = new Schema(STR_SCHEMA);
     Tuple tuple = TypesUtils.createTuple(schema);
     TypesUtils.resetTuple(tuple);
