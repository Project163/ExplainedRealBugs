diff --git a/CHANGES.txt b/CHANGES.txt
index d3ad0f71f..c14285137 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -182,6 +182,8 @@ PIG-1696: Performance: Use System.arraycopy() instead of manually copying the by
 
 BUG FIXES
 
+PIG-1814: mapred.output.compress in SET statement does not work (daijy)
+
 PIG-1976: One more TwoLevelAccess to remove (daijy)
 
 PIG-1865: BinStorage/PigStorageSchema cannot load data from a different namenode (daijy)
diff --git a/src/org/apache/pig/PigServer.java b/src/org/apache/pig/PigServer.java
index 1f22e2d16..02b701b94 100644
--- a/src/org/apache/pig/PigServer.java
+++ b/src/org/apache/pig/PigServer.java
@@ -242,16 +242,6 @@ public class PigServer {
             pigContext.connect();
         }
 
-        if( "true".equals( pigContext.getProperties().getProperty( "mapred.output.compress" ) ) ) {
-            pigContext.getProperties().setProperty( "output.compression.enabled",  "true" );
-            String codec = pigContext.getProperties().getProperty( "mapred.output.compression.codec" );
-            if( codec == null ) {
-                throw new RuntimeException( "'mapred.output.compress' is set but no value is specified for 'mapred.output.compression.codec'." );
-            } else {
-                pigContext.getProperties().setProperty( "output.compression.codec", codec );
-            }
-        }
-
         addJarsFromProperties();
     }
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index 48ec5202d..04f07a2bf 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -356,6 +356,17 @@ public class JobControlCompiler{
         }else{
             log.info("mapred.job.reduce.markreset.buffer.percent is set to " + conf.get("mapred.job.reduce.markreset.buffer.percent"));
         }        
+        
+        // Convert mapred.output.* to output.compression.*, See PIG-1791
+        if( "true".equals( conf.get( "mapred.output.compress" ) ) ) {
+            conf.set( "output.compression.enabled",  "true" );
+            String codec = conf.get( "mapred.output.compression.codec" );
+            if( codec == null ) {
+                throw new JobCreationException("'mapred.output.compress' is set but no value is specified for 'mapred.output.compression.codec'." );
+            } else {
+                conf.set( "output.compression.codec", codec );
+            }
+        }
                 
         try{        
             //Process the POLoads
diff --git a/test/org/apache/pig/test/TestBZip.java b/test/org/apache/pig/test/TestBZip.java
index ced1262d2..ab146d1eb 100644
--- a/test/org/apache/pig/test/TestBZip.java
+++ b/test/org/apache/pig/test/TestBZip.java
@@ -18,16 +18,16 @@
 package org.apache.pig.test;
 
 import static org.junit.Assert.*;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotSame;
 
 import java.io.BufferedReader;
 import java.io.BufferedWriter;
 import java.io.File;
+import java.io.FileInputStream;
 import java.io.FileOutputStream;
 import java.io.FileReader;
 import java.io.FileWriter;
 import java.io.IOException;
+import java.io.PrintWriter;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Properties;
@@ -53,6 +53,7 @@ import org.junit.AfterClass;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
+
 @RunWith(JUnit4.class)
 public class TestBZip {
     static MiniCluster cluster = MiniCluster.buildCluster();
@@ -578,4 +579,40 @@ public class TestBZip {
     	out.close();
     }
     
+    // See PIG-1714
+    @Test
+    public void testBzipStoreInMultiQuery3() throws Exception {
+        String[] inputData = new String[] {
+                "1\t2\r3\t4"
+        };
+        
+        String inputFileName = "input3.txt";
+        Util.createInputFile(cluster, inputFileName, inputData);
+
+        String inputScript = "set mapred.output.compress true\n" +
+                "set mapred.output.compression.codec org.apache.hadoop.io.compress.BZip2Codec\n" +
+                "a = load '" + inputFileName + "';\n" +
+                "store a into 'output3.bz2';\n" +
+                "store a into 'output3';";
+        
+        String inputScriptName = "script3.txt";
+        PrintWriter pw = new PrintWriter(new FileWriter(inputScriptName));
+        pw.println(inputScript);
+        pw.close();
+        
+        PigServer pig = new PigServer(ExecType.MAPREDUCE, cluster
+                .getProperties());
+        
+        FileInputStream fis = new FileInputStream(inputScriptName);
+        pig.registerScript(fis);
+        
+        FileSystem fs = FileSystem.get(ConfigurationUtil.toConfiguration(
+                pig.getPigContext().getProperties()));
+        FileStatus stat = fs.getFileStatus(new Path("output3/part-m-00000.bz2"));        
+        assertTrue(stat.getLen() > 0);     
+        
+        stat = fs.getFileStatus(new Path("output3.bz2/part-m-00000.bz2"));
+        assertTrue(stat.getLen() > 0);     
+    }
+ 
 }
