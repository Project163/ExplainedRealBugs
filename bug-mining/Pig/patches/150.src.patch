diff --git a/CHANGES.txt b/CHANGES.txt
index 77eac065e..d479800ab 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -378,3 +378,6 @@ Trunk (unreleased changes)
     PIG-615: Wrong number of jobs with limit (shravanmn via sms)
 
     PIG-635: POCast.java has incorrect formatting (sms)
+
+    PIG-634: When POUnion is one of the roots of a map plan, POUnion.getNext()
+    gives a null pointer exception (pradeepk)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POUnion.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POUnion.java
index 731179fba..471e31dbd 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POUnion.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POUnion.java
@@ -124,7 +124,29 @@ public class POUnion extends PhysicalOperator {
 
         // Case 1 : Normal connected plan
         if (!isInputAttached()) {
-
+            
+            if (inputs == null || inputs.size()==0) {
+                // Neither does this Union have predecessors nor
+                // was any input attached! This can happen when we have
+                // a plan like below
+                // POUnion
+                // |
+                // |--POLocalRearrange
+                // |    |
+                // |    |-POUnion (root 2)--> This union's getNext() can lead the code here
+                // |
+                // |--POLocalRearrange (root 1)
+                
+                // The inner POUnion above is a root in the plan which has 2 roots.
+                // So these 2 roots would have input coming from different input
+                // sources (dfs files). So certain maps would be working on input only
+                // meant for "root 1" above and some maps would work on input
+                // meant only for "root 2". In the former case, "root 2" would
+                // neither get input attached to it nor does it have predecessors
+                // which is the case which can lead us here.
+                return eopResult;
+            }
+          
             while(true){
                 if (done.nextClearBit(0) >= inputs.size()) {
                     clearDone();
diff --git a/test/org/apache/pig/test/TestUnion.java b/test/org/apache/pig/test/TestUnion.java
index 7de8b8edf..c47c30d91 100644
--- a/test/org/apache/pig/test/TestUnion.java
+++ b/test/org/apache/pig/test/TestUnion.java
@@ -21,8 +21,11 @@ import static org.junit.Assert.assertEquals;
 
 import java.io.File;
 import java.io.IOException;
+import java.util.Iterator;
 
+import org.apache.pig.ExecType;
 import org.apache.pig.FuncSpec;
+import org.apache.pig.PigServer;
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.builtin.PigStorage;
 import org.apache.pig.data.DataBag;
@@ -167,4 +170,50 @@ public class TestUnion extends junit.framework.TestCase {
         assertEquals(true, TestHelper.compareBags(expBag, outBag));
     }
 
+    // Test the case when POUnion is one of the roots in a map reduce
+    // plan and the input to it can be null
+    // This can happen when we have
+    // a plan like below
+    // POUnion
+    // |
+    // |--POLocalRearrange
+    // |    |
+    // |    |-POUnion (root 2)--> This union's getNext() can lead the code here
+    // |
+    // |--POLocalRearrange (root 1)
+    
+    // The inner POUnion above is a root in the plan which has 2 roots.
+    // So these 2 roots would have input coming from different input
+    // sources (dfs files). So certain maps would be working on input only
+    // meant for "root 1" above and some maps would work on input
+    // meant only for "root 2". In the former case, "root 2" would
+    // neither get input attached to it nor does it have predecessors
+    @Test
+    public void testGetNextNullInput() throws Exception {
+        Util.createInputFile(cluster, "a.txt", new String[] {"1\t2\t3", "4\t5\t6"});
+        Util.createInputFile(cluster, "b.txt", new String[] {"7\t8\t9", "1\t200\t300"});
+        Util.createInputFile(cluster, "c.txt", new String[] {"1\t20\t30"});
+        PigServer pig = new PigServer(ExecType.MAPREDUCE, cluster.getProperties());
+        pig.registerQuery("a = load 'a.txt' ;");
+        pig.registerQuery("b = load 'b.txt';");
+        pig.registerQuery("c = union a, b;");
+        pig.registerQuery("d = load 'c.txt' ;");
+        pig.registerQuery("e = cogroup c by $0 inner, d by $0 inner;");
+        pig.explain("e", System.err);
+        // output should be 
+        // (1,{(1,2,3),(1,200,300)},{(1,20,30)})
+        Tuple expectedResult = new DefaultTuple();
+        expectedResult.append(new DataByteArray("1"));
+        Tuple[] secondFieldContents = new DefaultTuple[2];
+        secondFieldContents[0] = Util.createTuple(Util.toDataByteArrays(new String[] {"1", "2", "3"}));
+        secondFieldContents[1] = Util.createTuple(Util.toDataByteArrays(new String[] {"1", "200", "300"}));
+        DataBag secondField = Util.createBag(secondFieldContents);
+        expectedResult.append(secondField);
+        DataBag thirdField = Util.createBag(new Tuple[]{Util.createTuple(Util.toDataByteArrays(new String[]{"1", "20", "30"}))});
+        expectedResult.append(thirdField);
+        Iterator<Tuple> it = pig.openIterator("e");
+        assertEquals(expectedResult, it.next());
+        assertFalse(it.hasNext());
+    }
+    
 }
