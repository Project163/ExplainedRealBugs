diff --git a/src/org/apache/pig/PigConfiguration.java b/src/org/apache/pig/PigConfiguration.java
index 4114e312e..b152f12aa 100644
--- a/src/org/apache/pig/PigConfiguration.java
+++ b/src/org/apache/pig/PigConfiguration.java
@@ -270,4 +270,9 @@ public class PigConfiguration {
      * This key is used to turns off use of task reports in job statistics.
      */
     public static final String PIG_NO_TASK_REPORT = "pig.stats.notaskreport";
+    
+    public static final String PIG_CROSS_PARALLELISM_HINT = "pig.cross.parallelism.hint";
+
+    public static final String REDUCER_ESTIMATOR_KEY = "pig.exec.reducer.estimator";
+    public static final String REDUCER_ESTIMATOR_ARG_KEY =  "pig.exec.reducer.estimator.arg";
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index fc20cf08d..412261967 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -61,6 +61,7 @@ import org.apache.hadoop.mapred.jobcontrol.Job;
 import org.apache.hadoop.mapred.jobcontrol.JobControl;
 import org.apache.pig.ComparisonFunc;
 import org.apache.pig.ExecType;
+import org.apache.pig.FuncSpec;
 import org.apache.pig.LoadFunc;
 import org.apache.pig.OverwritableStoreFunc;
 import org.apache.pig.PigConfiguration;
@@ -95,6 +96,7 @@ import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.impl.PigImplConstants;
+import org.apache.pig.impl.builtin.GFCross;
 import org.apache.pig.impl.io.FileLocalizer;
 import org.apache.pig.impl.io.FileSpec;
 import org.apache.pig.impl.io.NullableBigDecimalWritable;
@@ -544,6 +546,22 @@ public class JobControlCompiler{
                 nwJob.setNumReduceTasks(0);
             }
 
+            for (String udf : mro.UDFs) {
+                if (udf.contains("GFCross")) {
+                    Object func = pigContext.instantiateFuncFromSpec(new FuncSpec(udf));
+                    if (func instanceof GFCross) {
+                        String crossKey = ((GFCross)func).getCrossKey();
+                        // If non GFCross has been processed yet
+                        if (pigContext.getProperties().get(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + "." + crossKey)==null) {
+                            pigContext.getProperties().setProperty(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + "." + crossKey,
+                                    Integer.toString(nwJob.getNumReduceTasks()));
+                        }
+                        conf.set(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + "." + crossKey,
+                                (String)pigContext.getProperties().get(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + "." + crossKey));
+                    }
+                }
+            }
+
             if(lds!=null && lds.size()>0){
                 for (POLoad ld : lds) {
                     //Store the target operators for tuples read
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POGlobalRearrange.java b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POGlobalRearrange.java
index dabcca540..52cfb73be 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POGlobalRearrange.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/physicalLayer/relationalOperators/POGlobalRearrange.java
@@ -49,6 +49,8 @@ public class POGlobalRearrange extends PhysicalOperator {
      */
     protected String customPartitioner;
 
+    private boolean cross = false;
+
     public String getCustomPartitioner() {
 		return customPartitioner;
 	}
@@ -104,4 +106,12 @@ public class POGlobalRearrange extends PhysicalOperator {
     public Tuple illustratorMarkup(Object in, Object out, int eqClassIndex) {
       return null;
     }
+
+    public void setCross(boolean cross) {
+        this.cross = cross;
+    }
+
+    public boolean isCross() {
+        return cross;
+    }
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezCompiler.java
index 638653579..73e6cea79 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezCompiler.java
@@ -862,6 +862,9 @@ public class TezCompiler extends PhyPlanVisitor {
             blocking();
             TezCompilerUtil.setCustomPartitioner(op.getCustomPartitioner(), curTezOp);
             curTezOp.setRequestedParallelism(op.getRequestedParallelism());
+            if (op.isCross()) {
+                curTezOp.setCrossKey(op.getOperatorKey().toString());
+            }
             phyToTezOpMap.put(op, curTezOp);
         } catch (Exception e) {
             int errCode = 2034;
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezDagBuilder.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezDagBuilder.java
index fb86aa874..3fd1e7257 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezDagBuilder.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezDagBuilder.java
@@ -39,7 +39,6 @@ import org.apache.hadoop.mapreduce.Job;
 import org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager;
 import org.apache.hadoop.mapreduce.v2.util.MRApps;
 import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.pig.LoadFunc;
 import org.apache.pig.PigConfiguration;
 import org.apache.pig.PigException;
 import org.apache.pig.StoreFuncInterface;
@@ -93,15 +92,12 @@ import org.apache.pig.backend.hadoop.executionengine.physicalLayer.util.PlanHelp
 import org.apache.pig.backend.hadoop.executionengine.tez.TezPOPackageAnnotator.LoRearrangeDiscoverer;
 import org.apache.pig.backend.hadoop.executionengine.tez.util.MRToTezHelper;
 import org.apache.pig.backend.hadoop.executionengine.tez.util.SecurityHelper;
-import org.apache.pig.backend.hadoop.executionengine.util.ParallelConstantVisitor;
 import org.apache.pig.data.DataType;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.impl.io.FileLocalizer;
-import org.apache.pig.impl.io.FileSpec;
 import org.apache.pig.impl.io.NullablePartitionWritable;
 import org.apache.pig.impl.io.NullableTuple;
 import org.apache.pig.impl.plan.DependencyOrderWalker;
-import org.apache.pig.impl.plan.NodeIdGenerator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.pig.impl.util.ObjectSerializer;
@@ -125,7 +121,6 @@ import org.apache.tez.dag.library.vertexmanager.ShuffleVertexManager;
 import org.apache.tez.mapreduce.combine.MRCombiner;
 import org.apache.tez.mapreduce.committer.MROutputCommitter;
 import org.apache.tez.mapreduce.common.MRInputSplitDistributor;
-import org.apache.tez.mapreduce.hadoop.InputSplitInfo;
 import org.apache.tez.mapreduce.hadoop.MRHelpers;
 import org.apache.tez.mapreduce.hadoop.MRJobConfig;
 import org.apache.tez.mapreduce.input.MRInput;
@@ -142,17 +137,11 @@ import org.apache.tez.runtime.library.input.SortedGroupedMergedInput;
 public class TezDagBuilder extends TezOpPlanVisitor {
     private static final Log log = LogFactory.getLog(TezJobCompiler.class);
 
-    private static final String REDUCER_ESTIMATOR_KEY = "pig.exec.reducer.estimator";
-    private static final String REDUCER_ESTIMATOR_ARG_KEY =  "pig.exec.reducer.estimator.arg";
-
     private DAG dag;
     private Map<String, LocalResource> localResources;
     private PigContext pc;
     private Configuration globalConf;
 
-    private String scope;
-    private NodeIdGenerator nig;
-
     public TezDagBuilder(PigContext pc, TezOperPlan plan, DAG dag,
             Map<String, LocalResource> localResources) {
         super(plan, new DependencyOrderWalker<TezOperator, TezOperPlan>(plan));
@@ -160,8 +149,6 @@ public class TezDagBuilder extends TezOpPlanVisitor {
         this.globalConf = ConfigurationUtil.toConfiguration(pc.getProperties(), true);
         this.localResources = localResources;
         this.dag = dag;
-        this.scope = plan.getRoots().get(0).getOperatorKey().getScope();
-        this.nig = NodeIdGenerator.getGenerator();
 
         try {
             // Add credentials from binary token file and get tokens for namenodes
@@ -425,7 +412,10 @@ public class TezDagBuilder extends TezOpPlanVisitor {
         if (maxCombinedSplitSize > 0)
             payloadConf.setLong("pig.maxCombinedSplitSize", maxCombinedSplitSize);
 
-        List<POLoad> loads = processLoads(tezOp, payloadConf, job);
+        payloadConf.set("pig.inputs", ObjectSerializer.serialize(tezOp.getLoaderInfo().getInp()));
+        payloadConf.set("pig.inpSignatures", ObjectSerializer.serialize(tezOp.getLoaderInfo().getInpSignatureLists()));
+        payloadConf.set("pig.inpLimits", ObjectSerializer.serialize(tezOp.getLoaderInfo().getInpLimits()));
+        // Process stores
         LinkedList<POStore> stores = processStores(tezOp, payloadConf, job);
 
         payloadConf.set("pig.pigContext", ObjectSerializer.serialize(pc));
@@ -559,88 +549,6 @@ public class TezDagBuilder extends TezOpPlanVisitor {
                     ObjectSerializer.serialize(stores));
         }
 
-        // Can only set parallelism here if the parallelism isn't derived from
-        // splits
-        int parallelism = -1;
-        InputSplitInfo inputSplitInfo = null;
-        if (loads != null && loads.size() > 0) {
-            // Not using MRInputAMSplitGenerator because delegation tokens are
-            // fetched in FileInputFormat
-            inputSplitInfo = MRHelpers.generateInputSplitsToMem(payloadConf);
-            // TODO: Can be set to -1 if TEZ-601 gets fixed and getting input
-            // splits can be moved to if(loads) block below
-            parallelism = inputSplitInfo.getNumTasks();
-            tezOp.setRequestedParallelism(parallelism);
-        } else {
-            int prevParallelism = -1;
-            boolean isOneToOneParallelism = false;
-            for (Map.Entry<OperatorKey,TezEdgeDescriptor> entry : tezOp.inEdges.entrySet()) {
-                if (entry.getValue().dataMovementType == DataMovementType.ONE_TO_ONE) {
-                    TezOperator pred = mPlan.getOperator(entry.getKey());
-                    parallelism = pred.getEffectiveParallelism();
-                    if (prevParallelism == -1) {
-                        prevParallelism = parallelism;
-                    } else if (prevParallelism != parallelism) {
-                        throw new IOException("one to one sources parallelism for vertex "
-                                + tezOp.getOperatorKey().toString() + " are not equal");
-                    }
-                    if (pred.getRequestedParallelism()!=-1) {
-                        tezOp.setRequestedParallelism(pred.getRequestedParallelism());
-                    } else {
-                        tezOp.setEstimatedParallelism(pred.getEstimatedParallelism());
-                    }
-                    isOneToOneParallelism = true;
-                    parallelism = -1;
-                }
-            }
-            if (!isOneToOneParallelism) {
-                if (tezOp.getRequestedParallelism()!=-1) {
-                    parallelism = tezOp.getRequestedParallelism();
-                } else if (pc.defaultParallel!=-1) {
-                    parallelism = pc.defaultParallel;
-                } else {
-                    parallelism = estimateParallelism(job, mPlan, tezOp);
-                    tezOp.setEstimatedParallelism(parallelism);
-                    if (tezOp.isGlobalSort()||tezOp.isSkewedJoin()) {
-                        // Vertex manager will set parallelism
-                        parallelism = -1;
-                    }
-                }
-            }
-        }
-
-        // Once we decide the parallelism of the sampler, propagate to
-        // downstream operators if necessary
-        if (tezOp.isSampler()) {
-            // There could be multiple sampler and share the same sample aggregation job
-            // and partitioner job
-            TezOperator sampleAggregationOper = null;
-            TezOperator sampleBasedPartionerOper = null;
-            TezOperator sortOper = null;
-            for (TezOperator succ : mPlan.getSuccessors(tezOp)) {
-                if (succ.isVertexGroup()) {
-                    succ = mPlan.getSuccessors(succ).get(0);
-                }
-                if (succ.isSampleAggregation()) {
-                    sampleAggregationOper = succ;
-                } else if (succ.isSampleBasedPartitioner()) {
-                    sampleBasedPartionerOper = succ;
-                }
-            }
-            sortOper = mPlan.getSuccessors(sampleBasedPartionerOper).get(0);
-
-            if (sortOper.getRequestedParallelism()==-1 && pc.defaultParallel==-1) {
-                // set estimate parallelism for order by/skewed join to sampler parallelism
-                // that include:
-                // 1. sort operator
-                // 2. constant for sample aggregation oper
-                sortOper.setEstimatedParallelism(parallelism);
-                ParallelConstantVisitor visitor =
-                        new ParallelConstantVisitor(sampleAggregationOper.plan, parallelism);
-                visitor.visit();
-            }
-        }
-
         if (tezOp.isNeedEstimateParallelism()) {
             payloadConf.setBoolean(PigProcessor.ESTIMATE_PARALLELISM, true);
             log.info("Estimate quantile for sample aggregation vertex " + tezOp.getOperatorKey().toString());
@@ -650,7 +558,7 @@ public class TezDagBuilder extends TezOpPlanVisitor {
         byte[] userPayload = TezUtils.createUserPayloadFromConf(payloadConf);
         procDesc.setUserPayload(userPayload);
 
-        Vertex vertex = new Vertex(tezOp.getOperatorKey().toString(), procDesc, parallelism,
+        Vertex vertex = new Vertex(tezOp.getOperatorKey().toString(), procDesc, tezOp.getVertexParallelism(),
                 isMap ? MRHelpers.getMapResource(globalConf) : MRHelpers.getReduceResource(globalConf));
 
         Map<String, String> taskEnv = new HashMap<String, String>();
@@ -671,23 +579,23 @@ public class TezDagBuilder extends TezOpPlanVisitor {
                 : MRHelpers.getReduceJavaOpts(globalConf));
 
         log.info("For vertex - " + tezOp.getOperatorKey().toString()
-                + ": parallelism=" + parallelism
+                + ": parallelism=" + tezOp.getVertexParallelism()
                 + ", memory=" + vertex.getTaskResource().getMemory()
                 + ", java opts=" + vertex.getTaskLaunchCmdOpts()
                 );
 
         // Right now there can only be one of each of these. Will need to be
         // more generic when there can be more.
-        for (POLoad ld : loads) {
+        for (POLoad ld : tezOp.getLoaderInfo().getLoads()) {
 
             // TODO: These should get the globalConf, or a merged version that
             // keeps settings like pig.maxCombinedSplitSize
-            vertex.setTaskLocationsHint(inputSplitInfo.getTaskLocationHints());
+            vertex.setTaskLocationsHint(tezOp.getLoaderInfo().getInputSplitInfo().getTaskLocationHints());
             vertex.addDataSource(ld.getOperatorKey().toString(),
                     new InputDescriptor(MRInput.class.getName())
                             .setUserPayload(MRHelpers.createMRInputPayload(
                                     userPayload,
-                                    inputSplitInfo.getSplitsProto())),
+                                    tezOp.getLoaderInfo().getInputSplitInfo().getSplitsProto())),
                     new InputInitializerDescriptor(MRInputSplitDistributor.class.getName()));
         }
 
@@ -772,76 +680,6 @@ public class TezDagBuilder extends TezOpPlanVisitor {
         return vertex;
     }
 
-    /**
-     * Do the final configuration of LoadFuncs and store what goes where. This
-     * will need to be changed as the inputs get un-bundled
-     *
-     * @param tezOp
-     * @param conf
-     * @param job
-     * @return true if any POLoads were found, else false.
-     * @throws VisitorException
-     * @throws IOException
-     */
-    private List<POLoad> processLoads(TezOperator tezOp, Configuration conf,
-            Job job) throws VisitorException, IOException {
-        ArrayList<FileSpec> inp = new ArrayList<FileSpec>();
-        ArrayList<List<OperatorKey>> inpTargets = new ArrayList<List<OperatorKey>>();
-        ArrayList<String> inpSignatureLists = new ArrayList<String>();
-        ArrayList<Long> inpLimits = new ArrayList<Long>();
-
-        List<POLoad> lds = PlanHelper.getPhysicalOperators(tezOp.plan,
-                POLoad.class);
-
-        if (lds != null && lds.size() > 0) {
-            for (POLoad ld : lds) {
-                LoadFunc lf = ld.getLoadFunc();
-                lf.setLocation(ld.getLFile().getFileName(), job);
-
-                // Store the inp filespecs
-                inp.add(ld.getLFile());
-            }
-        }
-
-        if (lds != null && lds.size() > 0) {
-            for (POLoad ld : lds) {
-                // Store the target operators for tuples read
-                // from this input
-                List<PhysicalOperator> ldSucs = new ArrayList<PhysicalOperator>(
-                        tezOp.plan.getSuccessors(ld));
-                List<OperatorKey> ldSucKeys = new ArrayList<OperatorKey>();
-                if (ldSucs != null) {
-                    for (PhysicalOperator operator2 : ldSucs) {
-                        ldSucKeys.add(operator2.getOperatorKey());
-                    }
-                }
-                inpTargets.add(ldSucKeys);
-                inpSignatureLists.add(ld.getSignature());
-                inpLimits.add(ld.getLimit());
-                // Remove the POLoad from the plan
-                tezOp.plan.remove(ld);
-                // Now add the input handling operator for the Tez backend
-                // TODO: Move this upstream to the PhysicalPlan generation
-                POSimpleTezLoad tezLoad = new POSimpleTezLoad(new OperatorKey(
-                        scope, nig.getNextNodeId(scope)), ld.getLFile());
-                tezLoad.setInputKey(ld.getOperatorKey().toString());
-                tezLoad.copyAliasFrom(ld);
-                tezOp.plan.add(tezLoad);
-                for (PhysicalOperator sucs : ldSucs) {
-                    tezOp.plan.connect(tezLoad, sucs);
-                }
-
-            }
-        }
-
-        conf.set("pig.inputs", ObjectSerializer.serialize(inp));
-        conf.set("pig.inpTargets", ObjectSerializer.serialize(inpTargets));
-        conf.set("pig.inpSignatures", ObjectSerializer.serialize(inpSignatureLists));
-        conf.set("pig.inpLimits", ObjectSerializer.serialize(inpLimits));
-
-        return lds;
-    }
-
     private LinkedList<POStore> processStores(TezOperator tezOp,
             Configuration payloadConf, Job job) throws VisitorException,
             IOException {
@@ -1107,19 +945,4 @@ public class TezDagBuilder extends TezOpPlanVisitor {
         conf.set(TezRuntimeConfiguration.TEZ_RUNTIME_KEY_SECONDARY_COMPARATOR_CLASS,
                 comparatorClass);
     }
-
-    public static int estimateParallelism(Job job, TezOperPlan tezPlan,
-            TezOperator tezOp) throws IOException {
-        Configuration conf = job.getConfiguration();
-
-        TezParallelismEstimator estimator = conf.get(REDUCER_ESTIMATOR_KEY) == null ? new TezOperDependencyParallelismEstimator()
-                : PigContext.instantiateObjectFromParams(conf,
-                        REDUCER_ESTIMATOR_KEY, REDUCER_ESTIMATOR_ARG_KEY,
-                        TezParallelismEstimator.class);
-
-        log.info("Using parallel estimator: " + estimator.getClass().getName());
-        int numberOfReducers = estimator.estimateParallelism(tezPlan, tezOp, conf);
-        return numberOfReducers;
-    }
-
 }
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java
index 7e7066232..9a48e30ad 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezLauncher.java
@@ -41,7 +41,9 @@ import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
 import org.apache.pig.backend.hadoop.executionengine.Launcher;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStore;
+import org.apache.pig.backend.hadoop.executionengine.tez.optimizers.LoaderProcessor;
 import org.apache.pig.backend.hadoop.executionengine.tez.optimizers.NoopFilterRemover;
+import org.apache.pig.backend.hadoop.executionengine.tez.optimizers.ParallelismSetter;
 import org.apache.pig.backend.hadoop.executionengine.tez.optimizers.UnionOptimizer;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.impl.plan.CompilationMessageCollector;
@@ -323,6 +325,14 @@ public class TezLauncher extends Launcher {
             uo.visit();
         }
 
+        if (!pc.inExplain && !pc.inDumpSchema) {
+            LoaderProcessor loaderStorer = new LoaderProcessor(tezPlan, pc);
+            loaderStorer.visit();
+    
+            ParallelismSetter parallelismSetter = new ParallelismSetter(tezPlan, pc);
+            parallelismSetter.visit();
+        }
+
         return comp.getPlanContainer();
     }
 
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezOperator.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezOperator.java
index d8c61ef1f..244eb2c1a 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/tez/TezOperator.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/TezOperator.java
@@ -27,12 +27,15 @@ import java.util.concurrent.atomic.AtomicInteger;
 
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PhysicalPlan;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad;
 import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POStore;
+import org.apache.pig.impl.io.FileSpec;
 import org.apache.pig.impl.plan.Operator;
 import org.apache.pig.impl.plan.OperatorKey;
 import org.apache.pig.impl.plan.VisitorException;
 import org.apache.tez.dag.api.OutputDescriptor;
 import org.apache.tez.dag.api.VertexGroup;
+import org.apache.tez.mapreduce.hadoop.InputSplitInfo;
 
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
@@ -65,6 +68,12 @@ public class TezOperator extends Operator<TezOpPlanVisitor> {
     
     private int estimatedParallelism = -1;
 
+    // This is the parallelism of the vertex, it take account of:
+    // 1. default_parallel
+    // 2. -1 parallelism for one_to_one edge
+    // 3. -1 parallelism for sort/skewed join
+    private int vertexParallelism = -1;
+
     // TODO: When constructing Tez vertex, we have to specify how much resource
     // the vertex will need. So we need to estimate these values while compiling
     // physical plan into tez plan. For now, we're using default values - 1G mem
@@ -123,6 +132,8 @@ public class TezOperator extends Operator<TezOpPlanVisitor> {
     // If true, we will use secondary key sort in the job
     private boolean useSecondaryKey = false;
 
+    private String crossKey = null;
+
     // Types of blocking operators. For now, we only support the following ones.
     private static enum OPER_FEATURE {
         NONE,
@@ -150,6 +161,46 @@ public class TezOperator extends Operator<TezOpPlanVisitor> {
     // Mapping of OperatorKey of POStore OperatorKey to vertexGroup TezOperator
     private Map<OperatorKey, OperatorKey> vertexGroupStores = null;
 
+    public static class LoaderInfo {
+        private List<POLoad> loads = null;
+        private ArrayList<FileSpec> inp = new ArrayList<FileSpec>();
+        private ArrayList<String> inpSignatureLists = new ArrayList<String>();
+        private ArrayList<Long> inpLimits = new ArrayList<Long>();
+        private InputSplitInfo inputSplitInfo = null;
+        public List<POLoad> getLoads() {
+            return loads;
+        }
+        public void setLoads(List<POLoad> loads) {
+            this.loads = loads;
+        }
+        public ArrayList<FileSpec> getInp() {
+            return inp;
+        }
+        public void setInp(ArrayList<FileSpec> inp) {
+            this.inp = inp;
+        }
+        public ArrayList<String> getInpSignatureLists() {
+            return inpSignatureLists;
+        }
+        public void setInpSignatureLists(ArrayList<String> inpSignatureLists) {
+            this.inpSignatureLists = inpSignatureLists;
+        }
+        public ArrayList<Long> getInpLimits() {
+            return inpLimits;
+        }
+        public void setInpLimits(ArrayList<Long> inpLimits) {
+            this.inpLimits = inpLimits;
+        }
+        public InputSplitInfo getInputSplitInfo() {
+            return inputSplitInfo;
+        }
+        public void setInputSplitInfo(InputSplitInfo inputSplitInfo) {
+            this.inputSplitInfo = inputSplitInfo;
+        }
+    }
+
+    private LoaderInfo loaderInfo = new LoaderInfo();
+
     public TezOperator(OperatorKey k) {
         super(k);
         plan = new PhysicalPlan();
@@ -444,6 +495,26 @@ public class TezOperator extends Operator<TezOpPlanVisitor> {
         return combineSmallSplits;
     }
 
+    public void setCrossKey(String key) {
+        crossKey = key;
+    }
+
+    public String getCrossKey() {
+        return crossKey;
+    }
+
+    public int getVertexParallelism() {
+        return vertexParallelism;
+    }
+
+    public void setVertexParallelism(int vertexParallelism) {
+        this.vertexParallelism = vertexParallelism;
+    }
+
+    public LoaderInfo getLoaderInfo() {
+        return loaderInfo;
+    }
+
     public static class VertexGroupInfo {
 
         private List<OperatorKey> inputKeys;
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/optimizers/LoaderProcessor.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/optimizers/LoaderProcessor.java
new file mode 100644
index 000000000..c765ccf87
--- /dev/null
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/optimizers/LoaderProcessor.java
@@ -0,0 +1,144 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.backend.hadoop.executionengine.tez.optimizers;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.mapreduce.InputFormat;
+import org.apache.hadoop.mapreduce.Job;
+import org.apache.pig.LoadFunc;
+import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
+import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLoad;
+import org.apache.pig.backend.hadoop.executionengine.physicalLayer.util.PlanHelper;
+import org.apache.pig.backend.hadoop.executionengine.tez.POSimpleTezLoad;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezOpPlanVisitor;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezOperPlan;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezOperator;
+import org.apache.pig.impl.PigContext;
+import org.apache.pig.impl.io.FileSpec;
+import org.apache.pig.impl.plan.DependencyOrderWalker;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.VisitorException;
+import org.apache.pig.impl.util.ObjectSerializer;
+import org.apache.pig.impl.util.UDFContext;
+import org.apache.tez.mapreduce.hadoop.MRHelpers;
+
+public class LoaderProcessor extends TezOpPlanVisitor {
+    private Configuration conf;
+    private PigContext pc;
+    public LoaderProcessor(TezOperPlan plan, PigContext pigContext) {
+        super(plan, new DependencyOrderWalker<TezOperator, TezOperPlan>(plan));
+        this.pc = pigContext;
+        this.conf = ConfigurationUtil.toConfiguration(pc.getProperties());;
+    }
+
+    /**
+     * Do the final configuration of LoadFuncs and store what goes where. This
+     * will need to be changed as the inputs get un-bundled
+     *
+     * @param tezOp
+     * @param conf
+     * @param job
+     * @return true if any POLoads were found, else false.
+     * @throws VisitorException
+     * @throws IOException
+     * @throws InterruptedException 
+     * @throws ClassNotFoundException 
+     */
+    private List<POLoad> processLoads(TezOperator tezOp
+            ) throws VisitorException, IOException, ClassNotFoundException, InterruptedException {
+        ArrayList<FileSpec> inp = new ArrayList<FileSpec>();
+        ArrayList<List<OperatorKey>> inpTargets = new ArrayList<List<OperatorKey>>();
+        ArrayList<String> inpSignatureLists = new ArrayList<String>();
+        ArrayList<Long> inpLimits = new ArrayList<Long>();
+
+        Job job = Job.getInstance(conf);
+        conf = job.getConfiguration();
+        conf.setBoolean("mapred.mapper.new-api", true);
+        conf.setClass("mapreduce.inputformat.class",
+                PigInputFormat.class, InputFormat.class);
+        conf.set("pig.pigContext", ObjectSerializer.serialize(pc));
+        List<POLoad> lds = PlanHelper.getPhysicalOperators(tezOp.plan,
+                POLoad.class);
+
+        if (lds != null && lds.size() > 0) {
+            for (POLoad ld : lds) {
+                LoadFunc lf = ld.getLoadFunc();
+                lf.setLocation(ld.getLFile().getFileName(), job);
+
+                // Store the inp filespecs
+                inp.add(ld.getLFile());
+            }
+        }
+
+        if (lds != null && lds.size() > 0) {
+            for (POLoad ld : lds) {
+                // Store the target operators for tuples read
+                // from this input
+                List<PhysicalOperator> ldSucs = new ArrayList<PhysicalOperator>(
+                        tezOp.plan.getSuccessors(ld));
+                List<OperatorKey> ldSucKeys = new ArrayList<OperatorKey>();
+                if (ldSucs != null) {
+                    for (PhysicalOperator operator2 : ldSucs) {
+                        ldSucKeys.add(operator2.getOperatorKey());
+                    }
+                }
+                inpTargets.add(ldSucKeys);
+                inpSignatureLists.add(ld.getSignature());
+                inpLimits.add(ld.getLimit());
+                // Remove the POLoad from the plan
+                tezOp.plan.remove(ld);
+                // Now add the input handling operator for the Tez backend
+                // TODO: Move this upstream to the PhysicalPlan generation
+                POSimpleTezLoad tezLoad = new POSimpleTezLoad(ld.getOperatorKey(), ld.getLFile());
+                tezLoad.setInputKey(ld.getOperatorKey().toString());
+                tezLoad.copyAliasFrom(ld);
+                tezOp.plan.add(tezLoad);
+                for (PhysicalOperator sucs : ldSucs) {
+                    tezOp.plan.connect(tezLoad, sucs);
+                }
+            }
+            UDFContext.getUDFContext().serialize(conf);
+            conf.set("pig.inputs", ObjectSerializer.serialize(inp));
+            conf.set("pig.inpTargets", ObjectSerializer.serialize(inpTargets));
+            conf.set("pig.inpSignatures", ObjectSerializer.serialize(inpSignatureLists));
+            conf.set("pig.inpLimits", ObjectSerializer.serialize(inpLimits));
+            tezOp.getLoaderInfo().setInpSignatureLists(inpSignatureLists);
+            tezOp.getLoaderInfo().setInp(inp);
+            tezOp.getLoaderInfo().setInpLimits(inpLimits);
+            // Not using MRInputAMSplitGenerator because delegation tokens are
+            // fetched in FileInputFormat
+            tezOp.getLoaderInfo().setInputSplitInfo(MRHelpers.generateInputSplitsToMem(conf));
+        }
+        return lds;
+    }
+
+    @Override
+    public void visitTezOp(TezOperator tezOp) throws VisitorException {
+        try {
+            tezOp.getLoaderInfo().setLoads(processLoads(tezOp));
+        } catch (Exception e) {
+            throw new VisitorException(e);
+        }
+    }
+}
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/tez/optimizers/ParallelismSetter.java b/src/org/apache/pig/backend/hadoop/executionengine/tez/optimizers/ParallelismSetter.java
new file mode 100644
index 000000000..a37ecfba2
--- /dev/null
+++ b/src/org/apache/pig/backend/hadoop/executionengine/tez/optimizers/ParallelismSetter.java
@@ -0,0 +1,150 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.backend.hadoop.executionengine.tez.optimizers;
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.pig.PigConfiguration;
+import org.apache.pig.backend.hadoop.datastorage.ConfigurationUtil;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezEdgeDescriptor;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezOpPlanVisitor;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezOperDependencyParallelismEstimator;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezOperPlan;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezOperator;
+import org.apache.pig.backend.hadoop.executionengine.tez.TezParallelismEstimator;
+import org.apache.pig.backend.hadoop.executionengine.util.ParallelConstantVisitor;
+import org.apache.pig.impl.PigContext;
+import org.apache.pig.impl.plan.DependencyOrderWalker;
+import org.apache.pig.impl.plan.OperatorKey;
+import org.apache.pig.impl.plan.VisitorException;
+import org.apache.tez.dag.api.EdgeProperty.DataMovementType;
+
+public class ParallelismSetter extends TezOpPlanVisitor {
+    Configuration conf;
+    PigContext pc;
+    public ParallelismSetter(TezOperPlan plan, PigContext pigContext) {
+        super(plan, new DependencyOrderWalker<TezOperator, TezOperPlan>(plan));
+        this.pc = pigContext;
+        this.conf = ConfigurationUtil.toConfiguration(pc.getProperties());
+    }
+
+    @Override
+    public void visitTezOp(TezOperator tezOp) throws VisitorException {
+        try {
+            // Can only set parallelism here if the parallelism isn't derived from
+            // splits
+            int parallelism = -1;
+            if (tezOp.getLoaderInfo().getLoads() != null && tezOp.getLoaderInfo().getLoads().size() > 0) {
+                // TODO: Can be set to -1 if TEZ-601 gets fixed and getting input
+                // splits can be moved to if(loads) block below
+                parallelism = tezOp.getLoaderInfo().getInputSplitInfo().getNumTasks();
+                tezOp.setRequestedParallelism(parallelism);
+            } else {
+                int prevParallelism = -1;
+                boolean isOneToOneParallelism = false;
+                for (Map.Entry<OperatorKey,TezEdgeDescriptor> entry : tezOp.inEdges.entrySet()) {
+                    if (entry.getValue().dataMovementType == DataMovementType.ONE_TO_ONE) {
+                        TezOperator pred = mPlan.getOperator(entry.getKey());
+                        parallelism = pred.getEffectiveParallelism();
+                        if (prevParallelism == -1) {
+                            prevParallelism = parallelism;
+                        } else if (prevParallelism != parallelism) {
+                            throw new VisitorException("one to one sources parallelism for vertex "
+                                    + tezOp.getOperatorKey().toString() + " are not equal");
+                        }
+                        if (pred.getRequestedParallelism()!=-1) {
+                            tezOp.setRequestedParallelism(pred.getRequestedParallelism());
+                        } else {
+                            tezOp.setEstimatedParallelism(pred.getEstimatedParallelism());
+                        }
+                        isOneToOneParallelism = true;
+                        parallelism = -1;
+                    }
+                }
+                if (!isOneToOneParallelism) {
+                    if (tezOp.getRequestedParallelism()!=-1) {
+                        parallelism = tezOp.getRequestedParallelism();
+                    } else if (pc.defaultParallel!=-1) {
+                        parallelism = pc.defaultParallel;
+                    } else {
+                        parallelism = estimateParallelism(mPlan, tezOp);
+                        tezOp.setEstimatedParallelism(parallelism);
+                        if (tezOp.isGlobalSort()||tezOp.isSkewedJoin()) {
+                            // Vertex manager will set parallelism
+                            parallelism = -1;
+                        }
+                    }
+                }
+            }
+
+            // Once we decide the parallelism of the sampler, propagate to
+            // downstream operators if necessary
+            if (tezOp.isSampler()) {
+                // There could be multiple sampler and share the same sample aggregation job
+                // and partitioner job
+                TezOperator sampleAggregationOper = null;
+                TezOperator sampleBasedPartionerOper = null;
+                TezOperator sortOper = null;
+                for (TezOperator succ : mPlan.getSuccessors(tezOp)) {
+                    if (succ.isVertexGroup()) {
+                        succ = mPlan.getSuccessors(succ).get(0);
+                    }
+                    if (succ.isSampleAggregation()) {
+                        sampleAggregationOper = succ;
+                    } else if (succ.isSampleBasedPartitioner()) {
+                        sampleBasedPartionerOper = succ;
+                    }
+                }
+                sortOper = mPlan.getSuccessors(sampleBasedPartionerOper).get(0);
+
+                if (sortOper.getRequestedParallelism()==-1 && pc.defaultParallel==-1) {
+                    // set estimate parallelism for order by/skewed join to sampler parallelism
+                    // that include:
+                    // 1. sort operator
+                    // 2. constant for sample aggregation oper
+                    sortOper.setEstimatedParallelism(parallelism);
+                    ParallelConstantVisitor visitor =
+                            new ParallelConstantVisitor(sampleAggregationOper.plan, parallelism);
+                    visitor.visit();
+                }
+            }
+
+            tezOp.setVertexParallelism(parallelism);
+
+            if (tezOp.getCrossKey()!=null) {
+                pc.getProperties().put(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + "." + tezOp.getCrossKey(),
+                        Integer.toString(tezOp.getVertexParallelism()));
+            }
+        } catch (Exception e) {
+            throw new VisitorException(e);
+        }
+    }
+
+    private int estimateParallelism(TezOperPlan tezPlan, TezOperator tezOp) throws IOException {
+
+        TezParallelismEstimator estimator = conf.get(PigConfiguration.REDUCER_ESTIMATOR_KEY) == null ? new TezOperDependencyParallelismEstimator()
+                : PigContext.instantiateObjectFromParams(conf,
+                        PigConfiguration.REDUCER_ESTIMATOR_KEY, PigConfiguration.REDUCER_ESTIMATOR_ARG_KEY,
+                        TezParallelismEstimator.class);
+
+        int numberOfReducers = estimator.estimateParallelism(tezPlan, tezOp, conf);
+        return numberOfReducers;
+    }
+}
diff --git a/src/org/apache/pig/impl/builtin/GFCross.java b/src/org/apache/pig/impl/builtin/GFCross.java
index 8963fd490..ed15e4364 100644
--- a/src/org/apache/pig/impl/builtin/GFCross.java
+++ b/src/org/apache/pig/impl/builtin/GFCross.java
@@ -21,8 +21,8 @@ import java.io.IOException;
 import java.util.Random;
 
 import org.apache.hadoop.conf.Configuration;
-
 import org.apache.pig.EvalFunc;
+import org.apache.pig.PigConfiguration;
 import org.apache.pig.backend.executionengine.ExecException;
 import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRConfiguration;
 import org.apache.pig.data.BagFactory;
@@ -38,9 +38,17 @@ public class GFCross extends EvalFunc<DataBag> {
     private TupleFactory mTupleFactory = TupleFactory.getInstance();
     private int parallelism = 0;
     private Random r = new Random();
+    private String crossKey;
 
     static private final int DEFAULT_PARALLELISM = 96;
-    
+
+    public GFCross(String key) {
+        crossKey = key;
+    }
+
+    public String getCrossKey() {
+        return crossKey;
+    }
 
     @Override
     public DataBag exec(Tuple input) throws IOException {
@@ -48,9 +56,9 @@ public class GFCross extends EvalFunc<DataBag> {
             parallelism = DEFAULT_PARALLELISM;
             Configuration cfg = UDFContext.getUDFContext().getJobConf();
             if (cfg != null) {
-                String s = cfg.get(MRConfiguration.REDUCE_TASKS);
+                String s = cfg.get(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + "." + crossKey);
                 if (s == null) {
-                    throw new IOException("Unable to determine parallelism from job conf");
+                    throw new IOException("Unable to get parallelism hint from job conf");
                 }
                 parallelism = Integer.valueOf(s);
             }
diff --git a/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java b/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
index 9d6317710..a7ca0a6b2 100644
--- a/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
+++ b/src/org/apache/pig/newplan/logical/relational/LogToPhyTranslationVisitor.java
@@ -583,6 +583,7 @@ public class LogToPhyTranslationVisitor extends LogicalRelationalNodesVisitor {
             POPackage poPackage = new POPackage(new OperatorKey(scope, nodeGen
                     .getNextNodeId(scope)), cross.getRequestedParallelism());
             poGlobal.addOriginalLocation(cross.getAlias(), cross.getLocation());
+            poGlobal.setCross(true);
             currentPlan.add(poGlobal);
             currentPlan.add(poPackage);
 
@@ -609,7 +610,9 @@ public class LogToPhyTranslationVisitor extends LogicalRelationalNodesVisitor {
                     ce1.setValue(ce1val);
                     ce1.setResultType(DataType.TUPLE);*/
 
-                    POUserFunc gfc = new POUserFunc(new OperatorKey(scope, nodeGen.getNextNodeId(scope)),cross.getRequestedParallelism(), Arrays.asList((PhysicalOperator)ce1,(PhysicalOperator)ce2), new FuncSpec(GFCross.class.getName()));
+                    POUserFunc gfc = new POUserFunc(new OperatorKey(scope, nodeGen.getNextNodeId(scope)),cross.getRequestedParallelism(),
+                            Arrays.asList((PhysicalOperator)ce1,(PhysicalOperator)ce2), new FuncSpec(GFCross.class.getName()
+                            + "('" + poGlobal.getOperatorKey().toString() + "')"));
                     gfc.addOriginalLocation(cross.getAlias(), cross.getLocation());
                     gfc.setResultType(DataType.BAG);
                     fep1.addAsLeaf(gfc);
diff --git a/test/e2e/pig/tests/nightly.conf b/test/e2e/pig/tests/nightly.conf
index 11e7a6c55..9bd21793f 100644
--- a/test/e2e/pig/tests/nightly.conf
+++ b/test/e2e/pig/tests/nightly.conf
@@ -1352,6 +1352,28 @@ d = filter b by age < 25;
 e = cross c, d;
 f = filter e by c::age < d::age;
 store f into ':OUTPATH:';\,
+			},
+			{
+			'num' => 5,
+			'pig' => q\
+set default_parallel 2
+a = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);
+b = foreach a generate registration;
+c = distinct b;
+d = group c all;
+e = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
+f = cross e, d;
+g = foreach f generate $0, $1, $2, flatten($3);
+store g into ':OUTPATH:';\,
+                        'verify_pig_script' => q\
+a = load ':INPATH:/singlefile/votertab10k' as (name, age, registration, contributions);
+b = foreach a generate registration;
+c = distinct b;
+d = group c all;
+e = load ':INPATH:/singlefile/studenttab10k' as (name, age, gpa);
+f = cross e, d;
+g = foreach f generate $0, $1, $2, flatten($3);
+store g into ':OUTPATH:';\,
 			}
 		]
 		},
diff --git a/test/org/apache/pig/test/TestGFCross.java b/test/org/apache/pig/test/TestGFCross.java
index b148a4809..c62c550dc 100644
--- a/test/org/apache/pig/test/TestGFCross.java
+++ b/test/org/apache/pig/test/TestGFCross.java
@@ -20,8 +20,7 @@ package org.apache.pig.test;
 import static org.junit.Assert.assertEquals;
 
 import org.apache.hadoop.conf.Configuration;
-
-import org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRConfiguration;
+import org.apache.pig.PigConfiguration;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.Tuple;
 import org.apache.pig.data.TupleFactory;
@@ -41,7 +40,7 @@ public class TestGFCross {
         t.set(0, 2);
         t.set(1, 0);
 
-        GFCross cross = new GFCross();
+        GFCross cross = new GFCross("1");
         DataBag bag = cross.exec(t);
         assertEquals(10, bag.size());
     }
@@ -50,14 +49,14 @@ public class TestGFCross {
     @Test
     public void testSerial() throws Exception {
         Configuration cfg = new Configuration();
-        cfg.set(MRConfiguration.REDUCE_TASKS, "1");
+        cfg.set(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + ".1", "1");
         UDFContext.getUDFContext().addJobConf(cfg);
         Tuple t = TupleFactory.getInstance().newTuple(2);
 
         t.set(0, 2);
         t.set(1, 0);
 
-        GFCross cross = new GFCross();
+        GFCross cross = new GFCross("1");
         DataBag bag = cross.exec(t);
         assertEquals(1, bag.size());
     }
@@ -66,14 +65,14 @@ public class TestGFCross {
     @Test
     public void testParallelSet() throws Exception {
         Configuration cfg = new Configuration();
-        cfg.set(MRConfiguration.REDUCE_TASKS, "10");
+        cfg.set(PigConfiguration.PIG_CROSS_PARALLELISM_HINT + ".1", "10");
         UDFContext.getUDFContext().addJobConf(cfg);
         Tuple t = TupleFactory.getInstance().newTuple(2);
 
         t.set(0, 2);
         t.set(1, 0);
 
-        GFCross cross = new GFCross();
+        GFCross cross = new GFCross("1");
         DataBag bag = cross.exec(t);
         assertEquals(4, bag.size());
     }
diff --git a/test/org/apache/pig/tez/TestTezCompiler.java b/test/org/apache/pig/tez/TestTezCompiler.java
index 80e4a48e9..4b403cc97 100644
--- a/test/org/apache/pig/tez/TestTezCompiler.java
+++ b/test/org/apache/pig/tez/TestTezCompiler.java
@@ -551,6 +551,7 @@ public class TestTezCompiler {
     private void run(String query, String expectedFile) throws Exception {
         PhysicalPlan pp = Util.buildPp(pigServer, query);
         TezLauncher launcher = new TezLauncher();
+        pc.inExplain = true;
         TezPlanContainer tezPlanContainer = launcher.compile(pp, pc);
 
         ByteArrayOutputStream baos = new ByteArrayOutputStream();
diff --git a/test/org/apache/pig/tez/TestTezJobControlCompiler.java b/test/org/apache/pig/tez/TestTezJobControlCompiler.java
index d518a94d7..5112ac13c 100644
--- a/test/org/apache/pig/tez/TestTezJobControlCompiler.java
+++ b/test/org/apache/pig/tez/TestTezJobControlCompiler.java
@@ -47,6 +47,8 @@ import org.apache.pig.backend.hadoop.executionengine.tez.TezJobCompiler;
 import org.apache.pig.backend.hadoop.executionengine.tez.TezLocalExecType;
 import org.apache.pig.backend.hadoop.executionengine.tez.TezOperPlan;
 import org.apache.pig.backend.hadoop.executionengine.tez.TezOperator;
+import org.apache.pig.backend.hadoop.executionengine.tez.optimizers.LoaderProcessor;
+import org.apache.pig.backend.hadoop.executionengine.tez.optimizers.ParallelismSetter;
 import org.apache.pig.builtin.PigStorage;
 import org.apache.pig.impl.PigContext;
 import org.apache.pig.impl.util.Pair;
@@ -290,6 +292,10 @@ public class TestTezJobControlCompiler {
         TezJobCompiler jobComp = new TezJobCompiler(pc, new Configuration());
         MultiQueryOptimizerTez mqOptimizer = new MultiQueryOptimizerTez(tezPlan);
         mqOptimizer.visit();
+        LoaderProcessor loaderStorer = new LoaderProcessor(tezPlan, pc);
+        loaderStorer.visit();
+        ParallelismSetter parallelismSetter = new ParallelismSetter(tezPlan, pc);
+        parallelismSetter.visit();
         DAG dag = jobComp.buildDAG(tezPlan, new HashMap<String, LocalResource>());
         return new Pair<TezOperPlan, DAG>(tezPlan, dag);
     }
