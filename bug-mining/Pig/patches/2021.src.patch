diff --git a/CHANGES.txt b/CHANGES.txt
index c0d00b95e..d70150d12 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -34,6 +34,8 @@ PIG-5416: Spark unit tests failing randomly with "java.lang.RuntimeException: Un
 
 PIG-5447: Pig-on-Spark TestSkewedJoin.testSkewedJoinOuter failing with NoSuchElementException (knoguchi)
 
+PIG-5448: All TestHBaseStorage tests failing on pig-on-spark3 (knoguchi)
+
 Release 0.18.0 - Unreleased
  
 INCOMPATIBLE CHANGES
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/spark/SparkLauncher.java b/src/org/apache/pig/backend/hadoop/executionengine/spark/SparkLauncher.java
index 6a9e3cd2b..1e78877e4 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/spark/SparkLauncher.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/spark/SparkLauncher.java
@@ -591,6 +591,13 @@ public class SparkLauncher extends Launcher {
 
             sparkConf.setMaster(master);
             sparkConf.setAppName(pigCtxtProperties.getProperty(PigContext.JOB_NAME,"pig"));
+
+            // For non-hdfs inputs, PigSplit may show up as empty but still
+            // contain inputs when accessed.  These splits should not be
+            // skipped.
+            sparkConf.set("spark.hadoopRDD.ignoreEmptySplits", "false");
+
+
             // On Spark 1.6, Netty file server doesn't allow adding the same file with the same name twice
             // This is a problem for streaming using a script + explicit ship the same script combination (PIG-5134)
             // HTTP file server doesn't have this restriction, it overwrites the file if added twice
