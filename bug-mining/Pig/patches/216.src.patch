diff --git a/CHANGES.txt b/CHANGES.txt
index 1348f7d62..8e79b005e 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -40,6 +40,8 @@ OPTIMIZATIONS
 
 BUG FIXES
 
+    PIG-883: udf import list does not send to the backend (daijy)
+
     PIG-881: Pig should ship load udfs to the backend (daijy)
 
     PIG-876: limit changes order of order-by to ascending (daijy)
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
index 38c62c416..6967127fd 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/JobControlCompiler.java
@@ -321,6 +321,7 @@ public class JobControlCompiler{
             jobConf.set("pig.inputs", ObjectSerializer.serialize(inp));
             jobConf.set("pig.inpTargets", ObjectSerializer.serialize(inpTargets));
             jobConf.set("pig.pigContext", ObjectSerializer.serialize(pigContext));
+            jobConf.set("udf.import.list", ObjectSerializer.serialize(PigContext.getPackageImportList()));
             // this is for unit tests since some don't create PigServer
             if (pigContext.getProperties().getProperty(PigContext.JOB_NAME) != null)
                 jobConf.setJobName(pigContext.getProperties().getProperty(PigContext.JOB_NAME));
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java
index b640df2bd..4c3923831 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigCombiner.java
@@ -19,6 +19,7 @@ package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
@@ -94,6 +95,7 @@ public class PigCombiner {
             super.configure(jConf);
             sJobConf = jConf;
             try {
+                PigContext.setPackageImportList((ArrayList<String>)ObjectSerializer.deserialize(jConf.get("udf.import.list")));
                 cp = (PhysicalPlan) ObjectSerializer.deserialize(jConf
                         .get("pig.combinePlan"));
                 pack = (POPackage)ObjectSerializer.deserialize(jConf.get("pig.combine.package"));
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
index 33330bf88..791aa43ab 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigInputFormat.java
@@ -190,6 +190,7 @@ public class PigInputFormat implements InputFormat<Text, Tuple>,
 			        .deserialize(job.get("pig.inpTargets"));
 			pigContext = (PigContext) ObjectSerializer.deserialize(job
 			        .get("pig.pigContext"));
+			PigContext.setPackageImportList((ArrayList<String>)ObjectSerializer.deserialize(job.get("udf.import.list")));
 		} catch (Exception e) {
 			int errCode = 2094;
 			String msg = "Unable to deserialize object.";
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
index 1180d324b..57ace89fe 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapBase.java
@@ -146,6 +146,7 @@ public abstract class PigMapBase extends MapReduceBase{
         SpillableMemoryManager.configure(ConfigurationUtil.toProperties(job));
         PigMapReduce.sJobConf = job;
         try {
+            PigContext.setPackageImportList((ArrayList<String>)ObjectSerializer.deserialize(job.get("udf.import.list")));
             mp = (PhysicalPlan) ObjectSerializer.deserialize(
                 job.get("pig.mapPlan"));
             stores = PlanHelper.getStores(mp);
diff --git a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
index a64955a85..efacad41d 100644
--- a/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
+++ b/src/org/apache/pig/backend/hadoop/executionengine/mapReduceLayer/PigMapReduce.java
@@ -19,6 +19,7 @@ package org.apache.pig.backend.hadoop.executionengine.mapReduceLayer;
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
@@ -180,6 +181,7 @@ public class PigMapReduce {
             SpillableMemoryManager.configure(ConfigurationUtil.toProperties(jConf));
             sJobConf = jConf;
             try {
+                PigContext.setPackageImportList((ArrayList<String>)ObjectSerializer.deserialize(jConf.get("udf.import.list")));
                 rp = (PhysicalPlan) ObjectSerializer.deserialize(jConf
                         .get("pig.reducePlan"));
                 stores = PlanHelper.getStores(rp);
diff --git a/src/org/apache/pig/impl/PigContext.java b/src/org/apache/pig/impl/PigContext.java
index a26417510..9ee229991 100644
--- a/src/org/apache/pig/impl/PigContext.java
+++ b/src/org/apache/pig/impl/PigContext.java
@@ -633,4 +633,8 @@ public class PigContext implements Serializable, FunctionInstantiator {
     {
         return packageImportList;
     }
+    public static void setPackageImportList(ArrayList<String> list)
+    {
+        packageImportList = list;
+    }
 }
diff --git a/test/org/apache/pig/test/TestPigContext.java b/test/org/apache/pig/test/TestPigContext.java
index 34d4cc6bb..9cb081088 100644
--- a/test/org/apache/pig/test/TestPigContext.java
+++ b/test/org/apache/pig/test/TestPigContext.java
@@ -23,16 +23,22 @@ import java.io.File;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.OutputStreamWriter;
+import java.io.PrintStream;
 import java.util.ArrayList;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Properties;
+import java.util.Random;
 
 import junit.framework.TestCase;
 
 import org.apache.hadoop.mapred.FileAlreadyExistsException;
+import org.apache.pig.EvalFunc;
 import org.apache.pig.ExecType;
 import org.apache.pig.PigServer;
+import org.apache.pig.data.Tuple;
 import org.apache.pig.impl.PigContext;
+import org.apache.pig.impl.io.FileLocalizer;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -45,6 +51,7 @@ public class TestPigContext extends TestCase {
 
     private File input;
     private PigContext pigContext;
+    MiniCluster cluster = MiniCluster.buildCluster();
     
     @Before
     @Override
@@ -106,8 +113,14 @@ public class TestPigContext extends TestCase {
         File udf1Dir = new File(tmpDir.getAbsolutePath()+FILE_SEPARATOR+"com"+FILE_SEPARATOR+"xxx"+FILE_SEPARATOR+"udf1");
         udf1Dir.mkdirs();
         File udf1JavaSrc = new File(udf1Dir.getAbsolutePath()+FILE_SEPARATOR+"TestUDF.java");
-        String udf1Src = new String("package com.xxx.udf1;\n" +
-                "public class TestUDF {}\n");
+        String udf1Src = new String("package com.xxx.udf1;\n"+
+                "import java.io.IOException;\n"+
+                "import org.apache.pig.EvalFunc;\n"+
+                "import org.apache.pig.data.Tuple;\n"+
+                "public class TestUDF extends EvalFunc<Integer>{\n"+
+                "public Integer exec(Tuple input) throws IOException {\n"+
+                "return 1;}\n"+
+                "}");
         
         // generate java file
         FileOutputStream outStream = 
@@ -119,7 +132,7 @@ public class TestPigContext extends TestCase {
         
         // compile
         int status;
-        status = Util.executeShellCommand("javac " + udf1JavaSrc);
+        status = Util.executeShellCommand("javac -cp "+System.getProperty("java.class.path") + " " + udf1JavaSrc);
         
         // generate jar file
         String jarName = "TestUDFJar1.jar";
@@ -142,6 +155,30 @@ public class TestPigContext extends TestCase {
         Object udf = PigContext.instantiateFuncFromSpec("TestUDF");
         assertTrue(udf.getClass().toString().endsWith("com.xxx.udf1.TestUDF"));
         
+        int LOOP_COUNT = 40;
+        File tmpFile = File.createTempFile("test", "txt");
+        PrintStream ps = new PrintStream(new FileOutputStream(tmpFile));
+        Random r = new Random(1);
+        int rand;
+        for(int i = 0; i < LOOP_COUNT; i++) {
+            rand = r.nextInt(100);
+            ps.println(rand);
+        }
+        ps.close();
+        
+        FileLocalizer.deleteTempFiles();
+        PigServer pigServer = new PigServer(ExecType.MAPREDUCE, cluster.getProperties());
+        pigServer.registerQuery("A = LOAD '" + Util.generateURI(tmpFile.toString()) + "' AS (num:chararray);");
+        pigServer.registerQuery("B = foreach A generate TestUDF(num);");
+        Iterator<Tuple> iter = pigServer.openIterator("B");
+        if(!iter.hasNext()) fail("No output found");
+        int numIdentity = 0;
+        while(iter.hasNext()){
+            Tuple t = iter.next();
+            assertTrue(t.get(0) instanceof Integer);
+            assertTrue((Integer)t.get(0) == 1);
+        }
+        
         Util.deleteDirectory(tempDir);
     }
 
