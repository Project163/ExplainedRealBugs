<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Sat Nov 08 18:13:43 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HBASE-27097] SimpleRpcServer is broken</title>
                <link>https://issues.apache.org/jira/browse/HBASE-27097</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Concerns about SimpleRpcServer are not new, and not new to 2.5.&#160; @chenxu noticed a problem on &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-23917&quot; title=&quot;[SimpleRpcServer] Subsequent requests will have no response in case of request IO mess up&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-23917&quot;&gt;HBASE-23917&lt;/a&gt; back in 2020. After some simple evaluations it seems quite broken. &lt;/p&gt;

&lt;p&gt;When I run an async version of ITLCC against a 2.5.0 cluster configured with hbase.rpc.server.impl=SimpleRpcServer, the client almost immediately stalls because there are too many in flight requests. The logic to pause with too many in flight requests is my own. That&apos;s not important. Looking at the server logs it is apparent that SimpleRpcServer is quite broken. Handlers suffer frequent protobuf parse errors and do not properly return responses to the client. This is what stalls my test client. Rather quickly all available request slots are full of requests that will have to time out on the client side. &lt;/p&gt;

&lt;p&gt;Exceptions have three patterns but they all have in common SimpleServerRpcConnection#process. It seems likely the root cause is mismatched expectations or bugs in connection buffer handling in SimpleRpcServer/SimpleServerRpcConnection versus downstream classes that process and parse the buffers. It also seems likely that changes were made to downstream classes like ServerRpcConnection expecting NettyRpcServer&apos;s particulars without updating SimpleServerRpcConnection and/or SimpleRpcServer. That said, this is just a superficial analysis.&lt;/p&gt;

&lt;p&gt;1) &quot;Protocol message end-group tag did not match expected tag&quot;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; 2022-06-07T16:44:04,625 WARN &#160;[Reader=5,bindAddress=buildbox.localdomain,port=8120] ipc.RpcServer: /127.0.1.1:8120 is unable to read call parameter from client 127.0.0.1
org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message end-group tag did not match expected tag.
&#160; &#160; at org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidEndTag(InvalidProtocolBufferException.java:129) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
&#160; &#160; at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.checkLastTagWas(CodedInputStream.java:4034) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
&#160; &#160; at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4275) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue.&amp;lt;init&amp;gt;(ClientProtos.java:10520) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue.&amp;lt;init&amp;gt;(ClientProtos.java:10464) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$1.parsePartialFrom(ClientProtos.java:12251) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$1.parsePartialFrom(ClientProtos.java:12245) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto.&amp;lt;init&amp;gt;(ClientProtos.java:9981) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto.&amp;lt;init&amp;gt;(ClientProtos.java:9910) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$1.parsePartialFrom(ClientProtos.java:14097) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$1.parsePartialFrom(ClientProtos.java:14091) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest.&amp;lt;init&amp;gt;(ClientProtos.java:14251) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest.&amp;lt;init&amp;gt;(ClientProtos.java:14190) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$1.parsePartialFrom(ClientProtos.java:15304) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$1.parsePartialFrom(ClientProtos.java:15298) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$Builder.mergeFrom(ClientProtos.java:14860) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$Builder.mergeFrom(ClientProtos.java:14651) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:420) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
&#160; &#160; at org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:317) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
&#160; &#160; at org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.mergeFrom(ProtobufUtil.java:2638) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.ipc.ServerRpcConnection.processRequest(ServerRpcConnection.java:644) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.ipc.ServerRpcConnection.processOneRpc(ServerRpcConnection.java:444) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.process(SimpleServerRpcConnection.java:285) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.readAndProcess(SimpleServerRpcConnection.java:251) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener.doRead(SimpleRpcServer.java:318) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener$Reader.doRunLoop(SimpleRpcServer.java:180) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener$Reader.run(SimpleRpcServer.java:153) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
&#160; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2) &quot;Protocol message tag had invalid wire type.&quot;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2022-06-07T16:44:04,705 WARN  [Reader=6,bindAddress=buildbox.localdomain,port=8120] ipc.RpcServer: /127.0.1.1:8120 is unable to read call parameter from client 127.0.0.1
org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException$InvalidWireTypeException: Protocol message tag had invalid wire type.
	at org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidWireType(InvalidProtocolBufferException.java:134) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:527) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.parseUnknownField(GeneratedMessageV3.java:320) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue.&amp;lt;init&amp;gt;(ClientProtos.java:10700) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue.&amp;lt;init&amp;gt;(ClientProtos.java:10620) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue$1.parsePartialFrom(ClientProtos.java:11481) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue$1.parsePartialFrom(ClientProtos.java:11475) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue.&amp;lt;init&amp;gt;(ClientProtos.java:10520) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue.&amp;lt;init&amp;gt;(ClientProtos.java:10464) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$1.parsePartialFrom(ClientProtos.java:12251) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$1.parsePartialFrom(ClientProtos.java:12245) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto.&amp;lt;init&amp;gt;(ClientProtos.java:9981) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto.&amp;lt;init&amp;gt;(ClientProtos.java:9910) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$1.parsePartialFrom(ClientProtos.java:14097) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$1.parsePartialFrom(ClientProtos.java:14091) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest.&amp;lt;init&amp;gt;(ClientProtos.java:14251) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest.&amp;lt;init&amp;gt;(ClientProtos.java:14190) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$1.parsePartialFrom(ClientProtos.java:15304) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$1.parsePartialFrom(ClientProtos.java:15298) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$Builder.mergeFrom(ClientProtos.java:14860) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$Builder.mergeFrom(ClientProtos.java:14651) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:420) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:317) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.mergeFrom(ProtobufUtil.java:2638) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.ServerRpcConnection.processRequest(ServerRpcConnection.java:644) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.ServerRpcConnection.processOneRpc(ServerRpcConnection.java:444) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.process(SimpleServerRpcConnection.java:285) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.readAndProcess(SimpleServerRpcConnection.java:251) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener.doRead(SimpleRpcServer.java:318) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener$Reader.doRunLoop(SimpleRpcServer.java:180) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener$Reader.run(SimpleRpcServer.java:153) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;3) &quot;While parsing a protocol message, the input ended unexpectedly in the middle of a field.&quot;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2022-06-07T16:44:04,885 WARN  [Reader=9,bindAddress=buildbox.localdomain,port=8120] ipc.RpcServer: /127.0.1.1:8120 is unable to read call parameter from client 127.0.0.1
org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.hbase.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:107) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readRawLittleEndian64(CodedInputStream.java:4478) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readFixed64(CodedInputStream.java:4167) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:511) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.GeneratedMessageV3.parseUnknownField(GeneratedMessageV3.java:320) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue.&amp;lt;init&amp;gt;(ClientProtos.java:10700) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue.&amp;lt;init&amp;gt;(ClientProtos.java:10620) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue$1.parsePartialFrom(ClientProtos.java:11481) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$QualifierValue$1.parsePartialFrom(ClientProtos.java:11475) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue.&amp;lt;init&amp;gt;(ClientProtos.java:10520) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue.&amp;lt;init&amp;gt;(ClientProtos.java:10464) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$1.parsePartialFrom(ClientProtos.java:12251) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$ColumnValue$1.parsePartialFrom(ClientProtos.java:12245) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto.&amp;lt;init&amp;gt;(ClientProtos.java:9981) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto.&amp;lt;init&amp;gt;(ClientProtos.java:9910) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$1.parsePartialFrom(ClientProtos.java:14097) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutationProto$1.parsePartialFrom(ClientProtos.java:14091) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.CodedInputStream$ByteInputDecoder.readMessage(CodedInputStream.java:4274) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest.&amp;lt;init&amp;gt;(ClientProtos.java:14251) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest.&amp;lt;init&amp;gt;(ClientProtos.java:14190) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$1.parsePartialFrom(ClientProtos.java:15304) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$1.parsePartialFrom(ClientProtos.java:15298) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$Builder.mergeFrom(ClientProtos.java:14860) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$MutateRequest$Builder.mergeFrom(ClientProtos.java:14651) ~[hbase-protocol-shaded-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:420) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hbase.thirdparty.com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:317) ~[hbase-shaded-protobuf-4.1.0.jar:4.1.0]
	at org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.mergeFrom(ProtobufUtil.java:2638) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.ServerRpcConnection.processRequest(ServerRpcConnection.java:644) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.ServerRpcConnection.processOneRpc(ServerRpcConnection.java:444) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.process(SimpleServerRpcConnection.java:285) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleServerRpcConnection.readAndProcess(SimpleServerRpcConnection.java:251) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener.doRead(SimpleRpcServer.java:318) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener$Reader.doRunLoop(SimpleRpcServer.java:180) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.SimpleRpcServer$Listener$Reader.run(SimpleRpcServer.java:153) ~[hbase-server-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13448885">HBASE-27097</key>
            <summary>SimpleRpcServer is broken</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="apurtell">Andrew Kyle Purtell</assignee>
                                    <reporter username="apurtell">Andrew Kyle Purtell</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 Jun 2022 23:57:47 +0000</created>
                <updated>Mon, 11 Aug 2025 08:48:06 +0000</updated>
                            <resolved>Tue, 12 Jul 2022 18:18:37 +0000</resolved>
                                    <version>2.5.0</version>
                                    <fixVersion>2.5.0</fixVersion>
                    <fixVersion>3.0.0-alpha-4</fixVersion>
                    <fixVersion>2.4.14</fixVersion>
                                    <component>rpc</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                                                            <comments>
                            <comment id="17551318" author="apurtell" created="Tue, 7 Jun 2022 23:58:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vjasani&quot; class=&quot;user-hover&quot; rel=&quot;vjasani&quot;&gt;vjasani&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17551336" author="vjasani" created="Wed, 8 Jun 2022 00:50:26 +0000"  >&lt;p&gt;I would like to take a look and see if the fix is not time consuming, then we can go ahead and fix this. But since SimpleRpcServer has recent relevant commits made only on 2017, I assume hardly anyone would be using it.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;FYI &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=elserj&quot; class=&quot;user-hover&quot; rel=&quot;elserj&quot;&gt;elserj&lt;/a&gt; as you tried using SimpleRpcServer as an alternative for some cluster where Netty was causing this issue&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-26708&quot; title=&quot;Netty &amp;quot;leak detected&amp;quot; and OutOfDirectMemoryError due to direct memory buffering with SASL implementation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-26708&quot;&gt;&lt;del&gt;HBASE-26708&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhangduo&quot; class=&quot;user-hover&quot; rel=&quot;zhangduo&quot;&gt;zhangduo&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;apurtell&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17551353" author="apache9" created="Wed, 8 Jun 2022 02:20:54 +0000"  >&lt;p&gt;Let me take a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-26708&quot; title=&quot;Netty &amp;quot;leak detected&amp;quot; and OutOfDirectMemoryError due to direct memory buffering with SASL implementation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-26708&quot;&gt;&lt;del&gt;HBASE-26708&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17551538" author="wchevreuil" created="Wed, 8 Jun 2022 10:33:16 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;apurtell&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vjasani&quot; class=&quot;user-hover&quot; rel=&quot;vjasani&quot;&gt;vjasani&lt;/a&gt;, &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It also seems likely that changes were made to downstream classes like ServerRpcConnection expecting NettyRpcServer&apos;s particulars without updating SimpleServerRpcConnection and/or SimpleRpcServer&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks like SimpleRpcServer is completely broken in 2.5. That&apos;s a bit concerning. We have seen some cases of direct memory leaks apparently related to NettyRpcServer among our customers running deployments based out of 2.2. In such cases, our immediate workaround in the absence of a code fix is to switch to SimpleRpcServer.  And we still have the aforementioned &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-26708&quot; title=&quot;Netty &amp;quot;leak detected&amp;quot; and OutOfDirectMemoryError due to direct memory buffering with SASL implementation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-26708&quot;&gt;&lt;del&gt;HBASE-26708&lt;/del&gt;&lt;/a&gt; open. How confident are we with current state of NettyRpcServer in 2.5?&lt;/p&gt;

&lt;p&gt;Also, compatibility wise, would it be ok to remove it entirely on a minor release?&lt;/p&gt;</comment>
                            <comment id="17551696" author="apurtell" created="Wed, 8 Jun 2022 16:26:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;Also, compatibility wise, would it be ok to remove it entirely on a minor release?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Correct, that is an issue which is why I said this:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I realize this is a technical violation of the operational compatibility guideline for a minor release but unless a volunteer steps forward to fix it, there is no choice. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I will note that the last significant change to SimpleRpcServer was in 2017, that was 5 years ago, and nobody has showed up until now, technically not even now as I noticed this problem but have no intention to use SimpleRpcServer, so how important is SimpleRpcServer really? Surely this problem would have been noticed and fixed long before this if anyone was actually using it. So removal is, of course, fine as a practical matter. &lt;/p&gt;

&lt;p&gt;That said, we can choose to fix this with intention, deciding that SimpleRpcServer should be a viable alternative or fallback to NettyRpcServer. That would be fine too. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Looks like SimpleRpcServer is completely broken in 2.5.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The issue developed in branch-2 and master, and when 2.5 was forked from branch-2, then also in branch-2.5. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;among our customers running deployments based out of 2.2. In such cases, our immediate workaround in the absence of a code fix is to switch to SimpleRpcServer.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So just to confirm, you have customers successfully using SimpleRpcServer with 2.2.&lt;/p&gt;</comment>
                            <comment id="17552116" author="wchevreuil" created="Thu, 9 Jun 2022 10:45:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;So just to confirm, you have customers successfully using SimpleRpcServer with 2.2.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, some customers who faced some of the NettyRpcServer bytbuff leak in our 2.2 based distribution, reverting to SimpleRpcServer allowed them to proceed with their workloads.&lt;/p&gt;</comment>
                            <comment id="17552473" author="apurtell" created="Thu, 9 Jun 2022 23:34:09 +0000"  >&lt;p&gt;I was taking with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vjasani&quot; class=&quot;user-hover&quot; rel=&quot;vjasani&quot;&gt;vjasani&lt;/a&gt; offline and he feels SimpleRpcServer deserves fixes and stability. &lt;/p&gt;

&lt;p&gt;I think the consensus is keep SimpleRpcServer, but in its current state it is not releasable, so I will raise the priority of this issue to Blocker. &lt;/p&gt;</comment>
                            <comment id="17552502" author="aoxiang" created="Fri, 10 Jun 2022 02:18:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;apurtell&lt;/a&gt; what about apply the patch &#8220;MultiByteBuff.patch&#8221; &#65292; which fix a bug&#65311;&lt;/p&gt;</comment>
                            <comment id="17552517" author="vjasani" created="Fri, 10 Jun 2022 03:09:50 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=binlijin&quot; class=&quot;user-hover&quot; rel=&quot;binlijin&quot;&gt;binlijin&lt;/a&gt; for the patch! I was wondering if you have any UT that can break RPC calls with SimpleRpcServer impl without this patch. I tried writing few tests with minicluster and they were passing with SimpleRpcServer, hence I was wondering how come we see broken SimpleRpcServer only while testing on distributed cluster.&lt;/p&gt;</comment>
                            <comment id="17552529" author="aoxiang" created="Fri, 10 Jun 2022 04:05:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vjasani&quot; class=&quot;user-hover&quot; rel=&quot;vjasani&quot;&gt;vjasani&lt;/a&gt; No&#65292;do not have ut to reproduce it&#12290;&lt;/p&gt;</comment>
                            <comment id="17552900" author="apurtell" created="Fri, 10 Jun 2022 18:06:51 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=binlijin&quot; class=&quot;user-hover&quot; rel=&quot;binlijin&quot;&gt;binlijin&lt;/a&gt;, I will try your patch today.&lt;/p&gt;</comment>
                            <comment id="17552983" author="apurtell" created="Fri, 10 Jun 2022 21:33:42 +0000"  >&lt;p&gt;The patch solves the issue in my test environment. Let me prepare PRs.&lt;/p&gt;</comment>
                            <comment id="17552985" author="apurtell" created="Fri, 10 Jun 2022 22:02:54 +0000"  >&lt;p&gt;Assigned to me, but &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=binlijin&quot; class=&quot;user-hover&quot; rel=&quot;binlijin&quot;&gt;binlijin&lt;/a&gt; will get credit&lt;/p&gt;</comment>
                            <comment id="17553132" author="apurtell" created="Sat, 11 Jun 2022 17:49:05 +0000"  >&lt;p&gt;Committed to branch-2.4 and up&lt;/p&gt;</comment>
                            <comment id="17553207" author="hudson" created="Sun, 12 Jun 2022 04:53:11 +0000"  >&lt;p&gt;Results for branch branch-2.4&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/369/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #369 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/369/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop2 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/369/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop2) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/369/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/369/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="17553212" author="hudson" created="Sun, 12 Jun 2022 05:35:10 +0000"  >&lt;p&gt;Results for branch branch-2&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/566/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #566 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/566/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop2 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/566/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop2) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/566/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/566/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="17553320" author="hudson" created="Sun, 12 Jun 2022 19:08:34 +0000"  >&lt;p&gt;Results for branch master&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/610/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #610 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;red&quot;&gt;-1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/610/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;






&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/610/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/610/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="17553330" author="hudson" created="Sun, 12 Jun 2022 20:05:28 +0000"  >&lt;p&gt;Results for branch branch-2.5&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/141/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #141 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/141/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop2 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/141/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop2) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/141/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/141/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="17555240" author="vjasani" created="Thu, 16 Jun 2022 18:31:35 +0000"  >&lt;p&gt;When we use BlockingRpcClient or&#160;NettyRpcClient against SimpleRpcServer in hbase2 (with SaslAuth, Negotiated QoP: auth-conf), hbase shell commands throw checksum failed errors:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
hbase:010:0&amp;gt; rit


ERROR: Checksum failed
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Similarly, scanning of SYSTEM.CATALOG in Phoenix also fails:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.net.SocketTimeoutException: callTimeout=60000, callDuration=68788: Call to address=regionserver-1:60020 failed on local exception: javax.security.sasl.SaslException: Problems unwrapping SASL buffer [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)] row &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; on table &apos;&lt;/span&gt;SYSTEM.CATALOG&apos; at region=SYSTEM.CATALOG,,1651182322114.9706a466ac24135ce93769671b601652., hostname=regionserver-1,60020,1655397068266, seqNum=256
&#160; &#160; at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:156)
&#160; &#160; at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:74)
&#160; &#160; ... 3 more
Caused by: javax.security.sasl.SaslException: Call to address=regionserver-1:60020 failed on local exception: javax.security.sasl.SaslException: Problems unwrapping SASL buffer [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)] [Caused by javax.security.sasl.SaslException: Problems unwrapping SASL buffer [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)]]
&#160; &#160; at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
&#160; &#160; at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
&#160; &#160; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
&#160; &#160; at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
&#160; &#160; at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:240)
&#160; &#160; at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:385)
&#160; &#160; at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:89)
&#160; &#160; at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:417)
&#160; &#160; at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:413)
&#160; &#160; at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:115)
&#160; &#160; at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:130)
&#160; &#160; at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.cleanupCalls(NettyRpcDuplexHandler.java:203)
&#160; &#160; at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.exceptionCaught(NettyRpcDuplexHandler.java:220)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:143)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:381)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
&#160; &#160; ... 1 more
Caused by: javax.security.sasl.SaslException: Problems unwrapping SASL buffer [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)]
&#160; &#160; at com.sun.security.sasl.gsskerb.GssKrb5Base.unwrap(GssKrb5Base.java:90)
&#160; &#160; at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:51)
&#160; &#160; at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:32)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
&#160; &#160; ... 22 more
Caused by: GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)
&#160; &#160; at sun.security.jgss.krb5.CipherHelper.aes256Decrypt(CipherHelper.java:1399)
&#160; &#160; at sun.security.jgss.krb5.CipherHelper.decryptData(CipherHelper.java:574)
&#160; &#160; at sun.security.jgss.krb5.WrapToken_v2.getData(WrapToken_v2.java:130)
&#160; &#160; at sun.security.jgss.krb5.WrapToken_v2.getData(WrapToken_v2.java:105)
&#160; &#160; at sun.security.jgss.krb5.Krb5Context.unwrap(Krb5Context.java:1062)
&#160; &#160; at sun.security.jgss.GSSContextImpl.unwrap(GSSContextImpl.java:403)
&#160; &#160; at com.sun.security.sasl.gsskerb.GssKrb5Base.unwrap(GssKrb5Base.java:77)
&#160; &#160; ... 26 more
Caused by: java.security.GeneralSecurityException: Checksum failed
&#160; &#160; at sun.security.krb5.internal.crypto.dk.AesDkCrypto.decryptCTS(AesDkCrypto.java:451)
&#160; &#160; at sun.security.krb5.internal.crypto.dk.AesDkCrypto.decryptRaw(AesDkCrypto.java:291)
&#160; &#160; at sun.security.krb5.internal.crypto.Aes256.decryptRaw(Aes256.java:86)
&#160; &#160; at sun.security.jgss.krb5.CipherHelper.aes256Decrypt(CipherHelper.java:1395)
&#160; &#160; ... 32 more
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17555251" author="apurtell" created="Thu, 16 Jun 2022 18:52:08 +0000"  >&lt;p&gt;Reopened.&lt;/p&gt;</comment>
                            <comment id="17555252" author="apurtell" created="Thu, 16 Jun 2022 18:52:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vjasani&quot; class=&quot;user-hover&quot; rel=&quot;vjasani&quot;&gt;vjasani&lt;/a&gt; (and everyone...) additional fixes should be done on subtasks to disambiguate the one that went in with this ID&lt;/p&gt;</comment>
                            <comment id="17555264" author="vjasani" created="Thu, 16 Jun 2022 19:11:55 +0000"  >&lt;p&gt;Scanning of hbase:meta is very slow and it keeps throwing this after a while:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException: org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException: Expected nextCallSeq: 1 But the nextCallSeq got from client: 0; request=scanner_id: 9036221070314570992 number_of_rows: 100 close_scanner: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; next_call_seq: 0 client_handles_partials: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; client_handles_heartbeats: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; track_scan_metrics: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; renew: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.checkScanNextCallSeq(RSRpcServices.java:3197)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:3549)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:45819)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:384)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:131)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:371)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:351)


	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.instantiateException(RemoteWithExtrasException.java:97)
	at org.apache.hadoop.hbase.ipc.RemoteWithExtrasException.unwrapRemoteException(RemoteWithExtrasException.java:87)
	at org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.makeIOExceptionOfException(ProtobufUtil.java:378)
	at org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil.handleRemoteException(ProtobufUtil.java:366)
	at org.apache.hadoop.hbase.client.ScannerCallable.next(ScannerCallable.java:194)
	at org.apache.hadoop.hbase.client.ScannerCallable.rpcCall(ScannerCallable.java:258)
	at org.apache.hadoop.hbase.client.ScannerCallable.rpcCall(ScannerCallable.java:58)
	at org.apache.hadoop.hbase.client.RegionServerCallable.call(RegionServerCallable.java:124)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithoutRetries(RpcRetryingCallerImpl.java:189)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:393)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.call(ScannerCallableWithReplicas.java:367)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:104)
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:74)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:750)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException): org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException: Expected nextCallSeq: 1 But the nextCallSeq got from client: 0; request=scanner_id: 9036221070314570992 number_of_rows: 100 close_scanner: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; next_call_seq: 0 client_handles_partials: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; client_handles_heartbeats: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; track_scan_metrics: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; renew: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.checkScanNextCallSeq(RSRpcServices.java:3197)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:3549)
	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:45819)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:384)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:131)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:371)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:351)


	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:382)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:89)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:417)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:413)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:115)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:130)
	at org.apache.hadoop.hbase.ipc.BlockingRpcConnection.readResponse(BlockingRpcConnection.java:702)
	at org.apache.hadoop.hbase.ipc.BlockingRpcConnection.run(BlockingRpcConnection.java:358)
	... 1 more &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17555270" author="vjasani" created="Thu, 16 Jun 2022 19:40:23 +0000"  >&lt;p&gt;On the other hand, if we don&apos;t change client impl (i.e. keep default&#160;NettyRpcClient) against SimpleRpcServer (with same auth as above), CJ keeps failing with:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2022-06-16 17:15:31,890 WARN &#160;[,queue=15,port=60020] ipc.RpcServer - RpcServer.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.FPBQ.Fifo.handler=249,queue=15,port=60020: caught: org.apache.hbase.thirdparty.io.netty.util.IllegalReferenceCountException: refCnt: 0, decrement: 1
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.util.internal.ReferenceCountUpdater.toLiveRealRefCnt(ReferenceCountUpdater.java:74)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.util.internal.ReferenceCountUpdater.release(ReferenceCountUpdater.java:138)
&#160; &#160; at org.apache.hbase.thirdparty.io.netty.util.AbstractReferenceCounted.release(AbstractReferenceCounted.java:76)
&#160; &#160; at org.apache.hadoop.hbase.nio.ByteBuff.release(ByteBuff.java:77)
&#160; &#160; at org.apache.hadoop.hbase.ipc.ServerCall.cleanup(ServerCall.java:165)
&#160; &#160; at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:162)
&#160; &#160; at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:371)
&#160; &#160; at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:351)



2022-06-16 17:14:19,743 WARN &#160;[RpcServer.responder] ipc.RpcServer - RpcServer.responder: exception in Responder java.lang.NullPointerException
&#160; &#160; at org.apache.hadoop.hbase.ipc.ServerCall.wrapWithSasl(ServerCall.java:401)
&#160; &#160; at org.apache.hadoop.hbase.ipc.ServerCall.getResponse(ServerCall.java:548)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.processResponse(SimpleRpcServerResponder.java:226)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.processAllResponses(SimpleRpcServerResponder.java:270)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.doAsyncWrite(SimpleRpcServerResponder.java:203)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.doRunLoop(SimpleRpcServerResponder.java:122)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.run(SimpleRpcServerResponder.java:58)java.lang.NullPointerException
&#160; &#160; at org.apache.hadoop.hbase.ipc.ServerCall.wrapWithSasl(ServerCall.java:401)
&#160; &#160; at org.apache.hadoop.hbase.ipc.ServerCall.getResponse(ServerCall.java:548)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.processResponse(SimpleRpcServerResponder.java:226)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.processAllResponses(SimpleRpcServerResponder.java:270)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.doAsyncWrite(SimpleRpcServerResponder.java:203)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.doRunLoop(SimpleRpcServerResponder.java:122)
&#160; &#160; at org.apache.hadoop.hbase.ipc.SimpleRpcServerResponder.run(SimpleRpcServerResponder.java:58)



2022-06-16 17:34:19,921 WARN &#160;[ster-2:60000.Chore.1] janitor.CatalogJanitor - Failed janitorial scan of hbase:meta table
org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=46, exceptions: &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17561231" author="apurtell" created="Fri, 1 Jul 2022 01:58:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vjasani&quot; class=&quot;user-hover&quot; rel=&quot;vjasani&quot;&gt;vjasani&lt;/a&gt; This is holding up 2.5.0 so I wanted to determine if the issue is possibly environmental. &lt;/p&gt;

&lt;p&gt;Built HBase 2.5.1-SNAPSHOT with -Dhadoop.profile=3.0 -Dhadoop-three.version=3.3.3 &lt;/p&gt;

&lt;p&gt;I set up a VM... Configured BIND to serve DNS. Ensured forward and backward DNS resolution for the hostname. Set up Kerberos and initialized a realm. Added a principal. Created a keytab. Configured Hadoop and HBase daemons to use kerberos authentication. SASL+Kerberos and hbase.rpc.protection=privacy. Confirmed the configuration is secure and requires krb auth, e.g.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ klist
klist: No credentials cache found (filename: /tmp/krb5cc_1000)
$ ./hbase-2.5.1-SNAPSHOT/bin/hbase shell 
hbase:001:0&amp;gt; list
TABLE                                                                                                                                                                                                     
ERROR: Found no valid authentication method from options

$ kinit
Password for apurtell@LOCALDOMAIN: XXXXXXXXXXXX
$ ./hbase-2.5.1-SNAPSHOT/bin/hbase shell 
hbase:001:0&amp;gt; list
TABLE                                                                                                                                                                                                     
0 row(s)
Took 0.0162 seconds                                                                                                                                                                                       
=&amp;gt; []
hbase:002:0&amp;gt; list_security_capabilities
SECURE_AUTHENTICATION
Took 0.0323 seconds                                                                                                                                                                                       
=&amp;gt; [&quot;SECURE_AUTHENTICATION&quot;]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Tested with NettyRpcServer. All good. &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;./hbase-2.5.1-SNAPSHOT/bin/hbase ltt -read 100:10 -write 1:100:10 -num_keys 1000000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Switched the regionserver config to SimpleRpcServer. This is relevant output from the regionserver log:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2022-06-30T18:51:26,102 INFO  [main] ipc.RpcServerFactory: Creating org.apache.hadoop.hbase.ipc.SimpleRpcServer hosting hbase.pb.ClientService, hbase.pb.AdminService, hbase.pb.ClientMetaService
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ran LTT again.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;./hbase-2.5.1-SNAPSHOT/bin/hbase ltt -read 100:10 -write 1:100:10 -num_keys 1000000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;No issues.&lt;/p&gt;

&lt;p&gt;Last lines of LTT output included below:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2022-06-30T18:58:22,046 INFO  [MultiThreadedAction-ProgressReporter-1656640437023] util.MultiThreadedAction: [W:11] Keys=991869, cols=2.4 M, time=00:04:25 Overall: [keys/s= 3742, latency=2.66 ms] Current: [keys/s=3176, latency=3.14 ms], wroteUpTo=991855, wroteQSize=3
2022-06-30T18:58:22,059 INFO  [MultiThreadedAction-ProgressReporter-1656640437039] util.MultiThreadedAction: [R:10] Keys=4425274, cols=14.8 M, time=00:04:25 Overall: [keys/s= 16697, latency=0.04 ms] Current: [keys/s=14045, latency=0.15 ms], verified=4425274
Failed to write keys: 0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17561233" author="apurtell" created="Fri, 1 Jul 2022 02:14:04 +0000"  >&lt;p&gt;I also ran an instance of my async enhanced ITLCC loader (&lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-27088&quot; title=&quot;IntegrationLoadTestCommonCrawl async load improvements&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-27088&quot;&gt;&lt;del&gt;HBASE-27088&lt;/del&gt;&lt;/a&gt;) and things are more interesting. &lt;/p&gt;

&lt;p&gt;The writes are all fine. The reads... not so much. So the reproduction is somewhat use case dependent. My guess is the values used by LTT are too small. ITLCC values can be much larger. There are issues on the read side at the client with SASL unwrapping. The server side did something bad.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2022-07-01T02:04:43.532Z, RpcRetryingCaller{globalStartTime=2022-07-01T02:02:34.236Z, pause=100, maxAttempts=16}, javax.security.sasl.SaslException: Call to address=buildbox.localdomain:8120 failed on local exception: javax.security.sasl.SaslException: Problems unwrapping SASL buffer [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)] [Caused by javax.security.sasl.SaslException: Problems unwrapping SASL buffer [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)]]

	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:143) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:385) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.client.HTable.lambda$get$0(HTable.java:358) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216) ~[hbase-common-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:358) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.test.IntegrationTestLoadCommonCrawl$Verify$VerifyMapper.map(IntegrationTestLoadCommonCrawl.java:862) ~[hbase-it-2.5.1-SNAPSHOT-tests.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.test.IntegrationTestLoadCommonCrawl$Verify$VerifyMapper.map(IntegrationTestLoadCommonCrawl.java:816) ~[hbase-it-2.5.1-SNAPSHOT-tests.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146) ~[hadoop-mapreduce-client-core-3.3.3.jar:?]
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:800) ~[hadoop-mapreduce-client-core-3.3.3.jar:?]
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:348) ~[hadoop-mapreduce-client-core-3.3.3.jar:?]
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271) ~[hadoop-mapreduce-client-common-3.3.3.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_332]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
Caused by: javax.security.sasl.SaslException: Call to address=buildbox.localdomain:8120 failed on local exception: javax.security.sasl.SaslException: Problems unwrapping SASL buffer [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_332]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_332]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_332]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_332]
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:243) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:388) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:92) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:422) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:417) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:114) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:129) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.cleanupCalls(NettyRpcDuplexHandler.java:207) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.ipc.NettyRpcDuplexHandler.exceptionCaught(NettyRpcDuplexHandler.java:224) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:143) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:381) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[hbase-shaded-netty-4.1.0.jar:?]
	... 1 more
Caused by: javax.security.sasl.SaslException: Problems unwrapping SASL buffer
	at com.sun.security.sasl.gsskerb.GssKrb5Base.unwrap(GssKrb5Base.java:90) ~[?:1.8.0_332]
	at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:51) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:32) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[hbase-shaded-netty-4.1.0.jar:?]
	... 1 more
Caused by: org.ietf.jgss.GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)
	at sun.security.jgss.krb5.CipherHelper.aes256Decrypt(CipherHelper.java:1399) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.CipherHelper.decryptData(CipherHelper.java:574) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.WrapToken_v2.getData(WrapToken_v2.java:130) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.WrapToken_v2.getData(WrapToken_v2.java:105) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.Krb5Context.unwrap(Krb5Context.java:1062) ~[?:1.8.0_332]
	at sun.security.jgss.GSSContextImpl.unwrap(GSSContextImpl.java:403) ~[?:1.8.0_332]
	at com.sun.security.sasl.gsskerb.GssKrb5Base.unwrap(GssKrb5Base.java:77) ~[?:1.8.0_332]
	at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:51) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:32) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[hbase-shaded-netty-4.1.0.jar:?]
	... 1 more
Caused by: java.security.GeneralSecurityException: Checksum failed
	at sun.security.krb5.internal.crypto.dk.AesDkCrypto.decryptCTS(AesDkCrypto.java:451) ~[?:1.8.0_332]
	at sun.security.krb5.internal.crypto.dk.AesDkCrypto.decryptRaw(AesDkCrypto.java:291) ~[?:1.8.0_332]
	at sun.security.krb5.internal.crypto.Aes256.decryptRaw(Aes256.java:86) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.CipherHelper.aes256Decrypt(CipherHelper.java:1395) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.CipherHelper.decryptData(CipherHelper.java:574) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.WrapToken_v2.getData(WrapToken_v2.java:130) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.WrapToken_v2.getData(WrapToken_v2.java:105) ~[?:1.8.0_332]
	at sun.security.jgss.krb5.Krb5Context.unwrap(Krb5Context.java:1062) ~[?:1.8.0_332]
	at sun.security.jgss.GSSContextImpl.unwrap(GSSContextImpl.java:403) ~[?:1.8.0_332]
	at com.sun.security.sasl.gsskerb.GssKrb5Base.unwrap(GssKrb5Base.java:77) ~[?:1.8.0_332]
	at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:51) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hadoop.hbase.security.SaslUnwrapHandler.channelRead0(SaslUnwrapHandler.java:32) ~[hbase-client-2.5.1-SNAPSHOT.jar:2.5.1-SNAPSHOT]
	at org.apache.hbase.thirdparty.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:314) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:435) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:279) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[hbase-shaded-netty-4.1.0.jar:?]
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[hbase-shaded-netty-4.1.0.jar:?]
	... 1 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When I switch back to NettyRpcServer both the reads and writes complete successfully. &lt;/p&gt;

&lt;p&gt;Now that I can reproduce this perhaps I can make progess. &lt;/p&gt;

&lt;p&gt;javax.security.sasl.SaslException: Problems unwrapping SASL buffer &lt;span class=&quot;error&quot;&gt;&amp;#91;Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Could not use AES128 Cipher - Checksum failed)&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Checksum failed means the server side broke the SASL wrapping. Happens during reads. Happens when the values are perhaps large.&lt;/p&gt;</comment>
                            <comment id="17561632" author="apurtell" created="Fri, 1 Jul 2022 22:19:22 +0000"  >&lt;p&gt;Waiting for &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-27170&quot; title=&quot;ByteBuffAllocator leak when decompressing blocks near minSizeForReservoirUse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-27170&quot;&gt;&lt;del&gt;HBASE-27170&lt;/del&gt;&lt;/a&gt;. We are expecting a buffer management problem servicing reads, potentially only reads with values of a sufficient size, using SimpleRpcServer in the presence of SASL but assume the foundation is correct in the normal case (NettyRpcServer). It&apos;s not, see &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-27170&quot; title=&quot;ByteBuffAllocator leak when decompressing blocks near minSizeForReservoirUse&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-27170&quot;&gt;&lt;del&gt;HBASE-27170&lt;/del&gt;&lt;/a&gt;. Let&apos;s let that land and come back to this. &lt;/p&gt;</comment>
                            <comment id="17561703" author="vjasani" created="Sat, 2 Jul 2022 04:36:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;Let&apos;s let that land and come back to this.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1 &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurtell&quot; class=&quot;user-hover&quot; rel=&quot;apurtell&quot;&gt;apurtell&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17564622" author="apurtell" created="Sat, 9 Jul 2022 22:09:45 +0000"  >&lt;p&gt;Let me take this. &lt;/p&gt;</comment>
                            <comment id="17565185" author="apurtell" created="Mon, 11 Jul 2022 22:21:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/hbase/pull/4613&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hbase/pull/4613&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;Replace BufferChain#write(channel,int) with a simpler #write(channel) implementation that does not attempt to &quot;chunk&quot; data to be written. This method was used exclusively by SimpleRpcServer. The code was unnecessarily complex and caused short writes when values were large, which were exposed by MAC verification failures when SASL is enabled, so was corrected and simplified. Any difference in performance from this change will be limited to SimpleRpcServer. Testing under load confirms the fix and does not show significant regression.&lt;/p&gt;

&lt;p&gt;SimpleRpcServer and its related code is now also marked as @Deprecated.&lt;/p&gt;</comment>
                            <comment id="17565211" author="apurtell" created="Tue, 12 Jul 2022 01:08:41 +0000"  >&lt;p&gt;Copying another comment from the PR:&lt;/p&gt;

&lt;p&gt;Speaking of tests we don&apos;t actually have tests that exercise SimpleRpcServer, and by extension code that runs exclusively when it is active such as the BufferChain methods implicated here. The changes proposed on this PR were validated in a kerberized test environment using IntegrationTestLoadCommonCrawl. At this point with SimpleRpcServer deprecated I&apos;m not sure there is a good return on investment in adding tests. Perhaps something simple at least (pun, ha ha). What we really need is a test that runs SimpleRpcServer with Kerberos active (via MiniKdc?) and passes some reasonably large values around. And then without security active too, for symmetry. Let me think about it. I might have some time this week.&lt;/p&gt;</comment>
                            <comment id="17565949" author="apurtell" created="Tue, 12 Jul 2022 18:06:38 +0000"  >&lt;p&gt;Filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-27194&quot; title=&quot;Add test coverage for SimpleRpcServer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-27194&quot;&gt;&lt;del&gt;HBASE-27194&lt;/del&gt;&lt;/a&gt; for test coverage improvement.&lt;/p&gt;</comment>
                            <comment id="17566152" author="hudson" created="Wed, 13 Jul 2022 04:49:35 +0000"  >&lt;p&gt;Results for branch branch-2.4&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/388/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #388 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/388/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop2 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/388/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop2) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/388/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;red&quot;&gt;-1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.4/388/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="17566172" author="hudson" created="Wed, 13 Jul 2022 05:32:16 +0000"  >&lt;p&gt;Results for branch branch-2&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/591/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #591 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/591/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop2 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/591/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop2) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/591/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2/591/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="17566467" author="hudson" created="Wed, 13 Jul 2022 19:28:47 +0000"  >&lt;p&gt;Results for branch master&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/632/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #632 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/632/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;






&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/632/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/master/632/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="17566474" author="hudson" created="Wed, 13 Jul 2022 19:44:53 +0000"  >&lt;p&gt;Results for branch branch-2.5&lt;br/&gt;
	&lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/164/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;build #164 on builds.a.o&lt;/a&gt;: &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;details (if available):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 general checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/164/General_20Nightly_20Build_20Report/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see general report&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop2 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/164/JDK8_20Nightly_20Build_20Report_20_28Hadoop2_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop2) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk8 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/164/JDK8_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk8 (hadoop3) report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 jdk11 hadoop3 checks&lt;/font&gt;&lt;br/&gt;
&amp;#8211; For more information &lt;a href=&quot;https://ci-hbase.apache.org/job/HBase%20Nightly/job/branch-2.5/164/JDK11_20Nightly_20Build_20Report_20_28Hadoop3_29/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;see jdk11 report&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 source release artifact&lt;/font&gt;&lt;br/&gt;
&amp;#8211; See build output for details.&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;font color=&quot;green&quot;&gt;+1 client integration test&lt;/font&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="13469509">HBASE-27170</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13626041">HBASE-29515</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13424759">HBASE-26708</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13044874" name="MultiByteBuff.patch" size="619" author="binlijin" created="Fri, 10 Jun 2022 02:17:26 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="13471267">HBASE-27194</subtask>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 17 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1318g:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>