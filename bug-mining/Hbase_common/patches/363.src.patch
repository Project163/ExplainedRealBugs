diff --git a/hbase-common/pom.xml b/hbase-common/pom.xml
index ee56970273..c5f5a815a4 100644
--- a/hbase-common/pom.xml
+++ b/hbase-common/pom.xml
@@ -227,10 +227,6 @@
         </exclusion>
       </exclusions>
     </dependency>
-    <dependency>
-      <groupId>org.apache.hbase</groupId>
-      <artifactId>hbase-protocol</artifactId>
-    </dependency>
     <dependency>
       <groupId>org.apache.hbase</groupId>
       <artifactId>hbase-annotations</artifactId>
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ProcedureInfo.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ProcedureInfo.java
index 5bbff87930..451da12096 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ProcedureInfo.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ProcedureInfo.java
@@ -24,7 +24,6 @@ import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.hbase.security.User;
 import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
-import org.apache.hadoop.hbase.util.ForeignExceptionUtil;
 import org.apache.hadoop.hbase.util.NonceKey;
 import org.apache.hadoop.util.StringUtils;
 
@@ -40,7 +39,7 @@ public class ProcedureInfo implements Cloneable {
   private final ProcedureState procState;
   private final long parentId;
   private final NonceKey nonceKey;
-  private final ProcedureUtil.ForeignExceptionMsg exception;
+  private final IOException exception;
   private final long lastUpdate;
   private final long startTime;
   private final byte[] result;
@@ -55,7 +54,7 @@ public class ProcedureInfo implements Cloneable {
       final ProcedureState procState,
       final long parentId,
       final NonceKey nonceKey,
-      final ProcedureUtil.ForeignExceptionMsg exception,
+      final IOException exception,
       final long lastUpdate,
       final long startTime,
       final byte[] result) {
@@ -107,7 +106,7 @@ public class ProcedureInfo implements Cloneable {
 
     if (isFailed()) {
       sb.append(", exception=\"");
-      sb.append(getExceptionMessage());
+      sb.append(this.exception.getMessage());
       sb.append("\"");
     }
     sb.append(")");
@@ -152,29 +151,15 @@ public class ProcedureInfo implements Cloneable {
 
   public IOException getException() {
     if (isFailed()) {
-      return ForeignExceptionUtil.toIOException(exception.getForeignExchangeMessage());
+      return this.exception;
     }
     return null;
   }
 
-  @InterfaceAudience.Private
-  public ProcedureUtil.ForeignExceptionMsg getForeignExceptionMessage() {
-    return exception;
-  }
-
-  public String getExceptionCause() {
-    assert isFailed();
-    return exception.getForeignExchangeMessage().getGenericException().getClassName();
-  }
-
-  public String getExceptionMessage() {
-    assert isFailed();
-    return exception.getForeignExchangeMessage().getGenericException().getMessage();
-  }
-
   public String getExceptionFullMessage() {
     assert isFailed();
-    return getExceptionCause() + " - " + getExceptionMessage();
+    final IOException e = getException();
+    return e.getCause() + " - " + e.getMessage();
   }
 
   public boolean hasResultData() {
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ProcedureUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ProcedureUtil.java
deleted file mode 100644
index 2c935f3236..0000000000
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ProcedureUtil.java
+++ /dev/null
@@ -1,103 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.hbase;
-
-import org.apache.hadoop.hbase.classification.InterfaceAudience;
-import org.apache.hadoop.hbase.protobuf.generated.ProcedureProtos;
-import org.apache.hadoop.hbase.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage;
-import org.apache.hadoop.hbase.util.ByteStringer;
-import org.apache.hadoop.hbase.util.NonceKey;
-
-@InterfaceAudience.Private
-
-/**
- * Helper to convert to/from ProcedureProtos
- */
-public class ProcedureUtil {
-
-  private ProcedureUtil() {
-  }
-  /**
-   * @return Convert the current {@link ProcedureInfo} into a Protocol Buffers Procedure
-   * instance.
-   */
-  @InterfaceAudience.Private
-  public static ProcedureProtos.Procedure convertToProcedureProto(final ProcedureInfo procInfo) {
-    ProcedureProtos.Procedure.Builder builder = ProcedureProtos.Procedure.newBuilder();
-
-    builder.setClassName(procInfo.getProcName());
-    builder.setProcId(procInfo.getProcId());
-    builder.setStartTime(procInfo.getStartTime());
-    builder.setState(ProcedureProtos.ProcedureState.valueOf(procInfo.getProcState().name()));
-    builder.setLastUpdate(procInfo.getLastUpdate());
-
-    if (procInfo.hasParentId()) {
-      builder.setParentId(procInfo.getParentId());
-    }
-
-    if (procInfo.getProcOwner() != null) {
-      builder.setOwner(procInfo.getProcOwner());
-    }
-
-    if (procInfo.isFailed()) {
-      builder.setException(procInfo.getForeignExceptionMessage().getForeignExchangeMessage());
-    }
-
-    if (procInfo.hasResultData()) {
-      builder.setResult(ByteStringer.wrap(procInfo.getResult()));
-    }
-
-    return builder.build();
-  }
-
-  /**
-   * Helper to convert the protobuf object.
-   * @return Convert the current Protocol Buffers Procedure to {@link ProcedureInfo}
-   * instance.
-   */
-  @InterfaceAudience.Private
-  public static ProcedureInfo convert(final ProcedureProtos.Procedure procProto) {
-    NonceKey nonceKey = null;
-    if (procProto.getNonce() != HConstants.NO_NONCE) {
-      nonceKey = new NonceKey(procProto.getNonceGroup(), procProto.getNonce());
-    }
-
-    return new ProcedureInfo(procProto.getProcId(), procProto.getClassName(), procProto.getOwner(),
-        convertToProcedureState(procProto.getState()),
-        procProto.hasParentId() ? procProto.getParentId() : -1, nonceKey,
-        procProto.hasException() ? new ForeignExceptionMsg(procProto.getException()) : null,
-        procProto.getLastUpdate(), procProto.getStartTime(),
-        procProto.hasResult() ? procProto.getResult().toByteArray() : null);
-  }
-
-  public static ProcedureState convertToProcedureState(ProcedureProtos.ProcedureState state) {
-    return ProcedureState.valueOf(state.name());
-  }
-
-  public static class ForeignExceptionMsg {
-    private ForeignExceptionMessage exception;
-
-    public ForeignExceptionMsg(ForeignExceptionMessage exception) {
-      this.exception = exception;
-    }
-
-    public ForeignExceptionMessage getForeignExchangeMessage() {
-      return this.exception;
-    }
-  }
-}
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ServerName.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ServerName.java
index 12804df841..8d18db0bca 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ServerName.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ServerName.java
@@ -18,10 +18,6 @@
  */
 package org.apache.hadoop.hbase;
 
-import com.google.common.net.HostAndPort;
-import com.google.common.net.InetAddresses;
-import com.google.protobuf.InvalidProtocolBufferException;
-
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.List;
@@ -30,12 +26,12 @@ import java.util.regex.Pattern;
 
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
-import org.apache.hadoop.hbase.exceptions.DeserializationException;
-import org.apache.hadoop.hbase.protobuf.ProtobufMagic;
-import org.apache.hadoop.hbase.protobuf.generated.ZooKeeperProtos;
 import org.apache.hadoop.hbase.util.Addressing;
 import org.apache.hadoop.hbase.util.Bytes;
 
+import com.google.common.net.HostAndPort;
+import com.google.common.net.InetAddresses;
+
 /**
  * Instance of an HBase ServerName.
  * A server name is used uniquely identifying a server instance in a cluster and is made
@@ -369,47 +365,4 @@ import org.apache.hadoop.hbase.util.Bytes;
     if (str == null ||str.isEmpty()) return false;
     return SERVERNAME_PATTERN.matcher(str).matches();
   }
-
-  /**
-   * Get a ServerName from the passed in data bytes.
-   * @param data Data with a serialize server name in it; can handle the old style
-   * servername where servername was host and port.  Works too with data that
-   * begins w/ the pb 'PBUF' magic and that is then followed by a protobuf that
-   * has a serialized {@link ServerName} in it.
-   * @return Returns null if <code>data</code> is null else converts passed data
-   * to a ServerName instance.
-   * @throws DeserializationException 
-   */
-  public static ServerName parseFrom(final byte [] data) throws DeserializationException {
-    if (data == null || data.length <= 0) return null;
-    if (ProtobufMagic.isPBMagicPrefix(data)) {
-      int prefixLen = ProtobufMagic.lengthOfPBMagic();
-      try {
-        ZooKeeperProtos.Master rss =
-          ZooKeeperProtos.Master.PARSER.parseFrom(data, prefixLen, data.length - prefixLen);
-        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName sn = rss.getMaster();
-        return valueOf(sn.getHostName(), sn.getPort(), sn.getStartCode());
-      } catch (InvalidProtocolBufferException e) {
-        // A failed parse of the znode is pretty catastrophic. Rather than loop
-        // retrying hoping the bad bytes will changes, and rather than change
-        // the signature on this method to add an IOE which will send ripples all
-        // over the code base, throw a RuntimeException.  This should "never" happen.
-        // Fail fast if it does.
-        throw new DeserializationException(e);
-      }
-    }
-    // The str returned could be old style -- pre hbase-1502 -- which was
-    // hostname and port seperated by a colon rather than hostname, port and
-    // startcode delimited by a ','.
-    String str = Bytes.toString(data);
-    int index = str.indexOf(ServerName.SERVERNAME_SEPARATOR);
-    if (index != -1) {
-      // Presume its ServerName serialized with versioned bytes.
-      return ServerName.parseVersionedServerName(data);
-    }
-    // Presume it a hostname:port format.
-    String hostname = Addressing.parseHostname(str);
-    int port = Addressing.parsePort(str);
-    return valueOf(hostname, port, -1L);
-  }
-}
+}
\ No newline at end of file
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java
index 99f31b1cc1..2133750126 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java
@@ -23,9 +23,7 @@ import java.nio.ByteBuffer;
 import org.apache.hadoop.hbase.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.classification.InterfaceStability;
 import org.apache.hadoop.hbase.exceptions.DeserializationException;
-import org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos;
 import org.apache.hadoop.hbase.util.ByteBufferUtils;
-import org.apache.hadoop.hbase.util.ByteStringer;
 import org.apache.hadoop.hbase.util.Bytes;
 
 
@@ -57,13 +55,6 @@ public abstract class ByteArrayComparable implements Comparable<byte[]> {
    */
   public abstract byte [] toByteArray();
 
-  ComparatorProtos.ByteArrayComparable convert() {
-    ComparatorProtos.ByteArrayComparable.Builder builder =
-      ComparatorProtos.ByteArrayComparable.newBuilder();
-    if (value != null) builder.setValue(ByteStringer.wrap(value));
-    return builder.build();
-  }
-
   /**
    * @param pbBytes A pb serialized {@link ByteArrayComparable} instance
    * @return An instance of {@link ByteArrayComparable} made from <code>bytes</code>
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java
index 0fc0cb5b75..f42615a0e7 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/EncodedDataBlock.java
@@ -162,6 +162,8 @@ public class EncodedDataBlock {
    * @return Size of compressed data in bytes.
    * @throws IOException
    */
+  @edu.umd.cs.findbugs.annotations.SuppressWarnings(value="NP_NULL_ON_SOME_PATH_EXCEPTION",
+       justification="No sure what findbugs wants but looks to me like no NPE")
   public static int getCompressedSize(Algorithm algo, Compressor compressor,
       byte[] inputBuffer, int offset, int length) throws IOException {
 
@@ -186,7 +188,7 @@ public class EncodedDataBlock {
     } finally {
       nullOutputStream.close();
       compressedStream.close();
-      if (compressingStream != null) compressingStream.close();
+      compressingStream.close();
     }
   }
 
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/rsgroup/RSGroupInfo.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/rsgroup/RSGroupInfo.java
index 0fb02d8433..e68260a753 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/rsgroup/RSGroupInfo.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/rsgroup/RSGroupInfo.java
@@ -183,5 +183,4 @@ public class RSGroupInfo {
     result = 31 * result + name.hashCode();
     return result;
   }
-
-}
+}
\ No newline at end of file
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ForeignExceptionUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ForeignExceptionUtil.java
deleted file mode 100644
index f9aa531ff8..0000000000
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/ForeignExceptionUtil.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.hbase.util;
-
-import java.io.IOException;
-import java.lang.reflect.Constructor;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.hadoop.ipc.RemoteException;
-import org.apache.hadoop.hbase.classification.InterfaceAudience;
-import org.apache.hadoop.hbase.classification.InterfaceStability;
-import org.apache.hadoop.hbase.protobuf.generated.ErrorHandlingProtos.ForeignExceptionMessage;
-import org.apache.hadoop.hbase.protobuf.generated.ErrorHandlingProtos.GenericExceptionMessage;
-import org.apache.hadoop.hbase.protobuf.generated.ErrorHandlingProtos.StackTraceElementMessage;
-
-/**
- * Helper to convert Exceptions and StackTraces from/to protobuf.
- * (see ErrorHandling.proto for the internal of the proto messages)
- */
-@InterfaceAudience.Private
-@InterfaceStability.Evolving
-public final class ForeignExceptionUtil {
-  private ForeignExceptionUtil() { }
-
-  public static Exception toException(final ForeignExceptionMessage eem) {
-    final GenericExceptionMessage gem = eem.getGenericException();
-    final StackTraceElement[] trace = toStackTrace(gem.getTraceList());
-    try {
-      Class<?> realClass = Class.forName(gem.getClassName());
-      Class<? extends Exception> cls = realClass.asSubclass(Exception.class);
-      Constructor<? extends Exception> cn = cls.getConstructor(String.class);
-      cn.setAccessible(true);
-      Exception re = cn.newInstance(gem.getMessage());
-      re.setStackTrace(trace);
-      return re;
-    } catch (Throwable e) {
-      Exception re = new Exception(gem.getMessage());
-      re.setStackTrace(trace);
-      return re;
-    }
-  }
-
-  public static IOException toIOException(final ForeignExceptionMessage eem) {
-    GenericExceptionMessage gem = eem.getGenericException();
-    StackTraceElement[] trace = toStackTrace(gem.getTraceList());
-    RemoteException re = new RemoteException(gem.getClassName(), gem.getMessage());
-    re.setStackTrace(trace);
-    return re.unwrapRemoteException();
-  }
-
-  public static ForeignExceptionMessage toProtoForeignException(String source, Throwable t) {
-    GenericExceptionMessage.Builder gemBuilder = GenericExceptionMessage.newBuilder();
-    gemBuilder.setClassName(t.getClass().getName());
-    if (t.getMessage() != null) {
-      gemBuilder.setMessage(t.getMessage());
-    }
-    // set the stack trace, if there is one
-    List<StackTraceElementMessage> stack = toProtoStackTraceElement(t.getStackTrace());
-    if (stack != null) {
-      gemBuilder.addAllTrace(stack);
-    }
-    GenericExceptionMessage payload = gemBuilder.build();
-    ForeignExceptionMessage.Builder exception = ForeignExceptionMessage.newBuilder();
-    exception.setGenericException(payload).setSource(source);
-    return exception.build();
-  }
-
-  /**
-   * Convert a stack trace to list of {@link StackTraceElement}.
-   * @param trace the stack trace to convert to protobuf message
-   * @return <tt>null</tt> if the passed stack is <tt>null</tt>.
-   */
-  public static List<StackTraceElementMessage> toProtoStackTraceElement(StackTraceElement[] trace) {
-    // if there is no stack trace, ignore it and just return the message
-    if (trace == null) return null;
-    // build the stack trace for the message
-    List<StackTraceElementMessage> pbTrace = new ArrayList<StackTraceElementMessage>(trace.length);
-    for (StackTraceElement elem : trace) {
-      StackTraceElementMessage.Builder stackBuilder = StackTraceElementMessage.newBuilder();
-      stackBuilder.setDeclaringClass(elem.getClassName());
-      if (elem.getFileName() != null) {
-        stackBuilder.setFileName(elem.getFileName());
-      }
-      stackBuilder.setLineNumber(elem.getLineNumber());
-      stackBuilder.setMethodName(elem.getMethodName());
-      pbTrace.add(stackBuilder.build());
-    }
-    return pbTrace;
-  }
-
-  /**
-   * Unwind a serialized array of {@link StackTraceElementMessage}s to a
-   * {@link StackTraceElement}s.
-   * @param traceList list that was serialized
-   * @return the deserialized list or <tt>null</tt> if it couldn't be unwound (e.g. wasn't set on
-   *         the sender).
-   */
-  public static StackTraceElement[] toStackTrace(List<StackTraceElementMessage> traceList) {
-    if (traceList == null || traceList.size() == 0) {
-      return new StackTraceElement[0]; // empty array
-    }
-    StackTraceElement[] trace = new StackTraceElement[traceList.size()];
-    for (int i = 0; i < traceList.size(); i++) {
-      StackTraceElementMessage elem = traceList.get(i);
-      trace[i] = new StackTraceElement(
-          elem.getDeclaringClass(), elem.getMethodName(),
-          elem.hasFileName() ? elem.getFileName() : null,
-          elem.getLineNumber());
-    }
-    return trace;
-  }
-}
\ No newline at end of file
