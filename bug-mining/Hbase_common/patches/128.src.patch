diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoding.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoding.java
index 7ad338da2a..74d89420ae 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoding.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoding.java
@@ -173,7 +173,8 @@ public enum DataBlockEncoding {
     }
 
     DataBlockEncoding algorithm = idToEncoding.get(encoderId);
-    return algorithm.getClass().equals(encoder.getClass());
+    String encoderCls = encoder.getClass().getName();
+    return encoderCls.equals(algorithm.encoderCls);
   }
 
   public static DataBlockEncoding getEncodingById(short dataBlockEncodingId) {
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java
index add5fe7643..1b8f4ee97a 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java
@@ -52,8 +52,7 @@ public class HFileContext implements HeapSize, Cloneable {
   private int bytesPerChecksum = DEFAULT_BYTES_PER_CHECKSUM;
   /** Number of uncompressed bytes we allow per block. */
   private int blocksize = HConstants.DEFAULT_BLOCKSIZE;
-  private DataBlockEncoding encodingOnDisk = DataBlockEncoding.NONE;
-  private DataBlockEncoding encodingInCache = DataBlockEncoding.NONE;
+  private DataBlockEncoding encoding = DataBlockEncoding.NONE;
 
   //Empty constructor.  Go with setters
   public HFileContext() {
@@ -71,14 +70,12 @@ public class HFileContext implements HeapSize, Cloneable {
     this.checksumType = context.checksumType;
     this.bytesPerChecksum = context.bytesPerChecksum;
     this.blocksize = context.blocksize;
-    this.encodingOnDisk = context.encodingOnDisk;
-    this.encodingInCache = context.encodingInCache;
+    this.encoding = context.encoding;
   }
 
   public HFileContext(boolean useHBaseChecksum, boolean includesMvcc, boolean includesTags,
       Algorithm compressAlgo, boolean compressTags, ChecksumType checksumType,
-      int bytesPerChecksum, int blockSize, DataBlockEncoding encodingOnDisk,
-      DataBlockEncoding encodingInCache) {
+      int bytesPerChecksum, int blockSize, DataBlockEncoding encoding) {
     this.usesHBaseChecksum = useHBaseChecksum;
     this.includesMvcc =  includesMvcc;
     this.includesTags = includesTags;
@@ -87,8 +84,9 @@ public class HFileContext implements HeapSize, Cloneable {
     this.checksumType = checksumType;
     this.bytesPerChecksum = bytesPerChecksum;
     this.blocksize = blockSize;
-    this.encodingOnDisk = encodingOnDisk;
-    this.encodingInCache = encodingInCache;
+    if (encoding != null) {
+      this.encoding = encoding;
+    }
   }
 
   public Algorithm getCompression() {
@@ -135,12 +133,8 @@ public class HFileContext implements HeapSize, Cloneable {
     return blocksize;
   }
 
-  public DataBlockEncoding getEncodingOnDisk() {
-    return encodingOnDisk;
-  }
-
-  public DataBlockEncoding getEncodingInCache() {
-    return encodingInCache;
+  public DataBlockEncoding getDataBlockEncoding() {
+    return encoding;
   }
 
   /**
@@ -151,8 +145,8 @@ public class HFileContext implements HeapSize, Cloneable {
   @Override
   public long heapSize() {
     long size = ClassSize.align(ClassSize.OBJECT +
-        // Algorithm reference, encodingondisk, encodingincache, checksumtype
-        4 * ClassSize.REFERENCE +
+        // Algorithm reference, encoding, checksumtype
+        3 * ClassSize.REFERENCE +
         2 * Bytes.SIZEOF_INT +
         // usesHBaseChecksum, includesMvcc, includesTags and compressTags
         4 * Bytes.SIZEOF_BOOLEAN);
@@ -170,8 +164,7 @@ public class HFileContext implements HeapSize, Cloneable {
     clonnedCtx.checksumType = this.checksumType;
     clonnedCtx.bytesPerChecksum = this.bytesPerChecksum;
     clonnedCtx.blocksize = this.blocksize;
-    clonnedCtx.encodingOnDisk = this.encodingOnDisk;
-    clonnedCtx.encodingInCache = this.encodingInCache;
+    clonnedCtx.encoding = this.encoding;
     return clonnedCtx;
   }
 }
diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java
index 3a95080cbb..024b0ca3dd 100644
--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java
+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java
@@ -47,8 +47,7 @@ public class HFileContextBuilder {
   private int bytesPerChecksum = DEFAULT_BYTES_PER_CHECKSUM;
   /** Number of uncompressed bytes we allow per block. */
   private int blocksize = HConstants.DEFAULT_BLOCKSIZE;
-  private DataBlockEncoding encodingOnDisk = DataBlockEncoding.NONE;
-  private DataBlockEncoding encodingInCache = DataBlockEncoding.NONE;
+  private DataBlockEncoding encoding = DataBlockEncoding.NONE;
 
   public HFileContextBuilder withHBaseCheckSum(boolean useHBaseCheckSum) {
     this.usesHBaseChecksum = useHBaseCheckSum;
@@ -90,18 +89,13 @@ public class HFileContextBuilder {
     return this;
   }
 
-  public HFileContextBuilder withDataBlockEncodingOnDisk(DataBlockEncoding encodingOnDisk) {
-    this.encodingOnDisk = encodingOnDisk;
-    return this;
-  }
-
-  public HFileContextBuilder withDataBlockEncodingInCache(DataBlockEncoding encodingInCache) {
-    this.encodingInCache = encodingInCache;
+  public HFileContextBuilder withDataBlockEncoding(DataBlockEncoding encoding) {
+    this.encoding = encoding;
     return this;
   }
 
   public HFileContext build() {
     return new HFileContext(usesHBaseChecksum, includesMvcc, includesTags, compression,
-        compressTags, checksumType, bytesPerChecksum, blocksize, encodingOnDisk, encodingInCache);
+      compressTags, checksumType, bytesPerChecksum, blocksize, encoding);
   }
 }
