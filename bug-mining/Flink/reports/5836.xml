<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:05:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-24151] KafkaSink fails with setMaxConcurrentCheckpoints being enabled</title>
                <link>https://issues.apache.org/jira/browse/FLINK-24151</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;We experienced a &lt;tt&gt;RuntimeException&lt;/tt&gt; in a test run for &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-23850&quot; title=&quot;Test Kafka table connector with new runtime provider&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-23850&quot;&gt;&lt;del&gt;FLINK-23850&lt;/del&gt;&lt;/a&gt; :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.RuntimeException: Failed to send data to Kafka: This exception is raised by the broker &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; it could not locate the producer metadata associated with the producerId in question. This could happen &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; instance, the producer&lt;span class=&quot;code-quote&quot;&gt;&apos;s records were deleted because their retention time had elapsed. Once the last records of the producerId are removed, the producer&apos;&lt;/span&gt;s metadata is removed from the broker, and &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; appends by the producer will &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; exception.
        at org.apache.flink.connector.kafka.sink.KafkaWriter.checkErroneous(KafkaWriter.java:263) ~[flink-sql-connector-kafka_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.connector.kafka.sink.KafkaWriter.write(KafkaWriter.java:178) ~[flink-sql-connector-kafka_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.operators.sink.SinkOperator.processElement(SinkOperator.java:161) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:82) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:57) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:29) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:56) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:29) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.api.operators.StreamFilter.processElement(StreamFilter.java:39) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:82) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:57) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:29) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:56) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:29) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at StreamExecCalc$6.processElement(Unknown Source) ~[?:?]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:82) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:57) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:29) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:196) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36) ~[flink-sql-connector-kafka_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27) ~[flink-sql-connector-kafka_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:141) ~[flink-table_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:341) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:490) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:203) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:789) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:741) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:958) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:937) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:766) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575) ~[flink-dist_2.11-1.14-SNAPSHOT.jar:1.14-SNAPSHOT]
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748) ~[?:1.8.0_265]
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownProducerIdException: This exception is raised by the broker &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; it could not locate the producer metadata associated with the producerId in question. This could happen &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; instance, the producer&lt;span class=&quot;code-quote&quot;&gt;&apos;s records were deleted because their retention time had elapsed. Once the last records of the producerId are removed, the producer&apos;&lt;/span&gt;s metadata is removed from the broker, and &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; appends by the producer will &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; exception.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test job executed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        Configuration config = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration();
        config.set(ExecutionCheckpointingOptions.ENABLE_CHECKPOINTS_AFTER_TASKS_FINISH, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);

        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(config);
        env.setRuntimeMode(RuntimeExecutionMode.STREAMING);
        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(20, 2000));
        env.enableCheckpointing(10000, CheckpointingMode.EXACTLY_ONCE);
        env.getCheckpointConfig().setMaxConcurrentCheckpoints(2);
        env.setParallelism(6);

        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);

        tableEnv.createTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;T1&quot;&lt;/span&gt;,
                TableDescriptor.forConnector(&lt;span class=&quot;code-quote&quot;&gt;&quot;kafka&quot;&lt;/span&gt;)
                        .schema(Schema.newBuilder()
                                .column(&lt;span class=&quot;code-quote&quot;&gt;&quot;pk&quot;&lt;/span&gt;, DataTypes.STRING().notNull())
                                .column(&lt;span class=&quot;code-quote&quot;&gt;&quot;x&quot;&lt;/span&gt;, DataTypes.STRING().notNull())
                                .build())
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;topic&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;flink-23850-in1&quot;&lt;/span&gt;)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;properties.bootstrap.servers&quot;&lt;/span&gt;, FLINK23850Utils.BOOTSTRAP_SERVERS)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;value.format&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;scan.startup.mode&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;earliest-offset&quot;&lt;/span&gt;)
                        .build());

        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Table resultTable =
                tableEnv.sqlQuery(
                        &lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT &quot;&lt;/span&gt;
                                + &lt;span class=&quot;code-quote&quot;&gt;&quot;T1.pk, &quot;&lt;/span&gt;
                                + &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-quote&quot;&gt;&apos;asd&apos;&lt;/span&gt;, &quot;&lt;/span&gt;
                                + &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-quote&quot;&gt;&apos;foo&apos;&lt;/span&gt;, &quot;&lt;/span&gt;
                                + &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-quote&quot;&gt;&apos;bar&apos;&lt;/span&gt; &quot;&lt;/span&gt;
                                + &lt;span class=&quot;code-quote&quot;&gt;&quot;FROM T1&quot;&lt;/span&gt;);

        tableEnv.createTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;T4&quot;&lt;/span&gt;,
                TableDescriptor.forConnector(&lt;span class=&quot;code-quote&quot;&gt;&quot;kafka&quot;&lt;/span&gt;)
                        .schema(Schema.newBuilder()
                                .column(&lt;span class=&quot;code-quote&quot;&gt;&quot;pk&quot;&lt;/span&gt;, DataTypes.STRING().notNull())
                                .column(&lt;span class=&quot;code-quote&quot;&gt;&quot;some_calculated_value&quot;&lt;/span&gt;, DataTypes.STRING())
                                .column(&lt;span class=&quot;code-quote&quot;&gt;&quot;pk1&quot;&lt;/span&gt;, DataTypes.STRING())
                                .column(&lt;span class=&quot;code-quote&quot;&gt;&quot;pk2&quot;&lt;/span&gt;, DataTypes.STRING())
                                .build())
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;topic&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;flink-23850-out&quot;&lt;/span&gt;)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;properties.bootstrap.servers&quot;&lt;/span&gt;, FLINK23850Utils.BOOTSTRAP_SERVERS)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;value.format&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;sink.delivery-guarantee&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;exactly-once&quot;&lt;/span&gt;)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;sink.transactional-id-prefix&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;flink-23850&quot;&lt;/span&gt;)
                        .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;scan.startup.mode&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;earliest-offset&quot;&lt;/span&gt;)
                        .build());

        resultTable.executeInsert(&lt;span class=&quot;code-quote&quot;&gt;&quot;T4&quot;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13399243">FLINK-24151</key>
            <summary>KafkaSink fails with setMaxConcurrentCheckpoints being enabled</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="11">Done</resolution>
                                        <assignee username="arvid">Arvid Heise</assignee>
                                    <reporter username="mapohl">Matthias Pohl</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 Sep 2021 12:27:20 +0000</created>
                <updated>Tue, 7 Sep 2021 06:36:07 +0000</updated>
                            <resolved>Tue, 7 Sep 2021 06:36:07 +0000</resolved>
                                    <version>1.14.0</version>
                                    <fixVersion>1.14.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="17410944" author="arvid" created="Tue, 7 Sep 2021 06:35:16 +0000"  >&lt;p&gt;This is a Kafka broker issue, probably the root cause of &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9310&quot; title=&quot;StreamThread may die from recoverable UnknownProducerId exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9310&quot;&gt;&lt;del&gt;KAFKA-9310&lt;/del&gt;&lt;/a&gt;. From what I can see, it some kind of concurrency issue where the broker is just not able to write to a transaction right after another transaction was committed.&lt;/p&gt;

&lt;p&gt;We could reliably reproduce the issue with Kafka broker running on 2.4.1. But where unable to see the issue on 2.5.X or 2.7.X.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2021-09-06 16:48:14,620 DEBUG org.apache.flink.connector.kafka.sink.FlinkKafkaInternalProducer [] - Change transaction id from flink-23850-2-6 to flink-23850-2-8
2021-09-06 16:48:14,620 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager [] - [Producer clientId=producer-flink-23850-2-2, transactionalId=flink-23850-2-2] ProducerId set to -1 with epoch -1
2021-09-06 16:48:14,622 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager [] - [Producer clientId=producer-flink-23850-2-2, transactionalId=flink-23850-2-2] ProducerId set to 10041 with epoch 91
2021-09-06 16:48:14,622 INFO  org.apache.flink.connector.kafka.sink.KafkaWriter            [] - Created new transactional producer flink-23850-2-8
2021-09-06 16:48:14,629 INFO  org.apache.flink.streaming.runtime.operators.sink.AbstractStreamingCommitterHandler [] - Committing the state for checkpoint 7
2021-09-06 16:48:14,629 DEBUG org.apache.flink.connector.kafka.sink.KafkaCommitter         [] - Committing Kafka transaction flink-23850-2-7
2021-09-06 16:48:14,629 DEBUG org.apache.flink.connector.kafka.sink.FlinkKafkaInternalProducer [] - commitTransaction flink-23850-2-7
...
2021-09-06 16:48:14,980 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - Source: KafkaSource-default_catalog.default_database.T1 -&amp;gt; Calc(select=[pk, _UTF-16LE&apos;asd&apos; AS EXPR$1, _UTF-16LE&apos;foo&apos; AS EXPR$2, _UTF-16LE&apos;bar&apos; AS EXPR$3]) -&amp;gt; NotNullEnforcer(fields=[pk]) -&amp;gt; Sink Sink(table=[default_catalog.default_database.T4], fields=[pk, EXPR$1, EXPR$2, EXPR$3]) (3/6)#0 (a32ab17fecae6d2f69bba01bc2c6f21c) switched from RUNNING to FAILED with failure cause: org.apache.flink.util.FlinkRuntimeException: Failed to send data to Kafka flink-23850-out-0@-1 with FlinkKafkaInternalProducer{transactionalId=&apos;flink-23850-2-8&apos;, inTransaction=true, closed=false}
	at org.apache.flink.connector.kafka.sink.KafkaWriter$WriterCallback.lambda$onCompletion$0(KafkaWriter.java:383)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:338)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:324)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:201)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:789)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:741)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:958)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:937)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:766)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:575)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.flink.kafka.shaded.org.apache.kafka.common.errors.UnknownProducerIdException: This exception is raised by the broker if it could not locate the producer metadata associated with the producerId in question. This could happen if, for instance, the producer&apos;s records were deleted because their retention time had elapsed. Once the last records of the producerId are removed, the producer&apos;s metadata is removed from the broker, and future appends by the producer will return this exception.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The solution is similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9310&quot; title=&quot;StreamThread may die from recoverable UnknownProducerId exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9310&quot;&gt;&lt;del&gt;KAFKA-9310&lt;/del&gt;&lt;/a&gt;: just restart. However, Flink users probably experience longer downtime on average because of larger applications and state. Hence, we will give directly feedback to upgrade Kafka to 2.5+.&lt;/p&gt;

&lt;p&gt;This will be solved as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-24131&quot; title=&quot;KafkaSinkITCase &amp;quot;Detected producer leak&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-24131&quot;&gt;&lt;del&gt;FLINK-24131&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                                                <inwardlinks description="is superceded by">
                                        <issuelink>
            <issuekey id="13398963">FLINK-24131</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310760">
                    <name>Testing</name>
                                                                <inwardlinks description="Discovered while testing">
                                        <issuelink>
            <issuekey id="13395798">FLINK-23850</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13033004" name="release-testing-run-6.tar.gz" size="115844" author="mapohl" created="Fri, 3 Sep 2021 12:34:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 10 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0ulbk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>