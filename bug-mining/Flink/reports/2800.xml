<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:37:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10874] Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10874</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://api.travis-ci.org/v3/job/454449444/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/454449444/log.txt&lt;/a&gt;&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Test testMigrateFromAtLeastOnceToExactlyOnce(org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerITCase) is running.
--------------------------------------------------------------------------------
16:35:07,894 WARN  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer  - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
16:35:07,903 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer  - Starting FlinkKafkaInternalProducer (1/1) to produce into default topic testMigrateFromAtLeastOnceToExactlyOnce
16:35:08,785 ERROR org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerITCase  - 
--------------------------------------------------------------------------------
Test testMigrateFromAtLeastOnceToExactlyOnce(org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerITCase) failed with:
java.lang.Exception: Could not complete snapshot 0 for operator MockTask (1/1).
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.snapshotState(AbstractStreamOperator.java:419)
	at org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.snapshotWithLocalState(AbstractStreamOperatorTestHarness.java:505)
	at org.apache.flink.streaming.util.AbstractStreamOperatorTestHarness.snapshot(AbstractStreamOperatorTestHarness.java:497)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerITCase.testRecoverWithChangeSemantics(FlinkKafkaProducerITCase.java:591)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducerITCase.testMigrateFromAtLeastOnceToExactlyOnce(FlinkKafkaProducerITCase.java:569)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
Caused by: org.apache.flink.streaming.connectors.kafka.FlinkKafkaException: Failed to send data to Kafka: This server does not host this topic-partition.
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.checkErroneous(FlinkKafkaProducer.java:993)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.flush(FlinkKafkaProducer.java:778)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.preCommit(FlinkKafkaProducer.java:705)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.preCommit(FlinkKafkaProducer.java:94)
	at org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction.snapshotState(TwoPhaseCommitSinkFunction.java:291)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.snapshotState(FlinkKafkaProducer.java:783)
	at org.apache.flink.streaming.util.functions.StreamingFunctionUtils.trySnapshotFunctionState(StreamingFunctionUtils.java:118)
	at org.apache.flink.streaming.util.functions.StreamingFunctionUtils.snapshotFunctionState(StreamingFunctionUtils.java:99)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.snapshotState(AbstractUdfStreamOperator.java:90)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.snapshotState(AbstractStreamOperator.java:395)
	... 36 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13198260">FLINK-10874</key>
            <summary>Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="5">Cannot Reproduce</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="pnowojski">Piotr Nowojski</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 14 Nov 2018 08:35:32 +0000</created>
                <updated>Mon, 3 Dec 2018 12:56:35 +0000</updated>
                            <resolved>Fri, 30 Nov 2018 08:44:48 +0000</resolved>
                                    <version>1.8.0</version>
                                    <fixVersion>1.7.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16686361" author="pnowojski" created="Wed, 14 Nov 2018 10:59:44 +0000"  >&lt;p&gt;Google search for this error suggests that usually this error happens around broker restarting and re-electing the leaders. Maybe this is some kind of an after shock of restarting a broker from another test.&lt;/p&gt;

&lt;p&gt;Maybe this will be fixed by: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10838&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-10838&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16686473" author="githubbot" created="Wed, 14 Nov 2018 12:59:17 +0000"  >&lt;p&gt;pnowojski opened a new pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   This is a change in documentation only.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687625" author="githubbot" created="Thu, 15 Nov 2018 08:07:16 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r233741900&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r233741900&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Moreover, the connectors for 0.8 and 0.9+ uses different Kafka Java APIs. Might want to point that out.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687626" author="githubbot" created="Thu, 15 Nov 2018 08:07:16 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r233741559&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r233741559&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;br/&gt;
+and your problem might be independent of Flink and sometimes can be solved by upgrading Kafka brokers,&lt;br/&gt;
+reconfiguring Kafka brokers or reconfiguring &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt; in Flink.&lt;br/&gt;
+Some examples of common problems are listed below.&lt;br/&gt;
+&amp;lt;/div&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+### Data loss&lt;br/&gt;
+&lt;br/&gt;
+Depending on your Kafka configuration, even after Kafka acknowledges&lt;br/&gt;
+writes you can still experience data loss. In particular keep in mind about following properties&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   about &quot;the&quot; following properties&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687627" author="githubbot" created="Thu, 15 Nov 2018 08:07:16 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r233741735&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r233741735&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Can we include links to the Javadocs for `KafkaConsumer` and `KafkaProducer`?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687628" author="githubbot" created="Thu, 15 Nov 2018 08:07:16 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r233741497&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r233741497&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;br/&gt;
+and your problem might be independent of Flink and sometimes can be solved by upgrading Kafka brokers,&lt;br/&gt;
+reconfiguring Kafka brokers or reconfiguring &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt; in Flink.&lt;br/&gt;
+Some examples of common problems are listed below.&lt;br/&gt;
+&amp;lt;/div&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+### Data loss&lt;br/&gt;
+&lt;br/&gt;
+Depending on your Kafka configuration, even after Kafka acknowledges&lt;br/&gt;
+writes you can still experience data loss. In particular keep in mind about following properties&lt;br/&gt;
+in Kafka config:&lt;br/&gt;
+&lt;br/&gt;
+- `acks`&lt;br/&gt;
+- `log.flush.interval.messages`&lt;br/&gt;
+- `log.flush.interval.ms`&lt;br/&gt;
+- `log.flush.*`&lt;br/&gt;
+&lt;br/&gt;
+Default values for the above options can easily lead to data loss.&lt;br/&gt;
+Please refer to the Kafka documentation for more explanation.&lt;br/&gt;
+&lt;br/&gt;
+### UnknownTopicOrPartitionException&lt;br/&gt;
+&lt;br/&gt;
+One possible cause of this error is when a new leader election is taking place,&lt;br/&gt;
+for example after or during restarting a Kafka broker.&lt;br/&gt;
+This is a retriable exception, so Flink job should be able to restart and resume normal operation.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   As a comment that is independent of the PR:&lt;br/&gt;
   Have we thought about catching this exception, and reassigning the new elected partitions to the client?&lt;br/&gt;
   I&apos;m curious if this is possible and a proper solution on Flink&apos;s side.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687774" author="githubbot" created="Thu, 15 Nov 2018 10:31:10 +0000"  >&lt;p&gt;pnowojski commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r233788608&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r233788608&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;br/&gt;
+and your problem might be independent of Flink and sometimes can be solved by upgrading Kafka brokers,&lt;br/&gt;
+reconfiguring Kafka brokers or reconfiguring &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt; in Flink.&lt;br/&gt;
+Some examples of common problems are listed below.&lt;br/&gt;
+&amp;lt;/div&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+### Data loss&lt;br/&gt;
+&lt;br/&gt;
+Depending on your Kafka configuration, even after Kafka acknowledges&lt;br/&gt;
+writes you can still experience data loss. In particular keep in mind about following properties&lt;br/&gt;
+in Kafka config:&lt;br/&gt;
+&lt;br/&gt;
+- `acks`&lt;br/&gt;
+- `log.flush.interval.messages`&lt;br/&gt;
+- `log.flush.interval.ms`&lt;br/&gt;
+- `log.flush.*`&lt;br/&gt;
+&lt;br/&gt;
+Default values for the above options can easily lead to data loss.&lt;br/&gt;
+Please refer to the Kafka documentation for more explanation.&lt;br/&gt;
+&lt;br/&gt;
+### UnknownTopicOrPartitionException&lt;br/&gt;
+&lt;br/&gt;
+One possible cause of this error is when a new leader election is taking place,&lt;br/&gt;
+for example after or during restarting a Kafka broker.&lt;br/&gt;
+This is a retriable exception, so Flink job should be able to restart and resume normal operation.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Dunno, it would require some independent work to investigate it. I don&apos;t know how severe/often is that issue to weight it&apos;s priority. Probably not very frequent.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687775" author="githubbot" created="Thu, 15 Nov 2018 10:31:10 +0000"  >&lt;p&gt;pnowojski commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r233782492&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r233782492&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   That would be an external link to Kafka docs (for what version?). &lt;/p&gt;

&lt;p&gt;   What do you mean different Kafka Java APIs? (I&apos;m/I wasn&apos;t aware of that, so I don&apos;t know what should I point out)&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16704419" author="pnowojski" created="Fri, 30 Nov 2018 08:44:48 +0000"  >&lt;p&gt;I haven&apos;t seen Kafka 2.0 test failure since upgrading Kafka to &lt;tt&gt;2.0.1&lt;/tt&gt;. Closing this issue for now. Please re-open if you spot this error again.&lt;/p&gt;</comment>
                            <comment id="16707012" author="githubbot" created="Mon, 3 Dec 2018 11:15:14 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r238228646&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r238228646&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Kafka 0.8 uses a lower-level client called `SimpleConsumer`: &lt;a href=&quot;https://www.javadoc.io/doc/org.apache.kafka/kafka_2.10/0.8.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.javadoc.io/doc/org.apache.kafka/kafka_2.10/0.8.0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;   Other versions use a higher level client, called the `KafkaConsumer`:&lt;br/&gt;
   &lt;a href=&quot;https://kafka.apache.org/10/javadoc/?org/apache/kafka/clients/consumer/KafkaConsumer.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://kafka.apache.org/10/javadoc/?org/apache/kafka/clients/consumer/KafkaConsumer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16707013" author="githubbot" created="Mon, 3 Dec 2018 11:15:33 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r238228741&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r238228741&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;br/&gt;
+and your problem might be independent of Flink and sometimes can be solved by upgrading Kafka brokers,&lt;br/&gt;
+reconfiguring Kafka brokers or reconfiguring &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt; in Flink.&lt;br/&gt;
+Some examples of common problems are listed below.&lt;br/&gt;
+&amp;lt;/div&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+### Data loss&lt;br/&gt;
+&lt;br/&gt;
+Depending on your Kafka configuration, even after Kafka acknowledges&lt;br/&gt;
+writes you can still experience data loss. In particular keep in mind about following properties&lt;br/&gt;
+in Kafka config:&lt;br/&gt;
+&lt;br/&gt;
+- `acks`&lt;br/&gt;
+- `log.flush.interval.messages`&lt;br/&gt;
+- `log.flush.interval.ms`&lt;br/&gt;
+- `log.flush.*`&lt;br/&gt;
+&lt;br/&gt;
+Default values for the above options can easily lead to data loss.&lt;br/&gt;
+Please refer to the Kafka documentation for more explanation.&lt;br/&gt;
+&lt;br/&gt;
+### UnknownTopicOrPartitionException&lt;br/&gt;
+&lt;br/&gt;
+One possible cause of this error is when a new leader election is taking place,&lt;br/&gt;
+for example after or during restarting a Kafka broker.&lt;br/&gt;
+This is a retriable exception, so Flink job should be able to restart and resume normal operation.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Alright, as I mentioned, this shouldn&apos;t affect the PR. Lets keep it as is.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16707154" author="githubbot" created="Mon, 3 Dec 2018 12:54:16 +0000"  >&lt;p&gt;pnowojski commented on a change in pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097#discussion_r238256735&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097#discussion_r238256735&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/dev/connectors/kafka.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -804,4 +776,36 @@ When using standalone Flink deployment, you can also use `SASL_SSL`; please see&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt;&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Ok, done. Thanks for the review @tzulitai.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16707156" author="githubbot" created="Mon, 3 Dec 2018 12:54:44 +0000"  >&lt;p&gt;pnowojski closed pull request #7097: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10874&quot; title=&quot;Kafka 2.0 connector testMigrateFromAtLeastOnceToExactlyOnce failure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10874&quot;&gt;&lt;del&gt;FLINK-10874&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-docs&amp;#93;&lt;/span&gt; Document likely cause of UnknownTopicOrPartitionException&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7097&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7097&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/docs/dev/connectors/kafka.md b/docs/dev/connectors/kafka.md&lt;br/&gt;
index 0630c6ec7d6..351a4dc2d41 100644&lt;br/&gt;
&amp;#8212; a/docs/dev/connectors/kafka.md&lt;br/&gt;
+++ b/docs/dev/connectors/kafka.md&lt;br/&gt;
@@ -660,19 +660,6 @@ we recommend setting the number of retries to a higher value.&lt;br/&gt;
 *&lt;b&gt;Note&lt;/b&gt;*: There is currently no transactional producer for Kafka, so Flink can not guarantee exactly-once delivery&lt;br/&gt;
 into a Kafka topic.&lt;/p&gt;

&lt;p&gt;-&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;strong&amp;gt;Attention:&amp;lt;/strong&amp;gt; Depending on your Kafka configuration, even after Kafka acknowledges&lt;/li&gt;
	&lt;li&gt;writes you can still experience data loss. In particular keep in mind the following Kafka settings:&lt;/li&gt;
	&lt;li&gt;&amp;lt;ul&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;acks&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;log.flush.interval.messages&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;log.flush.interval.ms&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;log.flush.*&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/ul&amp;gt;&lt;/li&gt;
	&lt;li&gt;Default values for the above options can easily lead to data loss. Please refer to Kafka documentation&lt;/li&gt;
	&lt;li&gt;for more explanation.&lt;br/&gt;
-&amp;lt;/div&amp;gt;&lt;br/&gt;
-
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;
			&lt;ol&gt;
				&lt;li&gt;Kafka 0.11 and newer&lt;/li&gt;
			&lt;/ol&gt;
			&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; With Flink&apos;s checkpointing enabled, the `FlinkKafkaProducer011` (`FlinkKafkaProducer` for Kafka &amp;gt;= 1.0.0 versions) can provide&lt;br/&gt;
@@ -690,21 +677,6 @@ chosen by passing appropriate `semantic` parameter to the `FlinkKafkaProducer011&lt;br/&gt;
  or `read_uncommitted` - the latter one is the default value) for any application consuming records&lt;br/&gt;
  from Kafka.&lt;/p&gt;

&lt;p&gt;-&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;strong&amp;gt;Attention:&amp;lt;/strong&amp;gt; Depending on your Kafka configuration, even after Kafka acknowledges&lt;/li&gt;
	&lt;li&gt;writes you can still experience data losses. In particular keep in mind about following properties&lt;/li&gt;
	&lt;li&gt;in Kafka config:&lt;/li&gt;
	&lt;li&gt;&amp;lt;ul&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;acks&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;log.flush.interval.messages&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;log.flush.interval.ms&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;&amp;lt;tt&amp;gt;log.flush.*&amp;lt;/tt&amp;gt;&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/ul&amp;gt;&lt;/li&gt;
	&lt;li&gt;Default values for the above options can easily lead to data loss. Please refer to the Kafka documentation&lt;/li&gt;
	&lt;li&gt;for more explanation.&lt;br/&gt;
-&amp;lt;/div&amp;gt;&lt;br/&gt;
-&lt;br/&gt;
-
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;
			&lt;ol&gt;
				&lt;li&gt;
				&lt;ol&gt;
					&lt;li&gt;Caveats&lt;/li&gt;
				&lt;/ol&gt;
				&lt;/li&gt;
			&lt;/ol&gt;
			&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; `Semantic.EXACTLY_ONCE` mode relies on the ability to commit transactions&lt;br/&gt;
@@ -831,4 +803,38 @@ A mismatch in service name between client and server configuration will cause th&lt;br/&gt;
 For more information on Flink configuration for Kerberos security, please see &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/config.html).&lt;br/&gt;
 You can also find &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;({{ site.baseurl}}/ops/security-kerberos.html) further details on how Flink internally setups Kerberos-based security.&lt;/p&gt;

&lt;p&gt;+## Troubleshooting&lt;br/&gt;
+&lt;br/&gt;
+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+If you have a problem with Kafka when using Flink, keep in mind that Flink only wraps&lt;br/&gt;
+&amp;lt;a href=&quot;https://kafka.apache.org/documentation/#consumerapi&quot;&amp;gt;KafkaConsumer&amp;lt;/a&amp;gt; or&lt;br/&gt;
+&amp;lt;a href=&quot;https://kafka.apache.org/documentation/#producerapi&quot;&amp;gt;KafkaProducer&amp;lt;/a&amp;gt;&lt;br/&gt;
+and your problem might be independent of Flink and sometimes can be solved by upgrading Kafka brokers,&lt;br/&gt;
+reconfiguring Kafka brokers or reconfiguring &amp;lt;tt&amp;gt;KafkaConsumer&amp;lt;/tt&amp;gt; or &amp;lt;tt&amp;gt;KafkaProducer&amp;lt;/tt&amp;gt; in Flink.&lt;br/&gt;
+Some examples of common problems are listed below.&lt;br/&gt;
+&amp;lt;/div&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+### Data loss&lt;br/&gt;
+&lt;br/&gt;
+Depending on your Kafka configuration, even after Kafka acknowledges&lt;br/&gt;
+writes you can still experience data loss. In particular keep in mind about the following properties&lt;br/&gt;
+in Kafka config:&lt;br/&gt;
+&lt;br/&gt;
+- `acks`&lt;br/&gt;
+- `log.flush.interval.messages`&lt;br/&gt;
+- `log.flush.interval.ms`&lt;br/&gt;
+- `log.flush.*`&lt;br/&gt;
+&lt;br/&gt;
+Default values for the above options can easily lead to data loss.&lt;br/&gt;
+Please refer to the Kafka documentation for more explanation.&lt;br/&gt;
+&lt;br/&gt;
+### UnknownTopicOrPartitionException&lt;br/&gt;
+&lt;br/&gt;
+One possible cause of this error is when a new leader election is taking place,&lt;br/&gt;
+for example after or during restarting a Kafka broker.&lt;br/&gt;
+This is a retriable exception, so Flink job should be able to restart and resume normal operation.&lt;br/&gt;
+It also can be circumvented by changing `retries` property in the producer settings.&lt;br/&gt;
+However this might cause reordering of messages,&lt;br/&gt;
+which in turn if undesired can be circumvented by setting `max.in.flight.requests.per.connection` to 1.&lt;br/&gt;
+&lt;/p&gt;
 {% top %}




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16707160" author="pnowojski" created="Mon, 3 Dec 2018 12:56:35 +0000"  >&lt;p&gt;merged commit 59ebdb2 into apache:master&lt;br/&gt;
merged commit 7b23bf69e8 into apache:release-1.7&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13197370">FLINK-10838</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 50 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s00gxk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>