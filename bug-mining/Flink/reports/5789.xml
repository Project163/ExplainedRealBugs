<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:01:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-23896] The new KafkaSink drops data if job fails between checkpoint and transaction commit.</title>
                <link>https://issues.apache.org/jira/browse/FLINK-23896</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;ul&gt;
	&lt;li&gt;Any time a new &lt;b&gt;transactional producer&lt;/b&gt; is started, &quot;&lt;a href=&quot;https://kafka.apache.org/24/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html#initTransactions--&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;KafkaProducer#initTransactions()&lt;/a&gt;&quot;&#160;needs to be called in order to obtain new &lt;b&gt;ProducerId&lt;/b&gt; from &lt;b&gt;TransactionCoordinator&lt;/b&gt; (Kafka Broker component).
	&lt;ul&gt;
		&lt;li&gt;&lt;b&gt;ProducerId&lt;/b&gt; is increased every time a new producer with the same &lt;b&gt;TransactionalId&lt;/b&gt; is registered.&lt;/li&gt;
		&lt;li&gt;Publication of new ProducerId &lt;b&gt;FENCES&lt;/b&gt; all prior ProducerIds and &lt;b&gt;ABORTS&lt;/b&gt; all of uncommitted transactions assigned with them.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;KafkaCommitter&lt;/b&gt; uses a separate producer, that hacks into Kafka internals and resumes transaction using epoch and producer, without actually assigning a new ProducerId for itself. This committer uses &lt;b&gt;ProducerId&lt;/b&gt; that is stored in &lt;b&gt;KafkaComittable&lt;/b&gt; state to commit transaction.&lt;/li&gt;
	&lt;li&gt;If a &lt;b&gt;new producer is started before committing the transaction&lt;/b&gt; (this can happen in some failover scenarios), ProducerId stored in the state is already &lt;b&gt;FENCED&lt;/b&gt; and commit fails with &lt;b&gt;ProducerFencedException&lt;/b&gt;. Because we currently ignore this exception (we just log a warning), we effectively &lt;b&gt;DROP&lt;/b&gt; all uncommitted data from the previous checkpoint.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Basically any job failure that happens between successfully taking a checkpoint and committing transactions, will trigger this behavior.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13396314">FLINK-23896</key>
            <summary>The new KafkaSink drops data if job fails between checkpoint and transaction commit.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="arvid">Arvid Heise</assignee>
                                    <reporter username="dmvk">David Mor&#225;vek</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 20 Aug 2021 08:57:34 +0000</created>
                <updated>Wed, 17 Nov 2021 15:21:36 +0000</updated>
                            <resolved>Wed, 1 Sep 2021 06:50:10 +0000</resolved>
                                                    <fixVersion>1.14.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17402120" author="fabian.paul" created="Fri, 20 Aug 2021 09:12:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dmvk&quot; class=&quot;user-hover&quot; rel=&quot;dmvk&quot;&gt;dmvk&lt;/a&gt;&#160;thanks for looking into this. I am not sure your analysis is fully correct since in the current implementation it should be guaranteed that a transaction that is in the committer state is not reused by the KafkaWriter to write new records. This would cause the epoch to increase and fence the committer.&#160;&lt;/p&gt;

&lt;p&gt;Unfortunately, the current and old implementation has the downside that it indeed might lose data if the transaction is part of the checkpoint but not committed, the job fails and is not restarted until Kafka aborts the transactions. We recommend setting a high enough transaction timeout to alleviate this problem.&lt;/p&gt;</comment>
                            <comment id="17402127" author="davidmoravek" created="Fri, 20 Aug 2021 09:41:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpaul&quot; class=&quot;user-hover&quot; rel=&quot;fpaul&quot;&gt;fpaul&lt;/a&gt; We&apos;ve already discussed this with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arvid&quot; class=&quot;user-hover&quot; rel=&quot;arvid&quot;&gt;arvid&lt;/a&gt; a little bit. You&apos;re right that TransactionalId is unique, that something I&apos;ve missed. Can you please see the attached test case that simulates the issue if you can get an explanation for the ProducerFencedException?&lt;/p&gt;

&lt;p&gt;I&apos;m aware of potential problem with transaction timeouts (TX expiring on the broker side).&lt;/p&gt;</comment>
                            <comment id="17402135" author="davidmoravek" created="Fri, 20 Aug 2021 10:07:59 +0000"  >&lt;p&gt;After the hint with the transactional id uniqueness I did a second pass on the issue, the actual problem seems to be in the transaction abortion mechanism. Symptoms I&apos;ve described are still valid here.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
NEW PRODUCER kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-1
NEW PRODUCER kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-2
FAIL BEFORE AFTER CHECKPOINT / BEFORE COMMIT...
ABORT kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-1
ABORT kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-2
NEW PRODUCER kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-3
NEW PRODUCER kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-4
COMMIT kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-1
FENCED kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-1 &amp;lt;--------------- We need to commit &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; one.
COMMIT kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-3
NEW PRODUCER kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-5
COMMIT kafka-sink-d8b78c12-f8ba-45ae-99f5-e3426c31ec91-0-4
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17402186" author="davidmoravek" created="Fri, 20 Aug 2021 12:29:14 +0000"  >&lt;p&gt;NOTE: I&apos;ve tried exactly the same testing scenario for the old &lt;b&gt;FlinkKafkaProducer&lt;/b&gt; and it passes.&lt;/p&gt;</comment>
                            <comment id="17402188" author="fabian.paul" created="Fri, 20 Aug 2021 12:36:58 +0000"  >&lt;p&gt;I think the seen problem is not only affecting KafkaSink but all sinks implementing FLIP-143. The interface claims that if committing fails the committables should be returned &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;. Unfortunately, this behaviour was not implemented, and returning failed committables runs into an UnsupportedOperationException&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;. This means all errors happening during committing cause potential data loss.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://github.com/apache/flink/blob/273dce5b030e12dd3d7bebb2f51036a198d07112/flink-core/src/main/java/org/apache/flink/api/connector/sink/Committer.java#L39&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/blob/273dce5b030e12dd3d7bebb2f51036a198d07112/flink-core/src/main/java/org/apache/flink/api/connector/sink/Committer.java#L39&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;&#160;&lt;a href=&quot;https://github.com/apache/flink/blob/273dce5b030e12dd3d7bebb2f51036a198d07112/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/AbstractStreamingCommitterHandler.java#L141&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/blob/273dce5b030e12dd3d7bebb2f51036a198d07112/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/AbstractStreamingCommitterHandler.java#L141&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17403238" author="fabian.paul" created="Mon, 23 Aug 2021 15:25:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dmvk&quot; class=&quot;user-hover&quot; rel=&quot;dmvk&quot;&gt;dmvk&lt;/a&gt;&#160;after having a more careful look at the problem we have two different kind of problems in this ticket.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;It is currently not guaranteed that transactional ids are not reused which is causing the fencing exceptions because the recovered sink writer will initialize a transaction id which the committer is still trying to commit. This problem will be solved by &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-23854&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-23854&lt;/a&gt;&#160;whereby the transactionalId is including the checkpoint counter so the same transactionalId is never reused.&lt;/li&gt;
	&lt;li&gt;FLIP-143 planned that sink-committer-operators can retry failed committables by simply returning the failed ones from the commit method. Unfortunately, this was never implemented but I opened a PR &lt;a href=&quot;https://github.com/apache/flink/pull/16945&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/16945&lt;/a&gt;&#160;to fix it. It also enables retries for the KafkaCommitter i.e. in case the network becomes unstable during committing the committable will be retried on the next checkpoint.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I think this should solve the found problem. Please correct me If I missed something.&lt;/p&gt;</comment>
                            <comment id="17403702" author="davidmoravek" created="Tue, 24 Aug 2021 09:25:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpaul&quot; class=&quot;user-hover&quot; rel=&quot;fpaul&quot;&gt;fpaul&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For 1), if we guarantee this and fix the abortion mechanism (currently implemented in TransactionsToAbortChecker), that by itself should be enough to resolve this issue.&lt;/p&gt;

&lt;p&gt;For 2), I think we already have a &quot;retry mechanism&quot; in terms of, if we&apos;re not able to commit, we just restart the job. But more fine-grained approach would be great here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="17407881" author="arvid" created="Wed, 1 Sep 2021 06:50:10 +0000"  >&lt;p&gt;This issue has been solved as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-23854&quot; title=&quot;KafkaSink error when restart from the checkpoint with a lower parallelism by exactly-once guarantee&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-23854&quot;&gt;&lt;del&gt;FLINK-23854&lt;/del&gt;&lt;/a&gt; where we implemented retry logic on the SinkOperator level.&lt;/p&gt;</comment>
                            <comment id="17408166" author="arvid" created="Wed, 1 Sep 2021 13:25:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruanhang1993&quot; class=&quot;user-hover&quot; rel=&quot;ruanhang1993&quot;&gt;ruanhang1993&lt;/a&gt; manually verified that this particular issue was solved in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-23814&quot; title=&quot;Test FLIP-143 KafkaSink&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-23814&quot;&gt;&lt;del&gt;FLINK-23814&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13395837">FLINK-23854</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13395484">FLINK-23814</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13395700">FLINK-23839</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0u39c:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>