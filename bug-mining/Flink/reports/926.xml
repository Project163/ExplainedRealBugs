<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:23:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-1159] Case style anonymous functions not supported by Scala API</title>
                <link>https://issues.apache.org/jira/browse/FLINK-1159</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;In Scala it is very common to define anonymous functions of the following form&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;{
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; foo: Bar =&amp;gt; foobar(foo)
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RuntimeException()
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These case style anonymous functions are not supported yet by the Scala API. Thus, one has to write redundant code to name the function parameter.&lt;/p&gt;

&lt;p&gt;What works is the following pattern, but it is not intuitive for someone coming from Scala:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;dataset.map{
  _ match{
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; foo:Bar =&amp;gt; ...
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12747763">FLINK-1159</key>
            <summary>Case style anonymous functions not supported by Scala API</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="stefanobaghino">Stefano Baghino</assignee>
                                    <reporter username="trohrmann">Till Rohrmann</reporter>
                        <labels>
                    </labels>
                <created>Mon, 13 Oct 2014 16:43:32 +0000</created>
                <updated>Wed, 2 Oct 2019 17:42:35 +0000</updated>
                            <resolved>Mon, 4 Apr 2016 19:33:22 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>API / Scala</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14170675" author="aljoscha" created="Tue, 14 Oct 2014 08:36:22 +0000"  >&lt;p&gt;Yes, I&apos;m aware of this problem. The type checker cannot deal with it when the map function that takes a MapFunction is present. When you comment that one out you can use the &quot;case-style&quot; functions.&lt;/p&gt;</comment>
                            <comment id="14170687" author="rmetzger" created="Tue, 14 Oct 2014 08:48:40 +0000"  >&lt;p&gt;Mh. How about adding an additional method with a different name for that case?&lt;br/&gt;
Will Scala be able to support this at some point or is it a fundamental limitation?&lt;/p&gt;</comment>
                            <comment id="14216081" author="stephanewen" created="Tue, 18 Nov 2014 11:36:29 +0000"  >&lt;p&gt;Can we ever resolve this issue? Unless the Scala compiler improves the type checker?&lt;/p&gt;</comment>
                            <comment id="14219165" author="aljoscha" created="Thu, 20 Nov 2014 09:24:45 +0000"  >&lt;p&gt;I think we could only resolve it if we renamed the functions that take for example a MapFunction. So we would have mapRich() and map(). But that&apos;s a bit ugly.&lt;/p&gt;</comment>
                            <comment id="15150174" author="stefanobaghino" created="Wed, 17 Feb 2016 09:27:24 +0000"  >&lt;p&gt;If that&apos;s ok with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aljoscha&quot; class=&quot;user-hover&quot; rel=&quot;aljoscha&quot;&gt;aljoscha&lt;/a&gt; I would assign this issue to me as I&apos;ve started working on a solution (&lt;a href=&quot;https://github.com/radicalbit/flink/commits/1159-implicit&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;) that resulted from a mailing list discussion with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt; (&lt;a href=&quot;http://apache-flink-mailing-list-archive.1008284.n3.nabble.com/Case-style-anonymous-functions-not-supported-by-Scala-API-td10052.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="15150198" author="stephanewen" created="Wed, 17 Feb 2016 09:46:53 +0000"  >&lt;p&gt;Sure, I&apos;ll assign the issue you. As far as I know, Aljoscha is not currently working on this...&lt;/p&gt;</comment>
                            <comment id="15150214" author="aljoscha" created="Wed, 17 Feb 2016 09:54:59 +0000"  >&lt;p&gt;Assigned it to you.&lt;/p&gt;</comment>
                            <comment id="15162888" author="githubbot" created="Wed, 24 Feb 2016 12:08:24 +0000"  >&lt;p&gt;GitHub user stefanobaghino opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-1159&quot; title=&quot;Case style anonymous functions not supported by Scala API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-1159&quot;&gt;&lt;del&gt;FLINK-1159&lt;/del&gt;&lt;/a&gt; Case style anonymous functions not supported by Scala API&lt;/p&gt;

&lt;p&gt;    The proposed API extension methods would allow developers to pass a pattern matching anonymous function so that they are applied on a `DataSet` or `DataStream`; many methods defined on the `DataSet` and `DataStream` APIs don&apos;t support those functions due to the overloading[&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;][&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;]; pattern matching anonymous functions allow a very idiomatic approach in Scala to &lt;b&gt;decompose tuples, case classes and collections&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;    The PR does not pollute the original `DataSet` and `DataStream` APIs but is provided as an optional set of extensions methods, implemented via implicit conversions and made available to the developer by explicitly importing the required package, e.g.:&lt;/p&gt;

&lt;p&gt;    ```scala&lt;br/&gt;
    import org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    env.fromElements(&apos;a -&amp;gt; 1, &apos;b -&amp;gt; 2).mapWith &lt;/p&gt;
{
      case (key, value) =&amp;gt;
        ... // key and value are now available and have a sensible name
    }
&lt;p&gt;    ```&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;: &lt;a href=&quot;https://groups.google.com/d/msg/scala-user/3oHnDEl1UsM/dDNir9BsiG4J&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://groups.google.com/d/msg/scala-user/3oHnDEl1UsM/dDNir9BsiG4J&lt;/a&gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;: &lt;a href=&quot;http://www.scala-lang.org/files/archive/spec/2.11/06-expressions.html#overloading-resolution&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.scala-lang.org/files/archive/spec/2.11/06-expressions.html#overloading-resolution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/radicalbit/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/radicalbit/flink&lt;/a&gt; 1159&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1704&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 61d184075cce9fa4f3a8e477634adef083d3a070&lt;br/&gt;
Author: Stefano Baghino &amp;lt;stefano@baghino.me&amp;gt;&lt;br/&gt;
Date:   2016-02-24T12:05:16Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-1159&quot; title=&quot;Case style anonymous functions not supported by Scala API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-1159&quot;&gt;&lt;del&gt;FLINK-1159&lt;/del&gt;&lt;/a&gt; Case style anonymous functions not supported by Scala API&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15163088" author="githubbot" created="Wed, 24 Feb 2016 14:35:16 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53945878&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53945878&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,174 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Isn&apos;t it called `keyingBy`?&lt;/p&gt;</comment>
                            <comment id="15163089" author="githubbot" created="Wed, 24 Feb 2016 14:35:41 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53945929&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53945929&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,174 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This won&apos;t work. You have to import `org.apache.flink.api.scala.extensions.acceptPartialFunctions._`&lt;/p&gt;</comment>
                            <comment id="15163091" author="githubbot" created="Wed, 24 Feb 2016 14:36:27 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53946030&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53946030&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,174 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Sorry forget my comment.&lt;/p&gt;</comment>
                            <comment id="15163094" author="githubbot" created="Wed, 24 Feb 2016 14:36:55 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53946101&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53946101&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,133 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{JoinedStreams, CoGroupedStreams, KeyedStream, DataStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Shouldn&apos;t this be called `keyingBy`?&lt;/p&gt;</comment>
                            <comment id="15163095" author="githubbot" created="Wed, 24 Feb 2016 14:37:36 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53946205&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53946205&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,133 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{JoinedStreams, CoGroupedStreams, KeyedStream, DataStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    import shouldn&apos;t work if I&apos;m not mistaken&lt;/p&gt;</comment>
                            <comment id="15163107" author="githubbot" created="Wed, 24 Feb 2016 14:43:24 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53947144&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53947144&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,133 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{JoinedStreams, CoGroupedStreams, KeyedStream, DataStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +  *         case (id, value) =&amp;gt; id
    +  *       }
&lt;p&gt;    +  *     }&lt;br/&gt;
    +  *   }&lt;br/&gt;
    +  * }}}&lt;br/&gt;
    +  *&lt;br/&gt;
    +  */&lt;br/&gt;
    +package object acceptPartialFunctions {&lt;br/&gt;
    +&lt;br/&gt;
    +  implicit class OnDataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(stream: DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) &lt;/p&gt;
{
    +
    +    /**
    +      * Applies a function `fun` to each item of the stream
    +      *
    +      * @param fun The function to be applied to each item
    +      * @tparam R The type of the items in the returned stream
    +      * @return A dataset of R
    +      */
    +    def mapWith[R: TypeInformation: ClassTag](fun: T =&amp;gt; R): DataStream[R] =
    +      stream.map(fun)
    +
    +    /**
    +      * Applies a function `fun` to each item of the stream, producing a collection of items
    +      * that will be flattened in the resulting stream
    +      *
    +      * @param fun The function to be applied to each item
    +      * @tparam R The type of the items in the returned stream
    +      * @return A dataset of R
    +      */
    +    def flatMapWith[R: TypeInformation: ClassTag](fun: T =&amp;gt; TraversableOnce[R]): DataStream[R] =
    +      stream.flatMap(fun)
    +
    +    /**
    +      * Applies a predicate `fun` to each item of the stream, keeping only those for which
    +      * the predicate holds
    +      *
    +      * @param fun The predicate to be tested on each item
    +      * @return A dataset of R
    +      */
    +    def filterWith(fun: T =&amp;gt; Boolean): DataStream[T] =
    +      stream.filter(fun)
    +
    +    /**
    +      * Keys the items according to a keying function `fun`
    +      *
    +      * @param fun The keying function
    +      * @tparam K The type of the key, for which type information must be known
    +      * @return A stream of Ts keyed by Ks
    +      */
    +    def keyingBy[K: TypeInformation: ClassTag](fun: T =&amp;gt; K): KeyedStream[T, K] =
    +      stream.keyBy(fun)
    +
    +  }
&lt;p&gt;    +&lt;br/&gt;
    +  implicit class OnKeyedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation, K&amp;#93;&lt;/span&gt;(stream: KeyedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    What is with the `fold` operation?&lt;/p&gt;</comment>
                            <comment id="15163108" author="githubbot" created="Wed, 24 Feb 2016 14:44:02 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53947242&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53947242&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,133 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{JoinedStreams, CoGroupedStreams, KeyedStream, DataStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +  *         case (id, value) =&amp;gt; id
    +  *       }
&lt;p&gt;    +  *     }&lt;br/&gt;
    +  *   }&lt;br/&gt;
    +  * }}}&lt;br/&gt;
    +  *&lt;br/&gt;
    +  */&lt;br/&gt;
    +package object acceptPartialFunctions {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think the `ConnectedStreams` and `WindowedStreams` are missing.&lt;/p&gt;</comment>
                            <comment id="15163114" author="githubbot" created="Wed, 24 Feb 2016 14:48:58 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53948074&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53948074&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,174 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +  *         case (id, value) =&amp;gt; id
    +  *       }
&lt;p&gt;    +  *     }&lt;br/&gt;
    +  *   }&lt;br/&gt;
    +  * }}}&lt;br/&gt;
    +  *&lt;br/&gt;
    +  */&lt;br/&gt;
    +package object acceptPartialFunctions {&lt;br/&gt;
    +&lt;br/&gt;
    +  implicit class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to each item&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.mapPartition &lt;/p&gt;
{
    +        (it, out) =&amp;gt;
    +          out.collect(fun(it.to[Seq]))
    +      }&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to each item of the dataset, producing a collection of items&lt;br/&gt;
    +      * that will be flattened in the resulting data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to each item&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def flatMapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; TraversableOnce&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.flatMap(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a predicate `fun` to each item of the data set, keeping only those for which&lt;br/&gt;
    +      * the predicate holds&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The predicate to be tested on each item&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def filterWith(fun: T =&amp;gt; Boolean): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.filter(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a reducer `fun` to the data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The reducing function to be applied on the whole data set&lt;br/&gt;
    +      * @tparam R The type of the items in the returned collection&lt;br/&gt;
    +      * @return A data set of Rs&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def reduceWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: (T, T) =&amp;gt; T): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.reduce(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a reducer `fun` to a grouped data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to the whole grouping&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of Rs&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def reduceGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.reduceGroup {    +        (it, out) =&amp;gt;    +          out.collect(fun(it.to[Seq]))    +      }
&lt;p&gt;    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Groups the items according to a grouping function `fun`&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The grouping function&lt;br/&gt;
    +      * @tparam K The return type of the grouping function, for which type information must be known&lt;br/&gt;
    +      * @return A grouped data set of Ts&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def groupingBy&lt;span class=&quot;error&quot;&gt;&amp;#91;K: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; K): GroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.groupBy(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  implicit class OnJoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L: TypeInformation, R: TypeInformation&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      dataset: JoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt;) &lt;/p&gt;
{
    +
    +    /**
    +      * Joins the data sets using the function `fun` to project elements from both in the
    +      * resulting data set
    +      *
    +      * @param fun The function that defines the projection of the join
    +      * @tparam O The return type of the projection, for which type information must be known
    +      * @return A fully joined data set of Os
    +      */
    +    def projecting[O: TypeInformation: ClassTag](fun: (L, R) =&amp;gt; O): DataSet[O] =
    +      dataset(fun)
    +
    +  }
&lt;p&gt;    +&lt;br/&gt;
    +  implicit class OnCoGroupDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L: TypeInformation, R: TypeInformation&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      dataset: CoGroupDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Co-groups the data sets using the function `fun` to project elements from both in&lt;br/&gt;
    +      * the resulting data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function that defines the projection of the co-group operation&lt;br/&gt;
    +      * @tparam O The return type of the projection, for which type information must be known&lt;br/&gt;
    +      * @return A fully co-grouped data set of Os&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def projecting&lt;span class=&quot;error&quot;&gt;&amp;#91;O: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: (Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;L&amp;#93;&lt;/span&gt;, Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;) =&amp;gt; O): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;O&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      dataset &lt;/p&gt;
{
    +        (left, right) =&amp;gt;
    +          fun(left.to[Seq], right.to[Seq])
    +      }
&lt;p&gt;    +&lt;br/&gt;
    +  }&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `GroupedDataSet` is missing&lt;/p&gt;</comment>
                            <comment id="15163115" author="githubbot" created="Wed, 24 Feb 2016 14:49:17 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53948137&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53948137&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,174 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +  *         case (id, value) =&amp;gt; id
    +  *       }
&lt;p&gt;    +  *     }&lt;br/&gt;
    +  *   }&lt;br/&gt;
    +  * }}}&lt;br/&gt;
    +  *&lt;br/&gt;
    +  */&lt;br/&gt;
    +package object acceptPartialFunctions {&lt;br/&gt;
    +&lt;br/&gt;
    +  implicit class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to each item&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.mapPartition &lt;/p&gt;
{
    +        (it, out) =&amp;gt;
    +          out.collect(fun(it.to[Seq]))
    +      }&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to each item of the dataset, producing a collection of items&lt;br/&gt;
    +      * that will be flattened in the resulting data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to each item&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def flatMapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; TraversableOnce&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.flatMap(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a predicate `fun` to each item of the data set, keeping only those for which&lt;br/&gt;
    +      * the predicate holds&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The predicate to be tested on each item&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def filterWith(fun: T =&amp;gt; Boolean): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.filter(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a reducer `fun` to the data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The reducing function to be applied on the whole data set&lt;br/&gt;
    +      * @tparam R The type of the items in the returned collection&lt;br/&gt;
    +      * @return A data set of Rs&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def reduceWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: (T, T) =&amp;gt; T): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.reduce(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a reducer `fun` to a grouped data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to the whole grouping&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of Rs&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def reduceGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.reduceGroup {    +        (it, out) =&amp;gt;    +          out.collect(fun(it.to[Seq]))    +      }
&lt;p&gt;    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Groups the items according to a grouping function `fun`&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The grouping function&lt;br/&gt;
    +      * @tparam K The return type of the grouping function, for which type information must be known&lt;br/&gt;
    +      * @return A grouped data set of Ts&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def groupingBy&lt;span class=&quot;error&quot;&gt;&amp;#91;K: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; K): GroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.groupBy(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  implicit class OnJoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L: TypeInformation, R: TypeInformation&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      dataset: JoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt;) &lt;/p&gt;
{
    +
    +    /**
    +      * Joins the data sets using the function `fun` to project elements from both in the
    +      * resulting data set
    +      *
    +      * @param fun The function that defines the projection of the join
    +      * @tparam O The return type of the projection, for which type information must be known
    +      * @return A fully joined data set of Os
    +      */
    +    def projecting[O: TypeInformation: ClassTag](fun: (L, R) =&amp;gt; O): DataSet[O] =
    +      dataset(fun)
    +
    +  }
&lt;p&gt;    +&lt;br/&gt;
    +  implicit class OnCoGroupDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L: TypeInformation, R: TypeInformation&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      dataset: CoGroupDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Co-groups the data sets using the function `fun` to project elements from both in&lt;br/&gt;
    +      * the resulting data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function that defines the projection of the co-group operation&lt;br/&gt;
    +      * @tparam O The return type of the projection, for which type information must be known&lt;br/&gt;
    +      * @return A fully co-grouped data set of Os&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def projecting&lt;span class=&quot;error&quot;&gt;&amp;#91;O: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: (Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;L&amp;#93;&lt;/span&gt;, Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;) =&amp;gt; O): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;O&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      dataset &lt;/p&gt;
{
    +        (left, right) =&amp;gt;
    +          fun(left.to[Seq], right.to[Seq])
    +      }
&lt;p&gt;    +&lt;br/&gt;
    +  }&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `CrossDataSet` is missing&lt;/p&gt;</comment>
                            <comment id="15163119" author="githubbot" created="Wed, 24 Feb 2016 14:50:14 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53948314&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53948314&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,174 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +  *         case (id, value) =&amp;gt; id
    +  *       }
&lt;p&gt;    +  *     }&lt;br/&gt;
    +  *   }&lt;br/&gt;
    +  * }}}&lt;br/&gt;
    +  *&lt;br/&gt;
    +  */&lt;br/&gt;
    +package object acceptPartialFunctions {&lt;br/&gt;
    +&lt;br/&gt;
    +  implicit class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to each item&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.mapPartition &lt;/p&gt;
{
    +        (it, out) =&amp;gt;
    +          out.collect(fun(it.to[Seq]))
    +      }&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a function `fun` to each item of the dataset, producing a collection of items&lt;br/&gt;
    +      * that will be flattened in the resulting data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to each item&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def flatMapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; TraversableOnce&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.flatMap(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a predicate `fun` to each item of the data set, keeping only those for which&lt;br/&gt;
    +      * the predicate holds&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The predicate to be tested on each item&lt;br/&gt;
    +      * @return A dataset of R&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def filterWith(fun: T =&amp;gt; Boolean): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.filter(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a reducer `fun` to the data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The reducing function to be applied on the whole data set&lt;br/&gt;
    +      * @tparam R The type of the items in the returned collection&lt;br/&gt;
    +      * @return A data set of Rs&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def reduceWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: (T, T) =&amp;gt; T): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.reduce(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Applies a reducer `fun` to a grouped data set&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The function to be applied to the whole grouping&lt;br/&gt;
    +      * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +      * @return A dataset of Rs&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def reduceGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.reduceGroup {    +        (it, out) =&amp;gt;    +          out.collect(fun(it.to[Seq]))    +      }
&lt;p&gt;    +&lt;br/&gt;
    +    /**&lt;br/&gt;
    +      * Groups the items according to a grouping function `fun`&lt;br/&gt;
    +      *&lt;br/&gt;
    +      * @param fun The grouping function&lt;br/&gt;
    +      * @tparam K The return type of the grouping function, for which type information must be known&lt;br/&gt;
    +      * @return A grouped data set of Ts&lt;br/&gt;
    +      */&lt;br/&gt;
    +    def groupingBy&lt;span class=&quot;error&quot;&gt;&amp;#91;K: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; K): GroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +      ds.groupBy(fun)&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `combineGroupWith` is not supported.&lt;/p&gt;</comment>
                            <comment id="15163134" author="githubbot" created="Wed, 24 Feb 2016 14:55:50 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188289230&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188289230&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for your contribution @stefanobaghino. I really like this feature a lot &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;    Currently, the implementation is not complete, because the supported set of API calls is not complete. &lt;/p&gt;

&lt;p&gt;    With the current packaging structure one would always have to import `org.apache.flink.api.scala.extensions.acceptPartialFunctions.&lt;em&gt;`. I would rather like to import the following to get partial function support `org.apache.flink.api.scala.extensions.acceptPartialFunctions` or if I want to import all extensions: `org.apache.flink.api.scala.extensions.&lt;/em&gt;`. We could achieve this by introducing an `extensions` package object which does something like:&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
    package object extensions {&lt;br/&gt;
      implicit def acceptPartialFunctions&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;):&lt;br/&gt;
        DataStreamWithPartialFunctionSupport&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
        new DataStreamWithPartialFunctionSupport[T](ds)
      }
&lt;p&gt;    ```&lt;/p&gt;

&lt;p&gt;    What do you think?&lt;/p&gt;

</comment>
                            <comment id="15163135" author="githubbot" created="Wed, 24 Feb 2016 14:56:29 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188289888&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188289888&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    It would also be great to add some tests to make sure that the import is working. Furthermore, it would be great to add documentation for the extension feature.&lt;/p&gt;</comment>
                            <comment id="15163153" author="githubbot" created="Wed, 24 Feb 2016 15:05:40 +0000"  >&lt;p&gt;Github user stefanobaghino commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53950747&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53950747&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,174 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yup, leftover from the previous implementation, thanks for pointing it out, I&apos;ll fix this.&lt;/p&gt;</comment>
                            <comment id="15163154" author="githubbot" created="Wed, 24 Feb 2016 15:06:29 +0000"  >&lt;p&gt;Github user stefanobaghino commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r53950863&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r53950863&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,133 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{JoinedStreams, CoGroupedStreams, KeyedStream, DataStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +  * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +  * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +  * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +  * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * e.g.&lt;br/&gt;
    +  * {{{&lt;br/&gt;
    +  *   object Main {&lt;br/&gt;
    +  *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +  *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +  *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +  *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +  *       ds.filterWith &lt;/p&gt;
{
    +  *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +  *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +  *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +  *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +  *         case Point(x, y) =&amp;gt; (x, y)
    +  *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +  *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +  *       }
&lt;p&gt;.groupingBy {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Copy/paste error, good catch! I&apos;ll fix this.&lt;/p&gt;</comment>
                            <comment id="15163168" author="githubbot" created="Wed, 24 Feb 2016 15:15:31 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188301093&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188301093&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks @tillrohrmann, I&apos;ll fix the errors in the comments and add the missing methods and extensions.&lt;/p&gt;

&lt;p&gt;    Regarding the import mode, I agree with you. I started off with just one `DataSet` but then had to support many, I&apos;ll try to go back to the original design while retaining multiple &#180;DataSet&#180; subtype extensions.&lt;/p&gt;

&lt;p&gt;    The only thing I&apos;m not very convinced of from your snippet is about returning the extended `DataStreamWithPartialFunctionSupport` class. Implicit conversions have no runtime cost, so maybe it would be better to just return the `DataSet` to make the code more compact and readable. What do you think?&lt;/p&gt;

&lt;p&gt;    Regarding the tests: I actually have some tests in place locally but basically they&apos;re just copies of the original tests on the operators. Should I commit them as well?&lt;/p&gt;

&lt;p&gt;    Regarding the docs: absolutely, I wasn&apos;t sure about this. Where do you think it would be better to put them? Should I add a new chapter under the programming guides?&lt;/p&gt;</comment>
                            <comment id="15163236" author="githubbot" created="Wed, 24 Feb 2016 16:01:53 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188320230&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188320230&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    How do you want to do the implicit conversion if you return a `DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;`. If it makes the code more readable, then I think it&apos;s a good idea &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;    We should have a test, which makes sure that the implicit conversion works when you import the corresponding package. That should be enough.&lt;/p&gt;

&lt;p&gt;    I think we could add the documentation to the streaming guide. We could add a new page with the methods and link it from the scala tab of &lt;span class=&quot;error&quot;&gt;&amp;#91;DataStream Transformations&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/index.html#datastream-transformations&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/index.html#datastream-transformations&lt;/a&gt;) in the streaming guide.&lt;/p&gt;</comment>
                            <comment id="15163252" author="githubbot" created="Wed, 24 Feb 2016 16:08:46 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188325067&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188325067&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Just the streaming guide? Not on both the streaming and batch?&lt;/p&gt;</comment>
                            <comment id="15163269" author="githubbot" created="Wed, 24 Feb 2016 16:18:16 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188329671&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188329671&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Of course, you&apos;re right. Also in the batch guide &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15163278" author="githubbot" created="Wed, 24 Feb 2016 16:25:02 +0000"  >&lt;p&gt;Github user StephanEwen commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188335368&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188335368&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Looks very nice in my opinion.&lt;/p&gt;

&lt;p&gt;    Could you remove the `ClassTag` context bounds? We recently removed them from `DataStream`, because they are not needed.&lt;/p&gt;</comment>
                            <comment id="15163298" author="githubbot" created="Wed, 24 Feb 2016 16:39:29 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188343795&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188343795&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    :+1: @StephanEwen I started working on the extension before the removal, will fix this as well, thanks for the feedback.&lt;/p&gt;</comment>
                            <comment id="15163318" author="githubbot" created="Wed, 24 Feb 2016 16:58:05 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188352497&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188352497&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann I got mixed up reading your proposal and just got what you meant with the `extensions.acceptPartialFunctions` implicit conversion, thanks for the tip, I&apos;ll add it to the PR as well.&lt;/p&gt;</comment>
                            <comment id="15163540" author="githubbot" created="Wed, 24 Feb 2016 19:08:16 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188409068&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188409068&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    This should cover the missing implementations. I also included the tests I used to test the functionality, let me know if you prefer a wider coverage. I&apos;ll provide the docs ASAP.&lt;/p&gt;</comment>
                            <comment id="15167209" author="githubbot" created="Thu, 25 Feb 2016 13:50:35 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-188790808&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-188790808&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen I had to restore some of the context bounds on `ClassTag` to make it compile, apparently the delegated methods use them; I&apos;ve rebased with the latest changes on the master before putting them back in place.&lt;/p&gt;</comment>
                            <comment id="15168847" author="githubbot" created="Fri, 26 Feb 2016 11:31:34 +0000"  >&lt;p&gt;Github user StephanEwen commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-189232475&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-189232475&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @stefanobaghino Ah, yes, for `DataSet` you need the `ClassTag`, for `DataStream` they should not be needed...&lt;/p&gt;</comment>
                            <comment id="15177907" author="githubbot" created="Thu, 3 Mar 2016 14:55:32 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-191799798&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-191799798&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    There are scalastyle violations in the code:&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
    error file=/home/travis/build/apache/flink/flink-tests/src/test/scala/org/apache/flink/api/scala/extensions/AcceptPFFilterITCase.scala message=File must end with newline character&lt;br/&gt;
    error file=/home/travis/build/apache/flink/flink-tests/src/test/scala/org/apache/flink/api/scala/extensions/AcceptPFFlatMapITCase.scala message=File must end with newline character&lt;br/&gt;
    error file=/home/travis/build/apache/flink/flink-tests/src/test/scala/org/apache/flink/api/scala/extensions/AcceptPFMapITCase.scala message=File must end with newline character&lt;br/&gt;
    ```&lt;/p&gt;</comment>
                            <comment id="15179814" author="githubbot" created="Fri, 4 Mar 2016 12:21:41 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-192259307&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-192259307&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann Yes, I&apos;ve already fixed them locally, thanks for the notice and for pinging me. I&apos;m working on the documentation, sorry if it&apos;s taking me a little bit longer than expected but I had little time this week. I want to complete the PR by Sunday evening.&lt;/p&gt;</comment>
                            <comment id="15180750" author="githubbot" created="Fri, 4 Mar 2016 23:32:01 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-192522625&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-192522625&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I&apos;ve squashed the commits, I don&apos;t know what I was thinking about. :disappointed: &lt;br/&gt;
    This should more or less be it, I&apos;d just like to add more tests to cover all the operators.&lt;/p&gt;</comment>
                            <comment id="15190712" author="githubbot" created="Fri, 11 Mar 2016 09:39:33 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-195290267&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-195290267&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann The tests failure seem to be flaky, I&apos;ve re-run them all on our fork and they&apos;re all green now (after a couple of retries).&lt;/p&gt;</comment>
                            <comment id="15191349" author="githubbot" created="Fri, 11 Mar 2016 18:36:57 +0000"  >&lt;p&gt;Github user StephanEwen commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-195491606&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-195491606&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    This pull request adds a lot of tests (which is actually good), but all tests fire up a cluster to execute many programs. But need to somehow get this down, as these &quot;fire up mini cluster&quot; tests have made our build times explode.&lt;/p&gt;

&lt;p&gt;    Is actual program execution needed here? Or is it sufficient to see that the partial function for a certain transformation creates such a transformation?&lt;/p&gt;</comment>
                            <comment id="15193188" author="githubbot" created="Mon, 14 Mar 2016 12:36:56 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55993580&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55993580&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/OnDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,104 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{GroupedDataSet, DataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied to each item&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.mapPartition {&lt;br/&gt;
    +      (it, out) =&amp;gt;&lt;br/&gt;
    +        out.collect(fun(it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;))&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Does `it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;` materializes the `iterator`? If so, then this is not so good because you can run out of memory.&lt;/p&gt;</comment>
                            <comment id="15193189" author="githubbot" created="Mon, 14 Mar 2016 12:37:29 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55993625&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55993625&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/OnDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,104 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{GroupedDataSet, DataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied to each item&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.mapPartition &lt;/p&gt;
{
    +      (it, out) =&amp;gt;
    +        out.collect(fun(it.to[Seq]))
    +    }
&lt;p&gt;    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to each item of the dataset, producing a collection of items&lt;br/&gt;
    +    * that will be flattened in the resulting data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied to each item&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def flatMapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; TraversableOnce&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.flatMap(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a predicate `fun` to each item of the data set, keeping only those for which&lt;br/&gt;
    +    * the predicate holds&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The predicate to be tested on each item&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def filterWith(fun: T =&amp;gt; Boolean): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.filter(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a reducer `fun` to the data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The reducing function to be applied on the whole data set&lt;br/&gt;
    +    * @tparam R The type of the items in the returned collection&lt;br/&gt;
    +    * @return A data set of Rs&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation&amp;#93;&lt;/span&gt;(fun: (T, T) =&amp;gt; T): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.reduce(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a reducer `fun` to a grouped data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied to the whole grouping&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of Rs&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.reduceGroup {&lt;br/&gt;
    +      (it, out) =&amp;gt;&lt;br/&gt;
    +        out.collect(fun(it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;))&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Same question here with the materialization of the iterator.&lt;/p&gt;</comment>
                            <comment id="15193191" author="githubbot" created="Mon, 14 Mar 2016 12:37:48 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55993657&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55993657&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/OnGroupedDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,75 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.operators.Order&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{DataSet, GroupedDataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +class OnGroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: ClassTag&amp;#93;&lt;/span&gt;(ds: GroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Sorts a group using a sorting function `fun` and an `Order`&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The sorting function, defining the sorting key&lt;br/&gt;
    +    * @param order The ordering strategy (ascending, descending, etc.)&lt;br/&gt;
    +    * @tparam K The key type&lt;br/&gt;
    +    * @return A data set sorted group-wise&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def sortGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;K: TypeInformation&amp;#93;&lt;/span&gt;(order: Order)(fun: T =&amp;gt; K): GroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.sortGroup(fun, order)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Reduces the whole data set with a reducer `fun`&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The reducing function&lt;br/&gt;
    +    * @return A reduced data set of Ts&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceWith(fun: (T, T) =&amp;gt; T): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.reduce(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Reduces the data set group-wise with a reducer `fun`&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The reducing function&lt;br/&gt;
    +    * @tparam R The type of the items in the resulting data set&lt;br/&gt;
    +    * @return A data set of Rs reduced group-wise&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.reduceGroup {&lt;br/&gt;
    +      (it, out) =&amp;gt;&lt;br/&gt;
    +        out.collect(fun(it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;))&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Materialization?&lt;/p&gt;</comment>
                            <comment id="15193192" author="githubbot" created="Mon, 14 Mar 2016 12:37:54 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55993670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55993670&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/OnGroupedDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,75 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.operators.Order&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{DataSet, GroupedDataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +class OnGroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: ClassTag&amp;#93;&lt;/span&gt;(ds: GroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Sorts a group using a sorting function `fun` and an `Order`&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The sorting function, defining the sorting key&lt;br/&gt;
    +    * @param order The ordering strategy (ascending, descending, etc.)&lt;br/&gt;
    +    * @tparam K The key type&lt;br/&gt;
    +    * @return A data set sorted group-wise&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def sortGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;K: TypeInformation&amp;#93;&lt;/span&gt;(order: Order)(fun: T =&amp;gt; K): GroupedDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.sortGroup(fun, order)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Reduces the whole data set with a reducer `fun`&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The reducing function&lt;br/&gt;
    +    * @return A reduced data set of Ts&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceWith(fun: (T, T) =&amp;gt; T): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.reduce(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Reduces the data set group-wise with a reducer `fun`&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The reducing function&lt;br/&gt;
    +    * @tparam R The type of the items in the resulting data set&lt;br/&gt;
    +    * @return A data set of Rs reduced group-wise&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.reduceGroup &lt;/p&gt;
{
    +      (it, out) =&amp;gt;
    +        out.collect(fun(it.to[Seq]))
    +    }
&lt;p&gt;    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Same as a reducing operation but only acts locally,&lt;br/&gt;
    +    * ideal to perform pre-aggregation before a reduction.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The reducing function&lt;br/&gt;
    +    * @tparam R The type of the items in the resulting data set&lt;br/&gt;
    +    * @return A data set of Rs reduced group-wise&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def combineGroupWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.combineGroup {&lt;br/&gt;
    +      (it, out) =&amp;gt;&lt;br/&gt;
    +        out.collect(fun(it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;))&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Materialization?&lt;/p&gt;</comment>
                            <comment id="15193199" author="githubbot" created="Mon, 14 Mar 2016 12:41:18 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55993999&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55993999&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: docs/apis/scala_api_extensions.md &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,392 @@&lt;br/&gt;
    +---&lt;br/&gt;
    +title: &quot;Scala API Extensions&quot;&lt;br/&gt;
    +# Top-level navigation&lt;br/&gt;
    +top-nav-group: apis&lt;br/&gt;
    +top-nav-pos: 11&lt;br/&gt;
    +---&lt;br/&gt;
    +&amp;lt;!--&lt;br/&gt;
    +Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    +or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    +distributed with this work for additional information&lt;br/&gt;
    +regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    +to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    +&quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    +with the License.  You may obtain a copy of the License at&lt;br/&gt;
    +&lt;br/&gt;
    +  &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    +&lt;br/&gt;
    +Unless required by applicable law or agreed to in writing,&lt;br/&gt;
    +software distributed under the License is distributed on an&lt;br/&gt;
    +&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY&lt;br/&gt;
    +KIND, either express or implied.  See the License for the&lt;br/&gt;
    +specific language governing permissions and limitations&lt;br/&gt;
    +under the License.&lt;br/&gt;
    +--&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +In order to keep a fair amount of consistency between the Scala and Java APIs, some &lt;br/&gt;
    +of the features that allow a high-level of expressiveness in Scala have been left&lt;br/&gt;
    +out from the standard APIs for both batch and streaming.&lt;br/&gt;
    +&lt;br/&gt;
    +If you want to &lt;em&gt;enjoy the full Scala experience&lt;/em&gt; you can choose to opt-in to &lt;br/&gt;
    +extensions that enhance the Scala API via implicit conversions.&lt;br/&gt;
    +&lt;br/&gt;
    +To use all the available extensions, you can just add a simple `import` for the&lt;br/&gt;
    +DataSet API&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +&lt;br/&gt;
    +or the DataStream API&lt;br/&gt;
    +&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +import org.apache.flink.streaming.api.scala.extensions._&lt;br/&gt;
    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +&lt;br/&gt;
    +Alternatively, you can import individual extensions &lt;em&gt;a-l&#224;-carte&lt;/em&gt; to only use those&lt;br/&gt;
    +you prefer.&lt;br/&gt;
    +&lt;br/&gt;
    +## Accept partial functions&lt;br/&gt;
    +&lt;br/&gt;
    +Normally, both the DataSet and DataStream APIs don&apos;t accept anonymous pattern&lt;br/&gt;
    +matching functions to deconstruct tuples, case classes or collections, like the&lt;br/&gt;
    +following:&lt;br/&gt;
    +&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +val data: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, String, Double)&amp;#93;&lt;/span&gt; = // &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;br/&gt;
    +data.map {
    +  case (id, name, temperature) =&amp;gt; // [...]
    +  // The previous line causes the following compilation error:
    +  // &quot;The argument types of an anonymous function must be fully known. (SLS 8.5)&quot;
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +&lt;br/&gt;
    +This extension introduces new methods in both the DataSet and DataStream Scala API&lt;br/&gt;
    +that have a one-to-one correspondance in the extended API. These delegating methods &lt;br/&gt;
    +do support anonymous pattern matching functions.&lt;br/&gt;
    +&lt;br/&gt;
    +#### DataSet API&lt;br/&gt;
    +&lt;br/&gt;
    +&amp;lt;table class=&quot;table table-bordered&quot;&amp;gt;&lt;br/&gt;
    +  &amp;lt;thead&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Method&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Original&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-center&quot;&amp;gt;Example&amp;lt;/th&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/thead&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +  &amp;lt;tbody&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;map (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.mapWith {
    +  case (_, value) =&amp;gt; value.toString
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartitionWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartition (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.mapPartitionWith &lt;/p&gt;
{
    +  case head +: _ =&amp;gt; head
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMap (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.flatMapWith {
    +  case (_, name, visitTimes) =&amp;gt; visitTimes.map(name -&amp;gt; _)
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filterWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filter (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.filterWith {
    +  case Train(_, isOnTime) =&amp;gt; isOnTime
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduce (DataSet, GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.reduceWith &lt;/p&gt;
{
    +  case ((_, amount1), (_, amount2)) =&amp;gt; amount1 + amount2
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceGroupWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceGroup (GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.reduceGroupWith {
    +  case id +: value +: _ =&amp;gt; id -&amp;gt; value
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;groupingBy&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;groupBy (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.groupingBy {
    +  case (id, _, _) =&amp;gt; id
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;sortGroupWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;sortGroup (GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +grouped.sortGroupWith(Order.ASCENDING) &lt;/p&gt;
{
    +  case House(_, value) =&amp;gt; value
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;combineGroupWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;combineGroup (GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +grouped.combineGroupWith {
    +  case header +: amounts =&amp;gt; amounts.sum
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;projecting&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (JoinDataSet, CrossDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data1.join(data2).where(0).equalTo(1).projecting {
    +  case ((pk, tx), (products, fk)) =&amp;gt; tx -&amp;gt; products
    +}&lt;br/&gt;
    +&lt;br/&gt;
    +data1.cross(data2).projecting {
    +  case ((a, _), (_, b) =&amp;gt; a -&amp;gt; b
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;projecting&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (CoGroupDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data1.coGroup(data2).where(0).equalTo(1).projecting &lt;/p&gt;
{
    +  case (head1 +: _, head2 +: _) =&amp;gt; head1 -&amp;gt; head2
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/tbody&amp;gt;&lt;br/&gt;
    +&amp;lt;/table&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +#### DataStream API&lt;br/&gt;
    +&lt;br/&gt;
    +&amp;lt;table class=&quot;table table-bordered&quot;&amp;gt;&lt;br/&gt;
    +  &amp;lt;thead&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Method&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Original&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-center&quot;&amp;gt;Example&amp;lt;/th&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/thead&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +  &amp;lt;tbody&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;map (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.mapWith {
    +  case (_, value) =&amp;gt; value.toString
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartitionWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartition (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.mapPartitionWith {
    +  case head +: _ =&amp;gt; head
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMap (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.flatMapWith &lt;/p&gt;
{
    +  case (_, name, visits) =&amp;gt; visits.map(name -&amp;gt; _)
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filterWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filter (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.filterWith {
    +  case Train(_, isOnTime) =&amp;gt; isOnTime
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyingBy&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyBy (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.keyingBy {
    +  case (id, _, _) =&amp;gt; id
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;map (ConnectedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.mapWith(&lt;br/&gt;
    +  map1 = case (_, value) =&amp;gt; value.toString,&lt;br/&gt;
    +  map2 = case (_, _, value, _) =&amp;gt; value + 1&lt;br/&gt;
    +)&lt;br/&gt;
    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMap (ConnectedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.flatMapWith(&lt;br/&gt;
    +  flatMap1 = case (_, json) =&amp;gt; parse(json),&lt;br/&gt;
    +  flatMap2 = case (_, _, json, _) =&amp;gt; parse(json)&lt;br/&gt;
    +)&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyingBy&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyBy (ConnectedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.keyingBy(&lt;br/&gt;
    +  key1 = case (_, timestamp) =&amp;gt; timestamp,&lt;br/&gt;
    +  key2 = case (id, _, _) =&amp;gt; id&lt;br/&gt;
    +)&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduce (KeyedDataStream, WindowedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.reduceWith &lt;/p&gt;
{
    +  case ((_, sum1), (_, sum2) =&amp;gt; sum1 + sum2
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;foldWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;fold (KeyedDataStream, WindowedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.foldWith(User(bought = 0)) {
    +  case (User(b), (_, items)) =&amp;gt; User(b + items.size)
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;applyWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (WindowedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.applyWith(0)(&lt;br/&gt;
    +  foldFunction = case (sum, amount) =&amp;gt; sum + amount&lt;br/&gt;
    +  windowFunction = case (k, w, sum) =&amp;gt; // &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;br/&gt;
    +)&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;projecting&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (JoinedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data1.join(data2).where(0).equalTo(1).projecting &lt;/p&gt;
{
    +  case ((pk, tx), (products, fk)) =&amp;gt; tx -&amp;gt; products
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/tbody&amp;gt;&lt;br/&gt;
    +&amp;lt;/table&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +For more information on the semantics of each method, please refer to the &lt;br/&gt;
    +&lt;span class=&quot;error&quot;&gt;&amp;#91;DataStream&amp;#93;&lt;/span&gt;(batch/index.html) and &lt;span class=&quot;error&quot;&gt;&amp;#91;DataSet&amp;#93;&lt;/span&gt;(streaming/index.html) API documentation.&lt;br/&gt;
    +&lt;br/&gt;
    +To use this extension exclusively, you can add the following `import`:&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}
&lt;p&gt;    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Does this really work? Don&apos;t you have to import `o.a.f.api.scala.extensions.acceptPartialFunctionsOnDataSet` etc.?&lt;/p&gt;</comment>
                            <comment id="15193200" author="githubbot" created="Mon, 14 Mar 2016 12:43:11 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55994195&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55994195&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,201 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I&apos;m wondering whether we shouldn&apos;t overload the method `acceptPartialFunctions` with the different data set types instead of having a different method name for the different data sets (grouped, normal, etc.). I don&apos;t think that the user will want to enable partial function support on such a fine grained scale. Either he wants partial function support or not.&lt;/p&gt;</comment>
                            <comment id="15193204" author="githubbot" created="Mon, 14 Mar 2016 12:44:39 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55994329&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55994329&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,201 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }.reduceWith {
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }.mapWith {
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }.flatMapWith {
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }.groupingBy {
    +    *         case (id, value) =&amp;gt; id
    +    *       }&lt;br/&gt;
    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    new OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith {    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    JavaDocs does not fit to method since it only works on `JoinDataSet`.&lt;/p&gt;</comment>
                            <comment id="15193205" author="githubbot" created="Mon, 14 Mar 2016 12:45:02 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55994370&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55994370&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,201 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }.reduceWith {
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }.mapWith {
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }.flatMapWith {
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }.groupingBy {
    +    *         case (id, value) =&amp;gt; id
    +    *       }&lt;br/&gt;
    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    new OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith {    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }.mapWith {
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }.flatMapWith {
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }.groupingBy {
    +    *         case (id, value) =&amp;gt; id
    +    *       }&lt;br/&gt;
    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnJoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L: TypeInformation, R: TypeInformation&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      ds: JoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt;): OnJoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    new OnJoinDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith {
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }.reduceWith {    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Same here with the JavaDocs.&lt;/p&gt;</comment>
                            <comment id="15193212" author="githubbot" created="Mon, 14 Mar 2016 12:47:21 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55994602&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55994602&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/OnWindowedStream.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,78 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{DataStream, WindowedStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +class OnWindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W &amp;lt;: Window&amp;#93;&lt;/span&gt;(ds: WindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a reduce function to the window. The window function is called for each evaluation&lt;br/&gt;
    +    * of the window for each key individually. The output of the reduce function is interpreted&lt;br/&gt;
    +    * as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * This window will try and pre-aggregate data as much as the window policies permit.&lt;br/&gt;
    +    * For example,tumbling time windows can perfectly pre-aggregate the data, meaning that only one&lt;br/&gt;
    +    * element per key is stored. Sliding time windows will pre-aggregate on the granularity of the&lt;br/&gt;
    +    * slide interval, so a few elements are stored per key (one per slide interval).&lt;br/&gt;
    +    * Custom windows may not be able to pre-aggregate, or may need to store extra values in an&lt;br/&gt;
    +    * aggregation tree.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param function The reduce function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the reduce function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceWith(function: (T, T) =&amp;gt; T) =&lt;br/&gt;
    +    ds.reduce(function)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies the given fold function to each window. The window function is called for each&lt;br/&gt;
    +    * evaluation of the window for each key individually. The output of the reduce function is&lt;br/&gt;
    +    * interpreted as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param function The fold function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the fold function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def foldWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation&amp;#93;&lt;/span&gt;(initialValue: R)(function: (R, T) =&amp;gt; R) =&lt;br/&gt;
    +    ds.fold(initialValue)(function)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies the given window function to each window. The window function is called for each&lt;br/&gt;
    +    * evaluation of the window for each key individually. The output of the window function is&lt;br/&gt;
    +    * interpreted as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * Arriving data is incrementally aggregated using the given fold function.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param initialValue The initial value of the fold&lt;br/&gt;
    +    * @param foldFunction The fold function that is used for incremental aggregation&lt;br/&gt;
    +    * @param windowFunction The window function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the window function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def applyWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation&amp;#93;&lt;/span&gt;(initialValue: R)&lt;br/&gt;
    +                                   (foldFunction: (R, T) =&amp;gt; R,&lt;br/&gt;
    +                                    windowFunction: (K, W, R) =&amp;gt; TraversableOnce&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;):&lt;br/&gt;
    +      DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Formatting seems to be a bit off here.&lt;/p&gt;</comment>
                            <comment id="15193222" author="githubbot" created="Mon, 14 Mar 2016 12:53:35 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55995217&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55995217&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/OnWindowedStream.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,78 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{DataStream, WindowedStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +class OnWindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W &amp;lt;: Window&amp;#93;&lt;/span&gt;(ds: WindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a reduce function to the window. The window function is called for each evaluation&lt;br/&gt;
    +    * of the window for each key individually. The output of the reduce function is interpreted&lt;br/&gt;
    +    * as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * This window will try and pre-aggregate data as much as the window policies permit.&lt;br/&gt;
    +    * For example,tumbling time windows can perfectly pre-aggregate the data, meaning that only one&lt;br/&gt;
    +    * element per key is stored. Sliding time windows will pre-aggregate on the granularity of the&lt;br/&gt;
    +    * slide interval, so a few elements are stored per key (one per slide interval).&lt;br/&gt;
    +    * Custom windows may not be able to pre-aggregate, or may need to store extra values in an&lt;br/&gt;
    +    * aggregation tree.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param function The reduce function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the reduce function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceWith(function: (T, T) =&amp;gt; T) =&lt;br/&gt;
    +    ds.reduce(function)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies the given fold function to each window. The window function is called for each&lt;br/&gt;
    +    * evaluation of the window for each key individually. The output of the reduce function is&lt;br/&gt;
    +    * interpreted as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param function The fold function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the fold function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def foldWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation&amp;#93;&lt;/span&gt;(initialValue: R)(function: (R, T) =&amp;gt; R) =&lt;br/&gt;
    +    ds.fold(initialValue)(function)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies the given window function to each window. The window function is called for each&lt;br/&gt;
    +    * evaluation of the window for each key individually. The output of the window function is&lt;br/&gt;
    +    * interpreted as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * Arriving data is incrementally aggregated using the given fold function.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param initialValue The initial value of the fold&lt;br/&gt;
    +    * @param foldFunction The fold function that is used for incremental aggregation&lt;br/&gt;
    +    * @param windowFunction The window function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the window function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def applyWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation&amp;#93;&lt;/span&gt;(initialValue: R)&lt;br/&gt;
    +                                   (foldFunction: (R, T) =&amp;gt; R,&lt;br/&gt;
    +                                    windowFunction: (K, W, R) =&amp;gt; TraversableOnce&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;):&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why does the `windowFunction` work on a single `R` element and not on all elements of a window?&lt;/p&gt;</comment>
                            <comment id="15193226" author="githubbot" created="Mon, 14 Mar 2016 12:54:21 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55995289&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55995289&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,202 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }.reduceWith {
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }.mapWith {
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }.flatMapWith {
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }.keyingBy {
    +    *         case (id, value) =&amp;gt; id
    +    *       }&lt;br/&gt;
    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;):&lt;br/&gt;
    +      OnDataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    new OnDataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith {    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }.mapWith {
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }.flatMapWith {
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }.keyingBy {
    +    *         case (id, value) =&amp;gt; id
    +    *       }&lt;br/&gt;
    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnKeyedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation, K&amp;#93;&lt;/span&gt;(ds: KeyedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K&amp;#93;&lt;/span&gt;):&lt;br/&gt;
    +      OnKeyedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    new OnKeyedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith {
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }.reduceWith {    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }.flatMapWith {
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }.keyingBy {
    +    *         case (id, value) =&amp;gt; id
    +    *       }&lt;br/&gt;
    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnJoinedStream&lt;br/&gt;
    +      &lt;span class=&quot;error&quot;&gt;&amp;#91;L: TypeInformation, R: TypeInformation, K, W &amp;lt;: Window&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      ds: JoinedStreams&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R&amp;#93;&lt;/span&gt;#Where&lt;span class=&quot;error&quot;&gt;&amp;#91;K&amp;#93;&lt;/span&gt;#EqualTo#WithWindow&lt;span class=&quot;error&quot;&gt;&amp;#91;W&amp;#93;&lt;/span&gt;) =&lt;br/&gt;
    +    new OnJoinedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;L, R, K, W&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith {
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }.reduceWith {
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }.mapWith {    +    *         case Point(x, y) =&amp;gt; (x, y)    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }.keyingBy {
    +    *         case (id, value) =&amp;gt; id
    +    *       }&lt;br/&gt;
    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnConnectedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;IN1: TypeInformation, IN2: TypeInformation&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      ds: ConnectedStreams&lt;span class=&quot;error&quot;&gt;&amp;#91;IN1, IN2&amp;#93;&lt;/span&gt;) =&lt;br/&gt;
    +    new OnConnectedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;IN1, IN2&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataStream with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith {
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }.reduceWith {
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }.mapWith {
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }.flatMapWith {    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)    +    *       }
&lt;p&gt;.keyingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnWindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W &amp;lt;: Window&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      ds: WindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W&amp;#93;&lt;/span&gt;) =&lt;br/&gt;
    +    new OnWindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W&amp;#93;&lt;/span&gt;(ds)&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The same comments as for the extensions for the `DataSet` apply here.&lt;/p&gt;</comment>
                            <comment id="15193229" author="githubbot" created="Mon, 14 Mar 2016 12:56:32 +0000"  >&lt;p&gt;Github user stefanobaghino commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55995517&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55995517&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,201 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I&apos;ve tried but the implicit resolution doesn&apos;t seem to be smart enough to recognize which overloaded implicit definition to pick, so I had to fall back to this. I can make a couple of attempts using a common object with several methods or perhaps using type classes.&lt;/p&gt;</comment>
                            <comment id="15193232" author="githubbot" created="Mon, 14 Mar 2016 12:58:55 +0000"  >&lt;p&gt;Github user stefanobaghino commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55995777&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55995777&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: docs/apis/scala_api_extensions.md &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,392 @@&lt;br/&gt;
    +---&lt;br/&gt;
    +title: &quot;Scala API Extensions&quot;&lt;br/&gt;
    +# Top-level navigation&lt;br/&gt;
    +top-nav-group: apis&lt;br/&gt;
    +top-nav-pos: 11&lt;br/&gt;
    +---&lt;br/&gt;
    +&amp;lt;!--&lt;br/&gt;
    +Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    +or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    +distributed with this work for additional information&lt;br/&gt;
    +regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    +to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    +&quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    +with the License.  You may obtain a copy of the License at&lt;br/&gt;
    +&lt;br/&gt;
    +  &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    +&lt;br/&gt;
    +Unless required by applicable law or agreed to in writing,&lt;br/&gt;
    +software distributed under the License is distributed on an&lt;br/&gt;
    +&quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY&lt;br/&gt;
    +KIND, either express or implied.  See the License for the&lt;br/&gt;
    +specific language governing permissions and limitations&lt;br/&gt;
    +under the License.&lt;br/&gt;
    +--&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +In order to keep a fair amount of consistency between the Scala and Java APIs, some &lt;br/&gt;
    +of the features that allow a high-level of expressiveness in Scala have been left&lt;br/&gt;
    +out from the standard APIs for both batch and streaming.&lt;br/&gt;
    +&lt;br/&gt;
    +If you want to &lt;em&gt;enjoy the full Scala experience&lt;/em&gt; you can choose to opt-in to &lt;br/&gt;
    +extensions that enhance the Scala API via implicit conversions.&lt;br/&gt;
    +&lt;br/&gt;
    +To use all the available extensions, you can just add a simple `import` for the&lt;br/&gt;
    +DataSet API&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +&lt;br/&gt;
    +or the DataStream API&lt;br/&gt;
    +&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +import org.apache.flink.streaming.api.scala.extensions._&lt;br/&gt;
    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +&lt;br/&gt;
    +Alternatively, you can import individual extensions &lt;em&gt;a-l&#224;-carte&lt;/em&gt; to only use those&lt;br/&gt;
    +you prefer.&lt;br/&gt;
    +&lt;br/&gt;
    +## Accept partial functions&lt;br/&gt;
    +&lt;br/&gt;
    +Normally, both the DataSet and DataStream APIs don&apos;t accept anonymous pattern&lt;br/&gt;
    +matching functions to deconstruct tuples, case classes or collections, like the&lt;br/&gt;
    +following:&lt;br/&gt;
    +&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +val data: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, String, Double)&amp;#93;&lt;/span&gt; = // &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;br/&gt;
    +data.map {
    +  case (id, name, temperature) =&amp;gt; // [...]
    +  // The previous line causes the following compilation error:
    +  // &quot;The argument types of an anonymous function must be fully known. (SLS 8.5)&quot;
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +&lt;br/&gt;
    +This extension introduces new methods in both the DataSet and DataStream Scala API&lt;br/&gt;
    +that have a one-to-one correspondance in the extended API. These delegating methods &lt;br/&gt;
    +do support anonymous pattern matching functions.&lt;br/&gt;
    +&lt;br/&gt;
    +#### DataSet API&lt;br/&gt;
    +&lt;br/&gt;
    +&amp;lt;table class=&quot;table table-bordered&quot;&amp;gt;&lt;br/&gt;
    +  &amp;lt;thead&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Method&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Original&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-center&quot;&amp;gt;Example&amp;lt;/th&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/thead&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +  &amp;lt;tbody&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;map (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.mapWith {
    +  case (_, value) =&amp;gt; value.toString
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartitionWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartition (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.mapPartitionWith &lt;/p&gt;
{
    +  case head +: _ =&amp;gt; head
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMap (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.flatMapWith {
    +  case (_, name, visitTimes) =&amp;gt; visitTimes.map(name -&amp;gt; _)
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filterWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filter (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.filterWith {
    +  case Train(_, isOnTime) =&amp;gt; isOnTime
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduce (DataSet, GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.reduceWith &lt;/p&gt;
{
    +  case ((_, amount1), (_, amount2)) =&amp;gt; amount1 + amount2
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceGroupWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceGroup (GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.reduceGroupWith {
    +  case id +: value +: _ =&amp;gt; id -&amp;gt; value
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;groupingBy&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;groupBy (DataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.groupingBy {
    +  case (id, _, _) =&amp;gt; id
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;sortGroupWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;sortGroup (GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +grouped.sortGroupWith(Order.ASCENDING) &lt;/p&gt;
{
    +  case House(_, value) =&amp;gt; value
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;combineGroupWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;combineGroup (GroupedDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +grouped.combineGroupWith {
    +  case header +: amounts =&amp;gt; amounts.sum
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;projecting&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (JoinDataSet, CrossDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data1.join(data2).where(0).equalTo(1).projecting {
    +  case ((pk, tx), (products, fk)) =&amp;gt; tx -&amp;gt; products
    +}&lt;br/&gt;
    +&lt;br/&gt;
    +data1.cross(data2).projecting {
    +  case ((a, _), (_, b) =&amp;gt; a -&amp;gt; b
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;projecting&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (CoGroupDataSet)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data1.coGroup(data2).where(0).equalTo(1).projecting &lt;/p&gt;
{
    +  case (head1 +: _, head2 +: _) =&amp;gt; head1 -&amp;gt; head2
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/tbody&amp;gt;&lt;br/&gt;
    +&amp;lt;/table&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +#### DataStream API&lt;br/&gt;
    +&lt;br/&gt;
    +&amp;lt;table class=&quot;table table-bordered&quot;&amp;gt;&lt;br/&gt;
    +  &amp;lt;thead&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Method&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-left&quot; style=&quot;width: 20%&quot;&amp;gt;Original&amp;lt;/th&amp;gt;&lt;br/&gt;
    +      &amp;lt;th class=&quot;text-center&quot;&amp;gt;Example&amp;lt;/th&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/thead&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +  &amp;lt;tbody&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;map (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.mapWith {
    +  case (_, value) =&amp;gt; value.toString
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartitionWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapPartition (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.mapPartitionWith {
    +  case head +: _ =&amp;gt; head
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMap (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.flatMapWith &lt;/p&gt;
{
    +  case (_, name, visits) =&amp;gt; visits.map(name -&amp;gt; _)
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filterWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;filter (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.filterWith {
    +  case Train(_, isOnTime) =&amp;gt; isOnTime
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyingBy&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyBy (DataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.keyingBy {
    +  case (id, _, _) =&amp;gt; id
    +}&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;mapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;map (ConnectedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.mapWith(&lt;br/&gt;
    +  map1 = case (_, value) =&amp;gt; value.toString,&lt;br/&gt;
    +  map2 = case (_, _, value, _) =&amp;gt; value + 1&lt;br/&gt;
    +)&lt;br/&gt;
    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMapWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;flatMap (ConnectedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.flatMapWith(&lt;br/&gt;
    +  flatMap1 = case (_, json) =&amp;gt; parse(json),&lt;br/&gt;
    +  flatMap2 = case (_, _, json, _) =&amp;gt; parse(json)&lt;br/&gt;
    +)&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyingBy&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;keyBy (ConnectedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.keyingBy(&lt;br/&gt;
    +  key1 = case (_, timestamp) =&amp;gt; timestamp,&lt;br/&gt;
    +  key2 = case (id, _, _) =&amp;gt; id&lt;br/&gt;
    +)&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduceWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;reduce (KeyedDataStream, WindowedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data.reduceWith &lt;/p&gt;
{
    +  case ((_, sum1), (_, sum2) =&amp;gt; sum1 + sum2
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;foldWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;fold (KeyedDataStream, WindowedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}&lt;br/&gt;
    +data.foldWith(User(bought = 0)) {
    +  case (User(b), (_, items)) =&amp;gt; User(b + items.size)
    +}&lt;br/&gt;
    +{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;applyWith&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (WindowedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}&lt;br/&gt;
    +data.applyWith(0)(&lt;br/&gt;
    +  foldFunction = case (sum, amount) =&amp;gt; sum + amount&lt;br/&gt;
    +  windowFunction = case (k, w, sum) =&amp;gt; // &lt;span class=&quot;error&quot;&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;br/&gt;
    +)&lt;br/&gt;
    +{% endhighlight %}&lt;br/&gt;
    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +    &amp;lt;tr&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;projecting&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&amp;lt;strong&amp;gt;apply (JoinedDataStream)&amp;lt;/strong&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
    +      &amp;lt;td&amp;gt;&lt;br/&gt;
    +{% highlight scala %}
&lt;p&gt;    +data1.join(data2).where(0).equalTo(1).projecting &lt;/p&gt;
{
    +  case ((pk, tx), (products, fk)) =&amp;gt; tx -&amp;gt; products
    +}
&lt;p&gt;    +&lt;/p&gt;
{% endhighlight %}
&lt;p&gt;    +      &amp;lt;/td&amp;gt;&lt;br/&gt;
    +    &amp;lt;/tr&amp;gt;&lt;br/&gt;
    +  &amp;lt;/tbody&amp;gt;&lt;br/&gt;
    +&amp;lt;/table&amp;gt;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +For more information on the semantics of each method, please refer to the &lt;br/&gt;
    +&lt;span class=&quot;error&quot;&gt;&amp;#91;DataStream&amp;#93;&lt;/span&gt;(batch/index.html) and &lt;span class=&quot;error&quot;&gt;&amp;#91;DataSet&amp;#93;&lt;/span&gt;(streaming/index.html) API documentation.&lt;br/&gt;
    +&lt;br/&gt;
    +To use this extension exclusively, you can add the following `import`:&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;/p&gt;
{% highlight scala %}
&lt;p&gt;    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes, I wrote the docs before testing and rewriting the method signatures; good catch, thanks. I&apos;ll try to find a way to make a single import for all `acceptPartialFunctions` methods (see my reply to the next comment).&lt;/p&gt;</comment>
                            <comment id="15193243" author="githubbot" created="Mon, 14 Mar 2016 13:04:15 +0000"  >&lt;p&gt;Github user stefanobaghino commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55996335&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55996335&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/OnDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,104 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{GroupedDataSet, DataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied to each item&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.mapPartition {&lt;br/&gt;
    +      (it, out) =&amp;gt;&lt;br/&gt;
    +        out.collect(fun(it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;))&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;Yes, it does.&amp;#93;&lt;/span&gt;(&lt;a href=&quot;http://www.scala-lang.org/api/current/index.html#scala.collection.Traversable@to[Col[_]]:Col[A&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.scala-lang.org/api/current/index.html#scala.collection.Traversable@to[Col[_]]:Col[A&lt;/a&gt;]) I thought in this context I was fairly safe from OOMs but I&apos;ll refactor to make it work on each item of the collection individually. Thanks!&lt;/p&gt;</comment>
                            <comment id="15193260" author="githubbot" created="Mon, 14 Mar 2016 13:13:24 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55997348&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55997348&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/OnDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,104 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{GroupedDataSet, DataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied to each item&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.mapPartition {&lt;br/&gt;
    +      (it, out) =&amp;gt;&lt;br/&gt;
    +        out.collect(fun(it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;))&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think that `it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;` can be problematic, since it can happen that an underlying `Vector` is returned here. This means that the whole iterator will be materialized. It is better imo to define `fun: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R`.&lt;/p&gt;</comment>
                            <comment id="15193273" author="githubbot" created="Mon, 14 Mar 2016 13:26:41 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55998933&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55998933&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/acceptPartialFunctions/OnDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,104 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{GroupedDataSet, DataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to each item of the data set&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied to each item&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: T =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.map(fun)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a function `fun` to a partition as a whole&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param fun The function to be applied on the whole partition&lt;br/&gt;
    +    * @tparam R The type of the items in the returned data set&lt;br/&gt;
    +    * @return A dataset of R&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def mapPartitionWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation: ClassTag&amp;#93;&lt;/span&gt;(fun: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&amp;gt; R): DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    +    ds.mapPartition {&lt;br/&gt;
    +      (it, out) =&amp;gt;&lt;br/&gt;
    +        out.collect(fun(it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;))&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    @stefanobaghino, the idea of `mapPartition` is to process all elements but also to have the possibility to access them all from within one mapPartition call. Therefore, it should get an `Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;` as input instead of iterating over the iterator and calling the mapPartition for each element.&lt;/p&gt;</comment>
                            <comment id="15193276" author="githubbot" created="Mon, 14 Mar 2016 13:28:13 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55999131&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55999131&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,201 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Ah ok, I didn&apos;t know that Scala would have problems with implicits and method overloading. If it is not possible or it gets too complicated, then simply leave it as it is. &lt;/p&gt;</comment>
                            <comment id="15193285" author="githubbot" created="Mon, 14 Mar 2016 13:36:28 +0000"  >&lt;p&gt;Github user stefanobaghino commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r56000181&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r56000181&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/extensions/acceptPartialFunctions/OnWindowedStream.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,78 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.streaming.api.scala.extensions.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.streaming.api.scala.&lt;/p&gt;
{DataStream, WindowedStream}
&lt;p&gt;    +import org.apache.flink.streaming.api.windowing.windows.Window&lt;br/&gt;
    +&lt;br/&gt;
    +class OnWindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W &amp;lt;: Window&amp;#93;&lt;/span&gt;(ds: WindowedStream&lt;span class=&quot;error&quot;&gt;&amp;#91;T, K, W&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies a reduce function to the window. The window function is called for each evaluation&lt;br/&gt;
    +    * of the window for each key individually. The output of the reduce function is interpreted&lt;br/&gt;
    +    * as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * This window will try and pre-aggregate data as much as the window policies permit.&lt;br/&gt;
    +    * For example,tumbling time windows can perfectly pre-aggregate the data, meaning that only one&lt;br/&gt;
    +    * element per key is stored. Sliding time windows will pre-aggregate on the granularity of the&lt;br/&gt;
    +    * slide interval, so a few elements are stored per key (one per slide interval).&lt;br/&gt;
    +    * Custom windows may not be able to pre-aggregate, or may need to store extra values in an&lt;br/&gt;
    +    * aggregation tree.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param function The reduce function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the reduce function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def reduceWith(function: (T, T) =&amp;gt; T) =&lt;br/&gt;
    +    ds.reduce(function)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies the given fold function to each window. The window function is called for each&lt;br/&gt;
    +    * evaluation of the window for each key individually. The output of the reduce function is&lt;br/&gt;
    +    * interpreted as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param function The fold function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the fold function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def foldWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation&amp;#93;&lt;/span&gt;(initialValue: R)(function: (R, T) =&amp;gt; R) =&lt;br/&gt;
    +    ds.fold(initialValue)(function)&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Applies the given window function to each window. The window function is called for each&lt;br/&gt;
    +    * evaluation of the window for each key individually. The output of the window function is&lt;br/&gt;
    +    * interpreted as a regular non-windowed stream.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * Arriving data is incrementally aggregated using the given fold function.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * @param initialValue The initial value of the fold&lt;br/&gt;
    +    * @param foldFunction The fold function that is used for incremental aggregation&lt;br/&gt;
    +    * @param windowFunction The window function.&lt;br/&gt;
    +    * @return The data stream that is the result of applying the window function to the window.&lt;br/&gt;
    +    */&lt;br/&gt;
    +  def applyWith&lt;span class=&quot;error&quot;&gt;&amp;#91;R: TypeInformation&amp;#93;&lt;/span&gt;(initialValue: R)&lt;br/&gt;
    +                                   (foldFunction: (R, T) =&amp;gt; R,&lt;br/&gt;
    +                                    windowFunction: (K, W, R) =&amp;gt; TraversableOnce&lt;span class=&quot;error&quot;&gt;&amp;#91;R&amp;#93;&lt;/span&gt;):&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The implementation iterates over each `R` item. However, this approach seems to contrast with [the remarks you have on `it.to&lt;span class=&quot;error&quot;&gt;&amp;#91;Seq&amp;#93;&lt;/span&gt;`](&lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r55998933&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r55998933&lt;/a&gt;); I will restore the `Iterator` here as well. Thanks!&lt;/p&gt;</comment>
                            <comment id="15193297" author="githubbot" created="Mon, 14 Mar 2016 13:41:50 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-196314763&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-196314763&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @stefanobaghino, really good work &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I think we&apos;re close to get this merged. I had some minor comments.&lt;/p&gt;

&lt;p&gt;    Concerning the testing, I agree with @StephanEwen that it&apos;s not really necessary to execute a complete program for each new extension method. Instead, I think it is sufficient to check that the right operator/stream transformation has been instantiated. The operators and stream transformations should be already well tested. For the `DataSet` methods you could do something like&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
    val identityMapDs = ds.mapWith(identity)&lt;br/&gt;
    assertTrue(identityMapDs.javaSet.isInstanceOf[MapOperator&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;])&lt;br/&gt;
    ```&lt;/p&gt;

&lt;p&gt;    And for the `DataStream` methods&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
    val identity = stream.mapWith&lt;/p&gt;
{case x =&amp;gt; x}
&lt;p&gt;    assertTrue(identity.javaStream.getTransformation.asInstanceOf[OneInputTransformation&lt;span class=&quot;error&quot;&gt;&amp;#91;Int, Int&amp;#93;&lt;/span&gt;]&lt;br/&gt;
          .getOperator.isInstanceOf[StreamMap&lt;span class=&quot;error&quot;&gt;&amp;#91;Int, Int&amp;#93;&lt;/span&gt;])&lt;br/&gt;
    ```&lt;/p&gt;</comment>
                            <comment id="15193309" author="githubbot" created="Mon, 14 Mar 2016 13:46:38 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r56001580&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r56001580&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,201 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can you remember what the problem was? I quickly changed the method names and on a first glance the tests still seem to pass.&lt;/p&gt;</comment>
                            <comment id="15193325" author="githubbot" created="Mon, 14 Mar 2016 13:59:30 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-196320836&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-196320836&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann Thanks! Outstanding review, it&apos;s great to have some guidance when approaching a new project; thank you for the tips on testing as well, it turned out to be way more simple then I thought. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I&apos;ll make sure to apply the changes you mentioned, review the documentation and rewrite and expand the tests.&lt;/p&gt;</comment>
                            <comment id="15193327" author="githubbot" created="Mon, 14 Mar 2016 14:01:50 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-196321443&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-196321443&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann I just have one minor concern regarding the tests: would `isInstanceOf[StreamMap&lt;span class=&quot;error&quot;&gt;&amp;#91;Int, Int&amp;#93;&lt;/span&gt;]` work? Wouldn&apos;t the generic type parameters (the two `Int`s) be erased at runtime?&lt;/p&gt;</comment>
                            <comment id="15193347" author="githubbot" created="Mon, 14 Mar 2016 14:15:13 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-196325179&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-196325179&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Yes I think they will be removed at runtime. Thus, I guess it should also be fine to test for `isInstanceOf[StreamMap&lt;span class=&quot;error&quot;&gt;&amp;#91;_, _&amp;#93;&lt;/span&gt;]`. If you also want to check the input/output types properly, then you can use the `TypeInformations` which are accessible from the `OneInputTransformation`. &lt;/p&gt;</comment>
                            <comment id="15206440" author="githubbot" created="Tue, 22 Mar 2016 14:24:15 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-199837531&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-199837531&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    A quick status update: unfortunately I have had no time to work on this in the past week, I plan to get back to the fixes on Thursday or Friday.&lt;br/&gt;
    In the meanwhile, I have a small doubt on the usage of `Iterator`: they are indeed very good to allow the user to have access both to the whole `DataSet`/`DataStream` or accessing it one item at a time; however, they are not particularly useful when used with the case-style partial functions: they offer an edge to de-structure a single item like a tuple or a collection like `Seq` (e.g. using the `_ +: rest` operator to only get the item after the first).&lt;br/&gt;
    Are we sure we want to keep the `Iterator`? Is there an advantage in having an `Iterator` with this extension? I see to possible solutions: &lt;/p&gt;

&lt;p&gt;    1. the easy one: having two methods, one materializing the `Iterator` into a collection and another one accessing the items one a time: the only issue with this would be the need to have to methods with distinct names (otherwise we would be back to square one); this means the user can use the case-style functions to destructure the collection or each item separately; otherwise we can&lt;br/&gt;
    2. adopt a slightly more sophisticated solution: wrap the `Iterator` in a `Stream`, which is lazy but also fully destructurable in case-style functions (e.g.: using the `#::` operator). This would require some work as the `Iterator` is stateful with regards of the traversal while the `Stream` is not and we can&apos;t just use a naive solution or the semantic difference could lead to some nasty bugs in user code.&lt;/p&gt;</comment>
                            <comment id="15206448" author="githubbot" created="Tue, 22 Mar 2016 14:32:29 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-199840360&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-199840360&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Your 2. proposal looks more natural to me because what you receive as input to a user function is in fact a stream of data. So if this solution is feasible, then I would vote for it.&lt;/p&gt;</comment>
                            <comment id="15211923" author="githubbot" created="Fri, 25 Mar 2016 15:07:06 +0000"  >&lt;p&gt;Github user stefanobaghino commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r57452214&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r57452214&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/package.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,201 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.extensions.acceptPartialFunctions._&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +package object extensions {&lt;br/&gt;
    +&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * acceptPartialFunctions extends the original DataSet with methods with unique names&lt;br/&gt;
    +    * that delegate to core higher-order functions (e.g. `map`) so that we can work around&lt;br/&gt;
    +    * the fact that overloaded methods taking functions as parameters can&apos;t accept partial&lt;br/&gt;
    +    * functions as well. This enables the possibility to directly apply pattern matching&lt;br/&gt;
    +    * to decompose inputs such as tuples, case classes and collections.&lt;br/&gt;
    +    *&lt;br/&gt;
    +    * e.g.&lt;br/&gt;
    +    * {{{&lt;br/&gt;
    +    *   object Main {&lt;br/&gt;
    +    *     import org.apache.flink.api.scala.extensions._&lt;br/&gt;
    +    *     case class Point(x: Double, y: Double)&lt;br/&gt;
    +    *     def main(args: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +    *       val env = ExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
    +    *       val ds = env.fromElements(Point(1, 2), Point(3, 4), Point(5, 6))&lt;br/&gt;
    +    *       ds.filterWith &lt;/p&gt;
{
    +    *         case Point(x, _) =&amp;gt; x &amp;gt; 1
    +    *       }
&lt;p&gt;.reduceWith &lt;/p&gt;
{
    +    *         case (Point(x1, y1), (Point(x2, y2))) =&amp;gt; Point(x1 + y1, x2 + y2)
    +    *       }
&lt;p&gt;.mapWith &lt;/p&gt;
{
    +    *         case Point(x, y) =&amp;gt; (x, y)
    +    *       }
&lt;p&gt;.flatMapWith &lt;/p&gt;
{
    +    *         case (x, y) =&amp;gt; Seq(&apos;x&apos; -&amp;gt; x, &apos;y&apos; -&amp;gt; y)
    +    *       }
&lt;p&gt;.groupingBy &lt;/p&gt;
{
    +    *         case (id, value) =&amp;gt; id
    +    *       }
&lt;p&gt;    +    *     }&lt;br/&gt;
    +    *   }&lt;br/&gt;
    +    * }}}&lt;br/&gt;
    +    *&lt;br/&gt;
    +    */&lt;br/&gt;
    +  implicit def acceptPartialFunctionsOnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; =&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Ok, in the end the problem was a clash between the `acceptPartialFunctions` package and implicit conversions. I&apos;ve solved it by moving the actual implementations under the `impl` package under `acceptPartialFunctions`; now the whole set of conversions can be imported with the `acceptPartialFunctions` name. I was wrong regarding the issue on the resolution of overloaded implicit conversions.&lt;/p&gt;</comment>
                            <comment id="15211924" author="githubbot" created="Fri, 25 Mar 2016 15:07:38 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-201325574&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-201325574&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann I moved forward on the batch extensions: I added support for anonymous partial functions on `where` and `equalsTo` for joins and co-group operations. I also deleted the old tests and provided a full set of unit tests for each method under the same source root (`flink-scala`).&lt;/p&gt;

&lt;p&gt;    Now I have to work on the streaming and adjust the Scaladoc and documentation. I hope next week I&apos;ll have something ready to close this PR. Let me know if you prefer to have the work done so far pushed on this PR already.&lt;/p&gt;</comment>
                            <comment id="15215685" author="githubbot" created="Tue, 29 Mar 2016 08:37:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-202778390&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-202778390&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Sounds great @stefanobaghino. I think you can push your work to this PR as well since it is all related to the partial function support. Looking forward having partial function support &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15221478" author="githubbot" created="Fri, 1 Apr 2016 09:54:46 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-204334976&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-204334976&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Note on the tests of the streaming extensions: I couldn&apos;t find a more specific class than `SingleOutputStreamOperator&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;`, thus assertion may not be very meaningful. However, I&apos;d leave them in place to make sure further work on the extension won&apos;t break them at compile time.&lt;/p&gt;</comment>
                            <comment id="15222081" author="githubbot" created="Fri, 1 Apr 2016 18:09:37 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#discussion_r58244518&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#discussion_r58244518&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-scala/src/main/scala/org/apache/flink/api/scala/extensions/impl/acceptPartialFunctions/OnDataSet.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,111 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.scala.extensions.impl.acceptPartialFunctions&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
    +import org.apache.flink.api.scala.&lt;/p&gt;
{DataSet, GroupedDataSet}
&lt;p&gt;    +&lt;br/&gt;
    +import scala.reflect.ClassTag&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * Wraps a data set, allowing to use anonymous partial functions to&lt;br/&gt;
    +  * perform extraction of items in a tuple, case class instance or collection&lt;br/&gt;
    +  *&lt;br/&gt;
    +  * @param ds The wrapped data set&lt;br/&gt;
    +  * @tparam T The type of the data set items, for which the type information must be known&lt;br/&gt;
    +  */&lt;br/&gt;
    +class OnDataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T: TypeInformation&amp;#93;&lt;/span&gt;(ds: DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think you do not need the `TypeInformation` context bound here. Functions should never need the implicit type info for the input (that is contained in the DataSet already), only ever for the return type.&lt;/p&gt;</comment>
                            <comment id="15222095" author="githubbot" created="Fri, 1 Apr 2016 18:17:13 +0000"  >&lt;p&gt;Github user StephanEwen commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-204500365&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-204500365&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Looks pretty good. I noticed three remaining things:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Sometimes, the package and the directory trees are different (example: `OnCoGroupDataSetTest.scala`). While Scala allows that, we usually keep them in sync.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The classes that implement the &quot;withX&quot; functions sometimes have context bounds that I think they should not require (see inline comment above). Would be great to remove them, because removing them later makes it API breaking.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;We need to decide how to label this for the future: stable, or evolving. I would suggest to use `@PublicEvolving` on all the involved classes for now.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15223918" author="githubbot" created="Mon, 4 Apr 2016 10:35:42 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-205234947&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-205234947&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen Thanks for the feedback, I&apos;ve addressed the points you highlighted and took the time to add some missing Scaladoc to the `DataStream` extension.&lt;/p&gt;</comment>
                            <comment id="15224003" author="githubbot" created="Mon, 4 Apr 2016 12:13:29 +0000"  >&lt;p&gt;Github user StephanEwen commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-205271024&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-205271024&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Looks good to me. Will merge this finally!&lt;/p&gt;

&lt;p&gt;    Thanks for the hard work and the many iterations here...&lt;/p&gt;</comment>
                            <comment id="15224080" author="githubbot" created="Mon, 4 Apr 2016 13:05:03 +0000"  >&lt;p&gt;Github user stefanobaghino commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704#issuecomment-205288351&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704#issuecomment-205288351&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    It&apos;s been a pleasure, thanks for the patience and for guiding me through the iterations. :smiley: &lt;/p&gt;</comment>
                            <comment id="15224884" author="githubbot" created="Mon, 4 Apr 2016 19:32:53 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1704&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15224886" author="stephanewen" created="Mon, 4 Apr 2016 19:33:22 +0000"  >&lt;p&gt;Fixed via 5cb84f185963fa89be5d0c4e83bad66bac44d84d&lt;/p&gt;

&lt;p&gt;Thank you for the contribution!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 33 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i21407:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>