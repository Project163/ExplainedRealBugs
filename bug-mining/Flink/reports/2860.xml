<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:38:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-11171] Unexpected timestamp deserialization failure in RocksDB state backend</title>
                <link>https://issues.apache.org/jira/browse/FLINK-11171</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;We have a job that joins two data stream via Process function and using ValueState TTL with RocksDB backends. The jobs constantly fail to checkpoint due to timestamp&#160;serialization error.&lt;/p&gt;

&lt;p&gt;TTL state config&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
StateTtlConfig ttlConfig = StateTtlConfig
 .newBuilder(Time.hours(recommendationRetentionHr))
 .neverReturnExpired()
 .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
 .cleanupFullSnapshot()
 .build();

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;



&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Error&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;


2018-12-16 06:02:12,609 INFO &#160;org.apache.flink.runtime.checkpoint.CheckpointCoordinator &#160;&#160;&#160;&#160;- Triggering checkpoint 31 @ 1544940132568 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job 7825029dc256542aa312c0b68ecf0631.
 2018-12-16 06:22:12,609 INFO &#160;org.apache.flink.runtime.checkpoint.CheckpointCoordinator &#160;&#160;&#160;&#160;- Checkpoint 31 of job 7825029dc256542aa312c0b68ecf0631 expired before completing.
 2018-12-16 06:22:12,637 INFO &#160;org.apache.flink.runtime.checkpoint.CheckpointCoordinator &#160;&#160;&#160;&#160;- Triggering checkpoint 32 @ 1544941332609 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job 7825029dc256542aa312c0b68ecf0631.
 2018-12-16 06:22:12,899 INFO &#160;org.apache.flink.runtime.checkpoint.CheckpointCoordinator &#160;&#160;&#160;&#160;- Decline checkpoint 32 by task 176c8b3c3ff190d183415ab77b89344c of job 7825029dc256542aa312c0b68ecf0631.
 2018-12-16 06:22:12,900 INFO &#160;org.apache.flink.runtime.checkpoint.CheckpointCoordinator &#160;&#160;&#160;&#160;- Discarding checkpoint 32 of job 7825029dc256542aa312c0b68ecf0631.
 java.lang.Exception: Could not materialize checkpoint 32 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; joined-stream (1/6).
 at org.apache.flink.streaming.runtime.tasks.StreamTask$AsyncCheckpointRunnable.handleExecutionException(StreamTask.java:942)
 at org.apache.flink.streaming.runtime.tasks.StreamTask$AsyncCheckpointRunnable.run(StreamTask.java:884)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
 Caused by: java.util.concurrent.ExecutionException: org.apache.flink.util.FlinkRuntimeException: Unexpected timestamp deserialization failure
 at java.util.concurrent.FutureTask.report(FutureTask.java:122)
 at java.util.concurrent.FutureTask.get(FutureTask.java:192)
 at org.apache.flink.util.FutureUtil.runIfNotDoneAndGet(FutureUtil.java:53)
 at org.apache.flink.streaming.api.operators.OperatorSnapshotFinalizer.&amp;lt;init&amp;gt;(OperatorSnapshotFinalizer.java:47)
 at org.apache.flink.streaming.runtime.tasks.StreamTask$AsyncCheckpointRunnable.run(StreamTask.java:853)
 ... 5 more
 Caused by: org.apache.flink.util.FlinkRuntimeException: Unexpected timestamp deserialization failure
 at org.apache.flink.runtime.state.ttl.TtlStateSnapshotTransformer$TtlSerializedValueStateSnapshotTransformer.filterOrTransform(TtlStateSnapshotTransformer.java:94)
 at org.apache.flink.runtime.state.ttl.TtlStateSnapshotTransformer$TtlSerializedValueStateSnapshotTransformer.filterOrTransform(TtlStateSnapshotTransformer.java:79)
 at org.apache.flink.contrib.streaming.state.iterator.RocksTransformingIteratorWrapper.filterOrTransform(RocksTransformingIteratorWrapper.java:70)
 at org.apache.flink.contrib.streaming.state.iterator.RocksTransformingIteratorWrapper.seekToFirst(RocksTransformingIteratorWrapper.java:48)
 at org.apache.flink.contrib.streaming.state.iterator.RocksStatesPerKeyGroupMergeIterator.buildIteratorHeap(RocksStatesPerKeyGroupMergeIterator.java:128)
 at org.apache.flink.contrib.streaming.state.iterator.RocksStatesPerKeyGroupMergeIterator.&amp;lt;init&amp;gt;(RocksStatesPerKeyGroupMergeIterator.java:68)
 at org.apache.flink.contrib.streaming.state.snapshot.RocksFullSnapshotStrategy$SnapshotAsynchronousPartCallable.writeKVStateData(RocksFullSnapshotStrategy.java:312)
 at org.apache.flink.contrib.streaming.state.snapshot.RocksFullSnapshotStrategy$SnapshotAsynchronousPartCallable.writeSnapshotToOutputStream(RocksFullSnapshotStrategy.java:258)
 at org.apache.flink.contrib.streaming.state.snapshot.RocksFullSnapshotStrategy$SnapshotAsynchronousPartCallable.callInternal(RocksFullSnapshotStrategy.java:223)
 at org.apache.flink.contrib.streaming.state.snapshot.RocksFullSnapshotStrategy$SnapshotAsynchronousPartCallable.callInternal(RocksFullSnapshotStrategy.java:176)
 at org.apache.flink.runtime.state.AsyncSnapshotCallable.call(AsyncSnapshotCallable.java:76)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at org.apache.flink.util.FutureUtil.runIfNotDoneAndGet(FutureUtil.java:50)
 ... 7 more
 2018-12-16 06:22:14,248 WARN &#160;org.apache.flink.runtime.checkpoint.CheckpointCoordinator &#160;&#160;&#160;&#160;- Received late message &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; now expired checkpoint attempt 32 from f69eae02946afadeaaefb470472fd36d of job 7825029dc256542aa312c0b68ecf0631.
 2018-12-16 06:22:14,248 WARN &#160;org.apache.flink.runtime.checkpoint.CheckpointCoordinator &#160;&#160;&#160;&#160;- Received late message &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; now expired checkpoint attempt 32 from 4da75b007f58259167868d193208e45e of job 7825029dc256542aa312c0b68ecf0631.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Error in Job Manager State, each 20min the interval for checkpointing&lt;/p&gt;




&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2018-12-16 05:43:12,264 WARN &#160;org.apache.hadoop.hdfs.DFSClient &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;- DFSOutputStream ResponseProcessor exception &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block BP-1761982338-88.99.139.199-1495110347706:blk_1143342640_69606587
 java.io.IOException: Bad response ERROR &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block BP-1761982338-88.99.139.199-1495110347706:blk_1143342640_69606587 from datanode DatanodeInfoWithStorage[159.69.65.126:50010,DS-b0de28d5-53a5-41e8-9ff4-698520275b86,DISK]
 at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:883)
 2018-12-16 05:43:12,264 WARN &#160;org.apache.hadoop.hdfs.DFSClient &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;- Error Recovery &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block BP-1761982338-88.99.139.199-1495110347706:blk_1143342640_69606587 in pipeline DatanodeInfoWithStorage[94.130.13.247:50010,DS-075ddc51-750f-4163-9c6a-1a139a265aa7,DISK], DatanodeInfoWithStorage[xxxx:50010,DS-b17733c5-35d9-47aa-8400-fbd198fcdaa6,DISK], DatanodeInfoWithStorage[xxxx:50010,DS-b0de28d5-53a5-41e8-9ff4-698520275b86,DISK]: datanode 2(DatanodeInfoWithStorage[xxxxxxx:50010,DS-b0de28d5-53a5-41e8-9ff4-698520275b86,DISK]) is bad.
 2018-12-16 05:43:12,267 WARN &#160;org.apache.hadoop.hdfs.DFSClient &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;- DataStreamer Exception
 org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1761982338-88.99.139.199-1495110347706:blk_1143342640_69606587 does not exist or is not under Constructionnull
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:6683)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6751)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:930)
 at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:966)
 at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
 at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
 at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
 at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
 at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
 at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

at org.apache.hadoop.ipc.Client.call(Client.java:1476)
 at org.apache.hadoop.ipc.Client.call(Client.java:1413)
 at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
 at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
 at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:907)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
 at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
 at com.sun.proxy.$Proxy11.updateBlockForPipeline(Unknown Source)
 at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1290)
 at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:990)
 at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:507)
 2018-12-16 05:43:12,409 WARN &#160;org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory &#160;- Could not close the state stream &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hdfs:/user/flink/rocksdb_v2/tracking_clicks/7825029dc256542aa312c0b68ecf0631/chk-30/9f4297ba-6966-487a-8d20-9031c5ba8273.
 org.apache.hadoop.ipc.RemoteException(java.io.IOException): BP-1761982338-xxxxx-1495110347706:blk_1143342640_69606587 does not exist or is not under Constructionnull
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkUCBlock(FSNamesystem.java:6683)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updateBlockForPipeline(FSNamesystem.java:6751)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updateBlockForPipeline(NameNodeRpcServer.java:930)
 at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:966)
 at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
 at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
 at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
 at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
 at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
 at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)

at org.apache.hadoop.ipc.Client.call(Client.java:1476)
 at org.apache.hadoop.ipc.Client.call(Client.java:1413)
 at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
 at com.sun.proxy.$Proxy10.updateBlockForPipeline(Unknown Source)
 at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:907)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
 at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
 at com.sun.proxy.$Proxy11.updateBlockForPipeline(Unknown Source)
 at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1290)
 at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:990)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13204721">FLINK-11171</key>
            <summary>Unexpected timestamp deserialization failure in RocksDB state backend</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="azagrebin">Andrey Zagrebin</assignee>
                                    <reporter username="sayatez">Sayat Satybaldiyev</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Sun, 16 Dec 2018 11:37:42 +0000</created>
                <updated>Fri, 25 Jan 2019 21:43:53 +0000</updated>
                            <resolved>Fri, 25 Jan 2019 21:42:18 +0000</resolved>
                                    <version>1.6.2</version>
                    <version>1.7.0</version>
                                    <fixVersion>1.8.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1200">20m</timespent>
                                <comments>
                            <comment id="16722462" author="sayatez" created="Sun, 16 Dec 2018 11:41:00 +0000"  >&lt;p&gt;cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=azagrebin&quot; class=&quot;user-hover&quot; rel=&quot;azagrebin&quot;&gt;azagrebin&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srichter&quot; class=&quot;user-hover&quot; rel=&quot;srichter&quot;&gt;srichter&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16722952" author="yunta" created="Mon, 17 Dec 2018 12:49:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sayatez&quot; class=&quot;user-hover&quot; rel=&quot;sayatez&quot;&gt;sayatez&lt;/a&gt; I think the 2nd problem should have no relationship with the unexpected timestamp deserialization failure, from the logs &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 2018-12-16 05:43:12,264 WARN &#160;org.apache.hadoop.hdfs.DFSClient &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;- Error Recovery &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block BP-1761982338-88.99.139.199-1495110347706:blk_1143342640_69606587 in pipeline DatanodeInfoWithStorage[94.130.13.247:50010,DS-075ddc51-750f-4163-9c6a-1a139a265aa7,DISK], DatanodeInfoWithStorage[xxxx:50010,DS-b17733c5-35d9-47aa-8400-fbd198fcdaa6,DISK], DatanodeInfoWithStorage[xxxx:50010,DS-b0de28d5-53a5-41e8-9ff4-698520275b86,DISK]: datanode 2(DatanodeInfoWithStorage[xxxxxxx:50010,DS-b0de28d5-53a5-41e8-9ff4-698520275b86,DISK]) is bad.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;there should be not much disk free space left for these data-nodes.&lt;/p&gt;
&lt;h1&gt;&lt;a name=&quot;%C2%A0&quot;&gt;&lt;/a&gt;&#160;&lt;/h1&gt;</comment>
                            <comment id="16723279" author="sayatez" created="Mon, 17 Dec 2018 19:10:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yunta&quot; class=&quot;user-hover&quot; rel=&quot;yunta&quot;&gt;yunta&lt;/a&gt; agree, the exception in job manager doesn&apos;t correlate with the serialization exception. I assume that due to checkpoint error, JM eventually deletes the blocks from HDFS and hence we got an error. Data nodes have enough disk space.&lt;/p&gt;</comment>
                            <comment id="16752698" author="till.rohrmann" created="Fri, 25 Jan 2019 21:42:18 +0000"  >&lt;p&gt;Fixed via bced96a5a0b8f7b7848add316c12071e0398404a&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 42 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|u000ps:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>