<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:43:14 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-12785] RocksDB savepoint recovery can use a lot of unmanaged memory</title>
                <link>https://issues.apache.org/jira/browse/FLINK-12785</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;I&apos;m running an application that&apos;s backfilling data from Kafka. There&apos;s approximately 3 years worth of data, with a lot of watermark skew (i.e. new partitions were created over time) and I&apos;m using daily windows.&#160;This makes&#160;a lot of the windows buffer their contents before the watermark catches up to &quot;release&quot; them. In turn, this gives me a lot of in-flight windows (200-300) with very large state keys in rocksdb (on the order of 40-50mb per key).&lt;/p&gt;

&lt;p&gt;Running the pipeline tends to be mostly fine - it&apos;s not terribly fast when appends happen but everything works. The problem comes when doing a savepoint restore - specifically, the taskmanagers eat ram until the kernel kills it due to being out of memory. The extra memory isn&apos;t JVM heap since the memory usage of the process is ~4x the -Xmx value and there aren&apos;t any &lt;tt&gt;OutOfMemoryError&lt;/tt&gt;&#160;exceptions.&lt;/p&gt;

&lt;p&gt;I traced the culprit of the memory growth to &lt;a href=&quot;https://github.com/apache/flink/blob/68910fa5381c8804ddbde3087a2481911ebd6d85/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBFullRestoreOperation.java#L212&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;RocksDBFullRestoreOperation.java#L212&lt;/a&gt; . Specifically, while the keys/values are deserialized on the Java heap, &lt;tt&gt;RocksDBWriteBatchWrapper&lt;/tt&gt; forwards it to RocksDB&apos;s &lt;tt&gt;WriteBatch&lt;/tt&gt; which buffers in unmanaged memory. That&apos;s not in itself an issue, but &lt;tt&gt;RocksDBWriteBatchWrapper&lt;/tt&gt; flushes only based on a number of records - not a number of bytes in-flight. Specifically,&#160;&lt;tt&gt;RocksDBWriteBatchWrapper&lt;/tt&gt; will flush only once it has 500 records, and at 40mb per key, that&apos;s at least 20Gb of unmanaged memory before a flush.&lt;/p&gt;

&lt;p&gt;My suggestion would be to add an additional flush criteria to &lt;tt&gt;RocksDBWriteBatchWrapper&lt;/tt&gt; - one based on &lt;tt&gt;batch.getDataSize()&lt;/tt&gt;&#160;(e.g. 500 records or 5mb buffered). This way large key writes would be immediately flushed to RocksDB on recovery or even writes. I applied this approach and I was able to complete a savepoint restore for my job. That said, I&apos;m not entirely sure what else this change would impact since I&apos;m not very familiar with Flink.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13238441">FLINK-12785</key>
            <summary>RocksDB savepoint recovery can use a lot of unmanaged memory</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="klion26">Congxian Qiu</assignee>
                                    <reporter username="mikekap">Mike Kaplinskiy</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 10 Jun 2019 01:46:29 +0000</created>
                <updated>Fri, 10 Jan 2020 12:23:34 +0000</updated>
                            <resolved>Fri, 10 Jan 2020 12:23:34 +0000</resolved>
                                                    <fixVersion>1.10.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1200">20m</timespent>
                                <comments>
                            <comment id="16859657" author="klion26" created="Mon, 10 Jun 2019 02:12:40 +0000"  >&lt;p&gt;Thanks for filing the issue, I will have a look at it.&lt;/p&gt;</comment>
                            <comment id="16860481" author="klion26" created="Tue, 11 Jun 2019 02:27:57 +0000"  >&lt;p&gt;I think your analysis is correct, we should better add another flush strategy based on the in-flight byte size in RocksDBWriteBatchWrapper. Do you want to fix it, or If you don&apos;t mind I&apos;ll give a patch for this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikekap&quot; class=&quot;user-hover&quot; rel=&quot;mikekap&quot;&gt;mikekap&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srichter&quot; class=&quot;user-hover&quot; rel=&quot;srichter&quot;&gt;srichter&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16861347" author="mikekap" created="Tue, 11 Jun 2019 18:46:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=klion26&quot; class=&quot;user-hover&quot; rel=&quot;klion26&quot;&gt;klion26&lt;/a&gt;&#160;you can go ahead. I know that the&#160;RocksDBWriteBatchWrapper is used in several places and I&apos;m not sure if the same limit should apply to all of them. I set the limit at 5mb &amp;amp; 1000 messages, but I don&apos;t have a good sense of&#160;what&apos;s optimal.&lt;/p&gt;

&lt;p&gt;Separately, from a performance perspective, it would probably make sense to use the settings from&#160;&lt;a href=&quot;https://github.com/facebook/rocksdb/blob/master/options/options.cc#L374&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/facebook/rocksdb/blob/master/options/options.cc#L374&lt;/a&gt;&#160;to speed up recovery, but that might be good to do as a follow-up change since it requires re-opening the db afterwards.&lt;/p&gt;</comment>
                            <comment id="16861675" author="klion26" created="Wed, 12 Jun 2019 02:02:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikekap&quot; class=&quot;user-hover&quot; rel=&quot;mikekap&quot;&gt;mikekap&lt;/a&gt; thanks for the input, I&apos;ll keep that in mind.&lt;/p&gt;</comment>
                            <comment id="16980710" author="carp84" created="Sat, 23 Nov 2019 08:02:01 +0000"  >&lt;p&gt;I think fix of this one is necessary to control the total memory consumption of RocksDB (as described, during checkpoint restore), along with &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7289&quot; title=&quot;Memory allocation of RocksDB can be problematic in container environments&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-7289&quot;&gt;&lt;del&gt;FLINK-7289&lt;/del&gt;&lt;/a&gt;. Let&apos;s try best to fix this in 1.10.0 release &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=klion26&quot; class=&quot;user-hover&quot; rel=&quot;klion26&quot;&gt;klion26&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;CC &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yunta&quot; class=&quot;user-hover&quot; rel=&quot;yunta&quot;&gt;yunta&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16980711" author="carp84" created="Sat, 23 Nov 2019 08:03:29 +0000"  >&lt;p&gt;Add link to &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7289&quot; title=&quot;Memory allocation of RocksDB can be problematic in container environments&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-7289&quot;&gt;&lt;del&gt;FLINK-7289&lt;/del&gt;&lt;/a&gt; since this is also related to RocksDB memory consumption.&lt;/p&gt;</comment>
                            <comment id="17012720" author="carp84" created="Fri, 10 Jan 2020 11:09:38 +0000"  >&lt;p&gt;Fixed via&lt;br/&gt;
master: 6df2e0e6db6d58819fcec9a9dd1e9cf1c632af0a&lt;br/&gt;
release-1.10: 6e4385497451fef25e2c0adef99cc32496ca9381&lt;/p&gt;</comment>
                            <comment id="17012723" author="carp84" created="Fri, 10 Jan 2020 11:12:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=klion26&quot; class=&quot;user-hover&quot; rel=&quot;klion26&quot;&gt;klion26&lt;/a&gt; Please add some release notes about the newly introduced property and how to use it.&lt;/p&gt;

&lt;p&gt;Will close this issue after release note is completed.&lt;/p&gt;</comment>
                            <comment id="17012786" author="klion26" created="Fri, 10 Jan 2020 12:23:23 +0000"  >&lt;p&gt;Already added the release not, closing this issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13090718">FLINK-7289</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 44 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z03kao:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Before &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-12785&quot; title=&quot;RocksDB savepoint recovery can use a lot of unmanaged memory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-12785&quot;&gt;&lt;strike&gt;FLINK-12785&lt;/strike&gt;&lt;/a&gt;, user may encounter OOM if there are huge KV pairs when restoring from savepoint of RocksDB state backend. In &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-12785&quot; title=&quot;RocksDB savepoint recovery can use a lot of unmanaged memory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-12785&quot;&gt;&lt;strike&gt;FLINK-12785&lt;/strike&gt;&lt;/a&gt; we introduce a size limit in RocksDBWriteBatchWrapper with default value 2MB, and RocksDB&amp;#39;s WriteBatch will flush if the consumed memory exceeds it. User could tune the limit through the state.backend.rocksdb.write-batch-size property in flink-conf.yaml if needed.&lt;br/&gt;
</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>