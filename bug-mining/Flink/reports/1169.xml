<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:24:55 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-4514] ExpiredIteratorException in Kinesis Consumer on long catch-ups to head of stream</title>
                <link>https://issues.apache.org/jira/browse/FLINK-4514</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Original mailing thread for the reported issue:&lt;br/&gt;
&lt;a href=&quot;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Kinesis-connector-Iterator-expired-exception-td8711.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Kinesis-connector-Iterator-expired-exception-td8711.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Normally, the exception is thrown when the consumer uses the same shard iterator after 5 minutes since it was retrieved. I&apos;ve still yet to clarify &amp;amp; reproduce the root cause of the &lt;tt&gt;ExpiredIteratorException&lt;/tt&gt;, because from the code this seems to be impossible. I&apos;m leaning towards suspecting this is a Kinesis-side issue (from the description in the ML, the behaviour also seems indeterminate).&lt;/p&gt;

&lt;p&gt;Either way, the exception can be fairly easily handled so that the consumer doesn&apos;t just fail. When caught, we request a new shard iterator from Kinesis with the last sequence number.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13000460">FLINK-4514</key>
            <summary>ExpiredIteratorException in Kinesis Consumer on long catch-ups to head of stream</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="10003">Resolved</resolution>
                                        <assignee username="tzulitai">Tzu-Li (Gordon) Tai</assignee>
                                    <reporter username="tzulitai">Tzu-Li (Gordon) Tai</reporter>
                        <labels>
                    </labels>
                <created>Fri, 26 Aug 2016 17:36:22 +0000</created>
                <updated>Wed, 5 Oct 2016 03:58:07 +0000</updated>
                            <resolved>Tue, 30 Aug 2016 16:03:55 +0000</resolved>
                                    <version>1.1.0</version>
                    <version>1.1.1</version>
                                    <fixVersion>1.1.3</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                                    <component>Connectors / Kinesis</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="15445445" author="githubbot" created="Mon, 29 Aug 2016 10:04:48 +0000"  >&lt;p&gt;GitHub user tzulitai opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4514&quot; title=&quot;ExpiredIteratorException in Kinesis Consumer on long catch-ups to head of stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4514&quot;&gt;&lt;del&gt;FLINK-4514&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kinesis-connector&amp;#93;&lt;/span&gt; Handle unexpected ExpiredIteratorExceptions&lt;/p&gt;

&lt;p&gt;    Handle any unexpected &lt;tt&gt;ExpiredIteratorException}}s on {{getRecords()&lt;/tt&gt; calls be refreshing the failing shard iterator with a new one.&lt;/p&gt;

&lt;p&gt;    A user reported this issue when replaying Kinesis data over a wide time span, but then the consumer was back to normal after the consumer caught up with the latest data. I tried to reproduce the exception, but have come short to be able to reproduce. The behaviour seems to be inconsistent.&lt;/p&gt;

&lt;p&gt;    Therefore, this change treats the exception as &quot;unexpected&quot; by simply catching the exception and refreshing the iterator. There&apos;s actually no guarantee of how much time had passed between each getRecords() request anyways, so this is a simple way to handle this.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/tzulitai/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/tzulitai/flink&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4514&quot; title=&quot;ExpiredIteratorException in Kinesis Consumer on long catch-ups to head of stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4514&quot;&gt;&lt;del&gt;FLINK-4514&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2432&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit df833ddbca9971b5f03417efb65527408a8ad9c4&lt;br/&gt;
Author: Tzu-Li (Gordon) Tai &amp;lt;tzulitai@apache.org&amp;gt;&lt;br/&gt;
Date:   2016-08-29T09:30:39Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4514&quot; title=&quot;ExpiredIteratorException in Kinesis Consumer on long catch-ups to head of stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4514&quot;&gt;&lt;del&gt;FLINK-4514&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kinesis-connector&amp;#93;&lt;/span&gt; Handle unexpected ExpiredIteratorExceptions&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15445459" author="githubbot" created="Mon, 29 Aug 2016 10:11:08 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @rmetzger I know it might be a bit of a rush, but could you have a quick look at this too?&lt;br/&gt;
    It&apos;s not a critical blocker, but might as well would be good to make it into the 1.1.2 patch freeze.&lt;/p&gt;</comment>
                            <comment id="15445850" author="githubbot" created="Mon, 29 Aug 2016 13:15:25 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I think it&apos;ll also make sense to limit the config setting `ConsumerConfigConstants.SHARD_GETRECORDS_INTERVAL_MILLIS` to be lower than the shard iterator expire time, otherwise the shard iterator will definitely timeout on the next `getRecords()`.&lt;/p&gt;

&lt;p&gt;    AWS documentation says the expire is 5 minutes (&lt;a href=&quot;http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html&lt;/a&gt;), I propose to set the limit to be 4.5 min, although I don&apos;t expect any user would actually set such a high value.&lt;/p&gt;

&lt;p&gt;    Adding this now...&lt;/p&gt;</comment>
                            <comment id="15446017" author="githubbot" created="Mon, 29 Aug 2016 14:22:42 +0000"  >&lt;p&gt;Github user rmetzger commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I think a check for the interval to be lower than 5 minutes is sufficient. Setting the limit to 4.5 min seems to be a bit too strict. You never know if some advanced users want to cover a very specific use case.&lt;/p&gt;</comment>
                            <comment id="15446044" author="githubbot" created="Mon, 29 Aug 2016 14:33:23 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    The latest commit sets the check to be less than 5 minutes.&lt;/p&gt;</comment>
                            <comment id="15446048" author="githubbot" created="Mon, 29 Aug 2016 14:33:59 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432#discussion_r76617364&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432#discussion_r76617364&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/ShardConsumer.java &amp;#8212;&lt;br/&gt;
    @@ -219,19 +228,52 @@ private void deserializeRecordForCollectionAndUpdateState(UserRecord record)&lt;br/&gt;
     			subscribedShard.getStreamName(),&lt;br/&gt;
     			subscribedShard.getShard().getShardId());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (record.isAggregated()) 
{
    -			fetcherRef.emitRecordAndUpdateState(
    -				value,
    -				approxArrivalTimestamp,
    -				subscribedShardStateIndex,
    -				new SequenceNumber(record.getSequenceNumber(), record.getSubSequenceNumber()));
    -		}
&lt;p&gt; else &lt;/p&gt;
{
    -			fetcherRef.emitRecordAndUpdateState(
    -				value,
    -				approxArrivalTimestamp,
    -				subscribedShardStateIndex,
    -				new SequenceNumber(record.getSequenceNumber()));
    +		SequenceNumber collectedSequenceNumber = (record.isAggregated())
    +			? new SequenceNumber(record.getSequenceNumber(), record.getSubSequenceNumber())
    +			: new SequenceNumber(record.getSequenceNumber());
    +
    +		fetcherRef.emitRecordAndUpdateState(
    +			value,
    +			approxArrivalTimestamp,
    +			subscribedShardStateIndex,
    +			collectedSequenceNumber);
    +
    +		lastSequenceNum = collectedSequenceNumber;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Calls &lt;/p&gt;
{@link KinesisProxyInterface#getRecords(String, int)}
&lt;p&gt;, while also handling unexpected&lt;br/&gt;
    +	 * AWS &lt;/p&gt;
{@link ExpiredIteratorException}
&lt;p&gt;s to assure that we get results and don&apos;t just fail on&lt;br/&gt;
    +	 * such occasions. The returned shard iterator within the successful &lt;/p&gt;
{@link GetRecordsResult}
&lt;p&gt; should&lt;br/&gt;
    +	 * be used for the next call to this method.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note: it is important that this method is not called again before all the records from the last result have been&lt;br/&gt;
    +	 * fully collected with &lt;/p&gt;
{@link ShardConsumer#deserializeRecordForCollectionAndUpdateState(UserRecord)}
&lt;p&gt;, otherwise&lt;br/&gt;
    +	 * &lt;/p&gt;
{@link ShardConsumer#lastSequenceNum}
&lt;p&gt; may refer to a sub-record in the middle of an aggregated record, leading to&lt;br/&gt;
    +	 * incorrect shard iteration if the iterator had to be refreshed.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @param shardItr shard iterator to use&lt;br/&gt;
    +	 * @param maxNumberOfRecords the maximum number of records to fetch for this getRecords attempt&lt;br/&gt;
    +	 * @return get records result&lt;br/&gt;
    +	 * @throws InterruptedException&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private GetRecordsResult getRecords(String shardItr, int maxNumberOfRecords) throws InterruptedException {&lt;br/&gt;
    +		GetRecordsResult getRecordsResult = null;&lt;br/&gt;
    +		while (getRecordsResult == null) {&lt;br/&gt;
    +			try &lt;/p&gt;
{
    +				getRecordsResult = kinesis.getRecords(shardItr, maxNumberOfRecords);
    +			}
&lt;p&gt; catch (ExpiredIteratorException eiEx) {&lt;br/&gt;
    +				LOG.warn(&quot;Encountered an unexpected expired iterator {} for shard {};&quot; +&lt;br/&gt;
    +					&quot; refreshing the iterator ...&quot;, shardItr, subscribedShard);&lt;br/&gt;
    +				shardItr = kinesis.getShardIterator(subscribedShard, ShardIteratorType.AFTER_SEQUENCE_NUMBER.toString(), lastSequenceNum.getSequenceNumber());&lt;br/&gt;
    +&lt;br/&gt;
    +				// sleep for the fetch interval before the next getRecords attempt with the refreshed iterator&lt;br/&gt;
    +				if (fetchIntervalMillis != 0) &lt;/p&gt;
{
    +					Thread.sleep(fetchIntervalMillis);
    +				}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This fetchInterval implementation can lead to much larger fetch intervals.&lt;br/&gt;
    If the getRecords call needs `n` milliseconds, the waiting time between each `getRecords` call is is `n + fetchInterval`.&lt;br/&gt;
    We don&apos;t need to fix this in this PR, but I think in general, we should fix it (if you agree). Also, we need to see how we make this efficient (System.currentTimeMilis() is a somewhat expensive call).&lt;/p&gt;

</comment>
                            <comment id="15446086" author="githubbot" created="Mon, 29 Aug 2016 14:49:05 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432#discussion_r76620194&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432#discussion_r76620194&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/internals/ShardConsumer.java &amp;#8212;&lt;br/&gt;
    @@ -219,19 +228,52 @@ private void deserializeRecordForCollectionAndUpdateState(UserRecord record)&lt;br/&gt;
     			subscribedShard.getStreamName(),&lt;br/&gt;
     			subscribedShard.getShard().getShardId());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (record.isAggregated()) 
{
    -			fetcherRef.emitRecordAndUpdateState(
    -				value,
    -				approxArrivalTimestamp,
    -				subscribedShardStateIndex,
    -				new SequenceNumber(record.getSequenceNumber(), record.getSubSequenceNumber()));
    -		}
&lt;p&gt; else &lt;/p&gt;
{
    -			fetcherRef.emitRecordAndUpdateState(
    -				value,
    -				approxArrivalTimestamp,
    -				subscribedShardStateIndex,
    -				new SequenceNumber(record.getSequenceNumber()));
    +		SequenceNumber collectedSequenceNumber = (record.isAggregated())
    +			? new SequenceNumber(record.getSequenceNumber(), record.getSubSequenceNumber())
    +			: new SequenceNumber(record.getSequenceNumber());
    +
    +		fetcherRef.emitRecordAndUpdateState(
    +			value,
    +			approxArrivalTimestamp,
    +			subscribedShardStateIndex,
    +			collectedSequenceNumber);
    +
    +		lastSequenceNum = collectedSequenceNumber;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Calls &lt;/p&gt;
{@link KinesisProxyInterface#getRecords(String, int)}
&lt;p&gt;, while also handling unexpected&lt;br/&gt;
    +	 * AWS &lt;/p&gt;
{@link ExpiredIteratorException}
&lt;p&gt;s to assure that we get results and don&apos;t just fail on&lt;br/&gt;
    +	 * such occasions. The returned shard iterator within the successful &lt;/p&gt;
{@link GetRecordsResult}
&lt;p&gt; should&lt;br/&gt;
    +	 * be used for the next call to this method.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note: it is important that this method is not called again before all the records from the last result have been&lt;br/&gt;
    +	 * fully collected with &lt;/p&gt;
{@link ShardConsumer#deserializeRecordForCollectionAndUpdateState(UserRecord)}
&lt;p&gt;, otherwise&lt;br/&gt;
    +	 * &lt;/p&gt;
{@link ShardConsumer#lastSequenceNum}
&lt;p&gt; may refer to a sub-record in the middle of an aggregated record, leading to&lt;br/&gt;
    +	 * incorrect shard iteration if the iterator had to be refreshed.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @param shardItr shard iterator to use&lt;br/&gt;
    +	 * @param maxNumberOfRecords the maximum number of records to fetch for this getRecords attempt&lt;br/&gt;
    +	 * @return get records result&lt;br/&gt;
    +	 * @throws InterruptedException&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private GetRecordsResult getRecords(String shardItr, int maxNumberOfRecords) throws InterruptedException {&lt;br/&gt;
    +		GetRecordsResult getRecordsResult = null;&lt;br/&gt;
    +		while (getRecordsResult == null) {&lt;br/&gt;
    +			try &lt;/p&gt;
{
    +				getRecordsResult = kinesis.getRecords(shardItr, maxNumberOfRecords);
    +			}
&lt;p&gt; catch (ExpiredIteratorException eiEx) {&lt;br/&gt;
    +				LOG.warn(&quot;Encountered an unexpected expired iterator {} for shard {};&quot; +&lt;br/&gt;
    +					&quot; refreshing the iterator ...&quot;, shardItr, subscribedShard);&lt;br/&gt;
    +				shardItr = kinesis.getShardIterator(subscribedShard, ShardIteratorType.AFTER_SEQUENCE_NUMBER.toString(), lastSequenceNum.getSequenceNumber());&lt;br/&gt;
    +&lt;br/&gt;
    +				// sleep for the fetch interval before the next getRecords attempt with the refreshed iterator&lt;br/&gt;
    +				if (fetchIntervalMillis != 0) &lt;/p&gt;
{
    +					Thread.sleep(fetchIntervalMillis);
    +				}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Sorry for the race commit, didn&apos;t realize you was still reviewing.&lt;/p&gt;

&lt;p&gt;    I agree. So, if we&apos;re to limit the fetch interval configuration to 5 minutes, then we&apos;ll likely infinitely get stuck in this loop, right? I think that was what I had in mind for a more strict 4.5 min, to assure this doesn&apos;t happen &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; But still, logically, we never know what the `n` will be.&lt;/p&gt;</comment>
                            <comment id="15448772" author="githubbot" created="Tue, 30 Aug 2016 11:18:44 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Max seems to have just hotfixed the failing flink-mesos tests.&lt;br/&gt;
    Rebasing this PR on latest master. Merging this once Travis turns green.&lt;br/&gt;
    I&apos;ll open a separate JIRA to improve the fetch interval implementation.&lt;/p&gt;</comment>
                            <comment id="15449266" author="githubbot" created="Tue, 30 Aug 2016 15:07:48 +0000"  >&lt;p&gt;Github user rmetzger commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    +1&lt;/p&gt;</comment>
                            <comment id="15449354" author="githubbot" created="Tue, 30 Aug 2016 15:45:01 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the confirmation.&lt;br/&gt;
    The build will probably fail again due to an unused import: &lt;a href=&quot;https://travis-ci.org/tzulitai/flink/jobs/156191304&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://travis-ci.org/tzulitai/flink/jobs/156191304&lt;/a&gt;, which was just hotfixed, so we need to rebase again. But I think it&apos;s ok to merge this now, because the tests for all the connectors had passed the last run before it was rebased on the bucketed rolling sink.&lt;/p&gt;</comment>
                            <comment id="15449365" author="githubbot" created="Tue, 30 Aug 2016 15:48:15 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Merging ...&lt;/p&gt;</comment>
                            <comment id="15449379" author="githubbot" created="Tue, 30 Aug 2016 15:55:01 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2432&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15449397" author="tzulitai" created="Tue, 30 Aug 2016 16:03:03 +0000"  >&lt;p&gt;Resolved for master in &lt;a href=&quot;http://git-wip-us.apache.org/repos/asf/flink/commit/b7d83899&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://git-wip-us.apache.org/repos/asf/flink/commit/b7d83899&lt;/a&gt;&lt;br/&gt;
Resolved for 1.1.2 in &lt;a href=&quot;http://git-wip-us.apache.org/repos/asf/flink/commit/df72667b&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://git-wip-us.apache.org/repos/asf/flink/commit/df72667b&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 12 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32v1b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>