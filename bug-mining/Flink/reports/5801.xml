<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:02:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-24005] Resource requirements declaration may be incorrect if JobMaster disconnects with a TaskManager with available slots in the SlotPool</title>
                <link>https://issues.apache.org/jira/browse/FLINK-24005</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;When a TaskManager disconnects with JobMaster, it will trigger the `DeclarativeSlotPoolService#decreaseResourceRequirementsBy()` for all the slots that are registered to the JobMaster from the TaskManager. If the slots are still available, i.e. not assigned to any task,  the `decreaseResourceRequirementsBy` may lead to incorrect resource requirements declaration.&lt;/p&gt;

&lt;p&gt;For example, there is one job with 3 source tasks only. It requires 3 slots and declares for 3 slots. Initially all the tasks are running. Suddenly one task failed and waits for some delay before restarting. The previous slot is returned to the SlotPool. Now the job requires 2 slots and declares for 2 slots. At this moment, the TaskManager of that returned slot get lost. After the triggered `decreaseResourceRequirementsBy`, the job only declares for 1 slot. Finally, when the failed task starts to re-schedule, the job will declare for 2 slots while it actually needs 3 slots.&lt;/p&gt;

&lt;p&gt;The attached log of a real job and logs of the added test in &lt;a href=&quot;https://github.com/zhuzhurk/flink/commit/59ca0ac5fa9c77b97c6e8a43dcc53ca8a0ad6c37&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/zhuzhurk/flink/commit/59ca0ac5fa9c77b97c6e8a43dcc53ca8a0ad6c37&lt;/a&gt; can demonstrate this case.&lt;br/&gt;
Note that the real job is configured with a large &quot;restart-strategy.fixed-delay.delay&quot; and and large &quot;slot.idle.timeout&quot;. So possibly in production it is a rare case.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13397558">FLINK-24005</key>
            <summary>Resource requirements declaration may be incorrect if JobMaster disconnects with a TaskManager with available slots in the SlotPool</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chesnay">Chesnay Schepler</assignee>
                                    <reporter username="zhuzh">Zhu Zhu</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Thu, 26 Aug 2021 12:47:25 +0000</created>
                <updated>Thu, 2 Sep 2021 15:25:19 +0000</updated>
                            <resolved>Thu, 2 Sep 2021 15:25:19 +0000</resolved>
                                    <version>1.14.0</version>
                    <version>1.13.2</version>
                                    <fixVersion>1.14.0</fixVersion>
                    <fixVersion>1.13.3</fixVersion>
                                    <component>Runtime / Coordination</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="17405203" author="zhuzh" created="Thu, 26 Aug 2021 12:55:50 +0000"  >&lt;p&gt;Would it work if we do not decrease resource requirements if a TM disconnects? If a slot is already assigned to tasks, it will trigger task failover and the slot release will trigger the decrease of its resource requirements. If it is not assigned, looks to me there is no need to decrease resource requirements for it.&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chesnay&quot; class=&quot;user-hover&quot; rel=&quot;chesnay&quot;&gt;chesnay&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17405209" author="zentol" created="Thu, 26 Aug 2021 13:03:45 +0000"  >&lt;p&gt;I would have to think things through a bit.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure if it would work, because the release of slots in the slot pool is the very thing triggering the task failure. After that happens I&apos;m not sure if anything even calls back into the slot pool in this scenario, so who would reduce the requirements?&lt;/p&gt;</comment>
                            <comment id="17405212" author="zentol" created="Thu, 26 Aug 2021 13:06:46 +0000"  >&lt;p&gt;What I don&apos;t understand yet is why the requirements are reduced at all when the TM in this scenario fails. If a TM fails the requirements are reduced by the previously fulfilled requirements; but if the task is restarted (aka, the requirement was reduced), then it shouldn&apos;t be fulfilling anything?&lt;/p&gt;</comment>
                            <comment id="17405565" author="zhuzh" created="Fri, 27 Aug 2021 03:41:02 +0000"  >&lt;p&gt;That&apos;s also my question that why we need to decrease requirements when a TM disconnects. In my understanding, the requirement is from the job and should only change if the job status changes. If a TM disconnects with slots assigned to tasks, it will lead to FAILED task and the assigned slots releasing will decrease the requirements(in &lt;tt&gt;DeclarativeSlotPoolBridge#releaseSlot(...)&lt;/tt&gt;).&lt;/p&gt;

&lt;p&gt;2 side notes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;tt&gt;DeclarativeSlotPoolBridge#onFailAllocation()&lt;/tt&gt; will decrease resource requirements. So it may lead to similar issue as  &lt;tt&gt;DeclarativeSlotPoolBridge#onReleaseTaskManager()&lt;/tt&gt;.&lt;/li&gt;
	&lt;li&gt;The requirements decrease are only triggered in &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt;, so this issue will not affect adaptive scheduler.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17405624" author="zentol" created="Fri, 27 Aug 2021 06:34:15 +0000"  >&lt;p&gt;The current behavior is just an artifact of how the Bridge and legacy slot allocation works.&lt;/p&gt;

&lt;p&gt;Conceptually you are right; requirements shouldn&apos;t change because a task fails. And with the AdaptiveScheduler this is also the case.&lt;br/&gt;
However, the legacy scheduler is unable to specify requirements directly, and only communicates with the slot pool via slot requests. To solve that if a slot is requested we increase the requirements. When the slot is freed (for whatever reason) we decrease them again, because if that slot is still required later on a new slot request will be issued.&lt;/p&gt;

&lt;p&gt;So if a TM crashes we free all of it&apos;s slots, and we decrease the requirements for all slots that were currently in use, because we assume that they are later re-requested when the tasks are restarted, increasing the requirements again. And it seems here we do not identify correctly which slots are in use :/&lt;/p&gt;
</comment>
                            <comment id="17406024" author="till.rohrmann" created="Fri, 27 Aug 2021 20:40:16 +0000"  >&lt;p&gt;This is a very good finding that we need to fix. I am also not sure why we can&apos;t simply rely on the &lt;tt&gt;DeclarativeSlotPoolBridge.releaseSlot(SlotRequestId slotRequestId, Throwable cause)&lt;/tt&gt;. There must be something that prevents this method from being called if the slot is failed via &lt;tt&gt;DeclarativeSlotPoolService.releaseTaskManager&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="17406028" author="till.rohrmann" created="Fri, 27 Aug 2021 20:53:25 +0000"  >&lt;p&gt;I think the problem is the following: When we call &lt;tt&gt;DeclarativeSlotPoolService.releaseTaskManager&lt;/tt&gt;, then we release the slots in the &lt;tt&gt;DecalarativeSlotPool&lt;/tt&gt;. This will remove all bookkeeping information from the pool and fail the payloads of the slots. Failing the payloads will eventually call &lt;tt&gt;DeclarativeSlotPoolBridge.releaseSlot(SlotRequestId, Throwable)&lt;/tt&gt;. In this method we call call &lt;tt&gt;DeclarativeSlotPool.freeReservedSlot&lt;/tt&gt; which returns the &lt;tt&gt;ResourceCounter&lt;/tt&gt; if there was a reserved slot that we could free. However, in this case, we have already removed the slot and, thus, the &lt;tt&gt;DeclarativeSlotPool&lt;/tt&gt; no longer knows about the released slot and their resource profile. I think that is why we reduce the resource requirements by all released slots when &lt;tt&gt;DeclarativeSlotPoolService.releaseTaskManager&lt;/tt&gt; is called.&lt;/p&gt;

&lt;p&gt;As shown by Zhu Zhu, this is not correct and we would actually only want to reduce the resource requirements by the number of assigned slots. Conceptually, we would like to let &lt;tt&gt;DeclarativeSlotPoolBridge.releaseSlot&lt;/tt&gt; do the correct accounting if we knew the &lt;tt&gt;ResourceProfile&lt;/tt&gt; of the previously released slots.&lt;/p&gt;</comment>
                            <comment id="17406141" author="till.rohrmann" created="Sat, 28 Aug 2021 07:44:09 +0000"  >&lt;p&gt;One idea to solve this problem could be to move copy the mapping between &lt;tt&gt;AllocationID&lt;/tt&gt; and &lt;tt&gt;ResourceProfile&lt;/tt&gt; to the &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt;. If this component would know about which slot  request was mapped to which &lt;tt&gt;ResourceProfile&lt;/tt&gt;, it wouldn&apos;t need the information from the &lt;tt&gt;DeclarativeSlotPool.freeReservedSlot&lt;/tt&gt; call to properly decrement the resource requirements.&lt;/p&gt;

&lt;p&gt;We could achieve this if we store for a fulfilled request in the &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt; the resource profile by which we have increased the requirements before. I think this information is already present in the &lt;tt&gt;PendingRequest&lt;/tt&gt; class.&lt;/p&gt;</comment>
                            <comment id="17406474" author="zentol" created="Sun, 29 Aug 2021 22:17:05 +0000"  >&lt;p&gt;The analysis isn&apos;t quite correct.&lt;/p&gt;

&lt;p&gt;The issue is that we do not correctly determine whether a slot was fulfilling a requirement or not for the DefaultScheduler.&lt;/p&gt;

&lt;p&gt;When the task is failed then the slot is freed; the bridge decreases the requirements as it should and the pool holds on to the slot as it should.&lt;/p&gt;

&lt;p&gt;However, the pool still has that slot in the &lt;tt&gt;slotToRequirementProfileMappings&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;When the TM providing said slot now fails we look for which requirements the slots from said TM have been fulfilling, such that we can provide that information to the bridge so that it can reduce the requirements afterwards.&lt;/p&gt;

&lt;p&gt;Which requirement the slot was fulfilling is derived from the &lt;tt&gt;slotToRequirementProfileMappings&lt;/tt&gt;.&lt;br/&gt;
Because the slot is still in there it is considered to still be fulfilling a requirement, which we tell the bridge which in turn reduce the requirements, now for the second time.&lt;/p&gt;

&lt;p&gt;That the slot is still kept in the &lt;tt&gt;slotToRequirementProfileMappings&lt;/tt&gt; is generally fine. It is for example required by the AdaptiveScheduler because, in contrast to the DefaultScheduler, it is able to free slots without reducing requirements. But is also used when the slot is freed to figure out what requirement it was fulfilling.&lt;/p&gt;


&lt;p&gt;Solution-wise I don&apos;t think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt;s original suggestion of not decrementing requirements for lost slots could solve the issue. It wouldn&apos;t behave correctly in the case where the slots are being used at the moment. It would remove the slot from the backing pool, free the payload, but the call to freeReservedSlot would then be a no-op because the slot was already removed; we&apos;d end up never reducing the requirements.&lt;/p&gt;

&lt;p&gt;I would also prefer to not add more book-keeping into the bridge; we have enough as is and keeping all that in sync will just be annoying. It would in particular be unfortunate because so far the bridge never really had to deal with resource requirements, and I don&apos;t think we should start that.&lt;/p&gt;

&lt;p&gt;What I will try tomorrow is to make &lt;tt&gt;DefaultDeclarativeSlotPool#releaseSlots&lt;/tt&gt; a bit smarter such that it only determines the previous requirements for slots that are currently reserved. That should also solve the issue.&lt;/p&gt;</comment>
                            <comment id="17406577" author="zhuzh" created="Mon, 30 Aug 2021 06:19:52 +0000"  >&lt;p&gt;Thanks for the explanation! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chesnay&quot; class=&quot;user-hover&quot; rel=&quot;chesnay&quot;&gt;chesnay&lt;/a&gt;&lt;br/&gt;
I now understand why it was needed to decrease resource requirements for disconnected TMs. But I think it is more a like workaround. &lt;br/&gt;
Conceptually, resource requirements should be from the job/scheduler instead of from the acquired slots. i.e.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Resource requirements should be increased when job requires for some slots, including reserving available slots(&lt;tt&gt;DeclarativeSlotPoolBridge#reserveFreeSlotForResource()&lt;/tt&gt;) or request new slots(&lt;tt&gt;DeclarativeSlotPoolBridge#internalRequestNewAllocatedSlot()&lt;/tt&gt;)&lt;/li&gt;
	&lt;li&gt;Resource requirements should be decreased when job retract the requirements, including canceling pending requests(&lt;tt&gt;DeclarativeSlotPoolBridge#cancelPendingRequests()&lt;/tt&gt; &amp;amp; &lt;tt&gt;DeclarativeSlotPoolBridge#releaseSlot()&lt;/tt&gt;) and freeing reserved slots(&lt;tt&gt;DeclarativeSlotPoolBridge#releaseSlot()&lt;/tt&gt;).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Therefore, I think what Till proposed might be a cleaner solution. However, it would need more work to maintain a mapping between &lt;tt&gt;AllocationID&lt;/tt&gt; and &lt;tt&gt;ResourceProfile&lt;/tt&gt;. The main obstacle I can see is that the &lt;tt&gt;ResourceProfile&lt;/tt&gt; of &lt;tt&gt;PendingRequest&lt;/tt&gt; may not be correct in all cases, considering &lt;tt&gt;DefaultDeclarativeSlotPool#adjustRequirements()&lt;/tt&gt; may have been invoked. &lt;br/&gt;
So at the moment, I&apos;m also fine with that the fix proposed by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chesnay&quot; class=&quot;user-hover&quot; rel=&quot;chesnay&quot;&gt;chesnay&lt;/a&gt; which looks simpler. &lt;/p&gt;</comment>
                            <comment id="17406770" author="till.rohrmann" created="Mon, 30 Aug 2021 14:58:33 +0000"  >&lt;p&gt;I am not sure whether making the &lt;tt&gt;DefaultDeclarativeSlotPool#releaseSlots&lt;/tt&gt; smarter is the right solution here. The problem I see is that it moves responsibilities of the &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt; into the &lt;tt&gt;DefaultDeclarativeSlotPool&lt;/tt&gt;. W/o the bridge this specific functionality wouldn&apos;t be needed in the &lt;tt&gt;DefaultDeclarativeSlotPool&lt;/tt&gt;. Instead, the whole logic to increment/decrement the resource requirements when allocation/releasing slots should live imo in the &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;I do see the problem caused by &lt;tt&gt;DefaultDeclarativeSlotPool#adjustRequirements&lt;/tt&gt;. I think it can work if we return the actual &lt;tt&gt;ResourceProfile&lt;/tt&gt; from the &lt;tt&gt;DeclarativeSlotPool.reserveFreeSlot&lt;/tt&gt; method.&lt;/p&gt;

&lt;p&gt;On a related note, isn&apos;t &lt;tt&gt;DefaultDeclarativeSlotPool#adjustRequirements&lt;/tt&gt; only required by the default scheduler? Maybe this is something that should actually live in the &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt;, too, because the &lt;tt&gt;AdaptiveScheduler&lt;/tt&gt; does not need this remapping, if I am not mistaken.&lt;/p&gt;

&lt;p&gt;Maybe we can make the &lt;tt&gt;releaseSlots&lt;/tt&gt; smarter as a band aid for &lt;tt&gt;1.14.0&lt;/tt&gt; and then fix the problem properly with &lt;tt&gt;1.14.1&lt;/tt&gt; and &lt;tt&gt;1.15.0&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="17406816" author="zentol" created="Mon, 30 Aug 2021 16:20:29 +0000"  >&lt;p&gt;&lt;cite&gt;On a related note, isn&apos;t DefaultDeclarativeSlotPool#adjustRequirements only required by the default scheduler&lt;/cite&gt;?&lt;/p&gt;

&lt;p&gt;In practice this is currently the case, but if the AdaptiveScheduler were to actually support resource profiles then it would also need it I believe.&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;The problem I see is that it moves responsibilities of the DeclarativeSlotPoolBridge into the DefaultDeclarativeSlotPool.&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;Generally yes but this was already the case ever since we added the DeclarativeSlotPool. This problem isn&apos;t new, and we made the conscious decision to limit any resource concerns to the pool. It certainly wasn&apos;t ideal, the so is that we still need the bridge in the first place.&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;fix the problem properly with 1.14.1 and 1.15.0.&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m more inclined to leave things as is until we have a clear plan on how we resolve the duality of schedulers and slot-allocation-protocols. When we originally worked on the declarative resource management the intent was to write a new scheduler that supports all jobs; the DeclarativeSlotPoolBridge was only meant as a temporary measure.&lt;br/&gt;
We then limited the adaptive scheduler work to streaming jobs, but never really concluded what that meant for the bridge and DefaultScheduler.&lt;br/&gt;
Will we extend the adaptive scheduler to cover batch jobs?&lt;br/&gt;
Will we refactor the DefaultScheduler to directly work with declarative resource management (at the very least declaring requirements explicitly (which would solve &lt;em&gt;a lot&lt;/em&gt; of issues))?&lt;br/&gt;
Will we continue to have this compatibility layer?&lt;/p&gt;

&lt;p&gt;Before we start any larger refactorings we should have a clear idea where we are even headed.&lt;/p&gt;</comment>
                            <comment id="17407372" author="till.rohrmann" created="Tue, 31 Aug 2021 14:05:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;In practice this is currently the case, but if the AdaptiveScheduler were to actually support resource profiles then it would also need it I believe.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am not so sure about this. The &lt;tt&gt;AdaptiveScheduler&lt;/tt&gt; is in charge of the resource requirements and which slot it uses to fulfill what requirement. I would see it as the responsibility of the &lt;tt&gt;AdaptiveScheduler&lt;/tt&gt; to adjust the requirements if it decides to &lt;tt&gt;Executions&lt;/tt&gt; and &lt;tt&gt;Slots&lt;/tt&gt; differently.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Generally yes but this was already the case ever since we added the DeclarativeSlotPool. This problem isn&apos;t new, and we made the conscious decision to limit any resource concerns to the pool. It certainly wasn&apos;t ideal, the so is that we still need the bridge in the first place.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I agree that the responsibilities are not well separated atm. From a maintenance perspective it would be desirable to move all the default scheduler specific logic into the &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt;. Maybe it is now a bit clearer which responsibility should go into which class after having the &lt;tt&gt;AdaptiveScheduler&lt;/tt&gt; written.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Will we extend the adaptive scheduler to cover batch jobs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Eventually this would be really nice. But I don&apos;t have a good idea how to do it atm.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Will we refactor the DefaultScheduler to directly work with declarative resource management (at the very least declaring requirements explicitly (which would solve a lot of issues))?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think so. The declarative resource management specific logic will probably be contained in the &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Will we continue to have this compatibility layer?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I think so.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Before we start any larger refactorings we should have a clear idea where we are even headed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree. But we should acknowledge that the proposed fix will further entangle &lt;tt&gt;DeclarativeSlotPoolBridge&lt;/tt&gt; and &lt;tt&gt;DefaultDeclarativeSlotPool&lt;/tt&gt; which can make their maintenance harder in the future.&lt;/p&gt;</comment>
                            <comment id="17408611" author="zentol" created="Thu, 2 Sep 2021 07:14:59 +0000"  >&lt;p&gt;I will open a separate ticket to rethink the relationship of the pool &amp;amp; bridge.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-24125&quot; title=&quot;Rethink relationship between DeclarativeSlotPool and *Bridge&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-24125&quot;&gt;FLINK-24125&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17408612" author="zentol" created="Thu, 2 Sep 2021 07:15:04 +0000"  >&lt;p&gt;master: 0ff68d0e4aa80d7fa9c9ab4b9db65ca706a308f7&lt;br/&gt;
1.14: 0e413988a0784d3a15454924274b3e42991ebad3&lt;br/&gt;
1.13: c98babfa1751d2a4b2e9417534eb8bd20499943d  &lt;/p&gt;</comment>
                            <comment id="17408725" author="till.rohrmann" created="Thu, 2 Sep 2021 10:40:47 +0000"  >&lt;p&gt;Are you backporting this fix to &lt;tt&gt;1.13.3&lt;/tt&gt; as well &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chesnay&quot; class=&quot;user-hover&quot; rel=&quot;chesnay&quot;&gt;chesnay&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="17408728" author="zentol" created="Thu, 2 Sep 2021 10:42:20 +0000"  >&lt;p&gt;Yes, just waiting for CI.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="13032548" name="decrease_resource_requirements.log" size="22387" author="zhuzh" created="Thu, 26 Aug 2021 12:48:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 10 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0uaxk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>