<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:20:24 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-26050] Too many small sst files in rocksdb state backend when using time window created in ascending order</title>
                <link>https://issues.apache.org/jira/browse/FLINK-26050</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;When using processing or event time windows, in some workloads, there will be a lot of small sst files(serveral KB) in rocksdb local directory and may cause &quot;Too many files error&quot;.&lt;/p&gt;

&lt;p&gt;Use rocksdb tool ldb to find out content in sst files:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;column family of these small sst files is &quot;processing_window-timers&quot;.&lt;/li&gt;
	&lt;li&gt;most sst files are in level-1.&lt;/li&gt;
	&lt;li&gt;records in sst files are almost kTypeDeletion.&lt;/li&gt;
	&lt;li&gt;creation time of sst file correspond to checkpoint interval.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;These small sst files seem to be generated when flink checkpoint is triggered. Although all content in sst are delete tags, they are not compacted and deleted in rocksdb compaction because of not intersecting with each other(rocksdb &lt;a href=&quot;https://github.com/facebook/rocksdb/wiki/Compaction-Trivial-Move&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;compaction trivial move&lt;/a&gt;). And there seems to be no chance to delete them because of small size and not intersect with other sst files.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I will attach a simple program to reproduce the problem.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Since timer in processing time window is generated in strictly ascending order(both put and delete). So If workload of job happen to generate level-0 sst files not intersect with each other.(for example: processing window size much smaller than checkpoint interval, and no window content cross checkpoint interval or no new data in window crossing checkpoint interval). There will be many small sst files generated until job restored from savepoint, or incremental checkpoint is disabled.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;May be similar problem exists when user use timer in operators with same workload.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Code to reproduce the problem:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt; org.apache.flink.jira;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; lombok.extern.slf4j.Slf4j;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.configuration.Configuration;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.configuration.RestOptions;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.configuration.TaskManagerOptions;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.contrib.streaming.state.RocksDBStateBackend;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.TimeCharacteristic;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.checkpoint.ListCheckpointed;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.datastream.DataStreamSource;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.functions.source.SourceFunction;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.functions.windowing.ProcessWindowFunction;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.windowing.time.Time;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.streaming.api.windowing.windows.TimeWindow;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.util.Collector;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Collections;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.List;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Random;

@Slf4j
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;StreamApp  {
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    Configuration config = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration();
    config.set(RestOptions.ADDRESS, &lt;span class=&quot;code-quote&quot;&gt;&quot;127.0.0.1&quot;&lt;/span&gt;);
    config.set(RestOptions.PORT, 10086);
    config.set(TaskManagerOptions.NUM_TASK_SLOTS, 6);
    &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StreamApp().configureApp(StreamExecutionEnvironment.createLocalEnvironment(1, config));
  }

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void configureApp(StreamExecutionEnvironment env) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {

    env.enableCheckpointing(20000); &lt;span class=&quot;code-comment&quot;&gt;// 20sec
&lt;/span&gt;
    RocksDBStateBackend rocksDBStateBackend =
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RocksDBStateBackend(&lt;span class=&quot;code-quote&quot;&gt;&quot;file:&lt;span class=&quot;code-comment&quot;&gt;///Users/shenjiaqi/Workspace/jira/flink-51/checkpoints/&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;); // need to be reconfigured
&lt;/span&gt;    rocksDBStateBackend.setDbStoragePath(&lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/shenjiaqi/Workspace/jira/flink-51/flink/rocksdb_local_db&quot;&lt;/span&gt;); &lt;span class=&quot;code-comment&quot;&gt;// need to be reconfigured
&lt;/span&gt;
    env.setStateBackend(rocksDBStateBackend);
    env.getCheckpointConfig().setCheckpointTimeout(100000);
    env.getCheckpointConfig().setTolerableCheckpointFailureNumber(5);
    env.setParallelism(1);
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

    env.getConfig().setTaskCancellationInterval(10000);

    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; i &amp;lt; 1; ++i) {
      createOnePipeline(env);
    }

    env.execute(&lt;span class=&quot;code-quote&quot;&gt;&quot;StreamApp&quot;&lt;/span&gt;);
  }


  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void createOnePipeline(StreamExecutionEnvironment env) {
    &lt;span class=&quot;code-comment&quot;&gt;// data source is configured so that little window cross checkpoint interval
&lt;/span&gt;    DataStreamSource&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; stream = env.addSource(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Generator(1, 3000, 3600));

    stream.keyBy(x -&amp;gt; x)
        &lt;span class=&quot;code-comment&quot;&gt;// make sure window size less than checkpoint interval. though 100ms is too small, I think increase &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; value can still reproduce the problem with longer time.
&lt;/span&gt;        .window(TumblingProcessingTimeWindows.of(Time.milliseconds(100)))
        .process(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ProcessWindowFunction&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, TimeWindow&amp;gt;() {
          @Override
          &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void process(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; s, ProcessWindowFunction&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, TimeWindow&amp;gt;.Context context,
              Iterable&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; elements, Collector&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; out) {
            &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; ele: elements) {
              out.collect(ele);
            }
          }
        }).print();
  }

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Generator &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; SourceFunction&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;, ListCheckpointed&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; {

    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; serialVersionUID = -2819385275681175792L;

    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; numKeys;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; idlenessMs;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; recordsToEmit;

    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;volatile&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; numRecordsEmitted = 0;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;volatile&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; canceled = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;

    Generator(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; numKeys, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; idlenessMs, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; durationSeconds) {
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.numKeys = numKeys;
      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.idlenessMs = idlenessMs;

      &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.recordsToEmit = ((durationSeconds * 1000) / idlenessMs) * numKeys;
    }

    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void run(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; SourceContext&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; ctx) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
      Random rnd = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Random();
      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (numRecordsEmitted &amp;lt; recordsToEmit) {
        &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (ctx.getCheckpointLock()) {
          &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; i &amp;lt; numKeys; i++) {
            ctx.collect(&quot;&quot; + rnd.nextInt(1));
            numRecordsEmitted++;
          }
        }
        &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(idlenessMs);
      }

      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (!canceled) {
        &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(50);
      }

    }

    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void cancel() {
      canceled = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
    }

    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; snapshotState(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; checkpointId, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; timestamp) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Collections.singletonList(numRecordsEmitted);
    }

    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void restoreState(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; states) {
      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt; state : states) {
        numRecordsEmitted += state;
      }
    }
  }
}
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;Code to simulate flink checkpointing and timer creation and deletion and reproduce the problem:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-cpp&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;//
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//  main.cpp
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//  reproduce
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//  Created by shenjiaqi on 2022/2/8.
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//
&lt;/span&gt;
&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&amp;lt;filesystem&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&amp;lt;cstdio&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&amp;lt;cstdlib&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&amp;lt;string&amp;gt;&lt;/span&gt;
&lt;/span&gt;
&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&quot;rocksdb/utilities/checkpoint.h&quot;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&quot;rocksdb/db.h&quot;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&quot;rocksdb/slice.h&quot;&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;code-macro&quot;&gt;#include &lt;span class=&quot;code-quote-red&quot;&gt;&quot;rocksdb/options.h&quot;&lt;/span&gt;
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;namespace&lt;/span&gt; ROCKSDB_NAMESPACE;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; ROCKSDB_NAMESPACE::DB;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; ROCKSDB_NAMESPACE::Options;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; ROCKSDB_NAMESPACE::PinnableSlice;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; ROCKSDB_NAMESPACE::ReadOptions;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; ROCKSDB_NAMESPACE::Status;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; ROCKSDB_NAMESPACE::WriteBatch;
&lt;span class=&quot;code-keyword&quot;&gt;using&lt;/span&gt; ROCKSDB_NAMESPACE::WriteOptions;

&lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::string kDBPath = &lt;span class=&quot;code-quote-red&quot;&gt;&quot;/Users/shenjiaqi/Workspace/flink/jira/data-test&quot;&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// need to be reconfigured
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;void&lt;/span&gt;&lt;/span&gt; createCheckpoint(rocksdb::DB *db, rocksdb::Status &amp;amp;s) {
    &lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::cout &amp;lt;&amp;lt; &lt;span class=&quot;code-quote-red&quot;&gt;&quot;create checkpoint&quot;&lt;/span&gt; &amp;lt;&amp;lt; &lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::endl;
    &lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::string chkPath = kDBPath + &lt;span class=&quot;code-quote-red&quot;&gt;&quot;-chp&quot;&lt;/span&gt;;
    assert(chkPath.find(&lt;span class=&quot;code-quote-red&quot;&gt;&quot;/Users/shenjiaqi/Workspace/flink/jira/&quot;&lt;/span&gt;) &amp;gt;= 0); &lt;span class=&quot;code-comment&quot;&gt;// just in &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt;
&lt;/span&gt;    system((&lt;span class=&quot;code-quote-red&quot;&gt;&quot;rm -rf &quot;&lt;/span&gt; + chkPath).data()); &lt;span class=&quot;code-comment&quot;&gt;// use with care.
&lt;/span&gt;    
    Checkpoint* checkpoint_ptr;
    s = Checkpoint::Create(db, &amp;amp;checkpoint_ptr);
    assert(s.ok());
    
    s = checkpoint_ptr-&amp;gt;CreateCheckpoint(chkPath);
    assert(s.ok());
}


&lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&lt;/span&gt; main() {
    DB* db;
    Options options;
    &lt;span class=&quot;code-comment&quot;&gt;// Optimize RocksDB. This is the easiest way to get RocksDB to perform well
&lt;/span&gt;    options.IncreaseParallelism();
    options.OptimizeLevelStyleCompaction();
    &lt;span class=&quot;code-comment&quot;&gt;// create the DB&lt;span class=&quot;code-keyword&quot;&gt; if&lt;/span&gt; it&apos;s &lt;span class=&quot;code-keyword&quot;&gt;not&lt;/span&gt; already present
&lt;/span&gt;    options.create_if_missing = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
    options.info_log_level = DEBUG_LEVEL;
&lt;span class=&quot;code-comment&quot;&gt;//    options.level_compaction_dynamic_level_bytes = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
&lt;/span&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// open DB
&lt;/span&gt;    Status s = DB::Open(options, kDBPath, &amp;amp;db);
    assert(s.ok());

    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&lt;/span&gt; i = 0; i &amp;lt; 1000; ++i) {

        &lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::string key = &lt;span class=&quot;code-quote-red&quot;&gt;&quot;key&quot;&lt;/span&gt; + &lt;span class=&quot;code-comment&quot;&gt;/* &lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::to_string((&lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&lt;/span&gt;)rand()); &lt;span class=&quot;code-comment&quot;&gt;// */&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::to_string(i);
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::string value = &lt;span class=&quot;code-quote-red&quot;&gt;&quot;value&quot;&lt;/span&gt; + &lt;span class=&quot;code-keyword&quot;&gt;std&lt;/span&gt;::to_string(i);

        &lt;span class=&quot;code-comment&quot;&gt;// Put key-value
&lt;/span&gt;        s = db-&amp;gt;Put(WriteOptions(), key, value);
        assert(s.ok());

        &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;delete&lt;/span&gt; after put
&lt;/span&gt;        s = db-&amp;gt;Delete(WriteOptions(), key);
        assert(s.ok());

        if (i &amp;gt; 0 &amp;amp;&amp;amp; (i % 5) == 0) {
            createCheckpoint(db, s);
        }
    }
    
    createCheckpoint(db, s);
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; 0;
}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Many log such as: &quot;Moving #407 to level-1 1047 bytes&quot; can be found in LOG of rocksdb (not enabled in flink by default).&lt;/p&gt;</description>
                <environment></environment>
        <key id="13427453">FLINK-26050</key>
            <summary>Too many small sst files in rocksdb state backend when using time window created in ascending order</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="roman">Roman Khachatryan</assignee>
                                    <reporter username="shenjiaqi">shen</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 9 Feb 2022 10:21:32 +0000</created>
                <updated>Fri, 2 Aug 2024 14:32:16 +0000</updated>
                            <resolved>Fri, 2 Aug 2024 14:32:16 +0000</resolved>
                                    <version>1.10.2</version>
                    <version>1.14.3</version>
                                    <fixVersion>1.20.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="17489546" author="mayuehappy" created="Wed, 9 Feb 2022 13:24:45 +0000"  >&lt;p&gt;Does this issue occur in your production environment ? If so I think the easiest solution is to Set the configuration option &lt;em&gt;state.backend.rocksdb.timer-service.factory&lt;/em&gt; to heap to store timers on heap.&lt;/p&gt;</comment>
                            <comment id="17489976" author="JIRAUSER280100" created="Thu, 10 Feb 2022 06:01:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mayuehappy&quot; class=&quot;user-hover&quot; rel=&quot;mayuehappy&quot;&gt;mayuehappy&lt;/a&gt; , Thx for suggestion. We are actually testing new flink job. Currently we prepared several work around plans, including the one you proposed.&lt;/p&gt;

&lt;p&gt;In this Jira I want to find ways to fix the problem. Since rocksdb state backend is more robust and scalable. And this problem seems to be a performance degradation in some use case.&lt;/p&gt;</comment>
                            <comment id="17489977" author="JIRAUSER280100" created="Thu, 10 Feb 2022 06:03:16 +0000"  >&lt;p&gt;Created a new &lt;a href=&quot;https://github.com/facebook/rocksdb/issues/9540&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;issue&lt;/a&gt; in rocksdb github, try to get some help.&lt;/p&gt;</comment>
                            <comment id="17490640" author="mayuehappy" created="Fri, 11 Feb 2022 02:37:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shenjiaqi&quot; class=&quot;user-hover&quot; rel=&quot;shenjiaqi&quot;&gt;shenjiaqi&lt;/a&gt; kindly remind , I mean use this parameter to store &lt;b&gt;timer&lt;/b&gt; in heap instead of using FsStateBackend , the state of your data processing would still exists in rocksdb .&lt;br/&gt;
In addition, I have a question, did your job generate a lot of sst every time exectue checkpoint? Or because the checkpoint interval is short, a lot of files will be generated after a long running time ?&lt;br/&gt;
&#160;&lt;/p&gt;</comment>
                            <comment id="17491782" author="JIRAUSER280100" created="Mon, 14 Feb 2022 04:00:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mayuehappy&quot; class=&quot;user-hover&quot; rel=&quot;mayuehappy&quot;&gt;mayuehappy&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Using &lt;em&gt;state.backend.rocksdb.timer-service.factory to heap&lt;/em&gt;&#160;means store timer in jvm heap at runtime, but Flink &lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/state_backends/#timers-heap-vs-rocksdb&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;doc&lt;/a&gt; suggests using rocksdb backend over heap: &quot;That is a robust and scalable way that lets applications scale to many timers.&quot;. If my job will scale, I would prefer using rocksdb based timer over heap.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&quot;did your job generate a lot of sst every time exectue checkpoint? &quot;&lt;/p&gt;

&lt;p&gt;No, every time checkpoint is triggered, one sst file is forced to dump from memory.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&quot;Or because the checkpoint interval is short, a lot of files will be generated after a long running time ?&quot;&lt;/p&gt;

&lt;p&gt;Larger interval can moderate the problem, but it still exists.&lt;/p&gt;</comment>
                            <comment id="17491794" author="mayuehappy" created="Mon, 14 Feb 2022 05:05:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shenjiaqi&quot; class=&quot;user-hover&quot; rel=&quot;shenjiaqi&quot;&gt;shenjiaqi&lt;/a&gt;&#160;&lt;/p&gt;

&lt;p&gt;OK I understand. I personally feel that if the timer is only generated by Prcocessing Window then I think using heap is enough. If you insist on using rocksdb , I think you can try changing the Compaction Style to Universal or FIFO&lt;/p&gt;</comment>
                            <comment id="17495303" author="yunta" created="Mon, 21 Feb 2022 03:28:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shenjiaqi&quot; class=&quot;user-hover&quot; rel=&quot;shenjiaqi&quot;&gt;shenjiaqi&lt;/a&gt; Since Flink has disabled the WAL, and the suggestion of configuring &lt;tt&gt;log_size_for_flush&lt;/tt&gt; should not work here.&lt;/p&gt;

&lt;p&gt;It seems a limit of RocksDB level compaction, and I suggest to store those timers on heap considering not so many timers and it works fine in many cases.&lt;/p&gt;</comment>
                            <comment id="17780918" author="mayuehappy" created="Mon, 30 Oct 2023 09:15:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wzqiang1332&quot; class=&quot;user-hover&quot; rel=&quot;wzqiang1332&quot;&gt;wzqiang1332&lt;/a&gt; I think may be you can try with Periodic compaction .&lt;br/&gt;
h&lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/state&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;ttps://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/state/&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Periodic compaction could speed up expired state entries cleanup, especially for state entries rarely accessed. Files older than this value will be picked up for compaction, and re-written to the same level as they were before. It makes sure a file goes through compaction filters periodically. You can change it and pass a custom value to&#160;StateTtlConfig.newBuilder(...).cleanupInRocksdbCompactFilter(long queryTimeAfterNumEntries, Time periodicCompactionTime)&#160;method. The default value of Periodic compaction seconds is 30 days. You could set it to 0 to turn off periodic compaction or set a small value to speed up expired state entries cleanup, but it would trigger more compactions.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17816595" author="pnowojski" created="Mon, 12 Feb 2024 13:00:30 +0000"  >&lt;p&gt;I have encountered the same situation but with event time windows and the problem is AFAIK not only with state of the timers, but also state of the windows. In the case I&apos;ve seen we had checkpointing configured once every minute with windows with length of 10 minutes and there were hundreds of files created both every minute and then small fraction of files created every ten minutes.&lt;/p&gt;

&lt;p&gt;On top of that this can cause also other problems, not only too many opened files. In our case it was Akka frame limit exceeded, as each of those files small enough to fit in the byte state handle, and akka crashed trying to send ~3000 of those handles from JM to TM.&lt;/p&gt;</comment>
                            <comment id="17852344" author="roman_khachatryan" created="Wed, 5 Jun 2024 09:06:24 +0000"  >&lt;p&gt;Manual compaction merged into master as cd722033fb326837a80a6233603d12ad176da15c.&lt;/p&gt;

&lt;p&gt;As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yunta&quot; class=&quot;user-hover&quot; rel=&quot;yunta&quot;&gt;yunta&lt;/a&gt;&#160;&lt;a href=&quot;https://github.com/apache/flink/pull/24880#issuecomment-2148803082&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;pointed out&lt;/a&gt;, we also need to expand the documentation about it - I&apos;ll do that in a follow-up PR (please feel free to do that if you&apos;d like).&lt;/p&gt;</comment>
                            <comment id="17861339" author="weijie guo" created="Tue, 2 Jul 2024 07:24:36 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=roman&quot; class=&quot;user-hover&quot; rel=&quot;roman&quot;&gt;roman&lt;/a&gt;, could you expand the documentation about this or it is not needed?&lt;/p&gt;</comment>
                            <comment id="17870541" author="roman_khachatryan" created="Fri, 2 Aug 2024 14:29:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Weijie+Guo&quot; class=&quot;user-hover&quot; rel=&quot;Weijie Guo&quot;&gt;Weijie Guo&lt;/a&gt; I created a separate ticket to update the documentation (&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-35970&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-35970&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Will be closing this one.&lt;/p&gt;</comment>
                            <comment id="17870543" author="roman_khachatryan" created="Fri, 2 Aug 2024 14:32:16 +0000"  >&lt;p&gt;Merged as &lt;a href=&quot;https://github.com/apache/flink/commit/cd722033fb326837a80a6233603d12ad176da15c&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;cd722033fb326837a80a6233603d12ad176da15c&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13568170">FLINK-34430</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13587737">FLINK-35970</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13435075">FLINK-26800</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13039842" name="image-2022-02-09-21-22-13-920.png" size="312" author="mayuehappy" created="Wed, 9 Feb 2022 13:22:14 +0000"/>
                            <attachment id="13039890" name="image-2022-02-11-10-32-14-956.png" size="312" author="mayuehappy" created="Fri, 11 Feb 2022 02:32:16 +0000"/>
                            <attachment id="13039893" name="image-2022-02-11-10-36-46-630.png" size="312" author="mayuehappy" created="Fri, 11 Feb 2022 02:36:47 +0000"/>
                            <attachment id="13039971" name="image-2022-02-14-13-04-52-325.png" size="312" author="mayuehappy" created="Mon, 14 Feb 2022 05:04:53 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 14 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0zego:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>In some cases, the number of files produced by RocksDB state backend grows indefinitely.This might cause task state info (TDD and checkpoint ACK) to exceed RPC message size and fail recovery/checkpoint in addition to having lots of small files.&lt;br/&gt;
In Flink 1.20, you can manually merge such files in the background using RocksDB API.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>