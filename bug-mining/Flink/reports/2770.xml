<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:36:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10955] Extend release notes for Flink 1.7</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10955</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;We should extend the release notes for Flink 1.7 to include the release notes of all fixed issues with fix version &lt;tt&gt;1.7.0&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13199655">FLINK-10955</key>
            <summary>Extend release notes for Flink 1.7</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="trohrmann">Till Rohrmann</assignee>
                                    <reporter username="trohrmann">Till Rohrmann</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Tue, 20 Nov 2018 17:24:40 +0000</created>
                <updated>Wed, 28 Nov 2018 16:36:21 +0000</updated>
                            <resolved>Wed, 28 Nov 2018 16:36:21 +0000</resolved>
                                    <version>1.7.0</version>
                                    <fixVersion>1.7.0</fixVersion>
                                    <component>Documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16693550" author="githubbot" created="Tue, 20 Nov 2018 17:33:34 +0000"  >&lt;p&gt;tillrohrmann opened a new pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Extend release notes for Apache Flink 1.7.0. This includes all the release notes of issues fixed with a `fixVersion=1.7.0`.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This change is a trivial rework / code cleanup without any test coverage.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (no)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)&lt;/li&gt;
	&lt;li&gt;The serializers: (no)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (no)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (no)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (no)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (no)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (not applicable)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16693686" author="githubbot" created="Tue, 20 Nov 2018 19:18:37 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235134684&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235134684&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occured after a savepoint was taken but before the next checkpoint occured.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which all affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;br/&gt;
+To restore the previous default behavior users have to configure the `metrics.latency.interval` in `flink-conf.yaml`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   We could link directly against the configuration docs&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16693687" author="githubbot" created="Tue, 20 Nov 2018 19:18:37 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235134511&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235134511&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occured after a savepoint was taken but before the next checkpoint occured.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which all affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   `all affect all` -&amp;gt; `will affect all`?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16693688" author="githubbot" created="Tue, 20 Nov 2018 19:18:37 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235135547&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235135547&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occured after a savepoint was taken but before the next checkpoint occured.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which all affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;br/&gt;
+To restore the previous default behavior users have to configure the `metrics.latency.interval` in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Relocation of Hadoop&apos;s Netty dependency&lt;br/&gt;
+&lt;br/&gt;
+We now also relocate Hadoop&apos;s Netty dependency from `io.netty` to `org.apache.flink.hadoop.shaded.io.netty`.&lt;br/&gt;
+You can now bundle your own version of Netty into your job but may no longer assume that `io.netty` is present in the `flink-shaded-hadoop2-uber-*.jar` file.&lt;br/&gt;
+&lt;br/&gt;
+### Local recovery fixed&lt;br/&gt;
+&lt;br/&gt;
+With the improvements to Flink&apos;s scheduling, it can no longer happen that recoveries require more slots than before if local recovery is enabled.&lt;br/&gt;
+Consequently, we encourage our users to use the local recovery feature which can be enabled by `state.backend.local-recovery: true` in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Support for multi slot TaskManagers&lt;br/&gt;
+&lt;br/&gt;
+Flink now properly supports `TaskManagers` with multiple slots.&lt;br/&gt;
+Consequently, `TaskManagers` can now be started with an arbitrary number of slots and it is no longer recommended to start them with a single slot.&lt;br/&gt;
+&lt;br/&gt;
+### StandaloneJobClusterEntrypoint generates JobGraph with fixed JobID&lt;br/&gt;
+&lt;br/&gt;
+The `StandaloneJobClusterEntrypoint` now starts all jobs with a fixed `JobID`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   This is a rather technical explanation; mention instead which script/command is affected by this.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16693968" author="githubbot" created="Wed, 21 Nov 2018 00:57:04 +0000"  >&lt;p&gt;hequn8128 commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235222632&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235222632&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occured after a savepoint was taken but before the next checkpoint occured.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   A nice release notes! Replace occured with occurred here? There are two places in this sentence.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694431" author="githubbot" created="Wed, 21 Nov 2018 09:09:51 +0000"  >&lt;p&gt;tillrohrmann commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235303295&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235303295&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occured after a savepoint was taken but before the next checkpoint occured.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which all affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;br/&gt;
+To restore the previous default behavior users have to configure the `metrics.latency.interval` in `flink-conf.yaml`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Good idea. Will change it into a link.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694434" author="githubbot" created="Wed, 21 Nov 2018 09:14:35 +0000"  >&lt;p&gt;tillrohrmann commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235304865&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235304865&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occured after a savepoint was taken but before the next checkpoint occured.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which all affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;br/&gt;
+To restore the previous default behavior users have to configure the `metrics.latency.interval` in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Relocation of Hadoop&apos;s Netty dependency&lt;br/&gt;
+&lt;br/&gt;
+We now also relocate Hadoop&apos;s Netty dependency from `io.netty` to `org.apache.flink.hadoop.shaded.io.netty`.&lt;br/&gt;
+You can now bundle your own version of Netty into your job but may no longer assume that `io.netty` is present in the `flink-shaded-hadoop2-uber-*.jar` file.&lt;br/&gt;
+&lt;br/&gt;
+### Local recovery fixed&lt;br/&gt;
+&lt;br/&gt;
+With the improvements to Flink&apos;s scheduling, it can no longer happen that recoveries require more slots than before if local recovery is enabled.&lt;br/&gt;
+Consequently, we encourage our users to use the local recovery feature which can be enabled by `state.backend.local-recovery: true` in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Support for multi slot TaskManagers&lt;br/&gt;
+&lt;br/&gt;
+Flink now properly supports `TaskManagers` with multiple slots.&lt;br/&gt;
+Consequently, `TaskManagers` can now be started with an arbitrary number of slots and it is no longer recommended to start them with a single slot.&lt;br/&gt;
+&lt;br/&gt;
+### StandaloneJobClusterEntrypoint generates JobGraph with fixed JobID&lt;br/&gt;
+&lt;br/&gt;
+The `StandaloneJobClusterEntrypoint` now starts all jobs with a fixed `JobID`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   I will add the command. I still think that this is good to mention because the `StandaloneJobClusterEntrypoint` is intended to be used for container setups. People use it directly instead of going through the `standalone-job.sh` script.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694438" author="githubbot" created="Wed, 21 Nov 2018 09:19:59 +0000"  >&lt;p&gt;tillrohrmann commented on issue #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#issuecomment-440592622&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#issuecomment-440592622&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Thanks for the review @hequn8128 and @zentol. I&apos;ve addressed your comments.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694512" author="githubbot" created="Wed, 21 Nov 2018 10:10:22 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235324439&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235324439&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occurred after a savepoint was taken but before the next checkpoint occurred.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which will affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;br/&gt;
+To restore the previous default behavior users have to configure the &lt;span class=&quot;error&quot;&gt;&amp;#91;latency interval&amp;#93;&lt;/span&gt;(&lt;tt&gt;site.baseurl&lt;/tt&gt;/ops/config.html#metrics-latency-interval) in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Relocation of Hadoop&apos;s Netty dependency&lt;br/&gt;
+&lt;br/&gt;
+We now also relocate Hadoop&apos;s Netty dependency from `io.netty` to `org.apache.flink.hadoop.shaded.io.netty`.&lt;br/&gt;
+You can now bundle your own version of Netty into your job but may no longer assume that `io.netty` is present in the `flink-shaded-hadoop2-uber-*.jar` file.&lt;br/&gt;
+&lt;br/&gt;
+### Local recovery fixed&lt;br/&gt;
+&lt;br/&gt;
+With the improvements to Flink&apos;s scheduling, it can no longer happen that recoveries require more slots than before if local recovery is enabled.&lt;br/&gt;
+Consequently, we encourage our users to use the local recovery feature which can be enabled by `state.backend.local-recovery: true` in `flink-conf.yaml`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   add link to config docs&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694513" author="githubbot" created="Wed, 21 Nov 2018 10:10:22 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235324507&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235324507&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -37,6 +120,15 @@ You should only use this feature if you are executing a stateless streaming job.&lt;br/&gt;
 In any other cases, it is highly recommended to remove the config option `jobmanager.execution.failover-strategy` from your `flink-conf.yaml` or set it to `&quot;full&quot;`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   add link to config docs&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694514" author="githubbot" created="Wed, 21 Nov 2018 10:10:22 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235324470&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235324470&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occurred after a savepoint was taken but before the next checkpoint occurred.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which will affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;br/&gt;
+To restore the previous default behavior users have to configure the &lt;span class=&quot;error&quot;&gt;&amp;#91;latency interval&amp;#93;&lt;/span&gt;(&lt;tt&gt;site.baseurl&lt;/tt&gt;/ops/config.html#metrics-latency-interval) in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Relocation of Hadoop&apos;s Netty dependency&lt;br/&gt;
+&lt;br/&gt;
+We now also relocate Hadoop&apos;s Netty dependency from `io.netty` to `org.apache.flink.hadoop.shaded.io.netty`.&lt;br/&gt;
+You can now bundle your own version of Netty into your job but may no longer assume that `io.netty` is present in the `flink-shaded-hadoop2-uber-*.jar` file.&lt;br/&gt;
+&lt;br/&gt;
+### Local recovery fixed&lt;br/&gt;
+&lt;br/&gt;
+With the improvements to Flink&apos;s scheduling, it can no longer happen that recoveries require more slots than before if local recovery is enabled.&lt;br/&gt;
+Consequently, we encourage our users to use the local recovery feature which can be enabled by `state.backend.local-recovery: true` in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Support for multi slot TaskManagers&lt;br/&gt;
+&lt;br/&gt;
+Flink now properly supports `TaskManagers` with multiple slots.&lt;br/&gt;
+Consequently, `TaskManagers` can now be started with an arbitrary number of slots and it is no longer recommended to start them with a single slot.&lt;br/&gt;
+&lt;br/&gt;
+### StandaloneJobClusterEntrypoint generates JobGraph with fixed JobID&lt;br/&gt;
+&lt;br/&gt;
+The `StandaloneJobClusterEntrypoint`, which is launched by the script `standalone-job.sh` and used for the job-mode container images, now starts all jobs with a fixed `JobID`.&lt;br/&gt;
+Thus, in order to run a cluster in HA mode, one needs to set a different cluster id `high-availability.cluster-id` for each job/cluster. &lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   add link to config docs&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694515" author="githubbot" created="Wed, 21 Nov 2018 10:10:22 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235324410&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235324410&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occurred after a savepoint was taken but before the next checkpoint occurred.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the granularity to `metrics.latency.granularity: subtask`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   add link to config docs&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694516" author="githubbot" created="Wed, 21 Nov 2018 10:10:22 +0000"  >&lt;p&gt;zentol commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235324386&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235324386&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -22,6 +22,89 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occurred after a savepoint was taken but before the next checkpoint occurred.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+This port can be configured via `metrics.internal.query-service.port` and is set by default to `0`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   add link to config docs&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694606" author="githubbot" created="Wed, 21 Nov 2018 12:01:31 +0000"  >&lt;p&gt;tillrohrmann commented on a change in pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#discussion_r235359939&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#discussion_r235359939&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: docs/release-notes/flink-1.7.md&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -37,6 +120,15 @@ You should only use this feature if you are executing a stateless streaming job.&lt;br/&gt;
 In any other cases, it is highly recommended to remove the config option `jobmanager.execution.failover-strategy` from your `flink-conf.yaml` or set it to `&quot;full&quot;`.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   It&apos;s no longer documented, thus, there is no link to put here.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16694607" author="githubbot" created="Wed, 21 Nov 2018 12:02:44 +0000"  >&lt;p&gt;tillrohrmann commented on issue #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150#issuecomment-440639380&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150#issuecomment-440639380&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Good point @zentol. I&apos;ve replaced all config options with their respective links now.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16702113" author="githubbot" created="Wed, 28 Nov 2018 16:34:15 +0000"  >&lt;p&gt;tillrohrmann closed pull request #7150: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10955&quot; title=&quot;Extend release notes for Flink 1.7&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10955&quot;&gt;&lt;del&gt;FLINK-10955&lt;/del&gt;&lt;/a&gt; Extend release notes for Apache Flink 1.7.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7150&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7150&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/docs/release-notes/flink-1.7.md b/docs/release-notes/flink-1.7.md&lt;br/&gt;
index 8cdfe9d5400..ea2ae6f87e5 100644&lt;br/&gt;
&amp;#8212; a/docs/release-notes/flink-1.7.md&lt;br/&gt;
+++ b/docs/release-notes/flink-1.7.md&lt;br/&gt;
@@ -22,6 +22,97 @@ under the License.&lt;/p&gt;

&lt;p&gt; These release notes discuss important aspects, such as configuration, behavior, or dependencies, that changed between Flink 1.6 and Flink 1.7. Please read these notes carefully if you are planning to upgrade your Flink version to 1.7.&lt;/p&gt;

&lt;p&gt;+### Scala 2.12 support&lt;br/&gt;
+&lt;br/&gt;
+When using Scala `2.12` you might have to add explicit type annotations in places where they were not required when using Scala `2.11`.&lt;br/&gt;
+This is an excerpt from the `TransitiveClosureNaive.scala` example in the Flink code base that shows the changes that could be required.&lt;br/&gt;
+&lt;br/&gt;
+Previous code:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev, next, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+     val prevPaths = prev.toSet
+     for (n &amp;lt;- next)
+       if (!prevPaths.contains(n)) out.collect(n)
+   }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+With Scala `2.12` you have to change it to:&lt;br/&gt;
+```&lt;br/&gt;
+val terminate = prevPaths&lt;br/&gt;
+ .coGroup(nextPaths)&lt;br/&gt;
+ .where(0).equalTo(0) {&lt;br/&gt;
+   (prev: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, next: Iterator&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;, out: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;(Long, Long)&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+       val prevPaths = prev.toSet
+       for (n &amp;lt;- next)
+         if (!prevPaths.contains(n)) out.collect(n)
+     }
&lt;p&gt;+}&lt;br/&gt;
+```&lt;br/&gt;
+&lt;br/&gt;
+The reason for this is that Scala `2.12` changes how lambdas are implemented.&lt;br/&gt;
+They now use the lambda support using SAM interfaces introduced in Java 8.&lt;br/&gt;
+This makes some method calls ambiguous because now both Scala-style lambdas and SAMs are candidates for methods were it was previously clear which method would be invoked.&lt;br/&gt;
+&lt;br/&gt;
+### State evolution&lt;br/&gt;
+&lt;br/&gt;
+Before Flink 1.7, serializer snapshots were implemented as a `TypeSerializerConfigSnapshot` (which is now deprecated, and will eventually be removed in the future to be fully replaced by the new `TypeSerializerSnapshot` interface introduced in 1.7).&lt;br/&gt;
+Moreover, the responsibility of serializer schema compatibility checks lived within the `TypeSerializer`, implemented in the `TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)` method. &lt;br/&gt;
+&lt;br/&gt;
+To be future-proof and to have flexibility to migrate your state serializers and schema, it is highly recommended to migrate from the old abstractions. &lt;br/&gt;
+Details and migration guides can be found &lt;span class=&quot;error&quot;&gt;&amp;#91;here&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/dev/stream/state/custom_serialization.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-master/dev/stream/state/custom_serialization.html&lt;/a&gt;).&lt;br/&gt;
+&lt;br/&gt;
+### Removal of the legacy mode&lt;br/&gt;
+&lt;br/&gt;
+Flink no longer supports the legacy mode.&lt;br/&gt;
+If you depend on this, then please use Flink `1.6.x`.&lt;br/&gt;
+&lt;br/&gt;
+### Savepoints being used for recovery&lt;br/&gt;
+&lt;br/&gt;
+Savepoints are now used while recovering.&lt;br/&gt;
+Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occurred after a savepoint was taken but before the next checkpoint occurred.&lt;br/&gt;
+This results in the fact that savepoints are no longer exclusively under the control of the user.&lt;br/&gt;
+Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.&lt;br/&gt;
+&lt;br/&gt;
+### MetricQueryService runs in separate thread pool&lt;br/&gt;
+&lt;br/&gt;
+The metric query service runs now in its own `ActorSystem`.&lt;br/&gt;
+It needs consequently to open a new port for the query services to communicate with each other.&lt;br/&gt;
+The &lt;span class=&quot;error&quot;&gt;&amp;#91;query service port&amp;#93;&lt;/span&gt;(&lt;tt&gt;site.baseurl&lt;/tt&gt;/ops/config.html#metrics-internal-query-service-port) can be configured in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Granularity of latency metrics&lt;br/&gt;
+&lt;br/&gt;
+The default granularity for latency metrics has been modified.&lt;br/&gt;
+To restore the previous behavior users have to explicitly set the &lt;span class=&quot;error&quot;&gt;&amp;#91;granularity&amp;#93;&lt;/span&gt;(&lt;tt&gt;site.baseurl&lt;/tt&gt;/ops/config.html#metrics-latency-granularity) to `subtask`.&lt;br/&gt;
+&lt;br/&gt;
+### Latency marker activation&lt;br/&gt;
+&lt;br/&gt;
+Latency metrics are now disabled by default, which will affect all jobs that do not explicitly set the `latencyTrackingInterval` via `ExecutionConfig#setLatencyTrackingInterval`.&lt;br/&gt;
+To restore the previous default behavior users have to configure the &lt;span class=&quot;error&quot;&gt;&amp;#91;latency interval&amp;#93;&lt;/span&gt;(&lt;tt&gt;site.baseurl&lt;/tt&gt;/ops/config.html#metrics-latency-interval) in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Relocation of Hadoop&apos;s Netty dependency&lt;br/&gt;
+&lt;br/&gt;
+We now also relocate Hadoop&apos;s Netty dependency from `io.netty` to `org.apache.flink.hadoop.shaded.io.netty`.&lt;br/&gt;
+You can now bundle your own version of Netty into your job but may no longer assume that `io.netty` is present in the `flink-shaded-hadoop2-uber-*.jar` file.&lt;br/&gt;
+&lt;br/&gt;
+### Local recovery fixed&lt;br/&gt;
+&lt;br/&gt;
+With the improvements to Flink&apos;s scheduling, it can no longer happen that recoveries require more slots than before if local recovery is enabled.&lt;br/&gt;
+Consequently, we encourage our users to enable &lt;span class=&quot;error&quot;&gt;&amp;#91;local recovery&amp;#93;&lt;/span&gt;(&lt;tt&gt;site.baseurl&lt;/tt&gt;/ops/config.html#state-backend-local-recovery) in `flink-conf.yaml`.&lt;br/&gt;
+&lt;br/&gt;
+### Support for multi slot TaskManagers&lt;br/&gt;
+&lt;br/&gt;
+Flink now properly supports `TaskManagers` with multiple slots.&lt;br/&gt;
+Consequently, `TaskManagers` can now be started with an arbitrary number of slots and it is no longer recommended to start them with a single slot.&lt;br/&gt;
+&lt;br/&gt;
+### StandaloneJobClusterEntrypoint generates JobGraph with fixed JobID&lt;br/&gt;
+&lt;br/&gt;
+The `StandaloneJobClusterEntrypoint`, which is launched by the script `standalone-job.sh` and used for the job-mode container images, now starts all jobs with a fixed `JobID`.&lt;br/&gt;
+Thus, in order to run a cluster in HA mode, one needs to set a different &lt;span class=&quot;error&quot;&gt;&amp;#91;cluster id&amp;#93;&lt;/span&gt;(&lt;tt&gt;site.baseurl&lt;/tt&gt;/ops/config.html#high-availability-cluster-id) for each job/cluster. &lt;br/&gt;
+&lt;br/&gt;
 &amp;lt;!-- Should be removed once &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10911&quot; title=&quot;Enable flink-scala-shell with Scala 2.12&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10911&quot;&gt;&lt;del&gt;FLINK-10911&lt;/del&gt;&lt;/a&gt; is fixed --&amp;gt;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Scala shell does not work with Scala 2.12&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;@@ -37,6 +128,15 @@ You should only use this feature if you are executing a stateless streaming job.&lt;br/&gt;
 In any other cases, it is highly recommended to remove the config option `jobmanager.execution.failover-strategy` from your `flink-conf.yaml` or set it to `&quot;full&quot;`.&lt;/p&gt;

&lt;p&gt; In order to avoid future problems, this feature has been removed from the documentation until it will be fixed.&lt;br/&gt;
-See &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10880&quot; title=&quot;Failover strategies should not be applied to Batch Execution&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10880&quot;&gt;&lt;del&gt;FLINK-10880&lt;/del&gt;&lt;/a&gt;(&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10880&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-10880&lt;/a&gt;) for more details. &lt;br/&gt;
+See &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10880&quot; title=&quot;Failover strategies should not be applied to Batch Execution&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10880&quot;&gt;&lt;del&gt;FLINK-10880&lt;/del&gt;&lt;/a&gt;(&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10880&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-10880&lt;/a&gt;) for more details.&lt;br/&gt;
+&lt;br/&gt;
+### SQL over window preceding clause&lt;br/&gt;
+&lt;br/&gt;
+The over window `preceding` clause is now optional.&lt;br/&gt;
+It defaults to `UNBOUNDED` if not specified.&lt;br/&gt;
+&lt;br/&gt;
+### OperatorSnapshotUtil writes v2 snapshots&lt;br/&gt;
+&lt;br/&gt;
+Snapshots created with `OperatorSnapshotUtil` are now written in the savepoint format `v2`.&lt;/p&gt;

 {% top %}




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16702116" author="till.rohrmann" created="Wed, 28 Nov 2018 16:36:21 +0000"  >&lt;p&gt;Fixed via&lt;br/&gt;
master: &lt;a href=&quot;https://github.com/apache/flink/commit/bef3dc6fd3d6b85f1f934a36338fa9c0f5dd4b87&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/commit/bef3dc6fd3d6b85f1f934a36338fa9c0f5dd4b87&lt;/a&gt;&lt;br/&gt;
1.7.0: &lt;a href=&quot;https://github.com/apache/flink/commit/b272f20e94eb9b0bd5b0af92105826be2437d5b6&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/commit/b272f20e94eb9b0bd5b0af92105826be2437d5b6&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 50 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s00pi0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>