<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:30:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-7657] SQL Timestamps Converted To Wrong Type By Optimizer Causing ClassCastException</title>
                <link>https://issues.apache.org/jira/browse/FLINK-7657</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;I have a SQL statement using the Tables API that has a timestamp in it. When the execution environment tries to optimize the SQL, it causes an exception (attached below).  The result is any SQL query with a timestamp, date, or time literal is unexecutable if any table source is marked with FilterableTableSource. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt; 
Exception in thread &quot;main&quot; java.lang.RuntimeException: Error while applying rule PushFilterIntoTableSourceScanRule, args [rel#30:FlinkLogicalCalc.LOGICAL(input=rel#29:Subset#0.LOGICAL,expr#0..1={inputs},expr#2=2017-05-01,expr#3=&amp;gt;($t1, $t2),data=$t0,last_updated=$t1,$condition=$t3), Scan(table:[test_table], fields:(data, last_updated))]
	at org.apache.calcite.plan.volcano.VolcanoRuleCall.onMatch(VolcanoRuleCall.java:235)
	at org.apache.calcite.plan.volcano.VolcanoPlanner.findBestExp(VolcanoPlanner.java:650)
	at org.apache.calcite.tools.Programs$RuleSetProgram.run(Programs.java:368)
	at org.apache.flink.table.api.TableEnvironment.runVolcanoPlanner(TableEnvironment.scala:266)
	at org.apache.flink.table.api.BatchTableEnvironment.optimize(BatchTableEnvironment.scala:298)
	at org.apache.flink.table.api.BatchTableEnvironment.translate(BatchTableEnvironment.scala:328)
	at org.apache.flink.table.api.BatchTableEnvironment.writeToSink(BatchTableEnvironment.scala:135)
	at org.apache.flink.table.api.Table.writeToSink(table.scala:800)
	at org.apache.flink.table.api.Table.writeToSink(table.scala:773)
	at com.remitly.flink.TestReproductionApp$.delayedEndpoint$com$remitly$flink$TestReproductionApp$1(TestReproductionApp.scala:27)
	at com.remitly.flink.TestReproductionApp$delayedInit$body.apply(TestReproductionApp.scala:22)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:34)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:76)
	at scala.App$$anonfun$main$1.apply(App.scala:76)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35)
	at scala.App$class.main(App.scala:76)
	at com.remitly.flink.TestReproductionApp$.main(TestReproductionApp.scala:22)
	at com.remitly.flink.TestReproductionApp.main(TestReproductionApp.scala)
Caused by: java.lang.ClassCastException: java.util.GregorianCalendar cannot be cast to java.util.Date
	at org.apache.flink.table.expressions.Literal.dateToCalendar(literals.scala:107)
	at org.apache.flink.table.expressions.Literal.toRexNode(literals.scala:80)
	at org.apache.flink.table.expressions.BinaryComparison$$anonfun$toRexNode$1.apply(comparison.scala:35)
	at org.apache.flink.table.expressions.BinaryComparison$$anonfun$toRexNode$1.apply(comparison.scala:35)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.immutable.List.map(List.scala:285)
	at org.apache.flink.table.expressions.BinaryComparison.toRexNode(comparison.scala:35)
	at org.apache.flink.table.plan.rules.logical.PushFilterIntoTableSourceScanRule$$anonfun$1.apply(PushFilterIntoTableSourceScanRule.scala:92)
	at org.apache.flink.table.plan.rules.logical.PushFilterIntoTableSourceScanRule$$anonfun$1.apply(PushFilterIntoTableSourceScanRule.scala:92)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at org.apache.flink.table.plan.rules.logical.PushFilterIntoTableSourceScanRule.pushFilterIntoScan(PushFilterIntoTableSourceScanRule.scala:92)
	at org.apache.flink.table.plan.rules.logical.PushFilterIntoTableSourceScanRule.onMatch(PushFilterIntoTableSourceScanRule.scala:56)
	at org.apache.calcite.plan.volcano.VolcanoRuleCall.onMatch(VolcanoRuleCall.java:211)
	... 19 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ve done quite a bit of debugging on this and tracked it down to a problem with the way a Calcite AST is translated into an Expression tree for the predicates. Calcite parses timestamps as Calendar values, and you&apos;ll note in &lt;a href=&quot;https://github.com/apache/flink/blob/master/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/util/RexProgramExtractor.scala#L160&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;RegNodeToExpressionConverter&lt;/a&gt; that a Calendar value is being passed as-is to the &lt;a href=&quot;https://github.com/apache/flink/blob/master/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala#L54&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Literal&lt;/a&gt; which does no conversion of the value. The Literal, in turn, &lt;a href=&quot;https://github.com/apache/flink/blob/master/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala#L106&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;expects the value to be a java.sql.Date subclass&lt;/a&gt;, which is where the exception arises.&lt;/p&gt;

&lt;p&gt;I&apos;ve done some informal testing of a bugfix where I convert the calendars to java.sql.Date/java.sql.Time/java.sql.Timestamp in RegNodeToExpressionConverter and had good results. Here is some reproduction code in Scala. I am using Flink version 1.3.2 and running it in local mode (Right-click + Run-as in IntelliJ). &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt;
package kmurra

import java.sql.Date
import java.util

import org.apache.flink.api.common.typeinfo.{BasicTypeInfo, SqlTimeTypeInfo, TypeInformation}
import org.apache.flink.api.java
import org.apache.flink.api.java.DataSet
import org.apache.flink.api.java.typeutils.RowTypeInfo
import org.apache.flink.api.scala.ExecutionEnvironment
import org.apache.flink.table.api.TableEnvironment
import org.apache.flink.table.api.scala.BatchTableEnvironment
import org.apache.flink.table.expressions.Expression
import org.apache.flink.table.sinks.{BatchTableSink, TableSinkBase}
import org.apache.flink.table.sources.{BatchTableSource, FilterableTableSource, TableSource}
import org.apache.flink.types.Row

import scala.collection.mutable.ListBuffer
import scala.collection.JavaConversions._


object TestReproductionApp extends App {
  val tables: BatchTableEnvironment = TableEnvironment.getTableEnvironment(ExecutionEnvironment.getExecutionEnvironment)
  val source = new TestTableSource
  val sink = new PrintTableSink()
  tables.registerTableSource(&quot;test_table&quot;, source)
  tables.sql(&quot;SELECT * FROM test_table WHERE last_updated &amp;gt; DATE &apos;2017-05-01&apos;&quot;).writeToSink(sink)
}

class PrintTableSink() extends TableSinkBase[Row] with BatchTableSink[Row] {
  def emitDataSet(dataSet: DataSet[Row]): Unit = dataSet.print()
  def getOutputType: TypeInformation[Row] = new RowTypeInfo(getFieldTypes, getFieldNames)
  protected def copy: TableSinkBase[Row] = new PrintTableSink()
}

class TestTableSource(val isFilterPushedDown: Boolean = false) extends BatchTableSource[Row] with FilterableTableSource[Row] {
  val getReturnType: RowTypeInfo = {
    val typeInfo = Array[TypeInformation[_]](BasicTypeInfo.STRING_TYPE_INFO, SqlTimeTypeInfo.DATE)
    val fieldNames = Array(&quot;data&quot;, &quot;last_updated&quot;)
    new RowTypeInfo(typeInfo, fieldNames)
  }

  def applyPredicate(predicates: util.List[Expression]): TableSource[Row] = new TestTableSource(true)

  def getDataSet(execEnv: java.ExecutionEnvironment): java.DataSet[Row] = {
    execEnv.fromCollection({
      val data = ListBuffer[Row]()
      data += row(&quot;Success!&quot;, Date.valueOf(&quot;2017-09-01&quot;))
      data += row(&quot;Failure!&quot;, Date.valueOf(&quot;2017-01-01&quot;))
      data
    })
  }

  def row(data: String, lastUpdated: Date): Row = {
    val row = new Row(2)
    row.setField(0, data)
    row.setField(1, lastUpdated)
    row
  }
}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; Build system is SBT &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt; 
name := &quot;kmurra-flink-reproduction&quot;
organization := &quot;kmurra&quot; 
version := &quot;1.0&quot;

scalaVersion := &quot;2.11.8&quot;

resolvers ++= Seq(&quot;Apache Development Snapshot Repository&quot; at &quot;https://repository.apache.org/content/repositories/snapshots/&quot;, Resolver.mavenLocal)

val flinkVersion = &quot;1.3.2&quot;


libraryDependencies ++= Seq(
  &quot;org.apache.flink&quot;     %% &quot;flink-scala&quot;             % flinkVersion,//     % &quot;provided&quot;,
  &quot;org.apache.flink&quot;     %% &quot;flink-table&quot;             % flinkVersion,//     % &quot;provided&quot;,
  &quot;org.apache.flink&quot;     %% &quot;flink-avro&quot;              % flinkVersion,//    % &quot;provided&quot;,
  &quot;org.apache.flink&quot;     %% &quot;flink-streaming-scala&quot;   % flinkVersion,//    % &quot;provided&quot;,
  &quot;org.apache.flink&quot;     %  &quot;flink-jdbc&quot;              % flinkVersion,//     % &quot;provided&quot;
)

assemblyMergeStrategy in assembly := {
  case PathList(&quot;META-INF&quot;, xs @ _*) =&amp;gt; MergeStrategy.discard
  case x =&amp;gt; MergeStrategy.first
}

// exclude Scala library from assembly
assemblyOption in assembly := (assemblyOption in assembly).value.copy(includeScala = false)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13103652">FLINK-7657</key>
            <summary>SQL Timestamps Converted To Wrong Type By Optimizer Causing ClassCastException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kmurra">Kent Murra</assignee>
                                    <reporter username="kmurra">Kent Murra</reporter>
                        <labels>
                    </labels>
                <created>Wed, 20 Sep 2017 16:03:41 +0000</created>
                <updated>Mon, 13 Nov 2017 13:28:10 +0000</updated>
                            <resolved>Mon, 13 Nov 2017 13:28:10 +0000</resolved>
                                    <version>1.3.1</version>
                    <version>1.3.2</version>
                    <version>1.4.0</version>
                                    <fixVersion>1.4.0</fixVersion>
                    <fixVersion>1.5.0</fixVersion>
                                    <component>Table SQL / API</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16173419" author="kmurra" created="Wed, 20 Sep 2017 16:08:49 +0000"  >&lt;p&gt;I&apos;m looking at taking my bugfix and formatting it as a code submission, but need some time to get it aligned with standards and write some reproduction test cases.&lt;/p&gt;

&lt;p&gt;Also: I marked this as Critical per the linked guidelines as this causes an exception (and therefore crash) in well-formed Flink Table programs.&lt;/p&gt;</comment>
                            <comment id="16173442" author="fhueske" created="Wed, 20 Sep 2017 16:26:25 +0000"  >&lt;p&gt;Thanks for reporting this bug and investigating the cause &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kmurra&quot; class=&quot;user-hover&quot; rel=&quot;kmurra&quot;&gt;kmurra&lt;/a&gt;!&lt;br/&gt;
Looking forward to your bugfix.&lt;/p&gt;

&lt;p&gt;I&apos;ve given you contributor permissions and assigned the issue to you. &lt;br/&gt;
Hope that&apos;s OK.&lt;/p&gt;

&lt;p&gt;Best, Fabian&lt;/p&gt;</comment>
                            <comment id="16173505" author="kmurra" created="Wed, 20 Sep 2017 17:04:09 +0000"  >&lt;p&gt;Thats great, thanks!&lt;/p&gt;</comment>
                            <comment id="16173959" author="kmurra" created="Wed, 20 Sep 2017 22:47:55 +0000"  >&lt;p&gt;I&apos;ve noticed that the scope of the problem is a bit larger than what I found.  As an example, integer literals in a SQL statement values are parsed as BigDecimal and not converted when moved to a literal.  When running the test cases I&apos;ll see Literals that have a BigDecimal value and a BasicTypeInfo.INT type.  It tends to work since the underlying engine considers Integers and BigDecimal comparable, however, my concern is that it does not match the documentation.  I can see people implementing FilterableTableSource being surprised by this.  At the same time, fixing the issue might break people who depend on the old behavior.&lt;/p&gt;

&lt;p&gt;I think for testing purposes, the ideal thing is to have the literal also encode the type so that we can do type verification as well in the test cases.  However the scope of such a change is very large, and I&apos;m not sure the maintainers would want to review such a patch.  I can limit the scope of my change but my concern is that it won&apos;t be a &lt;b&gt;good&lt;/b&gt; fix and more of a duct-tape thing.&lt;/p&gt;

&lt;p&gt;Can I get some guidance on whether I should expand the scope or just limit it to the time-based literals as originally reported?&lt;/p&gt;

&lt;p&gt;Let me know if there are any questions surrounding this.&lt;/p&gt;</comment>
                            <comment id="16179870" author="fhueske" created="Mon, 25 Sep 2017 22:14:50 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kmurra&quot; class=&quot;user-hover&quot; rel=&quot;kmurra&quot;&gt;kmurra&lt;/a&gt;, thanks for looking into this.&lt;br/&gt;
I&apos;m currently traveling but &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=twalthr&quot; class=&quot;user-hover&quot; rel=&quot;twalthr&quot;&gt;twalthr&lt;/a&gt; knows the SQL / Table API type system very well (better than I do) and might be able to help.&lt;/p&gt;</comment>
                            <comment id="16180684" author="twalthr" created="Tue, 26 Sep 2017 12:37:52 +0000"  >&lt;p&gt;Thanks for looking into this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kmurra&quot; class=&quot;user-hover&quot; rel=&quot;kmurra&quot;&gt;kmurra&lt;/a&gt;. The main problem is that &lt;tt&gt;RexNodeToExpressionConverter&lt;/tt&gt; is still very limited and not feature complete. In the past we focused on converting Table API &lt;tt&gt;Expression&lt;/tt&gt; to Calcite&apos;s &lt;tt&gt;RexNode&lt;/tt&gt;, but the way back is actually only required in the filter push-down for table sources. You can fix several issues in one contribution for the &lt;tt&gt;RexNodeToExpressionConverter&lt;/tt&gt; if you like. But I would not touch the &lt;tt&gt;Literal&lt;/tt&gt; class at the moment. The long-term goal should be to have a 1-to-1 mapping from &lt;tt&gt;Expression&lt;/tt&gt; to &lt;tt&gt;RexNode&lt;/tt&gt; and back to &lt;tt&gt;Expression&lt;/tt&gt;. An alternative that I proposed earlier was to limit the expressions pushed into the sources (such as only literals and simple arithmetic). But I think we didn&apos;t want to do that right, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fhueske&quot; class=&quot;user-hover&quot; rel=&quot;fhueske&quot;&gt;fhueske&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="16183241" author="kmurra" created="Wed, 27 Sep 2017 20:47:40 +0000"  >&lt;p&gt;Thanks for the information Timo.  My approach was to add an apply method that takes in the RexLiteral to the object as follows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;object Literal {
  ...

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt;[flink] def apply(rexNode: RexLiteral): Literal = {
    val literalType = FlinkTypeFactory.toTypeInfo(rexNode.getType)

    val literalValue = literalType match {
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _@SqlTimeTypeInfo.DATE =&amp;gt;
        val rexValue = rexNode.getValueAs(classOf[DateString])
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Date(rexValue.getMillisSinceEpoch)
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _@SqlTimeTypeInfo.TIME =&amp;gt;
        val rexValue = rexNode.getValueAs(classOf[TimeString])
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Time(rexValue.getMillisOfDay)
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _@SqlTimeTypeInfo.TIMESTAMP =&amp;gt;
        &lt;span class=&quot;code-comment&quot;&gt;// We&lt;span class=&quot;code-quote&quot;&gt;&apos;re losing nanosecond precision but according to the documentation we&apos;&lt;/span&gt;re only
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// supporting TIMESTAMP(3) at the moment.  In order to support nanosecond precision, we&apos;d want to
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// convert to string and then to java.sql.Timestamp
&lt;/span&gt;        val rexValue = rexNode.getValueAs(classOf[TimestampString])
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Timestamp(rexValue.getMillisSinceEpoch)
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt;rexNode.getValue
    }

    Literal(literalValue, literalType)
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;My view: We want to keep the transformation logic to and from the RexNode in a similar file so its more obvious that changes need to be &quot;paired&quot;.  This doesn&apos;t match your suggestion, but I think that you were warning me away from touching the case class Literal since that appears to be fairly widely used, and impact is hard to gauge.&lt;/p&gt;

&lt;p&gt;Sorry for the delay in getting a PR out since I got randomized.  I&apos;m looking at this again, and I&apos;ll get something out and let you guys tell me what you do or don&apos;t like about it.  For now I&apos;ll focus on the Date/Time/Timestamp aspect and can follow up with the other types as necessary.&lt;/p&gt;</comment>
                            <comment id="16183465" author="kmurra" created="Wed, 27 Sep 2017 23:47:38 +0000"  >&lt;p&gt;As an aside, my testing indicates that the &quot;DATE/TIME/TIMESTAMP&quot; functions in the SQL language assume UTC time zone.  is that correct?  If so then it might be a good idea to document that in correct places in the API and the online documentation (I can attempt to do so if I can find the appropriate places to edit, which I haven&apos;t so-far).&lt;/p&gt;

&lt;p&gt;In particular, &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/table/sql.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/table/sql.html&lt;/a&gt; indicates field translations to a set of raw java types that are time-zone sensitive (all subclasses of java.util.Date) while not indicating the assumed time zone.  For my use case (trying to write something that pushes down timestamp predicates into a query against a MySQL database), this can cause some significant confusion and require experimentation to work out.&lt;/p&gt;

&lt;p&gt;Alternatively, we can mimic what Calcite is doing and have them be specially-typed strings (Calcite uses TimeString, TimestampString, DateString).  Since Java 7 is still supported we unfortunately can&apos;t use the new time API.&lt;/p&gt;</comment>
                            <comment id="16185270" author="githubbot" created="Fri, 29 Sep 2017 02:26:45 +0000"  >&lt;p&gt;GitHub user kmurra opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7657&quot; title=&quot;SQL Timestamps Converted To Wrong Type By Optimizer Causing ClassCastException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-7657&quot;&gt;&lt;del&gt;FLINK-7657&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Table&amp;#93;&lt;/span&gt; Adding logic to convert RexLiteral to expected SQL Date/Time/Timestamp classes&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    This change fixes handling of date, time, and timestamp literal expressions.&lt;/p&gt;

&lt;p&gt;    A ClassCastException occurs if you have a date, time, or timestamp literal included in the where clause of a SQL query.  When Calcite trees are converted to an Expression, Literal values are not properly converted to the expected types by the RegNodeToExpressionConverter.&lt;/p&gt;

&lt;p&gt;    See &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7657&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-7657&lt;/a&gt; for more information.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added a method that takes a RexLiteral in the Literal object and applies the appropriate transforms to date &amp;amp; time related fields.&lt;/li&gt;
	&lt;li&gt;Have a default fallback that works using the old behavior for other field types.&lt;/li&gt;
	&lt;li&gt;Note that handling of other types are incorrect per the public documentation, but fixes are out of scope for this JIRA&lt;/li&gt;
	&lt;li&gt;Added comments that explained handling of values (specifically why we&apos;re shifting them based on time zones)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    This change added tests and can be verified as follows:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Unit test cases were added covering changes&lt;/li&gt;
	&lt;li&gt;Added unit test case to RexProgramExtractorTest.scala to test that literal conversions are of the appropriate type.&lt;/li&gt;
	&lt;li&gt;Added unit test case to TableSourceTest.scala to confirm that received Expressions in a table source extending from FilterableTableSource do not cause exceptions and have expected values&lt;/li&gt;
	&lt;li&gt;Note: Other unit test cases cover possible regressions in output values from the Literal-&amp;gt;RexNode conversion&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): no&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: no&lt;/li&gt;
	&lt;li&gt;The serializers: no&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): no&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: no&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? no&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? not applicable&lt;/li&gt;
&lt;/ul&gt;




&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/kmurra/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/kmurra/flink&lt;/a&gt; kmurra-expression-timestamp-fix&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #4746&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit d8477977694614ed51ad53de55104df10ac55ad4&lt;br/&gt;
Author: Kent Murra &amp;lt;kentm@remitly.com&amp;gt;&lt;br/&gt;
Date:   2017-09-27T20:48:55Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7657&quot; title=&quot;SQL Timestamps Converted To Wrong Type By Optimizer Causing ClassCastException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-7657&quot;&gt;&lt;del&gt;FLINK-7657&lt;/del&gt;&lt;/a&gt; Adding logic to convert RexLiteral to expected SQL Date/Time/Timestamp classes, preventing ClassCastException&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16185271" author="kmurra" created="Fri, 29 Sep 2017 02:27:06 +0000"  >&lt;p&gt;Pull request has been submitted: &lt;a href=&quot;https://github.com/apache/flink/pull/4746&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16191135" author="githubbot" created="Wed, 4 Oct 2017 11:23:04 +0000"  >&lt;p&gt;Github user twalthr commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142633894&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142633894&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/CheckExpressionsTableSource.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,65 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.table.utils&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.RowTypeInfo&lt;br/&gt;
    +import org.apache.flink.api.java.&lt;/p&gt;
{DataSet, ExecutionEnvironment}
&lt;p&gt;    +import org.apache.flink.streaming.api.datastream.DataStream&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment&lt;br/&gt;
    +import org.apache.flink.table.expressions.Expression&lt;br/&gt;
    +import org.apache.flink.table.sources.&lt;/p&gt;
{BatchTableSource, FilterableTableSource, StreamTableSource}
&lt;p&gt;    +import org.apache.flink.types.Row&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util&lt;br/&gt;
    +import java.util.Collections&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.collection.JavaConverters._&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * A table source that takes in assertions and applies them when applyPredicate is called.&lt;br/&gt;
    +  * Allows for testing that expression push downs are handled properly&lt;br/&gt;
    +  * @param typeInfo The type info.&lt;br/&gt;
    +  * @param assertions A set of assertions as a function reference&lt;br/&gt;
    +  * @param pushedDown Whether this has been pushed down/&lt;br/&gt;
    +  */&lt;br/&gt;
    +class CheckExpressionsTableSource(typeInfo: RowTypeInfo,&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Maybe it would be better to generalize `TestFilterableTableSource`.&lt;/p&gt;</comment>
                            <comment id="16191136" author="githubbot" created="Wed, 4 Oct 2017 11:23:05 +0000"  >&lt;p&gt;Github user twalthr commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142632025&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142632025&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala &amp;#8212;&lt;br/&gt;
    @@ -49,10 +50,51 @@ object Literal &lt;/p&gt;
{
         case sqlTime: Time =&amp;gt; Literal(sqlTime, SqlTimeTypeInfo.TIME)
         case sqlTimestamp: Timestamp =&amp;gt; Literal(sqlTimestamp, SqlTimeTypeInfo.TIMESTAMP)
       }
&lt;p&gt;    +&lt;br/&gt;
    +  private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def apply(rexNode: RexLiteral): Literal = {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This logic is better located in `RexNodeToExpressionConverter.visitLiteral`.&lt;/p&gt;</comment>
                            <comment id="16191137" author="githubbot" created="Wed, 4 Oct 2017 11:23:05 +0000"  >&lt;p&gt;Github user twalthr commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142642598&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142642598&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala &amp;#8212;&lt;br/&gt;
    @@ -49,10 +50,51 @@ object Literal &lt;/p&gt;
{
         case sqlTime: Time =&amp;gt; Literal(sqlTime, SqlTimeTypeInfo.TIME)
         case sqlTimestamp: Timestamp =&amp;gt; Literal(sqlTimestamp, SqlTimeTypeInfo.TIMESTAMP)
       }
&lt;p&gt;    +&lt;br/&gt;
    +  private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def apply(rexNode: RexLiteral): Literal = {&lt;br/&gt;
    +    val literalType = FlinkTypeFactory.toTypeInfo(rexNode.getType)&lt;br/&gt;
    +&lt;br/&gt;
    +    val literalValue = literalType match {&lt;br/&gt;
    +      // Chrono use cases.  We&apos;re force-adjusting the UTC-based epoch timestamps to a new&lt;br/&gt;
    +      // timestamp such that we get the same year/month/hour/day field values in the query&apos;s&lt;br/&gt;
    +      // timezone (UTC)&lt;br/&gt;
    +      case _@SqlTimeTypeInfo.DATE =&amp;gt;&lt;br/&gt;
    +        val rexValue = rexNode.getValueAs(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;DateString&amp;#93;&lt;/span&gt;)&lt;br/&gt;
    +        val adjustedCal = adjustCalendar(rexValue.toCalendar, TimeZone.getDefault)&lt;br/&gt;
    +        new Date(adjustedCal.getTimeInMillis)&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This can be simplified to `new Date(rexValue.toString)`.&lt;/p&gt;</comment>
                            <comment id="16191138" author="githubbot" created="Wed, 4 Oct 2017 11:23:05 +0000"  >&lt;p&gt;Github user twalthr commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142641600&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142641600&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala &amp;#8212;&lt;br/&gt;
    @@ -103,13 +148,21 @@ case class Literal(value: Any, resultType: TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;) extends LeafExpre&lt;br/&gt;
         }&lt;br/&gt;
       }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def dateToCalendar: Calendar = {&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Convert a date value to a utc calendar.&lt;br/&gt;
    +    * &amp;lt;p&amp;gt;&lt;br/&gt;
    +    * We&apos;re assuming that when the user passes in a Date its constructed from fields,&lt;br/&gt;
    +    * such as days and hours, and that they want those fields to be in the same timezone as the&lt;br/&gt;
    +    * Calcite times, which are UTC.  Since we need to convert a Date to a Calendar, that means we&lt;br/&gt;
    +    * have to shift the epoch millisecond timestamp to account for the difference between UTC and&lt;br/&gt;
    +    * local time.&lt;br/&gt;
    +    * @return Get the Calendar value&lt;br/&gt;
    +    */&lt;br/&gt;
    +  private def valueAsUtcCalendar: Calendar = {&lt;br/&gt;
         val date = value.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;java.util.Date&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;val cal = Calendar.getInstance(Literal.GMT)&lt;/li&gt;
	&lt;li&gt;val t = date.getTime&lt;/li&gt;
	&lt;li&gt;// according to Calcite&apos;s SqlFunctions.internalToXXX methods&lt;/li&gt;
	&lt;li&gt;cal.setTimeInMillis(t + TimeZone.getDefault.getOffset(t))
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Could you explain why `cal.setTimeInMillis(t + TimeZone.getDefault.getOffset(t))` did not produce the correct result? Calcite is also doing it like that.&lt;/p&gt;</comment>
                            <comment id="16191139" author="githubbot" created="Wed, 4 Oct 2017 11:23:05 +0000"  >&lt;p&gt;Github user twalthr commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142634197&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142634197&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/TableTestBase.scala &amp;#8212;&lt;br/&gt;
    @@ -200,10 +201,30 @@ case class BatchTableTestUtil() extends TableTestUtil &lt;/p&gt;
{
         printTable(tableEnv.sqlQuery(query))
       }

&lt;p&gt;    +  def verifyExpressionProjection(fields: Seq[(String, TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;)],&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The `TableTestBase` class is intended for general test utilities. This looks very specific to me. I would add to to the `TableSourceTest` or a utils class there.&lt;/p&gt;</comment>
                            <comment id="16192076" author="githubbot" created="Wed, 4 Oct 2017 21:36:20 +0000"  >&lt;p&gt;Github user kmurra commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142799362&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142799362&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala &amp;#8212;&lt;br/&gt;
    @@ -49,10 +50,51 @@ object Literal &lt;/p&gt;
{
         case sqlTime: Time =&amp;gt; Literal(sqlTime, SqlTimeTypeInfo.TIME)
         case sqlTimestamp: Timestamp =&amp;gt; Literal(sqlTimestamp, SqlTimeTypeInfo.TIMESTAMP)
       }
&lt;p&gt;    +&lt;br/&gt;
    +  private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def apply(rexNode: RexLiteral): Literal = {&lt;br/&gt;
    +    val literalType = FlinkTypeFactory.toTypeInfo(rexNode.getType)&lt;br/&gt;
    +&lt;br/&gt;
    +    val literalValue = literalType match {&lt;br/&gt;
    +      // Chrono use cases.  We&apos;re force-adjusting the UTC-based epoch timestamps to a new&lt;br/&gt;
    +      // timestamp such that we get the same year/month/hour/day field values in the query&apos;s&lt;br/&gt;
    +      // timezone (UTC)&lt;br/&gt;
    +      case _@SqlTimeTypeInfo.DATE =&amp;gt;&lt;br/&gt;
    +        val rexValue = rexNode.getValueAs(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;DateString&amp;#93;&lt;/span&gt;)&lt;br/&gt;
    +        val adjustedCal = adjustCalendar(rexValue.toCalendar, TimeZone.getDefault)&lt;br/&gt;
    +        new Date(adjustedCal.getTimeInMillis)&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Unfortunately that constructor is deprecated in Java 8, which is why I avoided using it.  &lt;/p&gt;</comment>
                            <comment id="16192084" author="githubbot" created="Wed, 4 Oct 2017 21:40:53 +0000"  >&lt;p&gt;Github user kmurra commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142800400&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142800400&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala &amp;#8212;&lt;br/&gt;
    @@ -103,13 +148,21 @@ case class Literal(value: Any, resultType: TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;) extends LeafExpre&lt;br/&gt;
         }&lt;br/&gt;
       }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def dateToCalendar: Calendar = {&lt;br/&gt;
    +  /**&lt;br/&gt;
    +    * Convert a date value to a utc calendar.&lt;br/&gt;
    +    * &amp;lt;p&amp;gt;&lt;br/&gt;
    +    * We&apos;re assuming that when the user passes in a Date its constructed from fields,&lt;br/&gt;
    +    * such as days and hours, and that they want those fields to be in the same timezone as the&lt;br/&gt;
    +    * Calcite times, which are UTC.  Since we need to convert a Date to a Calendar, that means we&lt;br/&gt;
    +    * have to shift the epoch millisecond timestamp to account for the difference between UTC and&lt;br/&gt;
    +    * local time.&lt;br/&gt;
    +    * @return Get the Calendar value&lt;br/&gt;
    +    */&lt;br/&gt;
    +  private def valueAsUtcCalendar: Calendar = {&lt;br/&gt;
         val date = value.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;java.util.Date&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;val cal = Calendar.getInstance(Literal.GMT)&lt;/li&gt;
	&lt;li&gt;val t = date.getTime&lt;/li&gt;
	&lt;li&gt;// according to Calcite&apos;s SqlFunctions.internalToXXX methods&lt;/li&gt;
	&lt;li&gt;cal.setTimeInMillis(t + TimeZone.getDefault.getOffset(t))
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    The re-implemented adjustCalendar method is functionally the same as this when toTz is the UTC TimeZone.  Its just generalized to allow converting between arbitrary TimeZones so that I can re-use it in the RexLiteral to Expression conversion.&lt;/p&gt;</comment>
                            <comment id="16192085" author="githubbot" created="Wed, 4 Oct 2017 21:41:56 +0000"  >&lt;p&gt;Github user kmurra commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142800611&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142800611&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/CheckExpressionsTableSource.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,65 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.table.utils&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.RowTypeInfo&lt;br/&gt;
    +import org.apache.flink.api.java.&lt;/p&gt;
{DataSet, ExecutionEnvironment}
&lt;p&gt;    +import org.apache.flink.streaming.api.datastream.DataStream&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment&lt;br/&gt;
    +import org.apache.flink.table.expressions.Expression&lt;br/&gt;
    +import org.apache.flink.table.sources.&lt;/p&gt;
{BatchTableSource, FilterableTableSource, StreamTableSource}
&lt;p&gt;    +import org.apache.flink.types.Row&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util&lt;br/&gt;
    +import java.util.Collections&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.collection.JavaConverters._&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    +  * A table source that takes in assertions and applies them when applyPredicate is called.&lt;br/&gt;
    +  * Allows for testing that expression push downs are handled properly&lt;br/&gt;
    +  * @param typeInfo The type info.&lt;br/&gt;
    +  * @param assertions A set of assertions as a function reference&lt;br/&gt;
    +  * @param pushedDown Whether this has been pushed down/&lt;br/&gt;
    +  */&lt;br/&gt;
    +class CheckExpressionsTableSource(typeInfo: RowTypeInfo,&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I&apos;ll look at doing that.  It was my initial approach, but when I saw the potential set of test cases that would impact, I decided to do something more conservative.  Still do-able.&lt;/p&gt;</comment>
                            <comment id="16192087" author="githubbot" created="Wed, 4 Oct 2017 21:42:02 +0000"  >&lt;p&gt;Github user kmurra commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142800631&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142800631&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/TableTestBase.scala &amp;#8212;&lt;br/&gt;
    @@ -200,10 +201,30 @@ case class BatchTableTestUtil() extends TableTestUtil &lt;/p&gt;
{
         printTable(tableEnv.sqlQuery(query))
       }

&lt;p&gt;    +  def verifyExpressionProjection(fields: Seq[(String, TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;)],&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I will move this.&lt;/p&gt;</comment>
                            <comment id="16192090" author="githubbot" created="Wed, 4 Oct 2017 21:45:10 +0000"  >&lt;p&gt;Github user kmurra commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142801313&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142801313&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala &amp;#8212;&lt;br/&gt;
    @@ -49,10 +50,51 @@ object Literal &lt;/p&gt;
{
         case sqlTime: Time =&amp;gt; Literal(sqlTime, SqlTimeTypeInfo.TIME)
         case sqlTimestamp: Timestamp =&amp;gt; Literal(sqlTimestamp, SqlTimeTypeInfo.TIMESTAMP)
       }
&lt;p&gt;    +&lt;br/&gt;
    +  private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def apply(rexNode: RexLiteral): Literal = {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I&apos;ll commit to using your standards for the code-base.  However, allow me to voice a disagreement here:&lt;/p&gt;

&lt;p&gt;    The Literal class does the conversion from the Literal back to the RexLiteral.  Having this logic specifically in RexNodeToExpressionConverted means the RexLiteral-to-Literal logic is physically split from the Literal-to-RexLiteral logic.  This makes it slightly easier for a contributor to make a change in one side of the conversion without accounting for the other.  In particular, the date adjustments here become harder to understand since the context is split between two different files. &lt;/p&gt;
</comment>
                            <comment id="16192091" author="githubbot" created="Wed, 4 Oct 2017 21:45:38 +0000"  >&lt;p&gt;Github user kmurra commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746#discussion_r142801455&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746#discussion_r142801455&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/literals.scala &amp;#8212;&lt;br/&gt;
    @@ -49,10 +50,51 @@ object Literal &lt;/p&gt;
{
         case sqlTime: Time =&amp;gt; Literal(sqlTime, SqlTimeTypeInfo.TIME)
         case sqlTimestamp: Timestamp =&amp;gt; Literal(sqlTimestamp, SqlTimeTypeInfo.TIMESTAMP)
       }
&lt;p&gt;    +&lt;br/&gt;
    +  private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def apply(rexNode: RexLiteral): Literal = {&lt;br/&gt;
    +    val literalType = FlinkTypeFactory.toTypeInfo(rexNode.getType)&lt;br/&gt;
    +&lt;br/&gt;
    +    val literalValue = literalType match {&lt;br/&gt;
    +      // Chrono use cases.  We&apos;re force-adjusting the UTC-based epoch timestamps to a new&lt;br/&gt;
    +      // timestamp such that we get the same year/month/hour/day field values in the query&apos;s&lt;br/&gt;
    +      // timezone (UTC)&lt;br/&gt;
    +      case _@SqlTimeTypeInfo.DATE =&amp;gt;&lt;br/&gt;
    +        val rexValue = rexNode.getValueAs(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;DateString&amp;#93;&lt;/span&gt;)&lt;br/&gt;
    +        val adjustedCal = adjustCalendar(rexValue.toCalendar, TimeZone.getDefault)&lt;br/&gt;
    +        new Date(adjustedCal.getTimeInMillis)&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Do you want me to use the deprecated constructor or leave this as-is?&lt;/p&gt;</comment>
                            <comment id="16192108" author="githubbot" created="Wed, 4 Oct 2017 21:55:32 +0000"  >&lt;p&gt;Github user kmurra commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Regarding the time zones, I think I understand your argument here.  Is there anything in particular that you would want me to change overall that you haven&apos;t already outlined to account for that? I do want to document why we&apos;re doing any conversions of time zones since it took me some amount of time to understand why it was being done (it looked incorrect to myself and several other developers on first glance).&lt;/p&gt;

&lt;p&gt;    Also, I noticed that the Calcite fromCalendarFields simply take the fields directly from the Calendar, so making time-zone adjustments are unnecessary after I made the changes to toRexNode.  I&apos;ll fix that as well for my next commit.&lt;/p&gt;</comment>
                            <comment id="16199500" author="githubbot" created="Tue, 10 Oct 2017 22:39:01 +0000"  >&lt;p&gt;Github user kmurra commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    The biggest change here is in the test cases &amp;#8211; I generalized the test table source to have some basic filtering logic and allow for generic datasets.&lt;/p&gt;

&lt;p&gt;    I moved the Literal build logic to the RexNodeToExpressionConverter.visitLiteral.  I also rewrote several of the conversion methods to more closely align with the intended behavior of the code - that we&apos;re preserving the string values of the various time-related literals in the local timezone.  This made a bunch of the epoch-millisecond modifications go away.&lt;/p&gt;</comment>
                            <comment id="16249358" author="githubbot" created="Mon, 13 Nov 2017 10:28:36 +0000"  >&lt;p&gt;Github user twalthr commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the update @kmurra. I will go over the changes a last time and merge this.&lt;/p&gt;</comment>
                            <comment id="16249541" author="githubbot" created="Mon, 13 Nov 2017 13:22:34 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4746&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4746&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16249547" author="twalthr" created="Mon, 13 Nov 2017 13:28:10 +0000"  >&lt;p&gt;Fixed in 1.5: 3b333b289cbbe43f722edef2c36c370ff4550128 &amp;amp; 32e5194d95742dc0115a2b4d8c34e3f025feebd0&lt;br/&gt;
Fixed in 1.4: bb04187efffc74e17ded8b6199b023d7416ad5a3 &amp;amp; ce1cb8fd6d667713be9b5f9ec8f1c394b9ca4644&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 1 week, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3kb1b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>