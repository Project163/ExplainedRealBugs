<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:38:33 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10774] connection leak when partition discovery is disabled and open throws exception</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10774</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Here is the scenario to reproduce the issue&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;partition discovery is disabled&lt;/li&gt;
	&lt;li&gt;open method throws an exception (e.g. when broker SSL authorization denies request)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In this scenario, run method won&apos;t be executed. As a result, &lt;em&gt;partitionDiscoverer.close()&lt;/em&gt; won&apos;t be called. that caused the connection leak, because KafkaConsumer is initialized but not closed. That has caused outage that brought down our Kafka cluster, when a high-parallelism job got into a restart/failure loop.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13196125">FLINK-10774</key>
            <summary>connection leak when partition discovery is disabled and open throws exception</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="trohrmann">Till Rohrmann</assignee>
                                    <reporter username="stevenz3wu">Steven Zhen Wu</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Sun, 4 Nov 2018 18:31:32 +0000</created>
                <updated>Thu, 14 Feb 2019 16:15:35 +0000</updated>
                            <resolved>Thu, 31 Jan 2019 10:49:47 +0000</resolved>
                                    <version>1.4.2</version>
                    <version>1.5.5</version>
                    <version>1.6.2</version>
                                    <fixVersion>1.6.4</fixVersion>
                    <fixVersion>1.7.2</fixVersion>
                    <fixVersion>1.8.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1800">0.5h</timespent>
                                <comments>
                            <comment id="16674471" author="stevenz3wu" created="Sun, 4 Nov 2018 18:33:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srichter&quot; class=&quot;user-hover&quot; rel=&quot;srichter&quot;&gt;srichter&lt;/a&gt; &#160;FYI. I will submit a patch soon&lt;/p&gt;</comment>
                            <comment id="16674606" author="githubbot" created="Mon, 5 Nov 2018 02:29:15 +0000"  >&lt;p&gt;stevenzwu opened a new pull request #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &#8230;d open throws exception&lt;/p&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16685580" author="githubbot" created="Tue, 13 Nov 2018 18:31:26 +0000"  >&lt;p&gt;stevenzwu commented on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-438384937&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-438384937&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @tillrohrmann &lt;/p&gt;

&lt;p&gt;   &amp;gt; shouldn&apos;t we close the partitionDiscoverer in the open method in case of a failure. Moreover, we could also close it there in the case if automatic partition discovery is disabled. &lt;/p&gt;

&lt;p&gt;   right now, the if-else check of partition discovery is done in `run` method to decide if we need to close the `partitionDiscoverer` before `runFetchLoop`. I didn&apos;t want to change that, unless we want to move the starting of `discoveryLoopThread` into open method as well. is that what you have in mind?&lt;/p&gt;

&lt;p&gt;   I was thinking `cancel` method as the catch/finally block in Java. Plus it was the place where we close `partitionDiscoverer` for the enabled case. I though it might makes sense to ensure the cleanup in `cancel` method for both disabled and enabled cases&lt;/p&gt;

&lt;p&gt;   &amp;gt; in line FlinkKafkaConsumerBase.java:721 fails with an exception? &lt;/p&gt;

&lt;p&gt;   line 721 is for the partition discovery enabled case, partitionDiscoverer is closed in the cancel method in line 748&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16685582" author="githubbot" created="Tue, 13 Nov 2018 18:31:46 +0000"  >&lt;p&gt;stevenzwu edited a comment on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-438384937&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-438384937&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @tillrohrmann &lt;/p&gt;

&lt;p&gt;   &amp;gt; shouldn&apos;t we close the partitionDiscoverer in the open method in case of a failure. Moreover, we could also close it there in the case if automatic partition discovery is disabled. &lt;/p&gt;

&lt;p&gt;   right now, the if-else check of partition discovery is done in `run` method to decide if we need to close the `partitionDiscoverer` before `runFetchLoop`. I didn&apos;t want to change that, unless we want to move the starting of `discoveryLoopThread` into open method as well. is that what you have in mind?&lt;/p&gt;

&lt;p&gt;   I was thinking `cancel` method as the catch/finally block in Java. Plus it was the place where we close `partitionDiscoverer` for the enabled case. I though it might makes sense to ensure the cleanup in `cancel` method for both disabled and enabled cases&lt;/p&gt;

&lt;p&gt;   &amp;gt; in line FlinkKafkaConsumerBase.java:721 fails with an exception? &lt;/p&gt;

&lt;p&gt;   line 721 is for the partition discovery enabled case, `partitionDiscoverer` is closed in the `cancel` method in line 748&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16686106" author="githubbot" created="Wed, 14 Nov 2018 05:38:14 +0000"  >&lt;p&gt;stevenzwu commented on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-438544127&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-438544127&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   we saw some exception regarding redundant calls to close method. will need to fix it.&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   2018-11-13 18:26:54,928 ERROR org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase  - failed to close partitionDiscoverer&lt;br/&gt;
   java.lang.IllegalStateException: This consumer has already been closed.&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.ensureNotClosed(KafkaConsumer.java:1613)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.acquire(KafkaConsumer.java:1624)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1526)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1506)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09PartitionDiscoverer.closeConnections(Kafka09PartitionDiscoverer.java:97)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internals.AbstractPartitionDiscoverer.close(AbstractPartitionDiscoverer.java:101)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.cancel(FlinkKafkaConsumerBase.java:673)&lt;br/&gt;
   	at org.apache.flink.streaming.api.operators.StreamSource.cancel(StreamSource.java:108)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.cancelTask(SourceStreamTask.java:100)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.StreamTask.cancel(StreamTask.java:369)&lt;br/&gt;
   	at org.apache.flink.runtime.taskmanager.Task$TaskCanceler.run(Task.java:1481)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16686108" author="githubbot" created="Wed, 14 Nov 2018 05:41:09 +0000"  >&lt;p&gt;stevenzwu edited a comment on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-438544127&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-438544127&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   we saw some exception regarding redundant calls to close method. will need to fix it.&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   2018-11-13 18:26:54,928 ERROR org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase  - failed to close partitionDiscoverer&lt;br/&gt;
   java.lang.IllegalStateException: This consumer has already been closed.&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.ensureNotClosed(KafkaConsumer.java:1613)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.acquire(KafkaConsumer.java:1624)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1526)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1506)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09PartitionDiscoverer.closeConnections(Kafka09PartitionDiscoverer.java:97)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internals.AbstractPartitionDiscoverer.close(AbstractPartitionDiscoverer.java:101)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.cancel(FlinkKafkaConsumerBase.java:673)&lt;br/&gt;
   	at org.apache.flink.streaming.api.operators.StreamSource.cancel(StreamSource.java:108)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.cancelTask(SourceStreamTask.java:100)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.StreamTask.cancel(StreamTask.java:369)&lt;br/&gt;
   	at org.apache.flink.runtime.taskmanager.Task$TaskCanceler.run(Task.java:1481)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;   maybe we should add synchronized to this method?&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   	@Override&lt;br/&gt;
   	protected void closeConnections() throws Exception {&lt;br/&gt;
   		if (this.kafkaConsumer != null) &lt;/p&gt;
{
   			this.kafkaConsumer.close();
   
   			// de-reference the consumer to avoid closing multiple times
   			this.kafkaConsumer = null;
   		}
&lt;p&gt;   	}&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687278" author="githubbot" created="Wed, 14 Nov 2018 23:26:41 +0000"  >&lt;p&gt;stevenzwu edited a comment on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-438544127&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-438544127&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   we saw some exception regarding redundant calls to close method. will need to fix it.&lt;br/&gt;
   ```&lt;br/&gt;
   2018-11-13 18:26:54,928 ERROR org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase  - failed to close partitionDiscoverer&lt;br/&gt;
   java.lang.IllegalStateException: This consumer has already been closed.&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.ensureNotClosed(KafkaConsumer.java:1613)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.acquire(KafkaConsumer.java:1624)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1526)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1506)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09PartitionDiscoverer.closeConnections(Kafka09PartitionDiscoverer.java:97)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internals.AbstractPartitionDiscoverer.close(AbstractPartitionDiscoverer.java:101)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.cancel(FlinkKafkaConsumerBase.java:673)&lt;br/&gt;
   	at org.apache.flink.streaming.api.operators.StreamSource.cancel(StreamSource.java:108)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.cancelTask(SourceStreamTask.java:100)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.StreamTask.cancel(StreamTask.java:369)&lt;br/&gt;
   	at org.apache.flink.runtime.taskmanager.Task$TaskCanceler.run(Task.java:1481)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;   Can `run` method and `cancel` method executed in different threads? if so, we need to add `synchronized` to this method in `Kafka09PartitionDiscoverer`. &lt;br/&gt;
   ```&lt;br/&gt;
   	@Override&lt;br/&gt;
   	protected void closeConnections() throws Exception {&lt;br/&gt;
   		if (this.kafkaConsumer != null) &lt;/p&gt;
{
   			this.kafkaConsumer.close();
   
   			// de-reference the consumer to avoid closing multiple times
   			this.kafkaConsumer = null;
   		}
&lt;p&gt;   	}&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;   I looked at the `KafkaConsumer` code again. its close method calls `acquire`. I thought it is acquire lock, which is not the case.&lt;br/&gt;
   ```&lt;br/&gt;
       private void acquire() {&lt;br/&gt;
           this.ensureNotClosed();&lt;br/&gt;
           long threadId = Thread.currentThread().getId();&lt;br/&gt;
           if (threadId != this.currentThread.get() &amp;amp;&amp;amp; !this.currentThread.compareAndSet(-1L, threadId)) &lt;/p&gt;
{
               throw new ConcurrentModificationException(&quot;KafkaConsumer is not safe for multi-threaded access&quot;);
           }
&lt;p&gt; else &lt;/p&gt;
{
               this.refcount.incrementAndGet();
           }
&lt;p&gt;       }&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16687465" author="githubbot" created="Thu, 15 Nov 2018 04:36:15 +0000"  >&lt;p&gt;stevenzwu commented on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-438914628&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-438914628&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Got the evidence that it is thread safety problem&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   2018-11-15 04:24:17,795 ERROR org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase  - failed to close partitionDiscoverer&lt;br/&gt;
   java.util.ConcurrentModificationException: KafkaConsumer is not safe for multi-threaded access&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.acquire(KafkaConsumer.java:1627)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1526)&lt;br/&gt;
   	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1506)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09PartitionDiscoverer.closeConnections(Kafka09PartitionDiscoverer.java:97)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.internals.AbstractPartitionDiscoverer.close(AbstractPartitionDiscoverer.java:101)&lt;br/&gt;
   	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.cancel(FlinkKafkaConsumerBase.java:673)&lt;br/&gt;
   	at org.apache.flink.streaming.api.operators.StreamSource.cancel(StreamSource.java:108)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.cancelTask(SourceStreamTask.java:100)&lt;br/&gt;
   	at org.apache.flink.streaming.runtime.tasks.StreamTask.cancel(StreamTask.java:369)&lt;br/&gt;
   	at org.apache.flink.runtime.taskmanager.Task$TaskCanceler.run(Task.java:1481)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16714812" author="githubbot" created="Mon, 10 Dec 2018 14:47:52 +0000"  >&lt;p&gt;tillrohrmann commented on a change in pull request #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#discussion_r240235155&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#discussion_r240235155&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-connectors/flink-connector-kafka-0.8/src/main/java/org/apache/flink/streaming/connectors/kafka/internals/Kafka08PartitionDiscoverer.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -166,7 +166,7 @@ protected void wakeupConnections() {&lt;br/&gt;
 	}&lt;/p&gt;

&lt;p&gt; 	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;protected void closeConnections() throws Exception {&lt;br/&gt;
+	protected synchronized void closeConnections() throws Exception {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   Please revert&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16714813" author="githubbot" created="Mon, 10 Dec 2018 14:47:52 +0000"  >&lt;p&gt;tillrohrmann commented on a change in pull request #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#discussion_r240235652&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#discussion_r240235652&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -756,6 +756,20 @@ public void cancel() &lt;/p&gt;
{
 			// the discovery loop may currently be sleeping in-between
 			// consecutive discoveries; interrupt to shutdown faster
 			discoveryLoopThread.interrupt();
+		}
&lt;p&gt; else {&lt;br/&gt;
+			// when partition discovery is disabled,&lt;br/&gt;
+			// we should still call the close method.&lt;br/&gt;
+			// otherwise we may have connection leak,&lt;br/&gt;
+			// if open method throws an exception after partitionDiscoverer is constructed.&lt;br/&gt;
+			// In this case, run method won&apos;t be executed&lt;br/&gt;
+			// and partitionDiscoverer.close() won&apos;t be called.&lt;br/&gt;
+			if (partitionDiscoverer != null) {&lt;br/&gt;
+				try &lt;/p&gt;
{
+					partitionDiscoverer.close();
+				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
+					LOG.error(&quot;failed to close partitionDiscoverer&quot;, e);
+				}
&lt;p&gt;+			}&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   I think we should not close the `partitionDiscoverer` here. Instead we should close it in the `open` method if no longer needed and in the `run` method when leaving the `kafkaFetcher` thread.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16714814" author="githubbot" created="Mon, 10 Dec 2018 14:47:52 +0000"  >&lt;p&gt;tillrohrmann commented on a change in pull request #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#discussion_r240235183&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#discussion_r240235183&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-connectors/flink-connector-kafka-0.9/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/Kafka09PartitionDiscoverer.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -94,7 +94,7 @@ protected void wakeupConnections() {&lt;br/&gt;
 	}&lt;/p&gt;

&lt;p&gt; 	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;protected void closeConnections() throws Exception {&lt;br/&gt;
+	protected synchronized void closeConnections() throws Exception {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   Please revert&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16714817" author="githubbot" created="Mon, 10 Dec 2018 14:50:33 +0000"  >&lt;p&gt;tillrohrmann commented on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-445841775&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-445841775&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &amp;gt; @tillrohrmann&lt;br/&gt;
   &amp;gt; &lt;br/&gt;
   &amp;gt; &amp;gt; shouldn&apos;t we close the partitionDiscoverer in the open method in case of a failure. Moreover, we could also close it there in the case if automatic partition discovery is disabled.&lt;br/&gt;
   &amp;gt; &lt;br/&gt;
   &amp;gt; right now, the if-else check of partition discovery is done in `run` method to decide if we need to close the `partitionDiscoverer` before `runFetchLoop`. I didn&apos;t want to change that, unless we want to move the starting of `discoveryLoopThread` into open method as well. is that what you have in mind?&lt;br/&gt;
   &amp;gt; &lt;br/&gt;
   &amp;gt; I was thinking `cancel` method as the catch/finally block in Java. Plus it was the place where we close `partitionDiscoverer` for the enabled case. I though it might makes sense to ensure the cleanup in `cancel` method for both disabled and enabled cases&lt;br/&gt;
   &amp;gt; &lt;br/&gt;
   &amp;gt; &amp;gt; in line FlinkKafkaConsumerBase.java:721 fails with an exception?&lt;br/&gt;
   &amp;gt; &lt;br/&gt;
   &amp;gt; line 721 is for the partition discovery enabled case, `partitionDiscoverer` is closed in the `cancel` method in line 748&lt;/p&gt;

&lt;p&gt;   I don&apos;t think that we need to move the `discoveryLoopThread` creation into the `open` method. Maybe we should add an assertion that the `partitionDiscoverer` hasn&apos;t been closed yet when creating the `Thread`.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16716328" author="githubbot" created="Tue, 11 Dec 2018 06:21:37 +0000"  >&lt;p&gt;stevenzwu commented on issue #7020: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10774&quot; title=&quot;connection leak when partition discovery is disabled and open throws exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10774&quot;&gt;&lt;del&gt;FLINK-10774&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka&amp;#93;&lt;/span&gt; connection leak when partition discovery is disabled an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7020#issuecomment-446086480&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7020#issuecomment-446086480&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @tillrohrmann Thanks a lot for the feedbacks. I made the changes according to your comments. please take a look and see if I miss anything&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16757125" author="till.rohrmann" created="Thu, 31 Jan 2019 10:49:47 +0000"  >&lt;p&gt;Fixed via&lt;br/&gt;
1.8.0:&lt;br/&gt;
a9e18fa921&lt;br/&gt;
232560d0c9&lt;br/&gt;
83183ce4d9&lt;br/&gt;
3cbaabc527&lt;/p&gt;

&lt;p&gt;1.7.2:&lt;br/&gt;
af83b991f5&lt;br/&gt;
4789b3f768&lt;br/&gt;
198c4001fc&lt;br/&gt;
8012ab17bc&lt;/p&gt;

&lt;p&gt;1.6.4:&lt;br/&gt;
402f23507b&lt;br/&gt;
2a5d97d49e&lt;br/&gt;
c2150648de&lt;br/&gt;
1b9c464ab3&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                            <outwardlinks description="contains">
                                        <issuelink>
            <issuekey id="13195049">FLINK-10721</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 41 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s003sg:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>