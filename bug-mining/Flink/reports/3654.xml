<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:43:23 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-15355] Nightly streaming file sink fails with unshaded hadoop</title>
                <link>https://issues.apache.org/jira/browse/FLINK-15355</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: java.util.concurrent.ExecutionException: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
 at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:335)
 at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:205)
 at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:138)
 at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:664)
 at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:213)
 at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:895)
 at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:968)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)
 at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)
 at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:968)
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
 at org.apache.flink.util.ExceptionUtils.rethrow(ExceptionUtils.java:199)
 at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1751)
 at org.apache.flink.streaming.api.environment.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:94)
 at org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:63)
 at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1628)
 at StreamingFileSinkProgram.main(StreamingFileSinkProgram.java:77)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:321)
 ... 11 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
 at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
 at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1746)
 ... 20 more
Caused by: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
 at org.apache.flink.client.program.&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;.RestClusterClient.lambda$submitJob$7(RestClusterClient.java:326)
 at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:870)
 at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:852)
 at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
 at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977)
 at org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$8(FutureUtils.java:274)
 at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)
 at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)
 at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
 at java.util.concurrent.CompletableFuture.postFire(CompletableFuture.java:561)
 at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:929)
 at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: org.apache.flink.runtime.&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;.util.RestClientException: [Internal server error., &amp;lt;Exception on server side:
org.apache.flink.runtime.client.JobSubmissionException: Failed to submit job.
 at org.apache.flink.runtime.dispatcher.Dispatcher.lambda$internalSubmitJob$3(Dispatcher.java:336)
 at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:822)
 at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:797)
 at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)
 at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
 at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
 at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
 at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
 at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
 at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: org.apache.flink.runtime.client.JobExecutionException: Could not set up JobManager
 at org.apache.flink.util.function.CheckedSupplier.lambda$unchecked$0(CheckedSupplier.java:36)
 at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)
 ... 6 more
Caused by: org.apache.flink.runtime.client.JobExecutionException: Could not set up JobManager
 at org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl.&amp;lt;init&amp;gt;(JobManagerRunnerImpl.java:152)
 at org.apache.flink.runtime.dispatcher.DefaultJobManagerRunnerFactory.createJobManagerRunner(DefaultJobManagerRunnerFactory.java:84)
 at org.apache.flink.runtime.dispatcher.Dispatcher.lambda$createJobManagerRunner$6(Dispatcher.java:379)
 at org.apache.flink.util.function.CheckedSupplier.lambda$unchecked$0(CheckedSupplier.java:34)
 ... 7 more
Caused by: java.lang.NoSuchMethodError: org.apache.hadoop.conf.Configuration.getTimeDuration(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;;Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;;Ljava/util/concurrent/TimeUnit;)J
 at org.apache.hadoop.fs.s3a.S3ARetryPolicy.&amp;lt;init&amp;gt;(S3ARetryPolicy.java:113)
 at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:257)
 at org.apache.flink.fs.s3.common.AbstractS3FileSystemFactory.create(AbstractS3FileSystemFactory.java:126)
 at org.apache.flink.core.fs.PluginFileSystemFactory.create(PluginFileSystemFactory.java:61)
 at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:441)
 at org.apache.flink.core.fs.FileSystem.get(FileSystem.java:362)
 at org.apache.flink.core.fs.Path.getFileSystem(Path.java:298)
 at org.apache.flink.runtime.state.memory.MemoryBackendCheckpointStorage.&amp;lt;init&amp;gt;(MemoryBackendCheckpointStorage.java:85)
 at org.apache.flink.runtime.state.memory.MemoryStateBackend.createCheckpointStorage(MemoryStateBackend.java:295)
 at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.&amp;lt;init&amp;gt;(CheckpointCoordinator.java:279)
 at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.&amp;lt;init&amp;gt;(CheckpointCoordinator.java:205)
 at org.apache.flink.runtime.executiongraph.ExecutionGraph.enableCheckpointing(ExecutionGraph.java:486)
 at org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder.buildGraph(ExecutionGraphBuilder.java:338)
 at org.apache.flink.runtime.scheduler.SchedulerBase.createExecutionGraph(SchedulerBase.java:245)
 at org.apache.flink.runtime.scheduler.SchedulerBase.createAndRestoreExecutionGraph(SchedulerBase.java:217)
 at org.apache.flink.runtime.scheduler.SchedulerBase.&amp;lt;init&amp;gt;(SchedulerBase.java:205)
 at org.apache.flink.runtime.scheduler.DefaultScheduler.&amp;lt;init&amp;gt;(DefaultScheduler.java:119)
 at org.apache.flink.runtime.scheduler.DefaultSchedulerFactory.createInstance(DefaultSchedulerFactory.java:105)
 at org.apache.flink.runtime.jobmaster.JobMaster.createScheduler(JobMaster.java:278)
 at org.apache.flink.runtime.jobmaster.JobMaster.&amp;lt;init&amp;gt;(JobMaster.java:266)
 at org.apache.flink.runtime.jobmaster.factories.DefaultJobMasterServiceFactory.createJobMasterService(DefaultJobMasterServiceFactory.java:98)
 at org.apache.flink.runtime.jobmaster.factories.DefaultJobMasterServiceFactory.createJobMasterService(DefaultJobMasterServiceFactory.java:40)
 at org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl.&amp;lt;init&amp;gt;(JobManagerRunnerImpl.java:146)
 ... 10 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13275851">FLINK-15355</key>
            <summary>Nightly streaming file sink fails with unshaded hadoop</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="arvid">Arvid Heise</assignee>
                                    <reporter username="arvid">Arvid Heise</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Sat, 21 Dec 2019 07:16:02 +0000</created>
                <updated>Tue, 22 Jun 2021 14:07:18 +0000</updated>
                            <resolved>Tue, 21 Jan 2020 12:16:40 +0000</resolved>
                                    <version>1.10.0</version>
                    <version>1.11.0</version>
                                    <fixVersion>1.10.0</fixVersion>
                                    <component>FileSystems</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="8400">2h 20m</timespent>
                                <comments>
                            <comment id="17001629" author="arvid" created="Sat, 21 Dec 2019 07:20:28 +0000"  >&lt;p&gt;Most likely the Hadoop `Configuration` from flink-fs-hadoop-shaded has already been loaded, such that it&apos;s not loaded through child class loader.&lt;/p&gt;

&lt;p&gt;A quick-fix could be to relocate everything in the hadoop-s3 and presto-s3 that is also contained in flink-fs-hadoop-shaded (3 files at the time of writing).&lt;/p&gt;

&lt;p&gt;Long-term solution is to get rid of flink-fs-hadoop-shaded entirely and in particular moving it out of flink-dist (which is currently not feasible because of mapr).&lt;/p&gt;</comment>
                            <comment id="17001932" author="arvid" created="Sun, 22 Dec 2019 13:36:52 +0000"  >&lt;p&gt;Initial suspicion could not be verified: `Configuration` from flink-fs-hadoop-shaded has this method. So somehow another Configuration is coming into flink-dist or hadoop-s3.&lt;/p&gt;</comment>
                            <comment id="17002112" author="carp84" created="Mon, 23 Dec 2019 05:59:41 +0000"  >&lt;p&gt;Another 2 instances:&lt;br/&gt;
&lt;a href=&quot;https://api.travis-ci.org/v3/job/628137535/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/628137535/log.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://api.travis-ci.org/v3/job/628412438/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/628412438/log.txt&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17002703" author="banmoy" created="Tue, 24 Dec 2019 07:32:43 +0000"  >&lt;p&gt;This test begins to fail after&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-11956&quot; title=&quot;Remove shading from S3 filesystems build&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-11956&quot;&gt;&lt;del&gt;FLINK-11956&lt;/del&gt;&lt;/a&gt; with commit&#160;8ec545d56f007645ca8f2a2374386882132ffc7a.&#160;The name of this test is &quot;e2e - misc - hadoop 2.8&quot; whose profile contains &quot;-Dinclude-hadoop -Dhadoop.version=2.8.3&quot;, and flink-shaded-hadoop-2-uber-2.8.3-9.0.jar will be put into lib directory.&#160; After enable jvm option &quot;-verbose:class&quot; in jobmanager.sh, we can find that &quot;org.apache.hadoop.conf.Configuration&quot; is loaded from&#160;flink-shaded-hadoop-2-uber-2.8.3-9.0.jar rather than hadoop-s3.&#160;&quot;Configuration#getTimeDuration(String name, String defaultValue, TimeUnit unit)&quot; only exists in hadoop-3.1.0 which hadoop-s3 depends on, so NoSuchMethodError is throwed. &#160;&#160;&lt;/p&gt;</comment>
                            <comment id="17002723" author="banmoy" created="Tue, 24 Dec 2019 08:36:58 +0000"  >&lt;p&gt;The root cause is that default value of&#160;&quot;classloader.parent-first-patterns.default&quot; contains &quot;org.apache.hadoop.&quot;, and parent class loader includes hadoop, so&#160;ChildFirstClassLoader will not load Configuration from plugin jar. Actually if job runs on yarn cluster with no bundled hadoop, there may be also conflict between hadoop-s3 and yarn.&#160;My colleagues and I make some discussions about the solutions&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;remove&#160;&quot;org.apache.hadoop.&quot; from&#160;parent-first-patterns globally, but it can change other component&apos;s behavior, and need to be cautious.&lt;/li&gt;
	&lt;li&gt;provide a plugin-level option for&#160;parent-first-patterns, and each plugin can decide what dependency to inherit from parent class loader.&#160;&lt;/li&gt;
	&lt;li&gt;make hadoop used by Flink pluggable, and parent class loader will not contain hadoop. It maybe a long term goal.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;At the moment, solution 2 may be a better choice. What do you think? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arvid+heise&quot; class=&quot;user-hover&quot; rel=&quot;arvid heise&quot;&gt;arvid heise&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pnowojski&quot; class=&quot;user-hover&quot; rel=&quot;pnowojski&quot;&gt;pnowojski&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17002969" author="carp84" created="Tue, 24 Dec 2019 19:07:37 +0000"  >&lt;p&gt;Does it make sense if we revert &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-11956&quot; title=&quot;Remove shading from S3 filesystems build&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-11956&quot;&gt;&lt;del&gt;FLINK-11956&lt;/del&gt;&lt;/a&gt; and retarget it at 1.11.0 since it introduces some problem that a quick fix cannot resolve but requires long term solution with quite some impact, especially at this phase of the release? What&apos;s your opinion &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maguowei&quot; class=&quot;user-hover&quot; rel=&quot;maguowei&quot;&gt;maguowei&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjwang&quot; class=&quot;user-hover&quot; rel=&quot;zjwang&quot;&gt;zjwang&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt;? Thanks.&lt;/p&gt;</comment>
                            <comment id="17002988" author="arvid" created="Tue, 24 Dec 2019 20:37:18 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=banmoy&quot; class=&quot;user-hover&quot; rel=&quot;banmoy&quot;&gt;banmoy&lt;/a&gt; , thank you for the throughout investigation. Your provided options are plausible, but it&apos;s hard for me to decide which way to go.&lt;/p&gt;

&lt;p&gt;I drafted a 4. option as a PR that is inspired by your 1. and 2. options: remove parent-first-patterns from plugins altogether. I can see it being super useful in user code, especially for the often happening shading of flink jars inside the user code, but I currently don&apos;t see why it&apos;s necessary in the plugins that we provide. If that doesn&apos;t work out, option 2 should be best choice, albeit more complex.&lt;/p&gt;

&lt;p&gt;I added all e2e tests to the normal execution of said PR to hopefully gain some insides. &lt;a href=&quot;https://github.com/apache/flink/pull/10678&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/10678&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liyu&quot; class=&quot;user-hover&quot; rel=&quot;liyu&quot;&gt;liyu&lt;/a&gt;, reverting &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-11956&quot; title=&quot;Remove shading from S3 filesystems build&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-11956&quot;&gt;&lt;del&gt;FLINK-11956&lt;/del&gt;&lt;/a&gt; would certainly be an option. Removing the shading was pushed by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt; to avoid a whole lot of other issues with the current shaded plugins (namely the inability to use credential providers from AWS sufficiently, see &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-15215&quot; title=&quot;Not able to provide a custom AWS credentials provider with flink-s3-fs-hadoop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-15215&quot;&gt;&lt;del&gt;FLINK-15215&lt;/del&gt;&lt;/a&gt;). Before reverting, I&apos;d definitively consult him as well.&lt;/p&gt;</comment>
                            <comment id="17003051" author="fly_in_gis" created="Wed, 25 Dec 2019 02:45:10 +0000"  >&lt;p&gt;I think removing &lt;tt&gt;alwaysParentFirstPatterns&lt;/tt&gt; in plugin&#160;mechanism is a valid fix. Since we will&#160;delegate the always-parent-first-pattern configuration to each plugin implementation. Every plugin could decide which packages need to always load from parent. We need to create a new ticket to track this. However, it is not a blocker. Users could exclude these parent-first packages from the plugin jar to work around.&lt;/p&gt;</comment>
                            <comment id="17003482" author="carp84" created="Thu, 26 Dec 2019 06:18:12 +0000"  >&lt;p&gt;Another instance: &lt;a href=&quot;https://api.travis-ci.org/v3/job/629426131/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/629426131/log.txt&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17003484" author="carp84" created="Thu, 26 Dec 2019 06:21:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arvid+heise&quot; class=&quot;user-hover&quot; rel=&quot;arvid heise&quot;&gt;arvid heise&lt;/a&gt; thanks for the clarification and good to know the context. I&apos;m watching this issue since it&apos;s failing the release-1.10 nightly build stably, and hopefully we could figure out a way to unblock it quickly (but of course no rush or hack and finally resolve it through a thorough solution). Thanks.&lt;/p&gt;</comment>
                            <comment id="17003548" author="carp84" created="Thu, 26 Dec 2019 09:43:08 +0000"  >&lt;p&gt;Planning to temporarily disable the &quot;Streaming File Sink s3 end-to-end test&quot; until the issue here is fixed to unblock nightly build, FYI.&lt;/p&gt;</comment>
                            <comment id="17003608" author="carp84" created="Thu, 26 Dec 2019 12:08:00 +0000"  >&lt;p&gt;Temporarily disabled &quot;Streaming File Sink s3 end-to-end test&quot; in release-1.10 via: de45fdbb59&lt;/p&gt;</comment>
                            <comment id="17003658" author="arvid" created="Thu, 26 Dec 2019 14:17:59 +0000"  >&lt;p&gt;I reran &lt;a href=&quot;https://github.com/apache/flink/pull/10678&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/10678&lt;/a&gt; three times and haven&apos;t observed the issues anymore. However, none of the builds succeeded for other known e2e bugs.&lt;/p&gt;</comment>
                            <comment id="17004140" author="carp84" created="Fri, 27 Dec 2019 11:56:13 +0000"  >&lt;p&gt;True, 3 more e2e blocker issues emerge after disable the test here...: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-15426&quot; title=&quot;TPC-DS end-to-end test (Blink planner) fails on travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-15426&quot;&gt;&lt;del&gt;FLINK-15426&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-15427&quot; title=&quot;State TTL RocksDb backend end-to-end test stalls on travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-15427&quot;&gt;&lt;del&gt;FLINK-15427&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-15428&quot; title=&quot;Avro Confluent Schema Registry nightly end-to-end test fails on travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-15428&quot;&gt;&lt;del&gt;FLINK-15428&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17005159" author="carp84" created="Mon, 30 Dec 2019 06:44:49 +0000"  >&lt;p&gt;&apos;Shaded Hadoop S3A with credentials provider end-to-end test&apos; failed with the same issue, need to disable more tests to prevent the impact:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://api.travis-ci.org/v3/job/630372569/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/630372569/log.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://api.travis-ci.org/v3/job/630652293/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/630652293/log.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://api.travis-ci.org/v3/job/630652300/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/630652300/log.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Update: temporarily disabled &quot;Shaded Hadoop S3A with credentials provider&quot; in release-1.10 via 7e2690489d&lt;/p&gt;</comment>
                            <comment id="17006836" author="pnowojski" created="Thu, 2 Jan 2020 14:30:31 +0000"  >&lt;p&gt;Adapting &lt;a href=&quot;https://github.com/apache/flink/pull/10678#pullrequestreview-336577210&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;my comment from the pull request&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I would be against 4th option proposed by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arvid+heise&quot; class=&quot;user-hover&quot; rel=&quot;arvid heise&quot;&gt;arvid heise&lt;/a&gt;. I think it&#8217;s really important to all SPI classes be parent loaded first, otherwise very bad things can happen. For example if user accidentally embeds a different version (1.9.2 vs 1.9.1) of org.apache.flink classes. How I understand the issue:&lt;/p&gt;

&lt;p&gt;If you have a SPI class (like Foo), if you implement it&apos;s method (like Bar Foo#bar() { return new Bar(); }), it&apos;s important that every object/class that crosses the boundary between plugin&apos;s implementation and the core system (like Bar) must originate from the core&apos;s system class loader. If not, if they are incompatible, you risk all kind of the dependency convergence errors (deadlocks, livelocks, method not found) if the versions of Bar are not binary compatible. Additionally if this Bar is passed around, it can crash at any place/point of time, very far away from the place it was created. Also using older plugin versions can just result in having an unfixed bugs, for example if Bar in 1.9.2 has some bug fixed.&lt;/p&gt;

&lt;p&gt;Disclaimer: I don&apos;t have that much of an experience with class loading in Java and especially loading user classes, however all of the systems that I have seen, that were doing similar things (loading user classes, especially in a separate class loader), strongly emphasise &quot;parent first&quot; pattern for all of the dependencies that are on the boundary of the SPI.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/prestodb/presto/blob/master/presto-main/src/main/java/com/facebook/presto/server/PluginClassLoader.java#L41&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/prestodb/presto/blob/master/presto-main/src/main/java/com/facebook/presto/server/PluginClassLoader.java#L41&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/nifi/blob/master/nifi-nar-bundles/nifi-framework-bundle/nifi-framework/nifi-nar-utils/src/main/java/org/apache/nifi/nar/NarClassLoader.java#L42&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/nifi/blob/master/nifi-nar-bundles/nifi-framework-bundle/nifi-framework/nifi-nar-utils/src/main/java/org/apache/nifi/nar/NarClassLoader.java#L42&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I would be more inclined towards something like &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=banmoy&quot; class=&quot;user-hover&quot; rel=&quot;banmoy&quot;&gt;banmoy&lt;/a&gt;&apos;s option 1. or 2.&lt;/p&gt;

&lt;p&gt;However probably we can choose 1. for the sake of backward compatibility with non plugin based class loading (&lt;tt&gt;classloader.parent-first-patterns.default&lt;/tt&gt; is used in more places, not only in plugins). &lt;/p&gt;

&lt;p&gt;&lt;b&gt;What is the reason, why &lt;tt&gt;org.apache.hadoop&lt;/tt&gt; is added to this list in the first place?&lt;/b&gt; For plugins I think we should be able to drop it. Unless I&apos;m missing something, I do not see a reason why &lt;tt&gt;org.apache.hadoop&lt;/tt&gt; should be loaded parent first for any plugin - that would kind of defeat the purpose of any plugin using hadoop. As I wrote above, for Plugins, only SPI classes should be parent first loaded and &lt;tt&gt;org.apache.hadoop&lt;/tt&gt; should never be a part of any SPI that we expose (unless I&apos;m missing something...). &lt;/p&gt;

&lt;p&gt;If I&apos;m not missing anything, I would vote for duplicating &lt;tt&gt;classloader.parent-first-patterns.additional&lt;/tt&gt; and &lt;tt&gt;classloader.parent-first-patterns.default&lt;/tt&gt; to something like &lt;tt&gt;classloader.plugin-parent-first-patterns.*&lt;/tt&gt; and dropping maybe not only &lt;tt&gt;org.apache.hadoop&lt;/tt&gt;, but maybe almost everything from there.&lt;/p&gt;</comment>
                            <comment id="17008608" author="arvid" created="Mon, 6 Jan 2020 08:05:59 +0000"  >&lt;p&gt;Like I said before, option 4 assumes that no one bundles Flink classes into plugins. If we cannot guarantee that, it&apos;s not valid.&lt;/p&gt;

&lt;p&gt;What I&apos;d like to avoid is to have some magic list of patterns to avoid exactly these questions &quot;&lt;b&gt;why &lt;tt&gt;org.apache.hadoop&lt;/tt&gt; is added to this list in the first place&lt;/b&gt;&quot;.&lt;/p&gt;</comment>
                            <comment id="17008610" author="arvid" created="Mon, 6 Jan 2020 08:17:15 +0000"  >&lt;p&gt;Btw concerning why &lt;b&gt;&lt;tt&gt;org.apache.hadoop&lt;/tt&gt;&lt;/b&gt; is in the list: my guess is that the main reason is that we provide exactly some overridden implementation of Hadoop configuration etc. where parent first is absolutely necessary to properly support relocations.&lt;/p&gt;

&lt;p&gt;Now, we could argue that this becomes unnecessary when we remove the relocations from plugins. However, so far we have only removed it partly (s3 plugins) and not for all. Thus, we must support such a parent-first list for some plugins and adjust it for others.&lt;/p&gt;

&lt;p&gt;I&apos;d propose a fifth option which expands on the option 2 of &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=banmoy&quot; class=&quot;user-hover&quot; rel=&quot;banmoy&quot;&gt;banmoy&lt;/a&gt; . Allow plugins to specify a custom list (code is mostly there already). If such a custom list is supplied, it completely replaces Flink&apos;s default list. If no custom list is supplied, we fall back to Flink&apos;s default list.&lt;/p&gt;</comment>
                            <comment id="17008886" author="zentol" created="Mon, 6 Jan 2020 14:08:16 +0000"  >&lt;p&gt;Hadoop is in that list because some users ran into ClassCastException when using Hadoop and having Hadoop classes bundled in their jar. Source: &lt;a href=&quot;https://github.com/apache/flink/pull/5313&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5313&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17010505" author="pnowojski" created="Wed, 8 Jan 2020 09:23:50 +0000"  >&lt;p&gt;We have introduced a separate config options for parent first pattern in plugins.&lt;/p&gt;

&lt;p&gt;Merged to master as d46b07bc6ef44dde058f4a15710938d29cdc1798&lt;br/&gt;
Merged to release-1.10 as 4c7562bf84c865859710dc79f05ae09541fa3335..14c26e489d1e8f7ae02080b3b69810b59e3ebe32&lt;/p&gt;</comment>
                            <comment id="17011490" author="carp84" created="Thu, 9 Jan 2020 06:52:35 +0000"  >&lt;p&gt;Reopen since the same issue reoccurred in the latest release-1.10 nightly build: &lt;a href=&quot;https://api.travis-ci.org/v3/job/634330760/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/634330760/log.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SHA of the build is f1ee817 thus 4c7562b is already included: &lt;a href=&quot;https://travis-ci.org/apache/flink/builds/634330720&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://travis-ci.org/apache/flink/builds/634330720&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17011516" author="carp84" created="Thu, 9 Jan 2020 07:43:30 +0000"  >&lt;p&gt;Checked the travis run of &lt;a href=&quot;https://github.com/apache/flink/pull/10778&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PR#10778&lt;/a&gt; and confirmed it didn&apos;t really run the e2e case and gave a misleading result...&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;==============================================================================
Running &apos;Streaming File Sink s3 end-to-end test&apos;
==============================================================================
TEST_DATA_DIR: /home/travis/build/flink-ci/flink/flink-end-to-end-tests/test-scripts/temp-test-directory-51024728284
Flink dist directory: /home/travis/build/flink-ci/flink/flink-dist/target/flink-1.10-SNAPSHOT-bin/flink-1.10-SNAPSHOT
Did not find AWS environment variables, NOT running the e2e test.
Checking of logs skipped.

[PASS] &apos;Streaming File Sink s3 end-to-end test&apos; passed after 0 minutes and 0 seconds! Test exited with exit code 0.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://api.travis-ci.com/v3/job/272987373/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.com/v3/job/272987373/log.txt&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17011683" author="zentol" created="Thu, 9 Jan 2020 10:36:49 +0000"  >&lt;p&gt;In &lt;tt&gt;FileSystem#getUnguardedFileSystem&lt;/tt&gt; we use the classloader returned by the factory when calling &lt;tt&gt;FileSystem#create:&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
   &lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt; classLoader = factory.getClassLoader();
   &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; (TemporaryClassLoaderContext classLoaderContext = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TemporaryClassLoaderContext(classLoader)) {
      fs = factory.create(uri);
   }

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Supposedly this is the plugin classloader, but since the factory package is &lt;tt&gt;org.apache.flink...&lt;/tt&gt;, isn&apos;t it loaded by the ParentClassLoader?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17012387" author="zjwang" created="Fri, 10 Jan 2020 01:58:06 +0000"  >&lt;p&gt;Merged in release-1.10:&#160;aa37c0cd89053e68e72a19d51715b3a31b74163c&lt;/p&gt;

&lt;p&gt;Merged in master:&#160;f7833aff7d50af5a3a3a671d9b6a44bd5dc17a67&lt;/p&gt;</comment>
                            <comment id="17013677" author="carp84" created="Sun, 12 Jan 2020 08:35:52 +0000"  >&lt;p&gt;&apos;Shaded Hadoop S3A with credentials provider end-to-end test&apos; still fails in latest release-1.10 nightly builds, with below warning:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2020-01-12 01:32:13,095 WARN  org.apache.hadoop.fs.FileSystem                               - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.DistributedFileSystem not a subtype
2020-01-12 01:32:13,096 WARN  org.apache.hadoop.fs.FileSystem                               - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.WebHdfsFileSystem not a subtype
2020-01-12 01:32:13,097 WARN  org.apache.hadoop.fs.FileSystem                               - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.SWebHdfsFileSystem not a subtype
2020-01-12 01:32:13,097 WARN  org.apache.hadoop.fs.FileSystem                               - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HftpFileSystem not a subtype
2020-01-12 01:32:13,098 WARN  org.apache.hadoop.fs.FileSystem                               - Cannot load filesystem: java.util.ServiceConfigurationError: org.apache.hadoop.fs.FileSystem: Provider org.apache.hadoop.hdfs.web.HsftpFileSystem not a subtype
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://api.travis-ci.org/v3/job/635358189/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/635358189/log.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://api.travis-ci.org/v3/job/635722691/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/635722691/log.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It seems to me the root cause is still relative to the issue here, but please correct me if I&apos;m wrong and feel free to close this one and open another issue to track the new problem (if it&apos;s new). Thanks.&lt;/p&gt;</comment>
                            <comment id="17014209" author="till.rohrmann" created="Mon, 13 Jan 2020 10:39:54 +0000"  >&lt;p&gt;Another instance of the problem: &lt;a href=&quot;https://api.travis-ci.org/v3/job/635957245/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/635957245/log.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Full build matrix: &lt;a href=&quot;https://travis-ci.org/apache/flink/builds/635957218&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://travis-ci.org/apache/flink/builds/635957218&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17014442" author="arvid" created="Mon, 13 Jan 2020 16:15:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liyu&quot; class=&quot;user-hover&quot; rel=&quot;liyu&quot;&gt;liyu&lt;/a&gt;, you are right this issue is related to the unshading. Analysis of the issue:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In the system classloader, there is flink-dist and hadoop-uber.&lt;/li&gt;
	&lt;li&gt;The plugin classloader contains our s3 filesystem and the s3 hadoop implementation.&lt;/li&gt;
	&lt;li&gt;During initialization, the s3 hadoop implementation uses the `ServiceLoader` to load all hadoop FileSystems.&lt;/li&gt;
	&lt;li&gt;Classloader finds not only the expected service definitions but also those of hadoop-uber.&lt;/li&gt;
	&lt;li&gt;`ServiceLoader` tries to load all file systems but ofc cannot load those of hadoop-uber because of inconsistent class hierarchies (mixed plugin and system classloader)&lt;/li&gt;
	&lt;li&gt;`ServiceLoader` issues warning that trigger the `check_error` script to fail.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Firstly, I verified if this is a fundamental issue in the interplay of plugins and libraries or a cosmetic. I successfully mixed plugins and libraries by reading from a local HDFS and writing to S3 minio and vice versa.&lt;/p&gt;

&lt;p&gt;I implemented a solution &lt;a href=&quot;https://github.com/apache/flink/pull/10845&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/10845&lt;/a&gt; that limits the scope of services to plugins from the plugin perspective. That gives the desired isolation but may require users to add more jars to the plugin folder in the worst case (security provider?). On the other hand, that use case would allow users to use different versions of security providers for different plugins.&lt;/p&gt;

&lt;p&gt;We also need to investigate if the sketchy reinitialization of `FileSystem`s in `BucketingSink` is working with plugins.&lt;/p&gt;</comment>
                            <comment id="17016837" author="pnowojski" created="Thu, 16 Jan 2020 11:56:02 +0000"  >&lt;p&gt;Yet another fix merged:&lt;br/&gt;
merged commit d96456ebe32ebcf41a6bbf5dfaa76a4f4a8a1edb into apache:release-1.10&lt;br/&gt;
merged commit f2b6da5780742db82b428c9dbeabe02e3b080c48 into master&lt;/p&gt;</comment>
                            <comment id="17017877" author="arvid" created="Fri, 17 Jan 2020 10:15:49 +0000"  >&lt;p&gt;Current PluginClassLoader fails to load module classes in Java 9+.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: java.lang.ClassNotFoundException: org.ietf.jgss.GSSException
 at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:471)
 at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:588)
 at org.apache.flink.core.plugin.PluginLoader$PluginClassLoader.loadClass(PluginLoader.java:147)
 at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)
 ... 34 more&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17020024" author="carp84" created="Tue, 21 Jan 2020 08:14:00 +0000"  >&lt;p&gt;More instances in latest release-1.10 nightly build complaining &lt;tt&gt;GSSException&lt;/tt&gt; class not found:&lt;br/&gt;
&lt;a href=&quot;https://api.travis-ci.org/v3/job/639573115/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/639573115/log.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://api.travis-ci.org/v3/job/639573142/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/639573142/log.txt&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17020177" author="pnowojski" created="Tue, 21 Jan 2020 12:16:40 +0000"  >&lt;p&gt;Merged to release-1.10 as 2035b2ba3fc9cf39feeaa2427d10807527d8be20^..2035b2ba3fc9cf39feeaa2427d10807527d8be20&lt;br/&gt;
Merged to master as 9af50565fa4bfc676a6fb2d9d0ff2aec23779fe4^..9af50565fa4bfc676a6fb2d9d0ff2aec23779fe4&lt;/p&gt;

&lt;p&gt;Please do not re-open this issue unless the problem is exactly the same as before (the same exception, the same cause etc...), but create a new issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13278701">FLINK-15551</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13222287">FLINK-11956</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 43 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3jpe5:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>