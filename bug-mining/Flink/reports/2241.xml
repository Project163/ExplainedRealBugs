<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:32:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-8735] Add savepoint migration ITCase that covers operator state</title>
                <link>https://issues.apache.org/jira/browse/FLINK-8735</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The current &lt;tt&gt;StatefulJobSavepointMigrationITCase&lt;/tt&gt; does not cover operator state, meaning state accessed using &lt;tt&gt;OperatorStateStore&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13139946">FLINK-8735</key>
            <summary>Add savepoint migration ITCase that covers operator state</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="aljoscha">Aljoscha Krettek</assignee>
                                    <reporter username="aljoscha">Aljoscha Krettek</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Feb 2018 17:06:50 +0000</created>
                <updated>Thu, 22 Feb 2018 14:39:35 +0000</updated>
                            <resolved>Thu, 22 Feb 2018 14:39:35 +0000</resolved>
                                    <version>1.4.0</version>
                    <version>1.5.0</version>
                                    <fixVersion>1.4.2</fixVersion>
                    <fixVersion>1.5.0</fixVersion>
                                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16371795" author="githubbot" created="Wed, 21 Feb 2018 18:18:04 +0000"  >&lt;p&gt;GitHub user aljoscha opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;     &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8735&quot; title=&quot;Add savepoint migration ITCase that covers operator state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8735&quot;&gt;&lt;del&gt;FLINK-8735&lt;/del&gt;&lt;/a&gt; Add new StatefulJobSavepointMigrationITCase&lt;/p&gt;

&lt;p&gt;    R: @kl0u, and this is also relevant for your related PR that adds support for broadcast state. I think you would have to build on this new one and add broadcast state there. &#128563; &lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/aljoscha/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/aljoscha/flink&lt;/a&gt; jira-8735-new-savepoint-migration-test&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #5552&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 13c7fcc16c78f15abe11dfa4a0dbe91e7a96b3d8&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-21T17:08:13Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8735&quot; title=&quot;Add savepoint migration ITCase that covers operator state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8735&quot;&gt;&lt;del&gt;FLINK-8735&lt;/del&gt;&lt;/a&gt; Rename StatefulJobSavepointMigrationITCase&lt;/p&gt;

&lt;p&gt;    This is preparation for modifying a new ITCase to use modern state&lt;br/&gt;
    features.&lt;/p&gt;

&lt;p&gt;commit 5792c207f427f62aad9f26dd08112a676aab614b&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-21T17:10:55Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8735&quot; title=&quot;Add savepoint migration ITCase that covers operator state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8735&quot;&gt;&lt;del&gt;FLINK-8735&lt;/del&gt;&lt;/a&gt; Add new StatefulJobSavepointMigrationITCase&lt;/p&gt;

&lt;p&gt;    This new test does not pretend to use legacy state but now instead uses&lt;br/&gt;
    the more modern operator state varieties.&lt;/p&gt;

&lt;p&gt;    The binary savepoints for this were generated on the release-1.4 branch.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16371796" author="githubbot" created="Wed, 21 Feb 2018 18:18:34 +0000"  >&lt;p&gt;GitHub user aljoscha opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5553&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5553&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;     &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8735&quot; title=&quot;Add savepoint migration ITCase that covers operator state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8735&quot;&gt;&lt;del&gt;FLINK-8735&lt;/del&gt;&lt;/a&gt; Add new StatefulJobSavepointMigrationITCase (release-1.4)&lt;/p&gt;

&lt;p&gt;    Sister PR to #5552 for the release-1.4 branch.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/aljoscha/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/aljoscha/flink&lt;/a&gt; jira-8735-new-savepoint-migration-test-release-14&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5553.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5553.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #5553&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 82e6f8d5b8623f97f854ae9936e6754dc09ef5af&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-21T17:08:13Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8735&quot; title=&quot;Add savepoint migration ITCase that covers operator state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8735&quot;&gt;&lt;del&gt;FLINK-8735&lt;/del&gt;&lt;/a&gt; Rename StatefulJobSavepointMigrationITCase&lt;/p&gt;

&lt;p&gt;    This is preparation for modifying a new ITCase to use modern state&lt;br/&gt;
    features.&lt;/p&gt;

&lt;p&gt;commit bc848e43f8f6c041161d787da1c3131e4365b4c6&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-21T17:10:55Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8735&quot; title=&quot;Add savepoint migration ITCase that covers operator state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8735&quot;&gt;&lt;del&gt;FLINK-8735&lt;/del&gt;&lt;/a&gt; Add new StatefulJobSavepointMigrationITCase&lt;/p&gt;

&lt;p&gt;    This new test does not pretend to use legacy state but now instead uses&lt;br/&gt;
    the more modern operator state varieties.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16371797" author="githubbot" created="Wed, 21 Feb 2018 18:18:53 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    The sister PR for `release-1.4` is #5553 .&lt;/p&gt;</comment>
                            <comment id="16371842" author="githubbot" created="Wed, 21 Feb 2018 18:44:13 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169738273&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169738273&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/LegacyStatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,663 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.TimestampedCollector;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class LegacyStatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_2, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_2, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_3, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_3, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.3 with RocksDB,&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    remove TODO i guess?&lt;/p&gt;</comment>
                            <comment id="16371843" author="githubbot" created="Wed, 21 Feb 2018 18:44:13 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169734512&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169734512&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    that&apos;s a lot of TODOs in one comment.&lt;/p&gt;</comment>
                            <comment id="16371865" author="githubbot" created="Wed, 21 Feb 2018 19:05:38 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169740338&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169740338&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    reverse static and final?&lt;/p&gt;</comment>
                            <comment id="16371866" author="githubbot" created="Wed, 21 Feb 2018 19:05:38 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169741935&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169741935&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) {
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			} else {
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = {
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; };&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +					unionListState.add(s);
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getUnionListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}&lt;br/&gt;
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {    +				Thread.sleep(20);    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringParallelSourceWithUnionListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {    +    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getUnionListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(CheckpointedParallelSourceWithUnionListState.checkpointedStrings));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) &lt;/p&gt;
{
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}
&lt;p&gt;    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class KeyedStateSettingFlatMap extends RichFlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void flatMap(Tuple2&amp;lt;Long, Long&amp;gt; value, Collector&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; out) throws Exception &lt;/p&gt;
{
    +			out.collect(value);
    +
    +			getRuntimeContext().getState(stateDescriptor).update(value.f1);
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingKeyedStateFlatMap extends RichFlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingKeyedStateFlatMap.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void open(Configuration parameters) throws Exception &lt;/p&gt;
{
    +			super.open(parameters);
    +
    +			getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void flatMap(Tuple2&amp;lt;Long, Long&amp;gt; value, Collector&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; out) throws Exception {&lt;br/&gt;
    +			out.collect(value);&lt;br/&gt;
    +&lt;br/&gt;
    +			ValueState&amp;lt;Long&amp;gt; state = getRuntimeContext().getState(stateDescriptor);&lt;br/&gt;
    +			if (state == null) &lt;/p&gt;
{
    +				throw new RuntimeException(&quot;Missing key value state for &quot; + value);
    +			}
&lt;p&gt;    +&lt;br/&gt;
    +			assertEquals(value.f1, state.value());&lt;br/&gt;
    +			getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);&lt;br/&gt;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class TimelyStatefulOperator&lt;br/&gt;
    +		extends AbstractStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;&lt;br/&gt;
    +		implements OneInputStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, Triggerable&amp;lt;Long, Long&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient InternalTimerService&amp;lt;Long&amp;gt; timerService;&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void open() throws Exception &lt;/p&gt;
{
    +			super.open();
    +
    +			timerService = getInternalTimerService(
    +				&quot;timer&quot;,
    +				LongSerializer.INSTANCE,
    +				this);
    +
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void processElement(StreamRecord&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; element) throws Exception &lt;/p&gt;
{
    +			ValueState&amp;lt;Long&amp;gt; state = getKeyedStateBackend().getPartitionedState(
    +				element.getValue().f0,
    +				LongSerializer.INSTANCE,
    +				stateDescriptor);
    +
    +			state.update(element.getValue().f1);
    +
    +			timerService.registerEventTimeTimer(element.getValue().f0, timerService.currentWatermark() + 10);
    +			timerService.registerProcessingTimeTimer(element.getValue().f0, timerService.currentProcessingTime() + 30_000);
    +
    +			output.collect(element);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void onEventTime(InternalTimer&amp;lt;Long, Long&amp;gt; timer) throws Exception &lt;/p&gt;
{
    +
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void onProcessingTime(InternalTimer&amp;lt;Long, Long&amp;gt; timer) throws Exception {    +    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void processWatermark(Watermark mark) throws Exception &lt;/p&gt;
{
    +			output.emitWatermark(mark);
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingTimelyStatefulOperator&lt;br/&gt;
    +		extends AbstractStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;&lt;br/&gt;
    +		implements OneInputStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, Triggerable&amp;lt;Long, Long&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR = CheckingTimelyStatefulOperator.class + &quot;_PROCESS_CHECKS&quot;;&lt;br/&gt;
    +		public static final String SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR = CheckingTimelyStatefulOperator.class + &quot;_ET_CHECKS&quot;;&lt;br/&gt;
    +		public static final String SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR = CheckingTimelyStatefulOperator.class + &quot;_PT_CHECKS&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient InternalTimerService&amp;lt;Long&amp;gt; timerService;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    unused&lt;/p&gt;</comment>
                            <comment id="16371867" author="githubbot" created="Wed, 21 Feb 2018 19:05:38 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169741385&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169741385&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) {
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			} else {
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = {
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; };&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +					unionListState.add(s);
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getUnionListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}&lt;br/&gt;
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {    +				Thread.sleep(20);    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringParallelSourceWithUnionListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {    +    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getUnionListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(CheckpointedParallelSourceWithUnionListState.checkpointedStrings));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) &lt;/p&gt;
{
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}
&lt;p&gt;    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class KeyedStateSettingFlatMap extends RichFlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    the class naming scheme is inconsistent. The checkers have &quot;Checking&quot; as a prefix, while the setters have &quot;Setting&quot; as an infix.&lt;/p&gt;</comment>
                            <comment id="16371868" author="githubbot" created="Wed, 21 Feb 2018 19:05:38 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169742676&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169742676&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) &lt;/p&gt;
{
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = &lt;/p&gt;
{
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; }
&lt;p&gt;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) &lt;/p&gt;
{
    +					unionListState.add(s);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception &lt;/p&gt;
{
    +			unionListState = context.getOperatorStateStore().getUnionListState(
    +				stateDescriptor);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    you could remove the module operation by initializing i with `getRuntimeContext().getIndexOfThisSubtask()` and incrementing it by `getRuntimeContext().getNumberOfParallelSubtasks()`.&lt;/p&gt;

&lt;p&gt;    Not sure which one is easier to understand.&lt;/p&gt;</comment>
                            <comment id="16371869" author="githubbot" created="Wed, 21 Feb 2018 19:05:38 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169743891&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169743891&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) &lt;/p&gt;
{
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = &lt;/p&gt;
{
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; }
&lt;p&gt;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    could replace the conditional block with `unionListState.add(checkpointedStrings&lt;span class=&quot;error&quot;&gt;&amp;#91;getRuntimeContext().getIndexOfThisSubtask()&amp;#93;&lt;/span&gt;`.&lt;/p&gt;

&lt;p&gt;    This would make the behavior of each subtask obvious from the code.&lt;/p&gt;</comment>
                            <comment id="16371876" author="githubbot" created="Wed, 21 Feb 2018 19:09:15 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169745602&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169745602&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/LegacyStatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,663 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.TimestampedCollector;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class LegacyStatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_2, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_2, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_3, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_3, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.3 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_3, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public LegacyStatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    We could unify these methods.&lt;/p&gt;

&lt;p&gt;    Hide all function constructors behind a factory that accepts an enum `ExecutionMode(CREATE/RESTORE)` and add a switch at the end for deciding whether to call `executeAndSavepoint` and `restoreAndExecute`.&lt;/p&gt;

&lt;p&gt;    This would have the benefit that one test cannot be modified without becoming incompatible with the other.&lt;/p&gt;</comment>
                            <comment id="16372645" author="githubbot" created="Thu, 22 Feb 2018 10:46:41 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169917696&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169917696&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    so you only want to leave in one of the TODOs? Or are you suggesting to remove all of them?&lt;/p&gt;</comment>
                            <comment id="16372648" author="githubbot" created="Thu, 22 Feb 2018 10:49:47 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169918485&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169918485&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    fixing&lt;/p&gt;</comment>
                            <comment id="16372649" author="githubbot" created="Thu, 22 Feb 2018 10:49:53 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169918501&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169918501&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) {
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			} else {
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = {
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; };&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +					unionListState.add(s);
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getUnionListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}&lt;br/&gt;
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {    +				Thread.sleep(20);    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringParallelSourceWithUnionListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {    +    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getUnionListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(CheckpointedParallelSourceWithUnionListState.checkpointedStrings));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) &lt;/p&gt;
{
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}
&lt;p&gt;    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class KeyedStateSettingFlatMap extends RichFlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    fixing&lt;/p&gt;</comment>
                            <comment id="16372653" author="githubbot" created="Thu, 22 Feb 2018 10:53:36 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169919494&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169919494&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) {
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			} else {
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = {
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; };&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +					unionListState.add(s);
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getUnionListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}&lt;br/&gt;
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {    +				Thread.sleep(20);    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringParallelSourceWithUnionListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringParallelSourceWithUnionListState(int numElements) {
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {    +    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getUnionListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(CheckpointedParallelSourceWithUnionListState.checkpointedStrings));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    +					if (i % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) &lt;/p&gt;
{
    +						ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +					}
&lt;p&gt;    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class KeyedStateSettingFlatMap extends RichFlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void flatMap(Tuple2&amp;lt;Long, Long&amp;gt; value, Collector&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; out) throws Exception &lt;/p&gt;
{
    +			out.collect(value);
    +
    +			getRuntimeContext().getState(stateDescriptor).update(value.f1);
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingKeyedStateFlatMap extends RichFlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingKeyedStateFlatMap.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void open(Configuration parameters) throws Exception &lt;/p&gt;
{
    +			super.open(parameters);
    +
    +			getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void flatMap(Tuple2&amp;lt;Long, Long&amp;gt; value, Collector&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; out) throws Exception {&lt;br/&gt;
    +			out.collect(value);&lt;br/&gt;
    +&lt;br/&gt;
    +			ValueState&amp;lt;Long&amp;gt; state = getRuntimeContext().getState(stateDescriptor);&lt;br/&gt;
    +			if (state == null) &lt;/p&gt;
{
    +				throw new RuntimeException(&quot;Missing key value state for &quot; + value);
    +			}
&lt;p&gt;    +&lt;br/&gt;
    +			assertEquals(value.f1, state.value());&lt;br/&gt;
    +			getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);&lt;br/&gt;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class TimelyStatefulOperator&lt;br/&gt;
    +		extends AbstractStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;&lt;br/&gt;
    +		implements OneInputStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, Triggerable&amp;lt;Long, Long&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient InternalTimerService&amp;lt;Long&amp;gt; timerService;&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void open() throws Exception &lt;/p&gt;
{
    +			super.open();
    +
    +			timerService = getInternalTimerService(
    +				&quot;timer&quot;,
    +				LongSerializer.INSTANCE,
    +				this);
    +
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void processElement(StreamRecord&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; element) throws Exception &lt;/p&gt;
{
    +			ValueState&amp;lt;Long&amp;gt; state = getKeyedStateBackend().getPartitionedState(
    +				element.getValue().f0,
    +				LongSerializer.INSTANCE,
    +				stateDescriptor);
    +
    +			state.update(element.getValue().f1);
    +
    +			timerService.registerEventTimeTimer(element.getValue().f0, timerService.currentWatermark() + 10);
    +			timerService.registerProcessingTimeTimer(element.getValue().f0, timerService.currentProcessingTime() + 30_000);
    +
    +			output.collect(element);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void onEventTime(InternalTimer&amp;lt;Long, Long&amp;gt; timer) throws Exception &lt;/p&gt;
{
    +
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void onProcessingTime(InternalTimer&amp;lt;Long, Long&amp;gt; timer) throws Exception {    +    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void processWatermark(Watermark mark) throws Exception &lt;/p&gt;
{
    +			output.emitWatermark(mark);
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingTimelyStatefulOperator&lt;br/&gt;
    +		extends AbstractStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;&lt;br/&gt;
    +		implements OneInputStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, Triggerable&amp;lt;Long, Long&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR = CheckingTimelyStatefulOperator.class + &quot;_PROCESS_CHECKS&quot;;&lt;br/&gt;
    +		public static final String SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR = CheckingTimelyStatefulOperator.class + &quot;_ET_CHECKS&quot;;&lt;br/&gt;
    +		public static final String SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR = CheckingTimelyStatefulOperator.class + &quot;_PT_CHECKS&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;Long&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;Long&amp;gt;(&quot;state-name&quot;, LongSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient InternalTimerService&amp;lt;Long&amp;gt; timerService;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    fixing&lt;/p&gt;</comment>
                            <comment id="16372654" author="githubbot" created="Thu, 22 Feb 2018 10:54:22 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169919719&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169919719&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) &lt;/p&gt;
{
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = &lt;/p&gt;
{
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; }
&lt;p&gt;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) &lt;/p&gt;
{
    +					unionListState.add(s);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception &lt;/p&gt;
{
    +			unionListState = context.getOperatorStateStore().getUnionListState(
    +				stateDescriptor);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    could do, but I think this works fine &#128517; &lt;/p&gt;</comment>
                            <comment id="16372655" author="githubbot" created="Thu, 22 Feb 2018 10:55:06 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169919922&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169919922&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private final MigrationVersion flinkGenerateSavepointVersion = MigrationVersion.v1_4;&lt;br/&gt;
    +	private final String flinkGenerateSavepointBackendType = StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final MigrationVersion testMigrateVersion;&lt;br/&gt;
    +	private final String testStateBackend;&lt;br/&gt;
    +&lt;br/&gt;
    +	public StatefulJobSavepointMigrationITCase(Tuple2&amp;lt;MigrationVersion, String&amp;gt; testMigrateVersionAndBackend) &lt;/p&gt;
{
    +		this.testMigrateVersion = testMigrateVersionAndBackend.f0;
    +		this.testStateBackend = testMigrateVersionAndBackend.f1;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Manually run this to write binary snapshot data.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void writeSavepoint() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (flinkGenerateSavepointBackendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(4);&lt;br/&gt;
    +		env.setMaxParallelism(4);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckpointedParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new KeyedStateSettingFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new TimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		executeAndSavepoint(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			&quot;src/test/resources/&quot; + getSavepointPath(flinkGenerateSavepointVersion, flinkGenerateSavepointBackendType),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testSavepointRestore() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		final int parallelism = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.noRestart());&lt;br/&gt;
    +		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		switch (testStateBackend) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				env.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));
    +				break;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				env.setStateBackend(new MemoryStateBackend());
    +				break;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		env.enableCheckpointing(500);&lt;br/&gt;
    +		env.setParallelism(parallelism);&lt;br/&gt;
    +		env.setMaxParallelism(parallelism);&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap1&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator1&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		env&lt;br/&gt;
    +			.addSource(new CheckingRestoringParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS)).uid(&quot;CheckpointedSource2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.flatMap(new CheckingKeyedStateFlatMap()).startNewChain().uid(&quot;KeyedStateSettingFlatMap2&quot;)&lt;br/&gt;
    +			.keyBy(0)&lt;br/&gt;
    +			.transform(&lt;br/&gt;
    +				&quot;timely_stateful_operator&quot;,&lt;br/&gt;
    +				new TypeHint&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;() {}.getTypeInfo(),&lt;br/&gt;
    +				new CheckingTimelyStatefulOperator()).uid(&quot;TimelyStatefulOperator2&quot;)&lt;br/&gt;
    +			.addSink(new AccumulatorCountingSink&amp;lt;&amp;gt;());&lt;br/&gt;
    +&lt;br/&gt;
    +		restoreAndExecute(&lt;br/&gt;
    +			env,&lt;br/&gt;
    +			getResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingRestoringParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),&lt;br/&gt;
    +			new Tuple2&amp;lt;&amp;gt;(AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private String getSavepointPath(MigrationVersion savepointVersion, String backendType) {&lt;br/&gt;
    +		switch (backendType) &lt;/p&gt;
{
    +			case StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-rocksdb-savepoint&quot;;
    +			case StateBackendLoader.MEMORY_STATE_BACKEND_NAME:
    +				return &quot;new-stateful-udf-migration-itcase-flink&quot; + savepointVersion + &quot;-savepoint&quot;;
    +			default:
    +				throw new UnsupportedOperationException();
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedNonParallelSourceWithListState&lt;br/&gt;
    +		implements SourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;, CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String checkpointedString = &quot;Here be dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString1 = &quot;Here be more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString2 = &quot;Here be yet more dragons!&quot;;&lt;br/&gt;
    +		final static String checkpointedString3 = &quot;Here be the mostest dragons!&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedNonParallelSourceWithListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {
    +			unionListState.clear();
    +			unionListState.add(checkpointedString);
    +			unionListState.add(checkpointedString1);
    +			unionListState.add(checkpointedString2);
    +			unionListState.add(checkpointedString3);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {
    +			unionListState = context.getOperatorStateStore().getListState(
    +				stateDescriptor);
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(0));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) {
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// don&apos;t emit a final watermark so that we don&apos;t trigger the registered event-time&lt;br/&gt;
    +			// timers&lt;br/&gt;
    +			while (isRunning) {
    +				Thread.sleep(20);
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() {
    +			isRunning = false;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckingRestoringNonParallelSourceWithListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringNonParallelSourceWithListState.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckingRestoringNonParallelSourceWithListState(int numElements) {    +			this.numElements = numElements;    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
    +
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
    +			ListState&amp;lt;String&amp;gt; unionListState = context.getOperatorStateStore().getListState(&lt;br/&gt;
    +				CheckpointedNonParallelSourceWithListState.stateDescriptor);&lt;br/&gt;
    +&lt;br/&gt;
    +			if (context.isRestored()) &lt;/p&gt;
{
    +				assertThat(unionListState.get(),
    +					containsInAnyOrder(
    +						CheckpointedNonParallelSourceWithListState.checkpointedString,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString1,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString2,
    +						CheckpointedNonParallelSourceWithListState.checkpointedString3));
    +
    +				getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    +				getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				throw new RuntimeException(
    +					&quot;This source should always be restored because it&apos;s only used when restoring from a savepoint.&quot;);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +			// immediately trigger any set timers&lt;br/&gt;
    +			ctx.emitWatermark(new Watermark(1000));&lt;br/&gt;
    +&lt;br/&gt;
    +			synchronized (ctx.getCheckpointLock()) {&lt;br/&gt;
    +				for (long i = 0; i &amp;lt; numElements; i++) &lt;/p&gt;
{
    +					ctx.collect(new Tuple2&amp;lt;&amp;gt;(i, i));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			while (isRunning) &lt;/p&gt;
{
    +				Thread.sleep(20);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			isRunning = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointedParallelSourceWithUnionListState&lt;br/&gt;
    +		extends RichSourceFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		final static ListStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ListStateDescriptor&amp;lt;&amp;gt;(&quot;source-state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		final static String[] checkpointedStrings = &lt;/p&gt;
{
    +			&quot;Here be dragons!&quot;,
    +			&quot;Here be more dragons!&quot;,
    +			&quot;Here be yet more dragons!&quot;,
    +			&quot;Here be the mostest dragons!&quot; }
&lt;p&gt;;&lt;br/&gt;
    +&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final int numElements;&lt;br/&gt;
    +&lt;br/&gt;
    +		private transient ListState&amp;lt;String&amp;gt; unionListState;&lt;br/&gt;
    +&lt;br/&gt;
    +		public CheckpointedParallelSourceWithUnionListState(int numElements) &lt;/p&gt;
{
    +			this.numElements = numElements;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			unionListState.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +			for (String s : checkpointedStrings) {&lt;br/&gt;
    +				if (s.hashCode() % getRuntimeContext().getNumberOfParallelSubtasks() == getRuntimeContext().getIndexOfThisSubtask()) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    But this would only work if the length of the list matches the parallelism. It does here, but I wanted to be more general.&lt;/p&gt;</comment>
                            <comment id="16372657" author="githubbot" created="Thu, 22 Feb 2018 10:55:57 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169920122&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169920122&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,658 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing.utils;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.accumulators.IntCounter;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichFlatMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueState;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeHint;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackendLoader;&lt;br/&gt;
    +import org.apache.flink.runtime.state.memory.MemoryStateBackend;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.RichSourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.AbstractStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimer;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.InternalTimerService;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.OneInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.Triggerable;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +import org.apache.flink.streaming.util.migration.MigrationVersion;&lt;br/&gt;
    +import org.apache.flink.util.Collector;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.runner.RunWith;&lt;br/&gt;
    +import org.junit.runners.Parameterized;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Migration ITCases for a stateful job. The tests are parameterized to cover&lt;br/&gt;
    + * migrating for multiple previous Flink versions, as well as for different state backends.&lt;br/&gt;
    + */&lt;br/&gt;
    +@RunWith(Parameterized.class)&lt;br/&gt;
    +public class StatefulJobSavepointMigrationITCase extends SavepointMigrationTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_SOURCE_ELEMENTS = 4;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Parameterized.Parameters(name = &quot;Migrate Savepoint / Backend: &lt;/p&gt;
{0}
&lt;p&gt;&quot;)&lt;br/&gt;
    +	public static Collection&amp;lt;Tuple2&amp;lt;MigrationVersion, String&amp;gt;&amp;gt; parameters () &lt;/p&gt;
{
    +		return Arrays.asList(
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.MEMORY_STATE_BACKEND_NAME),
    +			Tuple2.of(MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * TODO to generate savepoints for a specific Flink version / backend type,&lt;br/&gt;
    +	 * TODO change these values accordingly, e.g. to generate for 1.4 with RocksDB,&lt;br/&gt;
    +	 * TODO set as (MigrationVersion.v1_4, StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME)&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    My impression was that they aren&apos;t TODOs to being with.&lt;/p&gt;</comment>
                            <comment id="16372664" author="githubbot" created="Thu, 22 Feb 2018 11:01:52 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I will have a look at the current state of the PR, but given that you started the effort, it would be good for completeness, to also refactor the `scala` equivalent `ITcase` to get rid of all the anonymous/internal/whatever classes, that mess up the extensibility of the `ITcase`. &lt;/p&gt;</comment>
                            <comment id="16372706" author="githubbot" created="Thu, 22 Feb 2018 11:44:04 +0000"  >&lt;p&gt;Github user kl0u commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552#discussion_r169928328&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552#discussion_r169928328&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java &amp;#8212;&lt;br/&gt;
    @@ -468,61 +518,6 @@ public void flatMap(Tuple2&amp;lt;Long, Long&amp;gt; value, Collector&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; out)&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class CheckpointedUdfOperator&lt;/li&gt;
	&lt;li&gt;extends AbstractUdfStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, FlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;&amp;gt;&lt;/li&gt;
	&lt;li&gt;implements OneInputStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;/li&gt;
	&lt;li&gt;private static final long serialVersionUID = 1L;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;private static final String CHECKPOINTED_STRING = &quot;Oh my, that&apos;s nice!&quot;;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;public CheckpointedUdfOperator(FlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; userFunction) 
{
    -			super(userFunction);
    -		}&lt;br/&gt;
    -&lt;br/&gt;
    -		@Override&lt;br/&gt;
    -		public void processElement(StreamRecord&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; element) throws Exception {
    -			userFunction.flatMap(element.getValue(), new TimestampedCollector&amp;lt;&amp;gt;(output));
    -		}&lt;br/&gt;
    -&lt;br/&gt;
    -		@Override&lt;br/&gt;
    -		public void processWatermark(Watermark mark) throws Exception {
    -			output.emitWatermark(mark);
    -		}&lt;br/&gt;
    -	}&lt;br/&gt;
    -&lt;br/&gt;
    -	private static class CheckingRestoringUdfOperator&lt;br/&gt;
    -		extends AbstractUdfStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, FlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
    -		implements OneInputStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; {&lt;br/&gt;
    -&lt;br/&gt;
    -		private static final long serialVersionUID = 1L;&lt;br/&gt;
    -&lt;br/&gt;
    -		public static final String SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR = CheckingRestoringUdfOperator.class + &quot;_RESTORE_CHECK&quot;;&lt;br/&gt;
    -&lt;br/&gt;
    -		private String restoredState;&lt;br/&gt;
    -&lt;br/&gt;
    -		public CheckingRestoringUdfOperator(FlatMapFunction&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;, Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; userFunction) {    -			super(userFunction);    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void open() throws Exception 
{
    -			super.open();
    -
    -			getRuntimeContext().addAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, new IntCounter());
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void processElement(StreamRecord&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt; element) throws Exception 
{
    -			userFunction.flatMap(element.getValue(), new TimestampedCollector&amp;lt;&amp;gt;(output));
    -			getRuntimeContext().getAccumulator(SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR).add(1);
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void processWatermark(Watermark mark) throws Exception 
{
    -			output.emitWatermark(mark);
    -		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;br/&gt;
     	private static class TimelyStatefulOperator&lt;br/&gt;
     		extends AbstractStreamOperator&amp;lt;Tuple2&amp;lt;Long, Long&amp;gt;&amp;gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Code-style comment: for code readability I would suggest to indent by one more `tab` the `extends`/`implements` lines, as this allows to separate them from the class fields. This is a general comment, I just put it here because it is more obvious that it can be difficult to separate the `implements`/`extends` clauses from the following `private static final long serialVersionUID = 1L;`&lt;/p&gt;</comment>
                            <comment id="16372745" author="githubbot" created="Thu, 22 Feb 2018 12:22:40 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I added some new commits that unify the test to have only one method for performing and verifying the savepoint. I didn&apos;t go for the factory approach in the end because I think that would have made the control flow harder to follow. @zentol WDYT?&lt;/p&gt;</comment>
                            <comment id="16372750" author="githubbot" created="Thu, 22 Feb 2018 12:28:37 +0000"  >&lt;p&gt;Github user zentol commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    looks good to me&lt;/p&gt;</comment>
                            <comment id="16372803" author="githubbot" created="Thu, 22 Feb 2018 13:31:03 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @kl0u thanks for the review! I saw that the Scala ITCase is very different from the Java one. I (or someone) should probably tackle that in a follow-up. WDYT?&lt;/p&gt;</comment>
                            <comment id="16372807" author="githubbot" created="Thu, 22 Feb 2018 13:32:24 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @aljoscha Yes.&lt;/p&gt;</comment>
                            <comment id="16372862" author="githubbot" created="Thu, 22 Feb 2018 14:31:02 +0000"  >&lt;p&gt;Github user aljoscha closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16372863" author="githubbot" created="Thu, 22 Feb 2018 14:31:10 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5552&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the reviews, y&apos;all. &#128077; &lt;/p&gt;</comment>
                            <comment id="16372871" author="githubbot" created="Thu, 22 Feb 2018 14:39:11 +0000"  >&lt;p&gt;Github user aljoscha closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5553&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5553&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16372872" author="aljoscha" created="Thu, 22 Feb 2018 14:39:35 +0000"  >&lt;p&gt;Added on release-1.4 in&lt;br/&gt;
f06ec38f223e94c926964b8760115d89988478c1&lt;/p&gt;

&lt;p&gt;Added on master in&lt;br/&gt;
e96f28bd381bbca6c5f7b0572c4527b9f3c7952a&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 38 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3qffr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>