<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:19:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-34063] When snapshot compression is enabled, rescaling of a source operator leads to some splits getting lost</title>
                <link>https://issues.apache.org/jira/browse/FLINK-34063</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;h2&gt;&lt;a name=&quot;Backstory&quot;&gt;&lt;/a&gt;Backstory&lt;/h2&gt;

&lt;p&gt;We&apos;ve been experimenting with Autoscaling on the Flink 1.18 and faced a pretty nasty bug. &lt;/p&gt;

&lt;p&gt;The symptoms on our production system were as following. After a while after deploying a job with autoscaler it started accumulating Kafka lag, and this could only be observed via external lag measurement - from inside Flink (measured by&lt;br/&gt;
&lt;tt&gt;&lt;em&gt;KafkaSourceReader_KafkaConsumer_records_lag_max&lt;/em&gt;&lt;/tt&gt; metric) the lag was OK:&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13065912/13065912_image-2024-01-11-16-27-09-066.png&quot; height=&quot;263&quot; width=&quot;887&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;After some digging, it turned out that the job has lost some Kafka partitions - i.e. it stopped consuming from them, &#8220;forgot&#8221; about their existence. That&#8217;s why from the Flink&#8217;s perspective everything was fine - the lag was growing on the partitions Flink no longer knew about.&lt;/p&gt;

&lt;p&gt;This was visible on a metric called &#8220;Assigned partitions&#8221; (KafkaSourceReader_KafkaConsumer_assigned_partitions):&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13065911/13065911_image-2024-01-11-16-30-47-466.png&quot; height=&quot;254&quot; width=&quot;1046&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;We see on the chart that the job used to know about 20 partitions, and then this number got dropped to 16.&lt;/p&gt;

&lt;p&gt;This drop has been quickly connected to the job&#8217;s scaling events. Or, more precisely, to the scaling of the source operator - with almost 100% probability any scaling of the source operator led to partitions loss.&lt;/p&gt;
&lt;h2&gt;&lt;a name=&quot;Investigation&quot;&gt;&lt;/a&gt;Investigation&lt;/h2&gt;

&lt;p&gt;We&apos;ve conducted the investigation. We use the latest Kubernetes operator and deploy jobs with Native Kubernetes.&lt;/p&gt;

&lt;p&gt;The reproducing scenario we used for investigation:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Launch a job with source operator parallelism = 4, enable DEBUG logging&lt;/li&gt;
	&lt;li&gt;Wait until it takes the first checkpoint&lt;/li&gt;
	&lt;li&gt;Scale-up the source operator to say 5 (no need to wait for autoscaling, it can be done via Flink UI)&lt;/li&gt;
	&lt;li&gt;Wait until the new checkpoint is taken&lt;/li&gt;
	&lt;li&gt;Scale-down the source operator to 3&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;These simple actions with almost 100% probability led to some partitions get lost.&lt;/p&gt;

&lt;p&gt;After that we&apos;ve downloaded all the logs and inspected them. Noticed these strange records in logs:&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
{&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;:1704415753166,&lt;span class=&quot;code-quote&quot;&gt;&quot;is_logging_enabled&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;logger_id&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.flink.streaming.api.operators.AbstractStreamOperator&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;log_level&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;INFO&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;message&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;Restoring state &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 4 split(s) to reader.&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;service_name&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;data-beaver&quot;&lt;/span&gt;} {&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;:1704415753166,&lt;span class=&quot;code-quote&quot;&gt;&quot;is_logging_enabled&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;logger_id&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.flink.connector.base.source.reader.SourceReaderBase&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;log_level&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;INFO&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;message&quot;&lt;/span&gt;:&quot;Adding split(s) to reader: 
[
[Partition: eventmesh-video-play-v1-6, StartingOffset: 1964306414, StoppingOffset: -9223372036854775808], 
[Partition: eventmesh-video-play-v1-19, StartingOffset: 1963002538, StoppingOffset: -9223372036854775808], 
[Partition: eventmesh-video-play-v1-6, StartingOffset: 1964306414, StoppingOffset: -9223372036854775808], 
[Partition: eventmesh-video-play-v1-19, StartingOffset: 1963002538, StoppingOffset: -9223372036854775808]]&lt;span class=&quot;code-quote&quot;&gt;&quot;, &quot;&lt;/span&gt;service_name&lt;span class=&quot;code-quote&quot;&gt;&quot;:&quot;&lt;/span&gt;data-beaver&quot;}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We see that some task being restored with 4 splits, however actual splits have duplicates - we see that in reality 2 unique partitions have been added (&lt;em&gt;eventmesh-video-play-v1-6&lt;/em&gt; and &lt;em&gt;eventmesh-video-play-v1-19&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Digging into the code and the logs a bit more, log lines like this started looking suspicious:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
{&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;:1704415753165,&lt;span class=&quot;code-quote&quot;&gt;&quot;is_logging_enabled&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;logger_id&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.flink.runtime.state.TaskStateManagerImpl&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;log_level&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;DEBUG&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;message&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;Operator 156a1ebbc1936f7d4558c8070b35ba93 has remote state SubtaskState{operatorStateFromBackend=StateObjectCollection{ [OperatorStateHandle{stateNameToPartitionOffsets={SourceReaderState=StateMetaInfo{offsets=[244, 244], distributionMode=SPLIT_DISTRIBUTE}}, delegateStateHandle=ByteStreamStateHandle{handleName=&lt;span class=&quot;code-quote&quot;&gt;&apos;gs:&lt;span class=&quot;code-comment&quot;&gt;//data-beaver/checkpoints/moj-tj-dummy-partition-loss-debug-v1/6e1ba15b1b5bedda64836ff48ed1c264/chk-3/fadb4f23-85dd-4048-b466-94c1c5329dd3&apos;&lt;/span&gt;, dataBytes=328}}, OperatorStateHandle{stateNameToPartitionOffsets={SourceReaderState=StateMetaInfo{offsets=[244, 244], distributionMode=SPLIT_DISTRIBUTE}}, delegateStateHandle=ByteStreamStateHandle{handleName=&lt;span class=&quot;code-quote&quot;&gt;&apos;gs://data-beaver/checkpoints/moj-tj-dummy-partition-loss-debug-v1/6e1ba15b1b5bedda64836ff48ed1c264/chk-3/102aa50b-78c2-457e-9a2f-0055f1dbeb98&apos;&lt;/span&gt;, dataBytes=328}}]}, operatorStateFromStream=StateObjectCollection{[]}, keyedStateFromBackend=StateObjectCollection{[]}, keyedStateFromStream=StateObjectCollection{[]}, inputChannelState=StateObjectCollection{[]}, resultSubpartitionState=StateObjectCollection{[]}, stateSize=656, checkpointedSize=656} from job manager and local state alternatives [] from local state store org.apache.flink.runtime.state.NoOpTaskLocalStateStoreImpl@1f89f054.&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;service_name&quot;&lt;/span&gt;:&lt;span class=&quot;code-quote&quot;&gt;&quot;data-beaver&quot;&lt;/span&gt;}&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;We see these strange offsets &lt;b&gt;offsets=&lt;span class=&quot;error&quot;&gt;&amp;#91;244, 244&amp;#93;&lt;/span&gt;&lt;/b&gt; that look weird.&lt;/p&gt;

&lt;p&gt;And this is a clearly wrong. Because when restoring from snapshot, &lt;a href=&quot;https://github.com/apache/flink/blob/881062f352f8bf8c21ab7cbea95e111fd82fdf20/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/RoundRobinOperatorStateRepartitioner.java#L350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this code&lt;/a&gt; will redistribute offsets to different batches - and they will read the same value.&lt;/p&gt;

&lt;p&gt;These offsets are produced by &lt;a href=&quot;https://github.com/apache/flink/blob/263f3283724a5081e41f679659fa6a5819350739/flink-runtime/src/main/java/org/apache/flink/runtime/state/PartitionableListState.java#L110&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this&lt;/a&gt; code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;[] write(FSDataOutputStream out) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {

      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;[] partitionOffsets = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;[internalList.size()];

      DataOutputView dov = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DataOutputViewStreamWrapper(out);

      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; i &amp;lt; internalList.size(); ++i) {
          S element = internalList.get(i);
          partitionOffsets[i] = out.getPos();
          getStateMetaInfo().getPartitionStateSerializer().serialize(element, dov);
      }

      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; partitionOffsets;
} &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The actual implementation that&#8217;s being used in this piece of code is &lt;a href=&quot;https://github.com/apache/flink/blob/263f3283724a5081e41f679659fa6a5819350739/flink-runtime/src/main/java/org/apache/flink/runtime/state/CompressibleFSDataOutputStream.java#L30&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;CompressibleFSDataOutputStream&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;At this moment we realised that we have snapshot compression enabled (execution.checkpointing.snapshot-compression = true).&lt;/p&gt;

&lt;p&gt;If we take a look into how getPos() is implemented in CompressibleFSDataOutputStream, we&apos;d see that getPos() is delegated to the actual output stream, while writing is happening through compressing delegate:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; CompressibleFSDataOutputStream(
            CheckpointStateOutputStream delegate, StreamCompressionDecorator compressionDecorator)
            &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.delegate = delegate;
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.compressingDelegate = compressionDecorator.decorateWithCompression(delegate);
    }

    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; getPos() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; delegate.getPos();
    }

    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void write(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; b) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
        compressingDelegate.write(b);
    } &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is incorrect when compression is enabled, because compressing delegate doesn&apos;t flush data into the actual output stream immediately (&lt;a href=&quot;https://github.com/xerial/snappy-java/blob/ebfbdead182937463735729bd8fe5f4cd69235e4/src/main/java/org/xerial/snappy/SnappyFramedOutputStream.java#L279&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;link&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void write(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; b)
&#160; &#160; &#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException
{
 &#160; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (closed) {
 &#160; &#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Stream is closed&quot;&lt;/span&gt;);
   }
&#160; &#160;&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (buffer.remaining() &amp;lt;= 0) {
&#160; &#160;&#160; flushBuffer();
&#160; &#160;}
&#160; &#160;buffer.put((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;) b);
} &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Hence, the position in the &lt;em&gt;delegate&lt;/em&gt;&#160;doesn&apos;t get updated, and all offsets end up being the same.&lt;/p&gt;
&lt;h2&gt;&lt;a name=&quot;Simplestreproducingscenario&quot;&gt;&lt;/a&gt;Simplest reproducing scenario&lt;/h2&gt;

&lt;p&gt;Now as we know the culprit, a simple reproducing scenario (verified) is the following, that can be checked locally eassily:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a Kafka topic with say 20 partitions&lt;/li&gt;
	&lt;li&gt;Launch a job reading from this topic with some parallelism, say 5. &lt;b&gt;Important: snapshot compression should be enabled in this job&lt;/b&gt;&lt;/li&gt;
	&lt;li&gt;Stop the job with savepoint&lt;/li&gt;
	&lt;li&gt;Restore the job from this savepoint and pick a different parallelism, say 3.&lt;/li&gt;
	&lt;li&gt;Result: some Kafka partitions will not be consumed anymore.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>&lt;p&gt;Can be reproduced in any environment. The most important thing is to enable snapshot compression.&lt;/p&gt;</environment>
        <key id="13564374">FLINK-34063</key>
            <summary>When snapshot compression is enabled, rescaling of a source operator leads to some splits getting lost</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dmvk">David Mor&#225;vek</assignee>
                                    <reporter username="isburmistrov">Ivan Burmistrov</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Thu, 11 Jan 2024 17:15:26 +0000</created>
                <updated>Wed, 16 Oct 2024 08:07:55 +0000</updated>
                            <resolved>Fri, 19 Jan 2024 14:29:59 +0000</resolved>
                                    <version>1.18.0</version>
                    <version>1.18.1</version>
                                    <fixVersion>1.19.0</fixVersion>
                    <fixVersion>1.18.2</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="17805934" author="pnowojski" created="Fri, 12 Jan 2024 08:32:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dmvk&quot; class=&quot;user-hover&quot; rel=&quot;dmvk&quot;&gt;dmvk&lt;/a&gt; could this issue be discovered by our ITCases if snapshot compression had been enabled in them? Regardless of that, it is probably a good idea to enable it using our configuration randomisation framework: &lt;tt&gt;org.apache.flink.streaming.util.TestStreamEnvironment#randomizeConfiguration&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="17806111" author="yang" created="Fri, 12 Jan 2024 16:00:56 +0000"  >&lt;p&gt;FYI, I have encountered also the issue of losing kafka partition in some slot after rescaling. But I don&apos;t use snapshot compression.&#160;&lt;/p&gt;

&lt;p&gt;I have used Flink 1.18.0, kafka source connector&#160;3.0.1-1.18. During our observation, even if we don&apos;t use autoscaling, this issue could happen after the source parallelism upgrade.&lt;/p&gt;

&lt;p&gt;And by experience I don&apos;t think we have this issue in flink 1.17&lt;/p&gt;</comment>
                            <comment id="17806131" author="davidmoravek" created="Fri, 12 Jan 2024 17:24:32 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yang&quot; class=&quot;user-hover&quot; rel=&quot;yang&quot;&gt;yang&lt;/a&gt;, it would be great if you open a separate issue a provide more details. We need more context to pin down the root cause of what you&apos;re describing.&lt;/p&gt;</comment>
                            <comment id="17806520" author="yang" created="Sun, 14 Jan 2024 19:46:06 +0000"  >&lt;p&gt;Ok &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dmvk&quot; class=&quot;user-hover&quot; rel=&quot;dmvk&quot;&gt;dmvk&lt;/a&gt; , I&apos;ll do it&lt;/p&gt;</comment>
                            <comment id="17806863" author="yang" created="Mon, 15 Jan 2024 15:00:49 +0000"  >&lt;p&gt;Hello &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dmvk&quot; class=&quot;user-hover&quot; rel=&quot;dmvk&quot;&gt;dmvk&lt;/a&gt; , FYI I have created a seperate ticket to report the issues I have encountered &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-34096&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-34096&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17808603" author="davidmoravek" created="Fri, 19 Jan 2024 11:33:50 +0000"  >&lt;p&gt;master:&lt;/p&gt;

&lt;p&gt;161378ad3a234f4ff17b6fd4e6f950e232e16a6f&lt;/p&gt;

&lt;p&gt;006a0869e32f64dbbe0b6d6142fc36bf7544ac5c&lt;/p&gt;

&lt;p&gt;6f76982e26405ee1a8531539e9d2c4b2c5e001c5&lt;/p&gt;

&lt;p&gt;d536b5a7d73bb0696291d6ea7c47544f4edd3e77&lt;/p&gt;

&lt;p&gt;b7c314b46acdde0936a0e2d329f48972d1ea3e0b&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;release-1.18:&lt;/p&gt;

&lt;p&gt;1cd68f954ee7d5360a98a779bd93c3cc7144c5a6&lt;/p&gt;

&lt;p&gt;5e40a556011949bd84d401d3161f4007beb56bce&lt;/p&gt;

&lt;p&gt;c334cbf24960978461bb3c64eead9907ea10fc99&lt;/p&gt;

&lt;p&gt;5136c2513b4601c4e86806ad3c1af47aa9b7670e&lt;/p&gt;

&lt;p&gt;e39559895ab694e427df7a840a5e37a3a510969d&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13564746">FLINK-34096</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13562069">FLINK-33863</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13504782">FLINK-30113</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13065912" name="image-2024-01-11-16-27-09-066.png" size="1495307" author="isburmistrov" created="Thu, 11 Jan 2024 16:27:09 +0000"/>
                            <attachment id="13065911" name="image-2024-01-11-16-30-47-466.png" size="237658" author="isburmistrov" created="Thu, 11 Jan 2024 16:30:48 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 42 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1mp2g:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Fixes a regression introduced in 1.18.0, where operator state couldn&amp;#39;t be properly restored in case snapshot compression is enabled. This could have led to either data loss or disability to restore from checkpoint.&lt;br/&gt;
&lt;br/&gt;
Any snapshots with enabled compression, that include operator state, taken from either Flink 1.18.0 or 1.18.1, need to be discarded, because they&amp;#39;re corrupted.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>