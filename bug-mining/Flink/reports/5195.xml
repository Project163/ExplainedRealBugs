<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:55:08 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-20114] Fix a few KafkaSource-related bugs</title>
                <link>https://issues.apache.org/jira/browse/FLINK-20114</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Feature introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-18323&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-18323&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;-------- &lt;br/&gt;
&lt;a href=&quot;https://cwiki.apache.org/confluence/display/FLINK/1.12+Release+-+Community+Testing&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;General Information about the Flink 1.12 release testing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When testing a feature, consider the following aspects:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Is the documentation easy to understand&lt;/li&gt;
	&lt;li&gt;Are the error messages, log messages, APIs etc. easy to understand&lt;/li&gt;
	&lt;li&gt;Is the feature working as expected under normal conditions&lt;/li&gt;
	&lt;li&gt;Is the feature working / failing as expected with invalid input, induced errors etc.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If you find a problem during testing, please file a ticket (Priority=Critical; Fix Version = 1.12.0), and link it in this testing ticket.&lt;br/&gt;
During the testing, and once you are finished, please write a short summary of all things you have tested.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13340249">FLINK-20114</key>
            <summary>Fix a few KafkaSource-related bugs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rmetzger">Robert Metzger</reporter>
                        <labels>
                            <label>pull-request-available</label>
                            <label>release-testing</label>
                    </labels>
                <created>Thu, 12 Nov 2020 14:16:01 +0000</created>
                <updated>Mon, 11 Nov 2024 02:32:26 +0000</updated>
                            <resolved>Fri, 7 May 2021 00:22:55 +0000</resolved>
                                    <version>1.12.0</version>
                                    <fixVersion>1.13.0</fixVersion>
                    <fixVersion>1.12.4</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="17233705" author="rmetzger" created="Tue, 17 Nov 2020 16:19:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevenz3wu&quot; class=&quot;user-hover&quot; rel=&quot;stevenz3wu&quot;&gt;stevenz3wu&lt;/a&gt; would you be interested in helping with the testing of the new Kafka source?&lt;br/&gt;
Since it is such a critical component, I believe we would benefit from a lot of testing coverage. I&apos;m pinging you already, even though there are a few known issues (see linked blockers) that we need to resolve first, but I thought it might be helpful for you to schedule this work some time later this week.&lt;/p&gt;</comment>
                            <comment id="17233762" author="stevenz3wu" created="Tue, 17 Nov 2020 17:30:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rmetzger&quot; class=&quot;user-hover&quot; rel=&quot;rmetzger&quot;&gt;rmetzger&lt;/a&gt; sorry. it might be difficult. We were having some production issues last week that we need to address in the next 2 weeks. We do plan to test 1.12 as soon as we can though.&lt;/p&gt;</comment>
                            <comment id="17233874" author="rmetzger" created="Tue, 17 Nov 2020 19:23:41 +0000"  >&lt;p&gt;Allright, no problem. Good luck with resolving the issues!&lt;/p&gt;</comment>
                            <comment id="17238154" author="rmetzger" created="Tue, 24 Nov 2020 14:11:33 +0000"  >&lt;p&gt;Testing Issue 1:&lt;br/&gt;
I started a job with the KafkaSource on a setup where no Kafka broker was reachable. The job was running without an errors for 15 minutes.&lt;br/&gt;
I would expect the job to fail after a timeout of a few minutes if no broker could be reached?&lt;/p&gt;



&lt;p&gt;Testing Issue 2:&lt;br/&gt;
While testing the new Kafka source on current master, I tried stopping the job with a savepoint. I came across this unexpected exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2020-11-24 14:37:56,517 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Triggering cancel-with-savepoint &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job fae21d0ce1804445dd4cc904fcdfbf43.
2020-11-24 14:37:56,522 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Triggering checkpoint 488 (type=SAVEPOINT) @ 1606225076519 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job fae21d0ce1804445dd4cc904fcdfbf43.
2020-11-24 14:37:56,554 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Savepoint stored in file:/tmp/sm-savepoint/savepoint-fae21d-9723b187d107. Now cancelling fae21d0ce1804445dd4cc904fcdfbf43.
2020-11-24 14:37:56,555 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Completed checkpoint 488 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job fae21d0ce1804445dd4cc904fcdfbf43 (7183 bytes in 35 ms).
2020-11-24 14:37:56,555 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job State machine job (fae21d0ce1804445dd4cc904fcdfbf43) switched from state RUNNING to CANCELLING.
2020-11-24 14:37:56,556 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (1/5) (b23b8a46bee25317d2bf1822bc043c31) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,557 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (2/5) (e40a16e61b64c8e71e873383a18c0a45) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,557 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (3/5) (d5b299c2e3f7a9dd9cfc5579c55845ba) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,557 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (4/5) (06bb492f8fe20534c9c3e9f5adf16d3c) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,557 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (5/5) (70c4d09343b647ee4f64b784b88145b6) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,558 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (1/5) (5b288ff9d47a2528783fe04d30844ac7) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,558 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (2/5) (e8b2cd2fcd7b5d240d7ce83693ad88b6) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,558 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (3/5) (a5ff2af6ae3c00104e0430eff149c2e8) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,558 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (4/5) (26ff08ea4128b9fa16bfe4251f390c11) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,558 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (5/5) (658b5ccf92f07ac5a3b2ea9b648c4ba9) switched from RUNNING to CANCELING.
2020-11-24 14:37:56,560 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Marking checkpoint 488 as completed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; source Source: Kafka Source.
2020-11-24 14:37:56,575 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (1/5) (b23b8a46bee25317d2bf1822bc043c31) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,576 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (3/5) (d5b299c2e3f7a9dd9cfc5579c55845ba) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,577 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (2/5) (e40a16e61b64c8e71e873383a18c0a45) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,578 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (5/5) (70c4d09343b647ee4f64b784b88145b6) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,579 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (2/5) (e8b2cd2fcd7b5d240d7ce83693ad88b6) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,580 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (5/5) (658b5ccf92f07ac5a3b2ea9b648c4ba9) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,582 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (4/5) (06bb492f8fe20534c9c3e9f5adf16d3c) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,583 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (4/5) (26ff08ea4128b9fa16bfe4251f390c11) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,589 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (1/5) (5b288ff9d47a2528783fe04d30844ac7) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,591 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Flat Map -&amp;gt; Sink: Print to Std. Out (3/5) (a5ff2af6ae3c00104e0430eff149c2e8) switched from CANCELING to CANCELED.
2020-11-24 14:37:56,592 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job State machine job (fae21d0ce1804445dd4cc904fcdfbf43) switched from state CANCELLING to CANCELED.
2020-11-24 14:37:56,592 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job fae21d0ce1804445dd4cc904fcdfbf43.
2020-11-24 14:37:56,593 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2020-11-24 14:37:56,593 INFO  org.apache.flink.runtime.checkpoint.CompletedCheckpoint      [] - Checkpoint with ID 488 at &lt;span class=&quot;code-quote&quot;&gt;&apos;file:/tmp/sm-savepoint/savepoint-fae21d-9723b187d107&apos;&lt;/span&gt; not discarded.
2020-11-24 14:37:56,596 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job fae21d0ce1804445dd4cc904fcdfbf43 reached globally terminal state CANCELED.
2020-11-24 14:37:56,630 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job State machine job(fae21d0ce1804445dd4cc904fcdfbf43).
2020-11-24 14:37:56,631 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; source Source: Kafka Source.
2020-11-24 14:37:56,631 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; handling result from async call in SourceCoordinator-Source: Kafka Source. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to handle partition splits change due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.handlePartitionSplitChanges(KafkaSourceEnumerator.java:199) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-075706c79af3170480b19252d2647a17:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$1(ExecutorNotifier.java:86) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) [flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:832) [?:?]
Caused by: java.lang.RuntimeException: Failed to get topic metadata.
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getPartitionChanges(TopicListSubscriber.java:60) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-075706c79af3170480b19252d2647a17:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.discoverAndInitializePartitionSplit(KafkaSourceEnumerator.java:176) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-075706c79af3170480b19252d2647a17:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:83) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	... 3 more
Caused by: java.lang.InterruptedException
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(Native Method) ~[?:?]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.wait(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.java:321) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:92) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-075706c79af3170480b19252d2647a17:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-075706c79af3170480b19252d2647a17:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getPartitionChanges(TopicListSubscriber.java:58) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-075706c79af3170480b19252d2647a17:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.discoverAndInitializePartitionSplit(KafkaSourceEnumerator.java:176) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-075706c79af3170480b19252d2647a17:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:83) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	... 3 more
2020-11-24 14:37:56,636 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Suspending SlotPool.
2020-11-24 14:37:56,637 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 1dc7c4d8b846d99ade33fbd7bfb620cf: Stopping JobMaster &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job State machine job(fae21d0ce1804445dd4cc904fcdfbf43)..
2020-11-24 14:37:56,637 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Stopping SlotPool.
2020-11-24 14:37:56,638 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//flink@localhost:6123/user/rpc/jobmanager_2 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job fae21d0ce1804445dd4cc904fcdfbf43 from the resource manager.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It does not seem to cause any issues, except that the logged exception might confuse users.&lt;/p&gt;

&lt;p&gt;Testing Issue 3:&lt;br/&gt;
I also noticed that the &lt;tt&gt;NetworkClient&lt;/tt&gt; kept logging every few seconds for ~ 1.5 minutes after the job has finished. It eventually stopped with a timeout. Maybe we can proactively stop the NetworkClient on the JobManager to avoid resource leaks in case the timeout is configured differently on a user setup:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2020-11-24 14:37:56,637 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Stopping SlotPool.
2020-11-24 14:37:56,638 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//flink@localhost:6123/user/rpc/jobmanager_2 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job fae21d0ce1804445dd4cc904fcdfbf43 from the resource manager.
&lt;/span&gt;2020-11-24 14:37:57,370 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-11-24 14:37:58,642 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-11-24 14:37:59,806 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-11-24 14:38:00,973 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.

[ ... ]

2020-11-24 14:38:56,002 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-11-24 14:38:56,639 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; source Source: Kafka Source closed.
2020-11-24 14:38:56,959 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.

[ ... ]

2020-11-24 14:39:37,927 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-11-24 14:39:38,890 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-11-24 14:39:39,944 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-11-24 14:39:40,050 INFO  org.apache.kafka.clients.admin.internals.AdminMetadataManager [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Timed out waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a node assignment.
2020-11-24 14:39:40,158 INFO  org.apache.kafka.clients.admin.internals.AdminMetadataManager [] - [AdminClient clientId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Testing Issue 4:&lt;/p&gt;

&lt;p&gt;When cancelling my job, I saw this WARNING in the logs. I have not added any jars into my lib folder.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2020-11-24 15:09:42,325 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//flink@localhost:6123/user/rpc/jobmanager_5 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; job b5bb1c9bb705d9d771b63e33dc6e877f from the resource manager.
&lt;/span&gt;2020-11-24 15:09:42,329 WARN  org.apache.kafka.common.utils.Utils                          [] - Failed to close KafkaClient with type org.apache.kafka.clients.NetworkClient
java.lang.NoClassDefFoundError: org/apache/kafka/common/network/Selector$CloseMode
	at org.apache.kafka.common.network.Selector.close(Selector.java:806) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-1eba36fb91ea0b66651554912ceaca10:?]
	at org.apache.kafka.common.network.Selector.close(Selector.java:365) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-1eba36fb91ea0b66651554912ceaca10:?]
	at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:639) ~[blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-1eba36fb91ea0b66651554912ceaca10:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:834) [blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-1eba36fb91ea0b66651554912ceaca10:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1219) [blob_p-38777177cae883549cd5d28a76d1854e5087cc9f-1eba36fb91ea0b66651554912ceaca10:?]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:832) [?:?]
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.network.Selector$CloseMode
	at java.net.URLClassLoader.findClass(URLClassLoader.java:435) ~[?:?]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:589) ~[?:?]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClassWithoutExceptionHandling(FlinkUserCodeClassLoader.java:63) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.util.ChildFirstClassLoader.loadClassWithoutExceptionHandling(ChildFirstClassLoader.java:72) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClass(FlinkUserCodeClassLoader.java:49) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:522) ~[?:?]
	... 6 more
2020-11-24 15:09:42,330 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; source Source: Kafka Source closed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17238160" author="rmetzger" created="Tue, 24 Nov 2020 14:16:25 +0000"  >&lt;p&gt;Testing Issue 5:&lt;br/&gt;
It seems that metrics are only reported for the &quot;bytes send&quot;, but not for &quot;records send&quot;. The receiver properly reports both metrics. I added a screenshot showing the problem to the ticket.&lt;/p&gt;</comment>
                            <comment id="17238168" author="rmetzger" created="Tue, 24 Nov 2020 14:26:47 +0000"  >&lt;p&gt;Testing Issue 6:&lt;/p&gt;

&lt;p&gt;I created a topic with 64 partitions, and started the job, which started failing with:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2020-11-24 15:25:00,530 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source (5/6) (74a3b791c148ea9ce9d17ae59f59becc) switched from RUNNING to FAILED on org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot@10db45bb.
java.lang.Exception: Could not perform checkpoint 11 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; Source: Kafka Source (5/6)#10.
	at org.apache.flink.streaming.runtime.tasks.StreamTask.triggerCheckpoint(StreamTask.java:866) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$triggerCheckpointAsync$8(StreamTask.java:831) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:47) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:78) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:302) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:184) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:575) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:539) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:722) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:547) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:832) ~[?:?]
Caused by: org.apache.flink.runtime.checkpoint.CheckpointException: Could not complete snapshot 11 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; Source: Kafka Source (5/6)#10. Failure reason: Checkpoint was declined.
	at org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.snapshotState(StreamOperatorStateHandler.java:226) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.snapshotState(StreamOperatorStateHandler.java:158) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.snapshotState(AbstractStreamOperator.java:343) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.checkpointStreamOperator(SubtaskCheckpointCoordinatorImpl.java:603) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.buildOperatorSnapshotFutures(SubtaskCheckpointCoordinatorImpl.java:529) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.takeSnapshotSync(SubtaskCheckpointCoordinatorImpl.java:496) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.checkpointState(SubtaskCheckpointCoordinatorImpl.java:266) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$performCheckpoint$9(StreamTask.java:924) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:47) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.performCheckpoint(StreamTask.java:914) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.triggerCheckpoint(StreamTask.java:857) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	... 10 more
Caused by: org.apache.flink.util.SerializedThrowable: Invalid negative offset
	at org.apache.kafka.clients.consumer.OffsetAndMetadata.&amp;lt;init&amp;gt;(OffsetAndMetadata.java:50) ~[?:?]
	at org.apache.kafka.clients.consumer.OffsetAndMetadata.&amp;lt;init&amp;gt;(OffsetAndMetadata.java:69) ~[?:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaSourceReader.snapshotState(KafkaSourceReader.java:96) ~[?:?]
	at org.apache.flink.streaming.api.operators.SourceOperator.snapshotState(SourceOperator.java:264) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.snapshotState(StreamOperatorStateHandler.java:197) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.snapshotState(StreamOperatorStateHandler.java:158) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.snapshotState(AbstractStreamOperator.java:343) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.checkpointStreamOperator(SubtaskCheckpointCoordinatorImpl.java:603) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.buildOperatorSnapshotFutures(SubtaskCheckpointCoordinatorImpl.java:529) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.takeSnapshotSync(SubtaskCheckpointCoordinatorImpl.java:496) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl.checkpointState(SubtaskCheckpointCoordinatorImpl.java:266) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$performCheckpoint$9(StreamTask.java:924) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:47) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.performCheckpoint(StreamTask.java:914) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.triggerCheckpoint(StreamTask.java:857) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]
	... 10 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17238171" author="rmetzger" created="Tue, 24 Nov 2020 14:28:52 +0000"  >&lt;p&gt;I attached the logs for these runs as well: Issues 1 - 5 are in the &quot;first-run.tgz&quot;, issue 6 is in second-run.tgz&lt;/p&gt;</comment>
                            <comment id="17238903" author="rmetzger" created="Wed, 25 Nov 2020 19:57:51 +0000"  >&lt;p&gt;I will continue with the testing once the issues reported so far are resolved. At least Issue 6, which breaks checkpointing.&lt;/p&gt;</comment>
                            <comment id="17311175" author="lindong" created="Tue, 30 Mar 2021 06:24:47 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rmetzger&quot; class=&quot;user-hover&quot; rel=&quot;rmetzger&quot;&gt;rmetzger&lt;/a&gt;, thank you for doing the test! Here is the status update.&lt;/p&gt;

&lt;p&gt;The following patches have been developed to fix KafkaSource related bugs:&lt;/p&gt;

&lt;p&gt;1) &lt;a href=&quot;https://github.com/apache/flink/pull/15161&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/15161&lt;/a&gt; has been merged with multiple commits to fix the issues mentioned in this bug.&lt;/p&gt;

&lt;p&gt;2) Jiangjie is working on &lt;a href=&quot;https://github.com/becketqin/flink/commit/1bb2be0935d48153c67981476fc5046afa4b172f&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/becketqin/flink/commit/1bb2be0935d48153c67981476fc5046afa4b172f&lt;/a&gt; which can fix a bug that is known to prevent savepoint from completion.&lt;/p&gt;

&lt;p&gt;After applying the patch mentioned below, I have run StateMachineExample and believe the issues 1-5 has been fixed. Please see below for details.&lt;/p&gt;

&lt;p&gt;Note that for Issue 6, I could not reproduce the original issue and it is not clear which bug caused the original issue. So it may be useful to double check it with the test you used earlier.&lt;/p&gt;

&lt;p&gt;1) Testing Issue 1:&lt;br/&gt;
This behavior is expected. If no Kafka broker was reachable, KafkaConsumer (and thus KafkaSource) is expected to keep polling without throwing error.&lt;/p&gt;

&lt;p&gt;This behavior is reasonable because, when Kafka service goes offline due to either maintenance or failure, it is not helpful for KafkaConsumer to fail fast.&lt;/p&gt;

&lt;p&gt;2) Testing Issue 2:&lt;br/&gt;
I could start StateMachineExample and then stop it with savepoint successfully.&lt;/p&gt;

&lt;p&gt;3) Testing Issue 3:&lt;br/&gt;
The issue should be fixed by the commit &lt;a href=&quot;https://github.com/apache/flink/commit/4c6c42392e7d116dee572fefb2e4e0e02abacefb&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/commit/4c6c42392e7d116dee572fefb2e4e0e02abacefb&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;4) Testing Issue 4:&lt;br/&gt;
I could start StateMachineExample and then cancel it successfully. There is no ClassNotFoundException in log files.&lt;/p&gt;

&lt;p&gt;5) Testing Issue 5:&lt;br/&gt;
The issue should be fixed by the commit &lt;a href=&quot;https://github.com/apache/flink/commit/b23f65f17b4de16cf0fd91b225c3c3c61c849450&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/commit/b23f65f17b4de16cf0fd91b225c3c3c61c849450&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;6) Testing Issue 6:&lt;br/&gt;
I could create the flink-demo-topic-1 topic with 64 partitions and then start StateMachineExample successfully. &lt;/p&gt;
</comment>
                            <comment id="17327934" author="rmetzger" created="Thu, 22 Apr 2021 11:23:22 +0000"  >&lt;p&gt;Thanks a lot for your detailed follow up! I won&apos;t have time continuing the testing effort for this feature at the moment. &lt;/p&gt;</comment>
                            <comment id="17335189" author="till.rohrmann" created="Thu, 29 Apr 2021 07:14:50 +0000"  >&lt;p&gt;I am a bit confused &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jqin&quot; class=&quot;user-hover&quot; rel=&quot;jqin&quot;&gt;jqin&lt;/a&gt;. There is a PR which has been merged but it is not listed here. Moreover, the ticket is still open. Do we intend to do other improvements and that&apos;s why it is not closed?&lt;/p&gt;</comment>
                            <comment id="17335209" author="becket_qin" created="Thu, 29 Apr 2021 07:56:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;&#160;Sorry for the confusion. The ticket was left open because we were planning to backport the PR to release 1.12. But there are API changes so I started a discussion thread in the mailing list. The ticket can be closed once we reach consensus on whether it should be backported or not. I&apos;ll follow up on the mailing list thread.&lt;/p&gt;</comment>
                            <comment id="17339729" author="thw" created="Wed, 5 May 2021 15:50:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt;&#160;while testing with 1.12 I run into issues that were already fixed. I will back port these changes and open a PR against 1.12 as otherwise the new KafkaSource isn&apos;t very useful even for experimentation.&lt;/p&gt;</comment>
                            <comment id="17896560" author="adrian z" created="Fri, 8 Nov 2024 05:06:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt;&#160; may I ask two questions?&lt;/p&gt;

&lt;p&gt;background: recently I found that &lt;em&gt;Flink-sql-connector-kafka-1.13.5&lt;/em&gt; kafka source DDL style, checkpoint is &lt;b&gt;NOT&lt;/b&gt; enabled,&#160; I still can see consumer group defined by &lt;em&gt;properties.group.id&lt;/em&gt; values in Kafka. And when I change to flink-sql-connector-kafka-1.17.2, checkpoint must enabled otherwise consumer group will never seem. Developers offen look into consumer groups to see whether program works properly.&lt;/p&gt;

&lt;p&gt;The expected result will be Flink document, saying:&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;If checkpointing is not enabled, Kafka source relies on Kafka consumer&#8217;s internal automatic periodic offset committing logic, configured by&#160;enable.auto.commit&#160;and&#160;auto.commit.interval.ms&#160;in the properties of Kafka consumer.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The simplist kafka source DDL:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
CREATE TABLE KafkaTable (
  `user_id` BIGINT,
  `item_id` BIGINT,
  `behavior` STRING,
  `ts` TIMESTAMP(3) METADATA FROM &lt;span class=&quot;code-quote&quot;&gt;&apos;timestamp&apos;&lt;/span&gt;
) WITH (
  &lt;span class=&quot;code-quote&quot;&gt;&apos;connector&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;kafka&apos;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&apos;topic&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;user_behavior&apos;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&apos;properties.bootstrap.servers&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;localhost:9092&apos;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&apos;properties.group.id&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;testGroup&apos;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&apos;scan.startup.mode&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;latest-offset&apos;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&apos;format&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;json&apos;&lt;/span&gt;
) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Precondition: &lt;em&gt;group.id&lt;/em&gt; always provided.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Here&apos;re my questions:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;why the &lt;em&gt;enable.auto.commit&lt;/em&gt; behavior turned off by default (The Kafka officially says defaults to true if there group.id provided) which may cause user use must define expilicity true to the kafka source DDL. (naturely peolple won&apos;t set it)&lt;/li&gt;
	&lt;li&gt;It seems that this ticket takes effects earlier than 1.13.5, what causes the commiting to consumer group behaivor diffierence between Flink 1.13.5 and Flink 1.17.2. (no checkpoint enabled)?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;logic related:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/flink/pull/15161&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Github PR-15161&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.flink.connector.kafka.source.KafkaSourceBuilder:

maybeOverride(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;); &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;FlinkKafkaConsumer.java respect the default value (which is true) ,&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Override
&lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; getIsAutoCommitEnabled() {
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; getBoolean(properties, ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
            &amp;amp;&amp;amp; PropertiesUtil.getLong(
                            properties, ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000)
                    &amp;gt; 0;
} &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The OffsetCommitModes :&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;OffsetCommitModes {
...
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; OffsetCommitMode fromConfiguration(
            &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; enableAutoCommit,
            &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; enableCommitOnCheckpoint,
            &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; enableCheckpointing) {

        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (enableCheckpointing) {
            &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; checkpointing is enabled, the mode depends only on whether committing on
&lt;/span&gt;            &lt;span class=&quot;code-comment&quot;&gt;// checkpoints is enabled
&lt;/span&gt;            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (enableCommitOnCheckpoint)
                    ? OffsetCommitMode.ON_CHECKPOINTS
                    : OffsetCommitMode.DISABLED;
        } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
            &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;, the mode depends only on whether auto committing is enabled in the provided
&lt;/span&gt;            &lt;span class=&quot;code-comment&quot;&gt;// Kafka properties
&lt;/span&gt;            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (enableAutoCommit) ? OffsetCommitMode.KAFKA_PERIODIC : OffsetCommitMode.DISABLED;
        }
    }
} &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17896853" author="becket_qin" created="Sat, 9 Nov 2024 06:46:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;why the&#160;&lt;em&gt;enable.auto.commit&lt;/em&gt;&#160;behavior turned off by default (The Kafka officially says defaults to true if there group.id provided) which may cause user use must define expilicity true to the kafka source DDL. (naturely peolple won&apos;t set it)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The idea is to associate the offset commit with the Flink checkpoint to avoid the rewind in committed offset. So the Flink job will only commit an offset after a checkpoint has succeeded. Otherwise, what could happen is after a job failover, the committed offset may go back because the job resets to the last successful checkpoint. By default checkpoint is enabled in Flink. So by default the offsets will be committed to Kafka.&lt;/p&gt;

&lt;p&gt;When checkpoint is disabled, to make sure of the same semantic of when checkpoint is enabled, by default no offset is committed unless user explicitly specifies to do so. But I can understand the argument that if checkpoint is disabled, default Kafka behavior should be honored. So both behavior has their own point. But from backwards compatibility perspective, I think keep the behavior the same as &lt;tt&gt;LiKafkaConsumer&lt;/tt&gt; makes sense.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;It seems that this ticket takes effects earlier than 1.13.5, what causes the commiting to consumer group behaivor diffierence between Flink 1.13.5 and Flink 1.17.2. (no checkpoint enabled)?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am not sure about this.&lt;/p&gt;</comment>
                            <comment id="17897063" author="adrian z" created="Mon, 11 Nov 2024 02:32:26 +0000"  >&lt;p&gt;I just found &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt;&#160; are the implement author of new Kafka Source, since 1.12.0.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt; Thanks for your answer. I will figure out the answer of consumer behavior.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I just created a new issue &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-36674&quot; title=&quot;Flink will not commit to kafka if checkpointing is not enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-36674&quot;&gt;FLINK-36674&lt;/a&gt; Flink will not commit to kafka if checkpointing is not enabled - ASF Jira&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="13339891">FLINK-20081</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13341085">FLINK-20193</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13341089">FLINK-20194</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13598159">FLINK-36674</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13598159">FLINK-36674</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13468640">FLINK-28266</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13015938" name="Screenshot 2020-11-24 at 15.14.35.png" size="88186" author="rmetzger" created="Tue, 24 Nov 2020 14:15:24 +0000"/>
                            <attachment id="13015940" name="first-run.tgz" size="307185" author="rmetzger" created="Tue, 24 Nov 2020 14:28:17 +0000"/>
                            <attachment id="13015939" name="second-run.tgz" size="196091" author="rmetzger" created="Tue, 24 Nov 2020 14:28:17 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0kiy8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>