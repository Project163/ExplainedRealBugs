<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:58:41 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-23188] Unsupported function definition: IFNULL. Only user defined functions are supported as inline functions</title>
                <link>https://issues.apache.org/jira/browse/FLINK-23188</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;CREATE TABLE database0_t0(&lt;br/&gt;
c0 FLOAT&lt;br/&gt;
) WITH (&lt;br/&gt;
&#160; &apos;connector&apos; = &apos;filesystem&apos;,&lt;br/&gt;
&#160; &apos;path&apos; = &apos;hdfs:///tmp/database0_t0.csv&apos;,&lt;br/&gt;
&#160; &apos;format&apos; = &apos;csv&apos;&lt;br/&gt;
);&lt;br/&gt;
INSERT OVERWRITE database0_t0(c0) VALUES(0.40445197);&lt;/p&gt;

&lt;p&gt;SELECT database0_t0.c0 AS ref0 FROM database0_t0 WHERE&#160;((IFNULL(database0_t0.c1, database0_t0.c1)) IS NULL);&lt;/p&gt;

&lt;p&gt;The errors:&lt;br/&gt;
&quot;&amp;lt;Exception&#160;on&#160;server&#160;side: org.apache.flink.table.api.TableException:&#160;Unsupported&#160;function&#160;definition:&#160;IFNULL.&#160;Only&#160;user&#160;defined&#160;functions&#160;are&#160;supported&#160;as&#160;inline&#160;functions. &#160;at&#160;org.apache.flink.table.planner.functions.bridging.BridgingUtils.lambda$createInlineFunctionName$0(BridgingUtils.java:81) &#160;at&#160;java.util.Optional.orElseThrow(Optional.java:290) &#160;at&#160;org.apache.flink.table.planner.functions.bridging.BridgingUtils.createInlineFunctionName(BridgingUtils.java:78) &#160;at&#160;org.apache.flink.table.planner.functions.bridging.BridgingUtils.createName(BridgingUtils.java:58) &#160;at&#160;org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction.&amp;lt;init&amp;gt;(BridgingSqlFunction.java:76) &#160;at&#160;org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction.of(BridgingSqlFunction.java:116) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.FunctionDefinitionConvertRule.convert(FunctionDefinitionConvertRule.java:65) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.ExpressionConverter.visit(ExpressionConverter.java:97) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.ExpressionConverter.visit(ExpressionConverter.java:71) &#160;at&#160;org.apache.flink.table.expressions.CallExpression.accept(CallExpression.java:134) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.ExpressionConverter$1.toRexNode(ExpressionConverter.java:247) &#160;at&#160;java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) &#160;at&#160;java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) &#160;at&#160;java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) &#160;at&#160;java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) &#160;at&#160;java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) &#160;at&#160;java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) &#160;at&#160;java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.ExpressionConverter.toRexNodes(ExpressionConverter.java:240) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.DirectConvertRule.lambda$convert$0(DirectConvertRule.java:220) &#160;at&#160;java.util.Optional.map(Optional.java:215) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.DirectConvertRule.convert(DirectConvertRule.java:217) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.ExpressionConverter.visit(ExpressionConverter.java:97) &#160;at&#160;org.apache.flink.table.planner.expressions.converter.ExpressionConverter.visit(ExpressionConverter.java:71) &#160;at&#160;org.apache.flink.table.expressions.CallExpression.accept(CallExpression.java:134) &#160;at&#160;org.apache.flink.table.planner.plan.rules.logical.PushFilterIntoSourceScanRuleBase.lambda$convertExpressionToRexNode$0(PushFilterIntoSourceScanRuleBase.java:73) &#160;at&#160;java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) &#160;at&#160;java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) &#160;at&#160;java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) &#160;at&#160;java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) &#160;at&#160;java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) &#160;at&#160;java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) &#160;at&#160;java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) &#160;at&#160;org.apache.flink.table.planner.plan.rules.logical.PushFilterIntoSourceScanRuleBase.convertExpressionToRexNode(PushFilterIntoSourceScanRuleBase.java:73) &#160;at&#160;org.apache.flink.table.planner.plan.rules.logical.PushFilterIntoSourceScanRuleBase.resolveFiltersAndCreateTableSourceTable(PushFilterIntoSourceScanRuleBase.java:116) &#160;at&#160;org.apache.flink.table.planner.plan.rules.logical.PushFilterIntoTableSourceScanRule.pushFilterIntoScan(PushFilterIntoTableSourceScanRule.java:95) &#160;at&#160;org.apache.flink.table.planner.plan.rules.logical.PushFilterIntoTableSourceScanRule.onMatch(PushFilterIntoTableSourceScanRule.java:70) &#160;at&#160;org.apache.calcite.plan.AbstractRelOptPlanner.fireRule(AbstractRelOptPlanner.java:333) &#160;at&#160;org.apache.calcite.plan.hep.HepPlanner.applyRule(HepPlanner.java:542) &#160;at&#160;org.apache.calcite.plan.hep.HepPlanner.applyRules(HepPlanner.java:407) &#160;at&#160;org.apache.calcite.plan.hep.HepPlanner.executeInstruction(HepPlanner.java:243) &#160;at&#160;org.apache.calcite.plan.hep.HepInstruction$RuleInstance.execute(HepInstruction.java:127) &#160;at&#160;org.apache.calcite.plan.hep.HepPlanner.executeProgram(HepPlanner.java:202) &#160;at&#160;org.apache.calcite.plan.hep.HepPlanner.findBestExp(HepPlanner.java:189) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkHepProgram.optimize(FlinkHepProgram.scala:69) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgram.optimize(FlinkHepRuleSetProgram.scala:87) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram$$anonfun$optimize$1$$anonfun$apply$1.apply(FlinkGroupProgram.scala:63) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram$$anonfun$optimize$1$$anonfun$apply$1.apply(FlinkGroupProgram.scala:60) &#160;at&#160;scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157) &#160;at&#160;scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157) &#160;at&#160;scala.collection.Iterator$class.foreach(Iterator.scala:891) &#160;at&#160;scala.collection.AbstractIterator.foreach(Iterator.scala:1334) &#160;at&#160;scala.collection.IterableLike$class.foreach(IterableLike.scala:72) &#160;at&#160;scala.collection.AbstractIterable.foreach(Iterable.scala:54) &#160;at&#160;scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157) &#160;at&#160;scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram$$anonfun$optimize$1.apply(FlinkGroupProgram.scala:60) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram$$anonfun$optimize$1.apply(FlinkGroupProgram.scala:55) &#160;at&#160;scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157) &#160;at&#160;scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157) &#160;at&#160;scala.collection.immutable.Range.foreach(Range.scala:160) &#160;at&#160;scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157) &#160;at&#160;scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram.optimize(FlinkGroupProgram.scala:55) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram$$anonfun$optimize$1.apply(FlinkChainedProgram.scala:62) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram$$anonfun$optimize$1.apply(FlinkChainedProgram.scala:58) &#160;at&#160;scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157) &#160;at&#160;scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157) &#160;at&#160;scala.collection.Iterator$class.foreach(Iterator.scala:891) &#160;at&#160;scala.collection.AbstractIterator.foreach(Iterator.scala:1334) &#160;at&#160;scala.collection.IterableLike$class.foreach(IterableLike.scala:72) &#160;at&#160;scala.collection.AbstractIterable.foreach(Iterable.scala:54) &#160;at&#160;scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157) &#160;at&#160;scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram.optimize(FlinkChainedProgram.scala:57) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.BatchCommonSubGraphBasedOptimizer.optimizeTree(BatchCommonSubGraphBasedOptimizer.scala:87) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.BatchCommonSubGraphBasedOptimizer.org$apache$flink$table$planner$plan$optimize$BatchCommonSubGraphBasedOptimizer$$optimizeBlock(BatchCommonSubGraphBasedOptimizer.scala:58) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.BatchCommonSubGraphBasedOptimizer$$anonfun$doOptimize$1.apply(BatchCommonSubGraphBasedOptimizer.scala:46) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.BatchCommonSubGraphBasedOptimizer$$anonfun$doOptimize$1.apply(BatchCommonSubGraphBasedOptimizer.scala:46) &#160;at&#160;scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) &#160;at&#160;scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.BatchCommonSubGraphBasedOptimizer.doOptimize(BatchCommonSubGraphBasedOptimizer.scala:46) &#160;at&#160;org.apache.flink.table.planner.plan.optimize.CommonSubGraphBasedOptimizer.optimize(CommonSubGraphBasedOptimizer.scala:93) &#160;at&#160;org.apache.flink.table.planner.delegation.PlannerBase.optimize(PlannerBase.scala:310) &#160;at&#160;org.apache.flink.table.planner.delegation.PlannerBase.translate(PlannerBase.scala:172) &#160;at&#160;com.ververica.flink.table.gateway.operation.SelectOperation.lambda$executeQueryInternal$0(SelectOperation.java:183) &#160;at&#160;com.ververica.flink.table.gateway.context.ExecutionContext.wrapClassLoader(ExecutionContext.java:130) &#160;at&#160;com.ververica.flink.table.gateway.operation.SelectOperation.executeQueryInternal(SelectOperation.java:182) &#160;at&#160;com.ververica.flink.table.gateway.operation.SelectOperation.execute(SelectOperation.java:82) &#160;at&#160;com.ververica.flink.table.gateway.operation.executor.OneByOneOperationExecutor.execute(OneByOneOperationExecutor.java:57) &#160;at&#160;com.ververica.flink.table.gateway.rest.session.Session.lambda$runStatement$1(Session.java:115) &#160;at&#160;com.ververica.flink.table.gateway.utils.EnvironmentUtil.lambda$wrapWithHadoopUsernameIfNeeded$0(EnvironmentUtil.java:57) &#160;at&#160;com.ververica.flink.table.gateway.utils.EnvironmentUtil.wrapWithHadoopUsernameIfNeeded(EnvironmentUtil.java:65) &#160;at&#160;com.ververica.flink.table.gateway.utils.EnvironmentUtil.wrapWithHadoopUsernameIfNeeded(EnvironmentUtil.java:56) &#160;at&#160;com.ververica.flink.table.gateway.rest.session.Session.runStatement(Session.java:114) &#160;at&#160;com.ververica.flink.table.gateway.rest.handler.StatementExecuteHandler.handleRequest(StatementExecuteHandler.java:83) &#160;at&#160;com.ververica.flink.table.gateway.rest.handler.AbstractRestHandler.respondToRequest(AbstractRestHandler.java:85) &#160;at&#160;com.ververica.flink.table.gateway.rest.handler.AbstractHandler.channelRead0(AbstractHandler.java:184) &#160;at&#160;com.ververica.flink.table.gateway.rest.handler.AbstractHandler.channelRead0(AbstractHandler.java:76) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) &#160;at&#160;org.apache.flink.runtime.rest.handler.router.RouterHandler.routed(RouterHandler.java:115) &#160;at&#160;org.apache.flink.runtime.rest.handler.router.RouterHandler.channelRead0(RouterHandler.java:94) &#160;at&#160;org.apache.flink.runtime.rest.handler.router.RouterHandler.channelRead0(RouterHandler.java:55) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) &#160;at&#160;org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(FileUploadHandler.java:208) &#160;at&#160;org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(FileUploadHandler.java:69) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) &#160;at&#160;org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) &#160;at&#160;java.lang.Thread.run(Thread.java:834) End&#160;of&#160;exception&#160;on&#160;server&#160;side&amp;gt;&quot;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13386629">FLINK-23188</key>
            <summary>Unsupported function definition: IFNULL. Only user defined functions are supported as inline functions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="airblader">Ingo B&#252;rk</assignee>
                                    <reporter username="xiaojin.wy">xiaojin.wy</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 30 Jun 2021 02:26:48 +0000</created>
                <updated>Thu, 23 Sep 2021 18:03:47 +0000</updated>
                            <resolved>Thu, 15 Jul 2021 10:13:29 +0000</resolved>
                                    <version>1.14.0</version>
                                    <fixVersion>1.14.0</fixVersion>
                    <fixVersion>1.13.2</fixVersion>
                                    <component>Table SQL / Planner</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17371860" author="airblader" created="Wed, 30 Jun 2021 07:25:11 +0000"  >&lt;p&gt;Thanks for reporting this issue. It seems this is related to the filter being pushed into the source. It&apos;d probably be easy enough to treat specialized functions separately in createInlineFunctionName, but I&apos;m not sure if this would be fixing a problem or treating a symptom. I&apos;ll dig into this.&lt;/p&gt;</comment>
                            <comment id="17371984" author="airblader" created="Wed, 30 Jun 2021 12:54:37 +0000"  >&lt;p&gt;Reproduction test case for `CalcITCase`:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Test
def test23188(): Unit = {
  val tableId = TestValuesTableFactory.registerData(Seq())

  tEnv.executeSql(s&quot;&quot;&quot;
                     |CREATE TABLE T (
                     |  f0 INT
                     |) WITH (
                     |  &lt;span class=&quot;code-quote&quot;&gt;&apos;connector&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;values&apos;&lt;/span&gt;,
                     |  &lt;span class=&quot;code-quote&quot;&gt;&apos;data-id&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;$tableId&apos;&lt;/span&gt;,
                     |  &lt;span class=&quot;code-quote&quot;&gt;&apos;bounded&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;&lt;/span&gt;
                     |)
     &quot;&quot;&quot;.stripMargin)

  tEnv.sqlQuery(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT f0 AS ref0 FROM T WHERE ((IFNULL(f0, f0)) IS NULL)&quot;&lt;/span&gt;).execute()
    .collect().toList
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17372005" author="airblader" created="Wed, 30 Jun 2021 13:34:54 +0000"  >&lt;p&gt;The following patch fixes it, but will have to discuss this first.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingUtils.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingUtils.java
index 541c998e0c..798a6d970e 100644
--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingUtils.java
+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingUtils.java
@@ -22,6 +22,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.api.TableException;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.catalog.DataTypeFactory;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.catalog.ObjectIdentifier;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.functions.AggregateFunctionDefinition;
+&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.functions.BuiltInFunctionDefinition;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.functions.FunctionDefinition;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.functions.FunctionIdentifier;
 &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.flink.table.functions.ScalarFunctionDefinition;
@@ -70,6 +71,10 @@ &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;BridgingUtils {
     }
 
     &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; createInlineFunctionName(FunctionDefinition functionDefinition) {
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (functionDefinition &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; BuiltInFunctionDefinition) {
+            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ((BuiltInFunctionDefinition) functionDefinition).getName();
+        }
+
         &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Optional&amp;lt;UserDefinedFunction&amp;gt; userDefinedFunction =
                 extractUserDefinedFunction(functionDefinition);
 
@@ -101,6 +106,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;BridgingUtils {
                     ((TableAggregateFunctionDefinition) functionDefinition)
                             .getTableAggregateFunction());
         }
+
         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Optional.empty();
     }
 

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17375572" author="airblader" created="Tue, 6 Jul 2021 11:26:34 +0000"  >&lt;p&gt;It seems that the functionIdentifier should in fact be set, and isn&apos;t because due to the filter pushdown there&apos;s a conversion step from RexNode to Expression which loses the functionIdentifier when later on it gets converted back to RexNode. The following fix is probably more appropriate, will look into it more:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/utils/RexNodeExtractor.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/utils/RexNodeExtractor.scala
index 3d8b8a4f6e..3401c1a1be 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/utils/RexNodeExtractor.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/utils/RexNodeExtractor.scala
@@ -532,7 +532,8 @@ &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;RexNodeToExpressionConverter(
     Try(functionCatalog.lookupFunction(identifier)) match {
       &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; Success(f: java.util.Optional[FunctionLookup.Result]) =&amp;gt;
         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (f.isPresent) {
-          Some(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CallExpression(f.get().getFunctionDefinition, operands, outputType))
+          Some(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CallExpression(f.get().getFunctionIdentifier, f.get().getFunctionDefinition,
+            operands, outputType))
         } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
           None
         }

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17380676" author="twalthr" created="Wed, 14 Jul 2021 15:07:17 +0000"  >&lt;p&gt;Fixed in 1.14.0: 7c64b245278704764254bb4287ec256f60704dfc&lt;/p&gt;

&lt;p&gt;I&apos;m currently investigating if we can safely merge the fix also to 1.13.&lt;/p&gt;</comment>
                            <comment id="17381228" author="twalthr" created="Thu, 15 Jul 2021 10:13:29 +0000"  >&lt;p&gt;Fixed in 1.13.3: 1db1112fa0e5e5e51be00e2b0bdceab76d5ce3e3&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 17 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0sfko:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>