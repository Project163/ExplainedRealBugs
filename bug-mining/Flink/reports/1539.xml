<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:27:20 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-4660] HadoopFileSystem (with S3A) may leak connections, which cause job to stuck in a restarting loop</title>
                <link>https://issues.apache.org/jira/browse/FLINK-4660</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Flink job with checkpoints enabled and configured to use S3A file system backend, sometimes experiences checkpointing failure due to S3 consistency issue. This behavior is also reported by other people and documented in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4218&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-4218&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This problem gets magnified by current HadoopFileSystem implementation, which can potentially leak S3 client connections, and eventually get into a restarting loop with &#8220;Timeout waiting for a connection from pool&#8221; exception thrown from aws client.&lt;/p&gt;

&lt;p&gt;I looked at the code, seems HadoopFileSystem.java never invoke close() method on fs object upon failure, but the FileSystem may be re-initialized every time the job gets restarted.&lt;/p&gt;

&lt;p&gt;A few evidence I observed:&lt;br/&gt;
1. When I set the connection pool limit to 128, and below commands shows 128 connections are stuck in CLOSE_WAIT state.&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;float: left&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12829668/12829668_Screen+Shot+2016-09-20+at+2.49.14+PM.png&quot; vspace=&quot;5&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt; &lt;/p&gt;


&lt;p&gt;2. task manager logs indicates that state backend file system consistently getting initialized upon job restarting.&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12829669/12829669_Screen+Shot+2016-09-20+at+2.49.32+PM.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;3. Log indicates there is NPE during cleanning up of stream task which was caused by &#8220;Timeout waiting for connection from pool&#8221; exception when trying to create a directory in S3 bucket.&lt;br/&gt;
2016-09-02 08:17:50,886 ERROR org.apache.flink.streaming.runtime.tasks.StreamTask - Error during cleanup of stream task&lt;br/&gt;
java.lang.NullPointerException&lt;br/&gt;
at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.cleanup(OneInputStreamTask.java:73)&lt;br/&gt;
at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:323)&lt;br/&gt;
at org.apache.flink.runtime.taskmanager.Task.run(Task.java:589)&lt;br/&gt;
at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;4.It appears StreamTask from invoking checkpointing operation, to handling failure, there is no logic associated with closing Hadoop File System object (which internally includes S3 aws client object), which resides in HadoopFileSystem.java.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13006627">FLINK-4660</key>
            <summary>HadoopFileSystem (with S3A) may leak connections, which cause job to stuck in a restarting loop</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="zhenzhongxu">Zhenzhong Xu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Sep 2016 19:44:22 +0000</created>
                <updated>Wed, 2 Oct 2019 17:44:49 +0000</updated>
                            <resolved>Fri, 6 Oct 2017 17:03:31 +0000</resolved>
                                                    <fixVersion>1.3.2</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="15513227" author="stephanewen" created="Thu, 22 Sep 2016 12:55:05 +0000"  >&lt;p&gt;We looked through this a bit, and the problem may be something else. Flink does not close the &lt;tt&gt;FileSystem&lt;/tt&gt; objects, but it also caches them, so there should be only one &lt;tt&gt;FileSystem&lt;/tt&gt; object per TaskManager.&lt;br/&gt;
The connections you see as open may be &lt;tt&gt;FsDataInputStream&lt;/tt&gt; connections to S3, reloading the state. Previous versions of Flink did not ensure that the streams were closes in case that the recovery was intercepted by another failure (such as File Not Found due to eventual consistency).&lt;/p&gt;

&lt;p&gt;The latest version of Flink more thoroughly closes these streams. Can you check if that fixes your problem?&lt;/p&gt;

&lt;p&gt;For the eventual consistency issue, let&apos;s continue the discussion in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4218&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-4218&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15514015" author="zimmermatt" created="Thu, 22 Sep 2016 18:02:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt; We last tested with latest on master as of 9/6.  Should it have been there then?&lt;/p&gt;

&lt;p&gt;In the mean time, we&apos;ll try to test with latest as of today, time allowing.&lt;/p&gt;</comment>
                            <comment id="15515997" author="stephanewen" created="Fri, 23 Sep 2016 09:51:57 +0000"  >&lt;p&gt;It should have been fixed as of 2 days ago: &lt;a href=&quot;https://github.com/apache/flink/commit/3b8fe95ec728d59e3ffba2901450c56d7cca2b24&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/commit/3b8fe95ec728d59e3ffba2901450c56d7cca2b24&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15872727" author="zhenzhongxu" created="Fri, 17 Feb 2017 23:24:17 +0000"  >&lt;p&gt;This is fixed,closing.&lt;/p&gt;</comment>
                            <comment id="16180517" author="soniclavier" created="Tue, 26 Sep 2017 09:08:39 +0000"  >&lt;p&gt;in which version is this fixed? I am using 1.3.1 and getting similar exception when reading input split from S3.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2017-09-26 08:47:27,220 INFO  org.apache.flink.api.common.io.LocatableInputSplitAssigner    - Assigning remote split to host ip-10-150-98-185
2017-09-26 08:47:27,344 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN DataSource (at .......Job$$anonfun$main$4$$anonfun$apply$3.apply(Job.scala:138) (org.apache.flink.api.java.io.TextInputFormat)) -&amp;gt; FlatMap (FlatMap at ......sources.SourceSelector$.selectSource(SourceSelector.scala:17)) -&amp;gt; Map (from: ....) (6/8) (df8e44219270f80170e6d027b77b246f) switched from RUNNING to FAILED.
com.amazonaws.SdkClientException: Unable to execute HTTP request: Timeout waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; connection from pool
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:972)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:676)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:650)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:633)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$300(AmazonHttpClient.java:601)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:583)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:447)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4137)
	at com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1346)
	at io.grhodes.hadoop.fs.s3a.S3AInputStream.reopen(S3AInputStream.java:72)
	at io.grhodes.hadoop.fs.s3a.S3AInputStream.openIfNeeded(S3AInputStream.java:43)
	at io.grhodes.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:137)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.read(HadoopDataInputStream.java:72)
	at org.apache.flink.api.common.io.DelimitedInputFormat.fillBuffer(DelimitedInputFormat.java:669)
	at org.apache.flink.api.common.io.DelimitedInputFormat.open(DelimitedInputFormat.java:490)
	at org.apache.flink.api.common.io.DelimitedInputFormat.open(DelimitedInputFormat.java:48)
	at org.apache.flink.runtime.operators.DataSourceTask.invoke(DataSourceTask.java:145)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:702)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; connection from pool
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:286)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:263)
	at sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.amazonaws.http.conn.ClientConnectionRequestFactory$Handler.invoke(ClientConnectionRequestFactory.java:70)
	at com.amazonaws.http.conn.$Proxy16.get(Unknown Source)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:190)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:82)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at com.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1115)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:964)
	... 19 more
2017-09-26 08:47:27,345 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Job Job_at_09/26/2017_08:44:08 (74a0b9f0eab746705ad88817849e5c4b) switched from state RUNNING to FAILING.
com.amazonaws.SdkClientException: Unable to execute HTTP request: Timeout waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; connection from pool
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:972)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:676)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:650)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:633)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$300(AmazonHttpClient.java:601)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:583)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:447)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4137)
	at com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:1346)
	at io.grhodes.hadoop.fs.s3a.S3AInputStream.reopen(S3AInputStream.java:72)
	at io.grhodes.hadoop.fs.s3a.S3AInputStream.openIfNeeded(S3AInputStream.java:43)
	at io.grhodes.hadoop.fs.s3a.S3AInputStream.read(S3AInputStream.java:137)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.read(HadoopDataInputStream.java:72)
	at org.apache.flink.api.common.io.DelimitedInputFormat.fillBuffer(DelimitedInputFormat.java:669)
	at org.apache.flink.api.common.io.DelimitedInputFormat.open(DelimitedInputFormat.java:490)
	at org.apache.flink.api.common.io.DelimitedInputFormat.open(DelimitedInputFormat.java:48)
	at org.apache.flink.runtime.operators.DataSourceTask.invoke(DataSourceTask.java:145)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:702)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; connection from pool
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.leaseConnection(PoolingHttpClientConnectionManager.java:286)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager$1.get(PoolingHttpClientConnectionManager.java:263)
	at sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.amazonaws.http.conn.ClientConnectionRequestFactory$Handler.invoke(ClientConnectionRequestFactory.java:70)
	at com.amazonaws.http.conn.$Proxy16.get(Unknown Source)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:190)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:82)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at com.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1115)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:964)
	... 19 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16194857" author="stephanewen" created="Fri, 6 Oct 2017 17:02:26 +0000"  >&lt;p&gt;This was part of the 1.3.2 release and will be part of the 1.4.0 release.&lt;/p&gt;</comment>
                            <comment id="16194859" author="stephanewen" created="Fri, 6 Oct 2017 17:02:54 +0000"  >&lt;p&gt;Reopening to assign proper fix version&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12989491">FLINK-4218</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12829668" name="Screen Shot 2016-09-20 at 2.49.14 PM.png" size="145952" author="zhenzhongxu" created="Wed, 21 Sep 2016 19:48:30 +0000"/>
                            <attachment id="12829669" name="Screen Shot 2016-09-20 at 2.49.32 PM.png" size="2570249" author="zhenzhongxu" created="Wed, 21 Sep 2016 19:48:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 6 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33x1j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Closing the reopened issue to update versions in which this is fixed</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>