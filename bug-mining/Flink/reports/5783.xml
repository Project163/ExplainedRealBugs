<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:01:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-23854] KafkaSink error when restart from the checkpoint with a lower parallelism by exactly-once guarantee</title>
                <link>https://issues.apache.org/jira/browse/FLINK-23854</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The KafkaSink throws the exception when restarted with a lower parallelism and the exactly-once guarantee. The exception is like this.&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.IllegalStateException: Internal error: It is expected that state from previous executions is distributed to the same subtask id.   
at org.apache.flink.util.Preconditions.checkState(Preconditions.java:193)   
at org.apache.flink.connector.kafka.sink.KafkaWriter.recoverAndInitializeState(KafkaWriter.java:178)   
at org.apache.flink.connector.kafka.sink.KafkaWriter.&amp;lt;init&amp;gt;(KafkaWriter.java:130)   
at org.apache.flink.connector.kafka.sink.KafkaSink.createWriter(KafkaSink.java:99)   
at org.apache.flink.streaming.runtime.operators.sink.SinkOperator.initializeState(SinkOperator.java:134)   
at org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.initializeOperatorState(StreamOperatorStateHandler.java:118)   
at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:286)   
at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.initializeStateAndOpenOperators(RegularOperatorChain.java:109)   
at org.apache.flink.streaming.runtime.tasks.StreamTask.restoreGates(StreamTask.java:690)   
at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.call(StreamTaskActionExecutor.java:55)   
at org.apache.flink.streaming.runtime.tasks.StreamTask.executeRestore(StreamTask.java:666)   
at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:785)   
at org.apache.flink.streaming.runtime.tasks.StreamTask.restore(StreamTask.java:638)   
at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:766)   
at org.apache.flink.runtime.taskmanager.Task.run(Task.java:572)   
at java.lang.Thread.run(Thread.java:748)    
Suppressed: java.lang.NullPointerException       
at org.apache.flink.streaming.runtime.operators.sink.SinkOperator.close(SinkOperator.java:195)       
at org.apache.flink.streaming.runtime.tasks.StreamOperatorWrapper.close(StreamOperatorWrapper.java:141)       
at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.closeAllOperators(RegularOperatorChain.java:127)       
at org.apache.flink.streaming.runtime.tasks.StreamTask.closeAllOperators(StreamTask.java:1028)       
at org.apache.flink.streaming.runtime.tasks.StreamTask.runAndSuppressThrowable(StreamTask.java:1014)       
at org.apache.flink.streaming.runtime.tasks.StreamTask.cleanUpInvoke(StreamTask.java:927)       
at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:797)        ... 4 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I start the kafka cluster(kafka_2.13-2.8.0) and the flink cluster in my own mac. I change the parallelism from 4 to 2 and restart the job from some completed checkpoint. Then the error occurs.&#160;&lt;/p&gt;

&lt;p&gt;And the cli command and the code are as follows.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// cli command
&lt;/span&gt;./bin/flink run -d -c com.test.KafkaExactlyOnceScaleDownTest -s /Users/test/checkpointDir/ExactlyOnceTest1/67105fcc1724e147fc6208af0dd90618/chk-1 /Users/test/project/self/target/test.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;KafkaExactlyOnceScaleDownTest { 
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception { 
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; kafkaSourceTopic = &lt;span class=&quot;code-quote&quot;&gt;&quot;flinkSourceTest&quot;&lt;/span&gt;; 
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; kafkaSinkTopic = &lt;span class=&quot;code-quote&quot;&gt;&quot;flinkSinkExactlyTest1&quot;&lt;/span&gt;; 
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; groupId = &lt;span class=&quot;code-quote&quot;&gt;&quot;ExactlyOnceTest1&quot;&lt;/span&gt;; 
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; brokers = &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost:9092&quot;&lt;/span&gt;; 
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; ckDir = &lt;span class=&quot;code-quote&quot;&gt;&quot;file:&lt;span class=&quot;code-comment&quot;&gt;///Users/test/checkpointDir/&quot;&lt;/span&gt; + groupId; 
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); 
    env.enableCheckpointing(60000); 
    env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);        
env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);
    env.getCheckpointConfig().setCheckpointStorage(ckDir); 
    env.setParallelism(4); 

    KafkaSource&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; source = KafkaSource.&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;builder() 
     .setBootstrapServers(brokers) 
     .setTopics(kafkaSourceTopic) 
     .setGroupId(groupId) 
     .setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &lt;span class=&quot;code-quote&quot;&gt;&quot;earliest&quot;&lt;/span&gt;) 
     .setValueOnlyDeserializer(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SimpleStringSchema()) 
     .build(); 

    DataStream&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; flintstones = env.fromSource(source, WatermarkStrategy.noWatermarks(), &lt;span class=&quot;code-quote&quot;&gt;&quot;Kafka Source&quot;&lt;/span&gt;); 
    DataStream&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; adults = flintstones.filter(s -&amp;gt; s != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; s.length() &amp;gt; 2); 
    Properties props = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Properties(); 
    props.setProperty(&lt;span class=&quot;code-quote&quot;&gt;&quot;transaction.timeout.ms&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;900000&quot;&lt;/span&gt;); 
    adults.sinkTo(KafkaSink.&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;builder() 
    .setBootstrapServers(brokers) 
    .setDeliverGuarantee(DeliveryGuarantee.EXACTLY_ONCE) 
    .setTransactionalIdPrefix(&lt;span class=&quot;code-quote&quot;&gt;&quot;tp-test-&quot;&lt;/span&gt;) 
    .setKafkaProducerConfig(props) 
    .setRecordSerializer(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SelfSerializationSchema(kafkaSinkTopic, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SimpleStringSchema())) 
    .build()); 

    env.execute(&lt;span class=&quot;code-quote&quot;&gt;&quot;ScaleDownTest&quot;&lt;/span&gt;); 
} 

&lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SelfSerializationSchema &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; KafkaRecordSerializationSchema&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; { &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; SerializationSchema&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; valueSerialization; &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; topic; SelfSerializationSchema(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; topic, SerializationSchema&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; valueSerialization){ &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.valueSerialization = valueSerialization; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.topic = topic; } @Override &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void open(SerializationSchema.InitializationContext context, KafkaSinkContext sinkContext) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception { KafkaRecordSerializationSchema.&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;.open(context, sinkContext); } @Override &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; ProducerRecord&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; serialize(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; s, KafkaSinkContext kafkaSinkContext, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; aLong) { &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] valueSerialized = valueSerialization.serialize(s); &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ProducerRecord&amp;lt;&amp;gt;(topic, valueSerialized); } } 
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13395837">FLINK-23854</key>
            <summary>KafkaSink error when restart from the checkpoint with a lower parallelism by exactly-once guarantee</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="arvid">Arvid Heise</assignee>
                                    <reporter username="ruanhang1993">Ruan Hang</reporter>
                        <labels>
                            <label>pull-request-available</label>
                            <label>release-testing</label>
                    </labels>
                <created>Wed, 18 Aug 2021 09:20:22 +0000</created>
                <updated>Tue, 29 Nov 2022 03:53:58 +0000</updated>
                            <resolved>Wed, 1 Sep 2021 06:29:59 +0000</resolved>
                                    <version>1.14.0</version>
                                    <fixVersion>1.14.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                                                                <comments>
                            <comment id="17401021" author="ruanhang1993" created="Wed, 18 Aug 2021 12:39:31 +0000"  >&lt;p&gt;After adding log in&#160;StatefulSinkWriterStateHandler class, the distribution of the operator state changes as follow.&#160;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;parallelism 4(before)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;parallelism 2(after)&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;subTask0 -&amp;gt; state0&lt;br/&gt;
 subTask1 -&amp;gt; state1&lt;br/&gt;
 subTask2 -&amp;gt; state2&lt;br/&gt;
 subTask3 -&amp;gt; state3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;subTask0 -&amp;gt; state0 &amp;amp; state1&lt;br/&gt;
 subTask1 - &amp;gt; state2 &amp;amp; state3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;Here are the log and the reult after changing to 2 parallelism.&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Add log in&#160;initializeState method of&#160;StatefulSinkWriterStateHandle&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;the log of subtask0&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;the log of subtask1&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; List&amp;lt;WriterStateT&amp;gt; initializeState(StateInitializationContext context) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ListState&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; rawState =
            context.getOperatorStateStore().getListState(WRITER_RAW_STATES_DESC);
    writerState =
            &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SimpleVersionedListState&amp;lt;&amp;gt;(rawState, writerStateSimpleVersionedSerializer);
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; List&amp;lt;WriterStateT&amp;gt; writerStates = CollectionUtil.iterableToList(writerState.get());
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; List&amp;lt;WriterStateT&amp;gt; states = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;(writerStates);

    &lt;span class=&quot;code-comment&quot;&gt;// add log
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;(WriterStateT stateT : states) {
        LOG.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Stateful Sink Writer state handler:&quot;&lt;/span&gt; + stateT.toString());
    }

    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; previousSinkStateName : previousSinkStateNames) {
        ......
    }
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; states;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2021-08-18 20:02:04,214 INFO org.apache.flink.streaming.runtime.operators.sink.StatefulSinkWriterStateHandler [] - Stateful Sink Writer state handler:KafkaWriterState{subtaskId=1, transactionalIdOffset=8, transactionalIdPrefix=&apos;tp-test-&apos;}&lt;br/&gt;
 2021-08-18 20:02:04,214 INFO org.apache.flink.streaming.runtime.operators.sink.StatefulSinkWriterStateHandler [] - Stateful Sink Writer state handler:KafkaWriterState{subtaskId=0, transactionalIdOffset=8, transactionalIdPrefix=&apos;tp-test-&apos;}&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2021-08-18 20:02:04,220 INFO org.apache.flink.streaming.runtime.operators.sink.StatefulSinkWriterStateHandler [] - Stateful Sink Writer state handler:KafkaWriterState{subtaskId=2, transactionalIdOffset=8, transactionalIdPrefix=&apos;tp-test-&apos;}&lt;br/&gt;
 2021-08-18 20:02:04,220 INFO org.apache.flink.streaming.runtime.operators.sink.StatefulSinkWriterStateHandler [] - Stateful Sink Writer state handler:KafkaWriterState{subtaskId=3, transactionalIdOffset=8, transactionalIdPrefix=&apos;tp-test-&apos;}&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
</comment>
                            <comment id="17401028" author="ruanhang1993" created="Wed, 18 Aug 2021 12:53:44 +0000"  >&lt;p&gt;And why do we need this check? I think the&#160;distribution behavior of the operator list state is fixed&#160;when the parallelism changes, just like the test shows.&lt;/p&gt;</comment>
                            <comment id="17403015" author="ruanhang1993" created="Mon, 23 Aug 2021 07:54:58 +0000"  >&lt;p&gt;Maybe I can work on it. I think the check aims at generating an unique transaction id for the topic. Maybe adding the attemptNum to the transaction prefix is a good solution.&lt;/p&gt;</comment>
                            <comment id="17407862" author="arvid" created="Wed, 1 Sep 2021 06:29:59 +0000"  >&lt;p&gt;Merged into master as f01c636aa4871590fb44f09e63aa97216277ff29..e396f4ab17f66ac6d631a2659746d1e55ad570a0.&lt;br/&gt;
Merged into 1.14 as 3076a23b1c7b14307160eba31af40bb4f4d72863..ba675e1ec8f2a6e90353988a80631ebad5668b56.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ruanhang1993&quot; class=&quot;user-hover&quot; rel=&quot;ruanhang1993&quot;&gt;ruanhang1993&lt;/a&gt; could you please retest with the current release-1.14. Sorry that it took so long to solve - we had to overhaul how we deal with lingering transactions.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13446903">FLINK-27787</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13396314">FLINK-23896</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0u0bc:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>