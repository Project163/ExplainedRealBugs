<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:38:35 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-11419] StreamingFileSink fails to recover after taskmanager failure</title>
                <link>https://issues.apache.org/jira/browse/FLINK-11419</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;If a job with a StreamingFileSink sending data to HDFS is running in a cluster with multiple taskmanagers and the taskmanager executing the job goes down (for some reason), when the other task manager start executing the job, it fails saying that there is some &quot;missing data in tmp file&quot; because it&apos;s not able to perform a truncate in the file.&lt;/p&gt;

&lt;p&gt;&#160;Here the full stack trace:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.io.IOException: Missing data in tmp file: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//path/to/hdfs/2019-01-20/.part-0-0.inprogress.823f9c20-3594-4fe3-ae8c-f57b6c35e191
&lt;/span&gt;	at org.apache.flink.runtime.fs.hdfs.HadoopRecoverableFsDataOutputStream.&amp;lt;init&amp;gt;(HadoopRecoverableFsDataOutputStream.java:93)
	at org.apache.flink.runtime.fs.hdfs.HadoopRecoverableWriter.recover(HadoopRecoverableWriter.java:72)
	at org.apache.flink.streaming.api.functions.sink.filesystem.Bucket.restoreInProgressFile(Bucket.java:140)
	at org.apache.flink.streaming.api.functions.sink.filesystem.Bucket.&amp;lt;init&amp;gt;(Bucket.java:127)
	at org.apache.flink.streaming.api.functions.sink.filesystem.Bucket.restore(Bucket.java:396)
	at org.apache.flink.streaming.api.functions.sink.filesystem.DefaultBucketFactoryImpl.restoreBucket(DefaultBucketFactoryImpl.java:64)
	at org.apache.flink.streaming.api.functions.sink.filesystem.Buckets.handleRestoredBucketState(Buckets.java:177)
	at org.apache.flink.streaming.api.functions.sink.filesystem.Buckets.initializeActiveBuckets(Buckets.java:165)
	at org.apache.flink.streaming.api.functions.sink.filesystem.Buckets.initializeState(Buckets.java:149)
	at org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink.initializeState(StreamingFileSink.java:334)
	at org.apache.flink.streaming.util.functions.StreamingFunctionUtils.tryRestoreFunction(StreamingFunctionUtils.java:178)
	at org.apache.flink.streaming.util.functions.StreamingFunctionUtils.restoreFunctionState(StreamingFunctionUtils.java:160)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.initializeState(AbstractUdfStreamOperator.java:96)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:278)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeState(StreamTask.java:738)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:289)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:704)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to TRUNCATE_FILE /path/to/hdfs/2019-01-20/.part-0-0.inprogress.823f9c20-3594-4fe3-ae8c-f57b6c35e191 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_NONMAPREDUCE_-2103482360_62 on x.xxx.xx.xx because &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; file lease is currently owned by DFSClient_NONMAPREDUCE_1834204750_59 on x.xx.xx.xx
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3190)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.truncateInternal(FSNamesystem.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.truncateInt(FSNamesystem.java:2228)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.truncate(FSNamesystem.java:2198)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.truncate(NameNodeRpcServer.java:1056)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.truncate(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2347)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	at org.apache.hadoop.ipc.Client.call(Client.java:1345)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy49.truncate(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.truncate(ClientNamenodeProtocolTranslatorPB.java:314)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy50.truncate(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.truncate(DFSClient.java:1632)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:777)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:774)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.truncate(DistributedFileSystem.java:774)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.fs.hdfs.HadoopRecoverableFsDataOutputStream.truncate(HadoopRecoverableFsDataOutputStream.java:179)
	at org.apache.flink.runtime.fs.hdfs.HadoopRecoverableFsDataOutputStream.&amp;lt;init&amp;gt;(HadoopRecoverableFsDataOutputStream.java:91)
	... 17 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I noticed there is already some code to handle this kind of situations, I also compared to BucketingSink (as there is no issue with BucketingSink) and I noticed that in the StreamingFileSink the &quot;truncate&quot; is done before waiting until the lease&#160;of the file is free... whereas in the BucketingSink the &quot;truncate&quot; is done after waiting for the lease is free.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;For reference:&#160;&lt;br/&gt;
 BucketingSink:&#160;&lt;a href=&quot;https://github.com/apache/flink/blob/release-1.7.1/flink-connectors/flink-connector-filesystem/src/main/java/org/apache/flink/streaming/connectors/fs/bucketing/BucketingSink.java#L830-L853&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/blob/release-1.7.1/flink-connectors/flink-connector-filesystem/src/main/java/org/apache/flink/streaming/connectors/fs/bucketing/BucketingSink.java#L830-L853&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;StreaminFileSink:&#160;&lt;a href=&quot;https://github.com/apache/flink/blob/release-1.7.1/flink-filesystems/flink-hadoop-fs/src/main/java/org/apache/flink/runtime/fs/hdfs/HadoopRecoverableFsDataOutputStream.java#L89-L96&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/blob/release-1.7.1/flink-filesystems/flink-hadoop-fs/src/main/java/org/apache/flink/runtime/fs/hdfs/HadoopRecoverableFsDataOutputStream.java#L89-L96&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13211344">FLINK-11419</key>
            <summary>StreamingFileSink fails to recover after taskmanager failure</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="edRojas">Edward Rojas</assignee>
                                    <reporter username="edRojas">Edward Rojas</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 23 Jan 2019 18:15:53 +0000</created>
                <updated>Wed, 2 Oct 2019 17:44:40 +0000</updated>
                            <resolved>Mon, 4 Feb 2019 10:02:57 +0000</resolved>
                                    <version>1.7.1</version>
                                    <fixVersion>1.7.2</fixVersion>
                    <fixVersion>1.8.0</fixVersion>
                                    <component>Connectors / FileSystem</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1200">20m</timespent>
                                <comments>
                            <comment id="16750967" author="kkl0u" created="Thu, 24 Jan 2019 10:10:56 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=edRojas&quot; class=&quot;user-hover&quot; rel=&quot;edRojas&quot;&gt;edRojas&lt;/a&gt;. Thanks for reporting this. &lt;/p&gt;

&lt;p&gt;I would assume that if the only problem is the lease not being released yet, then if you restart the job after a while it will start normally, and without any problems.&lt;/p&gt;

&lt;p&gt;If it does not, then are you sure that there is no other task manager writing to the same file? This can happen in the following cases:&lt;br/&gt;
1) if 2 jobs write to the same bucket or &lt;br/&gt;
2) if there are Task Managers from a previous execution of the job that are still running.&lt;/p&gt;

&lt;p&gt;Can you see if restarting the job fixes the problem? &lt;/p&gt;</comment>
                            <comment id="16750971" author="kkl0u" created="Thu, 24 Jan 2019 10:15:34 +0000"  >&lt;p&gt;In any case, from your report it seems that the initial message &quot;Missing data in tmp &lt;a href=&quot;file:&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:&lt;/a&gt;...&quot; is misleading and the truncate may have to move after the waiting for the lease to be released.&lt;/p&gt;</comment>
                            <comment id="16753965" author="edrojas" created="Mon, 28 Jan 2019 12:39:53 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt;, I performed several tests and even waiting for several minutes, when trying to restart the job from latest successful checkpoint (in order to don&apos;t lose state) the error continues to appear.&#160;&lt;/p&gt;

&lt;p&gt;When waiting for several minutes the error is a little different, instead of a &quot;AlreadyBeingCreatedException&quot; I get a &quot;RecoveryInProgressException&quot;.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.RecoveryInProgressException): Failed to TRUNCATE_FILE /path/to/hdfs/2019-01-27/.part-0-0.inprogress.c1cab2ae-fd85-48b9-8441-a36af02225ca &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; DFSClient_NONMAPREDUCE_187299180_62 on xx.x.x.x because lease recovery is in progress. Try again later.
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2437)
at org.apache.hadoop.hdfs.server.namenode.FSDirTruncateOp.truncate(FSDirTruncateOp.java:111)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.truncate(FSNamesystem.java:2056)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.truncate(NameNodeRpcServer.java:1043)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.truncate(ClientNamenodeProtocolServerSideTranslatorPB.java:629)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:868)
at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:814)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1886)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2603)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The cluster is configured with a &quot;Fixed Delay&quot; restart strategy and the next time the job is restarted, I get the error with the &quot;AlreadyBeingCreatedException&quot;.&lt;/p&gt;

&lt;p&gt;The error continues appearing even waiting for an hour to restart... and even if this could have solved the issue, we cannot afford to wait that longer to restart the job.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I verified that there is no other job writing to the same bucket and that there is no other taskmanager from previous executions running.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I&apos;m also able to reproduce the issue running everything in local, a Flink cluster with one jobmanager and 2 taskmanagers, local kafka and local HDFS. I send events to kafka and the job starts writing into HDFS, then I kill one taskmanager and when the other takes over, the Error occurs.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;When using the BucketingSink I don&apos;t have any issue. The other taskmanager takes over and continue without any problem.&lt;/p&gt;</comment>
                            <comment id="16754066" author="edrojas" created="Mon, 28 Jan 2019 15:12:48 +0000"  >&lt;p&gt;I performed more tests now by doing the modification I proposed in the description of the issue, this is by&#160;waiting for the lease to be released before trying to perform the truncate and with this the tests are successful.&#160; This is solving the issue in my use case and test scenario.&lt;/p&gt;

&lt;p&gt;I will issue a pull request for this.&lt;/p&gt;</comment>
                            <comment id="16754072" author="kkl0u" created="Mon, 28 Jan 2019 15:28:12 +0000"  >&lt;p&gt;Thanks a lot &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=edRojas&quot; class=&quot;user-hover&quot; rel=&quot;edRojas&quot;&gt;edRojas&lt;/a&gt; for looking into it. Looking forward to seeing the PR.&lt;/p&gt;</comment>
                            <comment id="16755180" author="edrojas" created="Tue, 29 Jan 2019 16:33:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt; I created the PR, you can review it now&lt;/p&gt;</comment>
                            <comment id="16756394" author="edrojas" created="Wed, 30 Jan 2019 18:33:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt; Travis build is failing but it&apos;s not related to the changes made in this PR.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt; I saw that you were the last person to modify this file, maybe you could take a look at the changes proposed.&lt;/p&gt;</comment>
                            <comment id="16759733" author="kkl0u" created="Mon, 4 Feb 2019 10:02:57 +0000"  >&lt;p&gt;Merged on master with 892ff1dff01f7ec10df7e8e41ed990b92eca0b34&lt;br/&gt;
and release-1.7 with 11bbf952f0fa0a4b897c37027031dccebf11485e&lt;br/&gt;
and release-1.6 with 4e78d586207d752669620a1ffd606dfd30e53fbe&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 41 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|yi08co:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>