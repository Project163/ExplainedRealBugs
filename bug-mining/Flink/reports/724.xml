<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:21:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-2837] FlinkTopologyBuilder cannot handle multiple input streams</title>
                <link>https://issues.apache.org/jira/browse/FLINK-2837</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;FlinkTopologyBuilder cannot handle multiple input streams correctly. Instead of union the incoming streams, it replicates the consuming bolt and each (logical) instance processes one of the input streams.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;final FlinkTopologyBuilder builder = new FlinkTopologyBuilder();

builder.setSpout(spoutId1, new FiniteRandomSpout(0, 10));
builder.setSpout(spoutId2, new FiniteRandomSpout(1, 8));
builder.setSpout(spoutId3, new FiniteRandomSpout(2, 13));

builder.setBolt(boltId, new MergerBolt())
	.shuffleGrouping(spoutId1)
	.shuffleGrouping(spoutId2)
	.shuffleGrouping(spoutId3);

builder.setBolt(&quot;sink&quot;, new BoltPrintSink(new SimpleOutputFormatter()))
	.shuffleGrouping(boltId);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;will only print the data from a single source instead of all sources.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12903381">FLINK-2837</key>
            <summary>FlinkTopologyBuilder cannot handle multiple input streams</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mjsax">Matthias J. Sax</assignee>
                                    <reporter username="mjsax">Matthias J. Sax</reporter>
                        <labels>
                    </labels>
                <created>Thu, 8 Oct 2015 14:09:28 +0000</created>
                <updated>Mon, 28 Dec 2015 14:15:29 +0000</updated>
                            <resolved>Mon, 28 Dec 2015 10:56:03 +0000</resolved>
                                                                    <component>Legacy Components / Storm Compatibility</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15021016" author="mxm" created="Sun, 22 Nov 2015 14:23:06 +0000"  >&lt;p&gt;Have you started working on this? I have fixed this and would like to open a pull request.&lt;/p&gt;</comment>
                            <comment id="15021102" author="mjsax" created="Sun, 22 Nov 2015 17:54:09 +0000"  >&lt;p&gt;No. Go ahead with your PR.&lt;/p&gt;</comment>
                            <comment id="15024176" author="githubbot" created="Tue, 24 Nov 2015 10:09:03 +0000"  >&lt;p&gt;GitHub user mxm opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2837&quot; title=&quot;FlinkTopologyBuilder cannot handle multiple input streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2837&quot;&gt;&lt;del&gt;FLINK-2837&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;storm&amp;#93;&lt;/span&gt; various improvements for Storm compatibility&lt;/p&gt;

&lt;p&gt;    This pull request contains various fixes. Most prominently, the parsing logic for Storm topologies has been changed to support multiple inputs. The API has been redone slightly. Two new examples have been added.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;refactor to use Storm&apos;s topology builder&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;remove FlinkTopologyBuilder&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;instantiate context-based StreamExecutionEnvironment (local or remote)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;remove Flink and Storm behavior replicating classes&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;modify FlinkTopology to parse Storm topology directly&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;replace StormTestBase with StreamingTestBase&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;let the FiniteFileSpout finish in corner cases&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;expose taskId, fix off by one task id&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add print example&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FlinkTopologyBuilder changes (check if all inputs are available before processing)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;correct package typo&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;support getter methods on TupleWrapper&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;two input support&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add join example&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;update docs&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;use Flink file system access&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/mxm/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/mxm/flink&lt;/a&gt; storm-dev-dev&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1398&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 613936cc7dce75e8dd811626cd2152b1f1383fe0&lt;br/&gt;
Author: Maximilian Michels &amp;lt;mxm@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-11-12T13:39:45Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2837&quot; title=&quot;FlinkTopologyBuilder cannot handle multiple input streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2837&quot;&gt;&lt;del&gt;FLINK-2837&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;storm&amp;#93;&lt;/span&gt; various improvements for Storm compatibility&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;refactor to use Storm&apos;s topology builder&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;remove FlinkTopologyBuilder&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;instantiate context-based StreamExecutionEnvironment (local or remote)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;remove Flink and Storm behavior replicating classes&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;modify FlinkTopology to parse Storm topology directly&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;replace StormTestBase with StreamingTestBase&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;let the FiniteFileSpout finish in corner cases&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;expose taskId, fix off by one task id&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add print example&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FlinkTopologyBuilder changes (check if all inputs are available before processing)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;correct package typo&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;two input support&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add join example&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;update docs&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;use Flink file system access&lt;/li&gt;
&lt;/ul&gt;


&lt;hr /&gt;</comment>
                            <comment id="15024243" author="githubbot" created="Tue, 24 Nov 2015 10:48:32 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45720083&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45720083&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: docs/apis/storm_compatibility.md &amp;#8212;&lt;br/&gt;
    @@ -57,20 +57,22 @@ See &lt;b&gt;WordCount Storm&lt;/b&gt; within `flink-storm-examples/pom.xml` for an example how t&lt;/p&gt;

&lt;p&gt;     Flink provides a Storm compatible API (`org.apache.flink.storm.api`) that offers replacements for the following classes:&lt;/p&gt;

&lt;p&gt;    &amp;#8211; `TopologyBuilder` replaced by `FlinkTopologyBuilder`&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;`StormSubmitter` replaced by `FlinkSubmitter`&lt;/li&gt;
	&lt;li&gt;`NimbusClient` and `Client` replaced by `FlinkClient`&lt;/li&gt;
	&lt;li&gt;`LocalCluster` replaced by `FlinkLocalCluster`&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -In order to submit a Storm topology to Flink, it is sufficient to replace the used Storm classes with their Flink replacements in the Storm &lt;b&gt;client code that assembles&lt;/b&gt; the topology.&lt;br/&gt;
    -The actual runtime code, ie, Spouts and Bolts, can be uses &lt;b&gt;unmodified&lt;/b&gt;.&lt;br/&gt;
    -If a topology is executed in a remote cluster, parameters `nimbus.host` and `nimbus.thrift.port` are used as `jobmanger.rpc.address` and `jobmanger.rpc.port`, respectively.&lt;br/&gt;
    -If a parameter is not specified, the value is taken from `flink-conf.yaml`.&lt;br/&gt;
    +In order to submit a Storm topology to Flink, it is sufficient to replace the&lt;br/&gt;
    +used Storm classes with their Flink replacements in the Storm *client code that&lt;br/&gt;
    +assembles* the topology.  The actual runtime code, ie, Spouts and Bolts, can be&lt;br/&gt;
    +used &lt;b&gt;unmodified&lt;/b&gt;.  If a topology is executed in a remote cluster, parameters&lt;br/&gt;
    +`nimbus.host` and `nimbus.thrift.port` are used as `jobmanger.rpc.address` and&lt;br/&gt;
    +`jobmanger.rpc.port`, respectively.  If a parameter is not specified, the value&lt;br/&gt;
    +is taken from `flink-conf.yaml`.&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Is there any change here? Looks like reformatting? I used a &quot;single-line per sentence&quot; formatting to make reviewing changes simples. Please stick to this formatting.&lt;/p&gt;</comment>
                            <comment id="15024284" author="githubbot" created="Tue, 24 Nov 2015 11:10:58 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45722053&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45722053&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: docs/apis/storm_compatibility.md &amp;#8212;&lt;br/&gt;
    @@ -57,20 +57,22 @@ See &lt;b&gt;WordCount Storm&lt;/b&gt; within `flink-storm-examples/pom.xml` for an example how t&lt;/p&gt;

&lt;p&gt;     Flink provides a Storm compatible API (`org.apache.flink.storm.api`) that offers replacements for the following classes:&lt;/p&gt;

&lt;p&gt;    &amp;#8211; `TopologyBuilder` replaced by `FlinkTopologyBuilder`&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;`StormSubmitter` replaced by `FlinkSubmitter`&lt;/li&gt;
	&lt;li&gt;`NimbusClient` and `Client` replaced by `FlinkClient`&lt;/li&gt;
	&lt;li&gt;`LocalCluster` replaced by `FlinkLocalCluster`&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -In order to submit a Storm topology to Flink, it is sufficient to replace the used Storm classes with their Flink replacements in the Storm &lt;b&gt;client code that assembles&lt;/b&gt; the topology.&lt;br/&gt;
    -The actual runtime code, ie, Spouts and Bolts, can be uses &lt;b&gt;unmodified&lt;/b&gt;.&lt;br/&gt;
    -If a topology is executed in a remote cluster, parameters `nimbus.host` and `nimbus.thrift.port` are used as `jobmanger.rpc.address` and `jobmanger.rpc.port`, respectively.&lt;br/&gt;
    -If a parameter is not specified, the value is taken from `flink-conf.yaml`.&lt;br/&gt;
    +In order to submit a Storm topology to Flink, it is sufficient to replace the&lt;br/&gt;
    +used Storm classes with their Flink replacements in the Storm *client code that&lt;br/&gt;
    +assembles* the topology.  The actual runtime code, ie, Spouts and Bolts, can be&lt;br/&gt;
    +used &lt;b&gt;unmodified&lt;/b&gt;.  If a topology is executed in a remote cluster, parameters&lt;br/&gt;
    +`nimbus.host` and `nimbus.thrift.port` are used as `jobmanger.rpc.address` and&lt;br/&gt;
    +`jobmanger.rpc.port`, respectively.  If a parameter is not specified, the value&lt;br/&gt;
    +is taken from `flink-conf.yaml`.&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Minor typo &quot;can be uses&quot; -&amp;gt; &quot;can be used&quot;. I think fixed line length is the best because sentences can span multiple lines. If it is an issue I can revert it.&lt;/p&gt;</comment>
                            <comment id="15024316" author="githubbot" created="Tue, 24 Nov 2015 11:39:56 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45724616&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45724616&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: docs/apis/storm_compatibility.md &amp;#8212;&lt;br/&gt;
    @@ -57,20 +57,22 @@ See &lt;b&gt;WordCount Storm&lt;/b&gt; within `flink-storm-examples/pom.xml` for an example how t&lt;/p&gt;

&lt;p&gt;     Flink provides a Storm compatible API (`org.apache.flink.storm.api`) that offers replacements for the following classes:&lt;/p&gt;

&lt;p&gt;    &amp;#8211; `TopologyBuilder` replaced by `FlinkTopologyBuilder`&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;`StormSubmitter` replaced by `FlinkSubmitter`&lt;/li&gt;
	&lt;li&gt;`NimbusClient` and `Client` replaced by `FlinkClient`&lt;/li&gt;
	&lt;li&gt;`LocalCluster` replaced by `FlinkLocalCluster`&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -In order to submit a Storm topology to Flink, it is sufficient to replace the used Storm classes with their Flink replacements in the Storm &lt;b&gt;client code that assembles&lt;/b&gt; the topology.&lt;br/&gt;
    -The actual runtime code, ie, Spouts and Bolts, can be uses &lt;b&gt;unmodified&lt;/b&gt;.&lt;br/&gt;
    -If a topology is executed in a remote cluster, parameters `nimbus.host` and `nimbus.thrift.port` are used as `jobmanger.rpc.address` and `jobmanger.rpc.port`, respectively.&lt;br/&gt;
    -If a parameter is not specified, the value is taken from `flink-conf.yaml`.&lt;br/&gt;
    +In order to submit a Storm topology to Flink, it is sufficient to replace the&lt;br/&gt;
    +used Storm classes with their Flink replacements in the Storm *client code that&lt;br/&gt;
    +assembles* the topology.  The actual runtime code, ie, Spouts and Bolts, can be&lt;br/&gt;
    +used &lt;b&gt;unmodified&lt;/b&gt;.  If a topology is executed in a remote cluster, parameters&lt;br/&gt;
    +`nimbus.host` and `nimbus.thrift.port` are used as `jobmanger.rpc.address` and&lt;br/&gt;
    +`jobmanger.rpc.port`, respectively.  If a parameter is not specified, the value&lt;br/&gt;
    +is taken from `flink-conf.yaml`.&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I like the single-line format because it make reviewing easier. If you have fixed line length, changing a small thing can lead for reformatting of a whole paragraph due to new line breaks etc. This make spotting the actual change quite hard. (I would appreciate it, if we could keep the current formatting &amp;#8211; but if is not &quot;an issue&quot; in the strong sense).&lt;/p&gt;</comment>
                            <comment id="15024325" author="githubbot" created="Tue, 24 Nov 2015 11:50:36 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45725506&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45725506&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -18,20 +18,23 @@&lt;br/&gt;
     package org.apache.flink.storm.util;&lt;/p&gt;

&lt;p&gt;     import backtype.storm.task.TopologyContext;&lt;br/&gt;
    +import org.apache.flink.core.fs.FSDataOutputStream;&lt;br/&gt;
    +import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
    +import org.apache.flink.core.fs.Path;&lt;/p&gt;

&lt;p&gt;     import java.io.BufferedWriter;&lt;br/&gt;
    -import java.io.FileWriter;&lt;br/&gt;
     import java.io.IOException;&lt;br/&gt;
    +import java.io.OutputStreamWriter;&lt;br/&gt;
     import java.util.Map;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Implements a sink that write the received data to the given file (as a result of 
{@code Object.toString()} for each&lt;br/&gt;
    + * Implements a sink that writes the received data to the given file (as a result of {@code Object.toString()}
&lt;p&gt; for each&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;attribute).&lt;br/&gt;
      */&lt;br/&gt;
     public final class BoltFileSink extends AbstractBoltSink {&lt;br/&gt;
     	private static final long serialVersionUID = 2014027288631273666L;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final String path;&lt;br/&gt;
    +	private final Path path;&lt;br/&gt;
     	private BufferedWriter writer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Please do not use `Path` &amp;#8211; *&lt;b&gt;all&lt;/b&gt;* spouts/bolts should be written the &quot;Storm&quot; way and not include dependencies to Flink.&lt;/p&gt;</comment>
                            <comment id="15024326" author="githubbot" created="Tue, 24 Nov 2015 11:50:56 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45725539&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45725539&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -40,16 +43,17 @@ public BoltFileSink(final String path) {&lt;/p&gt;

&lt;p&gt;     	public BoltFileSink(final String path, final OutputFormatter formatter) &lt;/p&gt;
{
     		super(formatter);
    -		this.path = path;
    +		this.path = new Path(path);
     	}

&lt;p&gt;     	@SuppressWarnings(&quot;rawtypes&quot;)&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public void prepareSimple(final Map stormConf, final TopologyContext context) {&lt;br/&gt;
     		try &lt;/p&gt;
{
    -			this.writer = new BufferedWriter(new FileWriter(this.path));
    +			FSDataOutputStream outputStream = FileSystem.getLocalFileSystem().create(path, false);
    +			this.writer = new BufferedWriter(new OutputStreamWriter(outputStream));
     		}
&lt;p&gt; catch (final IOException e) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Same here.&lt;/p&gt;</comment>
                            <comment id="15024332" author="githubbot" created="Tue, 24 Nov 2015 11:53:46 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45725806&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45725806&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -38,6 +38,8 @@&lt;br/&gt;
     	protected String path = null;&lt;br/&gt;
     	protected BufferedReader reader;&lt;/p&gt;

&lt;p&gt;    +	protected boolean finished;&lt;br/&gt;
    +&lt;br/&gt;
     	public FileSpout() {}&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `FileSpout` should be implemented the Storm way &amp;#8211; to set the &quot;finished&quot;&lt;br/&gt;
    flag here does not make sense from a Storm point of view (there is no&lt;br/&gt;
    such thing as a finite spout)&lt;/p&gt;</comment>
                            <comment id="15024334" author="githubbot" created="Tue, 24 Nov 2015 11:54:34 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45725866&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45725866&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FiniteFileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -32,46 +23,17 @@&lt;br/&gt;
     public class FiniteFileSpout extends FileSpout implements FiniteSpout {&lt;br/&gt;
     	private static final long serialVersionUID = -1472978008607215864L;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private String line;&lt;/li&gt;
	&lt;li&gt;private boolean newLineRead;&lt;br/&gt;
    -&lt;br/&gt;
     	public FiniteFileSpout() {}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	public FiniteFileSpout(String path) &lt;/p&gt;
{
     		super(path);
     	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;rawtypes&quot;)&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void open(final Map conf, final TopologyContext context, final SpoutOutputCollector collector) 
{
    -		super.open(conf, context, collector);
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void nextTuple() 
{
    -		this.collector.emit(new Values(line));
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;br/&gt;
     	/**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Can be called before nextTuple() any times including 0.&lt;br/&gt;
     	 */&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public boolean reachedEnd() {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
    -			readLine();
    -		}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
    -			throw new RuntimeException(&quot;Exception occured while reading file &quot; + path);
    -		}&lt;/li&gt;
	&lt;li&gt;return line == null;&lt;br/&gt;
    +		return finished;&lt;br/&gt;
     	}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This example shows how a regular Storm spout can be improved&lt;br/&gt;
    using FiniteSpout interface &amp;#8211; I would keep it as is (even if seems to&lt;br/&gt;
    be unnecessary complicated &amp;#8211; imagine that you don&apos;t have the code of&lt;br/&gt;
    FileSpout)&lt;/p&gt;</comment>
                            <comment id="15024336" author="githubbot" created="Tue, 24 Nov 2015 11:57:42 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45726093&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45726093&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkClient.java &amp;#8212;&lt;br/&gt;
    @@ -183,10 +183,10 @@ public void submitTopologyWithOpts(final String name, final String uploadedJarLo&lt;/p&gt;

&lt;p&gt;     		/* set storm configuration */&lt;br/&gt;
     		if (this.conf != null) &lt;/p&gt;
{
    -			topology.getConfig().setGlobalJobParameters(new StormConfig(this.conf));
    +			topology.getExecutionEnvironment().getConfig().setGlobalJobParameters(new StormConfig(this.conf));
     		}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why this change? Just want to understand?&lt;/p&gt;</comment>
                            <comment id="15024337" author="githubbot" created="Tue, 24 Nov 2015 11:58:10 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45726133&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45726133&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkClient.java &amp;#8212;&lt;br/&gt;
    @@ -183,10 +183,10 @@ public void submitTopologyWithOpts(final String name, final String uploadedJarLo&lt;/p&gt;

&lt;p&gt;     		/* set storm configuration */&lt;br/&gt;
     		if (this.conf != null) &lt;/p&gt;
{
    -			topology.getConfig().setGlobalJobParameters(new StormConfig(this.conf));
    +			topology.getExecutionEnvironment().getConfig().setGlobalJobParameters(new StormConfig(this.conf));
     		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StreamGraph streamGraph = topology.getStreamGraph();&lt;br/&gt;
    +		final StreamGraph streamGraph = topology.getExecutionEnvironment().getStreamGraph();&lt;br/&gt;
     		streamGraph.setJobName(name);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Same here? Why changed?&lt;/p&gt;</comment>
                            <comment id="15024339" author="githubbot" created="Tue, 24 Nov 2015 11:59:06 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45726196&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45726196&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkLocalCluster.java &amp;#8212;&lt;br/&gt;
    @@ -48,12 +49,10 @@&lt;br/&gt;
     	private static final Logger LOG = LoggerFactory.getLogger(FlinkLocalCluster.class);&lt;/p&gt;

&lt;p&gt;     	/** The flink mini cluster on which to execute the programs */&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final FlinkMiniCluster flink;&lt;br/&gt;
    +	private FlinkMiniCluster flink;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;     	public FlinkLocalCluster() &lt;/p&gt;
{
    -		this.flink = new LocalFlinkMiniCluster(new Configuration(), true, StreamingMode.STREAMING);
    -		this.flink.start();
     	}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    What is the advantage by removing this?&lt;/p&gt;</comment>
                            <comment id="15024345" author="githubbot" created="Tue, 24 Nov 2015 12:03:11 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45726538&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45726538&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +					int dop = common.get_parallelism_hint();
    +					outputStream.setParallelism(dop);
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					common.set_parallelism_hint(1);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	private DataStream&amp;lt;Tuple&amp;gt; processInput(String boltId, IRichBolt userBolt,&lt;br/&gt;
    +										GlobalStreamId streamId, Grouping grouping,&lt;br/&gt;
    +										Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Preconditions.checkNotNull(userBolt);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I would use `assert` here because it a private method.&lt;/p&gt;</comment>
                            <comment id="15024346" author="githubbot" created="Tue, 24 Nov 2015 12:03:53 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45726600&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45726600&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +					int dop = common.get_parallelism_hint();
    +					outputStream.setParallelism(dop);
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					common.set_parallelism_hint(1);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	private DataStream&amp;lt;Tuple&amp;gt; processInput(String boltId, IRichBolt userBolt,&lt;br/&gt;
    +										GlobalStreamId streamId, Grouping grouping,&lt;br/&gt;
    +										Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Preconditions.checkNotNull(userBolt);&lt;br/&gt;
    +		Preconditions.checkNotNull(boltId);&lt;br/&gt;
    +		Preconditions.checkNotNull(streamId);&lt;br/&gt;
    +		Preconditions.checkNotNull(grouping);&lt;br/&gt;
    +		Preconditions.checkNotNull(producer);&lt;br/&gt;
    +&lt;br/&gt;
    +		final String producerId = streamId.get_componentId();&lt;br/&gt;
    +		final String inputStreamId = streamId.get_streamId();&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStream&amp;lt;Tuple&amp;gt; inputStream = producer.get(inputStreamId);&lt;br/&gt;
    +&lt;br/&gt;
    +		final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +		declarers.put(boltId, declarer);&lt;br/&gt;
    +		userBolt.declareOutputFields(declarer);&lt;br/&gt;
    +		this.outputStreams.put(boltId, declarer.outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +		// if producer was processed already&lt;br/&gt;
    +		if (grouping.is_set_shuffle()) &lt;/p&gt;
{
    +			// Storm uses a round-robin shuffle strategy
    +			inputStream = inputStream.rebalance();
    +		}
&lt;p&gt; else if (grouping.is_set_fields()) {&lt;br/&gt;
    +			// global grouping is emulated in Storm via an empty fields grouping list&lt;br/&gt;
    +			final List&amp;lt;String&amp;gt; fields = grouping.get_fields();&lt;br/&gt;
    +			if (fields.size() &amp;gt; 0) &lt;/p&gt;
{
    +				FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);
    +				inputStream = inputStream.keyBy(prodDeclarer
    +						.getGroupingFieldIndexes(inputStreamId,
    +								grouping.get_fields()));
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				inputStream = inputStream.global();
    +			}
&lt;p&gt;    +		} else if (grouping.is_set_all()) &lt;/p&gt;
{
    +			inputStream = inputStream.broadcast();
    +		}
&lt;p&gt; else if (!grouping.is_set_local_or_shuffle()) &lt;/p&gt;
{
    +			throw new UnsupportedOperationException(
    +					&quot;Flink only supports (local-or-)shuffle, fields, all, and global grouping&quot;);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		return inputStream;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; createOutput(String boltId, IRichBolt bolt, GlobalStreamId streamId, DataStream&amp;lt;Tuple&amp;gt; inputStream) &lt;/p&gt;
{
    +		return createOutput(boltId, bolt, streamId, inputStream, null, null);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; createOutput(String boltId, IRichBolt bolt,&lt;br/&gt;
    +														GlobalStreamId streamId, DataStream&amp;lt;Tuple&amp;gt; inputStream,&lt;br/&gt;
    +														GlobalStreamId streamId2, DataStream&amp;lt;Tuple&amp;gt; inputStream2) {&lt;br/&gt;
    +		Preconditions.checkNotNull(boltId);&lt;br/&gt;
    +		Preconditions.checkNotNull(streamId);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `assert`&lt;/p&gt;</comment>
                            <comment id="15024351" author="githubbot" created="Tue, 24 Nov 2015 12:07:04 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45726840&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45726840&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -75,11 +78,13 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;@param bolt&lt;/li&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param componentId&lt;br/&gt;
    +	 * @param streamId&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@throws IllegalArgumentException&lt;/li&gt;
	&lt;li&gt;If the number of declared output attributes is not with range &lt;span class=&quot;error&quot;&gt;&amp;#91;0;25&amp;#93;&lt;/span&gt;.&lt;br/&gt;
     	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public BoltWrapper(final IRichBolt bolt) throws IllegalArgumentException {&lt;/li&gt;
	&lt;li&gt;this(bolt, null, (Collection&amp;lt;String&amp;gt;) null);&lt;br/&gt;
    +	public BoltWrapper(final IRichBolt bolt, String componentId, String streamId) throws IllegalArgumentException {&lt;br/&gt;
    +		this(bolt, componentId, streamId, null, (Collection&amp;lt;String&amp;gt;) null);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This makes the interface quite hard to use and should not be necessary. The `TopologyContext` created in `open()` contains this information.&lt;/p&gt;</comment>
                            <comment id="15024353" author="githubbot" created="Tue, 24 Nov 2015 12:10:01 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45727062&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45727062&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,6 +45,21 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String streamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String componentId;&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    There is a JIRA for this. &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2721&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-2721&lt;/a&gt; I am already working on it. I think that &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2721&quot; title=&quot;Add Tuple meta information&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2721&quot;&gt;&lt;del&gt;FLINK-2721&lt;/del&gt;&lt;/a&gt; should be resolved before this.&lt;/p&gt;</comment>
                            <comment id="15024355" author="githubbot" created="Tue, 24 Nov 2015 12:10:37 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45727099&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45727099&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -150,7 +153,7 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     			}&lt;br/&gt;
     			stormTopology = new StormTopology(spouts, bolts, new HashMap&amp;lt;String, StateSpoutSpec&amp;gt;());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;taskId = context.getIndexOfThisSubtask();&lt;br/&gt;
    +			taskId = context.getIndexOfThisSubtask() + 1;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why `+1` ?&lt;/p&gt;</comment>
                            <comment id="15024357" author="githubbot" created="Tue, 24 Nov 2015 12:11:24 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45727164&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45727164&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -187,14 +190,15 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     				}&lt;br/&gt;
     			}&lt;br/&gt;
     			for (Entry&amp;lt;String, StateSpoutSpec&amp;gt; stateSpout : stateSpouts.entrySet()) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer rc = taskId = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
    +				Integer rc = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
     						.getValue().get_common(), operatorName, context.getIndexOfThisSubtask(),&lt;br/&gt;
     						dop, taskToComponents, componentToSortedTasks, componentToStreamToFields);&lt;br/&gt;
     				if (rc != null) 
{
     					taskId = rc;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;assert (taskId != null);&lt;br/&gt;
    +&lt;br/&gt;
    +			Preconditions.checkNotNull(&quot;Task ID may not be null!&quot;, taskId);&lt;br/&gt;
     		}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I prefer `assert` for internal method.&lt;/p&gt;</comment>
                            <comment id="15024360" author="githubbot" created="Tue, 24 Nov 2015 12:14:21 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45727399&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45727399&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/StormTupleTest.java &amp;#8212;&lt;br/&gt;
    @@ -595,7 +593,7 @@ public void testGetBinaryByFieldPojoGetter() throws Exception {&lt;br/&gt;
     	private &amp;lt;T&amp;gt; StormTuple testGetByField(int arity, int index, T value)&lt;br/&gt;
     			throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assert (index &amp;lt; arity);&lt;br/&gt;
    +		Assert.assertTrue(index &amp;lt; arity);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This is not a assertion for a test result; thus usage of `assert` is correct (checks if test is written properly).&lt;/p&gt;</comment>
                            <comment id="15024361" author="githubbot" created="Tue, 24 Nov 2015 12:15:30 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45727477&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45727477&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Why did you change this?&lt;/p&gt;</comment>
                            <comment id="15024382" author="githubbot" created="Tue, 24 Nov 2015 12:24:35 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728165&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728165&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkClient.java &amp;#8212;&lt;br/&gt;
    @@ -183,10 +183,10 @@ public void submitTopologyWithOpts(final String name, final String uploadedJarLo&lt;/p&gt;

&lt;p&gt;     		/* set storm configuration */&lt;br/&gt;
     		if (this.conf != null) &lt;/p&gt;
{
    -			topology.getConfig().setGlobalJobParameters(new StormConfig(this.conf));
    +			topology.getExecutionEnvironment().getConfig().setGlobalJobParameters(new StormConfig(this.conf));
     		}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Because FlinkTopology is not subclassed from StreamExecutionEnvironment anymore. The class has been removed and FlinkTopologyBuilder is now FlinkTopology.&lt;/p&gt;</comment>
                            <comment id="15024383" author="githubbot" created="Tue, 24 Nov 2015 12:24:37 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728168&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728168&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkClient.java &amp;#8212;&lt;br/&gt;
    @@ -183,10 +183,10 @@ public void submitTopologyWithOpts(final String name, final String uploadedJarLo&lt;/p&gt;

&lt;p&gt;     		/* set storm configuration */&lt;br/&gt;
     		if (this.conf != null) &lt;/p&gt;
{
    -			topology.getConfig().setGlobalJobParameters(new StormConfig(this.conf));
    +			topology.getExecutionEnvironment().getConfig().setGlobalJobParameters(new StormConfig(this.conf));
     		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StreamGraph streamGraph = topology.getStreamGraph();&lt;br/&gt;
    +		final StreamGraph streamGraph = topology.getExecutionEnvironment().getStreamGraph();&lt;br/&gt;
     		streamGraph.setJobName(name);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Because FlinkTopology is not subclassed from StreamExecutionEnvironment anymore.&lt;/p&gt;</comment>
                            <comment id="15024384" author="githubbot" created="Tue, 24 Nov 2015 12:25:06 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728214&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728214&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkLocalCluster.java &amp;#8212;&lt;br/&gt;
    @@ -48,12 +49,10 @@&lt;br/&gt;
     	private static final Logger LOG = LoggerFactory.getLogger(FlinkLocalCluster.class);&lt;/p&gt;

&lt;p&gt;     	/** The flink mini cluster on which to execute the programs */&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final FlinkMiniCluster flink;&lt;br/&gt;
    +	private FlinkMiniCluster flink;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;     	public FlinkLocalCluster() &lt;/p&gt;
{
    -		this.flink = new LocalFlinkMiniCluster(new Configuration(), true, StreamingMode.STREAMING);
    -		this.flink.start();
     	}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Lazy startup of the flink cluster. This enables us to set the right number of task slots for the job.&lt;/p&gt;</comment>
                            <comment id="15024386" author="githubbot" created="Tue, 24 Nov 2015 12:26:19 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728317&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728317&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +					int dop = common.get_parallelism_hint();
    +					outputStream.setParallelism(dop);
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					common.set_parallelism_hint(1);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	private DataStream&amp;lt;Tuple&amp;gt; processInput(String boltId, IRichBolt userBolt,&lt;br/&gt;
    +										GlobalStreamId streamId, Grouping grouping,&lt;br/&gt;
    +										Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Preconditions.checkNotNull(userBolt);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Asserts are not enabled by default. I think it&apos;s important to always check this condition.&lt;/p&gt;</comment>
                            <comment id="15024387" author="githubbot" created="Tue, 24 Nov 2015 12:26:23 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728322&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728322&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +					int dop = common.get_parallelism_hint();
    +					outputStream.setParallelism(dop);
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					common.set_parallelism_hint(1);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	private DataStream&amp;lt;Tuple&amp;gt; processInput(String boltId, IRichBolt userBolt,&lt;br/&gt;
    +										GlobalStreamId streamId, Grouping grouping,&lt;br/&gt;
    +										Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Preconditions.checkNotNull(userBolt);&lt;br/&gt;
    +		Preconditions.checkNotNull(boltId);&lt;br/&gt;
    +		Preconditions.checkNotNull(streamId);&lt;br/&gt;
    +		Preconditions.checkNotNull(grouping);&lt;br/&gt;
    +		Preconditions.checkNotNull(producer);&lt;br/&gt;
    +&lt;br/&gt;
    +		final String producerId = streamId.get_componentId();&lt;br/&gt;
    +		final String inputStreamId = streamId.get_streamId();&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStream&amp;lt;Tuple&amp;gt; inputStream = producer.get(inputStreamId);&lt;br/&gt;
    +&lt;br/&gt;
    +		final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +		declarers.put(boltId, declarer);&lt;br/&gt;
    +		userBolt.declareOutputFields(declarer);&lt;br/&gt;
    +		this.outputStreams.put(boltId, declarer.outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +		// if producer was processed already&lt;br/&gt;
    +		if (grouping.is_set_shuffle()) &lt;/p&gt;
{
    +			// Storm uses a round-robin shuffle strategy
    +			inputStream = inputStream.rebalance();
    +		}
&lt;p&gt; else if (grouping.is_set_fields()) {&lt;br/&gt;
    +			// global grouping is emulated in Storm via an empty fields grouping list&lt;br/&gt;
    +			final List&amp;lt;String&amp;gt; fields = grouping.get_fields();&lt;br/&gt;
    +			if (fields.size() &amp;gt; 0) &lt;/p&gt;
{
    +				FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);
    +				inputStream = inputStream.keyBy(prodDeclarer
    +						.getGroupingFieldIndexes(inputStreamId,
    +								grouping.get_fields()));
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				inputStream = inputStream.global();
    +			}
&lt;p&gt;    +		} else if (grouping.is_set_all()) &lt;/p&gt;
{
    +			inputStream = inputStream.broadcast();
    +		}
&lt;p&gt; else if (!grouping.is_set_local_or_shuffle()) &lt;/p&gt;
{
    +			throw new UnsupportedOperationException(
    +					&quot;Flink only supports (local-or-)shuffle, fields, all, and global grouping&quot;);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		return inputStream;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; createOutput(String boltId, IRichBolt bolt, GlobalStreamId streamId, DataStream&amp;lt;Tuple&amp;gt; inputStream) &lt;/p&gt;
{
    +		return createOutput(boltId, bolt, streamId, inputStream, null, null);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; createOutput(String boltId, IRichBolt bolt,&lt;br/&gt;
    +														GlobalStreamId streamId, DataStream&amp;lt;Tuple&amp;gt; inputStream,&lt;br/&gt;
    +														GlobalStreamId streamId2, DataStream&amp;lt;Tuple&amp;gt; inputStream2) {&lt;br/&gt;
    +		Preconditions.checkNotNull(boltId);&lt;br/&gt;
    +		Preconditions.checkNotNull(streamId);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Asserts are not enabled by default. I think it&apos;s important to always check this condition.&lt;/p&gt;
</comment>
                            <comment id="15024389" author="githubbot" created="Tue, 24 Nov 2015 12:27:02 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728366&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728366&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,6 +45,21 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String streamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String componentId;&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This is fixed in this PR.&lt;/p&gt;</comment>
                            <comment id="15024391" author="githubbot" created="Tue, 24 Nov 2015 12:27:31 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728386&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728386&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -150,7 +153,7 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     			}&lt;br/&gt;
     			stormTopology = new StormTopology(spouts, bolts, new HashMap&amp;lt;String, StateSpoutSpec&amp;gt;());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;taskId = context.getIndexOfThisSubtask();&lt;br/&gt;
    +			taskId = context.getIndexOfThisSubtask() + 1;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Because Flink&apos;s task index starts with 0 but Storm starts with 1...&lt;/p&gt;</comment>
                            <comment id="15024392" author="githubbot" created="Tue, 24 Nov 2015 12:27:54 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728418&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728418&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -187,14 +190,15 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     				}&lt;br/&gt;
     			}&lt;br/&gt;
     			for (Entry&amp;lt;String, StateSpoutSpec&amp;gt; stateSpout : stateSpouts.entrySet()) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer rc = taskId = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
    +				Integer rc = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
     						.getValue().get_common(), operatorName, context.getIndexOfThisSubtask(),&lt;br/&gt;
     						dop, taskToComponents, componentToSortedTasks, componentToStreamToFields);&lt;br/&gt;
     				if (rc != null) 
{
     					taskId = rc;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;assert (taskId != null);&lt;br/&gt;
    +&lt;br/&gt;
    +			Preconditions.checkNotNull(&quot;Task ID may not be null!&quot;, taskId);&lt;br/&gt;
     		}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    They are disabled by default and are not reliable enough.&lt;/p&gt;</comment>
                            <comment id="15024393" author="githubbot" created="Tue, 24 Nov 2015 12:28:14 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728449&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728449&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    We should try to fix this... &lt;/p&gt;</comment>
                            <comment id="15024395" author="githubbot" created="Tue, 24 Nov 2015 12:29:01 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728523&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728523&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Because only number of inputs &amp;lt;= 2 are supported by the translator &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15024397" author="githubbot" created="Tue, 24 Nov 2015 12:29:58 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728576&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728576&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/StormTupleTest.java &amp;#8212;&lt;br/&gt;
    @@ -595,7 +593,7 @@ public void testGetBinaryByFieldPojoGetter() throws Exception {&lt;br/&gt;
     	private &amp;lt;T&amp;gt; StormTuple testGetByField(int arity, int index, T value)&lt;br/&gt;
     			throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assert (index &amp;lt; arity);&lt;br/&gt;
    +		Assert.assertTrue(index &amp;lt; arity);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Hmm, it&apos;s part of the test, no? Doesn&apos;t really matter but in general I thought usage of assert is discouraged.&lt;/p&gt;</comment>
                            <comment id="15024408" author="githubbot" created="Tue, 24 Nov 2015 12:30:58 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728678&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728678&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -18,20 +18,23 @@&lt;br/&gt;
     package org.apache.flink.storm.util;&lt;/p&gt;

&lt;p&gt;     import backtype.storm.task.TopologyContext;&lt;br/&gt;
    +import org.apache.flink.core.fs.FSDataOutputStream;&lt;br/&gt;
    +import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
    +import org.apache.flink.core.fs.Path;&lt;/p&gt;

&lt;p&gt;     import java.io.BufferedWriter;&lt;br/&gt;
    -import java.io.FileWriter;&lt;br/&gt;
     import java.io.IOException;&lt;br/&gt;
    +import java.io.OutputStreamWriter;&lt;br/&gt;
     import java.util.Map;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Implements a sink that write the received data to the given file (as a result of 
{@code Object.toString()} for each&lt;br/&gt;
    + * Implements a sink that writes the received data to the given file (as a result of {@code Object.toString()}
&lt;p&gt; for each&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;attribute).&lt;br/&gt;
      */&lt;br/&gt;
     public final class BoltFileSink extends AbstractBoltSink {&lt;br/&gt;
     	private static final long serialVersionUID = 2014027288631273666L;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final String path;&lt;br/&gt;
    +	private final Path path;&lt;br/&gt;
     	private BufferedWriter writer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Hmm but they depend on Flink anyways because of the Maven dependency?&lt;/p&gt;</comment>
                            <comment id="15024413" author="githubbot" created="Tue, 24 Nov 2015 12:32:27 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728796&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728796&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -40,16 +43,17 @@ public BoltFileSink(final String path) {&lt;/p&gt;

&lt;p&gt;     	public BoltFileSink(final String path, final OutputFormatter formatter) &lt;/p&gt;
{
     		super(formatter);
    -		this.path = path;
    +		this.path = new Path(path);
     	}

&lt;p&gt;     	@SuppressWarnings(&quot;rawtypes&quot;)&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public void prepareSimple(final Map stormConf, final TopologyContext context) {&lt;br/&gt;
     		try &lt;/p&gt;
{
    -			this.writer = new BufferedWriter(new FileWriter(this.path));
    +			FSDataOutputStream outputStream = FileSystem.getLocalFileSystem().create(path, false);
    +			this.writer = new BufferedWriter(new OutputStreamWriter(outputStream));
     		}
&lt;p&gt; catch (final IOException e) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I had problems if the path contained a file scheme without the file system abstraction.&lt;/p&gt;</comment>
                            <comment id="15024416" author="githubbot" created="Tue, 24 Nov 2015 12:33:27 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45728889&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45728889&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -38,6 +38,8 @@&lt;br/&gt;
     	protected String path = null;&lt;br/&gt;
     	protected BufferedReader reader;&lt;/p&gt;

&lt;p&gt;    +	protected boolean finished;&lt;br/&gt;
    +&lt;br/&gt;
     	public FileSpout() {}&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    But this doesn&apos;t alter the behavior of FileSpout. It is still infinite.&lt;/p&gt;</comment>
                            <comment id="15024420" author="githubbot" created="Tue, 24 Nov 2015 12:34:44 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45729000&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45729000&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FiniteFileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -32,46 +23,17 @@&lt;br/&gt;
     public class FiniteFileSpout extends FileSpout implements FiniteSpout {&lt;br/&gt;
     	private static final long serialVersionUID = -1472978008607215864L;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private String line;&lt;/li&gt;
	&lt;li&gt;private boolean newLineRead;&lt;br/&gt;
    -&lt;br/&gt;
     	public FiniteFileSpout() {}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	public FiniteFileSpout(String path) &lt;/p&gt;
{
     		super(path);
     	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;rawtypes&quot;)&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void open(final Map conf, final TopologyContext context, final SpoutOutputCollector collector) 
{
    -		super.open(conf, context, collector);
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void nextTuple() 
{
    -		this.collector.emit(new Values(line));
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;br/&gt;
     	/**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Can be called before nextTuple() any times including 0.&lt;br/&gt;
     	 */&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public boolean reachedEnd() {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
    -			readLine();
    -		}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
    -			throw new RuntimeException(&quot;Exception occured while reading file &quot; + path);
    -		}&lt;/li&gt;
	&lt;li&gt;return line == null;&lt;br/&gt;
    +		return finished;&lt;br/&gt;
     	}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I don&apos;t understand why I should copy code instead. It is more elegant this way. &lt;/p&gt;</comment>
                            <comment id="15024423" author="githubbot" created="Tue, 24 Nov 2015 12:38:38 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45729369&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45729369&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -75,11 +78,13 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;@param bolt&lt;/li&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param componentId&lt;br/&gt;
    +	 * @param streamId&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@throws IllegalArgumentException&lt;/li&gt;
	&lt;li&gt;If the number of declared output attributes is not with range &lt;span class=&quot;error&quot;&gt;&amp;#91;0;25&amp;#93;&lt;/span&gt;.&lt;br/&gt;
     	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public BoltWrapper(final IRichBolt bolt) throws IllegalArgumentException {&lt;/li&gt;
	&lt;li&gt;this(bolt, null, (Collection&amp;lt;String&amp;gt;) null);&lt;br/&gt;
    +	public BoltWrapper(final IRichBolt bolt, String componentId, String streamId) throws IllegalArgumentException {&lt;br/&gt;
    +		this(bolt, componentId, streamId, null, (Collection&amp;lt;String&amp;gt;) null);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    The naming is a bit odd but this is actually the component and stream id of the &lt;b&gt;producer&lt;/b&gt;.&lt;/p&gt;</comment>
                            <comment id="15024427" author="githubbot" created="Tue, 24 Nov 2015 12:42:39 +0000"  >&lt;p&gt;Github user mxm commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#issuecomment-159256830&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#issuecomment-159256830&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I will integrate the changes of #1387. It would be great if we merged these changes afterwards.&lt;/p&gt;</comment>
                            <comment id="15024437" author="githubbot" created="Tue, 24 Nov 2015 12:53:36 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45730807&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45730807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -18,20 +18,23 @@&lt;br/&gt;
     package org.apache.flink.storm.util;&lt;/p&gt;

&lt;p&gt;     import backtype.storm.task.TopologyContext;&lt;br/&gt;
    +import org.apache.flink.core.fs.FSDataOutputStream;&lt;br/&gt;
    +import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
    +import org.apache.flink.core.fs.Path;&lt;/p&gt;

&lt;p&gt;     import java.io.BufferedWriter;&lt;br/&gt;
    -import java.io.FileWriter;&lt;br/&gt;
     import java.io.IOException;&lt;br/&gt;
    +import java.io.OutputStreamWriter;&lt;br/&gt;
     import java.util.Map;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Implements a sink that write the received data to the given file (as a result of 
{@code Object.toString()} for each&lt;br/&gt;
    + * Implements a sink that writes the received data to the given file (as a result of {@code Object.toString()}
&lt;p&gt; for each&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;attribute).&lt;br/&gt;
      */&lt;br/&gt;
     public final class BoltFileSink extends AbstractBoltSink {&lt;br/&gt;
     	private static final long serialVersionUID = 2014027288631273666L;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final String path;&lt;br/&gt;
    +	private final Path path;&lt;br/&gt;
     	private BufferedWriter writer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    That&apos;s not the point. If I re-use an existing bolt, I don&apos;t want to change anything. And I want to be able (from an example point of view) to run this bolt as-is in Storm, too. (Without any dependencies to Flink)&lt;/p&gt;</comment>
                            <comment id="15024445" author="githubbot" created="Tue, 24 Nov 2015 12:54:43 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45730899&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45730899&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -40,16 +43,17 @@ public BoltFileSink(final String path) {&lt;/p&gt;

&lt;p&gt;     	public BoltFileSink(final String path, final OutputFormatter formatter) &lt;/p&gt;
{
     		super(formatter);
    -		this.path = path;
    +		this.path = new Path(path);
     	}

&lt;p&gt;     	@SuppressWarnings(&quot;rawtypes&quot;)&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public void prepareSimple(final Map stormConf, final TopologyContext context) {&lt;br/&gt;
     		try &lt;/p&gt;
{
    -			this.writer = new BufferedWriter(new FileWriter(this.path));
    +			FSDataOutputStream outputStream = FileSystem.getLocalFileSystem().create(path, false);
    +			this.writer = new BufferedWriter(new OutputStreamWriter(outputStream));
     		}
&lt;p&gt; catch (final IOException e) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    In my examples (ITCases) I strip the `&lt;a href=&quot;file://&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file://&lt;/a&gt;&quot; prefix before given the path to the spout.&lt;/p&gt;</comment>
                            <comment id="15024450" author="githubbot" created="Tue, 24 Nov 2015 12:56:39 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731094&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731094&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -38,6 +38,8 @@&lt;br/&gt;
     	protected String path = null;&lt;br/&gt;
     	protected BufferedReader reader;&lt;/p&gt;

&lt;p&gt;    +	protected boolean finished;&lt;br/&gt;
    +&lt;br/&gt;
     	public FileSpout() {}&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes. But as the argument from above explains. All spout/bolts should be written in a Flink agnostic way. No Storm developer would write it like this, because this flag does only make sense if you know about `FinitSpout` interface &amp;#8211; but you should not assume to know about it.&lt;/p&gt;</comment>
                            <comment id="15024453" author="githubbot" created="Tue, 24 Nov 2015 12:58:36 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731264&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731264&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FiniteFileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -32,46 +23,17 @@&lt;br/&gt;
     public class FiniteFileSpout extends FileSpout implements FiniteSpout {&lt;br/&gt;
     	private static final long serialVersionUID = -1472978008607215864L;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private String line;&lt;/li&gt;
	&lt;li&gt;private boolean newLineRead;&lt;br/&gt;
    -&lt;br/&gt;
     	public FiniteFileSpout() {}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	public FiniteFileSpout(String path) &lt;/p&gt;
{
     		super(path);
     	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;rawtypes&quot;)&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void open(final Map conf, final TopologyContext context, final SpoutOutputCollector collector) 
{
    -		super.open(conf, context, collector);
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void nextTuple() 
{
    -		this.collector.emit(new Values(line));
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;br/&gt;
     	/**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Can be called before nextTuple() any times including 0.&lt;br/&gt;
     	 */&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public boolean reachedEnd() {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
    -			readLine();
    -		}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
    -			throw new RuntimeException(&quot;Exception occured while reading file &quot; + path);
    -		}&lt;/li&gt;
	&lt;li&gt;return line == null;&lt;br/&gt;
    +		return finished;&lt;br/&gt;
     	}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    It is more elegant. But you have already Flink in mind. Given the Flink agnostic `FileSpout` we have to do it this way. (assume you do not have the source code of `FileSpout` but only the class file and want to extend it with `FiniteSpout` interface)&lt;/p&gt;</comment>
                            <comment id="15024454" author="githubbot" created="Tue, 24 Nov 2015 12:59:27 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731348&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731348&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkClient.java &amp;#8212;&lt;br/&gt;
    @@ -183,10 +183,10 @@ public void submitTopologyWithOpts(final String name, final String uploadedJarLo&lt;/p&gt;

&lt;p&gt;     		/* set storm configuration */&lt;br/&gt;
     		if (this.conf != null) &lt;/p&gt;
{
    -			topology.getConfig().setGlobalJobParameters(new StormConfig(this.conf));
    +			topology.getExecutionEnvironment().getConfig().setGlobalJobParameters(new StormConfig(this.conf));
     		}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I see. Makes sense now.&lt;/p&gt;</comment>
                            <comment id="15024455" author="githubbot" created="Tue, 24 Nov 2015 12:59:30 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731351&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731351&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkClient.java &amp;#8212;&lt;br/&gt;
    @@ -183,10 +183,10 @@ public void submitTopologyWithOpts(final String name, final String uploadedJarLo&lt;/p&gt;

&lt;p&gt;     		/* set storm configuration */&lt;br/&gt;
     		if (this.conf != null) &lt;/p&gt;
{
    -			topology.getConfig().setGlobalJobParameters(new StormConfig(this.conf));
    +			topology.getExecutionEnvironment().getConfig().setGlobalJobParameters(new StormConfig(this.conf));
     		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StreamGraph streamGraph = topology.getStreamGraph();&lt;br/&gt;
    +		final StreamGraph streamGraph = topology.getExecutionEnvironment().getStreamGraph();&lt;br/&gt;
     		streamGraph.setJobName(name);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I see. Makes sense now.&lt;/p&gt;</comment>
                            <comment id="15024460" author="githubbot" created="Tue, 24 Nov 2015 13:01:50 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731544&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731544&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkLocalCluster.java &amp;#8212;&lt;br/&gt;
    @@ -48,12 +49,10 @@&lt;br/&gt;
     	private static final Logger LOG = LoggerFactory.getLogger(FlinkLocalCluster.class);&lt;/p&gt;

&lt;p&gt;     	/** The flink mini cluster on which to execute the programs */&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final FlinkMiniCluster flink;&lt;br/&gt;
    +	private FlinkMiniCluster flink;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;     	public FlinkLocalCluster() &lt;/p&gt;
{
    -		this.flink = new LocalFlinkMiniCluster(new Configuration(), true, StreamingMode.STREAMING);
    -		this.flink.start();
     	}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I just realized that I have something similar in my current work on &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2721&quot; title=&quot;Add Tuple meta information&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2721&quot;&gt;&lt;del&gt;FLINK-2721&lt;/del&gt;&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15024462" author="githubbot" created="Tue, 24 Nov 2015 13:05:08 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731878&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731878&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +					int dop = common.get_parallelism_hint();
    +					outputStream.setParallelism(dop);
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					common.set_parallelism_hint(1);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	private DataStream&amp;lt;Tuple&amp;gt; processInput(String boltId, IRichBolt userBolt,&lt;br/&gt;
    +										GlobalStreamId streamId, Grouping grouping,&lt;br/&gt;
    +										Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Preconditions.checkNotNull(userBolt);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It&apos;s a matter of philosophy I guess. I think it is good enough to test via `assert` (which are enabled in the test). No external user can call this method, so checking if the calling code is correct in the test is sufficient to me.&lt;/p&gt;</comment>
                            <comment id="15024464" author="githubbot" created="Tue, 24 Nov 2015 13:05:26 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731894&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731894&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +					int dop = common.get_parallelism_hint();
    +					outputStream.setParallelism(dop);
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					common.set_parallelism_hint(1);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	private DataStream&amp;lt;Tuple&amp;gt; processInput(String boltId, IRichBolt userBolt,&lt;br/&gt;
    +										GlobalStreamId streamId, Grouping grouping,&lt;br/&gt;
    +										Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Preconditions.checkNotNull(userBolt);&lt;br/&gt;
    +		Preconditions.checkNotNull(boltId);&lt;br/&gt;
    +		Preconditions.checkNotNull(streamId);&lt;br/&gt;
    +		Preconditions.checkNotNull(grouping);&lt;br/&gt;
    +		Preconditions.checkNotNull(producer);&lt;br/&gt;
    +&lt;br/&gt;
    +		final String producerId = streamId.get_componentId();&lt;br/&gt;
    +		final String inputStreamId = streamId.get_streamId();&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStream&amp;lt;Tuple&amp;gt; inputStream = producer.get(inputStreamId);&lt;br/&gt;
    +&lt;br/&gt;
    +		final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +		declarers.put(boltId, declarer);&lt;br/&gt;
    +		userBolt.declareOutputFields(declarer);&lt;br/&gt;
    +		this.outputStreams.put(boltId, declarer.outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +		// if producer was processed already&lt;br/&gt;
    +		if (grouping.is_set_shuffle()) &lt;/p&gt;
{
    +			// Storm uses a round-robin shuffle strategy
    +			inputStream = inputStream.rebalance();
    +		}
&lt;p&gt; else if (grouping.is_set_fields()) {&lt;br/&gt;
    +			// global grouping is emulated in Storm via an empty fields grouping list&lt;br/&gt;
    +			final List&amp;lt;String&amp;gt; fields = grouping.get_fields();&lt;br/&gt;
    +			if (fields.size() &amp;gt; 0) &lt;/p&gt;
{
    +				FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);
    +				inputStream = inputStream.keyBy(prodDeclarer
    +						.getGroupingFieldIndexes(inputStreamId,
    +								grouping.get_fields()));
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				inputStream = inputStream.global();
    +			}
&lt;p&gt;    +		} else if (grouping.is_set_all()) &lt;/p&gt;
{
    +			inputStream = inputStream.broadcast();
    +		}
&lt;p&gt; else if (!grouping.is_set_local_or_shuffle()) &lt;/p&gt;
{
    +			throw new UnsupportedOperationException(
    +					&quot;Flink only supports (local-or-)shuffle, fields, all, and global grouping&quot;);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		return inputStream;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; createOutput(String boltId, IRichBolt bolt, GlobalStreamId streamId, DataStream&amp;lt;Tuple&amp;gt; inputStream) &lt;/p&gt;
{
    +		return createOutput(boltId, bolt, streamId, inputStream, null, null);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; createOutput(String boltId, IRichBolt bolt,&lt;br/&gt;
    +														GlobalStreamId streamId, DataStream&amp;lt;Tuple&amp;gt; inputStream,&lt;br/&gt;
    +														GlobalStreamId streamId2, DataStream&amp;lt;Tuple&amp;gt; inputStream2) {&lt;br/&gt;
    +		Preconditions.checkNotNull(boltId);&lt;br/&gt;
    +		Preconditions.checkNotNull(streamId);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    See above.&lt;/p&gt;</comment>
                            <comment id="15024465" author="githubbot" created="Tue, 24 Nov 2015 13:06:22 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45731988&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45731988&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -75,11 +78,13 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;@param bolt&lt;/li&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param componentId&lt;br/&gt;
    +	 * @param streamId&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@throws IllegalArgumentException&lt;/li&gt;
	&lt;li&gt;If the number of declared output attributes is not with range &lt;span class=&quot;error&quot;&gt;&amp;#91;0;25&amp;#93;&lt;/span&gt;.&lt;br/&gt;
     	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public BoltWrapper(final IRichBolt bolt) throws IllegalArgumentException {&lt;/li&gt;
	&lt;li&gt;this(bolt, null, (Collection&amp;lt;String&amp;gt;) null);&lt;br/&gt;
    +	public BoltWrapper(final IRichBolt bolt, String componentId, String streamId) throws IllegalArgumentException {&lt;br/&gt;
    +		this(bolt, componentId, streamId, null, (Collection&amp;lt;String&amp;gt;) null);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    `TopologyContext` contains this information, too.&lt;/p&gt;</comment>
                            <comment id="15024470" author="githubbot" created="Tue, 24 Nov 2015 13:09:02 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45732254&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45732254&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,6 +45,21 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String streamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String componentId;&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I have already worked on this and I think my solution is smoother as it compute all this stuff automatically under the hood (without the need that the user specifies the name in the constructor). No PR yet as not finished completely. Need to get in sync about it.&lt;/p&gt;</comment>
                            <comment id="15024472" author="githubbot" created="Tue, 24 Nov 2015 13:10:36 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45732371&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45732371&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -150,7 +153,7 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     			}&lt;br/&gt;
     			stormTopology = new StormTopology(spouts, bolts, new HashMap&amp;lt;String, StateSpoutSpec&amp;gt;());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;taskId = context.getIndexOfThisSubtask();&lt;br/&gt;
    +			taskId = context.getIndexOfThisSubtask() + 1;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Are you sure about this? I doubt it (but not 100% sure)&lt;/p&gt;</comment>
                            <comment id="15024473" author="githubbot" created="Tue, 24 Nov 2015 13:11:16 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45732428&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45732428&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -187,14 +190,15 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     				}&lt;br/&gt;
     			}&lt;br/&gt;
     			for (Entry&amp;lt;String, StateSpoutSpec&amp;gt; stateSpout : stateSpouts.entrySet()) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer rc = taskId = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
    +				Integer rc = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
     						.getValue().get_common(), operatorName, context.getIndexOfThisSubtask(),&lt;br/&gt;
     						dop, taskToComponents, componentToSortedTasks, componentToStreamToFields);&lt;br/&gt;
     				if (rc != null) 
{
     					taskId = rc;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;assert (taskId != null);&lt;br/&gt;
    +&lt;br/&gt;
    +			Preconditions.checkNotNull(&quot;Task ID may not be null!&quot;, taskId);&lt;br/&gt;
     		}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Why not readable enough?&lt;/p&gt;</comment>
                            <comment id="15024486" author="githubbot" created="Tue, 24 Nov 2015 13:16:54 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45732952&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45732952&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/StormTupleTest.java &amp;#8212;&lt;br/&gt;
    @@ -595,7 +593,7 @@ public void testGetBinaryByFieldPojoGetter() throws Exception {&lt;br/&gt;
     	private &amp;lt;T&amp;gt; StormTuple testGetByField(int arity, int index, T value)&lt;br/&gt;
     			throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assert (index &amp;lt; arity);&lt;br/&gt;
    +		Assert.assertTrue(index &amp;lt; arity);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Is it? I am not aware if this. Why? Using `assert` to check internal code invariants is the best way to go IMHO.&lt;/p&gt;</comment>
                            <comment id="15024495" author="githubbot" created="Tue, 24 Nov 2015 13:19:50 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733215&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733215&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    We need to fix this... Supporting only 2 inputs is quite weak. Think about a union of many input streams... Join is not the only use case for multiple inputs.&lt;/p&gt;</comment>
                            <comment id="15024498" author="githubbot" created="Tue, 24 Nov 2015 13:21:58 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733403&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733403&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -187,14 +190,15 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     				}&lt;br/&gt;
     			}&lt;br/&gt;
     			for (Entry&amp;lt;String, StateSpoutSpec&amp;gt; stateSpout : stateSpouts.entrySet()) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer rc = taskId = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
    +				Integer rc = processSingleOperator(stateSpout.getKey(), stateSpout&lt;br/&gt;
     						.getValue().get_common(), operatorName, context.getIndexOfThisSubtask(),&lt;br/&gt;
     						dop, taskToComponents, componentToSortedTasks, componentToStreamToFields);&lt;br/&gt;
     				if (rc != null) 
{
     					taskId = rc;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;assert (taskId != null);&lt;br/&gt;
    +&lt;br/&gt;
    +			Preconditions.checkNotNull(&quot;Task ID may not be null!&quot;, taskId);&lt;br/&gt;
     		}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Not &quot;reliable enough&quot; because they are disabled by default &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15024500" author="githubbot" created="Tue, 24 Nov 2015 13:22:26 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733444&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733444&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/join/SingleJoinExample.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,86 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.storm.join;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.testing.FeederSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import backtype.storm.tuple.Values;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import org.apache.flink.storm.util.BoltFileSink;&lt;br/&gt;
    +import org.apache.flink.storm.util.TupleOutputFormatter;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.bolt.SingleJoinBolt;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +public class SingleJoinExample {&lt;br/&gt;
    +&lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    +		final FeederSpout genderSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;gender&quot;));&lt;br/&gt;
    +		final FeederSpout ageSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;age&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can you extend this to use different number of attributes. Makes test more generic I think.&lt;/p&gt;</comment>
                            <comment id="15024501" author="githubbot" created="Tue, 24 Nov 2015 13:22:31 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733449&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733449&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/StormTupleTest.java &amp;#8212;&lt;br/&gt;
    @@ -595,7 +593,7 @@ public void testGetBinaryByFieldPojoGetter() throws Exception {&lt;br/&gt;
     	private &amp;lt;T&amp;gt; StormTuple testGetByField(int arity, int index, T value)&lt;br/&gt;
     			throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assert (index &amp;lt; arity);&lt;br/&gt;
    +		Assert.assertTrue(index &amp;lt; arity);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Because they are disabled during run time. This makes bugs e.g. in stack traces harder to find.&lt;/p&gt;</comment>
                            <comment id="15024505" author="githubbot" created="Tue, 24 Nov 2015 13:24:41 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733689&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733689&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This is an improvement. Before, it would just blindly take one input at a time and create an operator. As far as I understand, Flink only supports two inputs at a time. I would like to address any further improvements in this regard after the merge.&lt;/p&gt;</comment>
                            <comment id="15024512" author="githubbot" created="Tue, 24 Nov 2015 13:25:53 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733816&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733816&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -75,11 +78,13 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;@param bolt&lt;/li&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param componentId&lt;br/&gt;
    +	 * @param streamId&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@throws IllegalArgumentException&lt;/li&gt;
	&lt;li&gt;If the number of declared output attributes is not with range &lt;span class=&quot;error&quot;&gt;&amp;#91;0;25&amp;#93;&lt;/span&gt;.&lt;br/&gt;
     	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public BoltWrapper(final IRichBolt bolt) throws IllegalArgumentException {&lt;/li&gt;
	&lt;li&gt;this(bolt, null, (Collection&amp;lt;String&amp;gt;) null);&lt;br/&gt;
    +	public BoltWrapper(final IRichBolt bolt, String componentId, String streamId) throws IllegalArgumentException {&lt;br/&gt;
    +		this(bolt, componentId, streamId, null, (Collection&amp;lt;String&amp;gt;) null);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Okay, I will check if I can use the information contained in TopologyContext.&lt;/p&gt;</comment>
                            <comment id="15024514" author="githubbot" created="Tue, 24 Nov 2015 13:26:48 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733908&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733908&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,468 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public void increaseNumberOfTasks(final int dop) {&lt;/li&gt;
	&lt;li&gt;assert (dop &amp;gt; 0);&lt;/li&gt;
	&lt;li&gt;this.numberOfTasks += dop;&lt;br/&gt;
    +	public JobExecutionResult execute() throws Exception 
{
    +		return env.execute();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; Map&amp;lt;String, T&amp;gt; getPrivateField(String field) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			Field f = builder.getClass().getDeclaredField(field);
    +			f.setAccessible(true);
    +			return copyObject((Map&amp;lt;String, T&amp;gt;) f.get(builder));
    +		} catch (NoSuchFieldException | IllegalAccessException e) {
    +			throw new RuntimeException(&quot;Couldn&apos;t get &quot; + field + &quot; from TopologyBuilder&quot;, e);
    +		}    +	}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; T copyObject(T object) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		try {
    +			return InstantiationUtil.deserializeObject(
    +					InstantiationUtil.serializeObject(object),
    +					getClass().getClassLoader()
    +			);
    +		} catch (IOException | ClassNotFoundException e) {
    +			throw new RuntimeException(&quot;Failed to copy object.&quot;);
    +		}     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Return the number or required tasks to execute this program.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return the number or required tasks to execute this program&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;public int getNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;return this.numberOfTasks;&lt;br/&gt;
    +	private void translateTopology() {&lt;br/&gt;
    +&lt;br/&gt;
    +		unprocessdInputsPerBolt.clear();&lt;br/&gt;
    +		outputStreams.clear();&lt;br/&gt;
    +		declarers.clear();&lt;br/&gt;
    +		availableInputs.clear();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Storm defaults to parallelism 1&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		/* Translation of topology */&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +		for (final Entry&amp;lt;String, IRichSpout&amp;gt; spout : spouts.entrySet()) {&lt;br/&gt;
    +			final String spoutId = spout.getKey();&lt;br/&gt;
    +			final IRichSpout userSpout = spout.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +			final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();&lt;br/&gt;
    +			userSpout.declareOutputFields(declarer);&lt;br/&gt;
    +			final HashMap&amp;lt;String,Fields&amp;gt; sourceStreams = declarer.outputStreams;&lt;br/&gt;
    +			this.outputStreams.put(spoutId, sourceStreams);&lt;br/&gt;
    +			declarers.put(spoutId, declarer);&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +			final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;();&lt;br/&gt;
    +			final DataStreamSource&amp;lt;?&amp;gt; source;&lt;br/&gt;
    +&lt;br/&gt;
    +			if (sourceStreams.size() == 1) 
{
    +				final SpoutWrapper&amp;lt;Tuple&amp;gt; spoutWrapperSingleOutput = new SpoutWrapper&amp;lt;Tuple&amp;gt;(userSpout);
    +				spoutWrapperSingleOutput.setStormTopology(stormTopology);
    +
    +				final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
    +
    +				DataStreamSource&amp;lt;Tuple&amp;gt; src = env.addSource(spoutWrapperSingleOutput, spoutId,
    +						declarer.getOutputType(outputStreamId));
    +
    +				outputStreams.put(outputStreamId, src);
    +				source = src;
    +			}
&lt;p&gt; else &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				final SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; spoutWrapperMultipleOutputs = new SpoutWrapper&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt;(    +						userSpout);    +				spoutWrapperMultipleOutputs.setStormTopology(stormTopology);    +    +				@SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })    +				DataStreamSource&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; multiSource = env.addSource(    +						spoutWrapperMultipleOutputs, spoutId,    +						(TypeInformation) TypeExtractor.getForClass(SplitStreamType.class));    +    +				SplitStream&amp;lt;SplitStreamType&amp;lt;Tuple&amp;gt;&amp;gt; splitSource = multiSource    +						.split(new StormStreamSelector&amp;lt;Tuple&amp;gt;());    +				for (String streamId }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +			availableInputs.put(spoutId, outputStreams);&lt;br/&gt;
    +&lt;br/&gt;
    +			final ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();&lt;br/&gt;
    +			if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +				int dop = common.get_parallelism_hint();
    +				source.setParallelism(dop);
    +			}
&lt;p&gt; else &lt;/p&gt;
{
    +				common.set_parallelism_hint(1);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		/**&lt;br/&gt;
    +		* 1. Connect all spout streams with bolts streams&lt;br/&gt;
    +		* 2. Then proceed with the bolts stream already connected&lt;br/&gt;
    +		*&lt;br/&gt;
    +		*  Because we do not know the order in which an iterator steps over a set, we might process a consumer before&lt;br/&gt;
    +		* its producer&lt;br/&gt;
    +		* -&amp;gt;thus, we might need to repeat multiple times&lt;br/&gt;
    +		*/&lt;br/&gt;
    +		boolean makeProgress = true;&lt;br/&gt;
    +		while (bolts.size() &amp;gt; 0) {&lt;br/&gt;
    +			if (!makeProgress) &lt;/p&gt;
{
    +				throw new RuntimeException(
    +						&quot;Unable to build Topology. Could not connect the following bolts: &quot;
    +								+ bolts.keySet());
    +			}
&lt;p&gt;    +			makeProgress = false;&lt;br/&gt;
    +&lt;br/&gt;
    +			final Iterator&amp;lt;Entry&amp;lt;String, IRichBolt&amp;gt;&amp;gt; boltsIterator = bolts.entrySet().iterator();&lt;br/&gt;
    +			while (boltsIterator.hasNext()) {&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;String, IRichBolt&amp;gt; bolt = boltsIterator.next();&lt;br/&gt;
    +				final String boltId = bolt.getKey();&lt;br/&gt;
    +				final IRichBolt userBolt = copyObject(bolt.getValue());&lt;br/&gt;
    +&lt;br/&gt;
    +				final ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();&lt;br/&gt;
    +&lt;br/&gt;
    +				Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt; unprocessedBoltInputs = unprocessdInputsPerBolt.get(boltId);&lt;br/&gt;
    +				if (unprocessedBoltInputs == null) &lt;/p&gt;
{
    +					unprocessedBoltInputs = new HashSet&amp;lt;&amp;gt;();
    +					unprocessedBoltInputs.addAll(common.get_inputs().entrySet());
    +					unprocessdInputsPerBolt.put(boltId, unprocessedBoltInputs);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				// check if all inputs are available&lt;br/&gt;
    +				final int numberOfInputs = unprocessedBoltInputs.size();&lt;br/&gt;
    +				int inputsAvailable = 0;&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; entry : unprocessedBoltInputs) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +					final String producerId = entry.getKey().get_componentId();    +					final String streamId = entry.getKey().get_streamId();    +					final HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; streams = availableInputs.get(producerId);    +					if (streams != null &amp;amp;&amp;amp; streams.get(streamId) != null) {
    +						inputsAvailable++;
    +					}    +				}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +&lt;br/&gt;
    +				if (inputsAvailable != numberOfInputs) &lt;/p&gt;
{
    +					// traverse other bolts first until inputs are available
    +					continue;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					makeProgress = true;
    +					boltsIterator.remove();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Map&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; inputStreams = new HashMap&amp;lt;&amp;gt;(numberOfInputs);&lt;br/&gt;
    +&lt;br/&gt;
    +				for (Entry&amp;lt;GlobalStreamId, Grouping&amp;gt; input : unprocessedBoltInputs) &lt;/p&gt;
{
    +					final GlobalStreamId streamId = input.getKey();
    +					final Grouping grouping = input.getValue();
    +
    +					final String producerId = streamId.get_componentId();
    +
    +					final Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer = availableInputs.get(producerId);
    +
    +					inputStreams.put(streamId, processInput(boltId, userBolt, streamId, grouping, producer));
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				final Iterator&amp;lt;Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; iterator = inputStreams.entrySet().iterator();&lt;br/&gt;
    +&lt;br/&gt;
    +				final Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; firstInput = iterator.next();&lt;br/&gt;
    +				GlobalStreamId streamId = firstInput.getKey();&lt;br/&gt;
    +				DataStream&amp;lt;Tuple&amp;gt; inputStream = firstInput.getValue();&lt;br/&gt;
    +&lt;br/&gt;
    +				final SingleOutputStreamOperator&amp;lt;?, ?&amp;gt; outputStream;&lt;br/&gt;
    +&lt;br/&gt;
    +				switch (numberOfInputs) &lt;/p&gt;
{
    +					case 1:
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream);
    +						break;
    +					case 2:
    +						Entry&amp;lt;GlobalStreamId, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; secondInput = iterator.next();
    +						GlobalStreamId streamId2 = secondInput.getKey();
    +						DataStream&amp;lt;Tuple&amp;gt; inputStream2 = secondInput.getValue();
    +						outputStream = createOutput(boltId, userBolt, streamId, inputStream, streamId2, inputStream2);
    +						break;
    +					default:
    +						throw new UnsupportedOperationException(&quot;Don&apos;t know how to translate a bolt &quot;
    +								+ boltId + &quot; with &quot; + numberOfInputs + &quot; inputs.&quot;);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				if (common.is_set_parallelism_hint()) &lt;/p&gt;
{
    +					int dop = common.get_parallelism_hint();
    +					outputStream.setParallelism(dop);
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					common.set_parallelism_hint(1);
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	private DataStream&amp;lt;Tuple&amp;gt; processInput(String boltId, IRichBolt userBolt,&lt;br/&gt;
    +										GlobalStreamId streamId, Grouping grouping,&lt;br/&gt;
    +										Map&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt; producer) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Preconditions.checkNotNull(userBolt);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes, but these checks can be executed during run time of the user program. Assert only checks these when debugging is enabled.&lt;/p&gt;</comment>
                            <comment id="15024515" author="githubbot" created="Tue, 24 Nov 2015 13:27:30 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45733970&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45733970&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/StormTupleTest.java &amp;#8212;&lt;br/&gt;
    @@ -595,7 +593,7 @@ public void testGetBinaryByFieldPojoGetter() throws Exception {&lt;br/&gt;
     	private &amp;lt;T&amp;gt; StormTuple testGetByField(int arity, int index, T value)&lt;br/&gt;
     			throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assert (index &amp;lt; arity);&lt;br/&gt;
    +		Assert.assertTrue(index &amp;lt; arity);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    But not in testing scenario (ie, while executing JUnit and ITCase asserts are enabled). &lt;/p&gt;</comment>
                            <comment id="15024519" author="githubbot" created="Tue, 24 Nov 2015 13:29:28 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45734177&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45734177&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FiniteFileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -32,46 +23,17 @@&lt;br/&gt;
     public class FiniteFileSpout extends FileSpout implements FiniteSpout {&lt;br/&gt;
     	private static final long serialVersionUID = -1472978008607215864L;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private String line;&lt;/li&gt;
	&lt;li&gt;private boolean newLineRead;&lt;br/&gt;
    -&lt;br/&gt;
     	public FiniteFileSpout() {}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	public FiniteFileSpout(String path) &lt;/p&gt;
{
     		super(path);
     	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;rawtypes&quot;)&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void open(final Map conf, final TopologyContext context, final SpoutOutputCollector collector) 
{
    -		super.open(conf, context, collector);
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void nextTuple() 
{
    -		this.collector.emit(new Values(line));
    -		newLineRead = false;
    -	}
&lt;p&gt;    -&lt;br/&gt;
     	/**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Can be called before nextTuple() any times including 0.&lt;br/&gt;
     	 */&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public boolean reachedEnd() {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
    -			readLine();
    -		}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
    -			throw new RuntimeException(&quot;Exception occured while reading file &quot; + path);
    -		}&lt;/li&gt;
	&lt;li&gt;return line == null;&lt;br/&gt;
    +		return finished;&lt;br/&gt;
     	}
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Following your argument, we should also remove the `FiniteSpout` functionality, because it is not included in Storm as well. I&apos;ll revert this but I don&apos;t understand your argument.&lt;/p&gt;</comment>
                            <comment id="15024520" author="githubbot" created="Tue, 24 Nov 2015 13:29:57 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45734220&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45734220&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -38,6 +38,8 @@&lt;br/&gt;
     	protected String path = null;&lt;br/&gt;
     	protected BufferedReader reader;&lt;/p&gt;

&lt;p&gt;    +	protected boolean finished;&lt;br/&gt;
    +&lt;br/&gt;
     	public FileSpout() {}&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Okay, I&apos;ll revert although `FiniteSpout` is Flink specific as well...&lt;/p&gt;</comment>
                            <comment id="15024522" author="githubbot" created="Tue, 24 Nov 2015 13:30:51 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45734323&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45734323&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -40,16 +43,17 @@ public BoltFileSink(final String path) {&lt;/p&gt;

&lt;p&gt;     	public BoltFileSink(final String path, final OutputFormatter formatter) &lt;/p&gt;
{
     		super(formatter);
    -		this.path = path;
    +		this.path = new Path(path);
     	}

&lt;p&gt;     	@SuppressWarnings(&quot;rawtypes&quot;)&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public void prepareSimple(final Map stormConf, final TopologyContext context) {&lt;br/&gt;
     		try &lt;/p&gt;
{
    -			this.writer = new BufferedWriter(new FileWriter(this.path));
    +			FSDataOutputStream outputStream = FileSystem.getLocalFileSystem().create(path, false);
    +			this.writer = new BufferedWriter(new OutputStreamWriter(outputStream));
     		}
&lt;p&gt; catch (final IOException e) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    That&apos;s odd but if so I&apos;d change this to strip the &lt;a href=&quot;file://&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file://&lt;/a&gt; prefix.&lt;/p&gt;</comment>
                            <comment id="15024524" author="githubbot" created="Tue, 24 Nov 2015 13:32:02 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45734441&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45734441&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -18,20 +18,23 @@&lt;br/&gt;
     package org.apache.flink.storm.util;&lt;/p&gt;

&lt;p&gt;     import backtype.storm.task.TopologyContext;&lt;br/&gt;
    +import org.apache.flink.core.fs.FSDataOutputStream;&lt;br/&gt;
    +import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
    +import org.apache.flink.core.fs.Path;&lt;/p&gt;

&lt;p&gt;     import java.io.BufferedWriter;&lt;br/&gt;
    -import java.io.FileWriter;&lt;br/&gt;
     import java.io.IOException;&lt;br/&gt;
    +import java.io.OutputStreamWriter;&lt;br/&gt;
     import java.util.Map;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Implements a sink that write the received data to the given file (as a result of 
{@code Object.toString()} for each&lt;br/&gt;
    + * Implements a sink that writes the received data to the given file (as a result of {@code Object.toString()}
&lt;p&gt; for each&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;attribute).&lt;br/&gt;
      */&lt;br/&gt;
     public final class BoltFileSink extends AbstractBoltSink {&lt;br/&gt;
     	private static final long serialVersionUID = 2014027288631273666L;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final String path;&lt;br/&gt;
    +	private final Path path;&lt;br/&gt;
     	private BufferedWriter writer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    So people download Flink and learn about the Storm compatibility layer to write spouts/bolts which they use in Storm topologies that run without Flink? That is beyond my imagination &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15024525" author="githubbot" created="Tue, 24 Nov 2015 13:36:26 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45734993&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45734993&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/FileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -38,6 +38,8 @@&lt;br/&gt;
     	protected String path = null;&lt;br/&gt;
     	protected BufferedReader reader;&lt;/p&gt;

&lt;p&gt;    +	protected boolean finished;&lt;br/&gt;
    +&lt;br/&gt;
     	public FileSpout() {}&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The point it the following. `FileSpout` is a Flink agnostic implementation that is improved in a Flink aware way by `FiniteFileSpout`. Thus, `FileSpout` should be implemented the Storm way without any knowledge of Flink. And `FiniteFileSpout` should use Flink stuff, but not change the code of `FileSpout`.&lt;/p&gt;</comment>
                            <comment id="15024530" author="githubbot" created="Tue, 24 Nov 2015 13:41:02 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45735762&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45735762&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/util/BoltFileSink.java &amp;#8212;&lt;br/&gt;
    @@ -18,20 +18,23 @@&lt;br/&gt;
     package org.apache.flink.storm.util;&lt;/p&gt;

&lt;p&gt;     import backtype.storm.task.TopologyContext;&lt;br/&gt;
    +import org.apache.flink.core.fs.FSDataOutputStream;&lt;br/&gt;
    +import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
    +import org.apache.flink.core.fs.Path;&lt;/p&gt;

&lt;p&gt;     import java.io.BufferedWriter;&lt;br/&gt;
    -import java.io.FileWriter;&lt;br/&gt;
     import java.io.IOException;&lt;br/&gt;
    +import java.io.OutputStreamWriter;&lt;br/&gt;
     import java.util.Map;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Implements a sink that write the received data to the given file (as a result of 
{@code Object.toString()} for each&lt;br/&gt;
    + * Implements a sink that writes the received data to the given file (as a result of {@code Object.toString()}
&lt;p&gt; for each&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;attribute).&lt;br/&gt;
      */&lt;br/&gt;
     public final class BoltFileSink extends AbstractBoltSink {&lt;br/&gt;
     	private static final long serialVersionUID = 2014027288631273666L;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final String path;&lt;br/&gt;
    +	private final Path path;&lt;br/&gt;
     	private BufferedWriter writer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    No. People will have spout/bolt code they do not want to touch when running it in Flink. Thus there code will be written in the same way &amp;#8211; and so should be example be. Otherwise, we deliver the impression they need to change there code &amp;#8211; but they don&apos;t. Thus, we implement the example Spout/Bolts in a pure Storm way. Of course, if somebody develops a new Spout/Bolt with Flink in mind, your approach makes sense. However, this is not the main focus (it would be even better if the code new stuff Flink native in embedded mode, instead of develop Spout/Bolts which are Flink tailored).&lt;/p&gt;</comment>
                            <comment id="15024584" author="githubbot" created="Tue, 24 Nov 2015 14:21:30 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45740238&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45740238&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/join/SingleJoinExample.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,86 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.storm.join;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.testing.FeederSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import backtype.storm.tuple.Values;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import org.apache.flink.storm.util.BoltFileSink;&lt;br/&gt;
    +import org.apache.flink.storm.util.TupleOutputFormatter;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.bolt.SingleJoinBolt;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +public class SingleJoinExample {&lt;br/&gt;
    +&lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    +		final FeederSpout genderSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;gender&quot;));&lt;br/&gt;
    +		final FeederSpout ageSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;age&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You mean different number of fields?&lt;/p&gt;</comment>
                            <comment id="15024590" author="githubbot" created="Tue, 24 Nov 2015 14:25:35 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45740805&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45740805&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/join/SingleJoinExample.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,86 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.storm.join;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.testing.FeederSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import backtype.storm.tuple.Values;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import org.apache.flink.storm.util.BoltFileSink;&lt;br/&gt;
    +import org.apache.flink.storm.util.TupleOutputFormatter;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.bolt.SingleJoinBolt;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +public class SingleJoinExample {&lt;br/&gt;
    +&lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    +		final FeederSpout genderSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;gender&quot;));&lt;br/&gt;
    +		final FeederSpout ageSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;age&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; For example, 2 fields for one input and 3 fields for the other input. (The idea is to have different number for both inputs to make sure the input schemas of both can differ not only by their types and also by their number of attributes)&lt;/p&gt;</comment>
                            <comment id="15024595" author="githubbot" created="Tue, 24 Nov 2015 14:28:31 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45741186&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45741186&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Agreed. My concern was to get the join working but union should also be supported for same data output types. Could we do that in a follow-up?&lt;/p&gt;</comment>
                            <comment id="15024596" author="githubbot" created="Tue, 24 Nov 2015 14:30:11 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45741402&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45741402&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/join/SingleJoinExample.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,86 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.storm.join;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.testing.FeederSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import backtype.storm.tuple.Values;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import org.apache.flink.storm.util.BoltFileSink;&lt;br/&gt;
    +import org.apache.flink.storm.util.TupleOutputFormatter;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.bolt.SingleJoinBolt;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +public class SingleJoinExample {&lt;br/&gt;
    +&lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    +		final FeederSpout genderSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;gender&quot;));&lt;br/&gt;
    +		final FeederSpout ageSpout = new FeederSpout(new Fields(&quot;id&quot;, &quot;age&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Okay should be doable.&lt;/p&gt;</comment>
                            <comment id="15024605" author="githubbot" created="Tue, 24 Nov 2015 14:35:42 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45742093&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45742093&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Well. From a Storm point of view, there is only `union`. As it is the generic Storm case it includes the join case. I guess you specialized join solution would be obsolete after generic union is supported. Therefore, I would prefer to get it right from the beginning on... My idea would be to try to get rid of `TwoInputBoltWrapper` and &quot;union&quot; the incoming streams somehow to feed a single stream to `BoltWrapper`. The tricky part is, that we cannot use Flink&apos;s `union` because it assume the same input type, but Storm can union different types into one stream... What do you think about this idea? &lt;/p&gt;</comment>
                            <comment id="15024614" author="githubbot" created="Tue, 24 Nov 2015 14:46:21 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45743505&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45743505&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Well. Get it right from the beginning. I think it was all but right until now &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; And in this regard, its much more defined now. At least you get an error if you have more than two inputs.&lt;/p&gt;

&lt;p&gt;    I agree that we should fix this. But it&apos;s going to be a bit tricky because we have to hack around Flink&apos;s limitation. I would rather not do this in this pull request.&lt;/p&gt;</comment>
                            <comment id="15024624" author="githubbot" created="Tue, 24 Nov 2015 14:52:52 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45744427&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45744427&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I see you point. But this PR might be too big anyway. You try to do 3 thing at the same time (two are backed up by a JIRA). How hard would it be to split this PR? Last but not least, the multi-input-stream JIRA is not resolved by this. &lt;span class=&quot;error&quot;&gt;&amp;#91;And the second JIRA you try to resolve is assigned to me, and I have already worked on it -- I actually would like to finish my work on it&amp;#93;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="15024658" author="githubbot" created="Tue, 24 Nov 2015 15:15:35 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45747566&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45747566&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I was actually not specifically trying to address JIRA issues but just fixed everything I discovered on the way while trying out the compatibility layer. Only after fixing I realized there are open JIRA issues. One is assigned to me (&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2837&quot; title=&quot;FlinkTopologyBuilder cannot handle multiple input streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2837&quot;&gt;&lt;del&gt;FLINK-2837&lt;/del&gt;&lt;/a&gt;] and the other one (&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2721&quot; title=&quot;Add Tuple meta information&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2721&quot;&gt;&lt;del&gt;FLINK-2721&lt;/del&gt;&lt;/a&gt;) is open since two months. I think it would be a shame not to merge this pull request soon. It provides a good foundation to address any further issues. Splitting this PR should not be trivial with all the changes.&lt;/p&gt;

&lt;p&gt;    I already accommodated you with the API changes. Also, I would like to address most of your comments but I&apos;m not too inclined to split up this PR (if it is even possible). Could you base your work on this pull request and do a follow-up? &lt;/p&gt;</comment>
                            <comment id="15024785" author="githubbot" created="Tue, 24 Nov 2015 16:32:05 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45758926&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45758926&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -180,8 +178,6 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     		builder.setBolt(&quot;bolt2&quot;, (IRichBolt) operators.get(&quot;bolt2&quot;), dops.get(&quot;bolt2&quot;)).allGrouping(&quot;spout2&quot;);&lt;br/&gt;
     		builder.setBolt(&quot;sink&quot;, (IRichBolt) operators.get(&quot;sink&quot;), dops.get(&quot;sink&quot;))&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.groupingStreamId)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt1&quot;, TestDummyBolt.shuffleStreamId)&lt;/li&gt;
	&lt;li&gt;.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.groupingStreamId)&lt;br/&gt;
     				.shuffleGrouping(&quot;bolt2&quot;, TestDummyBolt.shuffleStreamId);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Don&apos;t understand me wrong. I don&apos;t want to discard your work! And I believe that you did not intent do get a &quot;messy&quot; PR. But that&apos;s the current state.&lt;/p&gt;

&lt;p&gt;    I think we can refine and merge it. But it does not resolve &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2837&quot; title=&quot;FlinkTopologyBuilder cannot handle multiple input streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2837&quot;&gt;&lt;del&gt;FLINK-2837&lt;/del&gt;&lt;/a&gt; even if it improves on it. I would also assume, that your union code will be reworked heavily later on... Not sure about your tuple meta information code. Need to have a look in detail. That is the reason why I had the idea to apply the discussed API changes only in a single PR. But if this is too complex, we should just carry on with this PR.&lt;/p&gt;

&lt;p&gt;    Btw: even if the JIRA is quite old it is not assigned to you; thus you should have ask about it. You did the same with &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2837&quot; title=&quot;FlinkTopologyBuilder cannot handle multiple input streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2837&quot;&gt;&lt;del&gt;FLINK-2837&lt;/del&gt;&lt;/a&gt; which was assigned to me, too &amp;#8211; I did not work in it yet so a assigned it to you (I thought as you did have the union code together with the API changes, that should be fine).&lt;/p&gt;

&lt;p&gt;    Additionally, the reason I just assigned it to you was, that &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2837&quot; title=&quot;FlinkTopologyBuilder cannot handle multiple input streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2837&quot;&gt;&lt;del&gt;FLINK-2837&lt;/del&gt;&lt;/a&gt; is actually a requirement for &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2721&quot; title=&quot;Add Tuple meta information&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2721&quot;&gt;&lt;del&gt;FLINK-2721&lt;/del&gt;&lt;/a&gt;. That is why I stopped working on it back than, but did not have time to fix &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2837&quot; title=&quot;FlinkTopologyBuilder cannot handle multiple input streams&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2837&quot;&gt;&lt;del&gt;FLINK-2837&lt;/del&gt;&lt;/a&gt; either. I did not assume that you tackle the join-case which does require the tuple meta info... A regular union does not require it.&lt;/p&gt;

&lt;p&gt;    Anyway. Just let us get this PR done. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                            <comment id="15026612" author="githubbot" created="Wed, 25 Nov 2015 11:03:08 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45854121&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45854121&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -150,7 +153,7 @@ static synchronized TopologyContext createTopologyContext(&lt;br/&gt;
     			}&lt;br/&gt;
     			stormTopology = new StormTopology(spouts, bolts, new HashMap&amp;lt;String, StateSpoutSpec&amp;gt;());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;taskId = context.getIndexOfThisSubtask();&lt;br/&gt;
    +			taskId = context.getIndexOfThisSubtask() + 1;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Actually, it doesn&apos;t matter. I set this before changing the topology parsing logic. For some topologies it would only run with this fix. But this has been fixed so the +1 is not necessary anymore.&lt;/p&gt;</comment>
                            <comment id="15026931" author="githubbot" created="Wed, 25 Nov 2015 15:31:26 +0000"  >&lt;p&gt;Github user mxm commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#issuecomment-159641971&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#issuecomment-159641971&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I&apos;ve rebased to the latest master and addressed your comments. I would like to merge this and programmatically fix the multiple inputs issue afterwards.&lt;/p&gt;</comment>
                            <comment id="15027013" author="githubbot" created="Wed, 25 Nov 2015 16:14:09 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45885529&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45885529&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/print/PrintSampleStream.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,61 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.storm.print;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.spout.TwitterSampleSpout;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Prints incoming tweets. Tweets can be filtered by keywords.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class PrintSampleStream {        &lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    What is the purpose of this example? Does it show anything special?&lt;/p&gt;</comment>
                            <comment id="15027014" author="githubbot" created="Wed, 25 Nov 2015 16:14:50 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45885615&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45885615&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/split/operators/RandomSpout.java &amp;#8212;&lt;br/&gt;
    @@ -17,9 +17,6 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.split.operators;&lt;/p&gt;

&lt;p&gt;    -import java.util.Map;&lt;br/&gt;
    -import java.util.Random;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027015" author="githubbot" created="Wed, 25 Nov 2015 16:14:55 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45885626&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45885626&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/split/operators/VerifyAndEnrichBolt.java &amp;#8212;&lt;br/&gt;
    @@ -17,8 +17,6 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.split.operators;&lt;/p&gt;

&lt;p&gt;    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027027" author="githubbot" created="Wed, 25 Nov 2015 16:21:20 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45886387&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45886387&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/wordcount/WordCountLocal.java &amp;#8212;&lt;br/&gt;
    @@ -57,16 +57,13 @@ public static void main(final String[] args) throws Exception {&lt;br/&gt;
     		}&lt;/p&gt;

&lt;p&gt;     		// build Topology the Storm way&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final FlinkTopologyBuilder builder = WordCountTopology.buildTopology();&lt;br/&gt;
    +		final TopologyBuilder builder = WordCountTopology.buildTopology(false);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Please remove `false` &amp;#8211; this test should use index (and not name) to specify the key. `WordCountLocalByName` does it the other way round such that both cases are covered.&lt;/p&gt;</comment>
                            <comment id="15027029" author="githubbot" created="Wed, 25 Nov 2015 16:22:13 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45886536&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45886536&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/wordcount/SpoutSourceWordCount.java &amp;#8212;&lt;br/&gt;
    @@ -19,7 +19,6 @@&lt;/p&gt;

&lt;p&gt;     import backtype.storm.topology.IRichSpout;&lt;br/&gt;
     import backtype.storm.utils.Utils;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027031" author="githubbot" created="Wed, 25 Nov 2015 16:22:38 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45886597&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45886597&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/wordcount/operators/WordCountDataPojos.java &amp;#8212;&lt;br/&gt;
    @@ -17,10 +17,10 @@&lt;/p&gt;

&lt;p&gt;     package org.apache.flink.storm.wordcount.operators;&lt;/p&gt;

&lt;p&gt;    -import java.io.Serializable;&lt;br/&gt;
    -&lt;br/&gt;
     import org.apache.flink.examples.java.wordcount.util.WordCountData;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027033" author="githubbot" created="Wed, 25 Nov 2015 16:22:48 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45886615&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45886615&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/wordcount/operators/WordCountFileSpout.java &amp;#8212;&lt;br/&gt;
    @@ -17,10 +17,9 @@&lt;/p&gt;

&lt;p&gt;     package org.apache.flink.storm.wordcount.operators;&lt;/p&gt;

&lt;p&gt;    -import org.apache.flink.storm.util.FileSpout;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027040" author="githubbot" created="Wed, 25 Nov 2015 16:24:06 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45886799&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45886799&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/test/java/org/apache/flink/storm/split/SplitBolt.java &amp;#8212;&lt;br/&gt;
    @@ -17,8 +17,6 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.split;&lt;/p&gt;

&lt;p&gt;    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027054" author="githubbot" created="Wed, 25 Nov 2015 16:29:01 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45887487&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45887487&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkLocalCluster.java &amp;#8212;&lt;br/&gt;
    @@ -99,6 +111,7 @@ public void rebalance(final String name, final RebalanceOptions options) {&lt;/p&gt;

&lt;p&gt;     	public void shutdown() {&lt;br/&gt;
     		flink.stop();&lt;br/&gt;
    +		flink = null;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Should be kept. Otherwise, calling `submitTopologyWithOpts` a second time will run into a NPE. (Or add proper exception as `else` of `if (flink == null)` check, ie, &quot;Cannot run topology. Cluster got shut down.&quot; or similar.)&lt;/p&gt;</comment>
                            <comment id="15027061" author="githubbot" created="Wed, 25 Nov 2015 16:32:24 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45887969&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45887969&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkOutputFieldsDeclarer.java &amp;#8212;&lt;br/&gt;
    @@ -20,11 +20,9 @@&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
     import backtype.storm.utils.Utils;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027078" author="githubbot" created="Wed, 25 Nov 2015 16:38:41 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45888777&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45888777&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,474 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}
&lt;p&gt;, or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;br/&gt;
     	 *&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    typo: Strom with capital letter&lt;br/&gt;
    &quot;Flink program&quot; or &quot;Flink job&quot; (not &quot;Flink topology&quot; &amp;#8211; if you keep it as is also fine. &amp;#8211; I personally prefer the use topology only for Storm to avoid confusion in terminology)&lt;br/&gt;
    Typo: topology with lower case letter&lt;/p&gt;</comment>
                            <comment id="15027081" author="githubbot" created="Wed, 25 Nov 2015 16:39:17 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45888894&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45888894&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,474 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    add JavaDoc link to `ExecutionEnvironment`&lt;/p&gt;</comment>
                            <comment id="15027083" author="githubbot" created="Wed, 25 Nov 2015 16:41:03 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45889142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45889142&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,474 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Can we describe the exception in a meaningful way? Or are there too many reasons to get listed here? What does JavaDoc of `env.execute()` say?&lt;/p&gt;</comment>
                            <comment id="15027086" author="githubbot" created="Wed, 25 Nov 2015 16:41:55 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45889260&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45889260&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/print/PrintSampleStream.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,61 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.storm.print;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.spout.TwitterSampleSpout;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Prints incoming tweets. Tweets can be filtered by keywords.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class PrintSampleStream {        &lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It shows how to run an existing Storm topology with Flink. It prints from Twitter which is kind of neat. It&apos;s also included in Storm. It&apos;s nice to have some other examples other than WordCount. This was actually not working before this PR...&lt;/p&gt;</comment>
                            <comment id="15027087" author="githubbot" created="Wed, 25 Nov 2015 16:43:09 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45889473&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45889473&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltCollector.java &amp;#8212;&lt;br/&gt;
    @@ -19,7 +19,6 @@&lt;/p&gt;

&lt;p&gt;     import backtype.storm.task.IOutputCollector;&lt;br/&gt;
     import backtype.storm.tuple.Tuple;&lt;br/&gt;
    -&lt;br/&gt;
     import org.apache.flink.api.java.tuple.Tuple0;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027091" author="githubbot" created="Wed, 25 Nov 2015 16:45:46 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45889838&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45889838&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -53,21 +51,26 @@&lt;br/&gt;
     	private static final long serialVersionUID = -4788589118464155835L;&lt;/p&gt;

&lt;p&gt;     	/** The wrapped Storm &lt;/p&gt;
{@link IRichBolt bolt}
&lt;p&gt;. */&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final IRichBolt bolt;&lt;br/&gt;
    +	protected final IRichBolt bolt;&lt;br/&gt;
     	/** The name of the bolt. */&lt;br/&gt;
     	private final String name;&lt;br/&gt;
     	/** Number of attributes of the bolt&apos;s output tuples per stream. */&lt;/li&gt;
	&lt;li&gt;private final HashMap&amp;lt;String, Integer&amp;gt; numberOfAttributes;&lt;br/&gt;
    +	protected final HashMap&amp;lt;String, Integer&amp;gt; numberOfAttributes;&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the input stream. */&lt;/li&gt;
	&lt;li&gt;private final Fields inputSchema;&lt;br/&gt;
    +	protected final Fields inputSchema;&lt;br/&gt;
     	/** The original Storm topology. */&lt;br/&gt;
     	protected StormTopology stormTopology;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +	protected transient TopologyContext topologyContext;&lt;br/&gt;
    +&lt;br/&gt;
    +	protected final String inputComponentId;&lt;br/&gt;
    +	protected final String inputStreamId;&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Please add JavaDoc to those three.&lt;/p&gt;</comment>
                            <comment id="15027092" author="githubbot" created="Wed, 25 Nov 2015 16:46:29 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45889924&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45889924&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -77,11 +80,13 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;@param bolt&lt;/li&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param inputStreamId&lt;br/&gt;
    +	 * @param inputComponentId&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    JavaDoc incomplete &amp;#8211; same below &amp;#8211; will not mark it again. Please complete everywhere.&lt;/p&gt;</comment>
                            <comment id="15027093" author="githubbot" created="Wed, 25 Nov 2015 16:47:29 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45890041&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45890041&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -89,17 +94,16 @@ public BoltWrapper(final IRichBolt bolt) throws IllegalArgumentException {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;used within a Flink streaming program. The given input schema enable attribute-by-name access for input types&lt;/li&gt;
	&lt;li&gt;{@link Tuple0} to {@link Tuple25}. The output type will be one of {@link Tuple0}
&lt;p&gt; to &lt;/p&gt;
{@link Tuple25}
&lt;p&gt; depending on&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;the bolt&apos;s declared number of attributes.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param bolt&lt;br/&gt;
    +	 *  @param bolt&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    delete one space before `@param`&lt;/p&gt;</comment>
                            <comment id="15027098" author="githubbot" created="Wed, 25 Nov 2015 16:49:32 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45890269&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45890269&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -89,17 +94,16 @@ public BoltWrapper(final IRichBolt bolt) throws IllegalArgumentException {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;used within a Flink streaming program. The given input schema enable attribute-by-name access for input types&lt;/li&gt;
	&lt;li&gt;{@link Tuple0} to {@link Tuple25}. The output type will be one of {@link Tuple0}
&lt;p&gt; to &lt;/p&gt;
{@link Tuple25}
&lt;p&gt; depending on&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;the bolt&apos;s declared number of attributes.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param bolt&lt;br/&gt;
    +	 *  @param bolt&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param inputStreamId&lt;br/&gt;
    +	 * @param inputComponentId&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@param inputSchema&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*            The schema (ie, ordered field names) of the input stream.&lt;/li&gt;
	&lt;li&gt;* @throws IllegalArgumentException&lt;/li&gt;
	&lt;li&gt;*             If the number of declared output attributes is not with range &lt;span class=&quot;error&quot;&gt;&amp;#91;0;25&amp;#93;&lt;/span&gt;.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Why do you delete `@throws` ? More documentation is always better.&lt;/p&gt;</comment>
                            <comment id="15027099" author="githubbot" created="Wed, 25 Nov 2015 16:49:44 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45890289&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45890289&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -108,20 +112,19 @@ public BoltWrapper(final IRichBolt bolt, final Fields inputSchema)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;for POJO input types. The output type can be any type if parameter 
{@code rawOutput} is {@code true} and the&lt;br/&gt;
     	 * bolt&apos;s number of declared output tuples is 1. If {@code rawOutput}
&lt;p&gt; is &lt;/p&gt;
{@code false}
&lt;p&gt; the output type will be one&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;of 
{@link Tuple0}
&lt;p&gt; to &lt;/p&gt;
{@link Tuple25}
&lt;p&gt; depending on the bolt&apos;s declared number of attributes.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param bolt&lt;br/&gt;
    +	 *  @param bolt
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    space&lt;/p&gt;</comment>
                            <comment id="15027101" author="githubbot" created="Wed, 25 Nov 2015 16:50:32 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45890399&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45890399&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -108,20 +112,19 @@ public BoltWrapper(final IRichBolt bolt, final Fields inputSchema)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;for POJO input types. The output type can be any type if parameter 
{@code rawOutput} is {@code true} and the&lt;br/&gt;
     	 * bolt&apos;s number of declared output tuples is 1. If {@code rawOutput}
&lt;p&gt; is &lt;/p&gt;
{@code false}
&lt;p&gt; the output type will be one&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;of 
{@link Tuple0}
&lt;p&gt; to &lt;/p&gt;
{@link Tuple25}
&lt;p&gt; depending on the bolt&apos;s declared number of attributes.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param bolt&lt;br/&gt;
    +	 *  @param bolt&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;The Storm 
{@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param inputStreamId&lt;br/&gt;
    +	 * @param inputComponentId&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@param rawOutputs&lt;/li&gt;
	&lt;li&gt;Contains stream names if a single attribute output stream, should not be of type 
{@link Tuple1}
&lt;p&gt; but be&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*            of a raw type.&lt;/li&gt;
	&lt;li&gt;* @throws IllegalArgumentException
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    keep `@throws`&lt;/p&gt;</comment>
                            <comment id="15027106" author="githubbot" created="Wed, 25 Nov 2015 16:53:21 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45890812&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45890812&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapperTwoInput.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,130 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.storm.wrappers;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple0;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple25;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.TwoInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * A &lt;/p&gt;
{@link BoltWrapperTwoInput}
&lt;p&gt; wraps an &lt;/p&gt;
{@link IRichBolt}
&lt;p&gt; in order to execute the Storm bolt within a Flink Streaming&lt;br/&gt;
    + * program. In contrast to &lt;/p&gt;
{@link BoltWrapper}
&lt;p&gt;, this wrapper takes two input stream as input.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class BoltWrapperTwoInput&amp;lt;IN1, IN2, OUT&amp;gt; extends BoltWrapper&amp;lt;IN1, OUT&amp;gt; implements TwoInputStreamOperator&amp;lt;IN1, IN2, OUT&amp;gt; {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** The schema (ie, ordered field names) of the second input stream. */&lt;br/&gt;
    +	private final Fields inputSchema2;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final String componentId2;&lt;br/&gt;
    +	private final String streamId2;&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    missing JavaDoc for both members&lt;/p&gt;</comment>
                            <comment id="15027112" author="githubbot" created="Wed, 25 Nov 2015 16:54:22 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45890935&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45890935&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapperTwoInput.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,130 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.storm.wrappers;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple0;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple25;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.TwoInputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.watermark.Watermark;&lt;br/&gt;
    +import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * A &lt;/p&gt;
{@link BoltWrapperTwoInput} wraps an {@link IRichBolt} in order to execute the Storm bolt within a Flink Streaming&lt;br/&gt;
    + * program. In contrast to {@link BoltWrapper}, this wrapper takes two input stream as input.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class BoltWrapperTwoInput&amp;lt;IN1, IN2, OUT&amp;gt; extends BoltWrapper&amp;lt;IN1, OUT&amp;gt; implements TwoInputStreamOperator&amp;lt;IN1, IN2, OUT&amp;gt; {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** The schema (ie, ordered field names) of the second input stream. */&lt;br/&gt;
    +	private final Fields inputSchema2;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final String componentId2;&lt;br/&gt;
    +	private final String streamId2;&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Instantiates a new {@link BoltWrapperTwoInput}
&lt;p&gt; that wraps the given Storm &lt;/p&gt;
{@link IRichBolt bolt} such that it can be&lt;br/&gt;
    +	 * used within a Flink streaming program. The given input schema enable attribute-by-name access for input types&lt;br/&gt;
    +	 * {@link Tuple0} to {@link Tuple25}. The output type can be any type if parameter {@code rawOutput} is {@code true}&lt;br/&gt;
    +	 * and the bolt&apos;s number of declared output tuples is 1. If {@code rawOutput} is {@code false} the output type will&lt;br/&gt;
    +	 * be one of {@link Tuple0} to {@link Tuple25} depending on the bolt&apos;s declared number of attributes.&lt;br/&gt;
    +	 *  @param bolt&lt;br/&gt;
    +	 *            The Storm {@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;br/&gt;
    +	 * @param boltId&lt;br/&gt;
    +	 * @param componentId2&lt;br/&gt;
    +	 * @param streamId1&lt;br/&gt;
    +	 * @param inputSchema1&lt;br/&gt;
    +*            The schema (ie, ordered field names) of the input stream.    @throws IllegalArgumentException&lt;br/&gt;
    +*             If &lt;/p&gt;
{@code rawOuput} is {@code true} and the number of declared output attributes is not 1 or if&lt;br/&gt;
    +*             {@code rawOuput}
&lt;p&gt; is &lt;/p&gt;
{@code false}
&lt;p&gt; and the number of declared output attributes is not with range&lt;br/&gt;
    +	 * */&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    formatting (space and stars) incomplete JavaDoc; missing `@throws`&lt;/p&gt;</comment>
                            <comment id="15027115" author="githubbot" created="Wed, 25 Nov 2015 16:54:48 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45890996&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45890996&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/FlinkTopologyContext.java &amp;#8212;&lt;br/&gt;
    @@ -27,13 +27,12 @@&lt;br/&gt;
     import backtype.storm.state.ISubscribedState;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import clojure.lang.Atom;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027117" author="githubbot" created="Wed, 25 Nov 2015 16:54:56 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45891019&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45891019&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/SetupOutputFieldsDeclarer.java &amp;#8212;&lt;br/&gt;
    @@ -17,12 +17,12 @@&lt;/p&gt;

&lt;p&gt;     package org.apache.flink.storm.wrappers;&lt;/p&gt;

&lt;p&gt;    -import java.util.HashMap;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027118" author="githubbot" created="Wed, 25 Nov 2015 16:55:14 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45891069&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45891069&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/SpoutCollector.java &amp;#8212;&lt;br/&gt;
    @@ -18,7 +18,6 @@&lt;br/&gt;
     package org.apache.flink.storm.wrappers;&lt;/p&gt;

&lt;p&gt;     import backtype.storm.spout.ISpoutOutputCollector;&lt;br/&gt;
    -&lt;br/&gt;
     import org.apache.flink.api.java.tuple.Tuple0;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027122" author="githubbot" created="Wed, 25 Nov 2015 16:55:33 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45891117&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45891117&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/SpoutWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -33,7 +30,8 @@&lt;br/&gt;
     import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
     import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;&lt;/p&gt;

&lt;p&gt;    -import com.google.common.collect.Sets;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +import java.util.HashMap;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027127" author="githubbot" created="Wed, 25 Nov 2015 16:56:21 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45891225&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45891225&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,16 +45,30 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String producerStreamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String producerComponentId;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Constructor which sets defaults for producerComponentId, taskId, and componentID&lt;br/&gt;
    +	 * @param flinkTuple the Flink tuple&lt;br/&gt;
    +	 * @param schema The schema of the storm fields&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	StormTuple(final IN flinkTuple, final Fields schema) &lt;/p&gt;
{
    +		this(flinkTuple, schema, -1, &quot;testStream&quot;, &quot;componentID&quot;);
    +	}
&lt;p&gt;    +&lt;br/&gt;
     	/**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a new Storm tuple from the given Flink tuple. The provided 
{@code nameIndexMap}
&lt;p&gt; is ignored for raw input&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;types.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param flinkTuple&lt;br/&gt;
    +	 *  @param flinkTuple&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;The Flink tuple to be converted.&lt;/li&gt;
	&lt;li&gt;@param schema&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 		The schema (ie, ordered field names) of the tuple.&lt;br/&gt;
    +	 * @param producerComponentId&lt;br/&gt;
     	 */
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    formatting; incomplete.&lt;/p&gt;</comment>
                            <comment id="15027135" author="githubbot" created="Wed, 25 Nov 2015 17:00:25 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45891849&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45891849&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/FlinkOutputFieldsDeclarerTest.java &amp;#8212;&lt;br/&gt;
    @@ -18,9 +18,7 @@&lt;/p&gt;

&lt;p&gt;     import backtype.storm.tuple.Fields;&lt;br/&gt;
     import backtype.storm.utils.Utils;&lt;br/&gt;
    -&lt;br/&gt;
     import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    -import org.apache.flink.storm.api.FlinkOutputFieldsDeclarer;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027141" author="githubbot" created="Wed, 25 Nov 2015 17:01:43 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45892009&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45892009&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/FlinkTopologyTest.java &amp;#8212;&lt;br/&gt;
    @@ -14,50 +14,70 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    -import org.junit.Assert;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummyBolt;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummySpout;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestSink;&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
     import org.junit.Test;&lt;/p&gt;

&lt;p&gt;     public class FlinkTopologyTest {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void testDefaultParallelism() {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Why removing this test?&lt;/p&gt;</comment>
                            <comment id="15027158" author="githubbot" created="Wed, 25 Nov 2015 17:07:37 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45892746&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45892746&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,474 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}
&lt;p&gt;, or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;br/&gt;
     	 *&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Let me get this straight. You&apos;re saying you don&apos;t want to use the name Flink topology but you are the author of the classes called FlinkTopology and FlinkTopologyBuilder (deleted by now). This is still a user-facing documentation and there we wanted to maintain the Storm vocabulary, right?&lt;/p&gt;</comment>
                            <comment id="15027162" author="githubbot" created="Wed, 25 Nov 2015 17:09:08 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45892911&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45892911&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,474 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Yes, execute just throws an Exception. Nothing to explain here. StreamExecutionEnvironment says&lt;br/&gt;
    &amp;gt; 	 * @throws Exception which occurs during job execution.&lt;/p&gt;
</comment>
                            <comment id="15027174" author="githubbot" created="Wed, 25 Nov 2015 17:15:37 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893736&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893736&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/FlinkTopologyTest.java &amp;#8212;&lt;br/&gt;
    @@ -14,50 +14,70 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    -import org.junit.Assert;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummyBolt;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummySpout;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestSink;&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
     import org.junit.Test;&lt;/p&gt;

&lt;p&gt;     public class FlinkTopologyTest {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void testDefaultParallelism() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(1, topology.getParallelism());&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowSpout() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecute() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute();&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowBolt() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt1&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +		builder.setBolt(&quot;bolt2&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecuteWithName() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute(null);&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUndeclaredStream() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	@Test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void testNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;br/&gt;
    +	@Ignore
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Please enable this test. I forgot to do this in my last commit which fixes this issue...&lt;/p&gt;</comment>
                            <comment id="15027175" author="githubbot" created="Wed, 25 Nov 2015 17:15:43 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893753&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893753&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/FlinkTopologyTest.java &amp;#8212;&lt;br/&gt;
    @@ -14,50 +14,70 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    -import org.junit.Assert;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummyBolt;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummySpout;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestSink;&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
     import org.junit.Test;&lt;/p&gt;

&lt;p&gt;     public class FlinkTopologyTest {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void testDefaultParallelism() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(1, topology.getParallelism());&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowSpout() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecute() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute();&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowBolt() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt1&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +		builder.setBolt(&quot;bolt2&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecuteWithName() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute(null);&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUndeclaredStream() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	@Test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void testNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void testFieldsGroupingOnMultipleSpoutOutputStreams() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
     
    -		Assert.assertEquals(0, topology.getNumberOfTasks());
    +		builder.setSpout(&quot;spout&quot;, new TestDummySpout());
    +		builder.setBolt(&quot;sink&quot;, new TestSink()).fieldsGrouping(&quot;spout&quot;,
    +				TestDummySpout.spoutStreamId, new Fields(&quot;id&quot;));
     
    -		topology.increaseNumberOfTasks(3);
    -		Assert.assertEquals(3, topology.getNumberOfTasks());
    +		FlinkTopology.createTopology(builder);
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;topology.increaseNumberOfTasks(2);&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(5, topology.getNumberOfTasks());&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Please enable this test. I forgot to do this in my last commit which fixes this issue...&lt;/p&gt;</comment>
                            <comment id="15027177" author="githubbot" created="Wed, 25 Nov 2015 17:16:09 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893790&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893790&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/TestBolt.java &amp;#8212;&lt;br/&gt;
    @@ -16,14 +16,14 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/p&gt;

&lt;p&gt;    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
     import backtype.storm.task.OutputCollector;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichBolt;&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;br/&gt;
     import backtype.storm.tuple.Tuple;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestBolt implements IRichBolt {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027178" author="githubbot" created="Wed, 25 Nov 2015 17:16:20 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893806&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893806&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/TestSpout.java &amp;#8212;&lt;br/&gt;
    @@ -16,13 +16,13 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/p&gt;

&lt;p&gt;    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
     import backtype.storm.spout.SpoutOutputCollector;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichSpout;&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestSpout implements IRichSpout {&lt;br/&gt;
     	private static final long serialVersionUID = -4884029383198924007L;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027179" author="githubbot" created="Wed, 25 Nov 2015 17:16:35 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893834&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893834&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/util/TestDummyBolt.java &amp;#8212;&lt;br/&gt;
    @@ -26,6 +24,8 @@&lt;br/&gt;
     import backtype.storm.tuple.Tuple;&lt;br/&gt;
     import backtype.storm.tuple.Values;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestDummyBolt implements IRichBolt {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatiing&lt;/p&gt;</comment>
                            <comment id="15027180" author="githubbot" created="Wed, 25 Nov 2015 17:16:43 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893853&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893853&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/util/TestDummySpout.java &amp;#8212;&lt;br/&gt;
    @@ -26,6 +24,8 @@&lt;br/&gt;
     import backtype.storm.tuple.Values;&lt;br/&gt;
     import backtype.storm.utils.Utils;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestDummySpout implements IRichSpout {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027181" author="githubbot" created="Wed, 25 Nov 2015 17:16:49 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893875&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893875&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/util/TestSink.java &amp;#8212;&lt;br/&gt;
    @@ -16,16 +16,16 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.util;&lt;/p&gt;

&lt;p&gt;    -import java.util.LinkedList;&lt;br/&gt;
    -import java.util.List;&lt;br/&gt;
    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
     import backtype.storm.task.OutputCollector;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichBolt;&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;br/&gt;
     import backtype.storm.tuple.Tuple;&lt;/p&gt;

&lt;p&gt;    +import java.util.LinkedList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestSink implements IRichBolt {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027183" author="githubbot" created="Wed, 25 Nov 2015 17:17:23 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45893951&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45893951&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/SpoutWrapperTest.java &amp;#8212;&lt;br/&gt;
    @@ -21,7 +21,6 @@&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichSpout;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
    -&lt;br/&gt;
     import org.apache.flink.api.common.ExecutionConfig;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    pure reformatting&lt;/p&gt;</comment>
                            <comment id="15027187" author="githubbot" created="Wed, 25 Nov 2015 17:18:57 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45894174&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45894174&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,16 +45,30 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String producerStreamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String producerComponentId;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Constructor which sets defaults for producerComponentId, taskId, and componentID&lt;br/&gt;
    +	 * @param flinkTuple the Flink tuple&lt;br/&gt;
    +	 * @param schema The schema of the storm fields&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	StormTuple(final IN flinkTuple, final Fields schema) &lt;/p&gt;
{
    +		this(flinkTuple, schema, -1, &quot;testStream&quot;, &quot;componentID&quot;);
    +	}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Are this meaningful/helpful defaults? Why not just set it to `null`?&lt;/p&gt;</comment>
                            <comment id="15027197" author="githubbot" created="Wed, 25 Nov 2015 17:21:54 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45894573&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45894573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/StormTupleTest.java &amp;#8212;&lt;br/&gt;
    @@ -613,29 +611,29 @@ public void testGetBinaryByFieldPojoGetter() throws Exception &lt;/p&gt;
{
     		return new StormTuple(tuple, schema);
     	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;br/&gt;
    +	@Test&lt;br/&gt;
     	public void testGetSourceGlobalStreamid() {&lt;/li&gt;
	&lt;li&gt;new StormTuple&amp;lt;Object&amp;gt;(null, null).getSourceGlobalStreamid();&lt;br/&gt;
    +		Assert.assertNotNull(new StormTuple&amp;lt;Object&amp;gt;(null, null).getSourceGlobalStreamid());
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Can we improve on all this tests? Just a check for &quot;not-null&quot; seems a  little limited to me. We should rather check for defaults values and also check the full constructor case.&lt;/p&gt;</comment>
                            <comment id="15027213" author="githubbot" created="Wed, 25 Nov 2015 17:29:28 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45895556&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45895556&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,474 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}, or {@link
    -	 * FlinkClient}.&lt;br/&gt;
     	 *&lt;br/&gt;
    -	 * @throws UnsupportedOperationException&lt;br/&gt;
    -	 * 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.&lt;br/&gt;
     	 */&lt;br/&gt;
    -	@Override&lt;br/&gt;
    -	public JobExecutionResult execute() throws Exception {&lt;br/&gt;
    -		throw new UnsupportedOperationException(&lt;br/&gt;
    -				&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;br/&gt;
    -				&quot;instead.&quot;);&lt;br/&gt;
    +	public static FlinkTopology createTopology(TopologyBuilder stormBuilder) {
    +		return new FlinkTopology(stormBuilder);
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}, {@link FlinkSubmitter}
&lt;p&gt; or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Returns the underlying Flink ExecutionEnvironment for the Storm topology.&lt;br/&gt;
    +	 * @return The contextual environment.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public JobExecutionResult execute(final String jobName) throws Exception {&lt;/li&gt;
	&lt;li&gt;throw new UnsupportedOperationException(&lt;/li&gt;
	&lt;li&gt;&quot;A FlinkTopology cannot be executed directly. Use FlinkLocalCluster, FlinkSubmitter, or FlinkClient &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;instead.&quot;);&lt;br/&gt;
    +	public StreamExecutionEnvironment getExecutionEnvironment() 
{
    +		return this.env;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Increased the number of declared tasks of this program by the given value.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param dop&lt;/li&gt;
	&lt;li&gt;* 		The dop of a new operator that increases the number of overall tasks.&lt;br/&gt;
    +	 * Directly executes the Storm topology based on the current context (local when in IDE and&lt;br/&gt;
    +	 * remote when executed thorugh ./bin/flink).&lt;br/&gt;
    +	 * @return The execution result&lt;br/&gt;
    +	 * @throws Exception&lt;br/&gt;
     	 */
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Maybe just put something similar &amp;#8211; even if it&apos;s not too useful... I thinks leaving it blank is even worse... (and if we really activate stricter code style checks once &amp;#8211; if this ever happens &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &amp;#8211; it is already complete.&lt;/p&gt;</comment>
                            <comment id="15027231" author="githubbot" created="Wed, 25 Nov 2015 17:37:43 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45896492&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45896492&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkTopology.java &amp;#8212;&lt;br/&gt;
    @@ -15,75 +16,474 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +import backtype.storm.generated.ComponentCommon;&lt;br/&gt;
    +import backtype.storm.generated.GlobalStreamId;&lt;br/&gt;
    +import backtype.storm.generated.Grouping;&lt;br/&gt;
     import backtype.storm.generated.StormTopology;&lt;br/&gt;
    +import backtype.storm.topology.IRichBolt;&lt;br/&gt;
    +import backtype.storm.topology.IRichSpout;&lt;br/&gt;
    +import backtype.storm.topology.IRichStateSpout;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import com.google.common.base.Preconditions;&lt;br/&gt;
     import org.apache.flink.api.common.JobExecutionResult;&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple;&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.TypeExtractor;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamMapper;&lt;br/&gt;
    +import org.apache.flink.storm.util.SplitStreamType;&lt;br/&gt;
    +import org.apache.flink.storm.util.StormStreamSelector;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapper;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.BoltWrapperTwoInput;&lt;br/&gt;
    +import org.apache.flink.storm.wrappers.SpoutWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.SplitStream;&lt;br/&gt;
     import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.util.InstantiationUtil;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.lang.reflect.Field;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Iterator;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Map.Entry;&lt;br/&gt;
    +import java.util.Set;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* 
{@link FlinkTopology} mimics a {@link StormTopology} and is implemented in terms of a {@link
    - * StreamExecutionEnvironment} . In contrast to a regular {@link StreamExecutionEnvironment}, a {@link FlinkTopology}&lt;/li&gt;
	&lt;li&gt;* cannot be executed directly, but must be handed over to a 
{@link FlinkLocalCluster}, {@link FlinkSubmitter}, or&lt;br/&gt;
    - * {@link FlinkClient}.&lt;br/&gt;
    + * {@link FlinkTopology} translates a {@link TopologyBuilder} to a Flink program.&lt;br/&gt;
    + * &amp;lt;strong&amp;gt;CAUTION: {@link IRichStateSpout StateSpout}s are currently not supported.&amp;lt;/strong&amp;gt;&lt;br/&gt;
      */&lt;br/&gt;
    -public class FlinkTopology extends StreamExecutionEnvironment {&lt;br/&gt;
    +public class FlinkTopology {&lt;br/&gt;
    +&lt;br/&gt;
    +	/** All declared streams and output schemas by operator ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt; outputStreams = new HashMap&amp;lt;String, HashMap&amp;lt;String, Fields&amp;gt;&amp;gt;();&lt;br/&gt;
    +	/** All spouts&amp;amp;bolts declarers by their ID */&lt;br/&gt;
    +	private final HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt; declarers = new HashMap&amp;lt;String, FlinkOutputFieldsDeclarer&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	private final HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt; unprocessdInputsPerBolt =&lt;br/&gt;
    +			new HashMap&amp;lt;String, Set&amp;lt;Entry&amp;lt;GlobalStreamId, Grouping&amp;gt;&amp;gt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	final HashMap&amp;lt;String, HashMap&amp;lt;String, DataStream&amp;lt;Tuple&amp;gt;&amp;gt;&amp;gt; availableInputs = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     &lt;br/&gt;
    -	/** The number of declared tasks for the whole program (ie, sum over all dops) */&lt;br/&gt;
    -	private int numberOfTasks = 0;&lt;br/&gt;
    +	private final TopologyBuilder builder;&lt;br/&gt;
     &lt;br/&gt;
    -	public FlinkTopology() {&lt;br/&gt;
    -		// Set default parallelism to 1, to mirror Storm default behavior&lt;br/&gt;
    -		super.setParallelism(1);&lt;br/&gt;
    +	// needs to be a class member for internal testing purpose&lt;br/&gt;
    +	private final StormTopology stormTopology;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichSpout&amp;gt; spouts;&lt;br/&gt;
    +	private final Map&amp;lt;String, IRichBolt&amp;gt; bolts;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final StreamExecutionEnvironment env;&lt;br/&gt;
    +&lt;br/&gt;
    +	private FlinkTopology(TopologyBuilder builder) {
    +		this.builder = builder;
    +		this.stormTopology = builder.createTopology();
    +		// extract the spouts and bolts
    +		this.spouts = getPrivateField(&quot;_spouts&quot;);
    +		this.bolts = getPrivateField(&quot;_bolts&quot;);
    +
    +		this.env = StreamExecutionEnvironment.getExecutionEnvironment();
    +
    +		// Kick off the translation immediately
    +		translateTopology();
     	}&lt;br/&gt;
     &lt;br/&gt;
     	/**&lt;br/&gt;
    -	 * Is not supported. In order to execute use {@link FlinkLocalCluster}
&lt;p&gt;, &lt;/p&gt;
{@link FlinkSubmitter}
&lt;p&gt;, or &lt;/p&gt;
{@link
    -	 * FlinkClient}
&lt;p&gt;.&lt;br/&gt;
     	 *&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* @throws UnsupportedOperationException&lt;/li&gt;
	&lt;li&gt;* 		at every invocation&lt;br/&gt;
    +	 * Creates a Flink program that uses the specified spouts and bolts.&lt;br/&gt;
    +	 * @param stormBuilder The storm topology builder to use for creating the Flink topology.&lt;br/&gt;
    +	 * @return A Flink Topology which may be executed.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Sorry for being not consistent by myself &amp;#8211; I always try hard (but not always with success). The name `FlinkTopology` is kind of hybrid as it brides between both systems. I would claim that a `FlinkTopology` is a Flink streaming program that was derived from a Storm topology. And as a stated above: *&lt;b&gt;keep it as is also fine&lt;/b&gt;*&lt;/p&gt;</comment>
                            <comment id="15028505" author="githubbot" created="Thu, 26 Nov 2015 10:32:09 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45963921&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45963921&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/FlinkTopologyContext.java &amp;#8212;&lt;br/&gt;
    @@ -27,13 +27,12 @@&lt;br/&gt;
     import backtype.storm.state.ISubscribedState;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import clojure.lang.Atom;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028507" author="githubbot" created="Thu, 26 Nov 2015 10:32:18 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45963933&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45963933&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,16 +45,30 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String producerStreamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String producerComponentId;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Constructor which sets defaults for producerComponentId, taskId, and componentID&lt;br/&gt;
    +	 * @param flinkTuple the Flink tuple&lt;br/&gt;
    +	 * @param schema The schema of the storm fields&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	StormTuple(final IN flinkTuple, final Fields schema) &lt;/p&gt;
{
    +		this(flinkTuple, schema, -1, &quot;testStream&quot;, &quot;componentID&quot;);
    +	}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The use of null is often problematic. I prefer default values.&lt;/p&gt;</comment>
                            <comment id="15028508" author="githubbot" created="Thu, 26 Nov 2015 10:32:23 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45963943&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45963943&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/SpoutWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -33,7 +30,8 @@&lt;br/&gt;
     import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;&lt;br/&gt;
     import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;&lt;/p&gt;

&lt;p&gt;    -import com.google.common.collect.Sets;&lt;br/&gt;
    +import java.util.Collection;&lt;br/&gt;
    +import java.util.HashMap;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028513" author="githubbot" created="Thu, 26 Nov 2015 10:33:19 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964023&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964023&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/SetupOutputFieldsDeclarer.java &amp;#8212;&lt;br/&gt;
    @@ -17,12 +17,12 @@&lt;/p&gt;

&lt;p&gt;     package org.apache.flink.storm.wrappers;&lt;/p&gt;

&lt;p&gt;    -import java.util.HashMap;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028516" author="githubbot" created="Thu, 26 Nov 2015 10:35:35 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964241&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964241&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/FlinkOutputFieldsDeclarerTest.java &amp;#8212;&lt;br/&gt;
    @@ -18,9 +18,7 @@&lt;/p&gt;

&lt;p&gt;     import backtype.storm.tuple.Fields;&lt;br/&gt;
     import backtype.storm.utils.Utils;&lt;br/&gt;
    -&lt;br/&gt;
     import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
    -import org.apache.flink.storm.api.FlinkOutputFieldsDeclarer;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028523" author="githubbot" created="Thu, 26 Nov 2015 10:40:00 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964610&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964610&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/FlinkTopologyTest.java &amp;#8212;&lt;br/&gt;
    @@ -14,50 +14,70 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    -import org.junit.Assert;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummyBolt;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummySpout;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestSink;&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
     import org.junit.Test;&lt;/p&gt;

&lt;p&gt;     public class FlinkTopologyTest {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void testDefaultParallelism() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(1, topology.getParallelism());&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowSpout() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecute() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute();&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowBolt() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt1&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +		builder.setBolt(&quot;bolt2&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecuteWithName() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute(null);&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUndeclaredStream() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	@Test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void testNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;br/&gt;
    +	@Ignore
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    ok&lt;/p&gt;</comment>
                            <comment id="15028525" author="githubbot" created="Thu, 26 Nov 2015 10:40:45 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964692&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964692&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/FlinkTopologyTest.java &amp;#8212;&lt;br/&gt;
    @@ -14,50 +14,70 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
      */&lt;br/&gt;
    -&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    -import org.junit.Assert;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummyBolt;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestDummySpout;&lt;br/&gt;
    +import org.apache.flink.storm.util.TestSink;&lt;br/&gt;
    +import org.junit.Ignore;&lt;br/&gt;
     import org.junit.Test;&lt;/p&gt;

&lt;p&gt;     public class FlinkTopologyTest {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void testDefaultParallelism() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(1, topology.getParallelism());&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowSpout() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecute() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute();&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUnknowBolt() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt1&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +		builder.setBolt(&quot;bolt2&quot;, new TestBolt()).shuffleGrouping(&quot;unknown&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = UnsupportedOperationException.class)&lt;/li&gt;
	&lt;li&gt;public void testExecuteWithName() throws Exception {&lt;/li&gt;
	&lt;li&gt;new FlinkTopology().execute(null);&lt;br/&gt;
    +	@Test(expected = RuntimeException.class)&lt;br/&gt;
    +	public void testUndeclaredStream() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
    +		builder.setSpout(&quot;spout&quot;, new TestSpout());
    +		builder.setBolt(&quot;bolt&quot;, new TestBolt()).shuffleGrouping(&quot;spout&quot;);
    +
    +		FlinkTopology.createTopology(builder);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	@Test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void testNumberOfTasks() {&lt;/li&gt;
	&lt;li&gt;final FlinkTopology topology = new FlinkTopology();&lt;br/&gt;
    +	@Ignore&lt;br/&gt;
    +	public void testFieldsGroupingOnMultipleSpoutOutputStreams() 
{
    +		TopologyBuilder builder = new TopologyBuilder();
     
    -		Assert.assertEquals(0, topology.getNumberOfTasks());
    +		builder.setSpout(&quot;spout&quot;, new TestDummySpout());
    +		builder.setBolt(&quot;sink&quot;, new TestSink()).fieldsGrouping(&quot;spout&quot;,
    +				TestDummySpout.spoutStreamId, new Fields(&quot;id&quot;));
     
    -		topology.increaseNumberOfTasks(3);
    -		Assert.assertEquals(3, topology.getNumberOfTasks());
    +		FlinkTopology.createTopology(builder);
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;topology.increaseNumberOfTasks(2);&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(5, topology.getNumberOfTasks());&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	@Ignore
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    ok&lt;/p&gt;</comment>
                            <comment id="15028527" author="githubbot" created="Thu, 26 Nov 2015 10:41:39 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/TestBolt.java &amp;#8212;&lt;br/&gt;
    @@ -16,14 +16,14 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/p&gt;

&lt;p&gt;    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
     import backtype.storm.task.OutputCollector;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichBolt;&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;br/&gt;
     import backtype.storm.tuple.Tuple;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestBolt implements IRichBolt {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028528" author="githubbot" created="Thu, 26 Nov 2015 10:42:03 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964832&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964832&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/api/TestSpout.java &amp;#8212;&lt;br/&gt;
    @@ -16,13 +16,13 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.api;&lt;/p&gt;

&lt;p&gt;    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
     import backtype.storm.spout.SpoutOutputCollector;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichSpout;&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestSpout implements IRichSpout {&lt;br/&gt;
     	private static final long serialVersionUID = -4884029383198924007L;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028529" author="githubbot" created="Thu, 26 Nov 2015 10:42:17 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964853&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964853&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/util/TestDummyBolt.java &amp;#8212;&lt;br/&gt;
    @@ -26,6 +24,8 @@&lt;br/&gt;
     import backtype.storm.tuple.Tuple;&lt;br/&gt;
     import backtype.storm.tuple.Values;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestDummyBolt implements IRichBolt {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028530" author="githubbot" created="Thu, 26 Nov 2015 10:42:26 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964866&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964866&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/util/TestDummySpout.java &amp;#8212;&lt;br/&gt;
    @@ -26,6 +24,8 @@&lt;br/&gt;
     import backtype.storm.tuple.Values;&lt;br/&gt;
     import backtype.storm.utils.Utils;&lt;/p&gt;

&lt;p&gt;    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestDummySpout implements IRichSpout {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028531" author="githubbot" created="Thu, 26 Nov 2015 10:42:32 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964876&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964876&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/util/TestSink.java &amp;#8212;&lt;br/&gt;
    @@ -16,16 +16,16 @@&lt;br/&gt;
      */&lt;br/&gt;
     package org.apache.flink.storm.util;&lt;/p&gt;

&lt;p&gt;    -import java.util.LinkedList;&lt;br/&gt;
    -import java.util.List;&lt;br/&gt;
    -import java.util.Map;&lt;br/&gt;
    -&lt;br/&gt;
     import backtype.storm.task.OutputCollector;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichBolt;&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;br/&gt;
     import backtype.storm.tuple.Tuple;&lt;/p&gt;

&lt;p&gt;    +import java.util.LinkedList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
     public class TestSink implements IRichBolt {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028532" author="githubbot" created="Thu, 26 Nov 2015 10:42:49 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45964904&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45964904&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/SpoutWrapperTest.java &amp;#8212;&lt;br/&gt;
    @@ -21,7 +21,6 @@&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.topology.IRichSpout;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
    -&lt;br/&gt;
     import org.apache.flink.api.common.ExecutionConfig;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028535" author="githubbot" created="Thu, 26 Nov 2015 10:47:08 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45965316&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45965316&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/print/PrintSampleStream.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,61 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.storm.print;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.spout.TwitterSampleSpout;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Prints incoming tweets. Tweets can be filtered by keywords.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class PrintSampleStream {        &lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I cannot see why it did not work before? Can you explain what the problem was?&lt;/p&gt;</comment>
                            <comment id="15028537" author="githubbot" created="Thu, 26 Nov 2015 10:49:15 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45965523&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45965523&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/FlinkTopologyContext.java &amp;#8212;&lt;br/&gt;
    @@ -27,13 +27,12 @@&lt;br/&gt;
     import backtype.storm.state.ISubscribedState;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import clojure.lang.Atom;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I see. DataArtians committer can do any change, but external committers get bullied if they apply similar changes... It is not against you or the change itself &amp;#8211; it unifies the style which does make sense. But I got bullied multiple times in other PRs when I did similar stuff...&lt;/p&gt;</comment>
                            <comment id="15028551" author="githubbot" created="Thu, 26 Nov 2015 11:00:40 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45966621&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45966621&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/api/FlinkOutputFieldsDeclarer.java &amp;#8212;&lt;br/&gt;
    @@ -20,11 +20,9 @@&lt;br/&gt;
     import backtype.storm.topology.OutputFieldsDeclarer;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
     import backtype.storm.utils.Utils;&lt;br/&gt;
    -&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It follows the import style of the other classes, so I&apos;ll leave this as it is.&lt;/p&gt;</comment>
                            <comment id="15028560" author="githubbot" created="Thu, 26 Nov 2015 11:08:56 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45967336&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45967336&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/FlinkTopologyContext.java &amp;#8212;&lt;br/&gt;
    @@ -27,13 +27,12 @@&lt;br/&gt;
     import backtype.storm.state.ISubscribedState;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import clojure.lang.Atom;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Not sure who is bullying whom &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Look at the classes and you will see that all imports are arranged like this. We want to be consistent, right? According to your suggestion, I changed the other import statements which were just reformatting.&lt;/p&gt;

&lt;p&gt;    Open source is often about compromises. Very rarely you will find that the code style of a person reflects exactly how you would do it. I&apos;m making compromises and changing things as you like them. That&apos;s fine for me. Please don&apos;t give me a harder time by blaming my employer. I&apos;m not aware I have done something like this to you. Next time you get blamed for something like this, please contact me and I&apos;ll try to help you. I don&apos;t think this is the right place to sort out things.&lt;/p&gt;</comment>
                            <comment id="15028617" author="githubbot" created="Thu, 26 Nov 2015 11:47:10 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45970389&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45970389&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/FlinkTopologyContext.java &amp;#8212;&lt;br/&gt;
    @@ -27,13 +27,12 @@&lt;br/&gt;
     import backtype.storm.state.ISubscribedState;&lt;br/&gt;
     import backtype.storm.task.TopologyContext;&lt;br/&gt;
     import backtype.storm.tuple.Fields;&lt;br/&gt;
    +import clojure.lang.Atom;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Good we are on the same page. And I don&apos;t want to bully you! I just mentioned the classes that do not contain any actual code change &amp;#8211; actually, according to the coding guidelines &amp;#8211; there should be no import-order changes even in the classes with code changes &amp;#8211; I did not comment on them &amp;#8211; just on the classes with pure reformatting. I like consistency so please apply the changes to all classes. But I did import-reorderings or making code formatting consistent (if it was inconsistent) and was always told &quot;don&apos;t do this&quot;. So if it is a general rule, I just point it out here, too. I did not come up with the rule. And I never force my own code style &amp;#8211; a always adapt to the given style. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; It&apos;s is really about time to get a proper maven formatting tool running to get rid of all this stupid discussions. (And a said already: &quot;It is not against you or the change itself&quot; &amp;#8211; but the process seems to be inconsistent &amp;#8211; people follow the rules more or less strictly)&lt;/p&gt;</comment>
                            <comment id="15028628" author="githubbot" created="Thu, 26 Nov 2015 11:51:34 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45970656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45970656&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,16 +45,30 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String producerStreamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String producerComponentId;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Constructor which sets defaults for producerComponentId, taskId, and componentID&lt;br/&gt;
    +	 * @param flinkTuple the Flink tuple&lt;br/&gt;
    +	 * @param schema The schema of the storm fields&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	StormTuple(final IN flinkTuple, final Fields schema) &lt;/p&gt;
{
    +		this(flinkTuple, schema, -1, &quot;testStream&quot;, &quot;componentID&quot;);
    +	}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Ok. I guess it would make sense to use Storm&apos;s `Utils.DEFAULT_STREAM_ID` here? And maybe add a `public final static String DEFAULT_OPERATOR_ID` variable to `StormTuple`? What about using &quot;defaultID&quot; or &quot;unspecified&quot; instead of &quot;componentID&quot; or similar? Just to make it clear if the name shows up in the UI?&lt;/p&gt;</comment>
                            <comment id="15028638" author="githubbot" created="Thu, 26 Nov 2015 12:02:52 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45971476&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45971476&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,16 +45,30 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	private final int taskId;&lt;br/&gt;
    +	private final String producerStreamId;&lt;br/&gt;
    +	private final MessageId id;&lt;br/&gt;
    +	private final String producerComponentId;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Constructor which sets defaults for producerComponentId, taskId, and componentID&lt;br/&gt;
    +	 * @param flinkTuple the Flink tuple&lt;br/&gt;
    +	 * @param schema The schema of the storm fields&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	StormTuple(final IN flinkTuple, final Fields schema) &lt;/p&gt;
{
    +		this(flinkTuple, schema, -1, &quot;testStream&quot;, &quot;componentID&quot;);
    +	}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Fair enough, I use default id constants now.&lt;/p&gt;</comment>
                            <comment id="15028646" author="githubbot" created="Thu, 26 Nov 2015 12:07:21 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r45971856&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r45971856&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/print/PrintSampleStream.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,61 @@&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + * &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.storm.print;&lt;br/&gt;
    +&lt;br/&gt;
    +import backtype.storm.Config;&lt;br/&gt;
    +import backtype.storm.topology.TopologyBuilder;&lt;br/&gt;
    +import backtype.storm.utils.Utils;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkLocalCluster;&lt;br/&gt;
    +import org.apache.flink.storm.api.FlinkTopology;&lt;br/&gt;
    +import storm.starter.bolt.PrinterBolt;&lt;br/&gt;
    +import storm.starter.spout.TwitterSampleSpout;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Prints incoming tweets. Tweets can be filtered by keywords.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class PrintSampleStream {        &lt;br/&gt;
    +	public static void main(String[] args) throws Exception {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The problem was that the `BoltWrapper` wouldn&apos;t create a `BoltCollector` if the bolt didn&apos;t define any output fields. That led to a NullPointerException.&lt;/p&gt;</comment>
                            <comment id="15029733" author="githubbot" created="Fri, 27 Nov 2015 10:17:45 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46033582&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46033582&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/exclamation/ExclamationWithBolt.java &amp;#8212;&lt;br/&gt;
    @@ -72,7 +71,7 @@ public static void main(final String[] args) throws Exception {&lt;br/&gt;
     				.transform(&quot;StormBoltTokenizer&quot;,&lt;br/&gt;
     						TypeExtractor.getForObject(&quot;&quot;),&lt;br/&gt;
     						new BoltWrapper&amp;lt;String, String&amp;gt;(new ExclamationBolt(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new String[] 
{ Utils.DEFAULT_STREAM_ID }))&lt;br/&gt;
    +								&quot;stream&quot;, &quot;component&quot;, new String[] { Utils.DEFAULT_STREAM_ID }
&lt;p&gt;))&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Can&apos;t we use default values for streamID and componentID here, ie, obit both parameters?&lt;/p&gt;</comment>
                            <comment id="15029735" author="githubbot" created="Fri, 27 Nov 2015 10:19:26 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46033705&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46033705&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/split/SpoutSplitExample.java &amp;#8212;&lt;br/&gt;
    @@ -70,7 +70,7 @@ public static void main(final String[] args) throws Exception {&lt;br/&gt;
     		oddStream.transform(&quot;oddBolt&quot;,&lt;br/&gt;
     				TypeExtractor.getForObject(new Tuple2&amp;lt;String, Integer&amp;gt;(&quot;&quot;, 0)),&lt;br/&gt;
     				new BoltWrapper&amp;lt;SplitStreamType&amp;lt;Integer&amp;gt;, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new VerifyAndEnrichBolt(false)))&lt;br/&gt;
    +						new VerifyAndEnrichBolt(false), &quot;stream&quot;, &quot;component&quot;))
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Default values for both? Or use `ODD_STREAM` for consistency.&lt;/p&gt;</comment>
                            <comment id="15029738" author="githubbot" created="Fri, 27 Nov 2015 10:20:02 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46033750&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46033750&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/wordcount/BoltTokenizerWordCount.java &amp;#8212;&lt;br/&gt;
    @@ -64,7 +63,7 @@ public static void main(final String[] args) throws Exception {&lt;br/&gt;
     				// this is done by a bolt that is wrapped accordingly&lt;br/&gt;
     				.transform(&quot;BoltTokenizer&quot;,&lt;br/&gt;
     						TypeExtractor.getForObject(new Tuple2&amp;lt;String, Integer&amp;gt;(&quot;&quot;, 0)),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new BoltWrapper&amp;lt;String, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;(new BoltTokenizer()))&lt;br/&gt;
    +						new BoltWrapper&amp;lt;String, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;(new BoltTokenizer(), &quot;stream&quot;, &quot;component&quot;))
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Same question here.&lt;/p&gt;</comment>
                            <comment id="15029739" author="githubbot" created="Fri, 27 Nov 2015 10:20:16 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46033770&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46033770&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/wordcount/BoltTokenizerWordCountPojo.java &amp;#8212;&lt;br/&gt;
    @@ -71,7 +70,7 @@ public static void main(final String[] args) throws Exception {&lt;br/&gt;
     				// this is done by a bolt that is wrapped accordingly&lt;br/&gt;
     				.transform(&quot;BoltTokenizerPojo&quot;,&lt;br/&gt;
     						TypeExtractor.getForObject(new Tuple2&amp;lt;String, Integer&amp;gt;(&quot;&quot;, 0)),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new BoltWrapper&amp;lt;Sentence, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;(new BoltTokenizerByName()))&lt;br/&gt;
    +						new BoltWrapper&amp;lt;Sentence, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;(new BoltTokenizerByName(), &quot;stream&quot;, &quot;component&quot;))
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Again.&lt;/p&gt;</comment>
                            <comment id="15029740" author="githubbot" created="Fri, 27 Nov 2015 10:20:24 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46033787&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46033787&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/wordcount/BoltTokenizerWordCountWithNames.java &amp;#8212;&lt;br/&gt;
    @@ -75,7 +74,7 @@ public static void main(final String[] args) throws Exception {&lt;br/&gt;
     						&quot;BoltTokenizerWithNames&quot;,&lt;br/&gt;
     						TypeExtractor.getForObject(new Tuple2&amp;lt;String, Integer&amp;gt;(&quot;&quot;, 0)),&lt;br/&gt;
     						new BoltWrapper&amp;lt;Tuple1&amp;lt;String&amp;gt;, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new BoltTokenizerByName(), new Fields(&quot;sentence&quot;)))&lt;br/&gt;
    +								new BoltTokenizerByName(), &quot;stream&quot;, &quot;component&quot;, new Fields(&quot;sentence&quot;)))
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Again.&lt;/p&gt;</comment>
                            <comment id="15029751" author="githubbot" created="Fri, 27 Nov 2015 10:34:40 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46034951&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46034951&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -193,24 +189,22 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     			Utils.sleep(++counter * 10000);&lt;br/&gt;
     			cluster.shutdown();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (TestSink.result.size() == 8) {&lt;br/&gt;
    +			if (TestSink.result.size() &amp;gt;= 4) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Why `&amp;gt;=` and not `==` ?&lt;/p&gt;</comment>
                            <comment id="15029753" author="githubbot" created="Fri, 27 Nov 2015 10:36:44 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46035118&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46035118&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/BoltWrapperTest.java &amp;#8212;&lt;br/&gt;
    @@ -265,12 +264,12 @@ public void testOpen() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testOpenSink() throws Exception {&lt;br/&gt;
     		final IRichBolt bolt = mock(IRichBolt.class);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BoltWrapper&amp;lt;Object, Object&amp;gt; wrapper = new BoltWrapper&amp;lt;Object, Object&amp;gt;(bolt);&lt;br/&gt;
    +		BoltWrapper&amp;lt;Object, Object&amp;gt; wrapper = new BoltWrapper&amp;lt;Object, Object&amp;gt;(bolt, &quot;stream&quot;, &quot;component&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		wrapper.setup(createMockStreamTask(), new StreamConfig(new Configuration()), mock(Output.class));&lt;br/&gt;
     		wrapper.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify(bolt).prepare(any(Map.class), any(TopologyContext.class), any(OutputCollector.class));&lt;br/&gt;
    +		verify(bolt).prepare(any(Map.class), any(TopologyContext.class), isNotNull(OutputCollector.class));
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Just out of curiosity: Why `isNotNull` instead of `any`? &lt;/p&gt;</comment>
                            <comment id="15029755" author="githubbot" created="Fri, 27 Nov 2015 10:39:21 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46035298&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46035298&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -224,7 +224,7 @@ static synchronized TopologyContext createTopologyContext(&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;OUTPUT: A map from all component IDs to there output streams and output fields.&lt;/li&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;@return A unique task ID if the currently processed Spout or Bolt (
{@code componentId}
&lt;p&gt;) is equal to the current&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*         Flink operator (
{@link operatorName}
&lt;p&gt;) &amp;#8211; &lt;/p&gt;
{@code null} otherwise.&lt;br/&gt;
    +	 *         Flink operator ({@param operatorName}) &amp;#8211; {@code null}
&lt;p&gt; otherwise.&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I guess `@link` is wrong, but does `@param` work? Maybe `@code` would be correct? But I am not sure.&lt;/p&gt;</comment>
                            <comment id="15033669" author="githubbot" created="Tue, 1 Dec 2015 13:27:38 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46276898&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46276898&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/WrapperSetupHelper.java &amp;#8212;&lt;br/&gt;
    @@ -224,7 +224,7 @@ static synchronized TopologyContext createTopologyContext(&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;OUTPUT: A map from all component IDs to there output streams and output fields.&lt;/li&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;@return A unique task ID if the currently processed Spout or Bolt (
{@code componentId}
&lt;p&gt;) is equal to the current&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*         Flink operator (
{@link operatorName}
&lt;p&gt;) &amp;#8211; &lt;/p&gt;
{@code null} otherwise.&lt;br/&gt;
    +	 *         Flink operator ({@param operatorName}) &amp;#8211; {@code null}
&lt;p&gt; otherwise.&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Ok, let&apos;s use code.&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;http://stackoverflow.com/questions/1667212/reference-a-method-parameter-in-javadoc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stackoverflow.com/questions/1667212/reference-a-method-parameter-in-javadoc&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15033674" author="githubbot" created="Tue, 1 Dec 2015 13:30:12 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46277213&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46277213&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/BoltWrapperTest.java &amp;#8212;&lt;br/&gt;
    @@ -265,12 +264,12 @@ public void testOpen() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testOpenSink() throws Exception {&lt;br/&gt;
     		final IRichBolt bolt = mock(IRichBolt.class);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BoltWrapper&amp;lt;Object, Object&amp;gt; wrapper = new BoltWrapper&amp;lt;Object, Object&amp;gt;(bolt);&lt;br/&gt;
    +		BoltWrapper&amp;lt;Object, Object&amp;gt; wrapper = new BoltWrapper&amp;lt;Object, Object&amp;gt;(bolt, &quot;stream&quot;, &quot;component&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		wrapper.setup(createMockStreamTask(), new StreamConfig(new Configuration()), mock(Output.class));&lt;br/&gt;
     		wrapper.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify(bolt).prepare(any(Map.class), any(TopologyContext.class), any(OutputCollector.class));&lt;br/&gt;
    +		verify(bolt).prepare(any(Map.class), any(TopologyContext.class), isNotNull(OutputCollector.class));
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    `any` matches also null (literally anything) but here I want to explicitly check `isNotNull`. &lt;/p&gt;</comment>
                            <comment id="15033699" author="githubbot" created="Tue, 1 Dec 2015 13:48:06 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46278994&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46278994&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/WrapperSetupHelperTest.java &amp;#8212;&lt;br/&gt;
    @@ -193,24 +189,22 @@ public void testCreateTopologyContext() {&lt;br/&gt;
     			Utils.sleep(++counter * 10000);&lt;br/&gt;
     			cluster.shutdown();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (TestSink.result.size() == 8) {&lt;br/&gt;
    +			if (TestSink.result.size() &amp;gt;= 4) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    The Storm executor sometimes returned more results for me. I&apos;ve adjusted it to a fixed size again. I think the important thing here is that we check all the returned results.&lt;/p&gt;</comment>
                            <comment id="15033703" author="githubbot" created="Tue, 1 Dec 2015 13:51:48 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46279370&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46279370&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm-examples/src/main/java/org/apache/flink/storm/exclamation/ExclamationWithBolt.java &amp;#8212;&lt;br/&gt;
    @@ -72,7 +71,7 @@ public static void main(final String[] args) throws Exception {&lt;br/&gt;
     				.transform(&quot;StormBoltTokenizer&quot;,&lt;br/&gt;
     						TypeExtractor.getForObject(&quot;&quot;),&lt;br/&gt;
     						new BoltWrapper&amp;lt;String, String&amp;gt;(new ExclamationBolt(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new String[] 
{ Utils.DEFAULT_STREAM_ID }))&lt;br/&gt;
    +								&quot;stream&quot;, &quot;component&quot;, new String[] { Utils.DEFAULT_STREAM_ID }
&lt;p&gt;))&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Can do.&lt;/p&gt;</comment>
                            <comment id="15033727" author="githubbot" created="Tue, 1 Dec 2015 14:11:43 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46281582&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46281582&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/test/java/org/apache/flink/storm/wrappers/BoltWrapperTest.java &amp;#8212;&lt;br/&gt;
    @@ -265,12 +264,12 @@ public void testOpen() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testOpenSink() throws Exception {&lt;br/&gt;
     		final IRichBolt bolt = mock(IRichBolt.class);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BoltWrapper&amp;lt;Object, Object&amp;gt; wrapper = new BoltWrapper&amp;lt;Object, Object&amp;gt;(bolt);&lt;br/&gt;
    +		BoltWrapper&amp;lt;Object, Object&amp;gt; wrapper = new BoltWrapper&amp;lt;Object, Object&amp;gt;(bolt, &quot;stream&quot;, &quot;component&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		wrapper.setup(createMockStreamTask(), new StreamConfig(new Configuration()), mock(Output.class));&lt;br/&gt;
     		wrapper.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify(bolt).prepare(any(Map.class), any(TopologyContext.class), any(OutputCollector.class));&lt;br/&gt;
    +		verify(bolt).prepare(any(Map.class), any(TopologyContext.class), isNotNull(OutputCollector.class));
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I see. Makes sense.&lt;/p&gt;</comment>
                            <comment id="15033741" author="githubbot" created="Tue, 1 Dec 2015 14:21:48 +0000"  >&lt;p&gt;Github user mxm commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#issuecomment-160982088&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#issuecomment-160982088&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I&apos;ve addressed your comments.&lt;/p&gt;</comment>
                            <comment id="15033755" author="githubbot" created="Tue, 1 Dec 2015 14:31:04 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46284023&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46284023&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -89,13 +99,9 @@ public BoltWrapper(final IRichBolt bolt) throws IllegalArgumentException {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;used within a Flink streaming program. The given input schema enable attribute-by-name access for input types&lt;/li&gt;
	&lt;li&gt;{@link Tuple0} to {@link Tuple25}. The output type will be one of {@link Tuple0}
&lt;p&gt; to &lt;/p&gt;
{@link Tuple25}
&lt;p&gt; depending on&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;the bolt&apos;s declared number of attributes.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param bolt&lt;/li&gt;
	&lt;li&gt;*            The Storm 
{@link IRichBolt bolt} to be used.&lt;br/&gt;
    +	 * @param bolt The Storm {@link IRichBolt bolt}
&lt;p&gt; to be used.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param inputSchema&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*            The schema (ie, ordered field names) of the input stream.&lt;/li&gt;
	&lt;li&gt;* @throws IllegalArgumentException
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Please keep `@throws`&lt;/p&gt;</comment>
                            <comment id="15033759" author="githubbot" created="Tue, 1 Dec 2015 14:32:08 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46284171&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46284171&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/BoltWrapper.java &amp;#8212;&lt;br/&gt;
    @@ -108,16 +114,13 @@ public BoltWrapper(final IRichBolt bolt, final Fields inputSchema)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;for POJO input types. The output type can be any type if parameter 
{@code rawOutput} is {@code true} and the&lt;br/&gt;
     	 * bolt&apos;s number of declared output tuples is 1. If {@code rawOutput}
&lt;p&gt; is &lt;/p&gt;
{@code false} the output type will be one&lt;br/&gt;
     	 * of {@link Tuple0} to {@link Tuple25} depending on the bolt&apos;s declared number of attributes.&lt;br/&gt;
    -	 * &lt;br/&gt;
    -	 * @param bolt&lt;br/&gt;
    -	 *            The Storm {@link IRichBolt bolt} to be used.&lt;br/&gt;
    +	 * @param bolt The Storm {@link IRichBolt bolt} to be used.&lt;br/&gt;
     	 * @param rawOutputs&lt;br/&gt;
     	 *            Contains stream names if a single attribute output stream, should not be of type {@link Tuple1} but be&lt;br/&gt;
     	 *            of a raw type.&lt;br/&gt;
     	 * @throws IllegalArgumentException&lt;br/&gt;
     	 *             If {@code rawOuput} is {@code true} and the number of declared output attributes is not 1 or if&lt;br/&gt;
     	 *             {@code rawOuput} is {@code false}
&lt;p&gt; and the number of declared output attributes is not with range&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*             &lt;span class=&quot;error&quot;&gt;&amp;#91;1;25&amp;#93;&lt;/span&gt;.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Please keep and update: should be `&lt;span class=&quot;error&quot;&gt;&amp;#91;0;25&amp;#93;&lt;/span&gt;`&lt;/p&gt;</comment>
                            <comment id="15033764" author="githubbot" created="Tue, 1 Dec 2015 14:34:32 +0000"  >&lt;p&gt;Github user mjsax commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#discussion_r46284474&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#discussion_r46284474&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-contrib/flink-storm/src/main/java/org/apache/flink/storm/wrappers/StormTuple.java &amp;#8212;&lt;br/&gt;
    @@ -44,16 +47,32 @@&lt;br/&gt;
     	/** The schema (ie, ordered field names) of the tuple */&lt;br/&gt;
     	private final Fields schema;&lt;/p&gt;

&lt;p&gt;    +	/** The task id where this tuple is processed */&lt;br/&gt;
    +	private final int taskId;&lt;br/&gt;
    +	/** The producer of this tuple */&lt;br/&gt;
    +	private final String producerStreamId;&lt;br/&gt;
    +	/** The producer&apos;s component id of this tuple */&lt;br/&gt;
    +	private final String producerComponentId;&lt;br/&gt;
    +	/*+ The message that is associated with this tuple */&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `/**` not `+`&lt;/p&gt;</comment>
                            <comment id="15033774" author="githubbot" created="Tue, 1 Dec 2015 14:39:01 +0000"  >&lt;p&gt;Github user mjsax commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#issuecomment-160985940&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#issuecomment-160985940&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    If Travis is green please merge. You can fix the last tiny comments directly before merging. No need to update this PR.&lt;/p&gt;</comment>
                            <comment id="15035551" author="githubbot" created="Wed, 2 Dec 2015 09:41:38 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15035829" author="githubbot" created="Wed, 2 Dec 2015 14:06:50 +0000"  >&lt;p&gt;Github user mxm commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#issuecomment-161304907&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#issuecomment-161304907&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for your feedback!&lt;/p&gt;</comment>
                            <comment id="15036469" author="githubbot" created="Wed, 2 Dec 2015 19:49:37 +0000"  >&lt;p&gt;Github user mjsax commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/1398#issuecomment-161412796&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/1398#issuecomment-161412796&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for you patience. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15072627" author="mjsax" created="Mon, 28 Dec 2015 10:55:33 +0000"  >&lt;p&gt;Fixed via f7b113d965fd30db993cac99b63194dcd7869ad4&lt;/p&gt;</comment>
                            <comment id="15072645" author="mxm" created="Mon, 28 Dec 2015 11:18:49 +0000"  >&lt;p&gt;Thanks for the fix. Looks good but could you open a pull request next time?&lt;/p&gt;</comment>
                            <comment id="15072651" author="mjsax" created="Mon, 28 Dec 2015 11:36:24 +0000"  >&lt;p&gt;Sorry.  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I thought a PR is only required for committers if they work on components they are not yet familiar with...&lt;/p&gt;</comment>
                            <comment id="15072743" author="mxm" created="Mon, 28 Dec 2015 14:15:29 +0000"  >&lt;p&gt;It is not strictly enforced if no design document has been requested. However, it is always good to let someone else look through the code. Especially, if the design choices have not been discussed publicly in advance. That also ensures people can discuss the changes and adapt each other&apos;s code to the upcoming changes.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 47 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2mr7z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>