<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:34:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-9289] Parallelism of generated operators should have max parallism of input</title>
                <link>https://issues.apache.org/jira/browse/FLINK-9289</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The DataSet API aims to chain generated operators such as key extraction mappers to their predecessor. This is done by assigning the same parallelism as the input operator.&lt;/p&gt;

&lt;p&gt;If a generated operator has more than two inputs, the operator cannot be chained anymore and the operator is generated with default parallelism. This can lead to a &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;NoResourceAvailableException: Not enough free slots available to run the job.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; as reported by a user on the mailing list: &lt;a href=&quot;https://lists.apache.org/thread.html/60a8bffcce54717b6273bf3de0f43f1940fbb711590f4b90cd666c9a@%3Cuser.flink.apache.org%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://lists.apache.org/thread.html/60a8bffcce54717b6273bf3de0f43f1940fbb711590f4b90cd666c9a@%3Cuser.flink.apache.org%3E&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I suggest to set the parallelism of a generated operator to the max parallelism of all of its inputs to fix this problem.&lt;/p&gt;

&lt;p&gt;Until the problem is fixed, a workaround is to set the default parallelism at the &lt;tt&gt;ExecutionEnvironment&lt;/tt&gt;:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ExecutionEnvironment env = ...
env.setParallelism(2);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13156600">FLINK-9289</key>
            <summary>Parallelism of generated operators should have max parallism of input</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="xccui">Xingcan Cui</assignee>
                                    <reporter username="fhueske">Fabian Hueske</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 2 May 2018 13:07:02 +0000</created>
                <updated>Wed, 15 Aug 2018 18:17:45 +0000</updated>
                            <resolved>Wed, 15 Aug 2018 18:17:45 +0000</resolved>
                                    <version>1.4.2</version>
                    <version>1.5.2</version>
                    <version>1.6.0</version>
                                    <fixVersion>1.4.3</fixVersion>
                    <fixVersion>1.5.3</fixVersion>
                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>1.7.0</fixVersion>
                                    <component>API / DataSet</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16470460" author="xccui" created="Thu, 10 May 2018 14:31:01 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fhueske&quot; class=&quot;user-hover&quot; rel=&quot;fhueske&quot;&gt;fhueske&lt;/a&gt;, I checked the sub-classes of &lt;tt&gt;DualInputOperator&lt;/tt&gt;, but failed to find an implicit generation with the default parallelism. I wonder if you could provide some hints for that.&lt;/p&gt;

&lt;p&gt;Thanks, Xingcan&lt;/p&gt;</comment>
                            <comment id="16471648" author="fhueske" created="Fri, 11 May 2018 08:21:35 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xccui&quot; class=&quot;user-hover&quot; rel=&quot;xccui&quot;&gt;xccui&lt;/a&gt;, the fix should go into &lt;tt&gt;KeyFunctions.appendKeyExtractor()&lt;/tt&gt;. This method generates key extraction mappers and sets the parallelism to the parallelism of the input. This doesn&apos;t work if the input is a union operator which doesn&apos;t have a parallelism by itself. If the input is a union, we need to go back to its inputs (recursively because the input of a union might be another union) and get the max parallelism of it. This should be the parallelism of the extraction mapper.&lt;/p&gt;</comment>
                            <comment id="16471660" author="xccui" created="Fri, 11 May 2018 08:32:43 +0000"  >&lt;p&gt;I see. Thanks for the explanation, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fhueske&quot; class=&quot;user-hover&quot; rel=&quot;fhueske&quot;&gt;fhueske&lt;/a&gt;. Will fix this as soon as possible.&lt;/p&gt;</comment>
                            <comment id="16473729" author="githubbot" created="Mon, 14 May 2018 03:12:07 +0000"  >&lt;p&gt;GitHub user xccui opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6003&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt; Parallelism of generated operators should have max parallelism of input&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    This PR aims to fix the default parallelism problem for the generated key-extraction mapper whose input is a union operator without parallelism in the batch environment.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;When creating a `Union` operator, automatically set its parallelism to the maximum one of its inputs.&lt;/li&gt;
	&lt;li&gt;Forbid the user to set parallelism for the union operator manually.&lt;/li&gt;
	&lt;li&gt;Add some test cases in `UnionOperatorTest.java` and `UnionTranslationTest.java`.&lt;/li&gt;
	&lt;li&gt;Adjust the results for `testUnionWithoutExtended()` and `testUnionWithExtended()` in `org.apache.flink.table.api.batch.ExplainTest`.&lt;/li&gt;
	&lt;li&gt;Remove the parallelism setting code for union in `PythonPlanBinder.java` and `PageRank.java`.&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    The change can be verified by the added test cases in `UnionOperatorTest.java` and `UnionTranslationTest.java`.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (no)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)&lt;/li&gt;
	&lt;li&gt;The serializers: (no)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (no)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (no)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (no)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (no)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (not applicable)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/xccui/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xccui/flink&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;-parallelism&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6003.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #6003&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 35be0811ef0a5e6c572d0a60160fa18c3b6afefa&lt;br/&gt;
Author: Xingcan Cui &amp;lt;xingcanc@...&amp;gt;&lt;br/&gt;
Date:   2018-05-13T12:20:36Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt; Parallelism of generated operators should have max parallism of input&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16520267" author="githubbot" created="Fri, 22 Jun 2018 11:31:08 +0000"  >&lt;p&gt;GitHub user zentol opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;rest&amp;#93;&lt;/span&gt; Rework JobSubmitHandler to accept jar/artifact files&lt;/p&gt;

&lt;p&gt;    Builds on #6199.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    This PR reworks the `JobSubmitHandler` to accept jars/artifacts and the jobgraph in a single REST request, and changes the `RestClusterClient` to make use of this feature.&lt;br/&gt;
    As a result the entire job submission now goes through the REST API.&lt;/p&gt;

&lt;p&gt;    There are still known issues in this PR but they won&apos;t impact the correctness; the core implementation is complete, works and is covered by tests.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul&gt;
	&lt;li&gt;remove blobserver port headers/handlers and usages&lt;/li&gt;
	&lt;li&gt;rework `JobSubmitRequestBody` to contain the names of the jobgraph, jar and artifact files, providing semantics to the collection of uploaded files&lt;/li&gt;
	&lt;li&gt;set visibility of utility methods in `ClientUtils` to `public`to allow passing jar/artifact collections manually&lt;/li&gt;
	&lt;li&gt;modified the `JobSubmitHandler` to&lt;/li&gt;
	&lt;li&gt;read the jobgraph from an uploaded file&lt;/li&gt;
	&lt;li&gt;upload uploaded jars/artifacts to the blob service and store keys in the jobgraph&lt;/li&gt;
	&lt;li&gt;modified the `RestClusterClient` to&lt;/li&gt;
	&lt;li&gt;write jobgraph into a file for later upload&lt;/li&gt;
	&lt;li&gt;make use of new `RestClient` API for multipart requests&lt;/li&gt;
	&lt;li&gt;extended &#180;RestConstants` for jar/binary `content-types`, and made the class an enum to get singleton properties&lt;/li&gt;
	&lt;li&gt;extended documentation of `JobSubmitHeaders`&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul&gt;
	&lt;li&gt;this PR only modifies existing tests to accommodate changes&lt;/li&gt;
	&lt;li&gt;the general functionality is covered by existing end-to-end tests&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (no)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes)&lt;/li&gt;
	&lt;li&gt;The serializers: (no)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (no)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (no)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (no)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (yes)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (docs)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/zentol/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/zentol/flink&lt;/a&gt; 9280_epsilon&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #6203&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 90d81f7bdde62f2b9bb1d1da071cc3d0b0d1b349&lt;br/&gt;
Author: zentol &amp;lt;chesnay@...&amp;gt;&lt;br/&gt;
Date:   2018-06-13T16:21:21Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9624&quot; title=&quot;Move jar/artifact upload logic out of JobGraph&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9624&quot;&gt;&lt;del&gt;FLINK-9624&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;runtime&amp;#93;&lt;/span&gt; Move jar/artifact upload out of jobgraph&lt;/p&gt;

&lt;p&gt;commit a365697a031d16a778f25334c3bc2c7706d13693&lt;br/&gt;
Author: zentol &amp;lt;chesnay@...&amp;gt;&lt;br/&gt;
Date:   2018-06-11T09:45:12Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9280&quot; title=&quot;Extend JobSubmitHandler to accept jar files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9280&quot;&gt;&lt;del&gt;FLINK-9280&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;rest&amp;#93;&lt;/span&gt; Remove BlobServer port handler&lt;/p&gt;

&lt;p&gt;commit 78b456eb861fd722a100ae6e153f1c0079649d8b&lt;br/&gt;
Author: zentol &amp;lt;chesnay@...&amp;gt;&lt;br/&gt;
Date:   2018-06-22T09:03:45Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;rest&amp;#93;&lt;/span&gt; Rework JobSubmitHandler to accept jar/artifact files&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16520269" author="githubbot" created="Fri, 22 Jun 2018 11:31:55 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197419621&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197419621&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/test/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandlerTest.java &amp;#8212;&lt;br/&gt;
    @@ -71,7 +106,16 @@ public void testSerializationFailureHandling() throws Exception {&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
     	public void testSuccessfulJobSubmission() throws Exception {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    should be extended to cover correct handling of uploaded jars and artifacts&lt;/p&gt;</comment>
                            <comment id="16520270" author="githubbot" created="Fri, 22 Jun 2018 11:32:54 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197419769&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197419769&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);&lt;br/&gt;
    +&lt;br/&gt;
    +		Collection&amp;lt;org.apache.flink.core.fs.Path&amp;gt; jarFiles = new ArrayList&amp;lt;&amp;gt;(requestBody.jarFileNames.size());&lt;br/&gt;
    +		for (String jarFileName : requestBody.jarFileNames) 
{
    +			Path jarFile = getPathAndAssertUpload(jarFileName, &quot;Jar&quot;, nameToFile);
    +			jarFiles.add(new org.apache.flink.core.fs.Path(jarFile.toString()));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		Collection&amp;lt;Tuple2&amp;lt;String, org.apache.flink.core.fs.Path&amp;gt;&amp;gt; artifacts = new ArrayList&amp;lt;&amp;gt;(requestBody.artifactFileNames.size());&lt;br/&gt;
    +		for (JobSubmitRequestBody.DistributedCacheFile artifactFileName : requestBody.artifactFileNames) &lt;/p&gt;
{
    +			Path artifactFile = getPathAndAssertUpload(artifactFileName.fileName, &quot;Artifact&quot;, nameToFile);
    +			artifacts.add(Tuple2.of(artifactFileName.entryName, new org.apache.flink.core.fs.Path(artifactFile.toString())));
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return gateway.submitJob(jobGraph, timeout)&lt;/li&gt;
	&lt;li&gt;.thenApply(ack -&amp;gt; new JobSubmitResponseBody(&quot;/jobs/&quot; + jobGraph.getJobID()));&lt;br/&gt;
    +		Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; temporaryHack = artifacts.stream()
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    this is only necessary due to a deficiency of an API introduced in #6199 that i already raised in the PR.&lt;/p&gt;</comment>
                            <comment id="16520317" author="githubbot" created="Fri, 22 Jun 2018 12:59:44 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197437488&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197437488&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +68,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    add a check that the number of uploaded files is equal to the number of filenames in the `JobSubmitRequestBody`&lt;/p&gt;</comment>
                            <comment id="16520336" author="githubbot" created="Fri, 22 Jun 2018 13:11:53 +0000"  >&lt;p&gt;Github user zentol commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    the scala shell tests are failing with these changes, currently investigating what could be the cause...&lt;/p&gt;</comment>
                            <comment id="16520344" author="githubbot" created="Fri, 22 Jun 2018 13:25:09 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197444135&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197444135&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java &amp;#8212;&lt;br/&gt;
    @@ -315,42 +315,51 @@ public JobSubmissionResult submitJob(JobGraph jobGraph, ClassLoader classLoader)&lt;br/&gt;
     		// we have to enable queued scheduling because slot will be allocated lazily&lt;br/&gt;
     		jobGraph.setAllowQueuedScheduling(true);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;log.info(&quot;Requesting blob server port.&quot;);&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;BlobServerPortResponseBody&amp;gt; portFuture = sendRequest(BlobServerPortHeaders.getInstance());&lt;br/&gt;
    +		CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; submissionFuture = CompletableFuture.supplyAsync(&lt;br/&gt;
    +			() -&amp;gt; {&lt;br/&gt;
    +				log.info(&quot;Submitting job graph.&quot;);&lt;br/&gt;
    +&lt;br/&gt;
    +				Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; userArtifacts = jobGraph.getUserArtifacts();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    unused&lt;/p&gt;</comment>
                            <comment id="16520374" author="githubbot" created="Fri, 22 Jun 2018 13:57:00 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197445250&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197445250&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java &amp;#8212;&lt;br/&gt;
    @@ -315,42 +315,51 @@ public JobSubmissionResult submitJob(JobGraph jobGraph, ClassLoader classLoader)&lt;br/&gt;
     		// we have to enable queued scheduling because slot will be allocated lazily&lt;br/&gt;
     		jobGraph.setAllowQueuedScheduling(true);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;log.info(&quot;Requesting blob server port.&quot;);&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;BlobServerPortResponseBody&amp;gt; portFuture = sendRequest(BlobServerPortHeaders.getInstance());&lt;br/&gt;
    +		CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; submissionFuture = CompletableFuture.supplyAsync(&lt;br/&gt;
    +			() -&amp;gt; {&lt;br/&gt;
    +				log.info(&quot;Submitting job graph.&quot;);&lt;br/&gt;
    +&lt;br/&gt;
    +				Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; userArtifacts = jobGraph.getUserArtifacts();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Good to remove it then.&lt;/p&gt;</comment>
                            <comment id="16520375" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197448846&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197448846&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Could this also return a `Collection&amp;lt;File&amp;gt;`? I think there would be two benefits: 1. indicating that this file is really a local file and 2. we would not have the problem with two `Path` classes in the same scope.&lt;/p&gt;</comment>
                            <comment id="16520376" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197449994&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197449994&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);&lt;br/&gt;
    +&lt;br/&gt;
    +		Collection&amp;lt;org.apache.flink.core.fs.Path&amp;gt; jarFiles = new ArrayList&amp;lt;&amp;gt;(requestBody.jarFileNames.size());&lt;br/&gt;
    +		for (String jarFileName : requestBody.jarFileNames) 
{
    +			Path jarFile = getPathAndAssertUpload(jarFileName, &quot;Jar&quot;, nameToFile);
    +			jarFiles.add(new org.apache.flink.core.fs.Path(jarFile.toString()));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		Collection&amp;lt;Tuple2&amp;lt;String, org.apache.flink.core.fs.Path&amp;gt;&amp;gt; artifacts = new ArrayList&amp;lt;&amp;gt;(requestBody.artifactFileNames.size());&lt;br/&gt;
    +		for (JobSubmitRequestBody.DistributedCacheFile artifactFileName : requestBody.artifactFileNames) &lt;/p&gt;
{
    +			Path artifactFile = getPathAndAssertUpload(artifactFileName.fileName, &quot;Artifact&quot;, nameToFile);
    +			artifacts.add(Tuple2.of(artifactFileName.entryName, new org.apache.flink.core.fs.Path(artifactFile.toString())));
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return gateway.submitJob(jobGraph, timeout)&lt;/li&gt;
	&lt;li&gt;.thenApply(ack -&amp;gt; new JobSubmitResponseBody(&quot;/jobs/&quot; + jobGraph.getJobID()));&lt;br/&gt;
    +		Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; temporaryHack = artifacts.stream()&lt;br/&gt;
    +			.collect(Collectors.toMap(&lt;br/&gt;
    +				tuple -&amp;gt; tuple.f0,&lt;br/&gt;
    +				// the actual entry definition is mostly irrelevant as only the blobkey is accessed&lt;br/&gt;
    +				// blame whoever wrote the ClientUtils API&lt;br/&gt;
    +				tuple -&amp;gt; new DistributedCache.DistributedCacheEntry(tuple.f1.toString(), false)&lt;br/&gt;
    +			));&lt;br/&gt;
    +&lt;br/&gt;
    +		// TODO: use executor&lt;br/&gt;
    +		CompletableFuture&amp;lt;JobGraph&amp;gt; jobGraphFuture = CompletableFuture.supplyAsync(() -&amp;gt; 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			JobGraph jobGraph;    +			try (ObjectInputStream objectIn = new ObjectInputStream(Files.newInputStream(jobGraphFile))) {
    +				jobGraph = (JobGraph) objectIn.readObject();
    +			} catch (Exception e) {
    +				throw new CompletionException(new RestHandlerException(
    +					&quot;Failed to deserialize JobGraph.&quot;,
    +					HttpResponseStatus.BAD_REQUEST,
    +					e));
    +			}    +			return jobGraph;    +		}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;);&lt;br/&gt;
    +&lt;br/&gt;
    +		CompletableFuture&amp;lt;Integer&amp;gt; blobServerPortFuture = gateway.getBlobServerPort(timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		CompletableFuture&amp;lt;JobGraph&amp;gt; finalizedJobGraphFuture = jobGraphFuture.thenCombine(blobServerPortFuture, (jobGraph, blobServerPort) -&amp;gt; {&lt;br/&gt;
    +			final InetSocketAddress address = new InetSocketAddress(gateway.getHostname(), blobServerPort);&lt;br/&gt;
    +			try (BlobClient blobClient = new BlobClient(address, new Configuration())) &lt;/p&gt;
{
    +				Collection&amp;lt;PermanentBlobKey&amp;gt; jarBlobKeys = ClientUtils.uploadUserJars(jobGraph.getJobID(), jarFiles, blobClient);
    +				ClientUtils.setUserJarBlobKeys(jarBlobKeys, jobGraph);
    +
    +				Collection&amp;lt;Tuple2&amp;lt;String, PermanentBlobKey&amp;gt;&amp;gt; artifactBlobKeys = ClientUtils.uploadUserArtifacts(jobGraph.getJobID(), temporaryHack, blobClient);
    +				ClientUtils.setUserArtifactBlobKeys(jobGraph, artifactBlobKeys);
    +			}
&lt;p&gt; catch (IOException e) {&lt;br/&gt;
    +				throw new CompletionException(new RestHandlerException(&lt;br/&gt;
    +					&quot;Could not upload job files.&quot;,&lt;br/&gt;
    +					HttpResponseStatus.INTERNAL_SERVER_ERROR,&lt;br/&gt;
    +					e));&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    What happens to the uploaded jars in case of a failure? We should try to delete them if they won&apos;t be cleaned up automatically.&lt;/p&gt;</comment>
                            <comment id="16520377" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197450074&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197450074&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);&lt;br/&gt;
    +&lt;br/&gt;
    +		Collection&amp;lt;org.apache.flink.core.fs.Path&amp;gt; jarFiles = new ArrayList&amp;lt;&amp;gt;(requestBody.jarFileNames.size());&lt;br/&gt;
    +		for (String jarFileName : requestBody.jarFileNames) 
{
    +			Path jarFile = getPathAndAssertUpload(jarFileName, &quot;Jar&quot;, nameToFile);
    +			jarFiles.add(new org.apache.flink.core.fs.Path(jarFile.toString()));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		Collection&amp;lt;Tuple2&amp;lt;String, org.apache.flink.core.fs.Path&amp;gt;&amp;gt; artifacts = new ArrayList&amp;lt;&amp;gt;(requestBody.artifactFileNames.size());&lt;br/&gt;
    +		for (JobSubmitRequestBody.DistributedCacheFile artifactFileName : requestBody.artifactFileNames) &lt;/p&gt;
{
    +			Path artifactFile = getPathAndAssertUpload(artifactFileName.fileName, &quot;Artifact&quot;, nameToFile);
    +			artifacts.add(Tuple2.of(artifactFileName.entryName, new org.apache.flink.core.fs.Path(artifactFile.toString())));
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return gateway.submitJob(jobGraph, timeout)&lt;/li&gt;
	&lt;li&gt;.thenApply(ack -&amp;gt; new JobSubmitResponseBody(&quot;/jobs/&quot; + jobGraph.getJobID()));&lt;br/&gt;
    +		Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; temporaryHack = artifacts.stream()&lt;br/&gt;
    +			.collect(Collectors.toMap(&lt;br/&gt;
    +				tuple -&amp;gt; tuple.f0,&lt;br/&gt;
    +				// the actual entry definition is mostly irrelevant as only the blobkey is accessed&lt;br/&gt;
    +				// blame whoever wrote the ClientUtils API&lt;br/&gt;
    +				tuple -&amp;gt; new DistributedCache.DistributedCacheEntry(tuple.f1.toString(), false)&lt;br/&gt;
    +			));&lt;br/&gt;
    +&lt;br/&gt;
    +		// TODO: use executor
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    let&apos;s resolve this TODO&lt;/p&gt;</comment>
                            <comment id="16520378" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197449818&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197449818&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);&lt;br/&gt;
    +&lt;br/&gt;
    +		Collection&amp;lt;org.apache.flink.core.fs.Path&amp;gt; jarFiles = new ArrayList&amp;lt;&amp;gt;(requestBody.jarFileNames.size());&lt;br/&gt;
    +		for (String jarFileName : requestBody.jarFileNames) 
{
    +			Path jarFile = getPathAndAssertUpload(jarFileName, &quot;Jar&quot;, nameToFile);
    +			jarFiles.add(new org.apache.flink.core.fs.Path(jarFile.toString()));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		Collection&amp;lt;Tuple2&amp;lt;String, org.apache.flink.core.fs.Path&amp;gt;&amp;gt; artifacts = new ArrayList&amp;lt;&amp;gt;(requestBody.artifactFileNames.size());&lt;br/&gt;
    +		for (JobSubmitRequestBody.DistributedCacheFile artifactFileName : requestBody.artifactFileNames) &lt;/p&gt;
{
    +			Path artifactFile = getPathAndAssertUpload(artifactFileName.fileName, &quot;Artifact&quot;, nameToFile);
    +			artifacts.add(Tuple2.of(artifactFileName.entryName, new org.apache.flink.core.fs.Path(artifactFile.toString())));
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return gateway.submitJob(jobGraph, timeout)&lt;/li&gt;
	&lt;li&gt;.thenApply(ack -&amp;gt; new JobSubmitResponseBody(&quot;/jobs/&quot; + jobGraph.getJobID()));&lt;br/&gt;
    +		Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; temporaryHack = artifacts.stream()
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Let&apos;s change it then.&lt;/p&gt;</comment>
                            <comment id="16520379" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197451254&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197451254&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Move closer to usage&lt;/p&gt;</comment>
                            <comment id="16520380" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197450435&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197450435&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);&lt;br/&gt;
    +&lt;br/&gt;
    +		Collection&amp;lt;org.apache.flink.core.fs.Path&amp;gt; jarFiles = new ArrayList&amp;lt;&amp;gt;(requestBody.jarFileNames.size());&lt;br/&gt;
    +		for (String jarFileName : requestBody.jarFileNames) {&lt;br/&gt;
    +			Path jarFile = getPathAndAssertUpload(jarFileName, &quot;Jar&quot;, nameToFile);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    introduce a constant for `&quot;Jar&quot;`?&lt;/p&gt;</comment>
                            <comment id="16520381" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197451641&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197451641&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);&lt;br/&gt;
    +&lt;br/&gt;
    +		Collection&amp;lt;org.apache.flink.core.fs.Path&amp;gt; jarFiles = new ArrayList&amp;lt;&amp;gt;(requestBody.jarFileNames.size());&lt;br/&gt;
    +		for (String jarFileName : requestBody.jarFileNames) 
{
    +			Path jarFile = getPathAndAssertUpload(jarFileName, &quot;Jar&quot;, nameToFile);
    +			jarFiles.add(new org.apache.flink.core.fs.Path(jarFile.toString()));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		Collection&amp;lt;Tuple2&amp;lt;String, org.apache.flink.core.fs.Path&amp;gt;&amp;gt; artifacts = new ArrayList&amp;lt;&amp;gt;(requestBody.artifactFileNames.size());&lt;br/&gt;
    +		for (JobSubmitRequestBody.DistributedCacheFile artifactFileName : requestBody.artifactFileNames) &lt;/p&gt;
{
    +			Path artifactFile = getPathAndAssertUpload(artifactFileName.fileName, &quot;Artifact&quot;, nameToFile);
    +			artifacts.add(Tuple2.of(artifactFileName.entryName, new org.apache.flink.core.fs.Path(artifactFile.toString())));
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return gateway.submitJob(jobGraph, timeout)&lt;/li&gt;
	&lt;li&gt;.thenApply(ack -&amp;gt; new JobSubmitResponseBody(&quot;/jobs/&quot; + jobGraph.getJobID()));&lt;br/&gt;
    +		Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; temporaryHack = artifacts.stream()&lt;br/&gt;
    +			.collect(Collectors.toMap(&lt;br/&gt;
    +				tuple -&amp;gt; tuple.f0,&lt;br/&gt;
    +				// the actual entry definition is mostly irrelevant as only the blobkey is accessed&lt;br/&gt;
    +				// blame whoever wrote the ClientUtils API&lt;br/&gt;
    +				tuple -&amp;gt; new DistributedCache.DistributedCacheEntry(tuple.f1.toString(), false)&lt;br/&gt;
    +			));&lt;br/&gt;
    +&lt;br/&gt;
    +		// TODO: use executor&lt;br/&gt;
    +		CompletableFuture&amp;lt;JobGraph&amp;gt; jobGraphFuture = CompletableFuture.supplyAsync(() -&amp;gt; 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			JobGraph jobGraph;    +			try (ObjectInputStream objectIn = new ObjectInputStream(Files.newInputStream(jobGraphFile))) {
    +				jobGraph = (JobGraph) objectIn.readObject();
    +			} catch (Exception e) {
    +				throw new CompletionException(new RestHandlerException(
    +					&quot;Failed to deserialize JobGraph.&quot;,
    +					HttpResponseStatus.BAD_REQUEST,
    +					e));
    +			}    +			return jobGraph;    +		}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;);&lt;br/&gt;
    +&lt;br/&gt;
    +		CompletableFuture&amp;lt;Integer&amp;gt; blobServerPortFuture = gateway.getBlobServerPort(timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		CompletableFuture&amp;lt;JobGraph&amp;gt; finalizedJobGraphFuture = jobGraphFuture.thenCombine(blobServerPortFuture, (jobGraph, blobServerPort) -&amp;gt; &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			final InetSocketAddress address = new InetSocketAddress(gateway.getHostname(), blobServerPort);    +			try (BlobClient blobClient = new BlobClient(address, new Configuration())) {
    +				Collection&amp;lt;PermanentBlobKey&amp;gt; jarBlobKeys = ClientUtils.uploadUserJars(jobGraph.getJobID(), jarFiles, blobClient);
    +				ClientUtils.setUserJarBlobKeys(jarBlobKeys, jobGraph);
    +
    +				Collection&amp;lt;Tuple2&amp;lt;String, PermanentBlobKey&amp;gt;&amp;gt; artifactBlobKeys = ClientUtils.uploadUserArtifacts(jobGraph.getJobID(), temporaryHack, blobClient);
    +				ClientUtils.setUserArtifactBlobKeys(jobGraph, artifactBlobKeys);
    +			} catch (IOException e) {
    +				throw new CompletionException(new RestHandlerException(
    +					&quot;Could not upload job files.&quot;,
    +					HttpResponseStatus.INTERNAL_SERVER_ERROR,
    +					e));
    +			}    +			return jobGraph;    +		}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;);&lt;br/&gt;
    +&lt;br/&gt;
    +		CompletableFuture&amp;lt;Acknowledge&amp;gt; jobSubmissionFuture = finalizedJobGraphFuture.thenCompose(jobGraph -&amp;gt; gateway.submitJob(jobGraph, timeout));&lt;br/&gt;
    +&lt;br/&gt;
    +		return jobSubmissionFuture.thenCombine(jobGraphFuture,&lt;br/&gt;
    +			(ack, jobGraph) -&amp;gt; new JobSubmitResponseBody(&quot;/jobs/&quot; + jobGraph.getJobID()));&lt;br/&gt;
    +	}&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This method is quite long. We could think about moving the generation of the `jarFiles` and `temporaryHack` structures into individual methods.&lt;/p&gt;</comment>
                            <comment id="16520382" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197452051&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197452051&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java &amp;#8212;&lt;br/&gt;
    @@ -317,43 +315,51 @@ public JobSubmissionResult submitJob(JobGraph jobGraph, ClassLoader classLoader)&lt;br/&gt;
     		// we have to enable queued scheduling because slot will be allocated lazily&lt;br/&gt;
     		jobGraph.setAllowQueuedScheduling(true);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;log.info(&quot;Requesting blob server port.&quot;);&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;BlobServerPortResponseBody&amp;gt; portFuture = sendRequest(BlobServerPortHeaders.getInstance());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;JobGraph&amp;gt; jobUploadFuture = portFuture.thenCombine(&lt;/li&gt;
	&lt;li&gt;getDispatcherAddress(),&lt;/li&gt;
	&lt;li&gt;(BlobServerPortResponseBody response, String dispatcherAddress) -&amp;gt; {&lt;/li&gt;
	&lt;li&gt;final int blobServerPort = response.port;&lt;/li&gt;
	&lt;li&gt;final InetSocketAddress address = new InetSocketAddress(dispatcherAddress, blobServerPort);&lt;br/&gt;
    +		CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; submissionFuture = CompletableFuture.supplyAsync(&lt;br/&gt;
    +			() -&amp;gt; {&lt;br/&gt;
    +				log.info(&quot;Submitting job graph.&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;List&amp;lt;Path&amp;gt; userJars = jobGraph.getUserJars();&lt;br/&gt;
     				Map&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; userArtifacts = jobGraph.getUserArtifacts();&lt;/li&gt;
	&lt;li&gt;if (!userJars.isEmpty() || !userArtifacts.isEmpty()) {&lt;/li&gt;
	&lt;li&gt;try (BlobClient client = new BlobClient(address, flinkConfig)) 
{
    -						log.info(&quot;Uploading jar files.&quot;);
    -						ClientUtils.uploadAndSetUserJars(jobGraph, client);
    -						log.info(&quot;Uploading jar artifacts.&quot;);
    -						ClientUtils.uploadAndSetUserArtifacts(jobGraph, client);
    -					}
&lt;p&gt; catch (IOException ioe) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new CompletionException(new FlinkException(&quot;Could not upload job files.&quot;, ioe));&lt;br/&gt;
    +&lt;br/&gt;
    +				List&amp;lt;String&amp;gt; jarFileNames = new ArrayList&amp;lt;&amp;gt;(8);&lt;br/&gt;
    +				List&amp;lt;JobSubmitRequestBody.DistributedCacheFile&amp;gt; artifactFileNames = new ArrayList&amp;lt;&amp;gt;(8);&lt;br/&gt;
    +				Collection&amp;lt;FileUpload&amp;gt; filesToUpload = new ArrayList&amp;lt;&amp;gt;(8);&lt;br/&gt;
    +&lt;br/&gt;
    +				// TODO: need configurable location&lt;br/&gt;
    +				final String jobGraphFileName;&lt;br/&gt;
    +				try {&lt;br/&gt;
    +					final java.nio.file.Path tempFile = Files.createTempFile(&quot;flink-jobgraph&quot;, &quot;.bin&quot;);&lt;br/&gt;
    +					try (OutputStream fileOut = Files.newOutputStream(tempFile)) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +						try (ObjectOutputStream objectOut = new ObjectOutputStream(fileOut)) {
    +							objectOut.writeObject(jobGraph);
    +						}     					}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +					filesToUpload.add(new FileUpload(tempFile, RestConstants.CONTENT_TYPE_BINARY));&lt;br/&gt;
    +					jobGraphFileName = tempFile.getFileName().toString();&lt;br/&gt;
    +				} catch (IOException e) &lt;/p&gt;
{
    +					throw new RuntimeException(&quot;lol&quot;, e);
     				}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return jobGraph;&lt;/li&gt;
	&lt;li&gt;});&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; submissionFuture = jobUploadFuture.thenCompose(&lt;/li&gt;
	&lt;li&gt;(JobGraph jobGraphToSubmit) -&amp;gt; {&lt;/li&gt;
	&lt;li&gt;log.info(&quot;Submitting job graph.&quot;);&lt;br/&gt;
    +				for (Path jar : jobGraph.getUserJars()) 
{
    +					jarFileNames.add(jar.getName());
    +					filesToUpload.add(new FileUpload(Paths.get(jar.toUri()), RestConstants.CONTENT_TYPE_JAR));
    +				}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
    -					return sendRequest(
    -						JobSubmitHeaders.getInstance(),
    -						new JobSubmitRequestBody(jobGraph));
    -				}
&lt;p&gt; catch (IOException ioe) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new CompletionException(new FlinkException(&quot;Could not create JobSubmitRequestBody.&quot;, ioe));&lt;br/&gt;
    +				for (Map.Entry&amp;lt;String, DistributedCache.DistributedCacheEntry&amp;gt; artifacts : jobGraph.getUserArtifacts().entrySet()) 
{
    +					artifactFileNames.add(new JobSubmitRequestBody.DistributedCacheFile(artifacts.getKey(), artifacts.getValue().filePath));
    +					filesToUpload.add(new FileUpload(Paths.get(artifacts.getValue().filePath), RestConstants.CONTENT_TYPE_BINARY));
     				}&lt;/li&gt;
	&lt;li&gt;});&lt;br/&gt;
    +&lt;br/&gt;
    +				return sendRetriableRequest(&lt;br/&gt;
    +					JobSubmitHeaders.getInstance(),&lt;br/&gt;
    +					EmptyMessageParameters.getInstance(),&lt;br/&gt;
    +					new JobSubmitRequestBody(&lt;br/&gt;
    +						jobGraphFileName,&lt;br/&gt;
    +						jarFileNames,&lt;br/&gt;
    +						artifactFileNames),&lt;br/&gt;
    +					filesToUpload,&lt;br/&gt;
    +					isConnectionProblemOrServiceUnavailable());
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I think it would be better to clean up the generated `JobGraph` file after we&apos;ve sent the request.&lt;/p&gt;</comment>
                            <comment id="16520383" author="githubbot" created="Fri, 22 Jun 2018 13:57:01 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6203#discussion_r197450505&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6203#discussion_r197450505&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobSubmitHandler.java &amp;#8212;&lt;br/&gt;
    @@ -54,18 +69,89 @@ public JobSubmitHandler(&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
     	protected CompletableFuture&amp;lt;JobSubmitResponseBody&amp;gt; handleRequest(@Nonnull HandlerRequest&amp;lt;JobSubmitRequestBody, EmptyMessageParameters&amp;gt; request, @Nonnull DispatcherGateway gateway) throws RestHandlerException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;JobGraph jobGraph;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			ObjectInputStream objectIn = new ObjectInputStream(new ByteArrayInputStream(request.getRequestBody().serializedJobGraph));
    -			jobGraph = (JobGraph) objectIn.readObject();
    -		}
&lt;p&gt; catch (Exception e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new RestHandlerException(&lt;/li&gt;
	&lt;li&gt;&quot;Failed to deserialize JobGraph.&quot;,&lt;/li&gt;
	&lt;li&gt;HttpResponseStatus.BAD_REQUEST,&lt;/li&gt;
	&lt;li&gt;e);&lt;br/&gt;
    +		Collection&amp;lt;Path&amp;gt; uploadedFiles = request.getUploadedFiles();&lt;br/&gt;
    +		Map&amp;lt;String, Path&amp;gt; nameToFile = uploadedFiles.stream().collect(Collectors.toMap(&lt;br/&gt;
    +			path -&amp;gt; path.getFileName().toString(),&lt;br/&gt;
    +			entry -&amp;gt; entry&lt;br/&gt;
    +		));&lt;br/&gt;
    +&lt;br/&gt;
    +		JobSubmitRequestBody requestBody = request.getRequestBody();&lt;br/&gt;
    +&lt;br/&gt;
    +		Path jobGraphFile = getPathAndAssertUpload(requestBody.jobGraphFileName, &quot;JobGraph&quot;, nameToFile);&lt;br/&gt;
    +&lt;br/&gt;
    +		Collection&amp;lt;org.apache.flink.core.fs.Path&amp;gt; jarFiles = new ArrayList&amp;lt;&amp;gt;(requestBody.jarFileNames.size());&lt;br/&gt;
    +		for (String jarFileName : requestBody.jarFileNames) 
{
    +			Path jarFile = getPathAndAssertUpload(jarFileName, &quot;Jar&quot;, nameToFile);
    +			jarFiles.add(new org.apache.flink.core.fs.Path(jarFile.toString()));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		Collection&amp;lt;Tuple2&amp;lt;String, org.apache.flink.core.fs.Path&amp;gt;&amp;gt; artifacts = new ArrayList&amp;lt;&amp;gt;(requestBody.artifactFileNames.size());&lt;br/&gt;
    +		for (JobSubmitRequestBody.DistributedCacheFile artifactFileName : requestBody.artifactFileNames) {&lt;br/&gt;
    +			Path artifactFile = getPathAndAssertUpload(artifactFileName.fileName, &quot;Artifact&quot;, nameToFile);&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Same here for `&quot;Artifact&quot;`&lt;/p&gt;</comment>
                            <comment id="16531112" author="githubbot" created="Tue, 3 Jul 2018 09:41:40 +0000"  >&lt;p&gt;GitHub user zentol opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6241&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6241&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;rest&amp;#93;&lt;/span&gt; Rework JobSubmitHandler to accept jar files&lt;/p&gt;

&lt;p&gt;    Backport of #6203 for 1.5.&lt;/p&gt;

&lt;p&gt;    The differences to the current version of the linked PR (state @ b9a804c350d12469eccf0fd78d82dcac8eaa3c5b) are:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;`ClientUtils` were not introduced&lt;/li&gt;
	&lt;li&gt;removed all code related to the upload of artifacts, as this feature was introduced in 1.6&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    @tillrohrmann &lt;/p&gt;


&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/zentol/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/zentol/flink&lt;/a&gt; 9280_epsilon_bp&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6241.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6241.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #6241&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit a8765ae2f006c99a905afd93e93cbe9b0cfef09b&lt;br/&gt;
Author: zentol &amp;lt;chesnay@...&amp;gt;&lt;br/&gt;
Date:   2018-06-11T09:45:12Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;rest&amp;#93;&lt;/span&gt; Rework JobSubmitHandler to accept jar files&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16531843" author="githubbot" created="Tue, 3 Jul 2018 19:26:14 +0000"  >&lt;p&gt;Github user zentol closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6241&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6241&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16563806" author="githubbot" created="Tue, 31 Jul 2018 15:10:36 +0000"  >&lt;p&gt;xccui commented on issue #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#issuecomment-409256314&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#issuecomment-409256314&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Hi @fhueske, I wonder if you could take a look at this PR when it&apos;s convenient for you. Thanks.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16570859" author="githubbot" created="Mon, 6 Aug 2018 22:24:25 +0000"  >&lt;p&gt;fhueske commented on issue #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#issuecomment-410872065&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#issuecomment-410872065&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Thanks for the reminder @xccui! &lt;br/&gt;
   I&apos;ll try to have a look this week.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16571680" author="githubbot" created="Tue, 7 Aug 2018 13:50:35 +0000"  >&lt;p&gt;fhueske commented on issue #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#issuecomment-411063032&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#issuecomment-411063032&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Hi @xccui, I think the problem can be fixed more easily with fewer side effects on tests. &lt;/p&gt;

&lt;p&gt;   As pointed out in the Jira issue, I think can add Union-specific logic to the `KeyFunctions.appendKeyExtractor()` methods. IMO, the best approach would be to add key extractors to all inputs of the union:&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   public static &amp;lt;T, K&amp;gt; org.apache.flink.api.common.operators.Operator&amp;lt;Tuple2&amp;lt;K, T&amp;gt;&amp;gt; appendKeyExtractor(&lt;br/&gt;
       org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; input,&lt;br/&gt;
       SelectorFunctionKeys&amp;lt;T, K&amp;gt; key) {&lt;/p&gt;

&lt;p&gt;     if (input instanceof Union) &lt;/p&gt;
{
       // if input is a union, we apply the key extractors recursively to all inputs
       org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; firstInput = ((Union) input).getFirstInput();
       org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; secondInput = ((Union) input).getSecondInput();
   
       org.apache.flink.api.common.operators.Operator&amp;lt;Tuple2&amp;lt;K, T&amp;gt;&amp;gt; firstKeyExtractor =
         appendKeyExtractor(firstInput, key);
       org.apache.flink.api.common.operators.Operator&amp;lt;Tuple2&amp;lt;K, T&amp;gt;&amp;gt; secondKeyExtractor =
         appendKeyExtractor(secondInput, key);
   
       return new Union(firstKeyExtractor, secondKeyExtractor, input.getName());
     }
&lt;p&gt; else &lt;/p&gt;
{
       // original implementation
   }
&lt;p&gt;   ```&lt;/p&gt;

&lt;p&gt;   This change for both `appendKeyExtractor()` methods and a test that verifies the correct parallelism of all operators would be sufficient to fix the issue.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16573418" author="githubbot" created="Wed, 8 Aug 2018 15:58:08 +0000"  >&lt;p&gt;xccui commented on issue #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#issuecomment-411458158&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#issuecomment-411458158&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Thanks for the review @fhueske. I also agree that updating `KeyFunctions.appendKeyExtractor()` can fix this issue, easily and effectively. However, it seems not to be a graceful, or say, an untimate solution. &lt;/p&gt;

&lt;p&gt;   I think the main problem is whether we take the Union operator as a special one without parallelism (your solution) or a common operator whose parallelism is forcibly set to the larger one of its inputs (my solution). IMO, the drawback of the former solution is that we may need to add more Union-specific logic in the future, while the drawback of the later one is that I&apos;m not sure setting the parallelism like that can really solve the problem once for all. Anyway, we should forbid the users to set the parallelism for Union since it does not take effect.&lt;/p&gt;

&lt;p&gt;   What do you think?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16573434" author="githubbot" created="Wed, 8 Aug 2018 16:16:37 +0000"  >&lt;p&gt;fhueske commented on issue #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#issuecomment-411464535&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#issuecomment-411464535&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Hi @xccui, in principle uniform handling of operators is a very good idea!&lt;/p&gt;

&lt;p&gt;   However, union is a special operator, because there is no Union runtime operator. An operator that consumes from Union will simply multiplex all unioned inputs. Hence, the parallelism of the (non-existing) union is the parallelism of its successor. Since there is already quite a bit of custom code for union operators, I&apos;m a bit afraid that your fix might cause problems in some corner cases.&lt;/p&gt;

&lt;p&gt;   Another benefit of my approach is that the key extractors can be chained to the previous operators. This is not the case if the extractor is applied on the unioned result. &lt;/p&gt;

&lt;p&gt;   Best, Fabian&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16573477" author="githubbot" created="Wed, 8 Aug 2018 16:39:38 +0000"  >&lt;p&gt;xccui commented on issue #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#issuecomment-411472064&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#issuecomment-411472064&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Thanks for the explanation @fhueske. It&apos;s true that the key extractors cannot be chained for a union operator unless we manually specify them for inputs (with different parallelisms), specifically. Maybe it&apos;s worth to give this operator &quot;special treatment&quot; &#128516;I&apos;ll update the PR according to your suggestion.&lt;/p&gt;

&lt;p&gt;   Thanks, Xingcan&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16579647" author="githubbot" created="Tue, 14 Aug 2018 11:03:59 +0000"  >&lt;p&gt;fhueske commented on a change in pull request #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#discussion_r209909097&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#discussion_r209909097&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-java/src/main/java/org/apache/flink/api/java/operators/UnionOperator.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -62,4 +62,10 @@ public UnionOperator(DataSet&amp;lt;T&amp;gt; input1, DataSet&amp;lt;T&amp;gt; input2, String unionLocationN&lt;br/&gt;
 	protected Union&amp;lt;T&amp;gt; translateToDataFlow(Operator&amp;lt;T&amp;gt; input1, Operator&amp;lt;T&amp;gt; input2) &lt;/p&gt;
{
 		return new Union&amp;lt;T&amp;gt;(input1, input2, unionLocationName);
 	}
&lt;p&gt;+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public UnionOperator&amp;lt;T&amp;gt; setParallelism(int parallelism) {&lt;br/&gt;
+		// The parallelism of an UnionOperator should not be set.&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Change the comment to: &quot;Union is not translated to an independent operator but executed by multiplexing its input on the following operator. Hence, the parallelism of a Union cannot be set.&quot;&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16580923" author="githubbot" created="Wed, 15 Aug 2018 10:57:23 +0000"  >&lt;p&gt;xccui commented on issue #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#issuecomment-413163702&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#issuecomment-413163702&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Hi @fhueske. I just added some tests for the union operator. &lt;/p&gt;

&lt;p&gt;   Thanks, Xingcan&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16580960" author="githubbot" created="Wed, 15 Aug 2018 11:40:49 +0000"  >&lt;p&gt;fhueske commented on a change in pull request #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003#discussion_r210240946&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003#discussion_r210240946&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-java/src/main/java/org/apache/flink/api/java/operators/UnionOperator.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -65,7 +65,8 @@ public UnionOperator(DataSet&amp;lt;T&amp;gt; input1, DataSet&amp;lt;T&amp;gt; input2, String unionLocationN&lt;/p&gt;

&lt;p&gt; 	@Override&lt;br/&gt;
 	public UnionOperator&amp;lt;T&amp;gt; setParallelism(int parallelism) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// The parallelism of an UnionOperator should not be set.&lt;br/&gt;
+        // Union is not translated to an independent operator but executed by multiplexing&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   -2 space indention&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16581322" author="githubbot" created="Wed, 15 Aug 2018 16:37:07 +0000"  >&lt;p&gt;asfgit closed pull request #6003: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9289&quot; title=&quot;Parallelism of generated operators should have max parallism of input&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9289&quot;&gt;&lt;del&gt;FLINK-9289&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Dataset&amp;#93;&lt;/span&gt; Parallelism of generated operators should have max parallelism of input&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6003&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6003&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-java/src/main/java/org/apache/flink/api/java/operators/KeyFunctions.java b/flink-java/src/main/java/org/apache/flink/api/java/operators/KeyFunctions.java&lt;br/&gt;
index f6336cde2b7..3e7a552a68f 100644&lt;br/&gt;
&amp;#8212; a/flink-java/src/main/java/org/apache/flink/api/java/operators/KeyFunctions.java&lt;br/&gt;
+++ b/flink-java/src/main/java/org/apache/flink/api/java/operators/KeyFunctions.java&lt;br/&gt;
@@ -22,6 +22,7 @@&lt;br/&gt;
 import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
 import org.apache.flink.api.common.operators.Keys.SelectorFunctionKeys;&lt;br/&gt;
 import org.apache.flink.api.common.operators.UnaryOperatorInformation;&lt;br/&gt;
+import org.apache.flink.api.common.operators.Union;&lt;br/&gt;
 import org.apache.flink.api.common.operators.base.MapOperatorBase;&lt;br/&gt;
 import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
 import org.apache.flink.api.java.operators.translation.KeyExtractingMapper;&lt;br/&gt;
@@ -43,6 +44,19 @@&lt;br/&gt;
 			org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; input,&lt;br/&gt;
 			SelectorFunctionKeys&amp;lt;T, K&amp;gt; key) {&lt;/p&gt;

&lt;p&gt;+		if (input instanceof Union) &lt;/p&gt;
{
+			// if input is a union, we apply the key extractors recursively to all inputs
+			org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; firstInput = ((Union) input).getFirstInput();
+			org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; secondInput = ((Union) input).getSecondInput();
+
+			org.apache.flink.api.common.operators.Operator&amp;lt;Tuple2&amp;lt;K, T&amp;gt;&amp;gt; firstInputWithKey =
+					appendKeyExtractor(firstInput, key);
+			org.apache.flink.api.common.operators.Operator&amp;lt;Tuple2&amp;lt;K, T&amp;gt;&amp;gt; secondInputWithKey =
+					appendKeyExtractor(secondInput, key);
+
+			return new Union(firstInputWithKey, secondInputWithKey, input.getName());
+		}
&lt;p&gt;+&lt;br/&gt;
 		TypeInformation&amp;lt;T&amp;gt; inputType = key.getInputType();&lt;br/&gt;
 		TypeInformation&amp;lt;Tuple2&amp;lt;K, T&amp;gt;&amp;gt; typeInfoWithKey = createTypeWithKey(key);&lt;br/&gt;
 		KeyExtractingMapper&amp;lt;T, K&amp;gt; extractor = new KeyExtractingMapper(key.getKeyExtractor());&lt;br/&gt;
@@ -66,6 +80,19 @@&lt;br/&gt;
 			SelectorFunctionKeys&amp;lt;T, K1&amp;gt; key1,&lt;br/&gt;
 			SelectorFunctionKeys&amp;lt;T, K2&amp;gt; key2) {&lt;/p&gt;

&lt;p&gt;+		if (input instanceof Union) &lt;/p&gt;
{
+			// if input is a union, we apply the key extractors recursively to all inputs
+			org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; firstInput = ((Union) input).getFirstInput();
+			org.apache.flink.api.common.operators.Operator&amp;lt;T&amp;gt; secondInput = ((Union) input).getSecondInput();
+
+			org.apache.flink.api.common.operators.Operator&amp;lt;Tuple3&amp;lt;K1, K2, T&amp;gt;&amp;gt; firstInputWithKey =
+					appendKeyExtractor(firstInput, key1, key2);
+			org.apache.flink.api.common.operators.Operator&amp;lt;Tuple3&amp;lt;K1, K2, T&amp;gt;&amp;gt; secondInputWithKey =
+					appendKeyExtractor(secondInput, key1, key2);
+
+			return new Union(firstInputWithKey, secondInputWithKey, input.getName());
+		}
&lt;p&gt;+&lt;br/&gt;
 		TypeInformation&amp;lt;T&amp;gt; inputType = key1.getInputType();&lt;br/&gt;
 		TypeInformation&amp;lt;Tuple3&amp;lt;K1, K2, T&amp;gt;&amp;gt; typeInfoWithKey = createTypeWithKey(key1, key2);&lt;br/&gt;
 		TwoKeyExtractingMapper&amp;lt;T, K1, K2&amp;gt; extractor =&lt;br/&gt;
diff --git a/flink-java/src/main/java/org/apache/flink/api/java/operators/UnionOperator.java b/flink-java/src/main/java/org/apache/flink/api/java/operators/UnionOperator.java&lt;br/&gt;
index 0da5e01a0b3..7d3c0d6fc3f 100644&lt;br/&gt;
&amp;#8212; a/flink-java/src/main/java/org/apache/flink/api/java/operators/UnionOperator.java&lt;br/&gt;
+++ b/flink-java/src/main/java/org/apache/flink/api/java/operators/UnionOperator.java&lt;br/&gt;
@@ -62,4 +62,11 @@ public UnionOperator(DataSet&amp;lt;T&amp;gt; input1, DataSet&amp;lt;T&amp;gt; input2, String unionLocationN&lt;br/&gt;
 	protected Union&amp;lt;T&amp;gt; translateToDataFlow(Operator&amp;lt;T&amp;gt; input1, Operator&amp;lt;T&amp;gt; input2) &lt;/p&gt;
{
 		return new Union&amp;lt;T&amp;gt;(input1, input2, unionLocationName);
 	}
&lt;p&gt;+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public UnionOperator&amp;lt;T&amp;gt; setParallelism(int parallelism) &lt;/p&gt;
{
+		// Union is not translated to an independent operator but executed by multiplexing
+		// its input on the following operator. Hence, the parallelism of a Union cannot be set.
+		throw new UnsupportedOperationException(&quot;Cannot set the parallelism for Union.&quot;);
+	}
&lt;p&gt; }&lt;br/&gt;
diff --git a/flink-java/src/test/java/org/apache/flink/api/java/operators/translation/UnionTranslationTest.java b/flink-java/src/test/java/org/apache/flink/api/java/operators/translation/UnionTranslationTest.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..216e37f2acf&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/flink-java/src/test/java/org/apache/flink/api/java/operators/translation/UnionTranslationTest.java&lt;br/&gt;
@@ -0,0 +1,158 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.flink.api.java.operators.translation;&lt;br/&gt;
+&lt;br/&gt;
+import org.apache.flink.api.common.ExecutionConfig;&lt;br/&gt;
+import org.apache.flink.api.common.Plan;&lt;br/&gt;
+import org.apache.flink.api.common.functions.GroupReduceFunction;&lt;br/&gt;
+import org.apache.flink.api.common.operators.GenericDataSinkBase;&lt;br/&gt;
+import org.apache.flink.api.common.operators.Order;&lt;br/&gt;
+import org.apache.flink.api.common.operators.SingleInputOperator;&lt;br/&gt;
+import org.apache.flink.api.common.operators.Union;&lt;br/&gt;
+import org.apache.flink.api.common.operators.base.MapOperatorBase;&lt;br/&gt;
+import org.apache.flink.api.java.DataSet;&lt;br/&gt;
+import org.apache.flink.api.java.ExecutionEnvironment;&lt;br/&gt;
+import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
+import org.apache.flink.api.java.io.DiscardingOutputFormat;&lt;br/&gt;
+import org.apache.flink.api.java.tuple.Tuple3;&lt;br/&gt;
+import org.apache.flink.types.LongValue;&lt;br/&gt;
+import org.apache.flink.types.StringValue;&lt;br/&gt;
+&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+&lt;br/&gt;
+import static org.junit.Assert.assertEquals;&lt;br/&gt;
+import static org.junit.Assert.assertTrue;&lt;br/&gt;
+import static org.junit.Assert.fail;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Tests for translation of union operation.&lt;br/&gt;
+ */&lt;br/&gt;
+@SuppressWarnings(&quot;serial&quot;)&lt;br/&gt;
+public class UnionTranslationTest {&lt;br/&gt;
+&lt;br/&gt;
+	@Test&lt;br/&gt;
+	public void translateUnion2Group() {&lt;br/&gt;
+		try {&lt;br/&gt;
+			final int parallelism = 4;&lt;br/&gt;
+			ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment(parallelism);&lt;br/&gt;
+&lt;br/&gt;
+			DataSet&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;&amp;gt; dataset1 = getSourceDataSet(env, 3);&lt;br/&gt;
+&lt;br/&gt;
+			DataSet&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;&amp;gt; dataset2 = getSourceDataSet(env, 2);&lt;br/&gt;
+&lt;br/&gt;
+			dataset1.union(dataset2)&lt;br/&gt;
+					.groupBy((KeySelector&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;, String&amp;gt;) value -&amp;gt; &quot;&quot;)&lt;br/&gt;
+					.reduceGroup((GroupReduceFunction&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;, String&amp;gt;) (values, out) -&amp;gt; {})&lt;br/&gt;
+					.returns(String.class)&lt;br/&gt;
+					.output(new DiscardingOutputFormat&amp;lt;&amp;gt;());&lt;br/&gt;
+&lt;br/&gt;
+			Plan p = env.createProgramPlan();&lt;br/&gt;
+&lt;br/&gt;
+			// The plan should look like the following one.&lt;br/&gt;
+			//&lt;br/&gt;
+			// DataSet1(3) - MapOperator(3)-+&lt;br/&gt;
+			//	                            |- Union(-1) - SingleInputOperator - Sink&lt;br/&gt;
+			// DataSet2(2) - MapOperator(2)-+&lt;br/&gt;
+&lt;br/&gt;
+			GenericDataSinkBase&amp;lt;?&amp;gt; sink = p.getDataSinks().iterator().next();&lt;br/&gt;
+			Union unionOperator = (Union) ((SingleInputOperator) sink.getInput()).getInput();&lt;br/&gt;
+&lt;br/&gt;
+			// The key mappers should be added to both of the two input streams for union.&lt;br/&gt;
+			assertTrue(unionOperator.getFirstInput() instanceof MapOperatorBase&amp;lt;?, ?, ?&amp;gt;);&lt;br/&gt;
+			assertTrue(unionOperator.getSecondInput() instanceof MapOperatorBase&amp;lt;?, ?, ?&amp;gt;);&lt;br/&gt;
+&lt;br/&gt;
+			// The parallelisms of the key mappers should be equal to those of their inputs.&lt;br/&gt;
+			assertEquals(unionOperator.getFirstInput().getParallelism(), 3);&lt;br/&gt;
+			assertEquals(unionOperator.getSecondInput().getParallelism(), 2);&lt;br/&gt;
+&lt;br/&gt;
+			// The union should always have the default parallelism.&lt;br/&gt;
+			assertEquals(unionOperator.getParallelism(), ExecutionConfig.PARALLELISM_DEFAULT);&lt;br/&gt;
+		}&lt;br/&gt;
+		catch (Exception e) &lt;/p&gt;
{
+			System.err.println(e.getMessage());
+			e.printStackTrace();
+			fail(&quot;Test caused an error: &quot; + e.getMessage());
+		}
&lt;p&gt;+	}&lt;br/&gt;
+&lt;br/&gt;
+	@Test&lt;br/&gt;
+	public void translateUnion3SortedGroup() {&lt;br/&gt;
+		try {&lt;br/&gt;
+			final int parallelism = 4;&lt;br/&gt;
+			ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment(parallelism);&lt;br/&gt;
+&lt;br/&gt;
+			DataSet&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;&amp;gt; dataset1 = getSourceDataSet(env, 2);&lt;br/&gt;
+&lt;br/&gt;
+			DataSet&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;&amp;gt; dataset2 = getSourceDataSet(env, 3);&lt;br/&gt;
+&lt;br/&gt;
+			DataSet&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;&amp;gt; dataset3 = getSourceDataSet(env, -1);&lt;br/&gt;
+&lt;br/&gt;
+			dataset1.union(dataset2).union(dataset3)&lt;br/&gt;
+					.groupBy((KeySelector&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;, String&amp;gt;) value -&amp;gt; &quot;&quot;)&lt;br/&gt;
+					.sortGroup((KeySelector&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;, String&amp;gt;) value -&amp;gt; &quot;&quot;, Order.ASCENDING)&lt;br/&gt;
+					.reduceGroup((GroupReduceFunction&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;, String&amp;gt;) (values, out) -&amp;gt; {})&lt;br/&gt;
+					.returns(String.class)&lt;br/&gt;
+					.output(new DiscardingOutputFormat&amp;lt;&amp;gt;());&lt;br/&gt;
+&lt;br/&gt;
+			Plan p = env.createProgramPlan();&lt;br/&gt;
+&lt;br/&gt;
+			// The plan should look like the following one.&lt;br/&gt;
+			//&lt;br/&gt;
+			// DataSet1(2) - MapOperator(2)-+&lt;br/&gt;
+			//	                            |- Union(-1) -+&lt;br/&gt;
+			// DataSet2(3) - MapOperator(3)&lt;del&gt;+             |&lt;/del&gt; Union(-1) - SingleInputOperator - Sink&lt;br/&gt;
+			//                                            |&lt;br/&gt;
+			//             DataSet3(&lt;del&gt;1) - MapOperator(-1)&lt;/del&gt;+&lt;br/&gt;
+&lt;br/&gt;
+			GenericDataSinkBase&amp;lt;?&amp;gt; sink = p.getDataSinks().iterator().next();&lt;br/&gt;
+			Union secondUnionOperator = (Union) ((SingleInputOperator) sink.getInput()).getInput();&lt;br/&gt;
+&lt;br/&gt;
+			// The first input of the second union should be the first union.&lt;br/&gt;
+			Union firstUnionOperator = (Union) secondUnionOperator.getFirstInput();&lt;br/&gt;
+&lt;br/&gt;
+			// The key mapper should be added to the second input stream of the second union.&lt;br/&gt;
+			assertTrue(secondUnionOperator.getSecondInput() instanceof MapOperatorBase&amp;lt;?, ?, ?&amp;gt;);&lt;br/&gt;
+&lt;br/&gt;
+			// The key mappers should be added to both of the two input streams for the first union.&lt;br/&gt;
+			assertTrue(firstUnionOperator.getFirstInput() instanceof MapOperatorBase&amp;lt;?, ?, ?&amp;gt;);&lt;br/&gt;
+			assertTrue(firstUnionOperator.getSecondInput() instanceof MapOperatorBase&amp;lt;?, ?, ?&amp;gt;);&lt;br/&gt;
+&lt;br/&gt;
+			// The parallelisms of the key mappers should be equal to those of their inputs.&lt;br/&gt;
+			assertEquals(firstUnionOperator.getFirstInput().getParallelism(), 2);&lt;br/&gt;
+			assertEquals(firstUnionOperator.getSecondInput().getParallelism(), 3);&lt;br/&gt;
+			assertEquals(secondUnionOperator.getSecondInput().getParallelism(), -1);&lt;br/&gt;
+&lt;br/&gt;
+			// The union should always have the default parallelism.&lt;br/&gt;
+			assertEquals(secondUnionOperator.getParallelism(), ExecutionConfig.PARALLELISM_DEFAULT);&lt;br/&gt;
+			assertEquals(firstUnionOperator.getParallelism(), ExecutionConfig.PARALLELISM_DEFAULT);&lt;br/&gt;
+		}&lt;br/&gt;
+		catch (Exception e) &lt;/p&gt;
{
+			System.err.println(e.getMessage());
+			e.printStackTrace();
+			fail(&quot;Test caused an error: &quot; + e.getMessage());
+		}
&lt;p&gt;+	}&lt;br/&gt;
+&lt;br/&gt;
+	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
+	private static DataSet&amp;lt;Tuple3&amp;lt;Double, StringValue, LongValue&amp;gt;&amp;gt; getSourceDataSet(ExecutionEnvironment env, int parallelism) &lt;/p&gt;
{
+		return env
+				.fromElements(new Tuple3&amp;lt;&amp;gt;(0.0, new StringValue(&quot;&quot;), new LongValue(1L)))
+				.setParallelism(parallelism);
+	}
&lt;p&gt;+}&lt;br/&gt;
diff --git a/flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/linkanalysis/PageRank.java b/flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/linkanalysis/PageRank.java&lt;br/&gt;
index d259fac6341..932ad78a1d8 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/linkanalysis/PageRank.java&lt;br/&gt;
+++ b/flink-libraries/flink-gelly/src/main/java/org/apache/flink/graph/library/linkanalysis/PageRank.java&lt;br/&gt;
@@ -235,7 +235,6 @@ protected void mergeConfiguration(GraphAlgorithmWrappingBase other) {&lt;br/&gt;
 		// s, adjusted pagerank(s)&lt;br/&gt;
 		DataSet&amp;lt;Tuple2&amp;lt;K, DoubleValue&amp;gt;&amp;gt; adjustedScores = vertexScores&lt;br/&gt;
 			.union(sourceVertices)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.setParallelism(parallelism)&lt;br/&gt;
 				.name(&quot;Union with source vertices&quot;)&lt;br/&gt;
 			.map(new AdjustScores&amp;lt;&amp;gt;(dampingFactor))&lt;br/&gt;
 				.withBroadcastSet(sumOfScores, SUM_OF_SCORES)&lt;br/&gt;
diff --git a/flink-libraries/flink-python/src/main/java/org/apache/flink/python/api/PythonPlanBinder.java b/flink-libraries/flink-python/src/main/java/org/apache/flink/python/api/PythonPlanBinder.java&lt;br/&gt;
index 1182708bb9f..4709fa52a5a 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-libraries/flink-python/src/main/java/org/apache/flink/python/api/PythonPlanBinder.java&lt;br/&gt;
+++ b/flink-libraries/flink-python/src/main/java/org/apache/flink/python/api/PythonPlanBinder.java&lt;br/&gt;
@@ -515,7 +515,7 @@ private void createSortOperation(PythonOperationInfo info) {&lt;br/&gt;
 	private &amp;lt;IN&amp;gt; void createUnionOperation(PythonOperationInfo info) 
{
 		DataSet&amp;lt;IN&amp;gt; op1 = sets.getDataSet(info.parentID);
 		DataSet&amp;lt;IN&amp;gt; op2 = sets.getDataSet(info.otherID);
-		sets.add(info.setID, op1.union(op2).setParallelism(info.parallelism).name(&quot;Union&quot;));
+		sets.add(info.setID, op1.union(op2).name(&quot;Union&quot;));
 	}&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	private &amp;lt;IN1, IN2, OUT&amp;gt; void createCoGroupOperation(PythonOperationInfo info, TypeInformation&amp;lt;OUT&amp;gt; type) {&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16581440" author="xccui" created="Wed, 15 Aug 2018 18:17:45 +0000"  >&lt;p&gt;Fixed in 1.4&#160;c9d6607b017f871e292650caab3802175a5b7b4a&lt;/p&gt;

&lt;p&gt;Fixed in 1.5&#160;9f1c12c10c3eb7b302f0688ed1b60fd08942dc03&lt;/p&gt;

&lt;p&gt;Fixed in 1.6&#160;f7501a44a3d8319e3be3996fa5ee4130589c0784&lt;/p&gt;

&lt;p&gt;Fixed in 1.7&#160;7af933b78400921ae798b8a882cba8ecff5c94be&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 13 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3t9c7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>