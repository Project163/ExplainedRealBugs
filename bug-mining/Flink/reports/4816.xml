<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:51:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-20143] use `yarn.provided.lib.dirs` config deploy job failed in yarn per job mode</title>
                <link>https://issues.apache.org/jira/browse/FLINK-20143</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;use follow command deploy flink job to yarn failed&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./bin/flink run -m yarn-cluster -d -ynm flink-1.12-test -ytm 3g -yjm 3g -yD yarn.provided.lib.dirs=hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib    ./examples/streaming/StateMachineExample.jar&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;log:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ ./bin/flink run -m yarn-cluster -d -ynm flink-1.12-test -ytm 3g -yjm 3g -yD yarn.provided.lib.dirs=hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib&#160; &#160; ./examples/streaming/StateMachineExample.jar$ ./bin/flink run -m yarn-cluster -d -ynm flink-1.12-test -ytm 3g -yjm 3g -yD yarn.provided.lib.dirs=hdfs:///flink/flink-1.12-SNAPSHOT/lib&#160; &#160; ./examples/streaming/StateMachineExample.jarSLF4J: &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/data1/app/flink-1.12-SNAPSHOT/lib/log4j-slf4j-impl-2.12.1.jar!/org/slf4j/impl/StaticLoggerBinder.&lt;span class=&quot;code-keyword&quot;&gt;class]&lt;/span&gt;SLF4J: Found binding in [jar:file:/data1/app/hadoop-2.7.3-snappy-32core12disk/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.&lt;span class=&quot;code-keyword&quot;&gt;class]&lt;/span&gt;SLF4J: Found binding in [jar:file:/data1/app/hadoop-2.7.3-snappy-32core12disk/share/hadoop/tools/lib/hadoop-aliyun-2.9.2-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.&lt;span class=&quot;code-keyword&quot;&gt;class]&lt;/span&gt;SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]2020-11-13 16:14:30,347 INFO&#160; org.apache.flink.yarn.cli.FlinkYarnSessionCli&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Dynamic Property set: yarn.provided.lib.dirs=hdfs:///flink/flink-1.12-SNAPSHOT/lib2020-11-13 16:14:30,347 INFO&#160; org.apache.flink.yarn.cli.FlinkYarnSessionCli&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Dynamic Property set: yarn.provided.lib.dirs=hdfs:///flink/flink-1.12-SNAPSHOT/libUsage with built-in data generator: StateMachineExample [--error-rate &amp;lt;probability-of-invalid-transition&amp;gt;] [--sleep &amp;lt;sleep-per-record-in-ms&amp;gt;]Usage with Kafka: StateMachineExample --kafka-topic &amp;lt;topic&amp;gt; [--brokers &amp;lt;brokers&amp;gt;]Options &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; both the above setups: [--backend &amp;lt;file|rocks&amp;gt;] [--checkpoint-dir &amp;lt;filepath&amp;gt;] [--async-checkpoints &amp;lt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;|&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;gt;] [--incremental-checkpoints &amp;lt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;|&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;gt;] [--output &amp;lt;filepath&amp;gt; OR &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; stdout]
&lt;/span&gt;Using standalone source with error rate 0.000000 and sleep delay 1 millis
2020-11-13 16:14:30,706 WARN&#160; org.apache.flink.yarn.configuration.YarnLogConfigUtil&#160; &#160; &#160; &#160; [] - The configuration directory (&lt;span class=&quot;code-quote&quot;&gt;&apos;/data1/app/flink-1.12-SNAPSHOT/conf&apos;&lt;/span&gt;) already contains a LOG4J config file.If you want to use logback, then please delete or rename the log configuration file.2020-11-13 16:14:30,947 INFO&#160; org.apache.hadoop.yarn.client.AHSProxy&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;[] - Connecting to Application History server at FAT-hadoopuat-69117.vm.dc01.tech/10.69.1.17:102002020-11-13 16:14:30,958 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - No path &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the flink jar passed. Using the location of &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.yarn.YarnClusterDescriptor to locate the jar2020-11-13 16:14:31,065 INFO&#160; org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm22020-11-13 16:14:31,130 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - The configured JobManager memory is 3072 MB. YARN will allocate 4096 MB to make up an integer multiple of its minimum allocation memory (2048 MB, configured via &lt;span class=&quot;code-quote&quot;&gt;&apos;yarn.scheduler.minimum-allocation-mb&apos;&lt;/span&gt;). The extra 1024 MB may not be used by Flink.2020-11-13 16:14:31,130 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - The configured TaskManager memory is 3072 MB. YARN will allocate 4096 MB to make up an integer multiple of its minimum allocation memory (2048 MB, configured via &lt;span class=&quot;code-quote&quot;&gt;&apos;yarn.scheduler.minimum-allocation-mb&apos;&lt;/span&gt;). The extra 1024 MB may not be used by Flink.2020-11-13 16:14:31,130 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Cluster specification: ClusterSpecification{masterMemoryMB=3072, taskManagerMemoryMB=3072, slotsPerTaskManager=2}2020-11-13 16:14:31,681 WARN&#160; org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory&#160; &#160; &#160; [] - The &lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt;-circuit local reads feature cannot be used because libhadoop cannot be loaded.2020-11-13 16:14:33,417 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Submitting application master application_1599741232083_219902020-11-13 16:14:33,446 INFO&#160; org.apache.hadoop.yarn.client.api.impl.YarnClientImpl&#160; &#160; &#160; &#160; [] - Submitted application application_1599741232083_219902020-11-13 16:14:33,446 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the cluster to be allocated2020-11-13 16:14:33,448 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Deploying cluster, current state ACCEPTED
------------------------------------------------------------&#160;The program finished with the following exception:
org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: Could not deploy Yarn job cluster. at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:330) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198) at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:114) at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:743) at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:242) at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:971) at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:1047) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698) at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1047)Caused by: org.apache.flink.client.deployment.ClusterDeploymentException: Could not deploy Yarn job cluster. at org.apache.flink.yarn.YarnClusterDescriptor.deployJobCluster(YarnClusterDescriptor.java:460) at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:70) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1916) at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128) at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1798) at org.apache.flink.streaming.examples.statemachine.StateMachineExample.main(StateMachineExample.java:142) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:316) ... 11 moreCaused by: org.apache.flink.yarn.YarnClusterDescriptor$YarnDeploymentException: The YARN application unexpectedly switched to state FAILED during deployment.Diagnostics from YARN: Application application_1599741232083_21990 failed 2 times in previous 10000 milliseconds due to AM Container &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; appattempt_1599741232083_21990_000002 exited with&#160; exitCode: -1Failing &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; attempt.Diagnostics: [2020-11-13 16:14:38.244]Destination must be relativeFor more detailed output, check the application tracking page: http:&lt;span class=&quot;code-comment&quot;&gt;//FAT-hadoopuat-69117.vm.dc01.tech:8188/applicationhistory/app/application_1599741232083_21990 Then click on links to logs of each attempt.. Failing the application.If log aggregation is enabled on your cluster, use &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; command to further investigate the issue:yarn logs -applicationId application_1599741232083_21990 at org.apache.flink.yarn.YarnClusterDescriptor.startAppMaster(YarnClusterDescriptor.java:1078) at org.apache.flink.yarn.YarnClusterDescriptor.deployInternal(YarnClusterDescriptor.java:558) at org.apache.flink.yarn.YarnClusterDescriptor.deployJobCluster(YarnClusterDescriptor.java:453) ... 22 more2020-11-13 16:14:38,492 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Cancelling deployment from Deployment Failure Hook2020-11-13 16:14:38,494 INFO&#160; org.apache.hadoop.yarn.client.AHSProxy&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;[] - Connecting to Application History server at FAT-hadoopuat-69117.vm.dc01.tech/10.69.1.17:102002020-11-13 16:14:38,495 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Killing YARN application2020-11-13 16:14:38,499 INFO&#160; org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm22020-11-13 16:14:38,503 INFO&#160; org.apache.hadoop.yarn.client.api.impl.YarnClientImpl&#160; &#160; &#160; &#160; [] - Killed application application_1599741232083_219902020-11-13 16:14:38,503 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Deleting files in hdfs://flashHadoopUAT/user/deploy/.flink/application_1599741232083_21990.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but if i set `execution.target: yarn-per-job` in flink-conf.yaml, it runs ok&lt;/p&gt;

&lt;p&gt;if i run in application mode, it runs ok too&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./bin/flink run-application -p 2 -d -t yarn-application -ytm 3g -yjm 3g -yD yarn.provided.lib.dirs=hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib&#160;./examples/streaming/StateMachineExample.jar&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but the jobid is&#160;00000000000000000000000000000000&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13340454">FLINK-20143</key>
            <summary>use `yarn.provided.lib.dirs` config deploy job failed in yarn per job mode</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wangyang0918">Yang Wang</assignee>
                                    <reporter username="zhisheng">zhisheng</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 13 Nov 2020 08:24:14 +0000</created>
                <updated>Wed, 18 Nov 2020 10:06:56 +0000</updated>
                            <resolved>Wed, 18 Nov 2020 10:06:56 +0000</resolved>
                                    <version>1.11.2</version>
                    <version>1.12.0</version>
                                    <fixVersion>1.11.3</fixVersion>
                    <fixVersion>1.12.0</fixVersion>
                                    <component>Client / Job Submission</component>
                    <component>Deployment / YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="17231276" author="kkl0u" created="Fri, 13 Nov 2020 09:10:08 +0000"  >&lt;p&gt;Can you share with us the job manager and task manager logs &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhisheng&quot; class=&quot;user-hover&quot; rel=&quot;zhisheng&quot;&gt;zhisheng&lt;/a&gt;? This may help figuring out what is happening. &lt;/p&gt;</comment>
                            <comment id="17231283" author="kkl0u" created="Fri, 13 Nov 2020 09:16:49 +0000"  >&lt;p&gt;Also I think that your second command is not correct. You are using &lt;tt&gt;-t&lt;/tt&gt; which activates the &lt;tt&gt;GenericCLI&lt;/tt&gt; but then you specify parameters using the &lt;tt&gt;YarnSessionCLI&lt;/tt&gt; convention of putting a &lt;tt&gt;-y&lt;/tt&gt; as a prefix. Can you verify if the memory specifications you put are picked up and the shared.lib.dir is actually. used?&lt;/p&gt;</comment>
                            <comment id="17231284" author="zhisheng" created="Fri, 13 Nov 2020 09:19:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt;&#160;it does not have jobmanager log and taskmanager log&lt;/p&gt;</comment>
                            <comment id="17231287" author="zhisheng" created="Fri, 13 Nov 2020 09:22:07 +0000"  >&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13015203/13015203_image-2020-11-13-17-21-47-751.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13015204/13015204_image-2020-11-13-17-22-06-111.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="17231300" author="zhisheng" created="Fri, 13 Nov 2020 09:24:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt; yes, -ytm and -yjm does not&#160;take effect&#65292;i create a issue some days ago&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-19973&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-19973&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17231301" author="kkl0u" created="Fri, 13 Nov 2020 09:25:27 +0000"  >&lt;p&gt;I am not sure if I can figure out what is happening from what is here. &lt;/p&gt;</comment>
                            <comment id="17231306" author="kkl0u" created="Fri, 13 Nov 2020 09:27:42 +0000"  >&lt;p&gt;As discussed in the issue, you have to specify the full config option name prefixed by &lt;tt&gt;-D&lt;/tt&gt; when using the &lt;tt&gt;GenericCLI&lt;/tt&gt;. This means for example that &lt;tt&gt;-ytm&lt;/tt&gt; should become &lt;tt&gt;-Dtaskmanager.memory.process.size=...&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="17231317" author="zhisheng" created="Fri, 13 Nov 2020 09:32:15 +0000"  >&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./bin/flink run -m yarn-cluster -d  -Dyarn.provided.lib.dirs=&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib&quot;&lt;/span&gt; ./examples/streaming/StateMachineExample.jar&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;i use this command(remove the -ynm flink-1.12-test -ytm 3g -yjm ), it runs ok&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17231319" author="zhisheng" created="Fri, 13 Nov 2020 09:35:06 +0000"  >&lt;p&gt;in our&#160;production environment&#65292;has many flink job&#65292;every job have the -ytm and -yjm -ynm config&#65292;if we upgrade to 1.12&#65292;It could change a lot &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17231321" author="zhisheng" created="Fri, 13 Nov 2020 09:36:55 +0000"  >&lt;p&gt;Are there any other methods to make job config&#160;compatibility&#65311;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17231326" author="kkl0u" created="Fri, 13 Nov 2020 09:40:18 +0000"  >&lt;p&gt;Also the above command seems to be problematic.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./bin/flink run -m yarn-cluster -d  -Dyarn.provided.lib.dirs=&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib&quot;&lt;/span&gt; ./examples/streaming/StateMachineExample.jar&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What if you use?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./bin/flink run -t yarn-per-job -Dexecution.attached=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; -Dyarn.provided.lib.dirs=&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib&quot;&lt;/span&gt; ./examples/streaming/StateMachineExample.jar&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and please check the logs to see if the shared dir is picked up or you are shipping everything from the client.&lt;/p&gt;</comment>
                            <comment id="17231346" author="zhisheng" created="Fri, 13 Nov 2020 10:06:28 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ ./bin/flink run -t yarn-per-job -Dexecution.attached=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; -Dyarn.provided.lib.dirs=&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib&quot;&lt;/span&gt; ./examples/streaming/StateMachineExample.jar
&lt;/span&gt;
SLF4J: &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/data1/app/flink-1.12-SNAPSHOT/lib/log4j-slf4j-impl-2.12.1.jar!/org/slf4j/impl/StaticLoggerBinder.&lt;span class=&quot;code-keyword&quot;&gt;class]&lt;/span&gt;SLF4J: Found binding in [jar:file:/data1/app/hadoop-2.7.3-snappy-32core12disk/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.&lt;span class=&quot;code-keyword&quot;&gt;class]&lt;/span&gt;SLF4J: Found binding in [jar:file:/data1/app/hadoop-2.7.3-snappy-32core12disk/share/hadoop/tools/lib/hadoop-aliyun-2.9.2-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.&lt;span class=&quot;code-keyword&quot;&gt;class]&lt;/span&gt;SLF4J: See http:&lt;span class=&quot;code-comment&quot;&gt;//www.slf4j.org/codes.html#multiple_bindings &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Usage with built-in data generator: StateMachineExample [--error-rate &amp;lt;probability-of-invalid-transition&amp;gt;] [--sleep &amp;lt;sleep-per-record-in-ms&amp;gt;]Usage with Kafka: StateMachineExample --kafka-topic &amp;lt;topic&amp;gt; [--brokers &amp;lt;brokers&amp;gt;]Options &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; both the above setups: [--backend &amp;lt;file|rocks&amp;gt;] [--checkpoint-dir &amp;lt;filepath&amp;gt;] [--async-checkpoints &amp;lt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;|&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;gt;] [--incremental-checkpoints &amp;lt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;|&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;gt;] [--output &amp;lt;filepath&amp;gt; OR &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; stdout]
&lt;/span&gt;Using standalone source with error rate 0.000000 and sleep delay 1 millis
2020-11-13 18:05:51,974 WARN&#160; org.apache.flink.yarn.configuration.YarnLogConfigUtil&#160; &#160; &#160; &#160; [] - The configuration directory (&lt;span class=&quot;code-quote&quot;&gt;&apos;/data1/app/flink-1.12-SNAPSHOT/conf&apos;&lt;/span&gt;) already contains a LOG4J config file.If you want to use logback, then please delete or rename the log configuration file.2020-11-13 18:05:52,202 INFO&#160; org.apache.hadoop.yarn.client.AHSProxy&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;[] - Connecting to Application History server at FAT-hadoopuat-69117.vm.dc01.tech/10.69.1.17:102002020-11-13 18:05:52,213 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - No path &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the flink jar passed. Using the location of &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.yarn.YarnClusterDescriptor to locate the jar2020-11-13 18:05:52,324 INFO&#160; org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm22020-11-13 18:05:52,387 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - The configured JobManager memory is 1600 MB. YARN will allocate 2048 MB to make up an integer multiple of its minimum allocation memory (2048 MB, configured via &lt;span class=&quot;code-quote&quot;&gt;&apos;yarn.scheduler.minimum-allocation-mb&apos;&lt;/span&gt;). The extra 448 MB may not be used by Flink.2020-11-13 18:05:52,388 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - The configured TaskManager memory is 1728 MB. YARN will allocate 2048 MB to make up an integer multiple of its minimum allocation memory (2048 MB, configured via &lt;span class=&quot;code-quote&quot;&gt;&apos;yarn.scheduler.minimum-allocation-mb&apos;&lt;/span&gt;). The extra 320 MB may not be used by Flink.2020-11-13 18:05:52,388 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Cluster specification: ClusterSpecification{masterMemoryMB=2048, taskManagerMemoryMB=1728, slotsPerTaskManager=2}2020-11-13 18:05:52,932 WARN&#160; org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory&#160; &#160; &#160; [] - The &lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt;-circuit local reads feature cannot be used because libhadoop cannot be loaded.2020-11-13 18:05:55,076 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Submitting application master application_1599741232083_220112020-11-13 18:05:55,307 INFO&#160; org.apache.hadoop.yarn.client.api.impl.YarnClientImpl&#160; &#160; &#160; &#160; [] - Submitted application application_1599741232083_220112020-11-13 18:05:55,308 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the cluster to be allocated2020-11-13 18:05:55,310 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Deploying cluster, current state ACCEPTED
------------------------------------------------------------&#160;The program finished with the following exception:
org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: Could not deploy Yarn job cluster. at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:330) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198) at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:114) at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:743) at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:242) at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:971) at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:1047) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698) at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1047)Caused by: org.apache.flink.client.deployment.ClusterDeploymentException: Could not deploy Yarn job cluster. at org.apache.flink.yarn.YarnClusterDescriptor.deployJobCluster(YarnClusterDescriptor.java:460) at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:70) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1916) at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128) at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76) at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1798) at org.apache.flink.streaming.examples.statemachine.StateMachineExample.main(StateMachineExample.java:142) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:316) ... 11 moreCaused by: org.apache.flink.yarn.YarnClusterDescriptor$YarnDeploymentException: The YARN application unexpectedly switched to state FAILED during deployment.Diagnostics from YARN: Application application_1599741232083_22011 failed 2 times in previous 10000 milliseconds due to AM Container &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; appattempt_1599741232083_22011_000002 exited with&#160; exitCode: -1Failing &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; attempt.Diagnostics: [2020-11-13 18:06:01.081]Destination must be relativeFor more detailed output, check the application tracking page: http:&lt;span class=&quot;code-comment&quot;&gt;//FAT-hadoopuat-69117.vm.dc01.tech:8188/applicationhistory/app/application_1599741232083_22011 Then click on links to logs of each attempt.. Failing the application.If log aggregation is enabled on your cluster, use &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; command to further investigate the issue:yarn logs -applicationId application_1599741232083_22011 at org.apache.flink.yarn.YarnClusterDescriptor.startAppMaster(YarnClusterDescriptor.java:1078) at org.apache.flink.yarn.YarnClusterDescriptor.deployInternal(YarnClusterDescriptor.java:558) at org.apache.flink.yarn.YarnClusterDescriptor.deployJobCluster(YarnClusterDescriptor.java:453) ... 22 more2020-11-13 18:06:01,111 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Cancelling deployment from Deployment Failure Hook2020-11-13 18:06:01,113 INFO&#160; org.apache.hadoop.yarn.client.AHSProxy&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;[] - Connecting to Application History server at FAT-hadoopuat-69117.vm.dc01.tech/10.69.1.17:102002020-11-13 18:06:01,114 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Killing YARN application2020-11-13 18:06:01,120 INFO&#160; org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm22020-11-13 18:06:01,124 INFO&#160; org.apache.hadoop.yarn.client.api.impl.YarnClientImpl&#160; &#160; &#160; &#160; [] - Killed application application_1599741232083_220112020-11-13 18:06:01,124 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Deleting files in hdfs://flashHadoopUAT/user/deploy/.flink/application_1599741232083_22011.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17231360" author="kkl0u" created="Fri, 13 Nov 2020 10:33:37 +0000"  >&lt;p&gt;Can&apos;t you use &lt;tt&gt;yarn logs -applicationId application_1599741232083_22011&lt;/tt&gt; to get the logs as the message says?&lt;/p&gt;</comment>
                            <comment id="17231361" author="kkl0u" created="Fri, 13 Nov 2020 10:35:52 +0000"  >&lt;p&gt;Also could you run the same command with DEBUG logging enabled?&lt;/p&gt;</comment>
                            <comment id="17231365" author="zhisheng" created="Fri, 13 Nov 2020 10:44:26 +0000"  >&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13015211/13015211_image-2020-11-13-18-43-55-188.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;does not has any log, i had say just now&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="17231369" author="zhisheng" created="Fri, 13 Nov 2020 10:50:16 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
22020-11-13 18:46:43,014 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - --------------------------------------------------------------------------------2020-11-13 18:46:43,014 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - --------------------------------------------------------------------------------2020-11-13 18:46:43,019 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; Starting Command Line Client (Version: 1.12-SNAPSHOT, Scala: 2.11, Rev:c55420b, Date:2020-11-05T05:29:49+01:00)2020-11-13 18:46:43,019 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; OS current user: deploy2020-11-13 18:46:43,415 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; Current Hadoop/Kerberos user: deploy2020-11-13 18:46:43,416 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.92-b142020-11-13 18:46:43,416 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; Maximum heap size: 7136 MiBytes2020-11-13 18:46:43,416 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; JAVA_HOME: /app/jdk/2020-11-13 18:46:43,418 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; Hadoop version: 2.7.32020-11-13 18:46:43,418 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; JVM Options:2020-11-13 18:46:43,418 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;-Dlog.file=/data1/app/flink-1.12-SNAPSHOT/log/flink-deploy-client-FAT-hadoopuat-69120.vm.dc01. .tech.log2020-11-13 18:46:43,418 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;-Dlog4j.configuration=file:/data1/app/flink-1.12-SNAPSHOT/conf/log4j-cli.properties2020-11-13 18:46:43,418 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;-Dlog4j.configurationFile=file:/data1/app/flink-1.12-SNAPSHOT/conf/log4j-cli.properties2020-11-13 18:46:43,418 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;-Dlogback.configurationFile=file:/data1/app/flink-1.12-SNAPSHOT/conf/logback.xml2020-11-13 18:46:43,419 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; Program Arguments:2020-11-13 18:46:43,420 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;run2020-11-13 18:46:43,420 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;-t2020-11-13 18:46:43,421 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;yarn-per-job2020-11-13 18:46:43,421 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;-Dexecution.attached=false2020-11-13 18:46:43,421 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;-Dyarn.provided.lib.dirs=hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib2020-11-13 18:46:43,421 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; &#160; &#160;./examples/streaming/StateMachineExample.jar2020-11-13 18:46:43,421 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] -&#160; Classpath: /data1/app/flink-1.12-SNAPSHOT/lib/flink-connector-jdbc_2.11-1.12-SNAPSHOT.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-csv-1.12-SNAPSHOT.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-json-1.12-SNAPSHOT.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-shaded-zookeeper-3.4.14.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-sql-connector-elasticsearch7_2.11-1.12-SNAPSHOT.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-sql-connector-kafka_2.11-1.12-SNAPSHOT.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-table_2.11-1.12-SNAPSHOT.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-table-blink_2.11-1.12-SNAPSHOT.jar:/data1/app/flink-1.12-SNAPSHOT/lib/log4j-1.2-api-2.12.1.jar:/data1/app/flink-1.12-SNAPSHOT/lib/log4j-api-2.12.1.jar:/data1/app/flink-1.12-SNAPSHOT/lib/log4j-core-2.12.1.jar:/data1/app/flink-1.12-SNAPSHOT/lib/log4j-slf4j-impl-2.12.1.jar:/data1/app/flink-1.12-SNAPSHOT/lib/flink-dist_2.11-1.12-SNAPSHOT.jar:/app/hadoop/etc/hadoop:/app/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/app/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/app/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/app/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/app/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/app/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/app/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/app/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/app/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/app/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/app/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/app/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/app/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/app/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/app/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/app/hadoop/share/hadoop/common/lib/xz-1.0.jar:/app/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/app/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/app/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/app/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/app/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/app/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/app/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/app/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/app/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/app/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/app/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/app/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/app/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/app/hadoop/share/hadoop/common/lib/-rack-awareness-policy-1.0.jar:/app/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/app/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/app/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/app/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/app/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/app/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/app/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/app/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/app/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/app/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/app/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/app/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/app/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/app/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/app/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/app/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/app/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/app/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/app/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/app/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/app/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/app/hadoop/share/hadoop/common/lib/junit-4.11.jar:/app/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/app/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/app/hadoop/share/hadoop/common/lib/activation-1.1.jar:/app/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/app/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/app/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/app/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/app/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/app/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/app/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/app/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/app/hadoop/share/hadoop/common/lib/asm-3.2.jar:/app/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/app/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/app/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/app/hadoop/share/hadoop/hdfs:/app/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/app/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/app/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/app/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/app/hadoop/share/hadoop/hdfs/lib/ranger-plugin-classloader-1.1.0.jar:/app/hadoop/share/hadoop/hdfs/lib/ranger-hdfs-plugin-shim-1.1.0.jar:/app/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/app/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/app/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/app/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/app/hadoop/share/hadoop/hdfs/lib/-block-placement-policy-1.0.jar:/app/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/app/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/app/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/app/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/app/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/app/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/app/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/app/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/app/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/app/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/app/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/app/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/app/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/app/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/app/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/app/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/app/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/app/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/app/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/app/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/app/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/app/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/app/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/app/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/app/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/app/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/app/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/app/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/app/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/app/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/app/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/app/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/app/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/app/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/app/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/app/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/app/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/app/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/app/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/app/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/app/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/app/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/app/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/app/hadoop/share/hadoop/yarn/lib/spark-2.3.1-yarn-shuffle.jar:/app/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/app/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/app/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/app/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/app/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/app/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/app/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/app/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/app/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/app/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/app/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/app/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/app/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/app/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/app/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/app/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/app/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/app/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/app/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/app/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/app/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/app/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/app/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/app/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/app/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/app/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/app/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/app/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/app/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/app/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/app/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/app/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/app/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/app/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/app/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/app/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/app/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/app/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/app/hadoop/share/hadoop/tools/lib/hadoop-aliyun-2.9.2-jar-with-dependencies.jar:/app/hadoop/contrib/capacity-scheduler/*.jar:/app/hadoop/etc/hadoop:/app/hadoop/etc/hadoop:/app/hbase/conf2020-11-13 18:46:43,422 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - --------------------------------------------------------------------------------2020-11-13 18:46:43,426 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: jobmanager.rpc.address, localhost2020-11-13 18:46:43,426 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: jobmanager.rpc.port, 61232020-11-13 18:46:43,426 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: jobmanager.memory.process.size, 1600m2020-11-13 18:46:43,426 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: taskmanager.memory.process.size, 1728m2020-11-13 18:46:43,426 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: taskmanager.numberOfTaskSlots, 22020-11-13 18:46:43,426 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: parallelism.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, 12020-11-13 18:46:43,426 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: high-availability, zookeeper2020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: high-availability.storageDir, hdfs:///flink/ha/2020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: high-availability.zookeeper.quorum, 10.69.1.15:2181,10.69.1.16:2181,10.69.1.17:21812020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: state.backend, rocksdb2020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: state.checkpoints.dir, hdfs:///flink/checkpoints2020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: state.savepoints.dir, hdfs:///flink/savepoints2020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: state.backend.incremental, true2020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: state.checkpoints.num-retained, 22020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: jobmanager.execution.failover-strategy, region2020-11-13 18:46:43,427 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: execution.checkpointing.externalized-checkpoint-retention, RETAIN_ON_CANCELLATION2020-11-13 18:46:43,428 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: execution.checkpointing.interval, 120s2020-11-13 18:46:43,428 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: execution.checkpointing.mode, AT_LEAST_ONCE2020-11-13 18:46:43,428 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: execution.checkpointing.timeout, 20 min2020-11-13 18:46:43,428 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: execution.checkpointing.min-pause, 1 s2020-11-13 18:46:43,428 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: historyserver.web.address, fat-hadoopuat-69120.vm.dc01. .tech2020-11-13 18:46:43,428 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: historyserver.web.port, 80822020-11-13 18:46:43,428 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: historyserver.archive.fs.refresh-interval, 100002020-11-13 18:46:43,429 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: jobmanager.archive.fs.dir, hdfs:///flink/history-log2020-11-13 18:46:43,429 INFO&#160; org.apache.flink.configuration.GlobalConfiguration&#160; &#160; &#160; &#160; &#160; &#160;[] - Loading configuration property: historyserver.archive.fs.dir, hdfs:///flink/history-log2020-11-13 18:46:43,611 INFO&#160; org.apache.flink.runtime.security.modules.HadoopModule&#160; &#160; &#160; &#160;[] - Hadoop user set to deploy (auth:SIMPLE)2020-11-13 18:46:43,618 INFO&#160; org.apache.flink.runtime.security.modules.JaasModule&#160; &#160; &#160; &#160; &#160;[] - Jaas file will be created as /tmp/jaas-264858002832469329.conf.2020-11-13 18:46:43,627 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Running &lt;span class=&quot;code-quote&quot;&gt;&apos;run&apos;&lt;/span&gt; command.2020-11-13 18:46:43,648 INFO&#160; org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Building program from JAR file2020-11-13 18:46:43,666 INFO&#160; org.apache.flink.client.ClientUtils&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Starting program (detached: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)2020-11-13 18:46:43,717 INFO&#160; org.apache.flink.contrib.streaming.state.RocksDBStateBackend [] - Using predefined options: DEFAULT.2020-11-13 18:46:43,718 INFO&#160; org.apache.flink.contrib.streaming.state.RocksDBStateBackend [] - Using &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; options factory: DefaultConfigurableOptionsFactory{configuredOptions={}}.2020-11-13 18:46:43,768 INFO&#160; org.apache.flink.api.java.typeutils.TypeExtractor&#160; &#160; &#160; &#160; &#160; &#160; [] - &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.streaming.examples.statemachine.event.Event does not contain a setter &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; field type2020-11-13 18:46:43,768 INFO&#160; org.apache.flink.api.java.typeutils.TypeExtractor&#160; &#160; &#160; &#160; &#160; &#160; [] - &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.streaming.examples.statemachine.event.Event cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on &lt;span class=&quot;code-quote&quot;&gt;&quot;Data Types &amp;amp; Serialization&quot;&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; details of the effect on performance.2020-11-13 18:46:43,883 INFO&#160; org.apache.flink.api.java.typeutils.TypeExtractor&#160; &#160; &#160; &#160; &#160; &#160; [] - &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.streaming.examples.statemachine.event.Alert does not contain a setter &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; field address2020-11-13 18:46:43,883 INFO&#160; org.apache.flink.api.java.typeutils.TypeExtractor&#160; &#160; &#160; &#160; &#160; &#160; [] - &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.streaming.examples.statemachine.event.Alert cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on &lt;span class=&quot;code-quote&quot;&gt;&quot;Data Types &amp;amp; Serialization&quot;&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; details of the effect on performance.2020-11-13 18:46:44,015 WARN&#160; org.apache.flink.yarn.configuration.YarnLogConfigUtil&#160; &#160; &#160; &#160; [] - The configuration directory (&lt;span class=&quot;code-quote&quot;&gt;&apos;/data1/app/flink-1.12-SNAPSHOT/conf&apos;&lt;/span&gt;) already contains a LOG4J config file.If you want to use logback, then please delete or rename the log configuration file.2020-11-13 18:46:44,228 INFO&#160; org.apache.hadoop.yarn.client.AHSProxy&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;[] - Connecting to Application History server at FAT-hadoopuat-69117.vm.dc01. .tech/10.69.1.17:102002020-11-13 18:46:44,238 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - No path &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the flink jar passed. Using the location of &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.yarn.YarnClusterDescriptor to locate the jar2020-11-13 18:46:44,255 INFO&#160; org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (160.000mb (167772162 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead2020-11-13 18:46:44,259 INFO&#160; org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (172.800mb (181193935 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead2020-11-13 18:46:44,352 INFO&#160; org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm22020-11-13 18:46:44,412 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - The configured JobManager memory is 1600 MB. YARN will allocate 2048 MB to make up an integer multiple of its minimum allocation memory (2048 MB, configured via &lt;span class=&quot;code-quote&quot;&gt;&apos;yarn.scheduler.minimum-allocation-mb&apos;&lt;/span&gt;). The extra 448 MB may not be used by Flink.2020-11-13 18:46:44,413 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - The configured TaskManager memory is 1728 MB. YARN will allocate 2048 MB to make up an integer multiple of its minimum allocation memory (2048 MB, configured via &lt;span class=&quot;code-quote&quot;&gt;&apos;yarn.scheduler.minimum-allocation-mb&apos;&lt;/span&gt;). The extra 320 MB may not be used by Flink.2020-11-13 18:46:44,413 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Cluster specification: ClusterSpecification{masterMemoryMB=2048, taskManagerMemoryMB=1728, slotsPerTaskManager=2}2020-11-13 18:46:44,960 WARN&#160; org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory&#160; &#160; &#160; [] - The &lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt;-circuit local reads feature cannot be used because libhadoop cannot be loaded.2020-11-13 18:46:47,129 INFO&#160; org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils [] - The derived from fraction jvm overhead memory (160.000mb (167772162 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead2020-11-13 18:46:47,146 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Submitting application master application_1599741232083_220232020-11-13 18:46:47,378 INFO&#160; org.apache.hadoop.yarn.client.api.impl.YarnClientImpl&#160; &#160; &#160; &#160; [] - Submitted application application_1599741232083_220232020-11-13 18:46:47,378 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the cluster to be allocated2020-11-13 18:46:47,380 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Deploying cluster, current state ACCEPTED2020-11-13 18:46:52,167 ERROR org.apache.flink.client.cli.CliFrontend&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; running the command.org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: Could not deploy Yarn job cluster. at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:330) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:198) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:114) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:743) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:242) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:971) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:1047) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_92] at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_92] at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698) [hadoop-common-2.7.3.jar:?] at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) [flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1047) [flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT]Caused by: org.apache.flink.client.deployment.ClusterDeploymentException: Could not deploy Yarn job cluster. at org.apache.flink.yarn.YarnClusterDescriptor.deployJobCluster(YarnClusterDescriptor.java:460) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:70) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1916) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1798) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.streaming.examples.statemachine.StateMachineExample.main(StateMachineExample.java:142) ~[?:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92] at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:316) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] ... 11 moreCaused by: org.apache.flink.yarn.YarnClusterDescriptor$YarnDeploymentException: The YARN application unexpectedly switched to state FAILED during deployment.Diagnostics from YARN: Application application_1599741232083_22023 failed 2 times in previous 10000 milliseconds due to AM Container &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; appattempt_1599741232083_22023_000002 exited with&#160; exitCode: -1Failing &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; attempt.Diagnostics: [2020-11-13 18:46:51.947]Destination must be relativeFor more detailed output, check the application tracking page: http://FAT-hadoopuat-69117.vm.dc01. .tech:8188/applicationhistory/app/application_1599741232083_22023 Then click on links to logs of each attempt.. Failing the application.If log aggregation is enabled on your cluster, use &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; command to further investigate the issue:yarn logs -applicationId application_1599741232083_22023 at org.apache.flink.yarn.YarnClusterDescriptor.startAppMaster(YarnClusterDescriptor.java:1078) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.yarn.YarnClusterDescriptor.deployInternal(YarnClusterDescriptor.java:558) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.yarn.YarnClusterDescriptor.deployJobCluster(YarnClusterDescriptor.java:453) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:70) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1916) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:128) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:76) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1798) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] at org.apache.flink.streaming.examples.statemachine.StateMachineExample.main(StateMachineExample.java:142) ~[?:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92] at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:316) ~[flink-dist_2.11-1.12-SNAPSHOT.jar:1.12-SNAPSHOT] ... 11 more2020-11-13 18:46:52,177 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Cancelling deployment from Deployment Failure Hook2020-11-13 18:46:52,179 INFO&#160; org.apache.hadoop.yarn.client.AHSProxy&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;[] - Connecting to Application History server at FAT-hadoopuat-69117.vm.dc01. .tech/10.69.1.17:102002020-11-13 18:46:52,180 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Killing YARN application2020-11-13 18:46:52,184 INFO&#160; org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm22020-11-13 18:46:52,188 INFO&#160; org.apache.hadoop.yarn.client.api.impl.YarnClientImpl&#160; &#160; &#160; &#160; [] - Killed application application_1599741232083_220232020-11-13 18:46:52,188 INFO&#160; org.apache.flink.yarn.YarnClusterDescriptor&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; [] - Deleting files in hdfs://flashHadoopUAT/user/deploy/.flink/application_1599741232083_22023.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17231415" author="kkl0u" created="Fri, 13 Nov 2020 12:00:33 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhisheng&quot; class=&quot;user-hover&quot; rel=&quot;zhisheng&quot;&gt;zhisheng&lt;/a&gt;, I run the command that I wrote in my previous comment on a local yarn cluster, and it seems to be working. I do not have your config.yaml though, as I start with the default one.&lt;/p&gt;</comment>
                            <comment id="17231522" author="kkl0u" created="Fri, 13 Nov 2020 14:28:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fly_in_gis&quot; class=&quot;user-hover&quot; rel=&quot;fly_in_gis&quot;&gt;fly_in_gis&lt;/a&gt; do you have an idea about this issue?&lt;/p&gt;</comment>
                            <comment id="17232488" author="fly_in_gis" created="Mon, 16 Nov 2020 03:41:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhisheng&quot; class=&quot;user-hover&quot; rel=&quot;zhisheng&quot;&gt;zhisheng&lt;/a&gt;&#160;Could you add the hdfs schema in the &lt;tt&gt;yarn.provided.lib.dirs&lt;/tt&gt; and have a try again.&lt;/p&gt;

&lt;p&gt;For example, &lt;tt&gt;-yD yarn.provided.lib.dirs=hdfs://hdpdev/flink/flink-1.12-SNAPSHOT/lib&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="17232558" author="fly_in_gis" created="Mon, 16 Nov 2020 06:11:37 +0000"  >&lt;p&gt;Hmm. I think maybe I find the root cause. When the &lt;tt&gt;yarn.provided.lib.dirs&lt;/tt&gt; is set to the non-qualified path(e.g. hdfs:///path/of/sharedLib), the &lt;tt&gt;URI#relativize&lt;/tt&gt;&#160;in &lt;tt&gt;YarnApplicationFileUploader#getAllFilesInProvidedLibDirs&lt;/tt&gt; could not work as expected.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhisheng&quot; class=&quot;user-hover&quot; rel=&quot;zhisheng&quot;&gt;zhisheng&lt;/a&gt;&#160;So for your situation, I guess all the deployment(e.g. yarn-per-job, yarn-application, yarn-session) could not work effectively if you are using&#160;non-qualified path.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt;&#160;Even though we have a work around, specify a qualified path(e.g. hdfs://hdpdev/path/of/sharedLib), I think it is better to fix this issue. I will attach a PR for this ticket.&lt;/p&gt;</comment>
                            <comment id="17232590" author="kkl0u" created="Mon, 16 Nov 2020 07:38:56 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fly_in_gis&quot; class=&quot;user-hover&quot; rel=&quot;fly_in_gis&quot;&gt;fly_in_gis&lt;/a&gt;, feel free to ping me for a review.&lt;/p&gt;</comment>
                            <comment id="17232689" author="fly_in_gis" created="Mon, 16 Nov 2020 11:13:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhisheng&quot; class=&quot;user-hover&quot; rel=&quot;zhisheng&quot;&gt;zhisheng&lt;/a&gt; I have attached a PR to fix this issue. Also I verified your command in a Yarn cluster after this change, it works well. Please have a try.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
./bin/flink run -m yarn-cluster -d -ynm flink-1.12-test -ytm 3g -yjm 3g -yD yarn.provided.lib.dirs=hdfs:&lt;span class=&quot;code-comment&quot;&gt;///flink/flink-1.12-SNAPSHOT/lib    ./examples/streaming/StateMachineExample.jar&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17233539" author="zhisheng" created="Tue, 17 Nov 2020 12:00:41 +0000"  >&lt;p&gt;thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fly_in_gis&quot; class=&quot;user-hover&quot; rel=&quot;fly_in_gis&quot;&gt;fly_in_gis&lt;/a&gt;&#160;, it works well now, thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kkl0u&quot; class=&quot;user-hover&quot; rel=&quot;kkl0u&quot;&gt;kkl0u&lt;/a&gt;&#160;too, it will push to 1.12.0 ?&lt;/p&gt;</comment>
                            <comment id="17233592" author="kkl0u" created="Tue, 17 Nov 2020 13:43:24 +0000"  >&lt;p&gt;Yes, I will try to merge it today and hopefully it will make it in 1.12 &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhisheng&quot; class=&quot;user-hover&quot; rel=&quot;zhisheng&quot;&gt;zhisheng&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17234446" author="kkl0u" created="Wed, 18 Nov 2020 10:06:56 +0000"  >&lt;p&gt;master: 424d41d124871b0a82d514f1ce15bc87b52169c6&lt;br/&gt;
1.11: f6f6271e8c17f7873ccb4cfe649d0ad35dfde445&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="13015203" name="image-2020-11-13-17-21-47-751.png" size="185602" author="zhisheng" created="Fri, 13 Nov 2020 09:21:49 +0000"/>
                            <attachment id="13015204" name="image-2020-11-13-17-22-06-111.png" size="40413" author="zhisheng" created="Fri, 13 Nov 2020 09:22:06 +0000"/>
                            <attachment id="13015211" name="image-2020-11-13-18-43-55-188.png" size="69352" author="zhisheng" created="Fri, 13 Nov 2020 10:43:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 51 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0kk7s:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>