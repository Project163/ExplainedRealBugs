<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:25:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-4329] Fix Streaming File Source Timestamps/Watermarks Handling</title>
                <link>https://issues.apache.org/jira/browse/FLINK-4329</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The &lt;tt&gt;ContinuousFileReaderOperator&lt;/tt&gt; does not correctly deal with watermarks, i.e. they are just passed through. This means that when the &lt;tt&gt;ContinuousFileMonitoringFunction&lt;/tt&gt; closes and emits a &lt;tt&gt;Long.MAX_VALUE&lt;/tt&gt; that watermark can &quot;overtake&quot; the records that are to be emitted in the &lt;tt&gt;ContinuousFileReaderOperator&lt;/tt&gt;. Together with the new &quot;allowed lateness&quot; setting in window operator this can lead to elements being dropped as late.&lt;/p&gt;

&lt;p&gt;Also, &lt;tt&gt;ContinuousFileReaderOperator&lt;/tt&gt; does not correctly assign ingestion timestamps since it is not technically a source but looks like one to the user.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12995632">FLINK-4329</key>
            <summary>Fix Streaming File Source Timestamps/Watermarks Handling</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kkl0u">Kostas Kloudas</assignee>
                                    <reporter username="aljoscha">Aljoscha Krettek</reporter>
                        <labels>
                    </labels>
                <created>Mon, 8 Aug 2016 12:00:18 +0000</created>
                <updated>Wed, 5 Oct 2016 22:24:20 +0000</updated>
                            <resolved>Wed, 5 Oct 2016 22:24:09 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.1.3</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                                    <component>Connectors / Common</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15415532" author="githubbot" created="Wed, 10 Aug 2016 16:31:32 +0000"  >&lt;p&gt;GitHub user kl0u opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4329&quot; title=&quot;Fix Streaming File Source Timestamps/Watermarks Handling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4329&quot;&gt;&lt;del&gt;FLINK-4329&lt;/del&gt;&lt;/a&gt; Fix Streaming File Source Timestamps/Watermarks Handling&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/kl0u/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/kl0u/flink&lt;/a&gt; continuous_file_fix&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2350&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 6207a9f5da086d808331afe0e8caf0f03b3fabc5&lt;br/&gt;
Author: kl0u &amp;lt;kkloudas@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-08-09T12:11:45Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4329&quot; title=&quot;Fix Streaming File Source Timestamps/Watermarks Handling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4329&quot;&gt;&lt;del&gt;FLINK-4329&lt;/del&gt;&lt;/a&gt; Fix Streaming File Source Timestamps/Watermarks Handling&lt;/p&gt;

&lt;p&gt;    Now the ContinuousFileReaderOperator ignores the watermarks sent by&lt;br/&gt;
    the source function and emits its own watermarks in case we are&lt;br/&gt;
    opearating on Ingestion time. In addition, and for Ingestion time&lt;br/&gt;
    only, the reader also assigns the correct timestamps to the elements&lt;br/&gt;
    that it reads.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15417121" author="githubbot" created="Thu, 11 Aug 2016 12:23:10 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    How does this fix work?&lt;/p&gt;</comment>
                            <comment id="15417133" author="githubbot" created="Thu, 11 Aug 2016 12:32:33 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    The way it works is that now the reader gets a ReaderContext and emits its own watermarks depending on which timeCharacteristic we are operating on. If it is on IngestionTime, which was the original problem, we emit periodically. In addition, in this case, it assigns timestamps to the emitted elements.&lt;/p&gt;</comment>
                            <comment id="15426349" author="githubbot" created="Thu, 18 Aug 2016 12:26:56 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75297857&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75297857&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperator.java &amp;#8212;&lt;br/&gt;
    @@ -179,7 +195,16 @@ public void close() throws Exception &lt;/p&gt;
{
     			// called by the StreamTask while having it.
     			checkpointLock.wait();
     		}
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;collector.close();&lt;br/&gt;
    +&lt;br/&gt;
    +		// finally if we are closed normally and we are operating on&lt;br/&gt;
    +		// event or ingestion time, emit the max watermark indicating&lt;br/&gt;
    +		// the end of the stream, like a normal source would do.&lt;br/&gt;
    +&lt;br/&gt;
    +		readerContext.emitWatermark(Watermark.MAX_WATERMARK);&lt;br/&gt;
    +		if (readerContext != null) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    if `readerContext` is null, we&apos;ll get a NPE in the line before.&lt;/p&gt;</comment>
                            <comment id="15426353" author="githubbot" created="Thu, 18 Aug 2016 12:28:20 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75298028&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75298028&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -146,16 +146,24 @@ void checkAsyncException() {&lt;br/&gt;
     		private final Output&amp;lt;StreamRecord&amp;lt;T&amp;gt;&amp;gt; output;&lt;br/&gt;
     		private final StreamRecord&amp;lt;T&amp;gt; reuse;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public NonTimestampContext(StreamSource&amp;lt;?, ?&amp;gt; owner, Object lockingObject, Output&amp;lt;StreamRecord&amp;lt;T&amp;gt;&amp;gt; output) {&lt;/li&gt;
	&lt;li&gt;this.owner = owner;&lt;br/&gt;
    +		public NonTimestampContext(AbstractStreamOperator&amp;lt;T&amp;gt; owner, Object lockingObject, Output&amp;lt;StreamRecord&amp;lt;T&amp;gt;&amp;gt; output) {&lt;br/&gt;
     			this.lockingObject = lockingObject;&lt;br/&gt;
     			this.output = output;&lt;br/&gt;
     			this.reuse = new StreamRecord&amp;lt;T&amp;gt;(null);&lt;br/&gt;
    +&lt;br/&gt;
    +			// if it is a source, then we cast and cache it&lt;br/&gt;
    +			// here so that we do not have to do it in every collect(),&lt;br/&gt;
    +			// collectWithTimestamp() and emitWatermark()&lt;br/&gt;
    +&lt;br/&gt;
    +			this.owner = (owner instanceof StreamSource) ?&lt;br/&gt;
    +				(StreamSource) owner : null;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This looks a bit hacky. How about you add an interface `AsyncException` or so, that all classes the `NonTimestampContext` are using can use.&lt;/p&gt;</comment>
                            <comment id="15426354" author="githubbot" created="Thu, 18 Aug 2016 12:28:38 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75298087&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75298087&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -146,16 +146,24 @@ void checkAsyncException() {&lt;br/&gt;
     		private final Output&amp;lt;StreamRecord&amp;lt;T&amp;gt;&amp;gt; output;&lt;br/&gt;
     		private final StreamRecord&amp;lt;T&amp;gt; reuse;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public NonTimestampContext(StreamSource&amp;lt;?, ?&amp;gt; owner, Object lockingObject, Output&amp;lt;StreamRecord&amp;lt;T&amp;gt;&amp;gt; output) {&lt;/li&gt;
	&lt;li&gt;this.owner = owner;&lt;br/&gt;
    +		public NonTimestampContext(AbstractStreamOperator&amp;lt;T&amp;gt; owner, Object lockingObject, Output&amp;lt;StreamRecord&amp;lt;T&amp;gt;&amp;gt; output) {&lt;br/&gt;
     			this.lockingObject = lockingObject;&lt;br/&gt;
     			this.output = output;&lt;br/&gt;
     			this.reuse = new StreamRecord&amp;lt;T&amp;gt;(null);&lt;br/&gt;
    +&lt;br/&gt;
    +			// if it is a source, then we cast and cache it&lt;br/&gt;
    +			// here so that we do not have to do it in every collect(),&lt;br/&gt;
    +			// collectWithTimestamp() and emitWatermark()&lt;br/&gt;
    +&lt;br/&gt;
    +			this.owner = (owner instanceof StreamSource) ?&lt;br/&gt;
    +				(StreamSource) owner : null;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    For the file reader, the method can just be empty&lt;/p&gt;
</comment>
                            <comment id="15426396" author="githubbot" created="Thu, 18 Aug 2016 13:05:09 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75303417&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75303417&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +109,140 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamConfig streamConfig = new StreamConfig(new Configuration());&lt;br/&gt;
    +		streamConfig.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(100);&lt;br/&gt;
    +&lt;br/&gt;
    +		TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider, streamConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		reader.setOutputType(typeInfo, new ExecutionConfig());&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You can reuse the EC created a few lines above &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15426400" author="githubbot" created="Thu, 18 Aug 2016 13:08:22 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75303846&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75303846&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +109,140 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamConfig streamConfig = new StreamConfig(new Configuration());&lt;br/&gt;
    +		streamConfig.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(100);&lt;br/&gt;
    +&lt;br/&gt;
    +		TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider, streamConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		reader.setOutputType(typeInfo, new ExecutionConfig());&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(0);&lt;br/&gt;
    +&lt;br/&gt;
    +		long elementTimestamp = 201;&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(elementTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that a watermark is actually emitted&lt;br/&gt;
    +		Assert.assertTrue(tester.getOutput().size() == 1 &amp;amp;&amp;amp;&lt;br/&gt;
    +			tester.getOutput().peek() instanceof Watermark &amp;amp;&amp;amp;&lt;br/&gt;
    +			((Watermark) tester.getOutput().peek()).getTimestamp() == 200);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You don&apos;t need to change it, but I think it&apos;s a good idea to test the conditions independently. This allows you to see which condition was false, based on the line number.&lt;/p&gt;</comment>
                            <comment id="15426402" author="githubbot" created="Thu, 18 Aug 2016 13:08:58 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75304033&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75304033&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +109,140 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamConfig streamConfig = new StreamConfig(new Configuration());&lt;br/&gt;
    +		streamConfig.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(100);&lt;br/&gt;
    +&lt;br/&gt;
    +		TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider, streamConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		reader.setOutputType(typeInfo, new ExecutionConfig());&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(0);&lt;br/&gt;
    +&lt;br/&gt;
    +		long elementTimestamp = 201;&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(elementTimestamp);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can you quickly explain how this works?&lt;br/&gt;
    Is the `OneInputStreamOperatorTestHarness` starting a thread in the background emitting watermarks?&lt;/p&gt;</comment>
                            <comment id="15426404" author="githubbot" created="Thu, 18 Aug 2016 13:10:45 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75304305&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75304305&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +109,140 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamConfig streamConfig = new StreamConfig(new Configuration());&lt;br/&gt;
    +		streamConfig.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(100);&lt;br/&gt;
    +&lt;br/&gt;
    +		TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider, streamConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		reader.setOutputType(typeInfo, new ExecutionConfig());&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(0);&lt;br/&gt;
    +&lt;br/&gt;
    +		long elementTimestamp = 201;&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(elementTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that a watermark is actually emitted&lt;br/&gt;
    +		Assert.assertTrue(tester.getOutput().size() == 1 &amp;amp;&amp;amp;&lt;br/&gt;
    +			tester.getOutput().peek() instanceof Watermark &amp;amp;&amp;amp;&lt;br/&gt;
    +			((Watermark) tester.getOutput().peek()).getTimestamp() == 200);&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		for(FileInputSplit split: splits) &lt;/p&gt;
{
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		/*&lt;br/&gt;
    +		* Given that the reader is multithreaded, the test finishes before the reader thread finishes&lt;br/&gt;
    +		* reading. This results in files being deleted by the test before being read, thus throwing an exception.&lt;br/&gt;
    +		* In addition, even if file deletion happens at the end, the results are not ready for testing.&lt;br/&gt;
    +		* To face this, we wait until all the output is collected or until the waiting time exceeds 1000 ms, or 1s.&lt;br/&gt;
    +		*/&lt;br/&gt;
    +&lt;br/&gt;
    +		long start = System.currentTimeMillis();&lt;br/&gt;
    +		Queue&amp;lt;Object&amp;gt; output;&lt;br/&gt;
    +		do &lt;/p&gt;
{
    +			output = tester.getOutput();
    +			Thread.sleep(50);
    +		}
&lt;p&gt; while ((output == null || output.size() != NO_OF_FILES * LINES_PER_FILE) &amp;amp;&amp;amp; (System.currentTimeMillis() - start) &amp;lt; 1000);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I wonder if this can lead to unstable tests (for example on Travis).&lt;br/&gt;
    What if the output needs more than one second to show up?&lt;/p&gt;</comment>
                            <comment id="15428241" author="githubbot" created="Fri, 19 Aug 2016 14:12:05 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75488070&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75488070&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperator.java &amp;#8212;&lt;br/&gt;
    @@ -103,12 +103,28 @@ public void open() throws Exception {&lt;br/&gt;
     		this.format.setRuntimeContext(getRuntimeContext());&lt;br/&gt;
     		this.format.configure(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.collector = new TimestampedCollector&amp;lt;&amp;gt;(output);&lt;br/&gt;
     		this.checkpointLock = getContainingTask().getCheckpointLock();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		Preconditions.checkState(reader == null, &quot;The reader is already initialized.&quot;);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.reader = new SplitReader&amp;lt;&amp;gt;(format, serializer, collector, checkpointLock, readerState);&lt;br/&gt;
    +		// set the reader context based on the time characteristic
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I think both the `SourceContext` plus subclasses and this instantiation code should be moved out of the sources since it is now used for more than that. &lt;/p&gt;</comment>
                            <comment id="15428249" author="githubbot" created="Fri, 19 Aug 2016 14:17:12 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I made one inline comments about moving the `SourceContext` and the instantiation code.&lt;/p&gt;

&lt;p&gt;    Also, the problem with the &quot;async exception check&quot; can be solved by introducing an interface `AsyncExceptionChecker` that is passed to the context. (I think that&apos;s what @rmetzger was hinting at.)&lt;/p&gt;

&lt;p&gt;    Even better yet, we might be able to get rid of that stuff by using `task.failExternally()` in all places that previously made these async checks necessary. (The file read operator already uses that, btw) &lt;/p&gt;</comment>
                            <comment id="15430434" author="githubbot" created="Mon, 22 Aug 2016 09:38:56 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75647030&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75647030&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperator.java &amp;#8212;&lt;br/&gt;
    @@ -63,22 +66,22 @@&lt;br/&gt;
      */&lt;br/&gt;
     @Internal&lt;br/&gt;
     public class ContinuousFileReaderOperator&amp;lt;OUT, S extends Serializable&amp;gt; extends AbstractStreamOperator&amp;lt;OUT&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;implements OneInputStreamOperator&amp;lt;FileInputSplit, OUT&amp;gt;, OutputTypeConfigurable&amp;lt;OUT&amp;gt; {&lt;br/&gt;
    +	implements OneInputStreamOperator&amp;lt;FileInputSplit, OUT&amp;gt;, OutputTypeConfigurable&amp;lt;OUT&amp;gt;, AsyncExceptionChecker {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	private static final long serialVersionUID = 1L;&lt;/p&gt;

&lt;p&gt;     	private static final Logger LOG = LoggerFactory.getLogger(ContinuousFileReaderOperator.class);&lt;/p&gt;

&lt;p&gt;    +	@VisibleForTesting&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This doesn&apos;t do anything. It&apos;s just a marker interface.&lt;/p&gt;</comment>
                            <comment id="15430486" author="githubbot" created="Mon, 22 Aug 2016 10:01:16 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    This looks very good now! &#128077; &lt;/p&gt;

&lt;p&gt;    I&apos;m running it a last time on Travis and them I&apos;m merging.&lt;/p&gt;</comment>
                            <comment id="15430499" author="githubbot" created="Mon, 22 Aug 2016 10:06:30 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75651032&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75651032&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -214,14 +216,26 @@ public AutomaticWatermarkContext(&lt;br/&gt;
     			this.watermarkInterval = watermarkInterval;&lt;br/&gt;
     			this.reuse = new StreamRecord&amp;lt;T&amp;gt;(null);&lt;/p&gt;

&lt;p&gt;    +			// if it is a source, then we cast and cache it&lt;br/&gt;
    +			// here so that we do not have to do it in every collect(),&lt;br/&gt;
    +			// collectWithTimestamp() and emitWatermark()&lt;br/&gt;
    +&lt;br/&gt;
    +			if (!(owner instanceof AsyncExceptionChecker)) &lt;/p&gt;
{
    +				throw new IllegalStateException(&quot;The ManualWatermarkContext can only be used &quot; +
    +					&quot;with sources that implement the AsyncExceptionThrower interface.&quot;);
    +			}
&lt;p&gt;    +			this.source = (AsyncExceptionChecker) owner;&lt;br/&gt;
    +&lt;br/&gt;
     			long now = owner.getCurrentProcessingTime();&lt;br/&gt;
     			this.watermarkTimer = owner.registerTimer(now + watermarkInterval,&lt;br/&gt;
     				new WatermarkEmittingTask(owner, lockingObjectParam, outputParam));&lt;br/&gt;
     		}&lt;/p&gt;

&lt;p&gt;     		@Override&lt;br/&gt;
     		public void collect(T element) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;owner.checkAsyncException();&lt;br/&gt;
    +			if (source != null) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I don&apos;t think these null checks are needed, because the `IllegalStateException` is thrown if `owner` is `null`.&lt;/p&gt;</comment>
                            <comment id="15430512" author="githubbot" created="Mon, 22 Aug 2016 10:20:01 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350#discussion_r75652728&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350#discussion_r75652728&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -188,18 +189,19 @@ public void close() {}&lt;br/&gt;
     	 */&lt;br/&gt;
     	public static class AutomaticWatermarkContext&amp;lt;T&amp;gt; implements SourceFunction.SourceContext&amp;lt;T&amp;gt; {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final StreamSource&amp;lt;?, ?&amp;gt; owner;&lt;br/&gt;
    +		private final AbstractStreamOperator&amp;lt;T&amp;gt; owner;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This should also be an AsyncExceptionChecker, same for the parameter. For the time handling, this can get a `TimeServiceProvider`, that way, things are cleanly separated. &lt;/p&gt;</comment>
                            <comment id="15430514" author="githubbot" created="Mon, 22 Aug 2016 10:20:28 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Ah, seems I was a  bit to quick earlier. I added one more inline comment.&lt;/p&gt;</comment>
                            <comment id="15440870" author="githubbot" created="Sat, 27 Aug 2016 06:52:36 +0000"  >&lt;p&gt;Github user kl0u closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2350&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15520984" author="githubbot" created="Sun, 25 Sep 2016 15:30:11 +0000"  >&lt;p&gt;GitHub user kl0u opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4329&quot; title=&quot;Fix Streaming File Source Timestamps/Watermarks Handling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4329&quot;&gt;&lt;del&gt;FLINK-4329&lt;/del&gt;&lt;/a&gt; Fix Streaming File Source Timestamps/Watermarks Handling&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/kl0u/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/kl0u/flink&lt;/a&gt; fix_ingestion_time&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2546&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 1b15b77b80334adf869714937dbfa8d8b7c2e12f&lt;br/&gt;
Author: kl0u &amp;lt;kkloudas@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-08-25T15:38:49Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4329&quot; title=&quot;Fix Streaming File Source Timestamps/Watermarks Handling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4329&quot;&gt;&lt;del&gt;FLINK-4329&lt;/del&gt;&lt;/a&gt; Fix Streaming File Source Timestamps/Watermarks Handling&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15529534" author="githubbot" created="Wed, 28 Sep 2016 13:05:37 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80901242&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80901242&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/AccumulatingAlignedProcessingTimeWindowOperatorTest.java &amp;#8212;&lt;br/&gt;
    @@ -201,6 +201,11 @@ public void testWindowTriggerTimeAlignment() throws Exception {&lt;br/&gt;
     			assertTrue(op.getNextEvaluationTime() % 1000 == 0);&lt;br/&gt;
     			op.dispose();&lt;/p&gt;

&lt;p&gt;    +			timerService.shutdownService();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Same here&lt;/p&gt;</comment>
                            <comment id="15529537" author="githubbot" created="Wed, 28 Sep 2016 13:05:37 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80901203&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80901203&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/AggregatingAlignedProcessingTimeWindowOperatorTest.java &amp;#8212;&lt;br/&gt;
    @@ -209,6 +209,11 @@ public void testWindowTriggerTimeAlignment() throws Exception {&lt;br/&gt;
     			assertTrue(op.getNextEvaluationTime() % 1000 == 0);&lt;br/&gt;
     			op.dispose();&lt;/p&gt;

&lt;p&gt;    +			timerService.shutdownService();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why does this need to create and shut down a timer service every time?&lt;/p&gt;</comment>
                            <comment id="15529536" author="githubbot" created="Wed, 28 Sep 2016 13:05:37 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80901399&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80901399&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/DefaultTimeServiceProvider.java &amp;#8212;&lt;br/&gt;
    @@ -109,9 +110,15 @@ public void run() {&lt;br/&gt;
     	public static DefaultTimeServiceProvider createForTesting(ScheduledExecutorService executor, Object checkpointLock) {&lt;br/&gt;
     		return new DefaultTimeServiceProvider(new AsyncExceptionHandler() {&lt;br/&gt;
     			@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void registerAsyncException(AsynchronousException exception) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			public void handleAsyncException(String message, Throwable exception) {
     				exception.printStackTrace();
     			}     		}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;, executor, checkpointLock);&lt;br/&gt;
     	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@VisibleForTesting&lt;br/&gt;
    +	public static DefaultTimeServiceProvider createForTestingWithHandler(&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Is this the exact same code as the default constructor? Can it be removed?&lt;/p&gt;</comment>
                            <comment id="15529539" author="githubbot" created="Wed, 28 Sep 2016 13:05:37 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80902027&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80902027&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/AsyncExceptionHandler.java &amp;#8212;&lt;br/&gt;
    @@ -18,12 +18,14 @@&lt;br/&gt;
     package org.apache.flink.streaming.runtime.tasks;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Interface for reporting exceptions that are thrown in (possibly) a different thread.&lt;br/&gt;
    + * An interface marking a task as capable of handling exceptions thrown&lt;br/&gt;
    + * by different threads, other than the one executing the task itself.&lt;br/&gt;
      */&lt;br/&gt;
     public interface AsyncExceptionHandler {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Registers the given exception.&lt;br/&gt;
    +	 * Handles an exception thrown by another thread (e.g. a TriggerTask),&lt;br/&gt;
    +	 * other than the one executing the main task.&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;void registerAsyncException(AsynchronousException exception);&lt;br/&gt;
    +	void handleAsyncException(String message, Throwable exception);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This name change is good!&lt;/p&gt;</comment>
                            <comment id="15529535" author="githubbot" created="Wed, 28 Sep 2016 13:05:37 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80904818&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80904818&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -224,7 +327,7 @@ public void testFilePathFiltering() throws Exception {&lt;br/&gt;
     		monitoringFunction.open(new Configuration());&lt;br/&gt;
     		monitoringFunction.run(new TestingSourceContext(monitoringFunction, uniqFilesFound));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Assert.assertTrue(uniqFilesFound.size() == NO_OF_FILES);&lt;br/&gt;
    +		Assert.assertEquals(uniqFilesFound.size(), NO_OF_FILES);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    `assertEquals()` takes &quot;expected&quot; first and &quot;actual&quot; second.&lt;/p&gt;</comment>
                            <comment id="15529538" author="githubbot" created="Wed, 28 Sep 2016 13:05:37 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80901983&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80901983&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/DefaultTimeServiceProvider.java &amp;#8212;&lt;br/&gt;
    @@ -99,7 +100,7 @@ public void run() &lt;/p&gt;
{
     					target.trigger(timestamp);
     				}
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
     					TimerException asyncException = new TimerException(t);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Do we need this extra level of exception wrapping?&lt;/p&gt;</comment>
                            <comment id="15529543" author="githubbot" created="Wed, 28 Sep 2016 13:06:22 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    All in all some minor change requests, otherwise this seems good.&lt;/p&gt;</comment>
                            <comment id="15529556" author="githubbot" created="Wed, 28 Sep 2016 13:13:04 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Actually, let me take a step back and understand a few things deeper, first.&lt;br/&gt;
    Who actually generates the watermarks (in ingestion time)? The operator that creates the file splits, or the operator that reads the splits?&lt;/p&gt;

&lt;p&gt;    If the configuration is set to IngestionTime, will the operator that creates the file splits emit a final LongMax watermark? Is that one passing through by the split-reading operator? Is there a test that test that specific scenario? (I believe it was the initially reported bug).&lt;/p&gt;</comment>
                            <comment id="15529592" author="githubbot" created="Wed, 28 Sep 2016 13:26:31 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hi @StephanEwen , thanks for the review!&lt;/p&gt;

&lt;p&gt;    The watermarks/timestamps are now generated by the Reader, and not the operator that creates the splits. The same holds for the LongMax watermark, which is created at the close() of the ContinuousFileReaderOperator. &lt;/p&gt;

&lt;p&gt;    As for tests, it is the testFileReadingOperatorWithIngestionTime() in the ContinuousFileMonitoringTest which checks if the last Watermark is the LongMax.&lt;/p&gt;

&lt;p&gt;    The original problem was that there were no timestamps assigned to the elements for Ingestion time and watermarks were emitted (I think it was a Process_once case).&lt;/p&gt;

</comment>
                            <comment id="15529627" author="githubbot" created="Wed, 28 Sep 2016 13:33:16 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80915830&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80915830&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,117 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(100);&lt;br/&gt;
    +&lt;br/&gt;
    +		TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig,&lt;br/&gt;
    +				timeServiceProvider, TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(w.getTimestamp(), 200 + (i * 100));&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(tester.getOutput().size(), 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    What will the `getNumberOfParallelSubtasks()` be here? The test does not control the number of splits, but leave this to the implicit behavior of the test harness?&lt;/p&gt;</comment>
                            <comment id="15529632" author="githubbot" created="Wed, 28 Sep 2016 13:34:57 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r80916240&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r80916240&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,117 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(100);&lt;br/&gt;
    +&lt;br/&gt;
    +		TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig,&lt;br/&gt;
    +				timeServiceProvider, TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(w.getTimestamp(), 200 + (i * 100));&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(tester.getOutput().size(), 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		for(FileInputSplit split: splits) &lt;/p&gt;
{
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		// then close the reader gracefully so that&lt;br/&gt;
    +		// we wait until all input is read&lt;br/&gt;
    +		synchronized (tester.getCheckpointLock()) &lt;/p&gt;
{
    +			tester.close();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for(org.apache.hadoop.fs.Path file: filesCreated) &lt;/p&gt;
{
    +			hdfs.delete(file, false);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		// the lines received must be the elements in the files +1 for the Long.MAX_VALUE watermark&lt;br/&gt;
    +		Assert.assertEquals(tester.getOutput().size(), NO_OF_FILES * LINES_PER_FILE + 1);&lt;br/&gt;
    +&lt;br/&gt;
    +		// put the elements read in a map by file they belong to&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (line instanceof StreamRecord) {&lt;br/&gt;
    +				StreamRecord&amp;lt;String&amp;gt; element = (StreamRecord&amp;lt;String&amp;gt;) line;&lt;br/&gt;
    +				Assert.assertEquals(element.getTimestamp(), 501);&lt;br/&gt;
    +&lt;br/&gt;
    +				int fileIdx = Character.getNumericValue(element.getValue().charAt(0));&lt;br/&gt;
    +				List&amp;lt;String&amp;gt; content = actualFileContents.get(fileIdx);&lt;br/&gt;
    +				if (content == null) &lt;/p&gt;
{
    +					content = new ArrayList&amp;lt;&amp;gt;();
    +					actualFileContents.put(fileIdx, content);
    +				}
&lt;p&gt;    +				content.add(element.getValue() + &quot;\n&quot;);&lt;br/&gt;
    +			} else if (line instanceof Watermark) {&lt;br/&gt;
    +				Assert.assertEquals(((Watermark) line).getTimestamp(), Long.MAX_VALUE);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Does the test assume that all watermarks emitted by the reader are LongMax? I am confused here, isn&apos;t that exactly what should NOT happen? Otherwise all emitted elements are late?&lt;/p&gt;</comment>
                            <comment id="15529640" author="githubbot" created="Wed, 28 Sep 2016 13:36:51 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I added some more comments. I could not find in that test anywhere the notion of checking that elements are not late, but properly interleaved with the watermarks.&lt;/p&gt;

&lt;p&gt;    Is there a test that checks that the reader does not let LongMax watermarks pass through? Or that the split generating task does not emit a long-max watermark on exit?&lt;/p&gt;</comment>
                            <comment id="15529764" author="githubbot" created="Wed, 28 Sep 2016 14:16:52 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Just a quick comment (I didn&apos;t review all code): Why does this touch the AlignedWindowOperator tests? I would like to keep this commit as small as possible because we&apos;re dealing with sensitive stuff where I&apos;d like to clearly separate things.&lt;/p&gt;

&lt;p&gt;    In `OneInputStreamOperatorTestHarness` and `KeyedOneInputStreamOperatorTestHarness`, restricting the time provider parameter to a `TestTimeServiceProvider` does not change anything, right? So I think we can leave it as is. Also in `OneInputStreamOperatorTestHarness` the additional `TimeCharacteristic` parameter is only useful for one specific test so I think it would be better to instead expose the `StreamConfig` and set the parameter there for the one test to keep the number of constructors manageable. &lt;/p&gt;
</comment>
                            <comment id="15529786" author="githubbot" created="Wed, 28 Sep 2016 14:22:36 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hi @aljoscha, the problem with the AlignedWindowOperator  tests is that they were using the DefaultTimeServiceProvider and by not shutting down the service, the previous timers would fire and throw a NPE because the reference to the operator they had would have been invalidated.&lt;/p&gt;

&lt;p&gt;    For the restriction to TestTimeServiceProvider, this was done because now the DefaultTimeServiceProvider needs the checkpointLock, so either in the same constructor we add this as an argument, or we have to restrict the options to only the TestProvider.&lt;/p&gt;

&lt;p&gt;    Finally for the StreamConfig I agree that it is only needed for one test so we can just expose it. &lt;/p&gt;</comment>
                            <comment id="15532167" author="githubbot" created="Thu, 29 Sep 2016 08:34:49 +0000"  >&lt;p&gt;Github user kl0u commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r81088167&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r81088167&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/DefaultTimeServiceProvider.java &amp;#8212;&lt;br/&gt;
    @@ -99,7 +100,7 @@ public void run() &lt;/p&gt;
{
     					target.trigger(timestamp);
     				}
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
     					TimerException asyncException = new TimerException(t);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    No. This is just because this is how it was before. I will remove it.&lt;/p&gt;</comment>
                            <comment id="15532181" author="githubbot" created="Thu, 29 Sep 2016 08:39:56 +0000"  >&lt;p&gt;Github user kl0u commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r81089031&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r81089031&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/DefaultTimeServiceProvider.java &amp;#8212;&lt;br/&gt;
    @@ -99,7 +100,7 @@ public void run() &lt;/p&gt;
{
     					target.trigger(timestamp);
     				}
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
     					TimerException asyncException = new TimerException(t);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Although, now that I think about it, it is good to know that it came from a timer callback. What do you think?&lt;/p&gt;</comment>
                            <comment id="15532622" author="githubbot" created="Thu, 29 Sep 2016 12:17:16 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the comments @StephanEwen and @aljoscha ! &lt;br/&gt;
    I integrated most of them. &lt;br/&gt;
    Please have a look.&lt;/p&gt;</comment>
                            <comment id="15533662" author="githubbot" created="Thu, 29 Sep 2016 18:45:05 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r81204990&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r81204990&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -190,12 +213,30 @@ public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
     				}&lt;br/&gt;
     				content.add(element.getValue() + &quot;\n&quot;);&lt;br/&gt;
     			} else if (line instanceof Watermark) &lt;/p&gt;
{
    -				Assert.assertEquals(((Watermark) line).getTimestamp(), Long.MAX_VALUE);
    +				watermarkTimestamps.add(((Watermark) line).getTimestamp());
     			}
&lt;p&gt; else &lt;/p&gt;
{
     				Assert.fail(&quot;Unknown element in the list.&quot;);
     			}
&lt;p&gt;     		}&lt;/p&gt;

&lt;p&gt;    +		// check if all the input was read&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES * LINES_PER_FILE, noOfLines);&lt;br/&gt;
    +&lt;br/&gt;
    +		// check if the last element is the LongMax watermark&lt;br/&gt;
    +		Assert.assertTrue(lastElement instanceof Watermark);&lt;br/&gt;
    +		Assert.assertEquals(Long.MAX_VALUE, ((Watermark) lastElement).getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +		System.out.println(watermarkTimestamps.size());&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Leftover sysout printing.&lt;/p&gt;</comment>
                            <comment id="15533663" author="githubbot" created="Thu, 29 Sep 2016 18:45:05 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r81204828&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r81204828&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -440,10 +491,50 @@ public void testFileSplitMonitoringProcessOnce() throws Exception {&lt;/p&gt;

&lt;p&gt;     	private int getLineNo(String line) &lt;/p&gt;
{
     		String[] tkns = line.split(&quot;\\s&quot;);
    -		Assert.assertEquals(tkns.length, 6);
    +		Assert.assertEquals(6, tkns.length);
     		return Integer.parseInt(tkns[tkns.length - 1]);
     	}

&lt;p&gt;    +	private class TimeUpdatingThread extends Thread {&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final TestTimeServiceProvider timeServiceProvider;&lt;br/&gt;
    +		private final OneInputStreamOperatorTestHarness testHarness;&lt;br/&gt;
    +		private final long wmInterval;&lt;br/&gt;
    +		private final int elementUntilUpdating;&lt;br/&gt;
    +&lt;br/&gt;
    +		TimeUpdatingThread(final TestTimeServiceProvider timeServiceProvider,&lt;br/&gt;
    +						   final OneInputStreamOperatorTestHarness testHarness,&lt;br/&gt;
    +						   final long wmInterval,&lt;br/&gt;
    +						   final int elementUntilUpdating) &lt;/p&gt;
{
    +
    +			this.timeServiceProvider = timeServiceProvider;
    +			this.testHarness = testHarness;
    +			this.wmInterval = wmInterval;
    +			this.elementUntilUpdating = elementUntilUpdating;
    +			this.isRunning = true;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run() {&lt;br/&gt;
    +			try {&lt;br/&gt;
    +				while (isRunning) {&lt;br/&gt;
    +					if (testHarness.getOutput().size() % elementUntilUpdating == 0) &lt;/p&gt;
{
    +						long now = timeServiceProvider.getCurrentProcessingTime();
    +						timeServiceProvider.setCurrentTime(now + wmInterval);
    +					}
&lt;p&gt;    +				}&lt;br/&gt;
    +			} catch (Exception e) {&lt;br/&gt;
    +				e.printStackTrace();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This will not result in any meaningful feedback to the test.&lt;/p&gt;</comment>
                            <comment id="15533664" author="githubbot" created="Thu, 29 Sep 2016 18:45:05 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546#discussion_r81204726&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546#discussion_r81204726&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -440,10 +491,50 @@ public void testFileSplitMonitoringProcessOnce() throws Exception {&lt;/p&gt;

&lt;p&gt;     	private int getLineNo(String line) &lt;/p&gt;
{
     		String[] tkns = line.split(&quot;\\s&quot;);
    -		Assert.assertEquals(tkns.length, 6);
    +		Assert.assertEquals(6, tkns.length);
     		return Integer.parseInt(tkns[tkns.length - 1]);
     	}

&lt;p&gt;    +	private class TimeUpdatingThread extends Thread {&lt;br/&gt;
    +&lt;br/&gt;
    +		private volatile boolean isRunning;&lt;br/&gt;
    +&lt;br/&gt;
    +		private final TestTimeServiceProvider timeServiceProvider;&lt;br/&gt;
    +		private final OneInputStreamOperatorTestHarness testHarness;&lt;br/&gt;
    +		private final long wmInterval;&lt;br/&gt;
    +		private final int elementUntilUpdating;&lt;br/&gt;
    +&lt;br/&gt;
    +		TimeUpdatingThread(final TestTimeServiceProvider timeServiceProvider,&lt;br/&gt;
    +						   final OneInputStreamOperatorTestHarness testHarness,&lt;br/&gt;
    +						   final long wmInterval,&lt;br/&gt;
    +						   final int elementUntilUpdating) &lt;/p&gt;
{
    +
    +			this.timeServiceProvider = timeServiceProvider;
    +			this.testHarness = testHarness;
    +			this.wmInterval = wmInterval;
    +			this.elementUntilUpdating = elementUntilUpdating;
    +			this.isRunning = true;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run() {&lt;br/&gt;
    +			try {&lt;br/&gt;
    +				while (isRunning) {&lt;br/&gt;
    +					if (testHarness.getOutput().size() % elementUntilUpdating == 0) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    There is a &quot;race&quot; between the operator emitting elements and this thread. Both run in loops without delays. Only if this condition is evaluated by chance at the exact point in time when the list happens to have so many result elements, there will actually be a time advance.&lt;/p&gt;</comment>
                            <comment id="15534216" author="githubbot" created="Thu, 29 Sep 2016 22:09:27 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hi @StephanEwen . If I understand correctly, your suggestion is to make the test something like the following: 1) put the split in the reader 2) read the split 3) when the split finishes update the time in the provider 4) observe the time in the output elements. If this is the case, then the problem is that the reader just puts the split in a queue, and this is picked up by another thread that reads it. In this context, there is no way of knowing when the reading thread has finished reading the split and goes to the next one. So step 3) cannot be synchronized correctly. This is the reason I am just having a thread in the test that tries (without guarantees - the race condition you mentioned) to update the time while the reader is still reading. Any suggestions are welcome.&lt;/p&gt;</comment>
                            <comment id="15548044" author="githubbot" created="Wed, 5 Oct 2016 08:21:26 +0000"  >&lt;p&gt;GitHub user kl0u opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4329&quot; title=&quot;Fix Streaming File Source Timestamps/Watermarks Handling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4329&quot;&gt;&lt;del&gt;FLINK-4329&lt;/del&gt;&lt;/a&gt; Fix Streaming File Source Timestamps/Watermarks Handling&lt;/p&gt;

&lt;p&gt;    This is a quick fix for the &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4329&quot; title=&quot;Fix Streaming File Source Timestamps/Watermarks Handling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4329&quot;&gt;&lt;del&gt;FLINK-4329&lt;/del&gt;&lt;/a&gt; issue. The fix on the master is different but it contains more changes that are not easy to back-port to 1.1.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/kl0u/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/kl0u/flink&lt;/a&gt; injestion_fix_1.1&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2593&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 79d48e77b4a9c8a8eaf4e1e3199e2787deebab63&lt;br/&gt;
Author: kl0u &amp;lt;kkloudas@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-10-04T13:27:59Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4329&quot; title=&quot;Fix Streaming File Source Timestamps/Watermarks Handling&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4329&quot;&gt;&lt;del&gt;FLINK-4329&lt;/del&gt;&lt;/a&gt; Fix Streaming File Source Timestamps/Watermarks Handling&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15548380" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81944208&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81944208&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) &lt;/p&gt;
{
    +					tester.getCheckpointLock().wait(10);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// verify that the results are the expected&lt;br/&gt;
    +			for(Object line: tester.getOutput()) {&lt;br/&gt;
    +				if (line instanceof StreamRecord) {&lt;br/&gt;
    +					StreamRecord&amp;lt;String&amp;gt; element = (StreamRecord&amp;lt;String&amp;gt;) line;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You could add a `@SupressWarnings(&quot;unchecked&quot;);` here.&lt;/p&gt;</comment>
                            <comment id="15548384" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81944676&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81944676&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) &lt;/p&gt;
{
    +					tester.getCheckpointLock().wait(10);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// verify that the results are the expected&lt;br/&gt;
    +			for(Object line: tester.getOutput()) {&lt;br/&gt;
    +				if (line instanceof StreamRecord) {&lt;br/&gt;
    +					StreamRecord&amp;lt;String&amp;gt; element = (StreamRecord&amp;lt;String&amp;gt;) line;&lt;br/&gt;
    +					lineCounter++;&lt;br/&gt;
    +&lt;br/&gt;
    +					Assert.assertEquals(nextTimestamp, element.getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +					int fileIdx = Character.getNumericValue(element.getValue().charAt(0));&lt;br/&gt;
    +					List&amp;lt;String&amp;gt; content = actualFileContents.get(fileIdx);&lt;br/&gt;
    +					if (content == null) &lt;/p&gt;
{
    +						content = new ArrayList&amp;lt;&amp;gt;();
    +						actualFileContents.put(fileIdx, content);
    +					}
&lt;p&gt;    +					content.add(element.getValue() + &quot;\n&quot;);&lt;br/&gt;
    +				} else if (line instanceof Watermark) &lt;/p&gt;
{
    +					long watermark = ((Watermark) line).getTimestamp();
    +
    +					Assert.assertEquals(nextTimestamp - (nextTimestamp % watermarkInterval), watermark);
    +					Assert.assertTrue(watermark &amp;gt; lastSeenWatermark);
    +					watermarkCounter++;
    +
    +					lastSeenWatermark = watermark;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					Assert.fail(&quot;Unknown element in the list.&quot;);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// clean the output to be ready for the next split&lt;br/&gt;
    +			tester.getOutput().clear();&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now we are processing one split after the other,&lt;br/&gt;
    +		// so all the elements must be here by now.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES * LINES_PER_FILE, lineCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// because we expect one watermark per split.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES, watermarkCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// then close the reader gracefully so that the Long.MAX watermark is emitted&lt;br/&gt;
    +		synchronized (tester.getCheckpointLock()) &lt;/p&gt;
{
    +			tester.close();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for(org.apache.hadoop.fs.Path file: filesCreated) &lt;/p&gt;
{
    +			hdfs.delete(file, false);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		// check if the last element is the LongMax watermark (by now this must be the only element)&lt;br/&gt;
    +		Assert.assertEquals(1, tester.getOutput().size());&lt;br/&gt;
    +		Assert.assertTrue(tester.getOutput().peek() instanceof Watermark);&lt;br/&gt;
    +		Assert.assertEquals(Long.MAX_VALUE, ((Watermark) tester.getOutput().poll()).getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +		// check if the elements are the expected ones.&lt;br/&gt;
    +		Assert.assertEquals(expectedFileContents.size(), actualFileContents.size());&lt;br/&gt;
    +		for (Integer fileIdx: expectedFileContents.keySet()) {&lt;br/&gt;
    +			Assert.assertTrue(&quot;file&quot; + fileIdx + &quot; not found&quot;, actualFileContents.keySet().contains(fileIdx));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You wouldn&apos;t have to use file indexes if you immediately checked the split output.&lt;/p&gt;</comment>
                            <comment id="15548383" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81947121&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81947121&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -299,7 +319,7 @@ public void trigger(long timestamp) {&lt;br/&gt;
     					synchronized (lockingObject) {&lt;br/&gt;
     						if (currentTime &amp;gt; nextWatermarkTime) {&lt;br/&gt;
     							output.emitWatermark(new Watermark(watermarkTime));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;nextWatermarkTime += watermarkInterval;&lt;br/&gt;
    +							nextWatermarkTime = watermarkTime + watermarkInterval;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Is this a fix? Does it change the semantics?&lt;/p&gt;</comment>
                            <comment id="15548381" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81944020&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81944020&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) {&lt;br/&gt;
    +					tester.getCheckpointLock().wait(10);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Seems like you don&apos;t need to synchronize on the checkpoint lock here and you simply want to `Thread.sleep(10)` to give the SplitReader thread more time to read. Perhaps add a comment to explain the +1.&lt;/p&gt;

&lt;p&gt;    ```java&lt;br/&gt;
    while (tester.getOutput().size() &amp;lt; (LINES_PER_FILE + 1)) &lt;/p&gt;
{
        // wait for all lines of this split to be read and the watermark to be emitted
        Thread.sleep(10);
    }
&lt;p&gt;    ```&lt;br/&gt;
    should be enough.&lt;/p&gt;</comment>
                            <comment id="15548382" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81944268&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81944268&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) &lt;/p&gt;
{
    +					tester.getCheckpointLock().wait(10);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// verify that the results are the expected&lt;br/&gt;
    +			for(Object line: tester.getOutput()) {&lt;br/&gt;
    +				if (line instanceof StreamRecord) {&lt;br/&gt;
    +					StreamRecord&amp;lt;String&amp;gt; element = (StreamRecord&amp;lt;String&amp;gt;) line;&lt;br/&gt;
    +					lineCounter++;&lt;br/&gt;
    +&lt;br/&gt;
    +					Assert.assertEquals(nextTimestamp, element.getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +					int fileIdx = Character.getNumericValue(element.getValue().charAt(0));&lt;br/&gt;
    +					List&amp;lt;String&amp;gt; content = actualFileContents.get(fileIdx);&lt;br/&gt;
    +					if (content == null) &lt;/p&gt;
{
    +						content = new ArrayList&amp;lt;&amp;gt;();
    +						actualFileContents.put(fileIdx, content);
    +					}
&lt;p&gt;    +					content.add(element.getValue() + &quot;\n&quot;);&lt;br/&gt;
    +				} else if (line instanceof Watermark) &lt;/p&gt;
{
    +					long watermark = ((Watermark) line).getTimestamp();
    +
    +					Assert.assertEquals(nextTimestamp - (nextTimestamp % watermarkInterval), watermark);
    +					Assert.assertTrue(watermark &amp;gt; lastSeenWatermark);
    +					watermarkCounter++;
    +
    +					lastSeenWatermark = watermark;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					Assert.fail(&quot;Unknown element in the list.&quot;);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// clean the output to be ready for the next split&lt;br/&gt;
    +			tester.getOutput().clear();&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now we are processing one split after the other,&lt;br/&gt;
    +		// so all the elements must be here by now.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES * LINES_PER_FILE, lineCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// because we expect one watermark per split.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES, watermarkCounter);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This should be `Assert.assertEquals(splits.length, watermarkCounter);`.&lt;/p&gt;</comment>
                            <comment id="15548385" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81944308&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81944308&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) &lt;/p&gt;
{
    +					tester.getCheckpointLock().wait(10);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// verify that the results are the expected&lt;br/&gt;
    +			for(Object line: tester.getOutput()) {&lt;br/&gt;
    +				if (line instanceof StreamRecord) {&lt;br/&gt;
    +					StreamRecord&amp;lt;String&amp;gt; element = (StreamRecord&amp;lt;String&amp;gt;) line;&lt;br/&gt;
    +					lineCounter++;&lt;br/&gt;
    +&lt;br/&gt;
    +					Assert.assertEquals(nextTimestamp, element.getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +					int fileIdx = Character.getNumericValue(element.getValue().charAt(0));&lt;br/&gt;
    +					List&amp;lt;String&amp;gt; content = actualFileContents.get(fileIdx);&lt;br/&gt;
    +					if (content == null) &lt;/p&gt;
{
    +						content = new ArrayList&amp;lt;&amp;gt;();
    +						actualFileContents.put(fileIdx, content);
    +					}
&lt;p&gt;    +					content.add(element.getValue() + &quot;\n&quot;);&lt;br/&gt;
    +				} else if (line instanceof Watermark) &lt;/p&gt;
{
    +					long watermark = ((Watermark) line).getTimestamp();
    +
    +					Assert.assertEquals(nextTimestamp - (nextTimestamp % watermarkInterval), watermark);
    +					Assert.assertTrue(watermark &amp;gt; lastSeenWatermark);
    +					watermarkCounter++;
    +
    +					lastSeenWatermark = watermark;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					Assert.fail(&quot;Unknown element in the list.&quot;);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// clean the output to be ready for the next split&lt;br/&gt;
    +			tester.getOutput().clear();&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now we are processing one split after the other,&lt;br/&gt;
    +		// so all the elements must be here by now.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES * LINES_PER_FILE, lineCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// because we expect one watermark per split.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES, watermarkCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// then close the reader gracefully so that the Long.MAX watermark is emitted&lt;br/&gt;
    +		synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +			tester.close();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I don&apos;t think you need to lock on the checkpoint lock here.&lt;/p&gt;</comment>
                            <comment id="15548386" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81946646&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81946646&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) {&lt;br/&gt;
    +					tester.getCheckpointLock().wait(10);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Actually, sleeping wouldn&apos;t be necessary if you disabled the threaded split processing of the `SplitReader` for this test. You could have a synchronous reader for the test (would require a small change of the operator/reader to enable that).&lt;/p&gt;</comment>
                            <comment id="15548387" author="githubbot" created="Wed, 5 Oct 2016 10:58:10 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81944479&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81944479&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) &lt;/p&gt;
{
    +					tester.getCheckpointLock().wait(10);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// verify that the results are the expected&lt;br/&gt;
    +			for(Object line: tester.getOutput()) {&lt;br/&gt;
    +				if (line instanceof StreamRecord) {&lt;br/&gt;
    +					StreamRecord&amp;lt;String&amp;gt; element = (StreamRecord&amp;lt;String&amp;gt;) line;&lt;br/&gt;
    +					lineCounter++;&lt;br/&gt;
    +&lt;br/&gt;
    +					Assert.assertEquals(nextTimestamp, element.getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +					int fileIdx = Character.getNumericValue(element.getValue().charAt(0));&lt;br/&gt;
    +					List&amp;lt;String&amp;gt; content = actualFileContents.get(fileIdx);&lt;br/&gt;
    +					if (content == null) &lt;/p&gt;
{
    +						content = new ArrayList&amp;lt;&amp;gt;();
    +						actualFileContents.put(fileIdx, content);
    +					}
&lt;p&gt;    +					content.add(element.getValue() + &quot;\n&quot;);&lt;br/&gt;
    +				} else if (line instanceof Watermark) &lt;/p&gt;
{
    +					long watermark = ((Watermark) line).getTimestamp();
    +
    +					Assert.assertEquals(nextTimestamp - (nextTimestamp % watermarkInterval), watermark);
    +					Assert.assertTrue(watermark &amp;gt; lastSeenWatermark);
    +					watermarkCounter++;
    +
    +					lastSeenWatermark = watermark;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					Assert.fail(&quot;Unknown element in the list.&quot;);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// clean the output to be ready for the next split&lt;br/&gt;
    +			tester.getOutput().clear();&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now we are processing one split after the other,&lt;br/&gt;
    +		// so all the elements must be here by now.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES * LINES_PER_FILE, lineCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// because we expect one watermark per split.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES, watermarkCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// then close the reader gracefully so that the Long.MAX watermark is emitted&lt;br/&gt;
    +		synchronized (tester.getCheckpointLock()) &lt;/p&gt;
{
    +			tester.close();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for(org.apache.hadoop.fs.Path file: filesCreated) &lt;/p&gt;
{
    +			hdfs.delete(file, false);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		// check if the last element is the LongMax watermark (by now this must be the only element)&lt;br/&gt;
    +		Assert.assertEquals(1, tester.getOutput().size());&lt;br/&gt;
    +		Assert.assertTrue(tester.getOutput().peek() instanceof Watermark);&lt;br/&gt;
    +		Assert.assertEquals(Long.MAX_VALUE, ((Watermark) tester.getOutput().poll()).getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +		// check if the elements are the expected ones.&lt;br/&gt;
    +		Assert.assertEquals(expectedFileContents.size(), actualFileContents.size());&lt;br/&gt;
    +		for (Integer fileIdx: expectedFileContents.keySet()) {&lt;br/&gt;
    +			Assert.assertTrue(&quot;file&quot; + fileIdx + &quot; not found&quot;, actualFileContents.keySet().contains(fileIdx));&lt;br/&gt;
    +&lt;br/&gt;
    +			List&amp;lt;String&amp;gt; cntnt = actualFileContents.get(fileIdx);&lt;br/&gt;
    +			Collections.sort(cntnt, new Comparator&amp;lt;String&amp;gt;() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Sorting here wouldn&apos;t be necessary if you immediately compared the output of the split after reading it.&lt;/p&gt;</comment>
                            <comment id="15548388" author="githubbot" created="Wed, 5 Oct 2016 10:58:11 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81945670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81945670&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think this can be more easily readable if you break it up into:&lt;/p&gt;

&lt;p&gt;    ```java&lt;br/&gt;
    timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    Assert.assertEquals(200, ((Watermark) tester.getOutput().poll()).getTimestamp());&lt;br/&gt;
    // ....&lt;br/&gt;
    ```&lt;/p&gt;</comment>
                            <comment id="15548389" author="githubbot" created="Wed, 5 Oct 2016 10:58:11 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81944138&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81944138&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) &lt;/p&gt;
{
    +					tester.getCheckpointLock().wait(10);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// verify that the results are the expected&lt;br/&gt;
    +			for(Object line: tester.getOutput()) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Generally, I find&lt;/p&gt;

&lt;p&gt;    ```java&lt;br/&gt;
    for (Object line : tester.getOutput()) {&lt;br/&gt;
    ```&lt;/p&gt;

&lt;p&gt;    more readable.&lt;/p&gt;</comment>
                            <comment id="15548392" author="githubbot" created="Wed, 5 Oct 2016 10:58:45 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81947893&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81947893&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-fs-tests/src/test/java/org/apache/flink/hdfstests/ContinuousFileMonitoringTest.java &amp;#8212;&lt;br/&gt;
    @@ -106,6 +107,155 @@ public static void destroyHDFS() {&lt;br/&gt;
     	//						TESTS&lt;/p&gt;

&lt;p&gt;     	@Test&lt;br/&gt;
    +	public void testFileReadingOperatorWithIngestionTime() throws Exception {&lt;br/&gt;
    +		Set&amp;lt;org.apache.hadoop.fs.Path&amp;gt; filesCreated = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
    +		Map&amp;lt;Integer, String&amp;gt; expectedFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; NO_OF_FILES; i++) &lt;/p&gt;
{
    +			Tuple2&amp;lt;org.apache.hadoop.fs.Path, String&amp;gt; file = fillWithData(hdfsURI, &quot;file&quot;, i, &quot;This is test line.&quot;);
    +			filesCreated.add(file.f0);
    +			expectedFileContents.put(i, file.f1);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		TextInputFormat format = new TextInputFormat(new Path(hdfsURI));&lt;br/&gt;
    +		TypeInformation&amp;lt;String&amp;gt; typeInfo = TypeExtractor.getInputFormatTypes(format);&lt;br/&gt;
    +&lt;br/&gt;
    +		final long watermarkInterval = 10;&lt;br/&gt;
    +		ExecutionConfig executionConfig = new ExecutionConfig();&lt;br/&gt;
    +		executionConfig.setAutoWatermarkInterval(watermarkInterval);&lt;br/&gt;
    +&lt;br/&gt;
    +		ContinuousFileReaderOperator&amp;lt;String, ?&amp;gt; reader = new ContinuousFileReaderOperator&amp;lt;&amp;gt;(format);&lt;br/&gt;
    +		reader.setOutputType(typeInfo, executionConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final TestTimeServiceProvider timeServiceProvider = new TestTimeServiceProvider();&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;FileInputSplit, String&amp;gt; tester =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(reader, executionConfig, timeServiceProvider);&lt;br/&gt;
    +		tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
    +		tester.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		Assert.assertEquals(TimeCharacteristic.IngestionTime, tester.getTimeCharacteristic());&lt;br/&gt;
    +&lt;br/&gt;
    +		// test that watermarks are correctly emitted&lt;br/&gt;
    +&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(201);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(301);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(401);&lt;br/&gt;
    +		timeServiceProvider.setCurrentTime(501);&lt;br/&gt;
    +&lt;br/&gt;
    +		int i = 0;&lt;br/&gt;
    +		for(Object line: tester.getOutput()) {&lt;br/&gt;
    +			if (!(line instanceof Watermark)) &lt;/p&gt;
{
    +				Assert.fail(&quot;Only watermarks are expected here &quot;);
    +			}
&lt;p&gt;    +			Watermark w = (Watermark) line;&lt;br/&gt;
    +			Assert.assertEquals(200 + (i * 100), w.getTimestamp());&lt;br/&gt;
    +			i++;&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// clear the output to get the elements only and the final watermark&lt;br/&gt;
    +		tester.getOutput().clear();&lt;br/&gt;
    +		Assert.assertEquals(0, tester.getOutput().size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// create the necessary splits for the test&lt;br/&gt;
    +		FileInputSplit[] splits = format.createInputSplits(&lt;br/&gt;
    +			reader.getRuntimeContext().getNumberOfParallelSubtasks());&lt;br/&gt;
    +&lt;br/&gt;
    +		// and feed them to the operator&lt;br/&gt;
    +		Map&amp;lt;Integer, List&amp;lt;String&amp;gt;&amp;gt; actualFileContents = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		long lastSeenWatermark = Long.MIN_VALUE;&lt;br/&gt;
    +		int lineCounter = 0;	// counter for the lines read from the splits&lt;br/&gt;
    +		int watermarkCounter = 0;&lt;br/&gt;
    +&lt;br/&gt;
    +		for(FileInputSplit split: splits) {&lt;br/&gt;
    +&lt;br/&gt;
    +			// set the next &quot;current processing time&quot;.&lt;br/&gt;
    +			long nextTimestamp = timeServiceProvider.getCurrentProcessingTime() + watermarkInterval;&lt;br/&gt;
    +			timeServiceProvider.setCurrentTime(nextTimestamp);&lt;br/&gt;
    +&lt;br/&gt;
    +			// send the next split to be read and wait until it is fully read.&lt;br/&gt;
    +			tester.processElement(new StreamRecord&amp;lt;&amp;gt;(split));&lt;br/&gt;
    +			synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +				while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) &lt;/p&gt;
{
    +					tester.getCheckpointLock().wait(10);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// verify that the results are the expected&lt;br/&gt;
    +			for(Object line: tester.getOutput()) {&lt;br/&gt;
    +				if (line instanceof StreamRecord) {&lt;br/&gt;
    +					StreamRecord&amp;lt;String&amp;gt; element = (StreamRecord&amp;lt;String&amp;gt;) line;&lt;br/&gt;
    +					lineCounter++;&lt;br/&gt;
    +&lt;br/&gt;
    +					Assert.assertEquals(nextTimestamp, element.getTimestamp());&lt;br/&gt;
    +&lt;br/&gt;
    +					int fileIdx = Character.getNumericValue(element.getValue().charAt(0));&lt;br/&gt;
    +					List&amp;lt;String&amp;gt; content = actualFileContents.get(fileIdx);&lt;br/&gt;
    +					if (content == null) &lt;/p&gt;
{
    +						content = new ArrayList&amp;lt;&amp;gt;();
    +						actualFileContents.put(fileIdx, content);
    +					}
&lt;p&gt;    +					content.add(element.getValue() + &quot;\n&quot;);&lt;br/&gt;
    +				} else if (line instanceof Watermark) &lt;/p&gt;
{
    +					long watermark = ((Watermark) line).getTimestamp();
    +
    +					Assert.assertEquals(nextTimestamp - (nextTimestamp % watermarkInterval), watermark);
    +					Assert.assertTrue(watermark &amp;gt; lastSeenWatermark);
    +					watermarkCounter++;
    +
    +					lastSeenWatermark = watermark;
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					Assert.fail(&quot;Unknown element in the list.&quot;);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			// clean the output to be ready for the next split&lt;br/&gt;
    +			tester.getOutput().clear();&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now we are processing one split after the other,&lt;br/&gt;
    +		// so all the elements must be here by now.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES * LINES_PER_FILE, lineCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// because we expect one watermark per split.&lt;br/&gt;
    +		Assert.assertEquals(NO_OF_FILES, watermarkCounter);&lt;br/&gt;
    +&lt;br/&gt;
    +		// then close the reader gracefully so that the Long.MAX watermark is emitted&lt;br/&gt;
    +		synchronized (tester.getCheckpointLock()) {&lt;br/&gt;
    +			tester.close();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Never mind. Actually, `close()` expects as to hold the lock.&lt;/p&gt;</comment>
                            <comment id="15548780" author="githubbot" created="Wed, 5 Oct 2016 13:56:25 +0000"  >&lt;p&gt;Github user kl0u commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks @mxm and @StephanEwen for the comments. I have updated the PR.&lt;/p&gt;</comment>
                            <comment id="15548994" author="githubbot" created="Wed, 5 Oct 2016 14:55:55 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81990874&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81990874&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -214,14 +216,26 @@ public AutomaticWatermarkContext(&lt;br/&gt;
     			this.watermarkInterval = watermarkInterval;&lt;br/&gt;
     			this.reuse = new StreamRecord&amp;lt;T&amp;gt;(null);&lt;/p&gt;

&lt;p&gt;    +			// if it is a source, then we cast and cache it&lt;br/&gt;
    +			// here so that we do not have to do it in every collect(),&lt;br/&gt;
    +			// collectWithTimestamp() and emitWatermark()&lt;br/&gt;
    +&lt;br/&gt;
    +			if (!(owner instanceof AsyncExceptionChecker)) &lt;/p&gt;
{
    +				throw new IllegalStateException(&quot;The ManualWatermarkContext can only be used &quot; +
    +					&quot;with sources that implement the AsyncExceptionChecker interface.&quot;);
    +			}
&lt;p&gt;    +			this.source = (AsyncExceptionChecker) owner;&lt;br/&gt;
    +&lt;br/&gt;
     			long now = owner.getCurrentProcessingTime();&lt;br/&gt;
     			this.watermarkTimer = owner.registerTimer(now + watermarkInterval,&lt;br/&gt;
     				new WatermarkEmittingTask(owner, lockingObjectParam, outputParam));&lt;br/&gt;
     		}&lt;/p&gt;

&lt;p&gt;     		@Override&lt;br/&gt;
     		public void collect(T element) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;owner.checkAsyncException();&lt;br/&gt;
    +			if (source != null) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    source can never be null?&lt;/p&gt;</comment>
                            <comment id="15548993" author="githubbot" created="Wed, 5 Oct 2016 14:55:55 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81990910&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81990910&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -250,7 +264,9 @@ public void collectWithTimestamp(T element, long timestamp) {&lt;/p&gt;

&lt;p&gt;     		@Override&lt;br/&gt;
     		public void emitWatermark(Watermark mark) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;owner.checkAsyncException();&lt;br/&gt;
    +			if (source != null) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    same here&lt;/p&gt;</comment>
                            <comment id="15549025" author="githubbot" created="Wed, 5 Oct 2016 15:10:00 +0000"  >&lt;p&gt;Github user kl0u commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r81995575&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r81995575&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -214,14 +216,26 @@ public AutomaticWatermarkContext(&lt;br/&gt;
     			this.watermarkInterval = watermarkInterval;&lt;br/&gt;
     			this.reuse = new StreamRecord&amp;lt;T&amp;gt;(null);&lt;/p&gt;

&lt;p&gt;    +			// if it is a source, then we cast and cache it&lt;br/&gt;
    +			// here so that we do not have to do it in every collect(),&lt;br/&gt;
    +			// collectWithTimestamp() and emitWatermark()&lt;br/&gt;
    +&lt;br/&gt;
    +			if (!(owner instanceof AsyncExceptionChecker)) &lt;/p&gt;
{
    +				throw new IllegalStateException(&quot;The ManualWatermarkContext can only be used &quot; +
    +					&quot;with sources that implement the AsyncExceptionChecker interface.&quot;);
    +			}
&lt;p&gt;    +			this.source = (AsyncExceptionChecker) owner;&lt;br/&gt;
    +&lt;br/&gt;
     			long now = owner.getCurrentProcessingTime();&lt;br/&gt;
     			this.watermarkTimer = owner.registerTimer(now + watermarkInterval,&lt;br/&gt;
     				new WatermarkEmittingTask(owner, lockingObjectParam, outputParam));&lt;br/&gt;
     		}&lt;/p&gt;

&lt;p&gt;     		@Override&lt;br/&gt;
     		public void collect(T element) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;owner.checkAsyncException();&lt;br/&gt;
    +			if (source != null) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    You are right. I fixed it!&lt;/p&gt;</comment>
                            <comment id="15549121" author="githubbot" created="Wed, 5 Oct 2016 15:48:45 +0000"  >&lt;p&gt;Github user mxm commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593#discussion_r82004204&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593#discussion_r82004204&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamSource.java &amp;#8212;&lt;br/&gt;
    @@ -214,14 +216,24 @@ public AutomaticWatermarkContext(&lt;br/&gt;
     			this.watermarkInterval = watermarkInterval;&lt;br/&gt;
     			this.reuse = new StreamRecord&amp;lt;T&amp;gt;(null);&lt;/p&gt;

&lt;p&gt;    +			// if it is a source, then we cast and cache it&lt;br/&gt;
    +			// here so that we do not have to do it in every collect(),&lt;br/&gt;
    +			// collectWithTimestamp() and emitWatermark()&lt;br/&gt;
    +&lt;br/&gt;
    +			if (!(owner instanceof AsyncExceptionChecker)) {&lt;br/&gt;
    +				throw new IllegalStateException(&quot;The ManualWatermarkContext can only be used &quot; +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    AutomaticWatermarkContext?&lt;/p&gt;</comment>
                            <comment id="15549142" author="githubbot" created="Wed, 5 Oct 2016 15:57:40 +0000"  >&lt;p&gt;Github user mxm commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks! Merged. Could you close the PR?&lt;/p&gt;</comment>
                            <comment id="15549145" author="githubbot" created="Wed, 5 Oct 2016 15:58:41 +0000"  >&lt;p&gt;Github user kl0u closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2593&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2593&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15550109" author="githubbot" created="Wed, 5 Oct 2016 22:17:54 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2546&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2546&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15550133" author="stephanewen" created="Wed, 5 Oct 2016 22:24:09 +0000"  >&lt;p&gt;Fixed in&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;1.2.0 via 8ff451bec58e9f5800eb77c74c1d7457b776cc94&lt;/li&gt;
	&lt;li&gt;1.1.3 via bab59dfa7cf94f4c392c3205ee180e72e1ad7814&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 6 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32193:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>