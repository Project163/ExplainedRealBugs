<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:34:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10269] Elasticsearch 6 UpdateRequest fail because of binary incompatibility</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10269</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;When trying to send UpdateRequest(s) to ElasticSearch6, and one gets the following&lt;br/&gt;
error:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.NoSuchMethodError:
org.elasticsearch.action.bulk.BulkProcessor.add(Lorg/elasticsearch/action/ActionRequest;)Lorg/elasticsearch/action/bulk/BulkProcessor;
	at
org.apache.flink.streaming.connectors.elasticsearch.BulkProcessorIndexer.add(BulkProcessorIndexer.java:76)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ElasticsearchSinkFunction:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
	&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.elasticsearch.action.update.UpdateRequest
	def upsertRequest(element: T): UpdateRequest = {
		&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; UpdateRequest(
			&lt;span class=&quot;code-quote&quot;&gt;&quot;myIndex&quot;&lt;/span&gt;,
			&lt;span class=&quot;code-quote&quot;&gt;&quot;record&quot;&lt;/span&gt;,
			s&lt;span class=&quot;code-quote&quot;&gt;&quot;${element.id}&quot;&lt;/span&gt;)
	        	.doc(element.toMap())
	}
	override def process(element: T, runtimeContext: RuntimeContext,
requestIndexer: RequestIndexer): Unit = {
		requestIndexer.add(upsertRequest(element))
	}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is due to a binary compatibility issue between the base module (which is compiled against a very old ES version and the current Elasticsearch version).&lt;/p&gt;

&lt;p&gt;As a work around you can simply copy org.apache.flink.streaming.connectors.elasticsearch.BulkProcessorIndexer to your project. This should ensure that the class is compiled correctly.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13182292">FLINK-10269</key>
            <summary>Elasticsearch 6 UpdateRequest fail because of binary incompatibility</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="twalthr">Timo Walther</assignee>
                                    <reporter username="twalthr">Timo Walther</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 31 Aug 2018 06:20:30 +0000</created>
                <updated>Thu, 13 Sep 2018 11:28:33 +0000</updated>
                            <resolved>Thu, 13 Sep 2018 11:28:33 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>1.7.0</fixVersion>
                                    <component>Connectors / ElasticSearch</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16611937" author="githubbot" created="Wed, 12 Sep 2018 11:19:48 +0000"  >&lt;p&gt;twalthr opened a new pull request #6682: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10269&quot; title=&quot;Elasticsearch 6 UpdateRequest fail because of binary incompatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10269&quot;&gt;&lt;del&gt;FLINK-10269&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;connectors&amp;#93;&lt;/span&gt; Fix Elasticsearch 6 UpdateRequest binary incompatibility&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6682&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6682&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This commit fixes the binary incompatibility for UpdateRequests in Elasticsearch. This is due to a binary compatibility issue between the base module (which is compiled against a very old ES version and the current Elasticsearch version).&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Let the API call bridge also provide the `RequestIndexer` version-specific.&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   End-to-end tests extended.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): no&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: no&lt;/li&gt;
	&lt;li&gt;The serializers: no&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): no&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: no&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: no&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? no&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? not applicable&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16613051" author="githubbot" created="Thu, 13 Sep 2018 05:53:37 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #6682: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10269&quot; title=&quot;Elasticsearch 6 UpdateRequest fail because of binary incompatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10269&quot;&gt;&lt;del&gt;FLINK-10269&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;connectors&amp;#93;&lt;/span&gt; Fix Elasticsearch 6 UpdateRequest binary incompatibility&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6682#discussion_r217266494&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6682#discussion_r217266494&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-end-to-end-tests/test-scripts/test_streaming_elasticsearch.sh&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -45,4 +45,5 @@ $FLINK_DIR/bin/flink run -p 1 $TEST_ES_JAR \&lt;br/&gt;
   --index index \&lt;br/&gt;
   --type type&lt;/p&gt;

&lt;p&gt;-verify_result 20 index&lt;br/&gt;
+# 40 index requests and 20 final update requests&lt;br/&gt;
+verify_result 60 index&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   so, is the reason why the e2e tests weren&apos;t failing because the incompatibility was only detected on update requests?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16613114" author="githubbot" created="Thu, 13 Sep 2018 07:14:11 +0000"  >&lt;p&gt;twalthr commented on a change in pull request #6682: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10269&quot; title=&quot;Elasticsearch 6 UpdateRequest fail because of binary incompatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10269&quot;&gt;&lt;del&gt;FLINK-10269&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;connectors&amp;#93;&lt;/span&gt; Fix Elasticsearch 6 UpdateRequest binary incompatibility&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6682#discussion_r217281262&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6682#discussion_r217281262&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-end-to-end-tests/test-scripts/test_streaming_elasticsearch.sh&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -45,4 +45,5 @@ $FLINK_DIR/bin/flink run -p 1 $TEST_ES_JAR \&lt;br/&gt;
   --index index \&lt;br/&gt;
   --type type&lt;/p&gt;

&lt;p&gt;-verify_result 20 index&lt;br/&gt;
+# 40 index requests and 20 final update requests&lt;br/&gt;
+verify_result 60 index&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   yes, that was the reason&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16613116" author="githubbot" created="Thu, 13 Sep 2018 07:15:48 +0000"  >&lt;p&gt;twalthr commented on issue #6682: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10269&quot; title=&quot;Elasticsearch 6 UpdateRequest fail because of binary incompatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10269&quot;&gt;&lt;del&gt;FLINK-10269&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;connectors&amp;#93;&lt;/span&gt; Fix Elasticsearch 6 UpdateRequest binary incompatibility&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6682#issuecomment-420908045&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6682#issuecomment-420908045&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Thank you @tzulitai. I will merge this...&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16613333" author="githubbot" created="Thu, 13 Sep 2018 11:17:51 +0000"  >&lt;p&gt;asfgit closed pull request #6682: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10269&quot; title=&quot;Elasticsearch 6 UpdateRequest fail because of binary incompatibility&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10269&quot;&gt;&lt;del&gt;FLINK-10269&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;connectors&amp;#93;&lt;/span&gt; Fix Elasticsearch 6 UpdateRequest binary incompatibility&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6682&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6682&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java&lt;br/&gt;
index f1dcc83f652..d3b774c8428 100644&lt;br/&gt;
&amp;#8212; a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java&lt;br/&gt;
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java&lt;br/&gt;
@@ -28,6 +28,7 @@&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.io.Serializable;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
+import java.util.concurrent.atomic.AtomicLong;&lt;/p&gt;

&lt;p&gt; /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;An 
{@link ElasticsearchApiCallBridge} is used to bridge incompatible Elasticsearch Java API calls across different versions.&lt;br/&gt;
@@ -79,6 +80,19 @@ void configureBulkProcessorBackoff(&lt;br/&gt;
 		BulkProcessor.Builder builder,&lt;br/&gt;
 		@Nullable ElasticsearchSinkBase.BulkFlushBackoffPolicy flushBackoffPolicy);&lt;br/&gt;
 &lt;br/&gt;
+	/**&lt;br/&gt;
+	 * Creates a {@link RequestIndexer} that is able to work with {@link BulkProcessor} binary compatible.&lt;br/&gt;
+	 */&lt;br/&gt;
+	default RequestIndexer createBulkProcessorIndexer(&lt;br/&gt;
+			BulkProcessor bulkProcessor,&lt;br/&gt;
+			boolean flushOnCheckpoint,&lt;br/&gt;
+			AtomicLong numPendingRequestsRef) {
+		return new PreElasticsearch6BulkProcessorIndexer(
+			bulkProcessor,
+			flushOnCheckpoint,
+			numPendingRequestsRef);
+	}&lt;br/&gt;
+&lt;br/&gt;
 	/**&lt;br/&gt;
 	 * Perform any necessary state cleanup.&lt;br/&gt;
 	 */&lt;br/&gt;
diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java&lt;br/&gt;
index 7dac06ceb8a..4d0c00252d2 100644&lt;br/&gt;
&amp;#8212; a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java&lt;br/&gt;
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java&lt;br/&gt;
@@ -164,7 +164,7 @@ public void setDelayMillis(long delayMillis) {&lt;br/&gt;
 	private boolean flushOnCheckpoint = true;&lt;br/&gt;
 &lt;br/&gt;
 	/** Provided to the user via the {@link ElasticsearchSinkFunction} to add {@link ActionRequest ActionRequests}. */&lt;br/&gt;
-	private transient BulkProcessorIndexer requestIndexer;&lt;br/&gt;
+	private transient RequestIndexer requestIndexer;&lt;br/&gt;
 &lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;br/&gt;
 	//  Internals for the Flink Elasticsearch Sink&lt;br/&gt;
@@ -295,7 +295,7 @@ public void disableFlushOnCheckpoint() {&lt;br/&gt;
 	public void open(Configuration parameters) throws Exception {
 		client = callBridge.createClient(userConfig);
 		bulkProcessor = buildBulkProcessor(new BulkProcessorListener());
-		requestIndexer = new BulkProcessorIndexer(bulkProcessor, flushOnCheckpoint, numPendingRequests);
+		requestIndexer = callBridge.createBulkProcessorIndexer(bulkProcessor, flushOnCheckpoint, numPendingRequests);
 	}&lt;br/&gt;
 &lt;br/&gt;
 	@Override&lt;br/&gt;
diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/PreElasticsearch6BulkProcessorIndexer.java b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/PreElasticsearch6BulkProcessorIndexer.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..85f4b9a3ea1&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/PreElasticsearch6BulkProcessorIndexer.java&lt;br/&gt;
@@ -0,0 +1,84 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.flink.streaming.connectors.elasticsearch;&lt;br/&gt;
+&lt;br/&gt;
+import org.apache.flink.annotation.Internal;&lt;br/&gt;
+&lt;br/&gt;
+import org.elasticsearch.action.ActionRequest;&lt;br/&gt;
+import org.elasticsearch.action.bulk.BulkProcessor;&lt;br/&gt;
+import org.elasticsearch.action.delete.DeleteRequest;&lt;br/&gt;
+import org.elasticsearch.action.index.IndexRequest;&lt;br/&gt;
+import org.elasticsearch.action.update.UpdateRequest;&lt;br/&gt;
+&lt;br/&gt;
+import java.util.concurrent.atomic.AtomicLong;&lt;br/&gt;
+&lt;br/&gt;
+import static org.apache.flink.util.Preconditions.checkNotNull;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Implementation of a {@link RequestIndexer}, using a {@link BulkProcessor}.&lt;br/&gt;
+ * {@link ActionRequest ActionRequests} will be buffered before sending a bulk request to the Elasticsearch cluster.&lt;br/&gt;
+ *&lt;br/&gt;
+ * @deprecated This class is not binary compatible with newer Elasticsearch 6+ versions&lt;br/&gt;
+ *             (i.e. the {@link #add(UpdateRequest...)} ). However, this module is currently&lt;br/&gt;
+ *             compiled against a very old Elasticsearch version.&lt;br/&gt;
+ */&lt;br/&gt;
+@Deprecated&lt;br/&gt;
+@Internal&lt;br/&gt;
+class PreElasticsearch6BulkProcessorIndexer implements RequestIndexer {&lt;br/&gt;
+&lt;br/&gt;
+	private final BulkProcessor bulkProcessor;&lt;br/&gt;
+	private final boolean flushOnCheckpoint;&lt;br/&gt;
+	private final AtomicLong numPendingRequestsRef;&lt;br/&gt;
+&lt;br/&gt;
+	PreElasticsearch6BulkProcessorIndexer(BulkProcessor bulkProcessor, boolean flushOnCheckpoint, AtomicLong numPendingRequestsRef) {
+		this.bulkProcessor = checkNotNull(bulkProcessor);
+		this.flushOnCheckpoint = flushOnCheckpoint;
+		this.numPendingRequestsRef = checkNotNull(numPendingRequestsRef);
+	}&lt;br/&gt;
+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public void add(DeleteRequest... deleteRequests) {&lt;br/&gt;
+		for (DeleteRequest deleteRequest : deleteRequests) {&lt;br/&gt;
+			if (flushOnCheckpoint) {
+				numPendingRequestsRef.getAndIncrement();
+			}&lt;br/&gt;
+			this.bulkProcessor.add(deleteRequest);&lt;br/&gt;
+		}&lt;br/&gt;
+	}&lt;br/&gt;
+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public void add(IndexRequest... indexRequests) {&lt;br/&gt;
+		for (IndexRequest indexRequest : indexRequests) {&lt;br/&gt;
+			if (flushOnCheckpoint) {+				numPendingRequestsRef.getAndIncrement();+			}&lt;br/&gt;
+			this.bulkProcessor.add(indexRequest);&lt;br/&gt;
+		}&lt;br/&gt;
+	}&lt;br/&gt;
+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public void add(UpdateRequest... updateRequests) {&lt;br/&gt;
+		for (UpdateRequest updateRequest : updateRequests) {&lt;br/&gt;
+			if (flushOnCheckpoint) {
+				numPendingRequestsRef.getAndIncrement();
+			}&lt;br/&gt;
+			this.bulkProcessor.add(updateRequest);&lt;br/&gt;
+		}&lt;br/&gt;
+	}&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/Elasticsearch6ApiCallBridge.java b/flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/Elasticsearch6ApiCallBridge.java&lt;br/&gt;
index 03bf9c07109..782cbbcf467 100644&lt;br/&gt;
&amp;#8212; a/flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/Elasticsearch6ApiCallBridge.java&lt;br/&gt;
+++ b/flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/Elasticsearch6ApiCallBridge.java&lt;br/&gt;
@@ -20,6 +20,7 @@&lt;br/&gt;
 import org.apache.flink.annotation.Internal;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchApiCallBridge;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase;&lt;br/&gt;
+import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;&lt;br/&gt;
 import org.apache.flink.util.Preconditions;&lt;br/&gt;
 &lt;br/&gt;
 import org.apache.http.HttpHost;&lt;br/&gt;
@@ -38,6 +39,7 @@&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
+import java.util.concurrent.atomic.AtomicLong;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
  * Implementation of {@link ElasticsearchApiCallBridge}
&lt;p&gt; for Elasticsearch 6 and later versions.&lt;br/&gt;
@@ -126,4 +128,15 @@ public void configureBulkProcessorBackoff(&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		builder.setBackoffPolicy(backoffPolicy);&lt;br/&gt;
 	}&lt;br/&gt;
+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public RequestIndexer createBulkProcessorIndexer(&lt;br/&gt;
+			BulkProcessor bulkProcessor,&lt;br/&gt;
+			boolean flushOnCheckpoint,&lt;br/&gt;
+			AtomicLong numPendingRequestsRef) &lt;/p&gt;
{
+		return new Elasticsearch6BulkProcessorIndexer(
+			bulkProcessor,
+			flushOnCheckpoint,
+			numPendingRequestsRef);
+	}
&lt;p&gt; }&lt;br/&gt;
diff --git a/flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/Elasticsearch6BulkProcessorIndexer.java b/flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/Elasticsearch6BulkProcessorIndexer.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..af3c5b13a9a&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/Elasticsearch6BulkProcessorIndexer.java&lt;br/&gt;
@@ -0,0 +1,85 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.flink.streaming.connectors.elasticsearch6;&lt;br/&gt;
+&lt;br/&gt;
+import org.apache.flink.annotation.Internal;&lt;br/&gt;
+import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;&lt;br/&gt;
+&lt;br/&gt;
+import org.elasticsearch.action.ActionRequest;&lt;br/&gt;
+import org.elasticsearch.action.bulk.BulkProcessor;&lt;br/&gt;
+import org.elasticsearch.action.delete.DeleteRequest;&lt;br/&gt;
+import org.elasticsearch.action.index.IndexRequest;&lt;br/&gt;
+import org.elasticsearch.action.update.UpdateRequest;&lt;br/&gt;
+&lt;br/&gt;
+import java.util.concurrent.atomic.AtomicLong;&lt;br/&gt;
+&lt;br/&gt;
+import static org.apache.flink.util.Preconditions.checkNotNull;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Implementation of a &lt;/p&gt;
{@link RequestIndexer}
&lt;p&gt;, using a &lt;/p&gt;
{@link BulkProcessor}
&lt;p&gt;.&lt;br/&gt;
+ * &lt;/p&gt;
{@link ActionRequest ActionRequests}
&lt;p&gt; will be buffered before sending a bulk request to the Elasticsearch cluster.&lt;br/&gt;
+ *&lt;br/&gt;
+ * &amp;lt;p&amp;gt;Note: This class is binary compatible to Elasticsearch 6.&lt;br/&gt;
+ */&lt;br/&gt;
+@Internal&lt;br/&gt;
+class Elasticsearch6BulkProcessorIndexer implements RequestIndexer {&lt;br/&gt;
+&lt;br/&gt;
+	private final BulkProcessor bulkProcessor;&lt;br/&gt;
+	private final boolean flushOnCheckpoint;&lt;br/&gt;
+	private final AtomicLong numPendingRequestsRef;&lt;br/&gt;
+&lt;br/&gt;
+	Elasticsearch6BulkProcessorIndexer(&lt;br/&gt;
+			BulkProcessor bulkProcessor,&lt;br/&gt;
+			boolean flushOnCheckpoint,&lt;br/&gt;
+			AtomicLong numPendingRequestsRef) &lt;/p&gt;
{
+		this.bulkProcessor = checkNotNull(bulkProcessor);
+		this.flushOnCheckpoint = flushOnCheckpoint;
+		this.numPendingRequestsRef = checkNotNull(numPendingRequestsRef);
+	}
&lt;p&gt;+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public void add(DeleteRequest... deleteRequests) {&lt;br/&gt;
+		for (DeleteRequest deleteRequest : deleteRequests) {&lt;br/&gt;
+			if (flushOnCheckpoint) &lt;/p&gt;
{
+				numPendingRequestsRef.getAndIncrement();
+			}&lt;br/&gt;
+			this.bulkProcessor.add(deleteRequest);&lt;br/&gt;
+		}&lt;br/&gt;
+	}&lt;br/&gt;
+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public void add(IndexRequest... indexRequests) {&lt;br/&gt;
+		for (IndexRequest indexRequest : indexRequests) {&lt;br/&gt;
+			if (flushOnCheckpoint) {+				numPendingRequestsRef.getAndIncrement();+			}
&lt;p&gt;+			this.bulkProcessor.add(indexRequest);&lt;br/&gt;
+		}&lt;br/&gt;
+	}&lt;br/&gt;
+&lt;br/&gt;
+	@Override&lt;br/&gt;
+	public void add(UpdateRequest... updateRequests) {&lt;br/&gt;
+		for (UpdateRequest updateRequest : updateRequests) {&lt;br/&gt;
+			if (flushOnCheckpoint) &lt;/p&gt;
{
+				numPendingRequestsRef.getAndIncrement();
+			}
&lt;p&gt;+			this.bulkProcessor.add(updateRequest);&lt;br/&gt;
+		}&lt;br/&gt;
+	}&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/flink-end-to-end-tests/flink-elasticsearch1-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch1SinkExample.java b/flink-end-to-end-tests/flink-elasticsearch1-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch1SinkExample.java&lt;br/&gt;
index 18fa05a8976..21c53edcf4f 100644&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/flink-elasticsearch1-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch1SinkExample.java&lt;br/&gt;
+++ b/flink-end-to-end-tests/flink-elasticsearch1-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch1SinkExample.java&lt;br/&gt;
@@ -17,16 +17,18 @@&lt;/p&gt;

&lt;p&gt; package org.apache.flink.streaming.tests;&lt;/p&gt;

&lt;p&gt;-import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
+import org.apache.flink.api.common.functions.FlatMapFunction;&lt;br/&gt;
 import org.apache.flink.api.common.functions.RuntimeContext;&lt;br/&gt;
+import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
 import org.apache.flink.api.java.utils.ParameterTool;&lt;br/&gt;
 import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSink;&lt;br/&gt;
-import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;&lt;br/&gt;
+import org.apache.flink.util.Collector;&lt;/p&gt;

&lt;p&gt; import org.elasticsearch.action.index.IndexRequest;&lt;br/&gt;
+import org.elasticsearch.action.update.UpdateRequest;&lt;br/&gt;
 import org.elasticsearch.client.Requests;&lt;br/&gt;
 import org.elasticsearch.common.transport.InetSocketTransportAddress;&lt;br/&gt;
 import org.elasticsearch.common.transport.TransportAddress;&lt;br/&gt;
@@ -56,11 +58,14 @@ public static void main(String[] args) throws Exception {&lt;br/&gt;
 		env.getConfig().disableSysoutLogging();&lt;br/&gt;
 		env.enableCheckpointing(5000);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;DataStream&amp;lt;String&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;/li&gt;
	&lt;li&gt;.map(new MapFunction&amp;lt;Long, String&amp;gt;() {&lt;br/&gt;
+		DataStream&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;br/&gt;
+			.flatMap(new FlatMapFunction&amp;lt;Long, Tuple2&amp;lt;String, String&amp;gt;&amp;gt;() {&lt;br/&gt;
 				@Override&lt;/li&gt;
	&lt;li&gt;public String map(Long value) throws Exception {&lt;/li&gt;
	&lt;li&gt;return &quot;message # &quot; + value;&lt;br/&gt;
+				public void flatMap(Long value, Collector&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; out) 
{
+					final String key = String.valueOf(value);
+					final String message = &quot;message #&quot; + value;
+					out.collect(Tuple2.of(key, message + &quot;update #1&quot;));
+					out.collect(Tuple2.of(key, message + &quot;update #2&quot;));
 				}&lt;br/&gt;
 			});&lt;br/&gt;
 &lt;br/&gt;
@@ -72,12 +77,13 @@ public String map(Long value) throws Exception {&lt;br/&gt;
 		List&amp;lt;TransportAddress&amp;gt; transports = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
 		transports.add(new InetSocketTransportAddress(InetAddress.getByName(&quot;127.0.0.1&quot;), 9300));&lt;br/&gt;
 &lt;br/&gt;
-		source.addSink(new ElasticsearchSink&amp;lt;&amp;gt;(userConfig, transports, new ElasticsearchSinkFunction&amp;lt;String&amp;gt;() {&lt;br/&gt;
-			@Override&lt;br/&gt;
-			public void process(String element, RuntimeContext ctx, RequestIndexer indexer) {
-				indexer.add(createIndexRequest(element, parameterTool));
-			}&lt;br/&gt;
-		}));&lt;br/&gt;
+		source.addSink(new ElasticsearchSink&amp;lt;&amp;gt;(&lt;br/&gt;
+			userConfig,&lt;br/&gt;
+			transports,&lt;br/&gt;
+			(Tuple2&amp;lt;String, String&amp;gt; element, RuntimeContext ctx, RequestIndexer indexer) -&amp;gt; {
+				indexer.add(createIndexRequest(element.f1, parameterTool));
+				indexer.add(createUpdateRequest(element, parameterTool));
+			}));&lt;br/&gt;
 &lt;br/&gt;
 		env.execute(&quot;Elasticsearch1.x end to end sink test example&quot;);&lt;br/&gt;
 	}&lt;br/&gt;
@@ -92,4 +98,16 @@ private static IndexRequest createIndexRequest(String element, ParameterTool par&lt;br/&gt;
 			.id(element)&lt;br/&gt;
 			.source(json);&lt;br/&gt;
 	}&lt;br/&gt;
+&lt;br/&gt;
+	private static UpdateRequest createUpdateRequest(Tuple2&amp;lt;String, String&amp;gt; element, ParameterTool parameterTool) {
+		Map&amp;lt;String, Object&amp;gt; json = new HashMap&amp;lt;&amp;gt;();
+		json.put(&quot;data&quot;, element.f1);
+
+		return new UpdateRequest(
+				parameterTool.getRequired(&quot;index&quot;),
+				parameterTool.getRequired(&quot;type&quot;),
+				element.f0)
+			.doc(json)
+			.upsert(json);
+	}&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-end-to-end-tests/flink-elasticsearch2-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch2SinkExample.java b/flink-end-to-end-tests/flink-elasticsearch2-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch2SinkExample.java&lt;br/&gt;
index f7532b1a8d6..f8f390e9747 100644&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/flink-elasticsearch2-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch2SinkExample.java&lt;br/&gt;
+++ b/flink-end-to-end-tests/flink-elasticsearch2-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch2SinkExample.java&lt;br/&gt;
@@ -17,15 +17,18 @@&lt;br/&gt;
 &lt;br/&gt;
 package org.apache.flink.streaming.tests;&lt;br/&gt;
 &lt;br/&gt;
-import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
+import org.apache.flink.api.common.functions.FlatMapFunction;&lt;br/&gt;
 import org.apache.flink.api.common.functions.RuntimeContext;&lt;br/&gt;
+import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
 import org.apache.flink.api.java.utils.ParameterTool;&lt;br/&gt;
 import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
-import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;&lt;br/&gt;
+import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch2.ElasticsearchSink;&lt;br/&gt;
+import org.apache.flink.util.Collector;&lt;br/&gt;
 &lt;br/&gt;
 import org.elasticsearch.action.index.IndexRequest;&lt;br/&gt;
+import org.elasticsearch.action.update.UpdateRequest;&lt;br/&gt;
 import org.elasticsearch.client.Requests;&lt;br/&gt;
 &lt;br/&gt;
 import java.net.InetAddress;&lt;br/&gt;
@@ -54,11 +57,14 @@ public static void main(String[] args) throws Exception {&lt;br/&gt;
 		env.getConfig().disableSysoutLogging();&lt;br/&gt;
 		env.enableCheckpointing(5000);&lt;br/&gt;
 &lt;br/&gt;
-		DataStream&amp;lt;String&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;br/&gt;
-			.map(new MapFunction&amp;lt;Long, String&amp;gt;() {&lt;br/&gt;
+		DataStream&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;br/&gt;
+			.flatMap(new FlatMapFunction&amp;lt;Long, Tuple2&amp;lt;String, String&amp;gt;&amp;gt;() {&lt;br/&gt;
 				@Override&lt;br/&gt;
-				public String map(Long value) throws Exception {&lt;br/&gt;
-					return &quot;message #&quot; + value;&lt;br/&gt;
+				public void flatMap(Long value, Collector&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; out) {+					final String key = String.valueOf(value);+					final String message = &quot;message #&quot; + value;+					out.collect(Tuple2.of(key, message + &quot;update #1&quot;));+					out.collect(Tuple2.of(key, message + &quot;update #2&quot;)); 				}
&lt;p&gt; 			});&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -70,12 +76,13 @@ public String map(Long value) throws Exception {&lt;br/&gt;
 		List&amp;lt;InetSocketAddress&amp;gt; transports = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
 		transports.add(new InetSocketAddress(InetAddress.getByName(&quot;127.0.0.1&quot;), 9300));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;source.addSink(new ElasticsearchSink&amp;lt;&amp;gt;(userConfig, transports, new ElasticsearchSinkFunction&amp;lt;String&amp;gt;(){&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void process(String element, RuntimeContext ctx, org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer indexer) 
{
-				indexer.add(createIndexRequest(element, parameterTool));
-			}&lt;br/&gt;
-		}));&lt;br/&gt;
+		source.addSink(new ElasticsearchSink&amp;lt;&amp;gt;(&lt;br/&gt;
+			userConfig,&lt;br/&gt;
+			transports,&lt;br/&gt;
+			(Tuple2&amp;lt;String, String&amp;gt; element, RuntimeContext ctx, RequestIndexer indexer) -&amp;gt; {
+				indexer.add(createIndexRequest(element.f1, parameterTool));
+				indexer.add(createUpdateRequest(element, parameterTool));
+			}));&lt;br/&gt;
 &lt;br/&gt;
 		env.execute(&quot;Elasticsearch2.x end to end sink test example&quot;);&lt;br/&gt;
 	}&lt;br/&gt;
@@ -90,4 +97,16 @@ private static IndexRequest createIndexRequest(String element, ParameterTool par&lt;br/&gt;
 			.id(element)&lt;br/&gt;
 			.source(json);&lt;br/&gt;
 	}&lt;br/&gt;
+&lt;br/&gt;
+	private static UpdateRequest createUpdateRequest(Tuple2&amp;lt;String, String&amp;gt; element, ParameterTool parameterTool) {
+		Map&amp;lt;String, Object&amp;gt; json = new HashMap&amp;lt;&amp;gt;();
+		json.put(&quot;data&quot;, element.f1);
+
+		return new UpdateRequest(
+				parameterTool.getRequired(&quot;index&quot;),
+				parameterTool.getRequired(&quot;type&quot;),
+				element.f0)
+			.doc(json)
+			.upsert(json);
+	}&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-end-to-end-tests/flink-elasticsearch5-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch5SinkExample.java b/flink-end-to-end-tests/flink-elasticsearch5-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch5SinkExample.java&lt;br/&gt;
index 39808f6fd4d..893d3662936 100644&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/flink-elasticsearch5-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch5SinkExample.java&lt;br/&gt;
+++ b/flink-end-to-end-tests/flink-elasticsearch5-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch5SinkExample.java&lt;br/&gt;
@@ -17,16 +17,18 @@&lt;br/&gt;
 &lt;br/&gt;
 package org.apache.flink.streaming.tests;&lt;br/&gt;
 &lt;br/&gt;
-import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
+import org.apache.flink.api.common.functions.FlatMapFunction;&lt;br/&gt;
 import org.apache.flink.api.common.functions.RuntimeContext;&lt;br/&gt;
+import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
 import org.apache.flink.api.java.utils.ParameterTool;&lt;br/&gt;
 import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
-import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch5.ElasticsearchSink;&lt;br/&gt;
+import org.apache.flink.util.Collector;&lt;br/&gt;
 &lt;br/&gt;
 import org.elasticsearch.action.index.IndexRequest;&lt;br/&gt;
+import org.elasticsearch.action.update.UpdateRequest;&lt;br/&gt;
 import org.elasticsearch.client.Requests;&lt;br/&gt;
 &lt;br/&gt;
 import java.net.InetAddress;&lt;br/&gt;
@@ -55,11 +57,14 @@ public static void main(String[] args) throws Exception {&lt;br/&gt;
 		env.getConfig().disableSysoutLogging();&lt;br/&gt;
 		env.enableCheckpointing(5000);&lt;br/&gt;
 &lt;br/&gt;
-		DataStream&amp;lt;String&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;br/&gt;
-			.map(new MapFunction&amp;lt;Long, String&amp;gt;() {&lt;br/&gt;
+		DataStream&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;br/&gt;
+			.flatMap(new FlatMapFunction&amp;lt;Long, Tuple2&amp;lt;String, String&amp;gt;&amp;gt;() {&lt;br/&gt;
 				@Override&lt;br/&gt;
-				public String map(Long value) throws Exception {&lt;br/&gt;
-					return &quot;message #&quot; + value;&lt;br/&gt;
+				public void flatMap(Long value, Collector&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; out) {
+					final String key = String.valueOf(value);
+					final String message = &quot;message #&quot; + value;
+					out.collect(Tuple2.of(key, message + &quot;update #1&quot;));
+					out.collect(Tuple2.of(key, message + &quot;update #2&quot;));
 				}&lt;br/&gt;
 			});&lt;br/&gt;
 &lt;br/&gt;
@@ -71,12 +76,13 @@ public String map(Long value) throws Exception {&lt;br/&gt;
 		List&amp;lt;InetSocketAddress&amp;gt; transports = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
 		transports.add(new InetSocketAddress(InetAddress.getByName(&quot;127.0.0.1&quot;), 9300));&lt;br/&gt;
 &lt;br/&gt;
-		source.addSink(new ElasticsearchSink&amp;lt;&amp;gt;(userConfig, transports, new ElasticsearchSinkFunction&amp;lt;String&amp;gt;() {&lt;br/&gt;
-			@Override&lt;br/&gt;
-			public void process(String element, RuntimeContext ctx, RequestIndexer indexer) {-				indexer.add(createIndexRequest(element, parameterTool));-			}&lt;/li&gt;
	&lt;li&gt;}));&lt;br/&gt;
+		source.addSink(new ElasticsearchSink&amp;lt;&amp;gt;(&lt;br/&gt;
+			userConfig,&lt;br/&gt;
+			transports,&lt;br/&gt;
+			(Tuple2&amp;lt;String, String&amp;gt; element, RuntimeContext ctx, RequestIndexer indexer) -&amp;gt; 
{
+				indexer.add(createIndexRequest(element.f1, parameterTool));
+				indexer.add(createUpdateRequest(element, parameterTool));
+			}));&lt;br/&gt;
 &lt;br/&gt;
 		env.execute(&quot;Elasticsearch5.x end to end sink test example&quot;);&lt;br/&gt;
 	}&lt;br/&gt;
@@ -91,4 +97,16 @@ private static IndexRequest createIndexRequest(String element, ParameterTool par&lt;br/&gt;
 			.id(element)&lt;br/&gt;
 			.source(json);&lt;br/&gt;
 	}&lt;br/&gt;
+&lt;br/&gt;
+	private static UpdateRequest createUpdateRequest(Tuple2&amp;lt;String, String&amp;gt; element, ParameterTool parameterTool) {
+		Map&amp;lt;String, Object&amp;gt; json = new HashMap&amp;lt;&amp;gt;();
+		json.put(&quot;data&quot;, element.f1);
+
+		return new UpdateRequest(
+				parameterTool.getRequired(&quot;index&quot;),
+				parameterTool.getRequired(&quot;type&quot;),
+				element.f0)
+			.doc(json)
+			.upsert(json);
+	}&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java b/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java&lt;br/&gt;
index dedcbb28f08..e813c2995f5 100644&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java&lt;br/&gt;
+++ b/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java&lt;br/&gt;
@@ -17,16 +17,19 @@&lt;br/&gt;
 &lt;br/&gt;
 package org.apache.flink.streaming.tests;&lt;br/&gt;
 &lt;br/&gt;
-import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
+import org.apache.flink.api.common.functions.FlatMapFunction;&lt;br/&gt;
 import org.apache.flink.api.common.functions.RuntimeContext;&lt;br/&gt;
+import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
 import org.apache.flink.api.java.utils.ParameterTool;&lt;br/&gt;
 import org.apache.flink.streaming.api.datastream.DataStream;&lt;br/&gt;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;&lt;br/&gt;
 import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink;&lt;br/&gt;
+import org.apache.flink.util.Collector;&lt;br/&gt;
 &lt;br/&gt;
 import org.apache.http.HttpHost;&lt;br/&gt;
 import org.elasticsearch.action.index.IndexRequest;&lt;br/&gt;
+import org.elasticsearch.action.update.UpdateRequest;&lt;br/&gt;
 import org.elasticsearch.client.Requests;&lt;br/&gt;
 &lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
@@ -53,20 +56,26 @@ public static void main(String[] args) throws Exception {&lt;br/&gt;
 		env.getConfig().disableSysoutLogging();&lt;br/&gt;
 		env.enableCheckpointing(5000);&lt;br/&gt;
 &lt;br/&gt;
-		DataStream&amp;lt;String&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;br/&gt;
-			.map(new MapFunction&amp;lt;Long, String&amp;gt;() {&lt;br/&gt;
+		DataStream&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; source = env.generateSequence(0, parameterTool.getInt(&quot;numRecords&quot;) - 1)&lt;br/&gt;
+			.flatMap(new FlatMapFunction&amp;lt;Long, Tuple2&amp;lt;String, String&amp;gt;&amp;gt;() {&lt;br/&gt;
 				@Override&lt;br/&gt;
-				public String map(Long value) throws Exception {&lt;br/&gt;
-					return &quot;message #&quot; + value;&lt;br/&gt;
+				public void flatMap(Long value, Collector&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; out) {
+					final String key = String.valueOf(value);
+					final String message = &quot;message #&quot; + value;
+					out.collect(Tuple2.of(key, message + &quot;update #1&quot;));
+					out.collect(Tuple2.of(key, message + &quot;update #2&quot;));
 				}&lt;br/&gt;
 			});&lt;br/&gt;
 &lt;br/&gt;
 		List&amp;lt;HttpHost&amp;gt; httpHosts = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
 		httpHosts.add(new HttpHost(&quot;127.0.0.1&quot;, 9200, &quot;http&quot;));&lt;br/&gt;
 &lt;br/&gt;
-		ElasticsearchSink.Builder&amp;lt;String&amp;gt; esSinkBuilder = new ElasticsearchSink.Builder&amp;lt;&amp;gt;(&lt;br/&gt;
+		ElasticsearchSink.Builder&amp;lt;Tuple2&amp;lt;String, String&amp;gt;&amp;gt; esSinkBuilder = new ElasticsearchSink.Builder&amp;lt;&amp;gt;(&lt;br/&gt;
 			httpHosts,&lt;br/&gt;
-			(String element, RuntimeContext ctx, RequestIndexer indexer) -&amp;gt; indexer.add(createIndexRequest(element, parameterTool)));&lt;br/&gt;
+			(Tuple2&amp;lt;String, String&amp;gt; element, RuntimeContext ctx, RequestIndexer indexer) -&amp;gt; {+				indexer.add(createIndexRequest(element.f1, parameterTool));+				indexer.add(createUpdateRequest(element, parameterTool));+			}
&lt;p&gt;);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		// this instructs the sink to emit after every element, otherwise they would be buffered&lt;br/&gt;
 		esSinkBuilder.setBulkFlushMaxActions(1);&lt;br/&gt;
@@ -86,4 +95,16 @@ private static IndexRequest createIndexRequest(String element, ParameterTool par&lt;br/&gt;
 			.id(element)&lt;br/&gt;
 			.source(json);&lt;br/&gt;
 	}&lt;br/&gt;
+&lt;br/&gt;
+	private static UpdateRequest createUpdateRequest(Tuple2&amp;lt;String, String&amp;gt; element, ParameterTool parameterTool) &lt;/p&gt;
{
+		Map&amp;lt;String, Object&amp;gt; json = new HashMap&amp;lt;&amp;gt;();
+		json.put(&quot;data&quot;, element.f1);
+
+		return new UpdateRequest(
+				parameterTool.getRequired(&quot;index&quot;),
+				parameterTool.getRequired(&quot;type&quot;),
+				element.f0)
+			.doc(json)
+			.upsert(json);
+	}
&lt;p&gt; }&lt;br/&gt;
diff --git a/flink-end-to-end-tests/test-scripts/test_streaming_elasticsearch.sh b/flink-end-to-end-tests/test-scripts/test_streaming_elasticsearch.sh&lt;br/&gt;
index c8cd2db17c9..800c4e20ae0 100755&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/test-scripts/test_streaming_elasticsearch.sh&lt;br/&gt;
+++ b/flink-end-to-end-tests/test-scripts/test_streaming_elasticsearch.sh&lt;br/&gt;
@@ -45,4 +45,5 @@ $FLINK_DIR/bin/flink run -p 1 $TEST_ES_JAR \&lt;br/&gt;
   --index index \&lt;br/&gt;
   --type type&lt;/p&gt;

&lt;p&gt;-verify_result 20 index&lt;br/&gt;
+# 40 index requests and 20 final update requests&lt;br/&gt;
+verify_result 60 index&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16613340" author="twalthr" created="Thu, 13 Sep 2018 11:28:33 +0000"  >&lt;p&gt;Fixed in 1.7.0: c4beb3aefa806d1b14ed4d388177935578203bf0&lt;br/&gt;
Fixed in 1.6.1: f3d6fac22ff160b53052d384d8d0c231557fcf3e&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13182322">FLINK-10271</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 9 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3xm9r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>