<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:21:14 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-2763] Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers.</title>
                <link>https://issues.apache.org/jira/browse/FLINK-2763</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The following exception is thrown when running the example triangle listing with an unmodified master build (4cadc3d6).&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;./bin/flink run ~/flink-examples/flink-java-examples/target/flink-java-examples-0.10-SNAPSHOT-EnumTrianglesOpt.jar ~/rmat/undirected/s19_e8.ssv output
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The only changes to &lt;tt&gt;flink-conf.yaml&lt;/tt&gt; are &lt;tt&gt;taskmanager.numberOfTaskSlots: 8&lt;/tt&gt; and &lt;tt&gt;parallelism.default: 8&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;I have confirmed with input files &lt;a href=&quot;https://drive.google.com/file/d/0B6TrSsnHj2HxR2lnMHR4amdyTnM/view?usp=sharing&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;s19_e8.ssv&lt;/a&gt; (40 MB) and &lt;a href=&quot;https://drive.google.com/file/d/0B6TrSsnHj2HxNi1HbmptU29MTm8/view?usp=sharing&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;s20_e8.ssv&lt;/a&gt; (83 MB). On a second machine only the larger file caused the exception.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job execution failed.
	at org.apache.flink.client.program.Client.runBlocking(Client.java:407)
	at org.apache.flink.client.program.Client.runBlocking(Client.java:386)
	at org.apache.flink.client.program.Client.runBlocking(Client.java:353)
	at org.apache.flink.client.program.ContextEnvironment.execute(ContextEnvironment.java:64)
	at org.apache.flink.examples.java.graph.EnumTrianglesOpt.main(EnumTrianglesOpt.java:125)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:434)
	at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:350)
	at org.apache.flink.client.program.Client.runBlocking(Client.java:290)
	at org.apache.flink.client.CliFrontend.executeProgramBlocking(CliFrontend.java:675)
	at org.apache.flink.client.CliFrontend.run(CliFrontend.java:324)
	at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:977)
	at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1027)
Caused by: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.
	at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1.applyOrElse(JobManager.scala:425)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply$mcVL$sp(AbstractPartialFunction.scala:33)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:33)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:25)
	at org.apache.flink.runtime.LeaderSessionMessageFilter$$anonfun$receive$1.applyOrElse(LeaderSessionMessageFilter.scala:36)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply$mcVL$sp(AbstractPartialFunction.scala:33)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:33)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:25)
	at org.apache.flink.runtime.LogMessages$$anon$1.apply(LogMessages.scala:33)
	at org.apache.flink.runtime.LogMessages$$anon$1.apply(LogMessages.scala:28)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:118)
	at org.apache.flink.runtime.LogMessages$$anon$1.applyOrElse(LogMessages.scala:28)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:107)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254)
	at akka.dispatch.Mailbox.run(Mailbox.scala:221)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:231)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers.
	at org.apache.flink.runtime.operators.hash.HashPartition.spillPartition(HashPartition.java:288)
	at org.apache.flink.runtime.operators.hash.MutableHashTable.spillPartition(MutableHashTable.java:1108)
	at org.apache.flink.runtime.operators.hash.MutableHashTable.insertBucketEntry(MutableHashTable.java:934)
	at org.apache.flink.runtime.operators.hash.MutableHashTable.insertIntoTable(MutableHashTable.java:859)
	at org.apache.flink.runtime.operators.hash.MutableHashTable.buildTableFromSpilledPartition(MutableHashTable.java:819)
	at org.apache.flink.runtime.operators.hash.MutableHashTable.prepareNextPartition(MutableHashTable.java:517)
	at org.apache.flink.runtime.operators.hash.MutableHashTable.nextRecord(MutableHashTable.java:556)
	at org.apache.flink.runtime.operators.hash.NonReusingBuildFirstHashMatchIterator.callWithNextKey(NonReusingBuildFirstHashMatchIterator.java:104)
	at org.apache.flink.runtime.operators.JoinDriver.run(JoinDriver.java:208)
	at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:489)
	at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:354)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:579)
	at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12896384">FLINK-2763</key>
            <summary>Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sewen">Stephan Ewen</assignee>
                                    <reporter username="greghogan">Greg Hogan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 25 Sep 2015 12:55:11 +0000</created>
                <updated>Wed, 4 Nov 2015 15:04:46 +0000</updated>
                            <resolved>Wed, 4 Nov 2015 10:41:01 +0000</resolved>
                                    <version>0.10.0</version>
                                    <fixVersion>0.10.0</fixVersion>
                                    <component>Runtime / Coordination</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14933239" author="stephanewen" created="Mon, 28 Sep 2015 12:33:20 +0000"  >&lt;p&gt;If the join tries to spill a partition with only one buffer, then all partitions have only one buffer. All other buffers must be already used in the hash table and overflow segments.&lt;/p&gt;

&lt;p&gt;I initially assumed that such a situation could never occur (the way segments are distributed), but I think I may have been mistaken there. If this situation occurs (all partitions have one buffer), then the only space to free is overflow buffers.&lt;/p&gt;

&lt;p&gt;So we should actually look for partitions to spill by counting partition buffers and overflow buffers. In that case, there should be no lack of buffers before one partition has accumulated two buffers.&lt;/p&gt;</comment>
                            <comment id="14935070" author="stephanewen" created="Tue, 29 Sep 2015 12:12:40 +0000"  >&lt;p&gt;I have a fix coming up...&lt;/p&gt;</comment>
                            <comment id="14935148" author="stephanewen" created="Tue, 29 Sep 2015 13:23:06 +0000"  >&lt;p&gt;Fixed via af477563eb1acaab74da1a508c7e5fa37339c206&lt;/p&gt;</comment>
                            <comment id="14935149" author="stephanewen" created="Tue, 29 Sep 2015 13:23:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=greghogan&quot; class=&quot;user-hover&quot; rel=&quot;greghogan&quot;&gt;greghogan&lt;/a&gt; Can you check whether the latest master solves your problem and close the issue if it does (reopen if it does not) ?&lt;/p&gt;</comment>
                            <comment id="14935317" author="greghogan" created="Tue, 29 Sep 2015 15:19:40 +0000"  >&lt;p&gt;Success!&lt;/p&gt;</comment>
                            <comment id="14955693" author="f.pompermaier" created="Tue, 13 Oct 2015 21:15:28 +0000"  >&lt;p&gt;Still the same error using the current master (0.10-SNAPSHOT):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.lang.RuntimeException: Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers.
at org.apache.flink.runtime.operators.hash.HashPartition.spillPartition(HashPartition.java:301)
at org.apache.flink.runtime.operators.hash.MutableHashTable.spillPartition(MutableHashTable.java:1108)
at org.apache.flink.runtime.operators.hash.MutableHashTable.nextSegment(MutableHashTable.java:1277)
at org.apache.flink.runtime.operators.hash.HashPartition$BuildSideBuffer.nextSegment(HashPartition.java:523)
at org.apache.flink.runtime.memory.AbstractPagedOutputView.advance(AbstractPagedOutputView.java:140)
at org.apache.flink.runtime.memory.AbstractPagedOutputView.write(AbstractPagedOutputView.java:201)
at org.apache.flink.api.java.typeutils.runtime.DataOutputViewStream.write(DataOutputViewStream.java:39)
at com.esotericsoftware.kryo.io.Output.flush(Output.java:163)
at org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize(KryoSerializer.java:187)
at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.serialize(TupleSerializer.java:116)
at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.serialize(TupleSerializer.java:30)
at org.apache.flink.runtime.operators.hash.HashPartition.insertIntoBuildBuffer(HashPartition.java:256)
at org.apache.flink.runtime.operators.hash.MutableHashTable.insertIntoTable(MutableHashTable.java:856)
at org.apache.flink.runtime.operators.hash.MutableHashTable.buildInitialTable(MutableHashTable.java:685)
at org.apache.flink.runtime.operators.hash.MutableHashTable.open(MutableHashTable.java:443)
at org.apache.flink.runtime.operators.hash.NonReusingBuildSecondHashMatchIterator.open(NonReusingBuildSecondHashMatchIterator.java:85)
at org.apache.flink.runtime.operators.JoinDriver.prepare(JoinDriver.java:195)
at org.apache.flink.runtime.operators.BatchTask.run(BatchTask.java:459)
... 3 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14957123" author="stephanewen" created="Wed, 14 Oct 2015 15:50:45 +0000"  >&lt;p&gt;Thanks for reporting this. I&apos;ll try to look into this in the coming days. I may have overlooked a case in the previous fix.&lt;/p&gt;</comment>
                            <comment id="14957172" author="f.pompermaier" created="Wed, 14 Oct 2015 16:12:40 +0000"  >&lt;p&gt;Ok, just let me know if you need to test the patch or you need some more&lt;br/&gt;
debug info!&lt;/p&gt;

</comment>
                            <comment id="14958474" author="f.pompermaier" created="Thu, 15 Oct 2015 07:49:58 +0000"  >&lt;p&gt;I think that this bug could be related to &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2800&quot; title=&quot;kryo serialization problem&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2800&quot;&gt;&lt;del&gt;FLINK-2800&lt;/del&gt;&lt;/a&gt; and a bad implementation of the KryoSerializer..both output and kryo could be not thread safe somehow?&lt;/p&gt;</comment>
                            <comment id="14958485" author="stefano.bortoli" created="Thu, 15 Oct 2015 08:00:19 +0000"  >&lt;p&gt;Kryo serialization/deserialization is not threadsafe. In fact it is a good idea to use a pool of Kryo objects in general. However, it would mean that the same KryoSerializer is used concurrently, which I am not sure is supposed to happen. Fortunately, the twitter library used to instantiate the Kryo() offers pooled serialization/deserialization methods embedding borrow() and release() executors. It should be sufficient to extend the default pool to implement the KryoSerializer initialization, and then use that one. I will give it a try and report.&lt;/p&gt;</comment>
                            <comment id="14960455" author="f.pompermaier" created="Fri, 16 Oct 2015 10:07:01 +0000"  >&lt;p&gt;I don&apos;t know whether Stefano&apos;s patch made some difference or not (fixing the kryo serialization) but just removing the following code in the HashPartition made everything work in my case (actually I don&apos;t know it the results are correct or not but at least the process was able to complete..):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (getNumOccupiedMemorySegments() &amp;lt; 2) {
	&lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RuntimeException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Bug in Hybrid Hash Join: &quot;&lt;/span&gt; + &lt;span class=&quot;code-quote&quot;&gt;&quot;Request to spill a partition with less than two buffers.&quot;&lt;/span&gt;);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I hope this could be helpful..&lt;/p&gt;</comment>
                            <comment id="14989297" author="till.rohrmann" created="Wed, 4 Nov 2015 10:41:01 +0000"  >&lt;p&gt;I think the problem was solved by &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2964&quot; title=&quot;MutableHashTable fails when spilling partitions without overflow segments&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2964&quot;&gt;&lt;del&gt;FLINK-2964&lt;/del&gt;&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=f.pompermaier&quot; class=&quot;user-hover&quot; rel=&quot;f.pompermaier&quot;&gt;f.pompermaier&lt;/a&gt; could you check whether the fix 76bebd4236cd9cff19e6442e9ab3d6113665924a solves your problem?&lt;/p&gt;</comment>
                            <comment id="14989658" author="f.pompermaier" created="Wed, 4 Nov 2015 15:04:46 +0000"  >&lt;p&gt;That fixed also my problem. Thanks Till&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                                                <inwardlinks description="Is contained by">
                                        <issuelink>
            <issuekey id="12910212">FLINK-2964</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 2 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2lk8f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>