<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:35:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10809] Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10809</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;I&apos;ve tried using &lt;tt&gt;DataStreamUtils.reinterpretAsKeyedStream&lt;/tt&gt; for results of windowed aggregation:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
		DataStream&amp;lt;Tuple2&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, List&amp;lt;Event&amp;gt;&amp;gt;&amp;gt; eventStream4 = eventStream2.keyBy(Event::getKey)
			.window(SlidingEventTimeWindows.of(Time.milliseconds(150 * 3), Time.milliseconds(150)))
			.apply(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WindowFunction&amp;lt;Event, Tuple2&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, List&amp;lt;Event&amp;gt;&amp;gt;, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, TimeWindow&amp;gt;() {
				&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; serialVersionUID = 3166250579972849440L;

				@Override
				&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void apply(
					&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt; key, TimeWindow window, Iterable&amp;lt;Event&amp;gt; input,
					Collector&amp;lt;Tuple2&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, List&amp;lt;Event&amp;gt;&amp;gt;&amp;gt; out) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {

					out.collect(Tuple2.of(key, StreamSupport.stream(input.spliterator(), &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;).collect(Collectors.toList())));
				}
			});

		DataStreamUtils.reinterpretAsKeyedStream(eventStream4, events-&amp;gt; events.f0)
			.flatMap(createSlidingWindowCheckMapper(pt))
			.addSink(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PrintSinkFunction&amp;lt;&amp;gt;());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and then in the createSlidingWindowCheckMapper I verify that each event belongs to 3 consecutive windows, for which I keep contents of last window in ValueState. In a non-failure setup this check runs fine, but it misses few windows after restore at the beginning.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SlidingWindowCheckMapper &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; RichFlatMapFunction&amp;lt;Tuple2&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, List&amp;lt;Event&amp;gt;&amp;gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; {

	&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; serialVersionUID = -744070793650644485L;

	&lt;span class=&quot;code-comment&quot;&gt;/** This value state tracks previously seen events with the number of windows they appeared in. */&lt;/span&gt;
	&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;transient&lt;/span&gt; ValueState&amp;lt;List&amp;lt;Tuple2&amp;lt;Event, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt;&amp;gt;&amp;gt; previousWindow;

	&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; slideFactor;

	SlidingWindowCheckMapper(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; slideFactor) {
		&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.slideFactor = slideFactor;
	}

	@Override
	&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void open(Configuration parameters) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
		ValueStateDescriptor&amp;lt;List&amp;lt;Tuple2&amp;lt;Event, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt;&amp;gt;&amp;gt; previousWindowDescriptor =
			&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ValueStateDescriptor&amp;lt;&amp;gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;previousWindow&quot;&lt;/span&gt;,
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ListTypeInfo&amp;lt;&amp;gt;(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TupleTypeInfo&amp;lt;&amp;gt;(TypeInformation.of(Event.class), BasicTypeInfo.INT_TYPE_INFO)));

		previousWindow = getRuntimeContext().getState(previousWindowDescriptor);
	}

	@Override
	&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void flatMap(Tuple2&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, List&amp;lt;Event&amp;gt;&amp;gt; value, Collector&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; out) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
		List&amp;lt;Tuple2&amp;lt;Event, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt;&amp;gt; previousWindowValues = Optional.ofNullable(previousWindow.value()).orElseGet(
			Collections::emptyList);

		List&amp;lt;Event&amp;gt; newValues = value.f1;
		newValues.stream().reduce(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BinaryOperator&amp;lt;Event&amp;gt;() {
			@Override
			&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Event apply(Event event, Event event2) {
				&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (event2.getSequenceNumber() - 1 != event.getSequenceNumber()) {
					out.collect(&lt;span class=&quot;code-quote&quot;&gt;&quot;Alert: events in window out ouf order!&quot;&lt;/span&gt;);
				}

				&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; event2;
			}
		});

		List&amp;lt;Tuple2&amp;lt;Event, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt;&amp;gt; newWindow = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;();
		&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Tuple2&amp;lt;Event, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;&amp;gt; windowValue : previousWindowValues) {
			&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!newValues.contains(windowValue.f0)) {
				out.collect(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;Alert: event %s did not belong to %d consecutive windows. Event seen so far %d times.Current window: %s&quot;&lt;/span&gt;,
					windowValue.f0,
					slideFactor,
					windowValue.f1,
					value.f1));
			} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
				newValues.remove(windowValue.f0);
				&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (windowValue.f1 + 1 != slideFactor) {
					newWindow.add(Tuple2.of(windowValue.f0, windowValue.f1 + 1));
				}
			}
		}

		newValues.forEach(e -&amp;gt; newWindow.add(Tuple2.of(e, 1)));

		previousWindow.update(newWindow);
	}
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13196776">FLINK-10809</key>
            <summary>Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srichter">Stefan Richter</assignee>
                                    <reporter username="dwysakowicz">Dawid Wysakowicz</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 7 Nov 2018 09:36:45 +0000</created>
                <updated>Fri, 7 Dec 2018 10:36:08 +0000</updated>
                            <resolved>Fri, 7 Dec 2018 10:36:08 +0000</resolved>
                                    <version>1.5.5</version>
                    <version>1.6.2</version>
                    <version>1.7.0</version>
                                    <fixVersion>1.6.3</fixVersion>
                    <fixVersion>1.7.0</fixVersion>
                                    <component>API / DataStream</component>
                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16678454" author="githubbot" created="Wed, 7 Nov 2018 16:17:40 +0000"  >&lt;p&gt;StefanRRichter opened a new pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &#8230;ors in state assignment&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This PR includes keyed state that was not from a head operator (head of operator chain) in the state assignment. This fixes problems with restoring keyed state for operators after `DataStreamUtils.reinterpretAsKeyedStream`.&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Remove a check if keyed state is from a head operator in the state assignment algorithm. This was an optimization from the times where Flink only allowed keyed state in the head operators (like what happens after every `keyBy`).&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Extended `ReinterpretDataStreamAsKeyedStreamITCase` with a recovery cycle to test proper state restore of non-head operators.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (no)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)&lt;/li&gt;
	&lt;li&gt;The serializers: (no)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (no)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (no)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? ( no)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (not applicable)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16683356" author="githubbot" created="Mon, 12 Nov 2018 07:55:13 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#discussion_r232558772&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#discussion_r232558772&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -187,26 +208,71 @@ public void run(SourceContext&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; out) throws Exception {&lt;br/&gt;
 			this.running = true;&lt;br/&gt;
 			try {&lt;br/&gt;
 				while (running) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer key = din.readInt();&lt;/li&gt;
	&lt;li&gt;Integer val = din.readInt();&lt;/li&gt;
	&lt;li&gt;out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));&lt;br/&gt;
+&lt;br/&gt;
+					checkFail();&lt;br/&gt;
+&lt;br/&gt;
+					synchronized (out.getCheckpointLock()) 
{
+						Integer key = din.readInt();
+						Integer val = din.readInt();
+						out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));
+
+						position += 2 * Integer.BYTES;
+					}
&lt;p&gt; 				}&lt;br/&gt;
 			} catch (EOFException ignore) {&lt;br/&gt;
+				while (!isRestored) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   This while loop is a bit confusing for me.&lt;br/&gt;
   Isn&apos;t `isRestored` set only once in `initializeState`?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16683357" author="githubbot" created="Mon, 12 Nov 2018 07:55:13 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#discussion_r232559236&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#discussion_r232559236&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -227,5 +293,22 @@ public void close() throws Exception &lt;/p&gt;
{
 			Assert.assertEquals(expectedSum, runningSum);
 			super.close();
 		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
+			sumState.add(runningSum);
+		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
+			sumState = context.getOperatorStateStore().getListState(&lt;br/&gt;
+				new ListStateDescriptor&amp;lt;&amp;gt;(&quot;sumState&quot;, Integer.class));&lt;br/&gt;
+&lt;br/&gt;
+			if (context.isRestored()) {&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Where do we check whether or not we actually have restore something?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16683358" author="githubbot" created="Mon, 12 Nov 2018 07:55:13 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#discussion_r232551351&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#discussion_r232551351&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -156,15 +165,22 @@ public void invoke(Tuple2&amp;lt;Integer, Integer&amp;gt; value, Context context) throws Excep&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class FromPartitionFileSource extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; {&lt;br/&gt;
+	private static class FromPartitionFileSource extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt;&lt;br/&gt;
+	implements CheckpointedFunction, CheckpointListener {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   Needs proper indentation&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16683474" author="githubbot" created="Mon, 12 Nov 2018 09:47:09 +0000"  >&lt;p&gt;StefanRRichter commented on a change in pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#discussion_r232590240&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#discussion_r232590240&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -227,5 +293,22 @@ public void close() throws Exception &lt;/p&gt;
{
 			Assert.assertEquals(expectedSum, runningSum);
 			super.close();
 		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
+			sumState.add(runningSum);
+		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
+			sumState = context.getOperatorStateStore().getListState(&lt;br/&gt;
+				new ListStateDescriptor&amp;lt;&amp;gt;(&quot;sumState&quot;, Integer.class));&lt;br/&gt;
+&lt;br/&gt;
+			if (context.isRestored()) {&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Through through the restore flag and a validating sink? If state was dropped, the validation would go wrong.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16683716" author="githubbot" created="Mon, 12 Nov 2018 12:25:27 +0000"  >&lt;p&gt;tzulitai commented on a change in pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#discussion_r232637615&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#discussion_r232637615&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -187,26 +208,71 @@ public void run(SourceContext&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; out) throws Exception {&lt;br/&gt;
 			this.running = true;&lt;br/&gt;
 			try {&lt;br/&gt;
 				while (running) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer key = din.readInt();&lt;/li&gt;
	&lt;li&gt;Integer val = din.readInt();&lt;/li&gt;
	&lt;li&gt;out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));&lt;br/&gt;
+&lt;br/&gt;
+					checkFail();&lt;br/&gt;
+&lt;br/&gt;
+					synchronized (out.getCheckpointLock()) 
{
+						Integer key = din.readInt();
+						Integer val = din.readInt();
+						out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));
+
+						position += 2 * Integer.BYTES;
+					}
&lt;p&gt; 				}&lt;br/&gt;
 			} catch (EOFException ignore) {&lt;br/&gt;
+				while (!isRestored) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   Shouldn&apos;t then the `checkFail` call alone be enough? The `isRestored` flag is already checked there.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16683717" author="githubbot" created="Mon, 12 Nov 2018 12:26:12 +0000"  >&lt;p&gt;tzulitai commented on issue #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#issuecomment-437860559&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#issuecomment-437860559&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @StefanRRichter I only have one final comment about the while loop.&lt;br/&gt;
   Other than that, this LGTM &#128077; &lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16684123" author="githubbot" created="Mon, 12 Nov 2018 17:19:49 +0000"  >&lt;p&gt;StefanRRichter commented on a change in pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#discussion_r232744683&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#discussion_r232744683&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -187,26 +208,71 @@ public void run(SourceContext&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; out) throws Exception {&lt;br/&gt;
 			this.running = true;&lt;br/&gt;
 			try {&lt;br/&gt;
 				while (running) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer key = din.readInt();&lt;/li&gt;
	&lt;li&gt;Integer val = din.readInt();&lt;/li&gt;
	&lt;li&gt;out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));&lt;br/&gt;
+&lt;br/&gt;
+					checkFail();&lt;br/&gt;
+&lt;br/&gt;
+					synchronized (out.getCheckpointLock()) 
{
+						Integer key = din.readInt();
+						Integer val = din.readInt();
+						out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));
+
+						position += 2 * Integer.BYTES;
+					}
&lt;p&gt; 				}&lt;br/&gt;
 			} catch (EOFException ignore) {&lt;br/&gt;
+				while (!isRestored) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   Yeah, I guess we can just check it once in the beginning as an `if`.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16684125" author="githubbot" created="Mon, 12 Nov 2018 17:20:32 +0000"  >&lt;p&gt;StefanRRichter commented on issue #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048#issuecomment-437961859&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048#issuecomment-437961859&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Thanks for the review @tzulitai! Merging.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16684129" author="githubbot" created="Mon, 12 Nov 2018 17:24:03 +0000"  >&lt;p&gt;asfgit closed pull request #7048: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10809&quot; title=&quot;Using DataStreamUtils.reinterpretAsKeyedStream produces corrupted keyed state after restore&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10809&quot;&gt;&lt;del&gt;FLINK-10809&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;state&amp;#93;&lt;/span&gt; Include keyed state that is not from head operat&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/7048&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/7048&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java&lt;br/&gt;
index b0173886d57..02fc2013fb0 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/StateAssignmentOperation.java&lt;br/&gt;
@@ -71,13 +71,12 @@ public StateAssignmentOperation(&lt;br/&gt;
 		this.allowNonRestoredState = allowNonRestoredState;&lt;br/&gt;
 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public boolean assignStates() throws Exception {&lt;br/&gt;
+	public void assignStates() {&lt;br/&gt;
 		Map&amp;lt;OperatorID, OperatorState&amp;gt; localOperators = new HashMap&amp;lt;&amp;gt;(operatorStates);&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;JobVertexID, ExecutionJobVertex&amp;gt; localTasks = this.tasks;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		checkStateMappingCompleteness(allowNonRestoredState, operatorStates, tasks);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (Map.Entry&amp;lt;JobVertexID, ExecutionJobVertex&amp;gt; task : localTasks.entrySet()) {&lt;br/&gt;
+		for (Map.Entry&amp;lt;JobVertexID, ExecutionJobVertex&amp;gt; task : this.tasks.entrySet()) {&lt;br/&gt;
 			final ExecutionJobVertex executionJobVertex = task.getValue();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			// find the states of all operators belonging to this task&lt;br/&gt;
@@ -108,7 +107,6 @@ public boolean assignStates() throws Exception &lt;/p&gt;
{
 			assignAttemptState(task.getValue(), operatorStates);
 		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return true;&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	private void assignAttemptState(ExecutionJobVertex executionJobVertex, List&amp;lt;OperatorState&amp;gt; operatorStates) &lt;/p&gt;
{
@@ -254,10 +252,6 @@ public static OperatorSubtaskState operatorSubtaskStateFrom(
 			new StateObjectCollection&amp;lt;&amp;gt;(subRawKeyedState.getOrDefault(instanceID, Collections.emptyList())));
 	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static boolean isHeadOperator(int opIdx, List&amp;lt;OperatorID&amp;gt; operatorIDs) 
{
-		return opIdx == operatorIDs.size() - 1;
-	}
&lt;p&gt;-&lt;br/&gt;
 	public void checkParallelismPreconditions(List&amp;lt;OperatorState&amp;gt; operatorStates, ExecutionJobVertex executionJobVertex) {&lt;br/&gt;
 		for (OperatorState operatorState : operatorStates) {&lt;br/&gt;
 			checkParallelismPreconditions(operatorState, executionJobVertex);&lt;br/&gt;
@@ -278,19 +272,16 @@ private void reDistributeKeyedStates(&lt;br/&gt;
 		for (int operatorIndex = 0; operatorIndex &amp;lt; newOperatorIDs.size(); operatorIndex++) {&lt;br/&gt;
 			OperatorState operatorState = oldOperatorStates.get(operatorIndex);&lt;br/&gt;
 			int oldParallelism = operatorState.getParallelism();&lt;br/&gt;
-&lt;br/&gt;
 			for (int subTaskIndex = 0; subTaskIndex &amp;lt; newParallelism; subTaskIndex++) {&lt;br/&gt;
 				OperatorInstanceID instanceID = OperatorInstanceID.of(subTaskIndex, newOperatorIDs.get(operatorIndex));&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;if (isHeadOperator(operatorIndex, newOperatorIDs)) 
{
-					Tuple2&amp;lt;List&amp;lt;KeyedStateHandle&amp;gt;, List&amp;lt;KeyedStateHandle&amp;gt;&amp;gt; subKeyedStates = reAssignSubKeyedStates(
-						operatorState,
-						newKeyGroupPartitions,
-						subTaskIndex,
-						newParallelism,
-						oldParallelism);
-					newManagedKeyedState.put(instanceID, subKeyedStates.f0);
-					newRawKeyedState.put(instanceID, subKeyedStates.f1);
-				}
&lt;p&gt;+				Tuple2&amp;lt;List&amp;lt;KeyedStateHandle&amp;gt;, List&amp;lt;KeyedStateHandle&amp;gt;&amp;gt; subKeyedStates = reAssignSubKeyedStates(&lt;br/&gt;
+					operatorState,&lt;br/&gt;
+					newKeyGroupPartitions,&lt;br/&gt;
+					subTaskIndex,&lt;br/&gt;
+					newParallelism,&lt;br/&gt;
+					oldParallelism);&lt;br/&gt;
+				newManagedKeyedState.put(instanceID, subKeyedStates.f0);&lt;br/&gt;
+				newRawKeyedState.put(instanceID, subKeyedStates.f1);&lt;br/&gt;
 			}&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;br/&gt;
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
index fc8e9971683..c94319ed561 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/datastream/ReinterpretDataStreamAsKeyedStreamITCase.java&lt;br/&gt;
@@ -18,11 +18,18 @@&lt;br/&gt;
 package org.apache.flink.streaming.api.datastream;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import org.apache.flink.api.common.functions.ReduceFunction;&lt;br/&gt;
+import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
+import org.apache.flink.api.common.state.ListState;&lt;br/&gt;
+import org.apache.flink.api.common.state.ListStateDescriptor;&lt;br/&gt;
 import org.apache.flink.api.common.typeinfo.TypeInformation;&lt;br/&gt;
 import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
 import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
 import org.apache.flink.configuration.Configuration;&lt;br/&gt;
+import org.apache.flink.runtime.state.CheckpointListener;&lt;br/&gt;
+import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
+import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
 import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
 import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;&lt;br/&gt;
 import org.apache.flink.streaming.api.functions.source.ParallelSourceFunction;&lt;br/&gt;
@@ -73,6 +80,8 @@ public void testReinterpretAsKeyedStream() throws Exception {&lt;br/&gt;
 		env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime);&lt;br/&gt;
 		env.setMaxParallelism(maxParallelism);&lt;br/&gt;
 		env.setParallelism(parallelism);&lt;br/&gt;
+		env.enableCheckpointing(100);&lt;br/&gt;
+		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0L));&lt;/p&gt;

&lt;p&gt; 		final List&amp;lt;File&amp;gt; partitionFiles = new ArrayList&amp;lt;&amp;gt;(parallelism);&lt;br/&gt;
 		for (int i = 0; i &amp;lt; parallelism; ++i) &lt;/p&gt;
{
@@ -156,15 +165,22 @@ public void invoke(Tuple2&amp;lt;Integer, Integer&amp;gt; value, Context context) throws Excep
 		}
&lt;p&gt; 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class FromPartitionFileSource extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; {&lt;br/&gt;
+	private static class FromPartitionFileSource extends RichParallelSourceFunction&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt;&lt;br/&gt;
+	implements CheckpointedFunction, CheckpointListener {&lt;br/&gt;
 		private static final long serialVersionUID = 1L;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		private List&amp;lt;File&amp;gt; allPartitions;&lt;br/&gt;
 		private DataInputStream din;&lt;br/&gt;
 		private volatile boolean running;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public FromPartitionFileSource(List&amp;lt;File&amp;gt; allPartitons) {&lt;/li&gt;
	&lt;li&gt;this.allPartitions = allPartitons;&lt;br/&gt;
+		private long position;&lt;br/&gt;
+		private transient ListState&amp;lt;Long&amp;gt; positionState;&lt;br/&gt;
+		private transient boolean isRestored;&lt;br/&gt;
+&lt;br/&gt;
+		private transient volatile boolean canFail;&lt;br/&gt;
+&lt;br/&gt;
+		public FromPartitionFileSource(List&amp;lt;File&amp;gt; allPartitions) 
{
+			this.allPartitions = allPartitions;
 		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		@Override&lt;br/&gt;
@@ -174,6 +190,11 @@ public void open(Configuration parameters) throws Exception {&lt;br/&gt;
 			din = new DataInputStream(&lt;br/&gt;
 				new BufferedInputStream(&lt;br/&gt;
 					new FileInputStream(allPartitions.get(subtaskIdx))));&lt;br/&gt;
+&lt;br/&gt;
+			long toSkip = position;&lt;br/&gt;
+			while (toSkip &amp;gt; 0L) &lt;/p&gt;
{
+				toSkip -= din.skip(toSkip);
+			}
&lt;p&gt; 		}&lt;/p&gt;

&lt;p&gt; 		@Override&lt;br/&gt;
@@ -187,11 +208,27 @@ public void run(SourceContext&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; out) throws Exception {&lt;br/&gt;
 			this.running = true;&lt;br/&gt;
 			try {&lt;br/&gt;
 				while (running) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Integer key = din.readInt();&lt;/li&gt;
	&lt;li&gt;Integer val = din.readInt();&lt;/li&gt;
	&lt;li&gt;out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));&lt;br/&gt;
+&lt;br/&gt;
+					checkFail();&lt;br/&gt;
+&lt;br/&gt;
+					synchronized (out.getCheckpointLock()) 
{
+						Integer key = din.readInt();
+						Integer val = din.readInt();
+						out.collect(new Tuple2&amp;lt;&amp;gt;(key, val));
+
+						position += 2 * Integer.BYTES;
+					}
&lt;p&gt; 				}&lt;br/&gt;
 			} catch (EOFException ignore) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+				while (!isRestored) {
+					checkFail();
+				}+			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+		}&lt;br/&gt;
+&lt;br/&gt;
+		private void checkFail() throws Exception &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+			if (canFail) {
+				throw new Exception(&quot;Artificial failure.&quot;);
 			} 		}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -199,14 +236,43 @@ public void run(SourceContext&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; out) throws Exception {&lt;br/&gt;
 		public void cancel() &lt;/p&gt;
{
 			this.running = false;
 		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void notifyCheckpointComplete(long checkpointId) &lt;/p&gt;
{
+			canFail = !isRestored;
+		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
+			positionState.add(position);
+		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
+			canFail = false;&lt;br/&gt;
+			position = 0L;&lt;br/&gt;
+			isRestored = context.isRestored();&lt;br/&gt;
+			positionState = context.getOperatorStateStore().getListState(&lt;br/&gt;
+				new ListStateDescriptor&amp;lt;&amp;gt;(&quot;posState&quot;, Long.class));&lt;br/&gt;
+&lt;br/&gt;
+			if (isRestored) {&lt;br/&gt;
+&lt;br/&gt;
+				for (Long value : positionState.get()) &lt;/p&gt;
{
+					position += value;
+				}
&lt;p&gt;+			}&lt;br/&gt;
+		}&lt;br/&gt;
 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class ValidatingSink extends RichSinkFunction&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt; {&lt;br/&gt;
+	private static class ValidatingSink extends RichSinkFunction&amp;lt;Tuple2&amp;lt;Integer, Integer&amp;gt;&amp;gt;&lt;br/&gt;
+		implements CheckpointedFunction {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		private static final long serialVersionUID = 1L;&lt;br/&gt;
 		private final int expectedSum;&lt;br/&gt;
 		private int runningSum = 0;&lt;/p&gt;

&lt;p&gt;+		private transient ListState&amp;lt;Integer&amp;gt; sumState;&lt;br/&gt;
+&lt;br/&gt;
 		private ValidatingSink(int expectedSum) &lt;/p&gt;
{
 			this.expectedSum = expectedSum;
 		}
&lt;p&gt;@@ -227,5 +293,22 @@ public void close() throws Exception &lt;/p&gt;
{
 			Assert.assertEquals(expectedSum, runningSum);
 			super.close();
 		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void snapshotState(FunctionSnapshotContext context) throws Exception &lt;/p&gt;
{
+			sumState.add(runningSum);
+		}
&lt;p&gt;+&lt;br/&gt;
+		@Override&lt;br/&gt;
+		public void initializeState(FunctionInitializationContext context) throws Exception {&lt;br/&gt;
+			sumState = context.getOperatorStateStore().getListState(&lt;br/&gt;
+				new ListStateDescriptor&amp;lt;&amp;gt;(&quot;sumState&quot;, Integer.class));&lt;br/&gt;
+&lt;br/&gt;
+			if (context.isRestored()) {&lt;br/&gt;
+				for (Integer value : sumState.get()) &lt;/p&gt;
{
+					runningSum += value;
+				}
&lt;p&gt;+			}&lt;br/&gt;
+		}&lt;br/&gt;
 	}&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16684141" author="srichter" created="Mon, 12 Nov 2018 17:30:02 +0000"  >&lt;p&gt;Merged in:&lt;br/&gt;
master: bf760f9312&lt;br/&gt;
release-1.7: 45ad36fd75&lt;br/&gt;
release-1.6: 64c22cf245&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13196795">FLINK-10810</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 1 week, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s007so:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>