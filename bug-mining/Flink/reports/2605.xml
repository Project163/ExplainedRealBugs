<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:34:43 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10175] Fix concurrent access to shared buffer in map state / querable state</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10175</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Accidental sharing of buffers between event processing loop and queryable state thread can happen in &lt;tt&gt;RocksDBMapState::deserializeUserKey&lt;/tt&gt;. Queryable state should provide a separate buffer.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13179909">FLINK-10175</key>
            <summary>Fix concurrent access to shared buffer in map state / querable state</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srichter">Stefan Richter</assignee>
                                    <reporter username="srichter">Stefan Richter</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 20 Aug 2018 09:06:55 +0000</created>
                <updated>Wed, 21 Nov 2018 10:58:32 +0000</updated>
                            <resolved>Wed, 22 Aug 2018 11:35:55 +0000</resolved>
                                    <version>1.7.0</version>
                                    <fixVersion>1.7.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16585676" author="githubbot" created="Mon, 20 Aug 2018 09:17:11 +0000"  >&lt;p&gt;StefanRRichter opened a new pull request #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixing a shared buffer between two threads in `RocksDBMapState``-Replacing `ByteArrayData&lt;span class=&quot;error&quot;&gt;&amp;#91;Input|Output&amp;#93;&lt;/span&gt;View` with slightly enhanced versions of the already existing `Data&lt;span class=&quot;error&quot;&gt;&amp;#91;Output|InputDe&amp;#93;&lt;/span&gt;Serializer`&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This change is a trivial rework / code cleanup without any test coverage.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (no)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)&lt;/li&gt;
	&lt;li&gt;The serializers: (no)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (yes)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (no)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (no)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (not applicable)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16585677" author="githubbot" created="Mon, 20 Aug 2018 09:17:21 +0000"  >&lt;p&gt;StefanRRichter commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414251833&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414251833&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   CC @azagrebin &lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587519" author="githubbot" created="Tue, 21 Aug 2018 14:38:50 +0000"  >&lt;p&gt;kl0u commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414697718&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414697718&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   I was hoping that this also solves &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10138&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-10138&lt;/a&gt; but when running it locally, the queryable state end-to-end test still seems to be failing. Any other clues @StefanRRichter or @azagrebin where this may be coming from?&lt;/p&gt;

&lt;p&gt;   The command to run the test locally is:&lt;br/&gt;
   ```&lt;br/&gt;
   FLINK_DIR=YOUR_FLINK_DIR ./run-single-test.sh FLINK_DIR/test-scripts/test_queryable_state.sh &quot;rocksdb&quot;&lt;br/&gt;
   ```&lt;/p&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587528" author="githubbot" created="Tue, 21 Aug 2018 14:42:43 +0000"  >&lt;p&gt;kl0u edited a comment on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414697718&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414697718&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   I was hoping that this also solves &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10138&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-10138&lt;/a&gt; but when running it locally, the queryable state end-to-end test still seems to be failing. Any other clues @StefanRRichter or @azagrebin where this may be coming from?&lt;/p&gt;

&lt;p&gt;   The command to run the test locally is:&lt;br/&gt;
   ```&lt;br/&gt;
   FLINK_DIR=YOUR_FLINK_DIR ./run-single-test.sh FLINK_DIR/test-scripts/test_queryable_state.sh &quot;rocksdb&quot;&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;   I would also feel more comfortable if you could also verify that the issue is *&lt;b&gt;not&lt;/b&gt;* solved.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587550" author="githubbot" created="Tue, 21 Aug 2018 14:59:16 +0000"  >&lt;p&gt;StefanRRichter commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414705351&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414705351&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @kl0u failing with which exception exactly?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587553" author="githubbot" created="Tue, 21 Aug 2018 15:00:26 +0000"  >&lt;p&gt;kl0u commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414705770&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414705770&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   ```&lt;br/&gt;
   Exception in thread &quot;main&quot; java.util.concurrent.ExecutionException: java.lang.RuntimeException: Failed request 73.&lt;br/&gt;
    Caused by: java.lang.RuntimeException: Failed request 73.&lt;br/&gt;
    Caused by: java.lang.RuntimeException: Error while processing request with ID 73. Caused by: java.lang.ArrayIndexOutOfBoundsException: 17&lt;br/&gt;
   	at org.apache.flink.core.memory.DataInputDeserializer.readBoolean(DataInputDeserializer.java:123)&lt;br/&gt;
   	at org.apache.flink.api.java.typeutils.runtime.PojoSerializer.deserialize(PojoSerializer.java:405)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState.deserializeUserValue(RocksDBMapState.java:353)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState.access$100(RocksDBMapState.java:66)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState$RocksDBMapEntry.getValue(RocksDBMapState.java:454)&lt;br/&gt;
   	at org.apache.flink.queryablestate.client.state.serialization.KvStateSerializer.serializeMap(KvStateSerializer.java:222)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState.getSerializedValue(RocksDBMapState.java:298)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.getSerializedValue(KvStateServerHandler.java:107)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:84)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:48)&lt;br/&gt;
   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.run(AbstractServerHandler.java:236)&lt;br/&gt;
   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:95)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:48)&lt;br/&gt;
   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.run(AbstractServerHandler.java:236)&lt;br/&gt;
   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.lambda$run$11(AbstractServerHandler.java:273)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.uniWhenCompleteStage(CompletableFuture.java:778)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.whenComplete(CompletableFuture.java:2140)&lt;br/&gt;
   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.run(AbstractServerHandler.java:236)&lt;br/&gt;
   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;   	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)&lt;br/&gt;
   	at org.apache.flink.streaming.tests.queryablestate.QsStateClient.getMapState(QsStateClient.java:121)&lt;br/&gt;
   	at org.apache.flink.streaming.tests.queryablestate.QsStateClient.main(QsStateClient.java:93)&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587555" author="githubbot" created="Tue, 21 Aug 2018 15:00:40 +0000"  >&lt;p&gt;kl0u edited a comment on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414705770&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414705770&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @StefanRRichter &lt;br/&gt;
   ```&lt;br/&gt;
   Exception in thread &quot;main&quot; java.util.concurrent.ExecutionException: java.lang.RuntimeException: Failed request 73.&lt;br/&gt;
    Caused by: java.lang.RuntimeException: Failed request 73.&lt;br/&gt;
    Caused by: java.lang.RuntimeException: Error while processing request with ID 73. Caused by: java.lang.ArrayIndexOutOfBoundsException: 17&lt;br/&gt;
   	at org.apache.flink.core.memory.DataInputDeserializer.readBoolean(DataInputDeserializer.java:123)&lt;br/&gt;
   	at org.apache.flink.api.java.typeutils.runtime.PojoSerializer.deserialize(PojoSerializer.java:405)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState.deserializeUserValue(RocksDBMapState.java:353)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState.access$100(RocksDBMapState.java:66)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState$RocksDBMapEntry.getValue(RocksDBMapState.java:454)&lt;br/&gt;
   	at org.apache.flink.queryablestate.client.state.serialization.KvStateSerializer.serializeMap(KvStateSerializer.java:222)&lt;br/&gt;
   	at org.apache.flink.contrib.streaming.state.RocksDBMapState.getSerializedValue(RocksDBMapState.java:298)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.getSerializedValue(KvStateServerHandler.java:107)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:84)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:48)&lt;br/&gt;
   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.run(AbstractServerHandler.java:236)&lt;br/&gt;
   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:95)&lt;br/&gt;
   	at org.apache.flink.queryablestate.server.KvStateServerHandler.handleRequest(KvStateServerHandler.java:48)&lt;br/&gt;
   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.run(AbstractServerHandler.java:236)&lt;br/&gt;
   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.lambda$run$11(AbstractServerHandler.java:273)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.uniWhenCompleteStage(CompletableFuture.java:778)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.whenComplete(CompletableFuture.java:2140)&lt;br/&gt;
   	at org.apache.flink.queryablestate.network.AbstractServerHandler$AsyncRequestTask.run(AbstractServerHandler.java:236)&lt;br/&gt;
   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
   	at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
   	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;   	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)&lt;br/&gt;
   	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)&lt;br/&gt;
   	at org.apache.flink.streaming.tests.queryablestate.QsStateClient.getMapState(QsStateClient.java:121)&lt;br/&gt;
   	at org.apache.flink.streaming.tests.queryablestate.QsStateClient.main(QsStateClient.java:93)&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587562" author="githubbot" created="Tue, 21 Aug 2018 15:06:34 +0000"  >&lt;p&gt;StefanRRichter commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414708037&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414708037&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Sure, I see that makes sense...same problem of course applies to user key AND user value. Will update the PR.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587563" author="githubbot" created="Tue, 21 Aug 2018 15:07:35 +0000"  >&lt;p&gt;kl0u commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414708446&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414708446&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Perfect! Thanks a lot @StefanRRichter .&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587582" author="githubbot" created="Tue, 21 Aug 2018 15:21:45 +0000"  >&lt;p&gt;StefanRRichter commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414713526&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414713526&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Alright, this should do the job.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16588675" author="githubbot" created="Wed, 22 Aug 2018 10:29:22 +0000"  >&lt;p&gt;StefanRRichter commented on issue #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583#issuecomment-414987221&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583#issuecomment-414987221&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Thanks for the review @kl0u ! Merging.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16588737" author="githubbot" created="Wed, 22 Aug 2018 11:35:48 +0000"  >&lt;p&gt;asfgit closed pull request #6583: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10175&quot; title=&quot;Fix concurrent access to shared buffer in map state / querable state&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10175&quot;&gt;&lt;del&gt;FLINK-10175&lt;/del&gt;&lt;/a&gt; Fix concurrent access to shared buffer between RocksDBMapState and querable state&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6583&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6583&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/util/serialization/TypeInformationKeyValueSerializationSchema.java b/flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/util/serialization/TypeInformationKeyValueSerializationSchema.java&lt;br/&gt;
index 3be5779ceec..cc4a54bfeef 100644&lt;br/&gt;
&amp;#8212; a/flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/util/serialization/TypeInformationKeyValueSerializationSchema.java&lt;br/&gt;
+++ b/flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/util/serialization/TypeInformationKeyValueSerializationSchema.java&lt;br/&gt;
@@ -101,11 +101,11 @@ public TypeInformationKeyValueSerializationSchema(Class&amp;lt;K&amp;gt; keyClass, Class&amp;lt;V&amp;gt; va&lt;br/&gt;
 		V value = null;&lt;/p&gt;

&lt;p&gt; 		if (messageKey != null) &lt;/p&gt;
{
-			inputDeserializer.setBuffer(messageKey, 0, messageKey.length);
+			inputDeserializer.setBuffer(messageKey);
 			key = keySerializer.deserialize(inputDeserializer);
 		}
&lt;p&gt; 		if (message != null) &lt;/p&gt;
{
-			inputDeserializer.setBuffer(message, 0, message.length);
+			inputDeserializer.setBuffer(message);
 			value = valueSerializer.deserialize(inputDeserializer);
 		}
&lt;p&gt; 		return new Tuple2&amp;lt;&amp;gt;(key, value);&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/api/common/serialization/TypeInformationSerializationSchema.java b/flink-core/src/main/java/org/apache/flink/api/common/serialization/TypeInformationSerializationSchema.java&lt;br/&gt;
index 78da3fadc3e..6be265a5152 100644&lt;br/&gt;
&amp;#8212; a/flink-core/src/main/java/org/apache/flink/api/common/serialization/TypeInformationSerializationSchema.java&lt;br/&gt;
+++ b/flink-core/src/main/java/org/apache/flink/api/common/serialization/TypeInformationSerializationSchema.java&lt;br/&gt;
@@ -81,9 +81,9 @@ public TypeInformationSerializationSchema(TypeInformation&amp;lt;T&amp;gt; typeInfo, TypeSeria&lt;br/&gt;
 	@Override&lt;br/&gt;
 	public T deserialize(byte[] message) {&lt;br/&gt;
 		if (dis != null) &lt;/p&gt;
{
-			dis.setBuffer(message, 0, message.length);
+			dis.setBuffer(message);
 		}
&lt;p&gt; else &lt;/p&gt;
{
-			dis = new DataInputDeserializer(message, 0, message.length);
+			dis = new DataInputDeserializer(message);
 		}

&lt;p&gt; 		try {&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/core/memory/ByteArrayDataInputView.java b/flink-core/src/main/java/org/apache/flink/core/memory/ByteArrayDataInputView.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 698a9f97dc0..00000000000&lt;br/&gt;
&amp;#8212; a/flink-core/src/main/java/org/apache/flink/core/memory/ByteArrayDataInputView.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,60 +0,0 @@&lt;br/&gt;
-/*&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one&lt;/li&gt;
	&lt;li&gt;* or more contributor license agreements.  See the NOTICE file&lt;/li&gt;
	&lt;li&gt;* distributed with this work for additional information&lt;/li&gt;
	&lt;li&gt;* regarding copyright ownership.  The ASF licenses this file&lt;/li&gt;
	&lt;li&gt;* to you under the Apache License, Version 2.0 (the&lt;/li&gt;
	&lt;li&gt;* &quot;License&quot;); you may not use this file except in compliance&lt;/li&gt;
	&lt;li&gt;* with the License.  You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-&lt;br/&gt;
-package org.apache.flink.core.memory;&lt;br/&gt;
-&lt;br/&gt;
-import javax.annotation.Nonnull;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;/li&gt;
	&lt;li&gt;* Reusable adapter to 
{@link DataInputView}
&lt;p&gt; that operates on given byte-arrays.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-public class ByteArrayDataInputView extends DataInputViewStreamWrapper {&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@Nonnull&lt;/li&gt;
	&lt;li&gt;private final ByteArrayInputStreamWithPos inStreamWithPos;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public ByteArrayDataInputView() 
{
-		super(new ByteArrayInputStreamWithPos());
-		this.inStreamWithPos = (ByteArrayInputStreamWithPos) in;
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public ByteArrayDataInputView(@Nonnull byte[] buffer) 
{
-		this(buffer, 0, buffer.length);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public ByteArrayDataInputView(@Nonnull byte[] buffer, int offset, int length) 
{
-		this();
-		setData(buffer, offset, length);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public int getPosition() 
{
-		return inStreamWithPos.getPosition();
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public void setPosition(int pos) 
{
-		inStreamWithPos.setPosition(pos);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public void setData(@Nonnull byte[] buffer, int offset, int length) 
{
-		inStreamWithPos.setBuffer(buffer, offset, length);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public void setData(@Nonnull byte[] buffer) 
{
-		setData(buffer, 0, buffer.length);
-	}
&lt;p&gt;-}&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/core/memory/ByteArrayDataOutputView.java b/flink-core/src/main/java/org/apache/flink/core/memory/ByteArrayDataOutputView.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index a96f3d3fef1..00000000000&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-core/src/main/java/org/apache/flink/core/memory/ByteArrayDataOutputView.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,61 +0,0 @@&lt;br/&gt;
-/*&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one&lt;/li&gt;
	&lt;li&gt;* or more contributor license agreements.  See the NOTICE file&lt;/li&gt;
	&lt;li&gt;* distributed with this work for additional information&lt;/li&gt;
	&lt;li&gt;* regarding copyright ownership.  The ASF licenses this file&lt;/li&gt;
	&lt;li&gt;* to you under the Apache License, Version 2.0 (the&lt;/li&gt;
	&lt;li&gt;* &quot;License&quot;); you may not use this file except in compliance&lt;/li&gt;
	&lt;li&gt;* with the License.  You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-&lt;br/&gt;
-package org.apache.flink.core.memory;&lt;br/&gt;
-&lt;br/&gt;
-import javax.annotation.Nonnull;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;/li&gt;
	&lt;li&gt;* Adapter to 
{@link DataOutputView}
&lt;p&gt; that operates on a byte-array and offers read/write access to the current position.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-public class ByteArrayDataOutputView extends DataOutputViewStreamWrapper {&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@Nonnull&lt;/li&gt;
	&lt;li&gt;private final ByteArrayOutputStreamWithPos outputStreamWithPos;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public ByteArrayDataOutputView() 
{
-		this(64);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public ByteArrayDataOutputView(int initialSize) 
{
-		super(new ByteArrayOutputStreamWithPos(initialSize));
-		this.outputStreamWithPos = (ByteArrayOutputStreamWithPos) out;
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public void reset() 
{
-		outputStreamWithPos.reset();
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Nonnull&lt;/li&gt;
	&lt;li&gt;public byte[] toByteArray() 
{
-		return outputStreamWithPos.toByteArray();
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public int getPosition() 
{
-		return outputStreamWithPos.getPosition();
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public void setPosition(int position) 
{
-		outputStreamWithPos.setPosition(position);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Nonnull&lt;/li&gt;
	&lt;li&gt;public byte[] getInternalBufferReference() 
{
-		return outputStreamWithPos.getBuf();
-	}
&lt;p&gt;-}&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/core/memory/DataInputDeserializer.java b/flink-core/src/main/java/org/apache/flink/core/memory/DataInputDeserializer.java&lt;br/&gt;
index 11973e836c9..ffdd828e77d 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-core/src/main/java/org/apache/flink/core/memory/DataInputDeserializer.java&lt;br/&gt;
+++ b/flink-core/src/main/java/org/apache/flink/core/memory/DataInputDeserializer.java&lt;br/&gt;
@@ -18,6 +18,9 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package org.apache.flink.core.memory;&lt;/p&gt;

&lt;p&gt;+import javax.annotation.Nonnull;&lt;br/&gt;
+import javax.annotation.Nullable;&lt;br/&gt;
+&lt;br/&gt;
 import java.io.EOFException;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.io.UTFDataFormatException;&lt;br/&gt;
@@ -29,6 +32,7 @@&lt;br/&gt;
  */&lt;br/&gt;
 public class DataInputDeserializer implements DataInputView, java.io.Serializable {&lt;/p&gt;

&lt;p&gt;+	private static final byte[] EMPTY = new byte&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;br/&gt;
 	private static final long serialVersionUID = 1L;&lt;/p&gt;

&lt;p&gt; 	// ------------------------------------------------------------------------&lt;br/&gt;
@@ -41,17 +45,19 @@&lt;/p&gt;

&lt;p&gt; 	// ------------------------------------------------------------------------&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public DataInputDeserializer() {}&lt;br/&gt;
+	public DataInputDeserializer() 
{
+		setBuffer(EMPTY);
+	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public DataInputDeserializer(byte[] buffer) {&lt;/li&gt;
	&lt;li&gt;setBuffer(buffer, 0, buffer.length);&lt;br/&gt;
+	public DataInputDeserializer(@Nonnull byte[] buffer) 
{
+		setBufferInternal(buffer, 0, buffer.length);
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public DataInputDeserializer(byte[] buffer, int start, int len) {&lt;br/&gt;
+	public DataInputDeserializer(@Nonnull byte[] buffer, int start, int len) 
{
 		setBuffer(buffer, start, len);
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public DataInputDeserializer(ByteBuffer buffer) {&lt;br/&gt;
+	public DataInputDeserializer(@Nonnull ByteBuffer buffer) 
{
 		setBuffer(buffer);
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -59,7 +65,7 @@ public DataInputDeserializer(ByteBuffer buffer) {&lt;br/&gt;
 	//  Changing buffers&lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void setBuffer(ByteBuffer buffer) {&lt;br/&gt;
+	public void setBuffer(@Nonnull ByteBuffer buffer) {&lt;br/&gt;
 		if (buffer.hasArray()) {&lt;br/&gt;
 			this.buffer = buffer.array();&lt;br/&gt;
 			this.position = buffer.arrayOffset() + buffer.position();&lt;br/&gt;
@@ -76,15 +82,20 @@ public void setBuffer(ByteBuffer buffer) {&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void setBuffer(byte[] buffer, int start, int len) {&lt;/li&gt;
	&lt;li&gt;if (buffer == null) 
{
-			throw new NullPointerException();
-		}
&lt;p&gt;+	public void setBuffer(@Nonnull byte[] buffer, int start, int len) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		if (start &amp;lt; 0 || len &amp;lt; 0 || start + len &amp;gt; buffer.length) &lt;/p&gt;
{
-			throw new IllegalArgumentException();
+			throw new IllegalArgumentException(&quot;Invalid bounds.&quot;);
 		}

&lt;p&gt;+		setBufferInternal(buffer, start, len);&lt;br/&gt;
+	}&lt;br/&gt;
+&lt;br/&gt;
+	public void setBuffer(@Nonnull byte[] buffer) &lt;/p&gt;
{
+		setBufferInternal(buffer, 0, buffer.length);
+	}
&lt;p&gt;+&lt;br/&gt;
+	private void setBufferInternal(@Nonnull byte[] buffer, int start, int len) {&lt;br/&gt;
 		this.buffer = buffer;&lt;br/&gt;
 		this.position = start;&lt;br/&gt;
 		this.end = start + len;&lt;br/&gt;
@@ -144,12 +155,12 @@ public float readFloat() throws IOException {&lt;br/&gt;
 	}&lt;/p&gt;

&lt;p&gt; 	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void readFully(byte[] b) throws IOException {&lt;br/&gt;
+	public void readFully(@Nonnull byte[] b) throws IOException 
{
 		readFully(b, 0, b.length);
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void readFully(byte[] b, int off, int len) throws IOException {&lt;br/&gt;
+	public void readFully(@Nonnull byte[] b, int off, int len) throws IOException {&lt;br/&gt;
 		if (len &amp;gt;= 0) {&lt;br/&gt;
 			if (off &amp;lt;= b.length - len) {&lt;br/&gt;
 				if (this.position &amp;lt;= this.end - len) {&lt;br/&gt;
@@ -161,7 +172,7 @@ public void readFully(byte[] b, int off, int len) throws IOException {&lt;br/&gt;
 			} else 
{
 				throw new ArrayIndexOutOfBoundsException();
 			}&lt;/li&gt;
	&lt;li&gt;} else if (len &amp;lt; 0) 
{
+		}
&lt;p&gt; else &lt;/p&gt;
{
 			throw new IllegalArgumentException(&quot;Length may not be negative.&quot;);
 		}
&lt;p&gt; 	}&lt;br/&gt;
@@ -182,6 +193,7 @@ public int readInt() throws IOException {&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+	@Nullable&lt;br/&gt;
 	@Override&lt;br/&gt;
 	public String readLine() throws IOException {&lt;br/&gt;
 		if (this.position &amp;lt; this.end) {&lt;br/&gt;
@@ -229,6 +241,7 @@ public short readShort() throws IOException {&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/p&gt;

&lt;p&gt;+	@Nonnull&lt;br/&gt;
 	@Override&lt;br/&gt;
 	public String readUTF() throws IOException {&lt;br/&gt;
 		int utflen = readUnsignedShort();&lt;br/&gt;
@@ -319,7 +332,7 @@ public int readUnsignedShort() throws IOException {&lt;br/&gt;
 	}&lt;/p&gt;

&lt;p&gt; 	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public int skipBytes(int n) throws IOException {&lt;br/&gt;
+	public int skipBytes(int n) {&lt;br/&gt;
 		if (this.position &amp;lt;= this.end - n) {&lt;br/&gt;
 			this.position += n;&lt;br/&gt;
 			return n;&lt;br/&gt;
@@ -340,10 +353,7 @@ public void skipBytesToRead(int numBytes) throws IOException {&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public int read(byte[] b, int off, int len) throws IOException {&lt;/li&gt;
	&lt;li&gt;if (b == null)
{
-			throw new NullPointerException(&quot;Byte array b cannot be null.&quot;);
-		}
&lt;p&gt;+	public int read(@Nonnull byte[] b, int off, int len) throws IOException {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		if (off &amp;lt; 0){&lt;br/&gt;
 			throw new IndexOutOfBoundsException(&quot;Offset cannot be negative.&quot;);&lt;br/&gt;
@@ -370,10 +380,14 @@ public int read(byte[] b, int off, int len) throws IOException {&lt;br/&gt;
 	}&lt;/p&gt;

&lt;p&gt; 	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public int read(byte[] b) throws IOException {&lt;br/&gt;
+	public int read(@Nonnull byte[] b) throws IOException 
{
 		return read(b, 0, b.length);
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+	public int getPosition() &lt;/p&gt;
{
+		return position;
+	}
&lt;p&gt;+&lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;br/&gt;
 	//  Utilities&lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/ttl/TtlStateSnapshotTransformer.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/ttl/TtlStateSnapshotTransformer.java&lt;br/&gt;
index 1ee05cd0392..e3706ec2944 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/state/ttl/TtlStateSnapshotTransformer.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/ttl/TtlStateSnapshotTransformer.java&lt;br/&gt;
@@ -19,7 +19,7 @@&lt;br/&gt;
 package org.apache.flink.runtime.state.ttl;&lt;/p&gt;

&lt;p&gt; import org.apache.flink.api.common.typeutils.base.LongSerializer;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
 import org.apache.flink.runtime.state.StateSnapshotTransformer;&lt;br/&gt;
 import org.apache.flink.runtime.state.StateSnapshotTransformer.CollectionStateSnapshotTransformer;&lt;br/&gt;
 import org.apache.flink.util.FlinkRuntimeException;&lt;br/&gt;
@@ -34,12 +34,12 @@&lt;br/&gt;
 abstract class TtlStateSnapshotTransformer&amp;lt;T&amp;gt; implements CollectionStateSnapshotTransformer&amp;lt;T&amp;gt; {&lt;br/&gt;
 	private final TtlTimeProvider ttlTimeProvider;&lt;br/&gt;
 	final long ttl;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final ByteArrayDataInputView div;&lt;br/&gt;
+	private final DataInputDeserializer div;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	TtlStateSnapshotTransformer(@Nonnull TtlTimeProvider ttlTimeProvider, long ttl) &lt;/p&gt;
{
 		this.ttlTimeProvider = ttlTimeProvider;
 		this.ttl = ttl;
-		this.div = new ByteArrayDataInputView();
+		this.div = new DataInputDeserializer();
 	}

&lt;p&gt; 	&amp;lt;V&amp;gt; TtlValue&amp;lt;V&amp;gt; filterTtlValue(TtlValue&amp;lt;V&amp;gt; value) {&lt;br/&gt;
@@ -55,7 +55,7 @@ boolean expired(long ts) {&lt;br/&gt;
 	}&lt;/p&gt;

&lt;p&gt; 	long deserializeTs(byte[] value) throws IOException &lt;/p&gt;
{
-		div.setData(value, 0, Long.BYTES);
+		div.setBuffer(value, 0, Long.BYTES);
 		return LongSerializer.INSTANCE.deserialize(div);
 	}

&lt;p&gt;diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java&lt;br/&gt;
index 2a9ab7589a9..8c0f4d7da7b 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java&lt;br/&gt;
@@ -61,7 +61,7 @@ SV getInternal(byte[] key) {&lt;br/&gt;
 			if (valueBytes == null) &lt;/p&gt;
{
 				return null;
 			}&lt;br/&gt;
-			dataInputView.setData(valueBytes);&lt;br/&gt;
+			dataInputView.setBuffer(valueBytes);&lt;br/&gt;
 			return valueSerializer.deserialize(dataInputView);&lt;br/&gt;
 		} catch (IOException | RocksDBException e) {
 			throw new FlinkRuntimeException(&quot;Error while retrieving data from RocksDB&quot;, e);
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java
index 65b7f1fa4a7..8b8fbb23a99 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java
@@ -20,8 +20,8 @@
 import org.apache.flink.api.common.state.State;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.api.java.tuple.Tuple2;
-import org.apache.flink.core.memory.ByteArrayDataInputView;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;
+import org.apache.flink.core.memory.DataInputDeserializer;
+import org.apache.flink.core.memory.DataOutputSerializer;
 import org.apache.flink.queryablestate.client.state.serialization.KvStateSerializer;
 import org.apache.flink.runtime.state.KeyGroupRangeAssignment;
 import org.apache.flink.runtime.state.internal.InternalKvState;
@@ -66,9 +66,9 @@
 
 	protected final WriteOptions writeOptions;
 
-	protected final ByteArrayDataOutputView dataOutputView;
+	protected final DataOutputSerializer dataOutputView;
 
-	protected final ByteArrayDataInputView dataInputView;
+	protected final DataInputDeserializer dataInputView;
 
 	private final boolean ambiguousKeyPossible;
 
@@ -97,8 +97,8 @@ protected AbstractRocksDBState(
 		this.valueSerializer = Preconditions.checkNotNull(valueSerializer, &quot;State value serializer&quot;);
 		this.defaultValue = defaultValue;
 
-		this.dataOutputView = new ByteArrayDataOutputView(128);
-		this.dataInputView = new ByteArrayDataInputView();
+		this.dataOutputView = new DataOutputSerializer(128);
+		this.dataInputView = new DataInputDeserializer();
 		this.ambiguousKeyPossible =
 			RocksDBKeySerializationUtils.isAmbiguousKeyPossible(backend.getKeySerializer(), namespaceSerializer);
 	}&lt;br/&gt;
@@ -109,7 +109,7 @@ protected AbstractRocksDBState(&lt;br/&gt;
 	public void clear() {&lt;br/&gt;
 		try {
 			writeCurrentKeyWithGroupAndNamespace();
-			byte[] key = dataOutputView.toByteArray();
+			byte[] key = dataOutputView.getCopyOfBuffer();
 			backend.db.delete(columnFamily, writeOptions, key);
 		} catch (IOException | RocksDBException e) {&lt;br/&gt;
 			throw new FlinkRuntimeException(&quot;Error while removing entry from RocksDB&quot;, e);&lt;br/&gt;
@@ -141,7 +141,7 @@ public void setCurrentNamespace(N namespace) {&lt;br/&gt;
 &lt;br/&gt;
 		// we cannot reuse the keySerializationStream member since this method&lt;br/&gt;
 		// is called concurrently to the other ones and it may thus contain garbage&lt;br/&gt;
-		ByteArrayDataOutputView tmpKeySerializationView = new ByteArrayDataOutputView(128);&lt;br/&gt;
+		DataOutputSerializer tmpKeySerializationView = new DataOutputSerializer(128);&lt;br/&gt;
 &lt;br/&gt;
 		writeKeyWithGroupAndNamespace(&lt;br/&gt;
 				keyGroup,&lt;br/&gt;
@@ -151,13 +151,13 @@ public void setCurrentNamespace(N namespace) {
 				safeNamespaceSerializer,
 				tmpKeySerializationView);
 
-		return backend.db.get(columnFamily, tmpKeySerializationView.toByteArray());
+		return backend.db.get(columnFamily, tmpKeySerializationView.getCopyOfBuffer());
 	}&lt;br/&gt;
 &lt;br/&gt;
 	byte[] getKeyBytes() {&lt;br/&gt;
 		try {
 			writeCurrentKeyWithGroupAndNamespace();
-			return dataOutputView.toByteArray();
+			return dataOutputView.getCopyOfBuffer();
 		} catch (IOException e) {
 			throw new FlinkRuntimeException(&quot;Error while serializing key&quot;, e);
 		}&lt;br/&gt;
@@ -165,9 +165,9 @@ public void setCurrentNamespace(N namespace) {&lt;br/&gt;
 &lt;br/&gt;
 	byte[] getValueBytes(V value) {&lt;br/&gt;
 		try {
-			dataOutputView.reset();
+			dataOutputView.clear();
 			valueSerializer.serialize(value, dataOutputView);
-			return dataOutputView.toByteArray();
+			return dataOutputView.getCopyOfBuffer();
 		} catch (IOException e) {
 			throw new FlinkRuntimeException(&quot;Error while serializing value&quot;, e);
 		}&lt;br/&gt;
@@ -183,7 +183,7 @@ protected void writeCurrentKeyWithGroupAndNamespace() throws IOException {&lt;br/&gt;
 &lt;br/&gt;
 	protected void writeKeyWithGroupAndNamespace(&lt;br/&gt;
 			int keyGroup, K key, N namespace,&lt;br/&gt;
-			ByteArrayDataOutputView keySerializationDataOutputView) throws IOException {&lt;br/&gt;
+			DataOutputSerializer keySerializationDataOutputView) throws IOException {&lt;br/&gt;
 &lt;br/&gt;
 		writeKeyWithGroupAndNamespace(&lt;br/&gt;
 				keyGroup,&lt;br/&gt;
@@ -200,13 +200,13 @@ protected void writeKeyWithGroupAndNamespace(&lt;br/&gt;
 			final TypeSerializer&amp;lt;K&amp;gt; keySerializer,&lt;br/&gt;
 			final N namespace,&lt;br/&gt;
 			final TypeSerializer&amp;lt;N&amp;gt; namespaceSerializer,&lt;br/&gt;
-			final ByteArrayDataOutputView keySerializationDataOutputView) throws IOException {&lt;br/&gt;
+			final DataOutputSerializer keySerializationDataOutputView) throws IOException {&lt;br/&gt;
 &lt;br/&gt;
 		Preconditions.checkNotNull(key, &quot;No key set. This method should not be called outside of a keyed context.&quot;);&lt;br/&gt;
 		Preconditions.checkNotNull(keySerializer);&lt;br/&gt;
 		Preconditions.checkNotNull(namespaceSerializer);&lt;br/&gt;
 &lt;br/&gt;
-		keySerializationDataOutputView.reset();&lt;br/&gt;
+		keySerializationDataOutputView.clear();&lt;br/&gt;
 		RocksDBKeySerializationUtils.writeKeyGroup(keyGroup, backend.getKeyGroupPrefixBytes(), keySerializationDataOutputView);&lt;br/&gt;
 		RocksDBKeySerializationUtils.writeKey(key, keySerializer, keySerializationDataOutputView, ambiguousKeyPossible);&lt;br/&gt;
 		RocksDBKeySerializationUtils.writeNameSpace(namespace, namespaceSerializer, keySerializationDataOutputView, ambiguousKeyPossible);&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java&lt;br/&gt;
index 4f9ef2f811c..2085fb86256 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java&lt;br/&gt;
@@ -121,12 +121,12 @@ public void mergeNamespaces(N target, Collection&amp;lt;N&amp;gt; sources) {&lt;br/&gt;
 				if (source != null) {&lt;br/&gt;
 					writeKeyWithGroupAndNamespace(keyGroup, key, source, dataOutputView);&lt;br/&gt;
 &lt;br/&gt;
-					final byte[] sourceKey = dataOutputView.toByteArray();&lt;br/&gt;
+					final byte[] sourceKey = dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 					final byte[] valueBytes = backend.db.get(columnFamily, sourceKey);&lt;br/&gt;
 					backend.db.delete(columnFamily, writeOptions, sourceKey);&lt;br/&gt;
 &lt;br/&gt;
 					if (valueBytes != null) {&lt;br/&gt;
-						dataInputView.setData(valueBytes);&lt;br/&gt;
+						dataInputView.setBuffer(valueBytes);&lt;br/&gt;
 						ACC value = valueSerializer.deserialize(dataInputView);&lt;br/&gt;
 &lt;br/&gt;
 						if (current != null) {&lt;br/&gt;
@@ -144,23 +144,23 @@ public void mergeNamespaces(N target, Collection&amp;lt;N&amp;gt; sources) {&lt;br/&gt;
 				// create the target full-binary-key&lt;br/&gt;
 				writeKeyWithGroupAndNamespace(keyGroup, key, target, dataOutputView);&lt;br/&gt;
 &lt;br/&gt;
-				final byte[] targetKey = dataOutputView.toByteArray();&lt;br/&gt;
+				final byte[] targetKey = dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 				final byte[] targetValueBytes = backend.db.get(columnFamily, targetKey);&lt;br/&gt;
 &lt;br/&gt;
 				if (targetValueBytes != null) {
 					// target also had a value, merge
-					dataInputView.setData(targetValueBytes);
+					dataInputView.setBuffer(targetValueBytes);
 					ACC value = valueSerializer.deserialize(dataInputView);
 
 					current = aggFunction.merge(current, value);
 				}&lt;br/&gt;
 &lt;br/&gt;
 				// serialize the resulting value&lt;br/&gt;
-				dataOutputView.reset();&lt;br/&gt;
+				dataOutputView.clear();&lt;br/&gt;
 				valueSerializer.serialize(current, dataOutputView);&lt;br/&gt;
 &lt;br/&gt;
 				// write the resulting value&lt;br/&gt;
-				backend.db.put(columnFamily, writeOptions, targetKey, dataOutputView.toByteArray());&lt;br/&gt;
+				backend.db.put(columnFamily, writeOptions, targetKey, dataOutputView.getCopyOfBuffer());&lt;br/&gt;
 			}&lt;br/&gt;
 		}&lt;br/&gt;
 		catch (Exception e) {&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java&lt;br/&gt;
index 68b5b5fdee3..364185a2f3e 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java&lt;br/&gt;
@@ -19,8 +19,8 @@&lt;br/&gt;
 package org.apache.flink.contrib.streaming.state;&lt;br/&gt;
 &lt;br/&gt;
 import org.apache.flink.api.common.typeutils.TypeSerializer;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.runtime.state.InternalPriorityQueue;&lt;br/&gt;
 import org.apache.flink.runtime.state.heap.HeapPriorityQueueElement;&lt;br/&gt;
 import org.apache.flink.util.CloseableIterator;&lt;br/&gt;
@@ -84,11 +84,11 @@&lt;br/&gt;
 &lt;br/&gt;
 	/** Output view that helps to serialize elements. */&lt;br/&gt;
 	@Nonnull&lt;br/&gt;
-	private final ByteArrayDataOutputView outputView;&lt;br/&gt;
+	private final DataOutputSerializer outputView;&lt;br/&gt;
 &lt;br/&gt;
 	/** Input view that helps to de-serialize elements. */&lt;br/&gt;
 	@Nonnull&lt;br/&gt;
-	private final ByteArrayDataInputView inputView;&lt;br/&gt;
+	private final DataInputDeserializer inputView;&lt;br/&gt;
 &lt;br/&gt;
 	/** In memory cache that holds a head-subset of the elements stored in RocksDB. */&lt;br/&gt;
 	@Nonnull&lt;br/&gt;
@@ -114,8 +114,8 @@&lt;br/&gt;
 		@Nonnull RocksDB db,&lt;br/&gt;
 		@Nonnull ColumnFamilyHandle columnFamilyHandle,&lt;br/&gt;
 		@Nonnull TypeSerializer&amp;lt;E&amp;gt; byteOrderProducingSerializer,&lt;br/&gt;
-		@Nonnull ByteArrayDataOutputView outputStream,&lt;br/&gt;
-		@Nonnull ByteArrayDataInputView inputStream,&lt;br/&gt;
+		@Nonnull DataOutputSerializer outputStream,&lt;br/&gt;
+		@Nonnull DataInputDeserializer inputStream,&lt;br/&gt;
 		@Nonnull RocksDBWriteBatchWrapper batchWrapper,&lt;br/&gt;
 		@Nonnull OrderedByteArraySetCache orderedByteArraySetCache) {&lt;br/&gt;
 		this.db = db;&lt;br/&gt;
@@ -357,7 +357,7 @@ private static boolean isPrefixWith(byte[] bytes, byte[] prefixBytes) {&lt;br/&gt;
 	@Nonnull&lt;br/&gt;
 	private byte[] createKeyGroupBytes(int keyGroupId, int numPrefixBytes) {&lt;br/&gt;
 &lt;br/&gt;
-		outputView.reset();&lt;br/&gt;
+		outputView.clear();&lt;br/&gt;
 &lt;br/&gt;
 		try {&lt;br/&gt;
 			RocksDBKeySerializationUtils.writeKeyGroup(keyGroupId, numPrefixBytes, outputView);&lt;br/&gt;
@@ -365,16 +365,16 @@ private static boolean isPrefixWith(byte[] bytes, byte[] prefixBytes) {
 			throw new FlinkRuntimeException(&quot;Could not write key-group bytes.&quot;, e);
 		}&lt;br/&gt;
 &lt;br/&gt;
-		return outputView.toByteArray();&lt;br/&gt;
+		return outputView.getCopyOfBuffer();&lt;br/&gt;
 	}&lt;br/&gt;
 &lt;br/&gt;
 	@Nonnull&lt;br/&gt;
 	private byte[] serializeElement(@Nonnull E element) {&lt;br/&gt;
 		try {
-			outputView.reset();
+			outputView.clear();
 			outputView.write(groupPrefixBytes);
 			byteOrderProducingSerializer.serialize(element, outputView);
-			return outputView.toByteArray();
+			return outputView.getCopyOfBuffer();
 		} catch (IOException e) {
 			throw new FlinkRuntimeException(&quot;Error while serializing the element.&quot;, e);
 		}&lt;br/&gt;
@@ -383,7 +383,8 @@ private static boolean isPrefixWith(byte[] bytes, byte[] prefixBytes) {&lt;br/&gt;
 	@Nonnull&lt;br/&gt;
 	private E deserializeElement(@Nonnull byte[] bytes) {&lt;br/&gt;
 		try {
-			inputView.setData(bytes, groupPrefixBytes.length, bytes.length);
+			final int numPrefixBytes = groupPrefixBytes.length;
+			inputView.setBuffer(bytes, numPrefixBytes, bytes.length - numPrefixBytes);
 			return byteOrderProducingSerializer.deserialize(inputView);
 		} catch (IOException e) {&lt;br/&gt;
 			throw new FlinkRuntimeException(&quot;Error while deserializing the element.&quot;, e);&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtils.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtils.java&lt;br/&gt;
index 7c9e3f8c3f0..d8844bfece1 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtils.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtils.java&lt;br/&gt;
@@ -18,9 +18,9 @@&lt;br/&gt;
 package org.apache.flink.contrib.streaming.state;&lt;br/&gt;
 &lt;br/&gt;
 import org.apache.flink.api.common.typeutils.TypeSerializer;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
 import org.apache.flink.core.memory.DataInputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.core.memory.DataOutputView;&lt;br/&gt;
 &lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
@@ -41,7 +41,7 @@ static int readKeyGroup(int keyGroupPrefixBytes, DataInputView inputView) throws&lt;br/&gt;
 &lt;br/&gt;
 	public static &amp;lt;K&amp;gt; K readKey(&lt;br/&gt;
 		TypeSerializer&amp;lt;K&amp;gt; keySerializer,&lt;br/&gt;
-		ByteArrayDataInputView inputView,&lt;br/&gt;
+		DataInputDeserializer inputView,&lt;br/&gt;
 		boolean ambiguousKeyPossible) throws IOException {&lt;br/&gt;
 		int beforeRead = inputView.getPosition();&lt;br/&gt;
 		K key = keySerializer.deserialize(inputView);&lt;br/&gt;
@@ -54,7 +54,7 @@ static int readKeyGroup(int keyGroupPrefixBytes, DataInputView inputView) throws&lt;br/&gt;
 &lt;br/&gt;
 	public static &amp;lt;N&amp;gt; N readNamespace(&lt;br/&gt;
 		TypeSerializer&amp;lt;N&amp;gt; namespaceSerializer,&lt;br/&gt;
-		ByteArrayDataInputView inputView,&lt;br/&gt;
+		DataInputDeserializer inputView,&lt;br/&gt;
 		boolean ambiguousKeyPossible) throws IOException {&lt;br/&gt;
 		int beforeRead = inputView.getPosition();&lt;br/&gt;
 		N namespace = namespaceSerializer.deserialize(inputView);&lt;br/&gt;
@@ -68,10 +68,10 @@ static int readKeyGroup(int keyGroupPrefixBytes, DataInputView inputView) throws&lt;br/&gt;
 	public static &amp;lt;N&amp;gt; void writeNameSpace(&lt;br/&gt;
 		N namespace,&lt;br/&gt;
 		TypeSerializer&amp;lt;N&amp;gt; namespaceSerializer,&lt;br/&gt;
-		ByteArrayDataOutputView keySerializationDataOutputView,&lt;br/&gt;
+		DataOutputSerializer keySerializationDataOutputView,&lt;br/&gt;
 		boolean ambiguousKeyPossible) throws IOException {&lt;br/&gt;
 &lt;br/&gt;
-		int beforeWrite = keySerializationDataOutputView.getPosition();&lt;br/&gt;
+		int beforeWrite = keySerializationDataOutputView.length();&lt;br/&gt;
 		namespaceSerializer.serialize(namespace, keySerializationDataOutputView);&lt;br/&gt;
 &lt;br/&gt;
 		if (ambiguousKeyPossible) {&lt;br/&gt;
@@ -96,10 +96,10 @@ public static void writeKeyGroup(&lt;br/&gt;
 	public static &amp;lt;K&amp;gt; void writeKey(&lt;br/&gt;
 		K key,&lt;br/&gt;
 		TypeSerializer&amp;lt;K&amp;gt; keySerializer,&lt;br/&gt;
-		ByteArrayDataOutputView keySerializationDataOutputView,&lt;br/&gt;
+		DataOutputSerializer keySerializationDataOutputView,&lt;br/&gt;
 		boolean ambiguousKeyPossible) throws IOException {&lt;br/&gt;
 		//write key&lt;br/&gt;
-		int beforeWrite = keySerializationDataOutputView.getPosition();&lt;br/&gt;
+		int beforeWrite = keySerializationDataOutputView.length();&lt;br/&gt;
 		keySerializer.serialize(key, keySerializationDataOutputView);&lt;br/&gt;
 &lt;br/&gt;
 		if (ambiguousKeyPossible) {&lt;br/&gt;
@@ -117,8 +117,8 @@ private static void readVariableIntBytes(DataInputView inputView, int value) thr&lt;br/&gt;
 &lt;br/&gt;
 	private static void writeLengthFrom(&lt;br/&gt;
 		int fromPosition,&lt;br/&gt;
-		ByteArrayDataOutputView keySerializationDateDataOutputView) throws IOException {&lt;br/&gt;
-		int length = keySerializationDateDataOutputView.getPosition() - fromPosition;&lt;br/&gt;
+		DataOutputSerializer keySerializationDateDataOutputView) throws IOException {
+		int length = keySerializationDateDataOutputView.length() - fromPosition;
 		writeVariableIntBytes(length, keySerializationDateDataOutputView);
 	}&lt;br/&gt;
 &lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java&lt;br/&gt;
index 60baaedae75..42a1e26b8b5 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java&lt;br/&gt;
@@ -43,10 +43,10 @@&lt;br/&gt;
 import org.apache.flink.core.fs.FileStatus;&lt;br/&gt;
 import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
 import org.apache.flink.core.fs.Path;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
 import org.apache.flink.core.memory.DataInputView;&lt;br/&gt;
 import org.apache.flink.core.memory.DataInputViewStreamWrapper;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.runtime.checkpoint.CheckpointOptions;&lt;br/&gt;
 import org.apache.flink.runtime.checkpoint.CheckpointType;&lt;br/&gt;
 import org.apache.flink.runtime.query.TaskKvStateRegistry;&lt;br/&gt;
@@ -328,7 +328,7 @@ private static void checkAndCreateDirectory(File directory) throws IOException {&lt;br/&gt;
 			(RegisteredKeyValueStateBackendMetaInfo&amp;lt;N, ?&amp;gt;) columnInfo.f1;&lt;br/&gt;
 &lt;br/&gt;
 		final TypeSerializer&amp;lt;N&amp;gt; namespaceSerializer = registeredKeyValueStateBackendMetaInfo.getNamespaceSerializer();&lt;br/&gt;
-		final ByteArrayDataOutputView namespaceOutputView = new ByteArrayDataOutputView(8);&lt;br/&gt;
+		final DataOutputSerializer namespaceOutputView = new DataOutputSerializer(8);&lt;br/&gt;
 		boolean ambiguousKeyPossible = RocksDBKeySerializationUtils.isAmbiguousKeyPossible(keySerializer, namespaceSerializer);&lt;br/&gt;
 		final byte[] nameSpaceBytes;&lt;br/&gt;
 		try {&lt;br/&gt;
@@ -337,7 +337,7 @@ private static void checkAndCreateDirectory(File directory) throws IOException {
 				namespaceSerializer,
 				namespaceOutputView,
 				ambiguousKeyPossible);
-			nameSpaceBytes = namespaceOutputView.toByteArray();
+			nameSpaceBytes = namespaceOutputView.getCopyOfBuffer();
 		} catch (IOException ex) {
 			throw new FlinkRuntimeException(&quot;Failed to get keys from RocksDB state backend.&quot;, ex);
 		}&lt;br/&gt;
@@ -1501,15 +1501,15 @@ public static RocksIteratorWrapper getRocksIterator(&lt;br/&gt;
 &lt;br/&gt;
 		/** A shared buffer to serialize elements for the priority queue. */&lt;br/&gt;
 		@Nonnull&lt;br/&gt;
-		private final ByteArrayDataOutputView sharedElementOutView;&lt;br/&gt;
+		private final DataOutputSerializer sharedElementOutView;&lt;br/&gt;
 &lt;br/&gt;
 		/** A shared buffer to de-serialize elements for the priority queue. */&lt;br/&gt;
 		@Nonnull&lt;br/&gt;
-		private final ByteArrayDataInputView sharedElementInView;&lt;br/&gt;
+		private final DataInputDeserializer sharedElementInView;&lt;br/&gt;
 &lt;br/&gt;
 		RocksDBPriorityQueueSetFactory() {
-			this.sharedElementOutView = new ByteArrayDataOutputView();
-			this.sharedElementInView = new ByteArrayDataInputView();
+			this.sharedElementOutView = new DataOutputSerializer(128);
+			this.sharedElementInView = new DataInputDeserializer();
 		}&lt;br/&gt;
 &lt;br/&gt;
 		@Nonnull&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java&lt;br/&gt;
index cdd7afb7d9a..f70c6a57bad 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java&lt;br/&gt;
@@ -24,9 +24,8 @@&lt;br/&gt;
 import org.apache.flink.api.common.state.StateDescriptor;&lt;br/&gt;
 import org.apache.flink.api.common.typeutils.TypeSerializer;&lt;br/&gt;
 import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
-import org.apache.flink.core.memory.DataInputViewStreamWrapper;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.runtime.state.RegisteredKeyValueStateBackendMetaInfo;&lt;br/&gt;
 import org.apache.flink.runtime.state.StateSnapshotTransformer;&lt;br/&gt;
 import org.apache.flink.runtime.state.internal.InternalListState;&lt;br/&gt;
@@ -115,7 +114,7 @@ private RocksDBListState(&lt;br/&gt;
 	public List&amp;lt;V&amp;gt; getInternal() {&lt;br/&gt;
 		try {
 			writeCurrentKeyWithGroupAndNamespace();
-			byte[] key = dataOutputView.toByteArray();
+			byte[] key = dataOutputView.getCopyOfBuffer();
 			byte[] valueBytes = backend.db.get(columnFamily, key);
 			return deserializeList(valueBytes);
 		} catch (IOException | RocksDBException e) {
@@ -129,7 +128,7 @@ private RocksDBListState(
 			return null;
 		}&lt;br/&gt;
 &lt;br/&gt;
-		dataInputView.setData(valueBytes);&lt;br/&gt;
+		dataInputView.setBuffer(valueBytes);&lt;br/&gt;
 &lt;br/&gt;
 		List&amp;lt;V&amp;gt; result = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
 		V next;&lt;br/&gt;
@@ -139,7 +138,7 @@ private RocksDBListState(&lt;br/&gt;
 		return result;&lt;br/&gt;
 	}&lt;br/&gt;
 &lt;br/&gt;
-	private static &amp;lt;V&amp;gt; V deserializeNextElement(DataInputViewStreamWrapper in, TypeSerializer&amp;lt;V&amp;gt; elementSerializer) {&lt;br/&gt;
+	private static &amp;lt;V&amp;gt; V deserializeNextElement(DataInputDeserializer in, TypeSerializer&amp;lt;V&amp;gt; elementSerializer) {&lt;br/&gt;
 		try {&lt;br/&gt;
 			if (in.available() &amp;gt; 0) {&lt;br/&gt;
 				V element = elementSerializer.deserialize(in);&lt;br/&gt;
@@ -160,10 +159,10 @@ public void add(V value) {&lt;br/&gt;
 &lt;br/&gt;
 		try {
 			writeCurrentKeyWithGroupAndNamespace();
-			byte[] key = dataOutputView.toByteArray();
-			dataOutputView.reset();
+			byte[] key = dataOutputView.getCopyOfBuffer();
+			dataOutputView.clear();
 			elementSerializer.serialize(value, dataOutputView);
-			backend.db.merge(columnFamily, writeOptions, key, dataOutputView.toByteArray());
+			backend.db.merge(columnFamily, writeOptions, key, dataOutputView.getCopyOfBuffer());
 		} catch (Exception e) {
 			throw new FlinkRuntimeException(&quot;Error while adding data to RocksDB&quot;, e);
 		}&lt;br/&gt;
@@ -182,14 +181,14 @@ public void mergeNamespaces(N target, Collection&amp;lt;N&amp;gt; sources) {&lt;br/&gt;
 		try {&lt;br/&gt;
 			// create the target full-binary-key&lt;br/&gt;
 			writeKeyWithGroupAndNamespace(keyGroup, key, target, dataOutputView);&lt;br/&gt;
-			final byte[] targetKey = dataOutputView.toByteArray();&lt;br/&gt;
+			final byte[] targetKey = dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 &lt;br/&gt;
 			// merge the sources to the target&lt;br/&gt;
 			for (N source : sources) {&lt;br/&gt;
 				if (source != null) {&lt;br/&gt;
 					writeKeyWithGroupAndNamespace(keyGroup, key, source, dataOutputView);&lt;br/&gt;
 &lt;br/&gt;
-					byte[] sourceKey = dataOutputView.toByteArray();&lt;br/&gt;
+					byte[] sourceKey = dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 					byte[] valueBytes = backend.db.get(columnFamily, sourceKey);&lt;br/&gt;
 					backend.db.delete(columnFamily, writeOptions, sourceKey);&lt;br/&gt;
 &lt;br/&gt;
@@ -218,7 +217,7 @@ public void updateInternal(List&amp;lt;V&amp;gt; values) {&lt;br/&gt;
 		if (!values.isEmpty()) {&lt;br/&gt;
 			try {
 				writeCurrentKeyWithGroupAndNamespace();
-				byte[] key = dataOutputView.toByteArray();
+				byte[] key = dataOutputView.getCopyOfBuffer();
 				byte[] premerge = getPreMergedValue(values, elementSerializer, dataOutputView);
 				backend.db.put(columnFamily, writeOptions, key, premerge);
 			} catch (IOException | RocksDBException e) {&lt;br/&gt;
@@ -234,7 +233,7 @@ public void addAll(List&amp;lt;V&amp;gt; values) {&lt;br/&gt;
 		if (!values.isEmpty()) {&lt;br/&gt;
 			try {
 				writeCurrentKeyWithGroupAndNamespace();
-				byte[] key = dataOutputView.toByteArray();
+				byte[] key = dataOutputView.getCopyOfBuffer();
 				byte[] premerge = getPreMergedValue(values, elementSerializer, dataOutputView);
 				backend.db.merge(columnFamily, writeOptions, key, premerge);
 			} catch (IOException | RocksDBException e) {&lt;br/&gt;
@@ -246,9 +245,9 @@ public void addAll(List&amp;lt;V&amp;gt; values) {&lt;br/&gt;
 	private static &amp;lt;V&amp;gt; byte[] getPreMergedValue(&lt;br/&gt;
 		List&amp;lt;V&amp;gt; values,&lt;br/&gt;
 		TypeSerializer&amp;lt;V&amp;gt; elementSerializer,&lt;br/&gt;
-		ByteArrayDataOutputView keySerializationStream) throws IOException {&lt;br/&gt;
+		DataOutputSerializer keySerializationStream) throws IOException {&lt;br/&gt;
 &lt;br/&gt;
-		keySerializationStream.reset();&lt;br/&gt;
+		keySerializationStream.clear();&lt;br/&gt;
 		boolean first = true;&lt;br/&gt;
 		for (V value : values) {&lt;br/&gt;
 			Preconditions.checkNotNull(value, &quot;You cannot add null to a ListState.&quot;);&lt;br/&gt;
@@ -260,7 +259,7 @@ public void addAll(List&amp;lt;V&amp;gt; values) {
 			elementSerializer.serialize(value, keySerializationStream);
 		}&lt;br/&gt;
 &lt;br/&gt;
-		return keySerializationStream.toByteArray();&lt;br/&gt;
+		return keySerializationStream.getCopyOfBuffer();&lt;br/&gt;
 	}&lt;br/&gt;
 &lt;br/&gt;
 	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
@@ -280,7 +279,7 @@ public void addAll(List&amp;lt;V&amp;gt; values) {&lt;br/&gt;
 	static class StateSnapshotTransformerWrapper&amp;lt;T&amp;gt; implements StateSnapshotTransformer&amp;lt;byte[]&amp;gt; {&lt;br/&gt;
 		private final StateSnapshotTransformer&amp;lt;T&amp;gt; elementTransformer;&lt;br/&gt;
 		private final TypeSerializer&amp;lt;T&amp;gt; elementSerializer;&lt;br/&gt;
-		private final ByteArrayDataOutputView out = new ByteArrayDataOutputView(128);&lt;br/&gt;
+		private final DataOutputSerializer out = new DataOutputSerializer(128);&lt;br/&gt;
 		private final CollectionStateSnapshotTransformer.TransformStrategy transformStrategy;&lt;br/&gt;
 &lt;br/&gt;
 		StateSnapshotTransformerWrapper(StateSnapshotTransformer&amp;lt;T&amp;gt; elementTransformer, TypeSerializer&amp;lt;T&amp;gt; elementSerializer) {&lt;br/&gt;
@@ -298,7 +297,7 @@ public void addAll(List&amp;lt;V&amp;gt; values) { 				return null; 			}
&lt;p&gt; 			List&amp;lt;T&amp;gt; result = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ByteArrayDataInputView in = new ByteArrayDataInputView(value);&lt;br/&gt;
+			DataInputDeserializer in = new DataInputDeserializer(value);&lt;br/&gt;
 			T next;&lt;br/&gt;
 			int prevPosition = 0;&lt;br/&gt;
 			while ((next = deserializeNextElement(in, elementSerializer)) != null) {&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java&lt;br/&gt;
index ad6b7c22ec4..5c9f7f9f30c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java&lt;br/&gt;
@@ -24,8 +24,8 @@&lt;br/&gt;
 import org.apache.flink.api.common.typeutils.TypeSerializer;&lt;br/&gt;
 import org.apache.flink.api.common.typeutils.base.MapSerializer;&lt;br/&gt;
 import org.apache.flink.api.java.tuple.Tuple2;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.queryablestate.client.state.serialization.KvStateSerializer;&lt;br/&gt;
 import org.apache.flink.runtime.state.KeyGroupRangeAssignment;&lt;br/&gt;
 import org.apache.flink.runtime.state.RegisteredKeyValueStateBackendMetaInfo;&lt;br/&gt;
@@ -122,14 +122,14 @@ public UV get(UK userKey) throws IOException, RocksDBException 
{
 		byte[] rawKeyBytes = serializeUserKeyWithCurrentKeyAndNamespace(userKey);
 		byte[] rawValueBytes = backend.db.get(columnFamily, rawKeyBytes);
 
-		return (rawValueBytes == null ? null : deserializeUserValue(rawValueBytes));
+		return (rawValueBytes == null ? null : deserializeUserValue(dataInputView, rawValueBytes, userValueSerializer));
 	}&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	@Override&lt;br/&gt;
 	public void put(UK userKey, UV userValue) throws IOException, RocksDBException &lt;/p&gt;
{
 
 		byte[] rawKeyBytes = serializeUserKeyWithCurrentKeyAndNamespace(userKey);
-		byte[] rawValueBytes = serializeUserValue(userValue);
+		byte[] rawValueBytes = serializeUserValue(userValue, userValueSerializer, dataOutputView);
 
 		backend.db.put(columnFamily, writeOptions, rawKeyBytes, rawValueBytes);
 	}
&lt;p&gt;@@ -143,7 +143,7 @@ public void putAll(Map&amp;lt;UK, UV&amp;gt; map) throws IOException, RocksDBException {&lt;br/&gt;
 		try (RocksDBWriteBatchWrapper writeBatchWrapper = new RocksDBWriteBatchWrapper(backend.db, writeOptions)) {&lt;br/&gt;
 			for (Map.Entry&amp;lt;UK, UV&amp;gt; entry : map.entrySet()) &lt;/p&gt;
{
 				byte[] rawKeyBytes = serializeUserKeyWithCurrentKeyAndNamespace(entry.getKey());
-				byte[] rawValueBytes = serializeUserValue(entry.getValue());
+				byte[] rawValueBytes = serializeUserValue(entry.getValue(), userValueSerializer, dataOutputView);
 				writeBatchWrapper.put(columnFamily, rawKeyBytes, rawValueBytes);
 			}
&lt;p&gt; 		}&lt;br/&gt;
@@ -180,7 +180,7 @@ public boolean contains(UK userKey) throws IOException, RocksDBException {&lt;br/&gt;
 	public Iterable&amp;lt;UK&amp;gt; keys() throws IOException {&lt;br/&gt;
 		final byte[] prefixBytes = serializeCurrentKeyAndNamespace();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return () -&amp;gt; new RocksDBMapIterator&amp;lt;UK&amp;gt;(backend.db, prefixBytes, userKeySerializer, userValueSerializer) {&lt;br/&gt;
+		return () -&amp;gt; new RocksDBMapIterator&amp;lt;UK&amp;gt;(backend.db, prefixBytes, userKeySerializer, userValueSerializer, dataInputView) {&lt;br/&gt;
 			@Override&lt;br/&gt;
 			public UK next() {&lt;br/&gt;
 				RocksDBMapEntry entry = nextEntry();&lt;br/&gt;
@@ -193,7 +193,7 @@ public UK next() {&lt;br/&gt;
 	public Iterable&amp;lt;UV&amp;gt; values() throws IOException {&lt;br/&gt;
 		final byte[] prefixBytes = serializeCurrentKeyAndNamespace();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return () -&amp;gt; new RocksDBMapIterator&amp;lt;UV&amp;gt;(backend.db, prefixBytes, userKeySerializer, userValueSerializer) {&lt;br/&gt;
+		return () -&amp;gt; new RocksDBMapIterator&amp;lt;UV&amp;gt;(backend.db, prefixBytes, userKeySerializer, userValueSerializer, dataInputView) {&lt;br/&gt;
 			@Override&lt;br/&gt;
 			public UV next() {&lt;br/&gt;
 				RocksDBMapEntry entry = nextEntry();&lt;br/&gt;
@@ -206,7 +206,7 @@ public UV next() {&lt;br/&gt;
 	public Iterator&amp;lt;Map.Entry&amp;lt;UK, UV&amp;gt;&amp;gt; iterator() throws IOException {&lt;br/&gt;
 		final byte[] prefixBytes = serializeCurrentKeyAndNamespace();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return new RocksDBMapIterator&amp;lt;Map.Entry&amp;lt;UK, UV&amp;gt;&amp;gt;(backend.db, prefixBytes, userKeySerializer, userValueSerializer) {&lt;br/&gt;
+		return new RocksDBMapIterator&amp;lt;Map.Entry&amp;lt;UK, UV&amp;gt;&amp;gt;(backend.db, prefixBytes, userKeySerializer, userValueSerializer, dataInputView) {&lt;br/&gt;
 			@Override&lt;br/&gt;
 			public Map.Entry&amp;lt;UK, UV&amp;gt; next() {&lt;br/&gt;
 				return nextEntry();&lt;br/&gt;
@@ -259,7 +259,8 @@ public void clear() {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		int keyGroup = KeyGroupRangeAssignment.assignToKeyGroup(keyAndNamespace.f0, backend.getNumberOfKeyGroups());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ByteArrayDataOutputView outputView = new ByteArrayDataOutputView(128);&lt;br/&gt;
+		DataOutputSerializer outputView = new DataOutputSerializer(128);&lt;br/&gt;
+		DataInputDeserializer inputView = new DataInputDeserializer();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		writeKeyWithGroupAndNamespace(&lt;br/&gt;
 				keyGroup,&lt;br/&gt;
@@ -269,7 +270,7 @@ public void clear() {&lt;br/&gt;
 				safeNamespaceSerializer,&lt;br/&gt;
 				outputView);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final byte[] keyPrefixBytes = outputView.toByteArray();&lt;br/&gt;
+		final byte[] keyPrefixBytes = outputView.getCopyOfBuffer();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		final MapSerializer&amp;lt;UK, UV&amp;gt; serializer = (MapSerializer&amp;lt;UK, UV&amp;gt;) safeValueSerializer;&lt;/p&gt;

&lt;p&gt;@@ -280,7 +281,8 @@ public void clear() {&lt;br/&gt;
 				backend.db,&lt;br/&gt;
 				keyPrefixBytes,&lt;br/&gt;
 				dupUserKeySerializer,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;dupUserValueSerializer) {&lt;br/&gt;
+				dupUserValueSerializer,&lt;br/&gt;
+				inputView) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			@Override&lt;br/&gt;
 			public Map.Entry&amp;lt;UK, UV&amp;gt; next() {&lt;br/&gt;
@@ -303,26 +305,22 @@ public void clear() {&lt;br/&gt;
 	private byte[] serializeCurrentKeyAndNamespace() throws IOException &lt;/p&gt;
{
 		writeCurrentKeyWithGroupAndNamespace();
 
-		return dataOutputView.toByteArray();
+		return dataOutputView.getCopyOfBuffer();
 	}

&lt;p&gt; 	private byte[] serializeUserKeyWithCurrentKeyAndNamespace(UK userKey) throws IOException &lt;/p&gt;
{
 		serializeCurrentKeyAndNamespace();
 		userKeySerializer.serialize(userKey, dataOutputView);
 
-		return dataOutputView.toByteArray();
+		return dataOutputView.getCopyOfBuffer();
 	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private byte[] serializeUserValue(UV userValue) throws IOException 
{
-		return serializeUserValue(userValue, userValueSerializer);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private UV deserializeUserValue(byte[] rawValueBytes) throws IOException 
{
-		return deserializeUserValue(rawValueBytes, userValueSerializer);
-	}
&lt;p&gt;+	private static &amp;lt;UV&amp;gt; byte[] serializeUserValue(&lt;br/&gt;
+		UV userValue,&lt;br/&gt;
+		TypeSerializer&amp;lt;UV&amp;gt; valueSerializer,&lt;br/&gt;
+		DataOutputSerializer dataOutputView) throws IOException {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private byte[] serializeUserValue(UV userValue, TypeSerializer&amp;lt;UV&amp;gt; valueSerializer) throws IOException {&lt;/li&gt;
	&lt;li&gt;dataOutputView.reset();&lt;br/&gt;
+		dataOutputView.clear();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		if (userValue == null) {&lt;br/&gt;
 			dataOutputView.writeBoolean(true);&lt;br/&gt;
@@ -331,16 +329,24 @@ private UV deserializeUserValue(byte[] rawValueBytes) throws IOException &lt;/p&gt;
{
 			valueSerializer.serialize(userValue, dataOutputView);
 		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return dataOutputView.toByteArray();&lt;br/&gt;
+		return dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private UK deserializeUserKey(int userKeyOffset, byte[] rawKeyBytes, TypeSerializer&amp;lt;UK&amp;gt; keySerializer) throws IOException {&lt;/li&gt;
	&lt;li&gt;dataInputView.setData(rawKeyBytes, userKeyOffset, rawKeyBytes.length - userKeyOffset);&lt;br/&gt;
+	private static &amp;lt;UK&amp;gt; UK deserializeUserKey(&lt;br/&gt;
+		DataInputDeserializer dataInputView,&lt;br/&gt;
+		int userKeyOffset,&lt;br/&gt;
+		byte[] rawKeyBytes,&lt;br/&gt;
+		TypeSerializer&amp;lt;UK&amp;gt; keySerializer) throws IOException 
{
+		dataInputView.setBuffer(rawKeyBytes, userKeyOffset, rawKeyBytes.length - userKeyOffset);
 		return keySerializer.deserialize(dataInputView);
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private UV deserializeUserValue(byte[] rawValueBytes, TypeSerializer&amp;lt;UV&amp;gt; valueSerializer) throws IOException {&lt;/li&gt;
	&lt;li&gt;dataInputView.setData(rawValueBytes);&lt;br/&gt;
+	private static &amp;lt;UV&amp;gt; UV deserializeUserValue(&lt;br/&gt;
+		DataInputDeserializer dataInputView,&lt;br/&gt;
+		byte[] rawValueBytes,&lt;br/&gt;
+		TypeSerializer&amp;lt;UV&amp;gt; valueSerializer) throws IOException {&lt;br/&gt;
+&lt;br/&gt;
+		dataInputView.setBuffer(rawValueBytes);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		boolean isNull = dataInputView.readBoolean();&lt;/p&gt;

&lt;p&gt;@@ -388,9 +394,12 @@ private boolean startWithKeyPrefix(byte[] keyPrefixBytes, byte[] rawKeyBytes) {&lt;br/&gt;
 		/** The offset of User Key offset in raw key bytes. */&lt;br/&gt;
 		private final int userKeyOffset;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private TypeSerializer&amp;lt;UK&amp;gt; keySerializer;&lt;br/&gt;
+		private final TypeSerializer&amp;lt;UK&amp;gt; keySerializer;&lt;br/&gt;
+&lt;br/&gt;
+		private final TypeSerializer&amp;lt;UV&amp;gt; valueSerializer;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private TypeSerializer&amp;lt;UV&amp;gt; valueSerializer;&lt;br/&gt;
+		private final DataInputDeserializer dataInputView;&lt;br/&gt;
+		private final DataOutputSerializer dataOutputView;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		RocksDBMapEntry(&lt;br/&gt;
 				@Nonnull final RocksDB db,&lt;br/&gt;
@@ -398,7 +407,9 @@ private boolean startWithKeyPrefix(byte[] keyPrefixBytes, byte[] rawKeyBytes) {&lt;br/&gt;
 				@Nonnull final byte[] rawKeyBytes,&lt;br/&gt;
 				@Nonnull final byte[] rawValueBytes,&lt;br/&gt;
 				@Nonnull final TypeSerializer&amp;lt;UK&amp;gt; keySerializer,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Nonnull final TypeSerializer&amp;lt;UV&amp;gt; valueSerializer) {&lt;br/&gt;
+				@Nonnull final TypeSerializer&amp;lt;UV&amp;gt; valueSerializer,&lt;br/&gt;
+				@Nonnull DataInputDeserializer dataInputView,&lt;br/&gt;
+				@Nonnull DataOutputSerializer dataOutputView) {&lt;br/&gt;
 			this.db = db;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			this.userKeyOffset = userKeyOffset;&lt;br/&gt;
@@ -408,6 +419,8 @@ private boolean startWithKeyPrefix(byte[] keyPrefixBytes, byte[] rawKeyBytes) &lt;/p&gt;
{
 			this.rawKeyBytes = rawKeyBytes;
 			this.rawValueBytes = rawValueBytes;
 			this.deleted = false;
+			this.dataInputView = dataInputView;
+			this.dataOutputView = dataOutputView;
 		}

&lt;p&gt; 		public void remove() {&lt;br/&gt;
@@ -425,7 +438,7 @@ public void remove() {&lt;br/&gt;
 		public UK getKey() {&lt;br/&gt;
 			if (userKey == null) {&lt;br/&gt;
 				try &lt;/p&gt;
{
-					userKey = deserializeUserKey(userKeyOffset, rawKeyBytes, keySerializer);
+					userKey = deserializeUserKey(dataInputView, userKeyOffset, rawKeyBytes, keySerializer);
 				}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
 					throw new FlinkRuntimeException(&quot;Error while deserializing the user key.&quot;, e);
 				}
&lt;p&gt;@@ -441,7 +454,7 @@ public UV getValue() {&lt;br/&gt;
 			} else {&lt;br/&gt;
 				if (userValue == null) {&lt;br/&gt;
 					try &lt;/p&gt;
{
-						userValue = deserializeUserValue(rawValueBytes, valueSerializer);
+						userValue = deserializeUserValue(dataInputView, rawValueBytes, valueSerializer);
 					}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
 						throw new FlinkRuntimeException(&quot;Error while deserializing the user value.&quot;, e);
 					}
&lt;p&gt;@@ -461,7 +474,7 @@ public UV setValue(UV value) {&lt;/p&gt;

&lt;p&gt; 			try &lt;/p&gt;
{
 				userValue = value;
-				rawValueBytes = serializeUserValue(value, valueSerializer);
+				rawValueBytes = serializeUserValue(value, valueSerializer, dataOutputView);
 
 				db.put(columnFamily, writeOptions, rawKeyBytes, rawValueBytes);
 			}
&lt;p&gt; catch (IOException | RocksDBException e) {&lt;br/&gt;
@@ -499,17 +512,20 @@ public UV setValue(UV value) {&lt;/p&gt;

&lt;p&gt; 		private final TypeSerializer&amp;lt;UK&amp;gt; keySerializer;&lt;br/&gt;
 		private final TypeSerializer&amp;lt;UV&amp;gt; valueSerializer;&lt;br/&gt;
+		private final DataInputDeserializer dataInputView;&lt;/p&gt;

&lt;p&gt; 		RocksDBMapIterator(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final RocksDB db,&lt;/li&gt;
	&lt;li&gt;final byte[] keyPrefixBytes,&lt;/li&gt;
	&lt;li&gt;final TypeSerializer&amp;lt;UK&amp;gt; keySerializer,&lt;/li&gt;
	&lt;li&gt;final TypeSerializer&amp;lt;UV&amp;gt; valueSerializer) {&lt;br/&gt;
+			final RocksDB db,&lt;br/&gt;
+			final byte[] keyPrefixBytes,&lt;br/&gt;
+			final TypeSerializer&amp;lt;UK&amp;gt; keySerializer,&lt;br/&gt;
+			final TypeSerializer&amp;lt;UV&amp;gt; valueSerializer,&lt;br/&gt;
+			DataInputDeserializer dataInputView) 
{
 
 			this.db = db;
 			this.keyPrefixBytes = keyPrefixBytes;
 			this.keySerializer = keySerializer;
 			this.valueSerializer = valueSerializer;
+			this.dataInputView = dataInputView;
 		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		@Override&lt;br/&gt;
@@ -597,7 +613,9 @@ private void loadCache() {&lt;br/&gt;
 						iterator.key(),&lt;br/&gt;
 						iterator.value(),&lt;br/&gt;
 						keySerializer,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;valueSerializer);&lt;br/&gt;
+						valueSerializer,&lt;br/&gt;
+						dataInputView,&lt;br/&gt;
+						dataOutputView);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 					cacheEntries.add(entry);&lt;/p&gt;

&lt;p&gt;@@ -630,24 +648,24 @@ private void loadCache() {&lt;br/&gt;
 		private static final byte[] NULL_VALUE;&lt;br/&gt;
 		private static final byte NON_NULL_VALUE_PREFIX;&lt;br/&gt;
 		static {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ByteArrayDataOutputView dov = new ByteArrayDataOutputView(1);&lt;br/&gt;
+			DataOutputSerializer dov = new DataOutputSerializer(1);&lt;br/&gt;
 			try 
{
 				dov.writeBoolean(true);
-				NULL_VALUE = dov.toByteArray();
-				dov.reset();
+				NULL_VALUE = dov.getCopyOfBuffer();
+				dov.clear();
 				dov.writeBoolean(false);
-				NON_NULL_VALUE_PREFIX = dov.toByteArray()[0];
+				NON_NULL_VALUE_PREFIX = dov.getSharedBuffer()[0];
 			}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
 				throw new FlinkRuntimeException(&quot;Failed to serialize boolean flag of map user null value&quot;, e);
 			}
&lt;p&gt; 		}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		private final StateSnapshotTransformer&amp;lt;byte[]&amp;gt; elementTransformer;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final ByteArrayDataInputView div;&lt;br/&gt;
+		private final DataInputDeserializer div;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		StateSnapshotTransformerWrapper(StateSnapshotTransformer&amp;lt;byte[]&amp;gt; originalTransformer) &lt;/p&gt;
{
 			this.elementTransformer = originalTransformer;
-			this.div = new ByteArrayDataInputView();
+			this.div = new DataInputDeserializer();
 		}

&lt;p&gt; 		@Override&lt;br/&gt;
@@ -674,7 +692,7 @@ private void loadCache() {&lt;/p&gt;

&lt;p&gt; 		private boolean isNull(byte[] value) {&lt;br/&gt;
 			try &lt;/p&gt;
{
-				div.setData(value, 0, 1);
+				div.setBuffer(value, 0, 1);
 				return div.readBoolean();
 			}
&lt;p&gt; catch (IOException e) {&lt;br/&gt;
 				throw new FlinkRuntimeException(&quot;Failed to deserialize boolean flag of map user null value&quot;, e);&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java&lt;br/&gt;
index d1fe3bd3798..138357b0d77 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java&lt;br/&gt;
@@ -115,12 +115,12 @@ public void mergeNamespaces(N target, Collection&amp;lt;N&amp;gt; sources) {&lt;/p&gt;

&lt;p&gt; 					writeKeyWithGroupAndNamespace(keyGroup, key, source, dataOutputView);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final byte[] sourceKey = dataOutputView.toByteArray();&lt;br/&gt;
+					final byte[] sourceKey = dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 					final byte[] valueBytes = backend.db.get(columnFamily, sourceKey);&lt;br/&gt;
 					backend.db.delete(columnFamily, writeOptions, sourceKey);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 					if (valueBytes != null) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;dataInputView.setData(valueBytes);&lt;br/&gt;
+						dataInputView.setBuffer(valueBytes);&lt;br/&gt;
 						V value = valueSerializer.deserialize(dataInputView);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 						if (current != null) {&lt;br/&gt;
@@ -138,11 +138,11 @@ public void mergeNamespaces(N target, Collection&amp;lt;N&amp;gt; sources) {&lt;br/&gt;
 				// create the target full-binary-key&lt;br/&gt;
 				writeKeyWithGroupAndNamespace(keyGroup, key, target, dataOutputView);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final byte[] targetKey = dataOutputView.toByteArray();&lt;br/&gt;
+				final byte[] targetKey = dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 				final byte[] targetValueBytes = backend.db.get(columnFamily, targetKey);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 				if (targetValueBytes != null) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;dataInputView.setData(targetValueBytes);&lt;br/&gt;
+					dataInputView.setBuffer(targetValueBytes);&lt;br/&gt;
 					// target also had a value, merge&lt;br/&gt;
 					V value = valueSerializer.deserialize(dataInputView);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -150,11 +150,11 @@ public void mergeNamespaces(N target, Collection&amp;lt;N&amp;gt; sources) {&lt;br/&gt;
 				}&lt;/p&gt;

&lt;p&gt; 				// serialize the resulting value&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;dataOutputView.reset();&lt;br/&gt;
+				dataOutputView.clear();&lt;br/&gt;
 				valueSerializer.serialize(current, dataOutputView);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 				// write the resulting value&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;backend.db.put(columnFamily, writeOptions, targetKey, dataOutputView.toByteArray());&lt;br/&gt;
+				backend.db.put(columnFamily, writeOptions, targetKey, dataOutputView.getCopyOfBuffer());&lt;br/&gt;
 			}&lt;br/&gt;
 		}&lt;br/&gt;
 		catch (Exception e) {&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java&lt;br/&gt;
index e9399e12a32..0ca90d4a521 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java&lt;br/&gt;
@@ -81,12 +81,12 @@ private RocksDBValueState(&lt;br/&gt;
 	public V value() {&lt;br/&gt;
 		try {&lt;br/&gt;
 			writeCurrentKeyWithGroupAndNamespace();&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;byte[] key = dataOutputView.toByteArray();&lt;br/&gt;
+			byte[] key = dataOutputView.getCopyOfBuffer();&lt;br/&gt;
 			byte[] valueBytes = backend.db.get(columnFamily, key);&lt;br/&gt;
 			if (valueBytes == null) 
{
 				return getDefaultValue();
 			}&lt;/li&gt;
	&lt;li&gt;dataInputView.setData(valueBytes);&lt;br/&gt;
+			dataInputView.setBuffer(valueBytes);&lt;br/&gt;
 			return valueSerializer.deserialize(dataInputView);&lt;br/&gt;
 		} catch (IOException | RocksDBException e) {&lt;br/&gt;
 			throw new FlinkRuntimeException(&quot;Error while retrieving data from RocksDB.&quot;, e);&lt;br/&gt;
@@ -102,10 +102,10 @@ public void update(V value) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		try &lt;/p&gt;
{
 			writeCurrentKeyWithGroupAndNamespace();
-			byte[] key = dataOutputView.toByteArray();
-			dataOutputView.reset();
+			byte[] key = dataOutputView.getCopyOfBuffer();
+			dataOutputView.clear();
 			valueSerializer.serialize(value, dataOutputView);
-			backend.db.put(columnFamily, writeOptions, key, dataOutputView.toByteArray());
+			backend.db.put(columnFamily, writeOptions, key, dataOutputView.getCopyOfBuffer());
 		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
 			throw new FlinkRuntimeException(&quot;Error while adding data to RocksDB&quot;, e);
 		}
&lt;p&gt;diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksStateKeysIterator.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksStateKeysIterator.java&lt;br/&gt;
index 0fa93dc8a1f..4f79d870d87 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksStateKeysIterator.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksStateKeysIterator.java&lt;br/&gt;
@@ -21,7 +21,7 @@&lt;br/&gt;
 import org.apache.flink.api.common.typeutils.TypeSerializer;&lt;br/&gt;
 import org.apache.flink.contrib.streaming.state.RocksDBKeySerializationUtils;&lt;br/&gt;
 import org.apache.flink.contrib.streaming.state.RocksIteratorWrapper;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
 import org.apache.flink.util.FlinkRuntimeException;&lt;/p&gt;

&lt;p&gt; import javax.annotation.Nonnull;&lt;br/&gt;
@@ -53,7 +53,7 @@&lt;/p&gt;

&lt;p&gt; 	private final boolean ambiguousKeyPossible;&lt;br/&gt;
 	private final int keyGroupPrefixBytes;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final ByteArrayDataInputView byteArrayDataInputView;&lt;br/&gt;
+	private final DataInputDeserializer byteArrayDataInputView;&lt;br/&gt;
 	private K nextKey;&lt;br/&gt;
 	private K previousKey;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -72,7 +72,7 @@ public RocksStateKeysIterator(&lt;br/&gt;
 		this.nextKey = null;&lt;br/&gt;
 		this.previousKey = null;&lt;br/&gt;
 		this.ambiguousKeyPossible = ambiguousKeyPossible;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.byteArrayDataInputView = new ByteArrayDataInputView();&lt;br/&gt;
+		this.byteArrayDataInputView = new DataInputDeserializer();&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	@Override&lt;br/&gt;
@@ -107,8 +107,8 @@ public K next() &lt;/p&gt;
{
 		return tmpKey;
 	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private K deserializeKey(byte[] keyBytes, ByteArrayDataInputView readView) throws IOException {&lt;/li&gt;
	&lt;li&gt;readView.setData(keyBytes, keyGroupPrefixBytes, keyBytes.length - keyGroupPrefixBytes);&lt;br/&gt;
+	private K deserializeKey(byte[] keyBytes, DataInputDeserializer readView) throws IOException {&lt;br/&gt;
+		readView.setBuffer(keyBytes, keyGroupPrefixBytes, keyBytes.length - keyGroupPrefixBytes);&lt;br/&gt;
 		return RocksDBKeySerializationUtils.readKey(&lt;br/&gt;
 			keySerializer,&lt;br/&gt;
 			byteArrayDataInputView,&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/KeyGroupPartitionedPriorityQueueWithRocksDBStoreTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/KeyGroupPartitionedPriorityQueueWithRocksDBStoreTest.java&lt;br/&gt;
index ad8b74c975f..d402c3de574 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/KeyGroupPartitionedPriorityQueueWithRocksDBStoreTest.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/KeyGroupPartitionedPriorityQueueWithRocksDBStoreTest.java&lt;br/&gt;
@@ -18,8 +18,8 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package org.apache.flink.contrib.streaming.state;&lt;/p&gt;

&lt;p&gt;-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.runtime.state.InternalPriorityQueue;&lt;br/&gt;
 import org.apache.flink.runtime.state.InternalPriorityQueueTestBase;&lt;br/&gt;
 import org.apache.flink.runtime.state.heap.KeyGroupPartitionedPriorityQueue;&lt;br/&gt;
@@ -52,8 +52,8 @@ protected boolean testSetSemanticsAgainstDuplicateElements() {&lt;br/&gt;
 		TestElement, RocksDBCachingPriorityQueueSet&amp;lt;TestElement&amp;gt;&amp;gt; newFactory() {&lt;/p&gt;

&lt;p&gt; 		return (keyGroupId, numKeyGroups, keyExtractorFunction, elementComparator) -&amp;gt; {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ByteArrayDataOutputView outputStreamWithPos = new ByteArrayDataOutputView();&lt;/li&gt;
	&lt;li&gt;ByteArrayDataInputView inputStreamWithPos = new ByteArrayDataInputView();&lt;br/&gt;
+			DataOutputSerializer outputStreamWithPos = new DataOutputSerializer(128);&lt;br/&gt;
+			DataInputDeserializer inputStreamWithPos = new DataInputDeserializer();&lt;br/&gt;
 			int keyGroupPrefixBytes = RocksDBKeySerializationUtils.computeRequiredBytesInKeyGroupPrefix(numKeyGroups);&lt;br/&gt;
 			TreeOrderedSetCache orderedSetCache = new TreeOrderedSetCache(32);&lt;br/&gt;
 			return new RocksDBCachingPriorityQueueSet&amp;lt;&amp;gt;(&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtilsTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtilsTest.java&lt;br/&gt;
index 483b8fdd1dc..942d85cf5ea 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtilsTest.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtilsTest.java&lt;br/&gt;
@@ -18,7 +18,7 @@&lt;br/&gt;
 package org.apache.flink.contrib.streaming.state;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import org.apache.flink.api.common.typeutils.base.IntSerializer;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.runtime.state.KeyGroupRange;&lt;br/&gt;
 import org.apache.flink.runtime.state.KeyedStateHandle;&lt;br/&gt;
 import org.apache.flink.util.TestLogger;&lt;br/&gt;
@@ -112,30 +112,30 @@ private void testClipDBWithKeyGroupRangeHelper(&lt;br/&gt;
 			int currentGroupRangeStart = currentGroupRange.getStartKeyGroup();&lt;br/&gt;
 			int currentGroupRangeEnd = currentGroupRange.getEndKeyGroup();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ByteArrayDataOutputView outputView = new ByteArrayDataOutputView(32);&lt;br/&gt;
+			DataOutputSerializer outputView = new DataOutputSerializer(32);&lt;br/&gt;
 			for (int i = currentGroupRangeStart; i &amp;lt;= currentGroupRangeEnd; ++i) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: { 				for (int j = 0; j &amp;lt; 100; ++j) {
-					outputView.reset();
+					outputView.clear();
 					RocksDBKeySerializationUtils.writeKeyGroup(i, keyGroupPrefixBytes, outputView);
 					RocksDBKeySerializationUtils.writeKey(
 						j,
 						IntSerializer.INSTANCE,
 						outputView,
 						false);
-					rocksDB.put(columnFamilyHandle, outputView.toByteArray(), String.valueOf(j).getBytes());
+					rocksDB.put(columnFamilyHandle, outputView.getCopyOfBuffer(), String.valueOf(j).getBytes());
 				} 			}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			for (int i = currentGroupRangeStart; i &amp;lt;= currentGroupRangeEnd; ++i) {&lt;br/&gt;
 				for (int j = 0; j &amp;lt; 100; ++j) &lt;/p&gt;
{
-					outputView.reset();
+					outputView.clear();
 					RocksDBKeySerializationUtils.writeKeyGroup(i, keyGroupPrefixBytes, outputView);
 					RocksDBKeySerializationUtils.writeKey(
 						j,
 						IntSerializer.INSTANCE,
 						outputView,
 						false);
-					byte[] value = rocksDB.get(columnFamilyHandle, outputView.toByteArray());
+					byte[] value = rocksDB.get(columnFamilyHandle, outputView.getCopyOfBuffer());
 					Assert.assertEquals(String.valueOf(j), new String(value));
 				}
&lt;p&gt; 			}&lt;br/&gt;
@@ -149,14 +149,14 @@ private void testClipDBWithKeyGroupRangeHelper(&lt;/p&gt;

&lt;p&gt; 			for (int i = currentGroupRangeStart; i &amp;lt;= currentGroupRangeEnd; ++i) {&lt;br/&gt;
 				for (int j = 0; j &amp;lt; 100; ++j) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;outputView.reset();&lt;br/&gt;
+					outputView.clear();&lt;br/&gt;
 					RocksDBKeySerializationUtils.writeKeyGroup(i, keyGroupPrefixBytes, outputView);&lt;br/&gt;
 					RocksDBKeySerializationUtils.writeKey(&lt;br/&gt;
 						j,&lt;br/&gt;
 						IntSerializer.INSTANCE,&lt;br/&gt;
 						outputView,&lt;br/&gt;
 						false);&lt;/li&gt;
	&lt;li&gt;byte[] value = rocksDB.get(columnFamilyHandle, outputView.toByteArray());&lt;br/&gt;
+					byte[] value = rocksDB.get(columnFamilyHandle, outputView.getCopyOfBuffer());&lt;br/&gt;
 					if (targetGroupRange.contains&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) 
{
 						Assert.assertEquals(String.valueOf(j), new String(value));
 					}
&lt;p&gt; else {&lt;br/&gt;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtilsTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtilsTest.java&lt;br/&gt;
index d92bef5e960..66c13a9a05f 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtilsTest.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBKeySerializationUtilsTest.java&lt;br/&gt;
@@ -19,11 +19,11 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import org.apache.flink.api.common.typeutils.base.IntSerializer;&lt;br/&gt;
 import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataInputView;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
 import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;&lt;br/&gt;
 import org.apache.flink.core.memory.ByteArrayOutputStreamWithPos;&lt;br/&gt;
+import org.apache.flink.core.memory.DataInputDeserializer;&lt;br/&gt;
 import org.apache.flink.core.memory.DataInputViewStreamWrapper;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.core.memory.DataOutputView;&lt;br/&gt;
 import org.apache.flink.core.memory.DataOutputViewStreamWrapper;&lt;/p&gt;

&lt;p&gt;@@ -63,19 +63,19 @@ public void testKeyGroupSerializationAndDeserialization() throws Exception {&lt;/p&gt;

&lt;p&gt; 	@Test&lt;br/&gt;
 	public void testKeySerializationAndDeserialization() throws Exception {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ByteArrayDataOutputView outputView = new ByteArrayDataOutputView(8);&lt;/li&gt;
	&lt;li&gt;final ByteArrayDataInputView inputView = new ByteArrayDataInputView();&lt;br/&gt;
+		final DataOutputSerializer outputView = new DataOutputSerializer(8);&lt;br/&gt;
+		final DataInputDeserializer inputView = new DataInputDeserializer();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		// test for key&lt;br/&gt;
 		for (int orgKey = 0; orgKey &amp;lt; 100; ++orgKey) &lt;/p&gt;
{
-			outputView.reset();
+			outputView.clear();
 			RocksDBKeySerializationUtils.writeKey(orgKey, IntSerializer.INSTANCE, outputView, false);
-			inputView.setData(outputView.toByteArray());
+			inputView.setBuffer(outputView.getCopyOfBuffer());
 			int deserializedKey = RocksDBKeySerializationUtils.readKey(IntSerializer.INSTANCE, inputView, false);
 			Assert.assertEquals(orgKey, deserializedKey);
 
 			RocksDBKeySerializationUtils.writeKey(orgKey, IntSerializer.INSTANCE, outputView, true);
-			inputView.setData(outputView.toByteArray());
+			inputView.setBuffer(outputView.getCopyOfBuffer());
 			deserializedKey = RocksDBKeySerializationUtils.readKey(IntSerializer.INSTANCE, inputView, true);
 			Assert.assertEquals(orgKey, deserializedKey);
 		}
&lt;p&gt;@@ -83,18 +83,18 @@ public void testKeySerializationAndDeserialization() throws Exception {&lt;/p&gt;

&lt;p&gt; 	@Test&lt;br/&gt;
 	public void testNamespaceSerializationAndDeserialization() throws Exception {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ByteArrayDataOutputView outputView = new ByteArrayDataOutputView(8);&lt;/li&gt;
	&lt;li&gt;final ByteArrayDataInputView inputView = new ByteArrayDataInputView();&lt;br/&gt;
+		final DataOutputSerializer outputView = new DataOutputSerializer(8);&lt;br/&gt;
+		final DataInputDeserializer inputView = new DataInputDeserializer();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		for (int orgNamespace = 0; orgNamespace &amp;lt; 100; ++orgNamespace) &lt;/p&gt;
{
-			outputView.reset();
+			outputView.clear();
 			RocksDBKeySerializationUtils.writeNameSpace(orgNamespace, IntSerializer.INSTANCE, outputView, false);
-			inputView.setData(outputView.toByteArray());
+			inputView.setBuffer(outputView.getCopyOfBuffer());
 			int deserializedNamepsace = RocksDBKeySerializationUtils.readNamespace(IntSerializer.INSTANCE, inputView, false);
 			Assert.assertEquals(orgNamespace, deserializedNamepsace);
 
 			RocksDBKeySerializationUtils.writeNameSpace(orgNamespace, IntSerializer.INSTANCE, outputView, true);
-			inputView.setData(outputView.toByteArray());
+			inputView.setBuffer(outputView.getCopyOfBuffer());
 			deserializedNamepsace = RocksDBKeySerializationUtils.readNamespace(IntSerializer.INSTANCE, inputView, true);
 			Assert.assertEquals(orgNamespace, deserializedNamepsace);
 		}
&lt;p&gt;diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBRocksStateKeysIteratorTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBRocksStateKeysIteratorTest.java&lt;br/&gt;
index e042ebd0609..398df3f00c4 100644&lt;br/&gt;
&amp;#8212; a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBRocksStateKeysIteratorTest.java&lt;br/&gt;
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBRocksStateKeysIteratorTest.java&lt;br/&gt;
@@ -24,7 +24,7 @@&lt;br/&gt;
 import org.apache.flink.api.common.typeutils.base.IntSerializer;&lt;br/&gt;
 import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
 import org.apache.flink.contrib.streaming.state.iterator.RocksStateKeysIterator;&lt;br/&gt;
-import org.apache.flink.core.memory.ByteArrayDataOutputView;&lt;br/&gt;
+import org.apache.flink.core.memory.DataOutputSerializer;&lt;br/&gt;
 import org.apache.flink.runtime.execution.Environment;&lt;br/&gt;
 import org.apache.flink.runtime.operators.testutils.DummyEnvironment;&lt;br/&gt;
 import org.apache.flink.runtime.query.TaskKvStateRegistry;&lt;br/&gt;
@@ -105,7 +105,7 @@ public void testIterator() throws Exception&lt;/p&gt;
{
 				testState.update(String.valueOf(i));
 			}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ByteArrayDataOutputView outputStream = new ByteArrayDataOutputView(8);&lt;br/&gt;
+			DataOutputSerializer outputStream = new DataOutputSerializer(8);&lt;br/&gt;
 			boolean ambiguousKeyPossible = RocksDBKeySerializationUtils.isAmbiguousKeyPossible(keySerializer, namespaceSerializer);&lt;br/&gt;
 			RocksDBKeySerializationUtils.writeNameSpace(&lt;br/&gt;
 				namespace,&lt;br/&gt;
@@ -113,7 +113,7 @@ public void testIterator() throws Exception{&lt;br/&gt;
 				outputStream,&lt;br/&gt;
 				ambiguousKeyPossible);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;byte[] nameSpaceBytes = outputStream.toByteArray();&lt;br/&gt;
+			byte[] nameSpaceBytes = outputStream.getCopyOfBuffer();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			try (&lt;br/&gt;
 				ColumnFamilyHandle handle = keyedStateBackend.getColumnFamilyHandle(testStateName);&lt;br/&gt;
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/SerializedCheckpointData.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/SerializedCheckpointData.java&lt;br/&gt;
index 1a8bc58f7bc..0b082ff180e 100644&lt;br/&gt;
&amp;#8212; a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/SerializedCheckpointData.java&lt;br/&gt;
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/SerializedCheckpointData.java&lt;br/&gt;
@@ -162,7 +162,7 @@ public int getNumIds() &lt;/p&gt;
{
 				deser = new DataInputDeserializer(serializedData, 0, serializedData.length);
 			}
&lt;p&gt; 			else &lt;/p&gt;
{
-				deser.setBuffer(serializedData, 0, serializedData.length);
+				deser.setBuffer(serializedData);
 			}

&lt;p&gt; 			final Set&amp;lt;T&amp;gt; ids = new HashSet&amp;lt;&amp;gt;(checkpoint.getNumIds());&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16588738" author="srichter" created="Wed, 22 Aug 2018 11:35:55 +0000"  >&lt;p&gt;Merged in:&lt;br/&gt;
master: 2b6beed&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13178788">FLINK-10138</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13177954">FLINK-10111</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13178788">FLINK-10138</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 12 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3x7m7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>