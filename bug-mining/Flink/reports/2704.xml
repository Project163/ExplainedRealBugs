<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:35:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10368] &apos;Kerberized YARN on Docker test&apos; unstable</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10368</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Running Kerberized YARN on Docker test end-to-end test failed on an AWS instance. The problem seems to be that the NameNode went into safe-mode due to limited resources.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
SLF4J: &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/hadoop-user/flink-1.6.1/lib/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http:&lt;span class=&quot;code-comment&quot;&gt;//www.slf4j.org/codes.html#multiple_bindings &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; an explanation.
&lt;/span&gt;SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
2018-09-19 09:04:39,201 INFO  org.apache.hadoop.security.UserGroupInformation               - Login successful &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; user hadoop-user using keytab file /home/hadoop-user/hadoop-user.keytab
2018-09-19 09:04:39,453 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at master.docker-hadoop-cluster-network/172.22.0.3:8032
2018-09-19 09:04:39,640 INFO  org.apache.hadoop.yarn.client.AHSProxy                        - Connecting to Application History server at master.docker-hadoop-cluster-network/172.22.0.3:10200
2018-09-19 09:04:39,656 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the flink jar passed. Using the location of &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.yarn.YarnClusterDescriptor to locate the jar
2018-09-19 09:04:39,656 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - No path &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the flink jar passed. Using the location of &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.flink.yarn.YarnClusterDescriptor to locate the jar
2018-09-19 09:04:39,901 INFO  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - Cluster specification: ClusterSpecification{masterMemoryMB=2000, taskManagerMemoryMB=2000, numberTaskManagers=3, slotsPerTaskManager=1}
2018-09-19 09:04:40,286 WARN  org.apache.flink.yarn.AbstractYarnClusterDescriptor           - The configuration directory (&lt;span class=&quot;code-quote&quot;&gt;&apos;/home/hadoop-user/flink-1.6.1/conf&apos;&lt;/span&gt;) contains both LOG4J and Logback configuration files. Please delete or rename one of them.

------------------------------------------------------------
 The program finished with the following exception:

org.apache.flink.client.deployment.ClusterDeploymentException: Couldn&apos;t deploy Yarn session cluster
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.deploySessionCluster(AbstractYarnClusterDescriptor.java:420)
        at org.apache.flink.client.cli.CliFrontend.runProgram(CliFrontend.java:259)
        at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:215)
        at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:1044)
        at org.apache.flink.client.cli.CliFrontend.lambda$main$11(CliFrontend.java:1120)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)
        at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)
        at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1120)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/hadoop-user/.flink/application_1537266361291_0099/lib/slf4j-log4j12-1.7.7.jar. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; to safe mode. Use &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs dfsadmin -safemode leave&quot;&lt;/span&gt; to turn safe mode off. NamenodeHostName:master.docker-hadoop-cluster-network
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2278)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2223)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:728)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:413)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
        at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
        at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:270)
        at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1274)
        at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1216)
        at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:473)
        at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:470)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:470)
        at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:411)
        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:929)
        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:910)
        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:807)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:368)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341)
        at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2002)
        at org.apache.flink.yarn.Utils.setupLocalResource(Utils.java:162)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.setupSingleLocalResource(AbstractYarnClusterDescriptor.java:1139)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.access$000(AbstractYarnClusterDescriptor.java:111)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor$1.visitFile(AbstractYarnClusterDescriptor.java:1200)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor$1.visitFile(AbstractYarnClusterDescriptor.java:1188)
        at java.nio.file.Files.walkFileTree(Files.java:2670)
        at java.nio.file.Files.walkFileTree(Files.java:2742)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.uploadAndRegisterFiles(AbstractYarnClusterDescriptor.java:1188)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.startAppMaster(AbstractYarnClusterDescriptor.java:800)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.deployInternal(AbstractYarnClusterDescriptor.java:542)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.deploySessionCluster(AbstractYarnClusterDescriptor.java:413)
        ... 9 more
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/user/hadoop-user/.flink/application_1537266361291_0099/lib/slf4j-log4j12-1.7.7.jar. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; to safe mode. Use &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs dfsadmin -safemode leave&quot;&lt;/span&gt; to turn safe mode off. NamenodeHostName:master.docker-hadoop-cluster-network
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2278)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2223)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:728)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:413)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)

        at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1489)
        at org.apache.hadoop.ipc.Client.call(Client.java:1435)
        at org.apache.hadoop.ipc.Client.call(Client.java:1345)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
        at com.sun.proxy.$Proxy14.create(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:297)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
        at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
        at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
        at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
        at com.sun.proxy.$Proxy15.create(Unknown Source)
        at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:265)
        ... 33 more
Running the Flink job failed, might be that the cluster is not ready yet. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 795 seconds, retrying ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think it would be good to harden the test.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13186044">FLINK-10368</key>
            <summary>&apos;Kerberized YARN on Docker test&apos; unstable</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="aljoscha">Aljoscha Krettek</assignee>
                                    <reporter username="trohrmann">Till Rohrmann</reporter>
                        <labels>
                            <label>pull-request-available</label>
                            <label>test-stability</label>
                    </labels>
                <created>Wed, 19 Sep 2018 11:57:16 +0000</created>
                <updated>Tue, 6 Aug 2019 15:14:18 +0000</updated>
                            <resolved>Tue, 6 Aug 2019 15:13:45 +0000</resolved>
                                    <version>1.5.3</version>
                    <version>1.6.0</version>
                    <version>1.7.0</version>
                                    <fixVersion>1.8.2</fixVersion>
                    <fixVersion>1.9.0</fixVersion>
                                    <component>Deployment / YARN</component>
                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1200">20m</timespent>
                                <comments>
                            <comment id="16629861" author="aljoscha" created="Thu, 27 Sep 2018 07:28:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt; said we should at checks to the code that see if the cluster could be brought up and then exit the test gracefully without failing when it can&apos;t be brought up.&lt;/p&gt;</comment>
                            <comment id="16656901" author="till.rohrmann" created="Fri, 19 Oct 2018 15:02:11 +0000"  >&lt;p&gt;I encountered another problem:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;The program finished with the following exception:

org.apache.flink.client.deployment.ClusterDeploymentException: Couldn&apos;t deploy Yarn session cluster
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.deploySessionCluster(AbstractYarnClusterDescriptor.java:419)
        at org.apache.flink.client.cli.CliFrontend.runProgram(CliFrontend.java:261)
        at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:215)
        at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:1035)
        at org.apache.flink.client.cli.CliFrontend.lambda$main$9(CliFrontend.java:1111)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
        at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)
        at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1111)
Caused by: org.apache.flink.configuration.IllegalConfigurationException: The number of requested virtual cores per node 1 exceeds the maximum number of virtual cores 0 available in the Yarn Cluster. Please note that the number of virtual cores is set to the number of task slots by &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; unless configured in the Flink config with &lt;span class=&quot;code-quote&quot;&gt;&apos;yarn.containers.vcores.&apos;&lt;/span&gt;
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.isReadyForDeployment(AbstractYarnClusterDescriptor.java:299)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.deployInternal(AbstractYarnClusterDescriptor.java:491)
        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.deploySessionCluster(AbstractYarnClusterDescriptor.java:412)
        ... 9 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Apparently, the cluster thinks that it has only &lt;tt&gt;0&lt;/tt&gt; vcores. This might be a setup issue.&lt;/p&gt;</comment>
                            <comment id="16668821" author="githubbot" created="Tue, 30 Oct 2018 14:55:25 +0000"  >&lt;p&gt;dawidwys opened a new pull request #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Hardened the kerberized yarn e2e test, especially having in mind environments poor in resources.&lt;/p&gt;

&lt;p&gt;   Changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;wait for whole  bootstrapping script to execute on master node before submitting job&lt;/li&gt;
	&lt;li&gt;added check that all containers are up and running before submitting job&lt;/li&gt;
	&lt;li&gt;reduced memory requirements for the kerberized yarn test&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16668837" author="dawidwys" created="Tue, 30 Oct 2018 15:02:24 +0000"  >&lt;p&gt;I&apos;ve tried to harden the test by:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;waiting for whole bootstrapping script to execute on master node before submitting job - the bootstrapping script performs multiple operations on hdfs, we should catch initialization exceptions sooner and potentially fail gracefully, we also limit the number of false exceptions during job submission&lt;/li&gt;
	&lt;li&gt;adding check that all containers are up and running before submitting job - that should catch cases when not enough cores are available, that might happen if slave nodes failed&lt;/li&gt;
	&lt;li&gt;reducing memory requirements for the kerberized yarn test - that should decrease the chance that the cluster will be short on resources&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt; Do you think those changes are sufficient?&lt;/p&gt;</comment>
                            <comment id="16671476" author="githubbot" created="Thu, 1 Nov 2018 11:13:13 +0000"  >&lt;p&gt;aljoscha commented on a change in pull request #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#discussion_r230008139&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#discussion_r230008139&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-end-to-end-tests/test-scripts/test_yarn_kerberos_docker.sh&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -60,19 +64,41 @@ function cluster_shutdown {&lt;br/&gt;
 trap cluster_shutdown INT&lt;br/&gt;
 trap cluster_shutdown EXIT&lt;/p&gt;

&lt;p&gt;-until docker cp $FLINK_TARBALL_DIR/$FLINK_TARBALL master:/home/hadoop-user/; do&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# we&apos;re retrying this one because we don&apos;t know yet if the container is ready&lt;/li&gt;
	&lt;li&gt;echo &quot;Uploading Flink tarball to docker master failed, retrying ...&quot;&lt;/li&gt;
	&lt;li&gt;sleep 5&lt;br/&gt;
+# wait for kerberos to be set up&lt;br/&gt;
+start_time=$(date +%s)&lt;br/&gt;
+until docker logs master 2&amp;gt;&amp;amp;1 | grep -q &quot;Finished master initialization&quot;; do&lt;br/&gt;
+    current_time=$(date +%s)&lt;br/&gt;
+    time_diff=$((current_time - start_time))&lt;br/&gt;
+&lt;br/&gt;
+    if [ $time_diff -ge $MAX_RETRY_SECONDS ]; then&lt;br/&gt;
+        echo &quot;ERROR: Could not start hadoop cluster. Aborting...&quot;&lt;br/&gt;
+        exit 0&lt;br/&gt;
+    else&lt;br/&gt;
+        echo &quot;Waiting for hadoop cluster to come up. We have been trying for $time_diff seconds, retrying ...&quot;&lt;br/&gt;
+        sleep 10&lt;br/&gt;
+    fi&lt;br/&gt;
 done&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+# perform health checks&lt;br/&gt;
+if ! { [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; master 2&amp;gt;&amp;amp;1) = &apos;true&apos; ] &amp;amp;&amp;amp;&lt;br/&gt;
+       [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; slave1 2&amp;gt;&amp;amp;1) = &apos;true&apos; ] &amp;amp;&amp;amp;&lt;br/&gt;
+       [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; slave2 2&amp;gt;&amp;amp;1) = &apos;true&apos; ] &amp;amp;&amp;amp;&lt;br/&gt;
+       [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; kdc 2&amp;gt;&amp;amp;1) = &apos;true&apos; ]; };&lt;br/&gt;
+then&lt;br/&gt;
+    echo &quot;ERROR: Could not start hadoop cluster. At least one of the containers failed. Aborting...&quot;&lt;br/&gt;
+    exit 0&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Isn&apos;t exit code `1` the exit code for failure?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16671477" author="githubbot" created="Thu, 1 Nov 2018 11:13:13 +0000"  >&lt;p&gt;aljoscha commented on a change in pull request #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#discussion_r230008106&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#discussion_r230008106&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-end-to-end-tests/test-scripts/test_yarn_kerberos_docker.sh&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -60,19 +64,41 @@ function cluster_shutdown {&lt;br/&gt;
 trap cluster_shutdown INT&lt;br/&gt;
 trap cluster_shutdown EXIT&lt;/p&gt;

&lt;p&gt;-until docker cp $FLINK_TARBALL_DIR/$FLINK_TARBALL master:/home/hadoop-user/; do&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# we&apos;re retrying this one because we don&apos;t know yet if the container is ready&lt;/li&gt;
	&lt;li&gt;echo &quot;Uploading Flink tarball to docker master failed, retrying ...&quot;&lt;/li&gt;
	&lt;li&gt;sleep 5&lt;br/&gt;
+# wait for kerberos to be set up&lt;br/&gt;
+start_time=$(date +%s)&lt;br/&gt;
+until docker logs master 2&amp;gt;&amp;amp;1 | grep -q &quot;Finished master initialization&quot;; do&lt;br/&gt;
+    current_time=$(date +%s)&lt;br/&gt;
+    time_diff=$((current_time - start_time))&lt;br/&gt;
+&lt;br/&gt;
+    if [ $time_diff -ge $MAX_RETRY_SECONDS ]; then&lt;br/&gt;
+        echo &quot;ERROR: Could not start hadoop cluster. Aborting...&quot;&lt;br/&gt;
+        exit 0&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   Isn&apos;t exit code `1` the exit code for failure?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16671521" author="githubbot" created="Thu, 1 Nov 2018 12:07:19 +0000"  >&lt;p&gt;dawidwys commented on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435020917&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435020917&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Yes, you are right, I&apos;ve used this error code to gracefully abort the test. Wasn&apos;t it the suggested idea in JIRA ticket? &lt;/p&gt;

&lt;p&gt;   I wouldn&apos;t say it should happen often. I&apos;ve tried running the test with resources limited for docker containers and it generally passed. I don&apos;t know which is the better, I can see both pros &amp;amp; cons of both approaches.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16671528" author="githubbot" created="Thu, 1 Nov 2018 12:14:04 +0000"  >&lt;p&gt;aljoscha commented on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435022418&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435022418&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Ah, you&apos;re right! It was even my who said that Till proposed this. If @tillrohrmann is alright with this approach I&apos;d say this is good to merge.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16672919" author="githubbot" created="Fri, 2 Nov 2018 10:48:17 +0000"  >&lt;p&gt;tillrohrmann commented on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435340617&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435340617&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Would it work to retry the deployment logic and fail if we could not deploy the cluster after several attempts?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16673142" author="githubbot" created="Fri, 2 Nov 2018 14:15:08 +0000"  >&lt;p&gt;dawidwys commented on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435393642&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435393642&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   At first I thought it wouldn&apos;t change much (as the cluster starting consists only of bringing up docker containers), but actually there is some kerberos setting up logic, so it might actually make sense.&lt;/p&gt;

&lt;p&gt;   Just to be clear we should fail the test meaning (exit 1).&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16673160" author="githubbot" created="Fri, 2 Nov 2018 14:29:49 +0000"  >&lt;p&gt;tillrohrmann commented on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435398287&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435398287&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   That sounds promising. Let us know once you&apos;ve updated the PR.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16674849" author="githubbot" created="Mon, 5 Nov 2018 09:07:58 +0000"  >&lt;p&gt;dawidwys commented on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435802842&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435802842&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @tillrohrmann @aljoscha I&apos;ve updated the test. Could you have final look?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16674862" author="githubbot" created="Mon, 5 Nov 2018 09:22:04 +0000"  >&lt;p&gt;dawidwys edited a comment on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435802842&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435802842&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @tillrohrmann @aljoscha I&apos;ve updated the test. Could you have the final look?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16674876" author="githubbot" created="Mon, 5 Nov 2018 09:39:08 +0000"  >&lt;p&gt;aljoscha commented on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435811883&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435811883&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   I think this looks good to merge now. :&#128076;&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16674877" author="githubbot" created="Mon, 5 Nov 2018 09:39:15 +0000"  >&lt;p&gt;aljoscha edited a comment on issue #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965#issuecomment-435811883&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965#issuecomment-435811883&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   I think this looks good to merge now. &#128076;&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16674907" author="githubbot" created="Mon, 5 Nov 2018 10:07:25 +0000"  >&lt;p&gt;dawidwys closed pull request #6965: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10368&quot; title=&quot;&amp;#39;Kerberized YARN on Docker test&amp;#39; unstable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10368&quot;&gt;&lt;del&gt;FLINK-10368&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Hardened kerberized yarn e2e test&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6965&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6965&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/bootstrap.sh b/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/bootstrap.sh&lt;br/&gt;
index 7b5e50ba439..5b98b96e51d 100755&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/bootstrap.sh&lt;br/&gt;
+++ b/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/bootstrap.sh&lt;br/&gt;
@@ -124,6 +124,7 @@ elif [ &quot;$1&quot; == &quot;master&quot; ]; then&lt;br/&gt;
     hdfs dfs -chown hadoop-user:hadoop-user /user/hadoop-user&lt;/p&gt;

&lt;p&gt;     kdestroy&lt;br/&gt;
+    echo &quot;Finished master initialization&quot;&lt;/p&gt;

&lt;p&gt;     while true; do sleep 1000; done&lt;br/&gt;
 elif [ &quot;$1&quot; == &quot;worker&quot; ]; then&lt;br/&gt;
diff --git a/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/config/yarn-site.xml b/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/config/yarn-site.xml&lt;br/&gt;
index 9b17acc1656..c7736a69489 100644&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/config/yarn-site.xml&lt;br/&gt;
+++ b/flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/config/yarn-site.xml&lt;br/&gt;
@@ -21,6 +21,11 @@ under the License.&lt;br/&gt;
         &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;br/&gt;
     &amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;+	&amp;lt;property&amp;gt;&lt;br/&gt;
+		&amp;lt;name&amp;gt;yarn.nodemanager.vmem-pmem-ratio&amp;lt;/name&amp;gt;&lt;br/&gt;
+		&amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;&lt;br/&gt;
+	&amp;lt;/property&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
     &amp;lt;!-- this is ignored by the default scheduler but we have to set it because Flink would&lt;br/&gt;
     complain if we didn&apos;t have it --&amp;gt;&lt;br/&gt;
     &amp;lt;property&amp;gt;&lt;br/&gt;
@@ -33,12 +38,12 @@ under the License.&lt;br/&gt;
     are scheduled on one NM, which wouldn&apos;t provoke a previously fixed Kerberos keytab bug. --&amp;gt;&lt;br/&gt;
     &amp;lt;property&amp;gt;&lt;br/&gt;
         &amp;lt;name&amp;gt;yarn.nodemanager.resource.memory-mb&amp;lt;/name&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;value&amp;gt;4100&amp;lt;/value&amp;gt;&lt;br/&gt;
+        &amp;lt;value&amp;gt;2500&amp;lt;/value&amp;gt;&lt;br/&gt;
     &amp;lt;/property&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     &amp;lt;property&amp;gt;&lt;br/&gt;
         &amp;lt;name&amp;gt;yarn.scheduler.minimum-allocation-mb&amp;lt;/name&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;value&amp;gt;2000&amp;lt;/value&amp;gt;&lt;br/&gt;
+        &amp;lt;value&amp;gt;1000&amp;lt;/value&amp;gt;&lt;br/&gt;
     &amp;lt;/property&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     &amp;lt;property&amp;gt;&lt;br/&gt;
diff --git a/flink-end-to-end-tests/test-scripts/test_yarn_kerberos_docker.sh b/flink-end-to-end-tests/test-scripts/test_yarn_kerberos_docker.sh&lt;br/&gt;
index c9ef15d3dc5..5f2dea2ea6a 100755&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/test-scripts/test_yarn_kerberos_docker.sh&lt;br/&gt;
+++ b/flink-end-to-end-tests/test-scripts/test_yarn_kerberos_docker.sh&lt;br/&gt;
@@ -24,7 +24,8 @@ FLINK_TARBALL_DIR=$TEST_DATA_DIR&lt;br/&gt;
 FLINK_TARBALL=flink.tar.gz&lt;br/&gt;
 FLINK_DIRNAME=$(basename $FLINK_DIR)&lt;/p&gt;

&lt;p&gt;-MAX_RETRY_SECONDS=800&lt;br/&gt;
+MAX_RETRY_SECONDS=120&lt;br/&gt;
+CLUSTER_SETUP_RETRIES=3&lt;/p&gt;

&lt;p&gt; echo &quot;Flink Tarball directory $FLINK_TARBALL_DIR&quot;&lt;br/&gt;
 echo &quot;Flink tarball filename $FLINK_TARBALL&quot;&lt;br/&gt;
@@ -33,20 +34,6 @@ echo &quot;End-to-end directory $END_TO_END_DIR&quot;&lt;br/&gt;
 docker --version&lt;br/&gt;
 docker-compose --version&lt;/p&gt;

&lt;p&gt;-mkdir -p $FLINK_TARBALL_DIR&lt;br/&gt;
-tar czf $FLINK_TARBALL_DIR/$FLINK_TARBALL -C $(dirname $FLINK_DIR) .&lt;br/&gt;
-&lt;br/&gt;
-echo &quot;Building Hadoop Docker container&quot;&lt;br/&gt;
-until docker build --build-arg HADOOP_VERSION=2.8.4 -f $END_TO_END_DIR/test-scripts/docker-hadoop-secure-cluster/Dockerfile -t flink/docker-hadoop-secure-cluster:latest $END_TO_END_DIR/test-scripts/docker-hadoop-secure-cluster/; do&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# with all the downloading and ubuntu updating a lot of flakiness can happen, make sure&lt;/li&gt;
	&lt;li&gt;# we don&apos;t immediately fail&lt;/li&gt;
	&lt;li&gt;echo &quot;Something went wrong while building the Docker image, retrying ...&quot;&lt;/li&gt;
	&lt;li&gt;sleep 2&lt;br/&gt;
-done&lt;br/&gt;
-&lt;br/&gt;
-echo &quot;Starting Hadoop cluster&quot;&lt;br/&gt;
-docker-compose -f $END_TO_END_DIR/test-scripts/docker-hadoop-secure-cluster/docker-compose.yml up -d&lt;br/&gt;
-&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;make sure we stop our cluster at the end&lt;br/&gt;
 function cluster_shutdown {&lt;/li&gt;
	&lt;li&gt;don&apos;t call ourselves again for another signal interruption&lt;br/&gt;
@@ -60,12 +47,71 @@ function cluster_shutdown {&lt;br/&gt;
 trap cluster_shutdown INT&lt;br/&gt;
 trap cluster_shutdown EXIT&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;-until docker cp $FLINK_TARBALL_DIR/$FLINK_TARBALL master:/home/hadoop-user/; do&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# we&apos;re retrying this one because we don&apos;t know yet if the container is ready&lt;/li&gt;
	&lt;li&gt;echo &quot;Uploading Flink tarball to docker master failed, retrying ...&quot;&lt;/li&gt;
	&lt;li&gt;sleep 5&lt;br/&gt;
+function start_hadoop_cluster() {&lt;br/&gt;
+    echo &quot;Starting Hadoop cluster&quot;&lt;br/&gt;
+    docker-compose -f $END_TO_END_DIR/test-scripts/docker-hadoop-secure-cluster/docker-compose.yml up -d&lt;br/&gt;
+&lt;br/&gt;
+    # wait for kerberos to be set up&lt;br/&gt;
+    start_time=$(date +%s)&lt;br/&gt;
+    until docker logs master 2&amp;gt;&amp;amp;1 | grep -q &quot;Finished master initialization&quot;; do&lt;br/&gt;
+        current_time=$(date +%s)&lt;br/&gt;
+        time_diff=$((current_time - start_time))&lt;br/&gt;
+&lt;br/&gt;
+        if [ $time_diff -ge $MAX_RETRY_SECONDS ]; then&lt;br/&gt;
+            return 1&lt;br/&gt;
+        else&lt;br/&gt;
+            echo &quot;Waiting for hadoop cluster to come up. We have been trying for $time_diff seconds, retrying ...&quot;&lt;br/&gt;
+            sleep 10&lt;br/&gt;
+        fi&lt;br/&gt;
+    done&lt;br/&gt;
+&lt;br/&gt;
+    # perform health checks&lt;br/&gt;
+    if ! { [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; master 2&amp;gt;&amp;amp;1) = &apos;true&apos; ] &amp;amp;&amp;amp;&lt;br/&gt;
+           [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; slave1 2&amp;gt;&amp;amp;1) = &apos;true&apos; ] &amp;amp;&amp;amp;&lt;br/&gt;
+           [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; slave2 2&amp;gt;&amp;amp;1) = &apos;true&apos; ] &amp;amp;&amp;amp;&lt;br/&gt;
+           [ $(docker inspect -f &apos;&lt;tt&gt;.State.Running&lt;/tt&gt;&apos; kdc 2&amp;gt;&amp;amp;1) = &apos;true&apos; ]; };&lt;br/&gt;
+    then&lt;br/&gt;
+        return 1&lt;br/&gt;
+    fi&lt;br/&gt;
+&lt;br/&gt;
+    return 0&lt;br/&gt;
+}&lt;br/&gt;
+&lt;br/&gt;
+mkdir -p $FLINK_TARBALL_DIR&lt;br/&gt;
+tar czf $FLINK_TARBALL_DIR/$FLINK_TARBALL -C $(dirname $FLINK_DIR) .&lt;br/&gt;
+&lt;br/&gt;
+echo &quot;Building Hadoop Docker container&quot;&lt;br/&gt;
+until docker build --build-arg HADOOP_VERSION=2.8.4 \&lt;br/&gt;
+    -f $END_TO_END_DIR/test-scripts/docker-hadoop-secure-cluster/Dockerfile \&lt;br/&gt;
+    -t flink/docker-hadoop-secure-cluster:latest \&lt;br/&gt;
+    $END_TO_END_DIR/test-scripts/docker-hadoop-secure-cluster/;&lt;br/&gt;
+do&lt;br/&gt;
+    # with all the downloading and ubuntu updating a lot of flakiness can happen, make sure&lt;br/&gt;
+    # we don&apos;t immediately fail&lt;br/&gt;
+    echo &quot;Something went wrong while building the Docker image, retrying ...&quot;&lt;br/&gt;
+    sleep 2&lt;br/&gt;
+done&lt;br/&gt;
+&lt;br/&gt;
+CLUSTER_STARTED=1&lt;br/&gt;
&lt;ins&gt;for (( i = 0; i &amp;lt; $CLUSTER_SETUP_RETRIES; i&lt;/ins&gt;+ ))&lt;br/&gt;
+do&lt;br/&gt;
+    if start_hadoop_cluster; then&lt;br/&gt;
+       echo &quot;Cluster started successfully.&quot;&lt;br/&gt;
+       CLUSTER_STARTED=0&lt;br/&gt;
+       break #continue test, cluster set up succeeded&lt;br/&gt;
+    fi&lt;br/&gt;
+&lt;br/&gt;
+    echo &quot;ERROR: Could not start hadoop cluster. Retrying...&quot;&lt;br/&gt;
+    docker-compose -f $END_TO_END_DIR/test-scripts/docker-hadoop-secure-cluster/docker-compose.yml down&lt;br/&gt;
 done&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+if [[ ${CLUSTER_STARTED} -ne 0 ]]; then&lt;br/&gt;
+    echo &quot;ERROR: Could not start hadoop cluster. Aborting...&quot;&lt;br/&gt;
+    exit 1&lt;br/&gt;
+fi&lt;br/&gt;
+&lt;br/&gt;
+docker cp $FLINK_TARBALL_DIR/$FLINK_TARBALL master:/home/hadoop-user/&lt;br/&gt;
+&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;now, at least the container is ready&lt;br/&gt;
 docker exec -it master bash -c &quot;tar xzf /home/hadoop-user/$FLINK_TARBALL --directory /home/hadoop-user/&quot;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;@@ -73,6 +119,7 @@ docker exec -it master bash -c &quot;tar xzf /home/hadoop-user/$FLINK_TARBALL --direc&lt;br/&gt;
 docker exec -it master bash -c &quot;echo \&quot;security.kerberos.login.keytab: /home/hadoop-user/hadoop-user.keytab\&quot; &amp;gt; /home/hadoop-user/$FLINK_DIRNAME/conf/flink-conf.yaml&quot;&lt;br/&gt;
 docker exec -it master bash -c &quot;echo \&quot;security.kerberos.login.principal: hadoop-user\&quot; &amp;gt;&amp;gt; /home/hadoop-user/$FLINK_DIRNAME/conf/flink-conf.yaml&quot;&lt;br/&gt;
 docker exec -it master bash -c &quot;echo \&quot;slot.request.timeout: 60000\&quot; &amp;gt;&amp;gt; /home/hadoop-user/$FLINK_DIRNAME/conf/flink-conf.yaml&quot;&lt;br/&gt;
+docker exec -it master bash -c &quot;echo \&quot;containerized.heap-cutoff-min: 100\&quot; &amp;gt;&amp;gt; /home/hadoop-user/$FLINK_DIRNAME/conf/flink-conf.yaml&quot;&lt;/p&gt;

&lt;p&gt; echo &quot;Flink config:&quot;&lt;br/&gt;
 docker exec -it master bash -c &quot;cat /home/hadoop-user/$FLINK_DIRNAME/conf/flink-conf.yaml&quot;&lt;br/&gt;
@@ &lt;del&gt;84,33 +131,28 @@ OUTPUT_PATH=hdfs:///user/hadoop-user/wc-out&lt;/del&gt;$RANDOM&lt;br/&gt;
 start_time=$(date +%s)&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;it&apos;s important to run this with higher parallelism, otherwise we might risk that&lt;/li&gt;
	&lt;li&gt;JM and TM are on the same YARN node and that we therefore don&apos;t test the keytab shipping&lt;br/&gt;
-until docker exec -it master bash -c &quot;export HADOOP_CLASSPATH=\`hadoop classpath\` &amp;amp;&amp;amp; /home/hadoop-user/$FLINK_DIRNAME/bin/flink run -m yarn-cluster -yn 3 -ys 1 -ytm 2000 -yjm 2000 -p 3 /home/hadoop-user/$FLINK_DIRNAME/examples/streaming/WordCount.jar --output $OUTPUT_PATH&quot;; do&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;current_time=$(date +%s)&lt;/li&gt;
	&lt;li&gt;time_diff=$((current_time - start_time))&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;if [ $time_diff -ge $MAX_RETRY_SECONDS ]; then&lt;/li&gt;
	&lt;li&gt;echo &quot;We tried running the job for $time_diff seconds, max is $MAX_RETRY_SECONDS seconds, aborting&quot;&lt;/li&gt;
	&lt;li&gt;mkdir -p $TEST_DATA_DIR/logs&lt;/li&gt;
	&lt;li&gt;echo &quot;Hadoop logs:&quot;&lt;/li&gt;
	&lt;li&gt;docker cp master:/var/log/hadoop/* $TEST_DATA_DIR/logs/&lt;/li&gt;
	&lt;li&gt;for f in $TEST_DATA_DIR/logs/*; do&lt;/li&gt;
	&lt;li&gt;echo &quot;$f:&quot;&lt;/li&gt;
	&lt;li&gt;cat $f&lt;/li&gt;
	&lt;li&gt;done&lt;/li&gt;
	&lt;li&gt;echo &quot;Docker logs:&quot;&lt;/li&gt;
	&lt;li&gt;docker logs master&lt;/li&gt;
	&lt;li&gt;exit 1&lt;/li&gt;
	&lt;li&gt;else&lt;/li&gt;
	&lt;li&gt;echo &quot;Running the Flink job failed, might be that the cluster is not ready yet. We have been trying for $time_diff seconds, retrying ...&quot;&lt;/li&gt;
	&lt;li&gt;sleep 5&lt;/li&gt;
	&lt;li&gt;fi&lt;br/&gt;
-done&lt;br/&gt;
-&lt;br/&gt;
-docker exec -it master bash -c &quot;kinit -kt /home/hadoop-user/hadoop-user.keytab hadoop-user&quot;&lt;br/&gt;
-docker exec -it master bash -c &quot;hdfs dfs -ls $OUTPUT_PATH&quot;&lt;br/&gt;
-OUTPUT=$(docker exec -it master bash -c &quot;hdfs dfs -cat $OUTPUT_PATH/*&quot;)&lt;br/&gt;
-docker exec -it master bash -c &quot;kdestroy&quot;&lt;br/&gt;
-echo &quot;$OUTPUT&quot;&lt;br/&gt;
+if docker exec -it master bash -c &quot;export HADOOP_CLASSPATH=\`hadoop classpath\` &amp;amp;&amp;amp; \&lt;br/&gt;
+   /home/hadoop-user/$FLINK_DIRNAME/bin/flink run -m yarn-cluster -yn 3 -ys 1 -ytm 1000 -yjm 1000 \&lt;br/&gt;
+   -p 3 /home/hadoop-user/$FLINK_DIRNAME/examples/streaming/WordCount.jar --output $OUTPUT_PATH&quot;;&lt;br/&gt;
+then&lt;br/&gt;
+    docker exec -it master bash -c &quot;kinit -kt /home/hadoop-user/hadoop-user.keytab hadoop-user&quot;&lt;br/&gt;
+    docker exec -it master bash -c &quot;hdfs dfs -ls $OUTPUT_PATH&quot;&lt;br/&gt;
+    OUTPUT=$(docker exec -it master bash -c &quot;hdfs dfs -cat $OUTPUT_PATH/*&quot;)&lt;br/&gt;
+    docker exec -it master bash -c &quot;kdestroy&quot;&lt;br/&gt;
+    echo &quot;$OUTPUT&quot;&lt;br/&gt;
+else&lt;br/&gt;
+    echo &quot;Running the job failed.&quot;&lt;br/&gt;
+    mkdir -p $TEST_DATA_DIR/logs&lt;br/&gt;
+    echo &quot;Hadoop logs:&quot;&lt;br/&gt;
+    docker cp master:/var/log/hadoop/* $TEST_DATA_DIR/logs/&lt;br/&gt;
+    for f in $TEST_DATA_DIR/logs/*; do&lt;br/&gt;
+        echo &quot;$f:&quot;&lt;br/&gt;
+        cat $f&lt;br/&gt;
+    done&lt;br/&gt;
+    echo &quot;Docker logs:&quot;&lt;br/&gt;
+    docker logs master&lt;br/&gt;
+    exit 1&lt;br/&gt;
+fi&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; if [[ ! &quot;$OUTPUT&quot; =~ &quot;consummation,1&quot; ]]; then&lt;br/&gt;
     echo &quot;Output does not contain (consummation, 1) as required&quot;&lt;br/&gt;
@@ -139,7 +181,10 @@ fi&lt;br/&gt;
 echo &quot;Running Job without configured keytab, the exception you see below is expected&quot;&lt;br/&gt;
 docker exec -it master bash -c &quot;echo \&quot;\&quot; &amp;gt; /home/hadoop-user/$FLINK_DIRNAME/conf/flink-conf.yaml&quot;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;verify that it doesn&apos;t work if we don&apos;t configure a keytab&lt;br/&gt;
-OUTPUT=$(docker exec -it master bash -c &quot;export HADOOP_CLASSPATH=\`hadoop classpath\` &amp;amp;&amp;amp; /home/hadoop-user/$FLINK_DIRNAME/bin/flink run -m yarn-cluster -yn 3 -ys 1 -ytm 1200 -yjm 800 -p 3 /home/hadoop-user/$FLINK_DIRNAME/examples/streaming/WordCount.jar --output $OUTPUT_PATH&quot;)&lt;br/&gt;
+OUTPUT=$(docker exec -it master bash -c &quot;export HADOOP_CLASSPATH=\`hadoop classpath\` &amp;amp;&amp;amp; \&lt;br/&gt;
+    /home/hadoop-user/$FLINK_DIRNAME/bin/flink run \&lt;br/&gt;
+    -m yarn-cluster -yn 3 -ys 1 -ytm 1000 -yjm 1000 -p 3 \&lt;br/&gt;
+    /home/hadoop-user/$FLINK_DIRNAME/examples/streaming/WordCount.jar --output $OUTPUT_PATH&quot;)&lt;br/&gt;
 echo &quot;$OUTPUT&quot;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt; if [[ ! &quot;$OUTPUT&quot; =~ &quot;Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials&quot; ]]; then&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16674912" author="dawidwys" created="Mon, 5 Nov 2018 10:13:45 +0000"  >&lt;p&gt;Fixed in master via: 413a77157caf25dbbfb8b0caaf2c9e12c7374d98&lt;br/&gt;
Fixed in 1.7 via: 08cd6ea7cd8afa8d2761dde521eb9a7bf21ec5e6&lt;br/&gt;
Fixed in 1.6.3 via: ddcdfa5b8e89a7fb9bfe065bae376ff8571abf85&lt;br/&gt;
Fixed in 1.5.6 via: 42a84c7ea96e95ec9bfdf5fceb41ad841f44ba80&lt;/p&gt;</comment>
                            <comment id="16694596" author="till.rohrmann" created="Wed, 21 Nov 2018 11:53:57 +0000"  >&lt;p&gt;The test seems still to be unstable. It failed running it on an AWS instance:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Successfully built 48a8281421be
Starting Hadoop cluster
Creating network &lt;span class=&quot;code-quote&quot;&gt;&quot;docker-hadoop-cluster-network&quot;&lt;/span&gt; with the &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; driver
Creating kdc ... done
Creating master ... done
Creating slave2 ... done
Creating slave1 ... done
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 0 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 10 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 20 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 30 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 41 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 51 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 61 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 71 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 81 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 91 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 101 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 111 seconds, retrying ...
ERROR: Could not start hadoop cluster. Retrying...
Stopping slave1 ... done
Stopping slave2 ... done
Stopping master ... done
Stopping kdc    ... done
Removing slave1 ... done
Removing slave2 ... done
Removing master ... done
Removing kdc    ... done
Removing network docker-hadoop-cluster-network
Starting Hadoop cluster
Creating network &lt;span class=&quot;code-quote&quot;&gt;&quot;docker-hadoop-cluster-network&quot;&lt;/span&gt; with the &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; driver
Creating kdc ... done
Creating master ... done
Creating slave2 ... done
Creating slave1 ... done
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 11 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 21 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 31 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 41 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 51 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 61 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 71 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 81 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 91 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 101 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 111 seconds, retrying ...
ERROR: Could not start hadoop cluster. Retrying...
Stopping slave1 ... done
Stopping slave2 ... done
Stopping master ... done
Stopping kdc    ... done
Removing slave1 ... done
Removing slave2 ... done
Removing master ... done
Removing kdc    ... done
Removing network docker-hadoop-cluster-network
Starting Hadoop cluster
Creating network &lt;span class=&quot;code-quote&quot;&gt;&quot;docker-hadoop-cluster-network&quot;&lt;/span&gt; with the &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; driver
Creating kdc ... done
Creating master ... done
Creating slave2 ... done
Creating slave1 ... done
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 0 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 10 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 20 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 30 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 41 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 51 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 61 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 71 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 81 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 91 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 101 seconds, retrying ...
Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; hadoop cluster to come up. We have been trying &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 111 seconds, retrying ...
ERROR: Could not start hadoop cluster. Retrying...
Stopping slave1 ... done
Stopping slave2 ... done
Stopping master ... done
Stopping kdc    ... done
Removing slave1 ... done
Removing slave2 ... done
Removing master ... done
Removing kdc    ... done
Removing network docker-hadoop-cluster-network
ERROR: Could not start hadoop cluster. Aborting...
Removing network docker-hadoop-cluster-network
WARNING: Network docker-hadoop-cluster-network not found.
[FAIL] Test script contains errors.
Checking &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; errors...
No errors in log files.
Checking &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; exceptions...
No exceptions in log files.
Checking &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; non-empty .out files...
grep: /home/admin/flink-1.7.0/log/*.out: No such file or directory
No non-empty .out files.

[FAIL] &lt;span class=&quot;code-quote&quot;&gt;&apos;Running Kerberized YARN on Docker test &apos;&lt;/span&gt; failed after 15 minutes and 33 seconds! Test exited with exit code 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16897021" author="aljoscha" created="Wed, 31 Jul 2019 10:13:16 +0000"  >&lt;p&gt;From &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tzulitai&quot; class=&quot;user-hover&quot; rel=&quot;tzulitai&quot;&gt;tzulitai&lt;/a&gt;: lately the tests are failing for a different reason. See &lt;a href=&quot;https://api.travis-ci.org/v3/job/564925127/log.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://api.travis-ci.org/v3/job/564925127/log.txt&lt;/a&gt;, where we have:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not allocate all requires slots within timeout of 60000 ms. Slots required: 7, slots allocated: 3, previous allocation IDs: [], execution status: completed: Attempt #0 (Source: Collection Source (1/1)) @ org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot@41102513 - [SCHEDULED], completed exceptionally: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: java.util.concurrent.TimeoutException/java.util.concurrent.CompletableFuture@3948e0b9[Completed exceptionally], completed: Attempt #0 (Flat Map (2/3)) @ org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot@4c66bf85 - [SCHEDULED], completed: Attempt #0 (Flat Map (3/3)) @ org.apache.flink.runtime.jobmaster.slotpool.SingleLogicalSlot@4e0d1ec1 - [SCHEDULED], incomplete: java.util.concurrent.CompletableFuture@e7592ae[Not completed, 1 dependents], incomplete: java.util.concurrent.CompletableFuture@70c6f6f1[Not completed, 1 dependents], incomplete: java.util.concurrent.CompletableFuture@925e5fb[Not completed, 1 dependents]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16901003" author="aljoscha" created="Tue, 6 Aug 2019 12:52:09 +0000"  >&lt;p&gt;Resolved on master in&lt;br/&gt;
41e9f7831ae0eb5924cb21a4a2a7a64e9cb16bc6&lt;br/&gt;
515325694618d5b2dc8728bf40261f73d41512d7&lt;/p&gt;</comment>
                            <comment id="16901143" author="aljoscha" created="Tue, 6 Aug 2019 15:03:54 +0000"  >&lt;p&gt;Resolved on release-1.9 in&lt;br/&gt;
2544a04889535244f2e7153732bc7151b0fcd070&lt;br/&gt;
a01d2421336ee950beee7d8bfdc614c0137a6a24&lt;/p&gt;</comment>
                            <comment id="16901161" author="aljoscha" created="Tue, 6 Aug 2019 15:13:12 +0000"  >&lt;p&gt;Resolved on release-1.8 in&lt;br/&gt;
94415058a3e71ff53b7d3985fa038fa1c4e4aefa&lt;br/&gt;
954f3c0fb33185c34fca485ccf47a2d0de587d72&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 15 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z05584:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>