<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:56:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-20722] HiveTableSink should copy the record when converting RowData to Row</title>
                <link>https://issues.apache.org/jira/browse/FLINK-20722</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Add the following test in &lt;tt&gt;TableEnvHiveConnectorITCase&lt;/tt&gt; to reproduce the issue:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
	@Test
	&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void test() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
		TableEnvironment tableEnv = getTableEnvWithHiveCatalog();
		tableEnv.executeSql(&lt;span class=&quot;code-quote&quot;&gt;&quot;create table src1(key string, val string)&quot;&lt;/span&gt;);
		tableEnv.executeSql(&lt;span class=&quot;code-quote&quot;&gt;&quot;create table src2(key string, val string)&quot;&lt;/span&gt;);
		tableEnv.executeSql(&lt;span class=&quot;code-quote&quot;&gt;&quot;create table dest(key string, val string)&quot;&lt;/span&gt;);
		HiveTestUtils.createTextTableInserter(hiveCatalog, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;src1&quot;&lt;/span&gt;)
				.addRow(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;val1&quot;&lt;/span&gt;})
				.addRow(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;2&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;val2&quot;&lt;/span&gt;})
				.addRow(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;3&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;val3&quot;&lt;/span&gt;})
				.commit();
		HiveTestUtils.createTextTableInserter(hiveCatalog, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;src2&quot;&lt;/span&gt;)
				.addRow(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;3&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;val4&quot;&lt;/span&gt;})
				.addRow(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;4&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;val4&quot;&lt;/span&gt;})
				.commit();
		tableEnv.executeSql(&lt;span class=&quot;code-quote&quot;&gt;&quot;INSERT OVERWRITE dest\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT j.*\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;FROM (SELECT t1.key, p1.val\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      FROM src2 t1\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      LEFT OUTER JOIN src1 p1\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      ON (t1.key = p1.key)\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      UNION ALL\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      SELECT t2.key, p2.val\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      FROM src2 t2\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      LEFT OUTER JOIN src1 p2\n&quot;&lt;/span&gt; +
				&lt;span class=&quot;code-quote&quot;&gt;&quot;      ON (t2.key = p2.key)) j&quot;&lt;/span&gt;).await();
	}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13347352">FLINK-20722</key>
            <summary>HiveTableSink should copy the record when converting RowData to Row</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="lirui">Rui Li</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Tue, 22 Dec 2020 13:10:47 +0000</created>
                <updated>Sat, 28 Aug 2021 11:17:00 +0000</updated>
                            <resolved>Wed, 21 Apr 2021 03:13:02 +0000</resolved>
                                    <version>1.12.2</version>
                                    <fixVersion>1.13.0</fixVersion>
                    <fixVersion>1.14.0</fixVersion>
                    <fixVersion>1.12.3</fixVersion>
                                    <component>Connectors / Hive</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="17253485" author="lirui" created="Tue, 22 Dec 2020 13:12:51 +0000"  >&lt;p&gt;Execution plan is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Abstract Syntax Tree ==
LogicalSink(table=[test-catalog.default.dest], fields=[key, val])
+- LogicalProject(key=[$0], val=[$1])
   +- LogicalUnion(all=[true])
      :- LogicalProject(key=[$0], val=[$3])
      :  +- LogicalJoin(condition=[=($0, $2)], joinType=[left])
      :     :- LogicalTableScan(table=[[test-catalog, default, src2]])
      :     +- LogicalTableScan(table=[[test-catalog, default, src1]])
      +- LogicalProject(key=[$0], val=[$3])
         +- LogicalJoin(condition=[=($0, $2)], joinType=[left])
            :- LogicalTableScan(table=[[test-catalog, default, src2]])
            +- LogicalTableScan(table=[[test-catalog, default, src1]])

== Optimized Physical Plan ==
Sink(table=[test-catalog.default.dest], fields=[key, val])
+- Union(all=[true], union=[key, val])
   :- Calc(select=[key, val])
   :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(key, key0)], select=[key, key0, val], build=[left])
   :     :- Exchange(distribution=[hash[key]])
   :     :  +- TableSourceScan(table=[[test-catalog, default, src2, project=[key]]], fields=[key])
   :     +- Exchange(distribution=[hash[key]])
   :        +- TableSourceScan(table=[[test-catalog, default, src1]], fields=[key, val])
   +- Calc(select=[key, val])
      +- HashJoin(joinType=[LeftOuterJoin], where=[=(key, key0)], select=[key, key0, val], build=[left])
         :- Exchange(distribution=[hash[key]])
         :  +- TableSourceScan(table=[[test-catalog, default, src2, project=[key]]], fields=[key])
         +- Exchange(distribution=[hash[key]])
            +- TableSourceScan(table=[[test-catalog, default, src1]], fields=[key, val])

== Optimized Execution Plan ==
Sink(table=[test-catalog.default.dest], fields=[key, val])
+- MultipleInput(readOrder=[0,1], members=[\nUnion(all=[true], union=[key, val])\n:- Calc(select=[key, val])(reuse_id=[1])\n:  +- HashJoin(joinType=[LeftOuterJoin], where=[(key = key0)], select=[key, key0, val], build=[left])\n:     :- [#1] Exchange(distribution=[hash[key]])\n:     +- [#2] Exchange(distribution=[hash[key]])\n+- Reused(reference_id=[1])\n])
   :- Exchange(distribution=[hash[key]])
   :  +- TableSourceScan(table=[[test-catalog, default, src2, project=[key]]], fields=[key])
   +- Exchange(distribution=[hash[key]])
      +- TableSourceScan(table=[[test-catalog, default, src1]], fields=[key, val])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Stack trace is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: java.lang.ClassCastException: org.apache.flink.types.Row cannot be cast to org.apache.flink.table.data.RowData
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.table.runtime.operators.multipleinput.output.OneInputStreamOperatorOutput.pushToOperator(OneInputStreamOperatorOutput.java:77)
	at org.apache.flink.table.runtime.operators.multipleinput.output.OneInputStreamOperatorOutput.collect(OneInputStreamOperatorOutput.java:62)
	at org.apache.flink.table.runtime.operators.multipleinput.output.OneInputStreamOperatorOutput.collect(OneInputStreamOperatorOutput.java:32)
	at org.apache.flink.table.runtime.operators.multipleinput.output.BroadcastingOutput.collect(BroadcastingOutput.java:74)
	at org.apache.flink.table.runtime.operators.multipleinput.output.BroadcastingOutput.collect(BroadcastingOutput.java:37)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:52)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:30)
	at BatchExecCalc$16.processElement(Unknown Source)
	at org.apache.flink.table.runtime.operators.multipleinput.output.OneInputStreamOperatorOutput.pushToOperator(OneInputStreamOperatorOutput.java:77)
	at org.apache.flink.table.runtime.operators.multipleinput.output.OneInputStreamOperatorOutput.collect(OneInputStreamOperatorOutput.java:62)
	at org.apache.flink.table.runtime.operators.multipleinput.output.OneInputStreamOperatorOutput.collect(OneInputStreamOperatorOutput.java:32)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:52)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:30)
	at org.apache.flink.table.runtime.util.StreamRecordCollector.collect(StreamRecordCollector.java:44)
	at org.apache.flink.table.runtime.operators.join.HashJoinOperator.collect(HashJoinOperator.java:201)
	at org.apache.flink.table.runtime.operators.join.HashJoinOperator.innerJoin(HashJoinOperator.java:184)
	at org.apache.flink.table.runtime.operators.join.HashJoinOperator$BuildOuterHashJoinOperator.join(HashJoinOperator.java:331)
	at org.apache.flink.table.runtime.operators.join.HashJoinOperator.joinWithNextKey(HashJoinOperator.java:178)
	at org.apache.flink.table.runtime.operators.join.HashJoinOperator.processElement2(HashJoinOperator.java:147)
	at org.apache.flink.table.runtime.operators.multipleinput.input.SecondInputOfTwoInput.processElement(SecondInputOfTwoInput.java:41)
	at org.apache.flink.streaming.runtime.io.StreamMultipleInputProcessorFactory$StreamTaskNetworkOutput.emitRecord(StreamMultipleInputProcessorFactory.java:259)
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.processElement(StreamTaskNetworkInput.java:184)
	at org.apache.flink.streaming.runtime.io.StreamTaskNetworkInput.emitNext(StreamTaskNetworkInput.java:157)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:67)
	at org.apache.flink.streaming.runtime.io.StreamMultipleInputProcessor.processInput(StreamMultipleInputProcessor.java:83)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:372)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:191)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:575)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:539)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:722)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:547)
	at java.lang.Thread.run(Thread.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17253488" author="lirui" created="Tue, 22 Dec 2020 13:18:31 +0000"  >&lt;p&gt;I did a little debugging and I think it&apos;s because in &lt;tt&gt;BroadcastingOutput::collect&lt;/tt&gt; we broadcast the same StreamRecord to all the outputs. However, HiveTableSink &lt;a href=&quot;https://github.com/apache/flink/blob/release-1.12.0/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSink.java#L209&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;converts&lt;/a&gt; RowData to Row. Therefore when we pass the record to the 2nd output in BroadcastingOutput, the output finds out the data is a Row and thus the exception.&lt;/p&gt;</comment>
                            <comment id="17253853" author="godfreyhe" created="Wed, 23 Dec 2020 02:48:20 +0000"  >&lt;p&gt;HiveTableSink should copy the record if object reuse enabled.&lt;/p&gt;</comment>
                            <comment id="17253940" author="lirui" created="Wed, 23 Dec 2020 07:41:11 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=godfreyhe&quot; class=&quot;user-hover&quot; rel=&quot;godfreyhe&quot;&gt;godfreyhe&lt;/a&gt; for your suggestions. I&apos;ll open a PR accordingly.&lt;/p&gt;</comment>
                            <comment id="17276080" author="jark" created="Mon, 1 Feb 2021 06:24:43 +0000"  >&lt;p&gt;Sorry, but shouldn&apos;t this be fixed in &lt;tt&gt;multipleinput.output.BroadcastingOutput&lt;/tt&gt;? Otherwise, all the connectors may need this special fix which is introduced by multi-input. IMO, multi-input should create a copying &lt;tt&gt;BroadcastingOutput&lt;/tt&gt; when object reuse is enabled, just like how runtime operator chian does, &lt;tt&gt;CopyingBroadcastingOutputCollector&lt;/tt&gt; vs. &lt;tt&gt;BroadcastingOutputCollector&lt;/tt&gt;. What do you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=godfreyhe&quot; class=&quot;user-hover&quot; rel=&quot;godfreyhe&quot;&gt;godfreyhe&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="17313528" author="jark" created="Fri, 2 Apr 2021 02:53:38 +0000"  >&lt;p&gt;ping &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=godfreyhe&quot; class=&quot;user-hover&quot; rel=&quot;godfreyhe&quot;&gt;godfreyhe&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17313531" author="godfreyhe" created="Fri, 2 Apr 2021 03:00:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jark&quot; class=&quot;user-hover&quot; rel=&quot;jark&quot;&gt;jark&lt;/a&gt;, we should use CopyingBroadcastingOutput if isObjectReuseEnabled is true, just like line #586 in OperatorChain. &lt;/p&gt;</comment>
                            <comment id="17313592" author="jark" created="Fri, 2 Apr 2021 05:55:14 +0000"  >&lt;p&gt;Yes. Assigned to you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=godfreyhe&quot; class=&quot;user-hover&quot; rel=&quot;godfreyhe&quot;&gt;godfreyhe&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17319056" author="dawidwys" created="Mon, 12 Apr 2021 06:36:41 +0000"  >&lt;p&gt;Do you plan to include it in 1.13 &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jark&quot; class=&quot;user-hover&quot; rel=&quot;jark&quot;&gt;jark&lt;/a&gt;&#160; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=godfreyhe&quot; class=&quot;user-hover&quot; rel=&quot;godfreyhe&quot;&gt;godfreyhe&lt;/a&gt; ?&lt;/p&gt;</comment>
                            <comment id="17326226" author="godfreyhe" created="Wed, 21 Apr 2021 03:13:02 +0000"  >&lt;p&gt;Fixed in 1.140: 65827041830e1332aeb373eb64ae31505a49f268&lt;br/&gt;
Fixed in 1.13.0: d58db3b6d0129273ae592e541c3c25b6b379ba37&lt;br/&gt;
Fixed in 1.12.3: aada320d9027450e915b5791d86552bc9a30b386&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 29 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0lqq0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>