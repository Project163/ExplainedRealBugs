<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:30:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-7978] Kafka011 exactly-once Producer sporadically fails to commit under high parallelism</title>
                <link>https://issues.apache.org/jira/browse/FLINK-7978</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The Kafka011 exactly-once producer sporadically fails to commit/confirm the first checkpoint. The behavior seems to be easier reproduced under high job parallelism.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Logs/Stacktrace&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;10:24:35,347 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator     - Completed checkpoint 1 (191029 bytes in 1435 ms).
10:24:35,349 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 2/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-12], transactionStartTime=1509787474588} from checkpoint 1
10:24:35,349 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 1/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-8], transactionStartTime=1509787474393} from checkpoint 1
10:24:35,349 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 0/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-4], transactionStartTime=1509787474448} from checkpoint 1
10:24:35,350 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 6/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-34], transactionStartTime=1509787474742} from checkpoint 1
10:24:35,350 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 4/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-23], transactionStartTime=1509787474777} from checkpoint 1
10:24:35,353 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 10/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-52], transactionStartTime=1509787474930} from checkpoint 1
10:24:35,350 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 7/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-35], transactionStartTime=1509787474659} from checkpoint 1
10:24:35,349 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 5/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-25], transactionStartTime=1509787474652} from checkpoint 1
10:24:35,361 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 18/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-92], transactionStartTime=1509787475043} from checkpoint 1
10:24:35,349 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 3/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-15], transactionStartTime=1509787474590} from checkpoint 1
10:24:35,361 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 13/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-67], transactionStartTime=1509787474962} from checkpoint 1
10:24:35,359 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 20/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-104], transactionStartTime=1509787474654} from checkpoint 1
10:24:35,359 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 19/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-96], transactionStartTime=1509787474655} from checkpoint 1
10:24:35,358 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 17/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-89], transactionStartTime=1509787474389} from checkpoint 1
10:24:35,358 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 16/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-81], transactionStartTime=1509787474983} from checkpoint 1
10:24:35,358 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 15/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-78], transactionStartTime=1509787474782} from checkpoint 1
10:24:35,382 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 28/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-144], transactionStartTime=1509787475011} from checkpoint 1
10:24:35,358 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 14/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-74], transactionStartTime=1509787474590} from checkpoint 1
10:24:35,356 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 11/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-56], transactionStartTime=1509787474451} from checkpoint 1
10:24:35,353 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 12/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-63], transactionStartTime=1509787475127} from checkpoint 1
10:24:35,351 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 8/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-41], transactionStartTime=1509787474807} from checkpoint 1
10:24:35,351 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 9/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-45], transactionStartTime=1509787474659} from checkpoint 1
10:24:35,368 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 31/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-159], transactionStartTime=1509787474781} from checkpoint 1
10:24:35,368 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 29/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-149], transactionStartTime=1509787474330} from checkpoint 1
10:24:35,368 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 27/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-139], transactionStartTime=1509787474438} from checkpoint 1
10:24:35,367 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 26/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-134], transactionStartTime=1509787474437} from checkpoint 1
10:24:35,367 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 23/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-119], transactionStartTime=1509787474637} from checkpoint 1
10:24:35,367 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 22/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-114], transactionStartTime=1509787475143} from checkpoint 1
10:24:35,367 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 21/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-109], transactionStartTime=1509787474237} from checkpoint 1
10:24:35,388 INFO  org.apache.flink.runtime.taskmanager.Task                     - Attempting to fail task externally Sink: kafka-sink-1509787467330 (30/32) (46216003624d2cffd6cd7b424b66a0b9).
10:24:35,388 INFO  org.apache.flink.runtime.taskmanager.Task                     - Sink: kafka-sink-1509787467330 (30/32) (46216003624d2cffd6cd7b424b66a0b9) switched from RUNNING to FAILED.
java.lang.RuntimeException: Error while confirming checkpoint
	at org.apache.flink.runtime.taskmanager.Task$3.run(Task.java:1254)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.
10:24:35,394 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 25/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-129], transactionStartTime=1509787474563} from checkpoint 1
10:24:35,402 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 30/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-154], transactionStartTime=1509787474659} from checkpoint 1
10:24:35,394 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction  - FlinkKafkaProducer011 24/32 - checkpoint 1 complete, committing transaction TransactionHolder{handle=KafkaTransactionState [transactionalId=Sink: kafka-sink-1509787467330-124], transactionStartTime=1509787474637} from checkpoint 1
10:24:35,414 INFO  org.apache.flink.runtime.taskmanager.Task                     - Triggering cancellation of task code Sink: kafka-sink-1509787467330 (30/32) (46216003624d2cffd6cd7b424b66a0b9).
10:24:35,421 INFO  org.apache.flink.streaming.connectors.kafka.internal.FlinkKafkaProducer  - Flushing new partitions
10:24:35,422 INFO  org.apache.kafka.clients.producer.KafkaProducer               - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:24:35,423 INFO  org.apache.flink.runtime.taskmanager.Task                     - Freeing task resources for Sink: kafka-sink-1509787467330 (30/32) (46216003624d2cffd6cd7b424b66a0b9).
10:24:35,441 INFO  org.apache.flink.runtime.taskmanager.Task                     - Ensuring all FileSystem streams are closed for task Sink: kafka-sink-1509787467330 (30/32) (46216003624d2cffd6cd7b424b66a0b9) [FAILED]
10:24:35,443 INFO  org.apache.flink.runtime.taskmanager.TaskManager              - Un-registering task and sending final execution state FAILED to JobManager for task Sink: kafka-sink-1509787467330 (46216003624d2cffd6cd7b424b66a0b9)
10:24:35,444 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Sink: kafka-sink-1509787467330 (30/32) (46216003624d2cffd6cd7b424b66a0b9) switched from RUNNING to FAILED.
java.lang.RuntimeException: Error while confirming checkpoint
	at org.apache.flink.runtime.taskmanager.Task$3.run(Task.java:1254)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.
10:24:35,444 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Job Flink Streaming Java API Skeleton (58a76026ade37503dadebb28ffaafd1b) switched from state RUNNING to FAILING.
java.lang.RuntimeException: Error while confirming checkpoint
	at org.apache.flink.runtime.taskmanager.Task$3.run(Task.java:1254)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.
10:24:35,444 INFO  org.apache.flink.runtime.client.JobSubmissionClientActor      - 11/04/2017 10:24:35	Sink: kafka-sink-1509787467330(30/32) switched to FAILED 
java.lang.RuntimeException: Error while confirming checkpoint
	at org.apache.flink.runtime.taskmanager.Task$3.run(Task.java:1254)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.

11/04/2017 10:24:35	Sink: kafka-sink-1509787467330(30/32) switched to FAILED 
java.lang.RuntimeException: Error while confirming checkpoint
	at org.apache.flink.runtime.taskmanager.Task$3.run(Task.java:1254)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.

10:24:35,445 INFO  org.apache.flink.runtime.client.JobSubmissionClientActor      - 11/04/2017 10:24:35	Job execution switched to status FAILING.
java.lang.RuntimeException: Error while confirming checkpoint
	at org.apache.flink.runtime.taskmanager.Task$3.run(Task.java:1254)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.
11/04/2017 10:24:35	Job execution switched to status FAILING.
java.lang.RuntimeException: Error while confirming checkpoint
	at org.apache.flink.runtime.taskmanager.Task$3.run(Task.java:1254)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.
10:24:35,451 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Source: Collection Source (1/1) (b46e03bc27ee6458ef2c282ef0f3c426) switched from RUNNING to CANCELING.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;How to reproduce&lt;/b&gt;&lt;br/&gt;
Run example job and restart the job until the first commit/checkpoint confirmation fails:&lt;br/&gt;
&lt;a href=&quot;https://github.com/GJL/flink-kafka011-producer-test/blob/master/src/main/java/com/garyyao/StreamingJob.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/GJL/flink-kafka011-producer-test/blob/master/src/main/java/com/garyyao/StreamingJob.java&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13116136">FLINK-7978</key>
            <summary>Kafka011 exactly-once Producer sporadically fails to commit under high parallelism</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pnowojski">Piotr Nowojski</assignee>
                                    <reporter username="gjy">Gary Yao</reporter>
                        <labels>
                    </labels>
                <created>Sat, 4 Nov 2017 09:42:54 +0000</created>
                <updated>Wed, 8 Nov 2017 10:01:16 +0000</updated>
                            <resolved>Tue, 7 Nov 2017 18:01:35 +0000</resolved>
                                    <version>1.4.0</version>
                                    <fixVersion>1.4.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16240356" author="githubbot" created="Mon, 6 Nov 2017 14:22:00 +0000"  >&lt;p&gt;GitHub user pnowojski opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7978&quot; title=&quot;Kafka011 exactly-once Producer sporadically fails to commit under high parallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-7978&quot;&gt;&lt;del&gt;FLINK-7978&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; Ensure that transactional ids will never clash&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    Previously transactional ids to use and to abort could clash between subtasks. This could lead to a race condition between initialization and writting the data, where one subtask is still initializing/aborting some transactional id while different subtask is already trying to write the data using the same transactional id.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    First commit extracts `TransactionalIdsGenerator` logic and is a pure refactor, without any functional change. Second one is the actual fix. I would like to merge those two commits as they are, without squashing, so that a bug fix is actually easier to understand/read in the commit history.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    This fixes a bug and adds test coverage (`TransactionalIdsGeneratorTest`) for future regressions.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;The serializers: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (*&lt;b&gt;not applicable&lt;/b&gt;* / docs / JavaDocs / not documented)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/pnowojski/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/pnowojski/flink&lt;/a&gt; f7978&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #4955&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 54c1729fed93e51f416d365c65cbd64f67c27321&lt;br/&gt;
Author: Piotr Nowojski &amp;lt;piotr.nowojski@gmail.com&amp;gt;&lt;br/&gt;
Date:   2017-11-06T13:03:16Z&lt;/p&gt;

&lt;p&gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;hotfix&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; Extract TransactionalIdsGenerator class from FlinkKafkaProducer011&lt;/p&gt;

&lt;p&gt;    This is pure refactor without any functional changes.&lt;/p&gt;

&lt;p&gt;commit 96bb26e5d9289fb8393f0807936792d89138a744&lt;br/&gt;
Author: Piotr Nowojski &amp;lt;piotr.nowojski@gmail.com&amp;gt;&lt;br/&gt;
Date:   2017-11-06T13:14:01Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7978&quot; title=&quot;Kafka011 exactly-once Producer sporadically fails to commit under high parallelism&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-7978&quot;&gt;&lt;del&gt;FLINK-7978&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; Ensure that transactional ids will never clash&lt;/p&gt;

&lt;p&gt;    Previously transactional ids to use and to abort could clash between&lt;br/&gt;
    subtasks. This could lead to a race condition between initialization&lt;br/&gt;
    and writting the data, where one subtask is still initializing/aborting&lt;br/&gt;
    some transactional id while different subtask is already trying to write&lt;br/&gt;
    the data using the same transactional id.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16240373" author="githubbot" created="Mon, 6 Nov 2017 14:35:20 +0000"  >&lt;p&gt;Github user pnowojski commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @GJL @tzulitai could you take a look?&lt;/p&gt;</comment>
                            <comment id="16241735" author="githubbot" created="Tue, 7 Nov 2017 09:35:16 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149312052&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149312052&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGeneratorTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,79 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka.internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collections;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Set;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Tests for &lt;/p&gt;
{@link TransactionalIdsGenerator}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class TransactionalIdsGeneratorTest {&lt;br/&gt;
    +	private static final int POOL_SIZE = 3;&lt;br/&gt;
    +	private static final int SAFE_SCALE_DOWN_FACTOR = 3;&lt;br/&gt;
    +	private static final int SUBTASKS_COUNT = 5;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGenerateIdsToUse() &lt;/p&gt;
{
    +		TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, 2, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +
    +		assertEquals(
    +			new HashSet&amp;lt;&amp;gt;(Arrays.asList(&quot;test-42&quot;, &quot;test-43&quot;, &quot;test-44&quot;)),
    +			generator.generateIdsToUse(36));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Ids to abort and to use should never clash between subtasks.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGeneratedIdsDoNotClash() {&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToAbort = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToUse = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int subtask = 0; subtask &amp;lt; SUBTASKS_COUNT; subtask++) &lt;/p&gt;
{
    +			TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, subtask, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +			idsToUse.add(generator.generateIdsToUse(0));
    +			idsToAbort.add(generator.generateIdsToAbort());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for (int subtask1 = 0; subtask1 &amp;lt; SUBTASKS_COUNT; subtask1++) {&lt;br/&gt;
    +			for (int subtask2 = 0; subtask2 &amp;lt; SUBTASKS_COUNT; subtask2++) {&lt;br/&gt;
    +				if (subtask2 == subtask1) &lt;/p&gt;
{
    +					continue;
    +				}
&lt;p&gt;    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToAbort.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToUse.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    what about &lt;br/&gt;
    `assertIntersectionIsEmpty(idsToUse.get(subtask2), idsToAbort.get(subtask1));`?&lt;/p&gt;</comment>
                            <comment id="16241736" author="githubbot" created="Tue, 7 Nov 2017 09:35:16 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149310451&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149310451&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGenerator.java &amp;#8212;&lt;br/&gt;
    @@ -19,27 +19,35 @@&lt;/p&gt;

&lt;p&gt;     import java.util.HashSet;&lt;br/&gt;
     import java.util.Set;&lt;br/&gt;
    -import java.util.stream.Collectors;&lt;br/&gt;
    -import java.util.stream.LongStream;&lt;/p&gt;

&lt;p&gt;     import static org.apache.flink.util.Preconditions.checkNotNull;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Class responsible for generating transactional ids to use when communicating with Kafka.&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;It guarantees that:&lt;br/&gt;
    + * - generated ids to use will never clash with ids to use from different subtasks&lt;br/&gt;
    + * - generated ids to abort will never clash with ids to abort from different subtasks&lt;br/&gt;
    + * - generated ids to use will never clash with ids to abort from different subtasks&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;In other words, any particular generated id will always be assigned to one and only one subtask.&lt;br/&gt;
      */&lt;br/&gt;
     public class TransactionalIdsGenerator {&lt;br/&gt;
     	private final String prefix;&lt;br/&gt;
     	private final int subtaskIndex;&lt;br/&gt;
    +	private final int totalNumberOfSubtasks;&lt;br/&gt;
     	private final int poolSize;&lt;br/&gt;
     	private final int safeScaleDownFactor;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	public TransactionalIdsGenerator(&lt;br/&gt;
     			String prefix,&lt;br/&gt;
     			int subtaskIndex,&lt;br/&gt;
    +			int totalNumberOfSubtasks,&lt;br/&gt;
     			int poolSize,&lt;br/&gt;
     			int safeScaleDownFactor) {&lt;br/&gt;
     		this.prefix = checkNotNull(prefix);&lt;br/&gt;
     		this.subtaskIndex = subtaskIndex;&lt;br/&gt;
    +		this.totalNumberOfSubtasks = totalNumberOfSubtasks;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Maybe we should add some argument checks for subtask index and totalNumberOfSubtasks, at least.&lt;/p&gt;</comment>
                            <comment id="16241748" author="githubbot" created="Tue, 7 Nov 2017 09:46:05 +0000"  >&lt;p&gt;Github user GJL commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149315106&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149315106&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGenerator.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,86 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka.internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Set;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.apache.flink.util.Preconditions.checkNotNull;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Class responsible for generating transactional ids to use when communicating with Kafka.&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;It guarantees that:&lt;br/&gt;
    + * - generated ids to use will never clash with ids to use from different subtasks&lt;br/&gt;
    + * - generated ids to abort will never clash with ids to abort from different subtasks&lt;br/&gt;
    + * - generated ids to use will never clash with ids to abort from different subtasks&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;In other words, any particular generated id will always be assigned to one and only one subtask.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class TransactionalIdsGenerator {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It is better to use the unordered list tag, e.g.,&lt;br/&gt;
    ```&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;ul&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;generated ids to use will never clash with ids to use from different subtasks&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;generated ids to abort will never clash with ids to abort from different subtasks&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;generated ids to use will never clash with ids to abort from different subtasks&amp;lt;/li&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/ul&amp;gt;&lt;br/&gt;
    ```&lt;br/&gt;
    Otherwise it is rendered like this:&lt;br/&gt;
    !&lt;span class=&quot;error&quot;&gt;&amp;#91;image&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://user-images.githubusercontent.com/1681921/32487045-c97ffe8a-c3a8-11e7-95e8-f3ee127072b9.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://user-images.githubusercontent.com/1681921/32487045-c97ffe8a-c3a8-11e7-95e8-f3ee127072b9.png&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="16241749" author="githubbot" created="Tue, 7 Nov 2017 09:46:20 +0000"  >&lt;p&gt;Github user pnowojski commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149315173&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149315173&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGeneratorTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,79 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka.internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collections;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Set;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Tests for &lt;/p&gt;
{@link TransactionalIdsGenerator}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class TransactionalIdsGeneratorTest {&lt;br/&gt;
    +	private static final int POOL_SIZE = 3;&lt;br/&gt;
    +	private static final int SAFE_SCALE_DOWN_FACTOR = 3;&lt;br/&gt;
    +	private static final int SUBTASKS_COUNT = 5;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGenerateIdsToUse() &lt;/p&gt;
{
    +		TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, 2, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +
    +		assertEquals(
    +			new HashSet&amp;lt;&amp;gt;(Arrays.asList(&quot;test-42&quot;, &quot;test-43&quot;, &quot;test-44&quot;)),
    +			generator.generateIdsToUse(36));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Ids to abort and to use should never clash between subtasks.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGeneratedIdsDoNotClash() {&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToAbort = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToUse = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int subtask = 0; subtask &amp;lt; SUBTASKS_COUNT; subtask++) &lt;/p&gt;
{
    +			TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, subtask, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +			idsToUse.add(generator.generateIdsToUse(0));
    +			idsToAbort.add(generator.generateIdsToAbort());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for (int subtask1 = 0; subtask1 &amp;lt; SUBTASKS_COUNT; subtask1++) {&lt;br/&gt;
    +			for (int subtask2 = 0; subtask2 &amp;lt; SUBTASKS_COUNT; subtask2++) {&lt;br/&gt;
    +				if (subtask2 == subtask1) &lt;/p&gt;
{
    +					continue;
    +				}
&lt;p&gt;    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToAbort.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToUse.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    that will be covered by second half of looping (everytime I start from index 0). It would be necessary if the loop would look like:&lt;br/&gt;
    ```&lt;br/&gt;
    for (int subtask1 = 0; subtask1 &amp;lt; SUBTASKS_COUNT; subtask1++) {&lt;br/&gt;
        for (int subtask2 = subtask1; subtask2 &amp;lt; SUBTASKS_COUNT; subtask2++) {&lt;br/&gt;
    ```&lt;br/&gt;
    instead of as it is now:&lt;br/&gt;
    ```&lt;br/&gt;
    for (int subtask1 = 0; subtask1 &amp;lt; SUBTASKS_COUNT; subtask1++) {&lt;br/&gt;
        for (int subtask2 = 0; subtask2 &amp;lt; SUBTASKS_COUNT; subtask2++) {&lt;br/&gt;
    ```&lt;/p&gt;</comment>
                            <comment id="16241751" author="githubbot" created="Tue, 7 Nov 2017 09:47:49 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149315581&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149315581&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGeneratorTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,79 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka.internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collections;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Set;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Tests for &lt;/p&gt;
{@link TransactionalIdsGenerator}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class TransactionalIdsGeneratorTest {&lt;br/&gt;
    +	private static final int POOL_SIZE = 3;&lt;br/&gt;
    +	private static final int SAFE_SCALE_DOWN_FACTOR = 3;&lt;br/&gt;
    +	private static final int SUBTASKS_COUNT = 5;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGenerateIdsToUse() &lt;/p&gt;
{
    +		TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, 2, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +
    +		assertEquals(
    +			new HashSet&amp;lt;&amp;gt;(Arrays.asList(&quot;test-42&quot;, &quot;test-43&quot;, &quot;test-44&quot;)),
    +			generator.generateIdsToUse(36));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Ids to abort and to use should never clash between subtasks.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGeneratedIdsDoNotClash() {&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToAbort = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToUse = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int subtask = 0; subtask &amp;lt; SUBTASKS_COUNT; subtask++) &lt;/p&gt;
{
    +			TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, subtask, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +			idsToUse.add(generator.generateIdsToUse(0));
    +			idsToAbort.add(generator.generateIdsToAbort());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for (int subtask1 = 0; subtask1 &amp;lt; SUBTASKS_COUNT; subtask1++) {&lt;br/&gt;
    +			for (int subtask2 = 0; subtask2 &amp;lt; SUBTASKS_COUNT; subtask2++) {&lt;br/&gt;
    +				if (subtask2 == subtask1) &lt;/p&gt;
{
    +					continue;
    +				}
&lt;p&gt;    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToAbort.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToUse.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    ah you&apos;re right, thanks for the explanation &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16241760" author="githubbot" created="Tue, 7 Nov 2017 09:51:57 +0000"  >&lt;p&gt;Github user GJL commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149316761&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149316761&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/test/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGeneratorTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,79 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka.internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.Collections;&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Set;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Tests for &lt;/p&gt;
{@link TransactionalIdsGenerator}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class TransactionalIdsGeneratorTest {&lt;br/&gt;
    +	private static final int POOL_SIZE = 3;&lt;br/&gt;
    +	private static final int SAFE_SCALE_DOWN_FACTOR = 3;&lt;br/&gt;
    +	private static final int SUBTASKS_COUNT = 5;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGenerateIdsToUse() &lt;/p&gt;
{
    +		TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, 2, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +
    +		assertEquals(
    +			new HashSet&amp;lt;&amp;gt;(Arrays.asList(&quot;test-42&quot;, &quot;test-43&quot;, &quot;test-44&quot;)),
    +			generator.generateIdsToUse(36));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Ids to abort and to use should never clash between subtasks.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testGeneratedIdsDoNotClash() {&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToAbort = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		List&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; idsToUse = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int subtask = 0; subtask &amp;lt; SUBTASKS_COUNT; subtask++) &lt;/p&gt;
{
    +			TransactionalIdsGenerator generator = new TransactionalIdsGenerator(&quot;test&quot;, subtask, SUBTASKS_COUNT, POOL_SIZE, SAFE_SCALE_DOWN_FACTOR);
    +			idsToUse.add(generator.generateIdsToUse(0));
    +			idsToAbort.add(generator.generateIdsToAbort());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for (int subtask1 = 0; subtask1 &amp;lt; SUBTASKS_COUNT; subtask1++) {&lt;br/&gt;
    +			for (int subtask2 = 0; subtask2 &amp;lt; SUBTASKS_COUNT; subtask2++) {&lt;br/&gt;
    +				if (subtask2 == subtask1) &lt;/p&gt;
{
    +					continue;
    +				}
&lt;p&gt;    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToAbort.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToUse.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    +				assertIntersectionIsEmpty(idsToAbort.get(subtask2), idsToUse.get(subtask1));&lt;br/&gt;
    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private &amp;lt;T&amp;gt; void assertIntersectionIsEmpty(Set&amp;lt;T&amp;gt; first, Set&amp;lt;T&amp;gt; second) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Maybe `assertDisjoint`&lt;/p&gt;</comment>
                            <comment id="16241783" author="githubbot" created="Tue, 7 Nov 2017 10:14:45 +0000"  >&lt;p&gt;Github user pnowojski commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149322930&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149322930&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGenerator.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,86 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka.internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Set;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.apache.flink.util.Preconditions.checkNotNull;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Class responsible for generating transactional ids to use when communicating with Kafka.&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;It guarantees that:&lt;br/&gt;
    + * - generated ids to use will never clash with ids to use from different subtasks&lt;br/&gt;
    + * - generated ids to abort will never clash with ids to abort from different subtasks&lt;br/&gt;
    + * - generated ids to use will never clash with ids to abort from different subtasks&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;In other words, any particular generated id will always be assigned to one and only one subtask.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class TransactionalIdsGenerator {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    ops, forgot about it&lt;/p&gt;</comment>
                            <comment id="16241799" author="githubbot" created="Tue, 7 Nov 2017 10:29:30 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955#discussion_r149326628&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955#discussion_r149326628&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-0.11/src/main/java/org/apache/flink/streaming/connectors/kafka/internal/TransactionalIdsGenerator.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,86 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
    + * contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
    + * this work for additional information regarding copyright ownership.&lt;br/&gt;
    + * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
    + * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
    + * the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka.internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.HashSet;&lt;br/&gt;
    +import java.util.Set;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.apache.flink.util.Preconditions.checkNotNull;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Class responsible for generating transactional ids to use when communicating with Kafka.&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;It guarantees that:&lt;br/&gt;
    + * - generated ids to use will never clash with ids to use from different subtasks&lt;br/&gt;
    + * - generated ids to abort will never clash with ids to abort from different subtasks&lt;br/&gt;
    + * - generated ids to use will never clash with ids to abort from different subtasks&lt;br/&gt;
    + *&lt;br/&gt;
    + * &amp;lt;p&amp;gt;In other words, any particular generated id will always be assigned to one and only one subtask.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class TransactionalIdsGenerator {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    another nitpick &#128521;: `&amp;lt;li&amp;gt;` tags are usually not closed in Javadoc: &lt;a href=&quot;http://www.oracle.com/technetwork/articles/java/index-137868.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.oracle.com/technetwork/articles/java/index-137868.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16241939" author="githubbot" created="Tue, 7 Nov 2017 12:39:13 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    LGTM once Travis is green.&lt;/p&gt;</comment>
                            <comment id="16242538" author="aljoscha" created="Tue, 7 Nov 2017 18:01:35 +0000"  >&lt;p&gt;Fixed on release-1.4 in&lt;br/&gt;
3cbf467ebdf639df4d7d4da78b7bc2929aa4b5d9&lt;br/&gt;
460e27aeb5e246aff0f8137448441c315123608c&lt;/p&gt;

&lt;p&gt;Fixed on master in&lt;br/&gt;
2949dc43b238b7f689571f007fd3346de3b89ed9&lt;br/&gt;
d3aa3f0729e42d48820b3786f463eadc409ece4f&lt;/p&gt;</comment>
                            <comment id="16242540" author="githubbot" created="Tue, 7 Nov 2017 18:02:43 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for fixing this! And thanks for the review!&lt;/p&gt;

&lt;p&gt;    I merged, could you please close the PR?&lt;/p&gt;</comment>
                            <comment id="16243540" author="aljoscha" created="Wed, 8 Nov 2017 08:48:29 +0000"  >&lt;p&gt;I forgot to commit on master so the commits that are now on master are:&lt;br/&gt;
ab00d35b88ce9cf26c66b7cbb21486d1b18573a6&lt;br/&gt;
fdae3ae1f990ca90375264634dedd6ebd54502a1&lt;/p&gt;</comment>
                            <comment id="16243642" author="githubbot" created="Wed, 8 Nov 2017 10:01:15 +0000"  >&lt;p&gt;Github user pnowojski commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for reviews and merging!&lt;/p&gt;</comment>
                            <comment id="16243643" author="githubbot" created="Wed, 8 Nov 2017 10:01:16 +0000"  >&lt;p&gt;Github user pnowojski closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/4955&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/4955&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 1 week, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3mee7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>