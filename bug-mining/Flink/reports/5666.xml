<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:59:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-23509] FlinkKafkaInternalProducer overrides static final ProducerIdAndEpoch#NONE during transaction recovery (fails)</title>
                <link>https://issues.apache.org/jira/browse/FLINK-23509</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;When recovering Kafka transactions from a snapshot,&#160;FlinkKafkaInternalProducer&#160;overrides static final ProducerIdAndEpoch#NONE here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/flink/blob/f06faf13930f2e8acccf1e04e2c250b85bdbf48e/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/internals/FlinkKafkaInternalProducer.java#L229&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;FlinkKafkaInternalProducer#resumeTransaction&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and consequently TransactionManager initializes transactions as new transactions instead of recovered ones. Here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L332&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;TransactionManager#initializeTransactions&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;TransactionManager log (edited for readability):&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;{{&lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; INFO org.apache.kafka.clients.producer.KafkaProducer - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Overriding the default enable.idempotence to true since transactional.id is specified.&lt;br/&gt;
 &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; INFO org.apache.kafka.clients.producer.KafkaProducer - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Instantiated a transactional producer.&lt;br/&gt;
 &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; INFO org.apache.kafka.clients.producer.KafkaProducer - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Overriding the default retries config to the recommended value of 2147483647 since the idempotent producer is enabled.&lt;br/&gt;
 &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; INFO org.apache.kafka.clients.producer.KafkaProducer - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Overriding the default acks to all since idempotence is enabled.&lt;br/&gt;
 &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Transition from state UNINITIALIZED to INITIALIZING&lt;br/&gt;
 &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; INFO org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Invoking InitProducerId for the first time in order to acquire a producer ID&lt;br/&gt;
 &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Enqueuing transactional request InitProducerIdRequestData(transactionalId=&apos;Sink: trxRollupKafkaSink-...8b6-2&apos;, transactionTimeoutMs=60000, producerId=1545118, producerEpoch=17)&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; TRACE org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Request InitProducerIdRequestData(transactionalId=&apos;Sink: trxRollupKafkaSink-...8b6-2&apos;, transactionTimeoutMs=60000, producerId=1545118, producerEpoch=17) dequeued for sending&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Enqueuing transactional request FindCoordinatorRequestData(key=&apos;Sink: trxRollupKafkaSink-...8b6-2&apos;, keyType=1)&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Enqueuing transactional request InitProducerIdRequestData(transactionalId=&apos;Sink: trxRollupKafkaSink-...8b6-2&apos;, transactionTimeoutMs=60000, producerId=1545118, producerEpoch=17)&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; TRACE org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Request FindCoordinatorRequestData(key=&apos;Sink: trxRollupKafkaSink-...8b6-2&apos;, keyType=1) dequeued for sending&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; TRACE org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Received transactional response FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage=&apos;NONE&apos;, nodeId=3, host=&apos;ulxxtkafbrk03.adgr.net&apos;, port=9093) for request FindCoordinatorRequestData(key=&apos;Sink: trxRollupKafkaSink-...8b6-2&apos;, keyType=1)&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; INFO org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Discovered transaction coordinator ulxxtkafbrk03.adgr.net:9093 (id: 3 rack: null)&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; TRACE org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Request InitProducerIdRequestData(transactionalId=&apos;Sink: trxRollupKafkaSink-...8b6-2&apos;, transactionTimeoutMs=60000, producerId=1545118, producerEpoch=17) dequeued for sending&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; TRACE org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Received transactional response InitProducerIdResponseData(throttleTimeMs=0, errorCode=47, producerId=&lt;del&gt;1, producerEpoch=-1) for request InitProducerIdRequestData(transactionalId=&apos;Sink: trxRollupKafkaSink&lt;/del&gt;...8b6-2&apos;, transactionTimeoutMs=60000, producerId=1545118, producerEpoch=17)&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-producer-network-thread | producer-Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Transition from state INITIALIZING to error state FATAL_ERROR&lt;br/&gt;
 &lt;a href=&quot;#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sink: trxRollupKafkaSink (1/1)#3&lt;/a&gt; INFO org.apache.kafka.clients.producer.KafkaProducer - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=producer-Sink: trxRollupKafkaSink-...8b6-2, transactionalId=Sink: trxRollupKafkaSink-...8b6-2&amp;#93;&lt;/span&gt; Closing the Kafka producer with timeoutMillis = 0 ms.&lt;br/&gt;
 org.apache.kafka.common.KafkaException: Unexpected error in InitProducerIdResponse; Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.&lt;br/&gt;
 at org.apache.kafka.clients.producer.internals.TransactionManager$InitProducerIdHandler.handleResponse(TransactionManager.java:1352)&lt;br/&gt;
 at org.apache.kafka.clients.producer.internals.TransactionManager$TxnRequestHandler.onComplete(TransactionManager.java:1260)&lt;br/&gt;
 at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)&lt;br/&gt;
 at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:572)&lt;br/&gt;
 at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:564)&lt;br/&gt;
 at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:414)&lt;br/&gt;
 at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:312)&lt;br/&gt;
 at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)&lt;br/&gt;
 at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
 }}&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&#160;Notice here &quot;Invoking InitProducerId for the first time in order to acquire a producer ID&quot; indicates a request for a new transaction (-1, -1) but below we see instead: &quot;Enqueuing transactional request InitProducerIdRequestData(transactionalId=&apos;Sink: ...&apos;, ..., producerId=1545118, producerEpoch=17)&quot; because of changed&#160;ProducerIdAndEpoch#NONE&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;TransactionManager#initializeTransactions variables:&lt;/p&gt;

&lt;p&gt;&#160; &lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13031092/13031092_2021-07-26_16-47-48.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Notice the values above which should be -1, -1.&lt;/p&gt;

&lt;p&gt;Stack trace of&#160;TransactionManager#initializeTransactions:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;initializeTransactions:314, TransactionManager (org.apache.kafka.clients.producer.internals)&lt;br/&gt;
 initializeTransactions:310, TransactionManager (org.apache.kafka.clients.producer.internals)&lt;br/&gt;
 initTransactions:591, KafkaProducer (org.apache.kafka.clients.producer)&lt;br/&gt;
 initTransactions:88, FlinkKafkaInternalProducer (org.apache.flink.streaming.connectors.kafka.internals)&lt;br/&gt;
 recoverAndAbort:1060, FlinkKafkaProducer (org.apache.flink.streaming.connectors.kafka)&lt;br/&gt;
 recoverAndAbort:99, FlinkKafkaProducer (org.apache.flink.streaming.connectors.kafka)&lt;br/&gt;
 initializeState:371, TwoPhaseCommitSinkFunction (org.apache.flink.streaming.api.functions.sink)&lt;br/&gt;
 initializeState:1195, FlinkKafkaProducer (org.apache.flink.streaming.connectors.kafka)&lt;br/&gt;
 tryRestoreFunction:189, StreamingFunctionUtils (org.apache.flink.streaming.util.functions)&lt;br/&gt;
 restoreFunctionState:171, StreamingFunctionUtils (org.apache.flink.streaming.util.functions)&lt;br/&gt;
 initializeState:96, AbstractUdfStreamOperator (org.apache.flink.streaming.api.operators)&lt;br/&gt;
 initializeOperatorState:118, StreamOperatorStateHandler (org.apache.flink.streaming.api.operators)&lt;br/&gt;
 initializeState:290, AbstractStreamOperator (org.apache.flink.streaming.api.operators)&lt;br/&gt;
 initializeStateAndOpenOperators:436, OperatorChain (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 restoreGates:574, StreamTask (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 call:-1, 412600778 (org.apache.flink.streaming.runtime.tasks.StreamTask$$Lambda$745)&lt;br/&gt;
 call:55, StreamTaskActionExecutor$1 (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 restore:554, StreamTask (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 doRun:756, Task (org.apache.flink.runtime.taskmanager)&lt;br/&gt;
 run:563, Task (org.apache.flink.runtime.taskmanager)&lt;br/&gt;
 run:748, Thread (java.lang)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Stack trace of&#160;FlinkKafkaInternalProducer#resumeTransaction when the values are overridden:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;resumeTransaction:204, FlinkKafkaInternalProducer (org.apache.flink.streaming.connectors.kafka.internals)&lt;br/&gt;
 resumeTransaction:196, KafkaProducerJobSink$$anon$1$$anon$2 (ch.viseca.flink.connectors.kafka.sinks)&lt;br/&gt;
 recoverAndCommit:1029, FlinkKafkaProducer (org.apache.flink.streaming.connectors.kafka)&lt;br/&gt;
 recoverAndCommit:99, FlinkKafkaProducer (org.apache.flink.streaming.connectors.kafka)&lt;br/&gt;
 recoverAndCommitInternal:414, TwoPhaseCommitSinkFunction (org.apache.flink.streaming.api.functions.sink)&lt;br/&gt;
 initializeState:364, TwoPhaseCommitSinkFunction (org.apache.flink.streaming.api.functions.sink)&lt;br/&gt;
 initializeState:1195, FlinkKafkaProducer (org.apache.flink.streaming.connectors.kafka)&lt;br/&gt;
 tryRestoreFunction:189, StreamingFunctionUtils (org.apache.flink.streaming.util.functions)&lt;br/&gt;
 restoreFunctionState:171, StreamingFunctionUtils (org.apache.flink.streaming.util.functions)&lt;br/&gt;
 initializeState:96, AbstractUdfStreamOperator (org.apache.flink.streaming.api.operators)&lt;br/&gt;
 initializeOperatorState:118, StreamOperatorStateHandler (org.apache.flink.streaming.api.operators)&lt;br/&gt;
 initializeState:290, AbstractStreamOperator (org.apache.flink.streaming.api.operators)&lt;br/&gt;
 initializeStateAndOpenOperators:436, OperatorChain (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 restoreGates:574, StreamTask (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 call:-1, 412600778 (org.apache.flink.streaming.runtime.tasks.StreamTask$$Lambda$745)&lt;br/&gt;
 call:55, StreamTaskActionExecutor$1 (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 restore:554, StreamTask (org.apache.flink.streaming.runtime.tasks)&lt;br/&gt;
 doRun:756, Task (org.apache.flink.runtime.taskmanager)&lt;br/&gt;
 run:563, Task (org.apache.flink.runtime.taskmanager)&lt;br/&gt;
 run:748, Thread (java.lang)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Background:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;we recently upgraded from Flink 1.8.0 to 1.13.0&lt;/li&gt;
	&lt;li&gt;FlinkKafkaInternalProducer#resumeTransaction has not changed between these versions, however&lt;/li&gt;
	&lt;li&gt;in Flink 1.8.0 we never observed any resumable transaction as part of a checkpoint&lt;/li&gt;
	&lt;li&gt;we could not determine what actually made the change that causes the failure, however:&lt;/li&gt;
	&lt;li&gt;it would probably be much saver to instead of assigning new values to an arbitrary&#160;ProducerIdAndEpoch held by TransactionManager to directly assign a fresh&#160;ProducerIdAndEpoch and thus avoid overriding&#160;ProducerIdAndEpoch#NONE&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Sample workaround (scala):&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;val sink = new FlinkKafkaProducer&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;(val sink = new FlinkKafkaProducer&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;(&#160; defaultTopic,&#160; schema,&#160; getProperties,&#160; getSemantic,&#160; getProducerPoolSize) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {
 &#160; override protected def createProducer}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;&#160; &#160; &#160; override def resumeTransaction(producerId: Long, epoch: Short): Unit =&lt;br/&gt;
 Unknown macro: {&#160; &#160; &#160; &#160; val transactionManager = FlinkKafkaInternalProducer.getField(kafkaProducer, &quot;transactionManager&quot;)&#160; &#160; &#160; &#160; transactionManager.synchronized Unknown macro}&lt;br/&gt;
 &#160; &#160; &#160; &#160; super.resumeTransaction(producerId, epoch)&#160; &#160; &#160; }&#160; &#160; }&#160; }}&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13392037">FLINK-23509</key>
            <summary>FlinkKafkaInternalProducer overrides static final ProducerIdAndEpoch#NONE during transaction recovery (fails)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="fpaul">Fabian Paul</assignee>
                                    <reporter username="Matthias Schwalbe">Matthias Schwalbe</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Tue, 27 Jul 2021 06:51:45 +0000</created>
                <updated>Wed, 15 Dec 2021 01:40:24 +0000</updated>
                            <resolved>Fri, 6 Aug 2021 12:06:43 +0000</resolved>
                                    <version>1.14.0</version>
                    <version>1.12.5</version>
                    <version>1.13.2</version>
                                    <fixVersion>1.14.0</fixVersion>
                    <fixVersion>1.13.3</fixVersion>
                    <fixVersion>1.12.8</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="17387882" author="fabian.paul" created="Tue, 27 Jul 2021 08:37:00 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Matthias+Schwalbe&quot; class=&quot;user-hover&quot; rel=&quot;Matthias Schwalbe&quot;&gt;Matthias Schwalbe&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Unfortunately, we cannot easily set a new epoch and producer id because it might implicate data loss. It is important to commit all pending transactions from either previous checkpoints (which have not been completed successfully yet) or from other subtasks in case of a scale-in event.&#160;&lt;/p&gt;

&lt;p&gt;I think the problem you are seeing is related to &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-16419&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-16419&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17387922" author="matthias schwalbe" created="Tue, 27 Jul 2021 09:23:15 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpaul&quot; class=&quot;user-hover&quot; rel=&quot;fpaul&quot;&gt;fpaul&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I completely agree with your points, and the code does a good job in concluding phase 2 of the 2-phase-commit-protocol, after recovering from an interrupt. However&#160;ProducerIdAndEpoch tuple class has value semantics, i.e. it should never directly be changed but rather replaced with a new ProducerIdAndEpoch containing the correct values.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;race conditions out of our control lead to the fact that&lt;/li&gt;
	&lt;li&gt;TransactionManager sometimes directly holds&#160;ProducerIdAndEpoch#NONE&lt;/li&gt;
	&lt;li&gt;ProducerIdAndEpoch#NONE is used for comparison whether we work on a new transaction or an existing one&lt;/li&gt;
	&lt;li&gt;ProducerIdAndEpoch#NONE is especially sensitive to being changed by means of reflection&lt;/li&gt;
	&lt;li&gt;overriding&#160;ProducerIdAndEpoch#NONE can be avoided by changing&#160;&lt;a href=&quot;https://github.com/apache/flink/blob/f06faf13930f2e8acccf1e04e2c250b85bdbf48e/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/internals/FlinkKafkaInternalProducer.java#L229&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;FlinkKafkaInternalProducer#resumeTransaction&lt;/a&gt;&#160;to assign a new&#160;ProducerIdAndEpoch instead of overriding an arbitrary&#160;ProducerIdAndEpoch held by TransactionManager&lt;/li&gt;
	&lt;li&gt;all remaining protocol stays intact&lt;/li&gt;
	&lt;li&gt;the workaround given above completely fixes this, the approach could also be integrated&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;It took me a while to track down the root cause:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;at no time&#160;ProducerIdAndEpoch#NONE should contain values other that (-1, -1),&lt;/li&gt;
	&lt;li&gt;which can be violated due to race conditions by&#160;&lt;a href=&quot;https://github.com/apache/flink/blob/f06faf13930f2e8acccf1e04e2c250b85bdbf48e/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/internals/FlinkKafkaInternalProducer.java#L229&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;FlinkKafkaInternalProducer#resumeTransaction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Should be unite the two tickets?&lt;/p&gt;

&lt;p&gt;-&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-16419&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-16419&lt;/a&gt;&#160; proposes&#160;ignoreFailuresAfterTransactionTimeout() which only helps a little:&lt;/p&gt;

&lt;p&gt;-&#160;&#160;ProducerIdAndEpoch#NONE would still contain values other that (-1, -1) which seems to be the rot couse&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Looking forward to your response&#160;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="17387966" author="arvid" created="Tue, 27 Jul 2021 10:33:09 +0000"  >&lt;p&gt;Hi Matthias, good observation and I see your point. It may also solve &lt;a href=&quot;http://deprecated-apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/recover-from-svaepoint-td44081.html#a44157&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://deprecated-apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/recover-from-svaepoint-td44081.html#a44157&lt;/a&gt; .&lt;/p&gt;</comment>
                            <comment id="17387980" author="matthias schwalbe" created="Tue, 27 Jul 2021 11:22:34 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arvid&quot; class=&quot;user-hover&quot; rel=&quot;arvid&quot;&gt;arvid&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Yes, this exactly matches my observation.&lt;/p&gt;

&lt;p&gt;The fix would be to replace 3 lines with 2 different lines in &lt;a href=&quot;https://github.com/apache/flink/blob/f06faf13930f2e8acccf1e04e2c250b85bdbf48e/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/internals/FlinkKafkaInternalProducer.java#L229&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;FlinkKafkaInternalProducer#resumeTransaction&lt;/a&gt; and we would be on the save side, no matter how the specific version of Kafka client initializes TransactionManager#producerIdAndEpoch (cf. to Tia Zhaos comment here: &lt;a href=&quot;http://deprecated-apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/recover-from-svaepoint-tp44081p44162.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://deprecated-apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/recover-from-svaepoint-tp44081p44162.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17394728" author="fabian.paul" created="Fri, 6 Aug 2021 12:06:00 +0000"  >&lt;p&gt;Fixed in:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;release-1.12:&#160;adf2f29416eaf6f819cbb2a7944ecec4c1be0eb2&lt;/li&gt;
	&lt;li&gt;release-1.13:&#160;e13ae99953d2702f45db9a42d8714b6da93cd0ff&lt;/li&gt;
	&lt;li&gt;master: 543959ee6707b6e93412e809e9082227dd95efe0&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13394064">FLINK-23674</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13031092" name="2021-07-26_16-47-48.png" size="15328" author="Matthias Schwalbe" created="Tue, 27 Jul 2021 06:57:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 14 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0tcvc:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>