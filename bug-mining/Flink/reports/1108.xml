<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:24:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-4150] Problem with Blobstore in Yarn HA setting on recovery after cluster shutdown</title>
                <link>https://issues.apache.org/jira/browse/FLINK-4150</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Submitting a job in Yarn with HA can lead to the following exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot load user class: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09
&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt; info: URL &lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;:
    file: &lt;span class=&quot;code-quote&quot;&gt;&apos;/tmp/blobStore-ccec0f4a-3e07-455f-945b-4fcd08f5bac1/cache/blob_7fafffe9595cd06aff213b81b5da7b1682e1d6b0&apos;&lt;/span&gt; (invalid JAR: zip file is empty)
&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt; not resolvable through given classloader.
	at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperator(StreamConfig.java:207)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:222)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:588)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Some job information, including the Blob ids, are stored in Zookeeper. The actual Blobs are stored in a dedicated BlobStore, if the recovery mode is set to Zookeeper. This BlobStore is typically located in a FS like HDFS. When the cluster is shut down, the path for the BlobStore is deleted. When the cluster is then restarted, recovering jobs cannot restore because it&apos;s Blob ids stored in Zookeeper now point to deleted files.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12986640">FLINK-4150</key>
            <summary>Problem with Blobstore in Yarn HA setting on recovery after cluster shutdown</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="uce">Ufuk Celebi</assignee>
                                    <reporter username="srichter">Stefan Richter</reporter>
                        <labels>
                    </labels>
                <created>Mon, 4 Jul 2016 16:13:34 +0000</created>
                <updated>Thu, 28 Feb 2019 13:30:10 +0000</updated>
                            <resolved>Mon, 25 Jul 2016 13:21:57 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Runtime / Coordination</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15379374" author="githubbot" created="Fri, 15 Jul 2016 13:28:26 +0000"  >&lt;p&gt;GitHub user uce opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4150&quot; title=&quot;Problem with Blobstore in Yarn HA setting on recovery after cluster shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4150&quot;&gt;&lt;del&gt;FLINK-4150&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;runtime&amp;#93;&lt;/span&gt; Don&apos;t clean up BlobStore on BlobServer shut down&lt;/p&gt;

&lt;p&gt;    The `BlobServer` acts as a local cache for uploaded BLOBs. The life-cycle of each BLOB is bound to the life-cycle of the `BlobServer`. If the BlobServer shuts down (on JobManager shut down), all local files will be removed.&lt;/p&gt;

&lt;p&gt;    With HA, BLOBs are persisted to another file system (e.g. HDFS) via the `BlobStore` in order to have BLOBs available after a JobManager failure (or shut down). These BLOBs are only allowed to be removed when the job that requires them enters a globally terminal state (`FINISHED`, `CANCELLED`, `FAILED`).&lt;/p&gt;

&lt;p&gt;    This commit removes the `BlobStore` clean up call from the `BlobServer` shutdown. The `BlobStore` files will only be cleaned up via the `BlobLibraryCacheManager`&apos;s&apos; clean up task (periodically or on BlobLibraryCacheManager shutdown). This means that there is a chance that BLOBs will linger around after the job has terminated, if the job manager fails before the clean up.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/uce/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/uce/flink&lt;/a&gt; 4150-blobstore&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2256&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 0d4522270881dbbb7164130f47f9d4df617c19c5&lt;br/&gt;
Author: Ufuk Celebi &amp;lt;uce@apache.org&amp;gt;&lt;br/&gt;
Date:   2016-07-14T14:29:49Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4150&quot; title=&quot;Problem with Blobstore in Yarn HA setting on recovery after cluster shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4150&quot;&gt;&lt;del&gt;FLINK-4150&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;runtime&amp;#93;&lt;/span&gt; Don&apos;t clean up BlobStore on BlobServer shut down&lt;/p&gt;

&lt;p&gt;    The `BlobServer` acts as a local cache for uploaded BLOBs. The life-cycle of&lt;br/&gt;
    each BLOB is bound to the life-cycle of the `BlobServer`. If the BlobServer&lt;br/&gt;
    shuts down (on JobManager shut down), all local files will be removed.&lt;/p&gt;

&lt;p&gt;    With HA, BLOBs are persisted to another file system (e.g. HDFS) via the&lt;br/&gt;
    `BlobStore` in order to have BLOBs available after a JobManager failure (or&lt;br/&gt;
    shut down). These BLOBs are only allowed to be removed when the job that&lt;br/&gt;
    requires them enters a globally terminal state (`FINISHED`, `CANCELLED`,&lt;br/&gt;
    `FAILED`).&lt;/p&gt;

&lt;p&gt;    This commit removes the `BlobStore` clean up call from the `BlobServer`&lt;br/&gt;
    shutdown. The `BlobStore` files will only be cleaned up via the&lt;br/&gt;
    `BlobLibraryCacheManager`&apos;s&apos; clean up task (periodically or on&lt;br/&gt;
    BlobLibraryCacheManager shutdown). This means that there is a chance that&lt;br/&gt;
    BLOBs will linger around after the job has terminated, if the job manager&lt;br/&gt;
    fails before the clean up.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15379447" author="githubbot" created="Fri, 15 Jul 2016 14:14:53 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Just a quick question. Do we want to remove also failed jobs from the BlobStore and ZK? Or only finished or cancelled jobs?&lt;/p&gt;</comment>
                            <comment id="15379618" author="githubbot" created="Fri, 15 Jul 2016 16:10:04 +0000"  >&lt;p&gt;Github user uce commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I don&apos;t know if we &quot;want to&quot;, but it is the current behaviour. A job should only fail if its restart strategy is exhausted though. Do you think we should change that behaviour? &lt;/p&gt;</comment>
                            <comment id="15382419" author="githubbot" created="Mon, 18 Jul 2016 15:06:43 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    In general, I think it would be helpful for users to be able to retrieve checkpoints of a failed job. I could imagine a scenario where a job is faulty but one only runs into after some time. Being then able to transform a checkpoint into a savepoint and then restarting the failed job with a corrected jar could be helpful.&lt;/p&gt;

&lt;p&gt;    Thus, I think we should only remove the persisted job data if the job has reached FINISHED or CANCELED. Admittedly, this is a very conservative approach, but then users are less likely to lose data.&lt;/p&gt;

&lt;p&gt;    However, this should be out of the scope of this PR.&lt;/p&gt;</comment>
                            <comment id="15385713" author="githubbot" created="Wed, 20 Jul 2016 11:42:44 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256#discussion_r71509039&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256#discussion_r71509039&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/execution/librarycache/BlobLibraryCacheManager.java &amp;#8212;&lt;br/&gt;
    @@ -77,7 +77,7 @@ public BlobLibraryCacheManager(BlobService blobService, long cleanupInterval) {&lt;/p&gt;

&lt;p&gt;     		// Initializing the clean up task&lt;br/&gt;
     		this.cleanupTimer = new Timer(true);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.cleanupTimer.schedule(this, cleanupInterval);&lt;br/&gt;
    +		this.cleanupTimer.schedule(this, cleanupInterval, cleanupInterval);
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Good catch :+1:&lt;/p&gt;</comment>
                            <comment id="15385722" author="githubbot" created="Wed, 20 Jul 2016 11:52:26 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256#discussion_r71510844&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256#discussion_r71510844&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/test/java/org/apache/flink/runtime/jobmanager/JobManagerHARecoveryTest.java &amp;#8212;&lt;br/&gt;
    @@ -243,6 +256,268 @@ public void testJobRecoveryWhenLosingLeadership() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * Tests that the persisted job is not removed from the job graph store&lt;br/&gt;
    +	 * after the postStop method of the JobManager. Furthermore, it checks&lt;br/&gt;
    +	 * that BLOBs of the JobGraph are recovered properly and cleaned up after&lt;br/&gt;
    +	 * the job finishes.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testBlobRecoveryAfterLostJobManager() throws Exception {&lt;br/&gt;
    +		FiniteDuration timeout = new FiniteDuration(30, TimeUnit.SECONDS);&lt;br/&gt;
    +		FiniteDuration jobRecoveryTimeout = new FiniteDuration(3, TimeUnit.SECONDS);&lt;br/&gt;
    +		Deadline deadline = new FiniteDuration(2, TimeUnit.MINUTES).fromNow();&lt;br/&gt;
    +		Configuration flinkConfiguration = new Configuration();&lt;br/&gt;
    +		UUID leaderSessionID = UUID.randomUUID();&lt;br/&gt;
    +		UUID newLeaderSessionID = UUID.randomUUID();&lt;br/&gt;
    +		int slots = 2;&lt;br/&gt;
    +		ActorRef archiveRef = null;&lt;br/&gt;
    +		ActorRef jobManagerRef = null;&lt;br/&gt;
    +		ActorRef taskManagerRef = null;&lt;br/&gt;
    +&lt;br/&gt;
    +		String haStoragePath = temporaryFolder.newFolder().toString();&lt;br/&gt;
    +&lt;br/&gt;
    +		flinkConfiguration.setString(ConfigConstants.RECOVERY_MODE, &quot;zookeeper&quot;);&lt;br/&gt;
    +		flinkConfiguration.setString(ConfigConstants.ZOOKEEPER_RECOVERY_PATH, haStoragePath);&lt;br/&gt;
    +		flinkConfiguration.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, slots);&lt;br/&gt;
    +&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			MySubmittedJobGraphStore mySubmittedJobGraphStore = new MySubmittedJobGraphStore();&lt;br/&gt;
    +			TestingLeaderElectionService myLeaderElectionService = new TestingLeaderElectionService();&lt;br/&gt;
    +			TestingLeaderRetrievalService myLeaderRetrievalService = new TestingLeaderRetrievalService();&lt;br/&gt;
    +&lt;br/&gt;
    +			archiveRef = system.actorOf(Props.create(&lt;br/&gt;
    +					MemoryArchivist.class,&lt;br/&gt;
    +					10), &quot;archive&quot;);&lt;br/&gt;
    +&lt;br/&gt;
    +			jobManagerRef = createJobManagerActor(&lt;br/&gt;
    +					&quot;jobmanager-0&quot;,&lt;br/&gt;
    +					flinkConfiguration,&lt;br/&gt;
    +					myLeaderElectionService,&lt;br/&gt;
    +					mySubmittedJobGraphStore,&lt;br/&gt;
    +					3600000,&lt;br/&gt;
    +					timeout,&lt;br/&gt;
    +					jobRecoveryTimeout, archiveRef);&lt;br/&gt;
    +&lt;br/&gt;
    +			ActorGateway jobManager = new AkkaActorGateway(jobManagerRef, leaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			taskManagerRef = TaskManager.startTaskManagerComponentsAndActor(&lt;br/&gt;
    +					flinkConfiguration,&lt;br/&gt;
    +					ResourceID.generate(),&lt;br/&gt;
    +					system,&lt;br/&gt;
    +					&quot;localhost&quot;,&lt;br/&gt;
    +					Option.apply(&quot;taskmanager&quot;),&lt;br/&gt;
    +					Option.apply((LeaderRetrievalService) myLeaderRetrievalService),&lt;br/&gt;
    +					true,&lt;br/&gt;
    +					TestingTaskManager.class);&lt;br/&gt;
    +&lt;br/&gt;
    +			ActorGateway tmGateway = new AkkaActorGateway(taskManagerRef, leaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; tmAlive = tmGateway.ask(TestingMessages.getAlive(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(tmAlive, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			JobVertex sourceJobVertex = new JobVertex(&quot;Source&quot;);&lt;br/&gt;
    +			sourceJobVertex.setInvokableClass(BlockingInvokable.class);&lt;br/&gt;
    +			sourceJobVertex.setParallelism(slots);&lt;br/&gt;
    +&lt;br/&gt;
    +			JobGraph jobGraph = new JobGraph(&quot;TestingJob&quot;, sourceJobVertex);&lt;br/&gt;
    +&lt;br/&gt;
    +			// Upload fake JAR file to first JobManager&lt;br/&gt;
    +			File jarFile = temporaryFolder.newFile();&lt;br/&gt;
    +			ZipOutputStream out = new ZipOutputStream(new FileOutputStream(jarFile));&lt;br/&gt;
    +			out.close();&lt;br/&gt;
    +&lt;br/&gt;
    +			jobGraph.addJar(new Path(jarFile.toURI()));&lt;br/&gt;
    +			JobClient.uploadJarFiles(jobGraph, jobManager, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; isLeader = jobManager.ask(&lt;br/&gt;
    +					TestingJobManagerMessages.getNotifyWhenLeader(),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; isConnectedToJobManager = tmGateway.ask(&lt;br/&gt;
    +					new TestingTaskManagerMessages.NotifyWhenRegisteredAtJobManager(jobManagerRef),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// tell jobManager that he&apos;s the leader&lt;br/&gt;
    +			myLeaderElectionService.isLeader(leaderSessionID);&lt;br/&gt;
    +			// tell taskManager who&apos;s the leader&lt;br/&gt;
    +			myLeaderRetrievalService.notifyListener(jobManager.path(), leaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(isLeader, deadline.timeLeft());&lt;br/&gt;
    +			Await.ready(isConnectedToJobManager, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// submit blocking job&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; jobSubmitted = jobManager.ask(&lt;br/&gt;
    +					new JobManagerMessages.SubmitJob(jobGraph, ListeningBehaviour.DETACHED),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(jobSubmitted, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// Wait for running&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; jobRunning = jobManager.ask(&lt;br/&gt;
    +					new TestingJobManagerMessages.NotifyWhenJobStatus(jobGraph.getJobID(), JobStatus.RUNNING),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(jobRunning, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// terminate the job manager&lt;br/&gt;
    +			jobManagerRef.tell(PoisonPill.getInstance(), ActorRef.noSender());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Boolean&amp;gt; terminatedFuture = Patterns.gracefulStop(jobManagerRef, deadline.timeLeft());&lt;br/&gt;
    +			Boolean terminated = Await.result(terminatedFuture, deadline.timeLeft());&lt;br/&gt;
    +			assertTrue(&quot;Failed to stop job manager&quot;, terminated);&lt;br/&gt;
    +&lt;br/&gt;
    +			// job stays in the submitted job graph store&lt;br/&gt;
    +			assertTrue(mySubmittedJobGraphStore.contains(jobGraph.getJobID()));&lt;br/&gt;
    +&lt;br/&gt;
    +			// start new job manager&lt;br/&gt;
    +			myLeaderElectionService.reset();&lt;br/&gt;
    +&lt;br/&gt;
    +			jobManagerRef = createJobManagerActor(&lt;br/&gt;
    +					&quot;jobmanager-1&quot;,&lt;br/&gt;
    +					flinkConfiguration,&lt;br/&gt;
    +					myLeaderElectionService,&lt;br/&gt;
    +					mySubmittedJobGraphStore,&lt;br/&gt;
    +					500,&lt;br/&gt;
    +					timeout,&lt;br/&gt;
    +					jobRecoveryTimeout,&lt;br/&gt;
    +					archiveRef);&lt;br/&gt;
    +&lt;br/&gt;
    +			jobManager = new AkkaActorGateway(jobManagerRef, newLeaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; isAlive = jobManager.ask(TestingMessages.getAlive(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			isLeader = jobManager.ask(&lt;br/&gt;
    +					TestingJobManagerMessages.getNotifyWhenLeader(),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			isConnectedToJobManager = tmGateway.ask(&lt;br/&gt;
    +					new TestingTaskManagerMessages.NotifyWhenRegisteredAtJobManager(jobManagerRef),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(isAlive, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// tell new jobManager that he&apos;s the leader&lt;br/&gt;
    +			myLeaderElectionService.isLeader(newLeaderSessionID);&lt;br/&gt;
    +			// tell taskManager who&apos;s the leader&lt;br/&gt;
    +			myLeaderRetrievalService.notifyListener(jobManager.path(), newLeaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(isLeader, deadline.timeLeft());&lt;br/&gt;
    +			Await.ready(isConnectedToJobManager, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			jobRunning = jobManager.ask(&lt;br/&gt;
    +					new TestingJobManagerMessages.NotifyWhenJobStatus(jobGraph.getJobID(), JobStatus.RUNNING),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// wait that the job is recovered and reaches state RUNNING&lt;br/&gt;
    +			Await.ready(jobRunning, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; jobFinished = jobManager.ask(&lt;br/&gt;
    +					new TestingJobManagerMessages.NotifyWhenJobRemoved(jobGraph.getJobID()),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			BlockingInvokable.unblock();&lt;br/&gt;
    +&lt;br/&gt;
    +			// wait til the job has finished&lt;br/&gt;
    +			Await.ready(jobFinished, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// check that the job has been removed from the submitted job graph store&lt;br/&gt;
    +			assertFalse(mySubmittedJobGraphStore.contains(jobGraph.getJobID()));&lt;br/&gt;
    +&lt;br/&gt;
    +			// Check that the BLOB store files are removed&lt;br/&gt;
    +			File rootPath = new File(haStoragePath);&lt;br/&gt;
    +&lt;br/&gt;
    +			boolean cleanedUpFiles = false;&lt;br/&gt;
    +			while (deadline.hasTimeLeft()) {&lt;br/&gt;
    +				if (listFiles(rootPath).isEmpty()) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    We check that the directory no longer contains files. But we don&apos;t check for folders, right? I think that we no longer delete the folders created by the BlobStore. We could maybe check in `BlobStore.cleanUp` whether there are any empty folders which we can delete. Do you think that this could be relevant? &lt;/p&gt;</comment>
                            <comment id="15385726" author="githubbot" created="Wed, 20 Jul 2016 11:59:14 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Changes look good to me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Really good work @uce. I&apos;m just wondering whether we could remove empty folders upon shutdown of the `BlobStore`. Apart from that, +1 for merging.&lt;/p&gt;</comment>
                            <comment id="15387744" author="githubbot" created="Thu, 21 Jul 2016 14:10:33 +0000"  >&lt;p&gt;Github user uce commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256#discussion_r71711908&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256#discussion_r71711908&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/test/java/org/apache/flink/runtime/jobmanager/JobManagerHARecoveryTest.java &amp;#8212;&lt;br/&gt;
    @@ -243,6 +256,268 @@ public void testJobRecoveryWhenLosingLeadership() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * Tests that the persisted job is not removed from the job graph store&lt;br/&gt;
    +	 * after the postStop method of the JobManager. Furthermore, it checks&lt;br/&gt;
    +	 * that BLOBs of the JobGraph are recovered properly and cleaned up after&lt;br/&gt;
    +	 * the job finishes.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testBlobRecoveryAfterLostJobManager() throws Exception {&lt;br/&gt;
    +		FiniteDuration timeout = new FiniteDuration(30, TimeUnit.SECONDS);&lt;br/&gt;
    +		FiniteDuration jobRecoveryTimeout = new FiniteDuration(3, TimeUnit.SECONDS);&lt;br/&gt;
    +		Deadline deadline = new FiniteDuration(2, TimeUnit.MINUTES).fromNow();&lt;br/&gt;
    +		Configuration flinkConfiguration = new Configuration();&lt;br/&gt;
    +		UUID leaderSessionID = UUID.randomUUID();&lt;br/&gt;
    +		UUID newLeaderSessionID = UUID.randomUUID();&lt;br/&gt;
    +		int slots = 2;&lt;br/&gt;
    +		ActorRef archiveRef = null;&lt;br/&gt;
    +		ActorRef jobManagerRef = null;&lt;br/&gt;
    +		ActorRef taskManagerRef = null;&lt;br/&gt;
    +&lt;br/&gt;
    +		String haStoragePath = temporaryFolder.newFolder().toString();&lt;br/&gt;
    +&lt;br/&gt;
    +		flinkConfiguration.setString(ConfigConstants.RECOVERY_MODE, &quot;zookeeper&quot;);&lt;br/&gt;
    +		flinkConfiguration.setString(ConfigConstants.ZOOKEEPER_RECOVERY_PATH, haStoragePath);&lt;br/&gt;
    +		flinkConfiguration.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, slots);&lt;br/&gt;
    +&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			MySubmittedJobGraphStore mySubmittedJobGraphStore = new MySubmittedJobGraphStore();&lt;br/&gt;
    +			TestingLeaderElectionService myLeaderElectionService = new TestingLeaderElectionService();&lt;br/&gt;
    +			TestingLeaderRetrievalService myLeaderRetrievalService = new TestingLeaderRetrievalService();&lt;br/&gt;
    +&lt;br/&gt;
    +			archiveRef = system.actorOf(Props.create(&lt;br/&gt;
    +					MemoryArchivist.class,&lt;br/&gt;
    +					10), &quot;archive&quot;);&lt;br/&gt;
    +&lt;br/&gt;
    +			jobManagerRef = createJobManagerActor(&lt;br/&gt;
    +					&quot;jobmanager-0&quot;,&lt;br/&gt;
    +					flinkConfiguration,&lt;br/&gt;
    +					myLeaderElectionService,&lt;br/&gt;
    +					mySubmittedJobGraphStore,&lt;br/&gt;
    +					3600000,&lt;br/&gt;
    +					timeout,&lt;br/&gt;
    +					jobRecoveryTimeout, archiveRef);&lt;br/&gt;
    +&lt;br/&gt;
    +			ActorGateway jobManager = new AkkaActorGateway(jobManagerRef, leaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			taskManagerRef = TaskManager.startTaskManagerComponentsAndActor(&lt;br/&gt;
    +					flinkConfiguration,&lt;br/&gt;
    +					ResourceID.generate(),&lt;br/&gt;
    +					system,&lt;br/&gt;
    +					&quot;localhost&quot;,&lt;br/&gt;
    +					Option.apply(&quot;taskmanager&quot;),&lt;br/&gt;
    +					Option.apply((LeaderRetrievalService) myLeaderRetrievalService),&lt;br/&gt;
    +					true,&lt;br/&gt;
    +					TestingTaskManager.class);&lt;br/&gt;
    +&lt;br/&gt;
    +			ActorGateway tmGateway = new AkkaActorGateway(taskManagerRef, leaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; tmAlive = tmGateway.ask(TestingMessages.getAlive(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(tmAlive, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			JobVertex sourceJobVertex = new JobVertex(&quot;Source&quot;);&lt;br/&gt;
    +			sourceJobVertex.setInvokableClass(BlockingInvokable.class);&lt;br/&gt;
    +			sourceJobVertex.setParallelism(slots);&lt;br/&gt;
    +&lt;br/&gt;
    +			JobGraph jobGraph = new JobGraph(&quot;TestingJob&quot;, sourceJobVertex);&lt;br/&gt;
    +&lt;br/&gt;
    +			// Upload fake JAR file to first JobManager&lt;br/&gt;
    +			File jarFile = temporaryFolder.newFile();&lt;br/&gt;
    +			ZipOutputStream out = new ZipOutputStream(new FileOutputStream(jarFile));&lt;br/&gt;
    +			out.close();&lt;br/&gt;
    +&lt;br/&gt;
    +			jobGraph.addJar(new Path(jarFile.toURI()));&lt;br/&gt;
    +			JobClient.uploadJarFiles(jobGraph, jobManager, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; isLeader = jobManager.ask(&lt;br/&gt;
    +					TestingJobManagerMessages.getNotifyWhenLeader(),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; isConnectedToJobManager = tmGateway.ask(&lt;br/&gt;
    +					new TestingTaskManagerMessages.NotifyWhenRegisteredAtJobManager(jobManagerRef),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// tell jobManager that he&apos;s the leader&lt;br/&gt;
    +			myLeaderElectionService.isLeader(leaderSessionID);&lt;br/&gt;
    +			// tell taskManager who&apos;s the leader&lt;br/&gt;
    +			myLeaderRetrievalService.notifyListener(jobManager.path(), leaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(isLeader, deadline.timeLeft());&lt;br/&gt;
    +			Await.ready(isConnectedToJobManager, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// submit blocking job&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; jobSubmitted = jobManager.ask(&lt;br/&gt;
    +					new JobManagerMessages.SubmitJob(jobGraph, ListeningBehaviour.DETACHED),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(jobSubmitted, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// Wait for running&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; jobRunning = jobManager.ask(&lt;br/&gt;
    +					new TestingJobManagerMessages.NotifyWhenJobStatus(jobGraph.getJobID(), JobStatus.RUNNING),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(jobRunning, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// terminate the job manager&lt;br/&gt;
    +			jobManagerRef.tell(PoisonPill.getInstance(), ActorRef.noSender());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Boolean&amp;gt; terminatedFuture = Patterns.gracefulStop(jobManagerRef, deadline.timeLeft());&lt;br/&gt;
    +			Boolean terminated = Await.result(terminatedFuture, deadline.timeLeft());&lt;br/&gt;
    +			assertTrue(&quot;Failed to stop job manager&quot;, terminated);&lt;br/&gt;
    +&lt;br/&gt;
    +			// job stays in the submitted job graph store&lt;br/&gt;
    +			assertTrue(mySubmittedJobGraphStore.contains(jobGraph.getJobID()));&lt;br/&gt;
    +&lt;br/&gt;
    +			// start new job manager&lt;br/&gt;
    +			myLeaderElectionService.reset();&lt;br/&gt;
    +&lt;br/&gt;
    +			jobManagerRef = createJobManagerActor(&lt;br/&gt;
    +					&quot;jobmanager-1&quot;,&lt;br/&gt;
    +					flinkConfiguration,&lt;br/&gt;
    +					myLeaderElectionService,&lt;br/&gt;
    +					mySubmittedJobGraphStore,&lt;br/&gt;
    +					500,&lt;br/&gt;
    +					timeout,&lt;br/&gt;
    +					jobRecoveryTimeout,&lt;br/&gt;
    +					archiveRef);&lt;br/&gt;
    +&lt;br/&gt;
    +			jobManager = new AkkaActorGateway(jobManagerRef, newLeaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; isAlive = jobManager.ask(TestingMessages.getAlive(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			isLeader = jobManager.ask(&lt;br/&gt;
    +					TestingJobManagerMessages.getNotifyWhenLeader(),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			isConnectedToJobManager = tmGateway.ask(&lt;br/&gt;
    +					new TestingTaskManagerMessages.NotifyWhenRegisteredAtJobManager(jobManagerRef),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(isAlive, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// tell new jobManager that he&apos;s the leader&lt;br/&gt;
    +			myLeaderElectionService.isLeader(newLeaderSessionID);&lt;br/&gt;
    +			// tell taskManager who&apos;s the leader&lt;br/&gt;
    +			myLeaderRetrievalService.notifyListener(jobManager.path(), newLeaderSessionID);&lt;br/&gt;
    +&lt;br/&gt;
    +			Await.ready(isLeader, deadline.timeLeft());&lt;br/&gt;
    +			Await.ready(isConnectedToJobManager, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			jobRunning = jobManager.ask(&lt;br/&gt;
    +					new TestingJobManagerMessages.NotifyWhenJobStatus(jobGraph.getJobID(), JobStatus.RUNNING),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// wait that the job is recovered and reaches state RUNNING&lt;br/&gt;
    +			Await.ready(jobRunning, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			Future&amp;lt;Object&amp;gt; jobFinished = jobManager.ask(&lt;br/&gt;
    +					new TestingJobManagerMessages.NotifyWhenJobRemoved(jobGraph.getJobID()),&lt;br/&gt;
    +					deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			BlockingInvokable.unblock();&lt;br/&gt;
    +&lt;br/&gt;
    +			// wait til the job has finished&lt;br/&gt;
    +			Await.ready(jobFinished, deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +			// check that the job has been removed from the submitted job graph store&lt;br/&gt;
    +			assertFalse(mySubmittedJobGraphStore.contains(jobGraph.getJobID()));&lt;br/&gt;
    +&lt;br/&gt;
    +			// Check that the BLOB store files are removed&lt;br/&gt;
    +			File rootPath = new File(haStoragePath);&lt;br/&gt;
    +&lt;br/&gt;
    +			boolean cleanedUpFiles = false;&lt;br/&gt;
    +			while (deadline.hasTimeLeft()) {&lt;br/&gt;
    +				if (listFiles(rootPath).isEmpty()) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes, that is true. We will for example have empty folders `&amp;lt;root&amp;gt;/blob/cache` in this test. I&apos;ve added a method to try to delete the parent directory when deleting a BLOB (same as what are currently doing in `AbstractFileStateHandle`). I will adjust this check to check that the directory is empty.&lt;/p&gt;</comment>
                            <comment id="15387753" author="githubbot" created="Thu, 21 Jul 2016 14:15:09 +0000"  >&lt;p&gt;Github user uce commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thank you for your review. I&apos;ve addressed your comment and now parent directories are deleted if empty, resulting in an empty storage folder after regular cleanup. If there are no objections, I would like to merge this later today.&lt;/p&gt;</comment>
                            <comment id="15391874" author="githubbot" created="Mon, 25 Jul 2016 13:21:56 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2256&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15391875" author="uce" created="Mon, 25 Jul 2016 13:21:57 +0000"  >&lt;p&gt;Fixed in 3213016 (master).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12987798">FLINK-4182</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12987419">FLINK-4166</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 17 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30iav:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>