<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:33:49 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-9374] Flink Kinesis Producer does not backpressure</title>
                <link>https://issues.apache.org/jira/browse/FLINK-9374</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The &lt;tt&gt;FlinkKinesisProducer&lt;/tt&gt; just accepts records and forwards it to a &lt;tt&gt;KinesisProducer&lt;/tt&gt; from the Amazon Kinesis Producer Library (KPL). The KPL internally holds an unbounded queue of records that have not yet been sent.&lt;/p&gt;

&lt;p&gt;Since Kinesis is rate-limited to 1MB per second per shard, this queue may grow indefinitely if Flink sends records faster than the KPL can forward them to Kinesis.&lt;/p&gt;

&lt;p&gt;One way to circumvent this problem is to set a record TTL, so that queued records are dropped after a certain amount of time, but this will lead to data loss under high loads.&lt;/p&gt;

&lt;p&gt;Currently the only time the queue is flushed is during checkpointing: &lt;tt&gt;FlinkKinesisProducer&lt;/tt&gt; consumes records at arbitrary rate, either until a checkpoint is reached (and will wait until the queue is flushed), or until out-of-memory, whichever is reached first. (This gets worse due to the fact that the Java KPL is only a thin wrapper around a C++ process, so it is not even the Java process that runs out of memory, but the C++ process.) The implicit rate-limit due to checkpointing leads to a ragged throughput graph like this (the periods with zero throughput are the wait times before a checkpoint):&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;file:///home/fthoma/projects/flink/before.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12923611/12923611_before.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt; Throughput limited by checkpointing only&lt;/p&gt;

&lt;p&gt;My proposed solution is to add a config option &lt;tt&gt;queueLimit&lt;/tt&gt; to set a maximum number of records that may be waiting in the KPL queue. If this limit is reached, the &lt;tt&gt;FlinkKinesisProducer&lt;/tt&gt; should trigger a &lt;tt&gt;flush()&lt;/tt&gt; and wait (blocking) until the queue length is below the limit again. This automatically leads to backpressuring, since the &lt;tt&gt;FlinkKinesisProducer&lt;/tt&gt; cannot accept records while waiting. For compatibility, &lt;tt&gt;queueLimit&lt;/tt&gt; is set to &lt;tt&gt;Integer.MAX_VALUE&lt;/tt&gt; by default, so the behavior is unchanged unless a client explicitly sets the value. Setting a &#187;sane&#171; default value is not possible unfortunately, since sensible values for the limit depend on the record size (the limit should be chosen so that about 10&#8211;100MB of records per shard are accumulated before flushing, otherwise the maximum Kinesis throughput may not be reached).&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12923610/12923610_after.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt; Throughput with a queue limit of 100000 records (the spikes are checkpoints, where the queue is still flushed completely)&lt;/p&gt;</description>
                <environment></environment>
        <key id="13159637">FLINK-9374</key>
            <summary>Flink Kinesis Producer does not backpressure</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="fmthoma">Franz Thoma</assignee>
                                    <reporter username="fmthoma">Franz Thoma</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 16 May 2018 07:55:10 +0000</created>
                <updated>Fri, 22 Jun 2018 10:55:39 +0000</updated>
                            <resolved>Fri, 22 Jun 2018 09:26:43 +0000</resolved>
                                                    <fixVersion>1.5.1</fixVersion>
                    <fixVersion>1.6.0</fixVersion>
                                    <component>Connectors / Kinesis</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16477014" author="githubbot" created="Wed, 16 May 2018 08:12:17 +0000"  >&lt;p&gt;GitHub user fmthoma opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9374&quot; title=&quot;Flink Kinesis Producer does not backpressure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9374&quot;&gt;&lt;del&gt;FLINK-9374&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kinesis&amp;#93;&lt;/span&gt; Enable FlinkKinesisProducer Backpressuring&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    The `FlinkKinesisProducer` just accepts records and forwards it to a `KinesisProducer` from the Amazon Kinesis Producer Library (KPL). The KPL internally holds an unbounded queue of records that have not yet been sent.&lt;/p&gt;

&lt;p&gt;    Since Kinesis is rate-limited to 1MB per second per shard, this queue may grow indefinitely if Flink sends records faster than the KPL can forward them to Kinesis.&lt;/p&gt;

&lt;p&gt;    One way to circumvent this problem is to set a record TTL, so that queued records are dropped after a certain amount of time, but this will lead to data loss under high loads.&lt;/p&gt;

&lt;p&gt;    Currently the only time the queue is flushed is during checkpointing: `FlinkKinesisProducer` consumes records at arbitrary rate, either until a checkpoint is reached (and will wait until the queue is flushed), or until out-of-memory, whichever is reached first. (This gets worse due to the fact that the Java KPL is only a thin wrapper around a C++ process, so it is not even the Java process that runs out of memory, but the C++ process.)&lt;/p&gt;

&lt;p&gt;    My proposed solution is to add a config option `queueLimit` to set a maximum number of records that may be waiting in the KPL queue. If this limit is reached, the `FlinkKinesisProducer` should trigger a `flush()` and wait (blocking) until the queue length is below the limit again. This automatically leads to backpressuring, since the `FlinkKinesisProducer` cannot accept records while waiting. For compatibility, `queueLimit` is set to `Integer.MAX_VALUE` by default, so the behavior is unchanged unless a client explicitly sets the value. Setting a &#187;sane&#171; default value is not possible unfortunately, since sensible values for the limit depend on the record size (the limit should be chosen so that about 10&#8211;100MB of records per shard are accumulated before flushing, otherwise the maximum Kinesis throughput may not be reached).&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul&gt;
	&lt;li&gt;Add a `queueLimit` setting to `FlinkKinesisProducer` to limit the number of in-flight records in the Kinesis Producer Library, and enable backpressuring if the limit is exceeded&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    This change added tests and can be verified as follows:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Added unit test&lt;/li&gt;
	&lt;li&gt;Manually verified the change by running a job that produces to a 2-shard Kinesis stream. The input rate is limited by Kinesis (verified that the Kinesis stream is indeed at maximum capacity).&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): no&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: yes, but backwards compatible (option was added)&lt;/li&gt;
	&lt;li&gt;The serializers: no&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): don&apos;t know&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: don&apos;t know&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: no&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? yes&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? JavaDocs&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/fmthoma/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/fmthoma/flink&lt;/a&gt; queueLimit&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #6021&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 9a2930cbbec4cd6979e6bfacb741da820cdbb284&lt;br/&gt;
Author: Franz Thoma &amp;lt;franz.thoma@...&amp;gt;&lt;br/&gt;
Date:   2018-05-09T06:27:47Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9374&quot; title=&quot;Flink Kinesis Producer does not backpressure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9374&quot;&gt;&lt;del&gt;FLINK-9374&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kinesis&amp;#93;&lt;/span&gt; Add hardcoded queue size limit of 100000 records&lt;/p&gt;

&lt;p&gt;commit e41037eb5e07efb73ded7f945111d0d5f6e9b18b&lt;br/&gt;
Author: Franz Thoma &amp;lt;franz.thoma@...&amp;gt;&lt;br/&gt;
Date:   2018-05-09T06:56:53Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9374&quot; title=&quot;Flink Kinesis Producer does not backpressure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9374&quot;&gt;&lt;del&gt;FLINK-9374&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kinesis&amp;#93;&lt;/span&gt; Expose queueLimit option&lt;/p&gt;

&lt;p&gt;commit 9222849869da0018718072c33b32d8d935f3dec4&lt;br/&gt;
Author: Franz Thoma &amp;lt;franz.thoma@...&amp;gt;&lt;br/&gt;
Date:   2018-05-09T07:08:11Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9374&quot; title=&quot;Flink Kinesis Producer does not backpressure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9374&quot;&gt;&lt;del&gt;FLINK-9374&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kinesis&amp;#93;&lt;/span&gt; Refactor test: Mock implementation of flush() only flushes &lt;b&gt;some&lt;/b&gt;, not &lt;b&gt;all&lt;/b&gt; records&lt;/p&gt;

&lt;p&gt;commit f062c5b9cd2e572da9fef0cdb5c8ea89af2a228c&lt;br/&gt;
Author: Franz Thoma &amp;lt;franz.thoma@...&amp;gt;&lt;br/&gt;
Date:   2018-05-09T11:59:05Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9374&quot; title=&quot;Flink Kinesis Producer does not backpressure&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9374&quot;&gt;&lt;del&gt;FLINK-9374&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kinesis&amp;#93;&lt;/span&gt; adapt tests&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16480173" author="githubbot" created="Fri, 18 May 2018 05:17:56 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189163394&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189163394&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -218,6 +232,8 @@ public void invoke(OUT value, Context context) throws Exception &lt;/p&gt;
{
     			throw new RuntimeException(&quot;Kinesis producer has been closed&quot;);
     		}

&lt;p&gt;    +		checkAndPropagateAsyncError();&lt;br/&gt;
    +		checkQueueLimit();&lt;br/&gt;
     		checkAndPropagateAsyncError();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This second check is to check any async errors that occurred during the queue flush, correct?&lt;br/&gt;
    If so, we should probably move this second invocation into `checkQueueLimit` to make this more implicit.&lt;/p&gt;</comment>
                            <comment id="16480174" author="githubbot" created="Fri, 18 May 2018 05:17:56 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189164871&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189164871&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Do we have to do a flush here? Shouldn&apos;t the KPL child process process the user records in the background without an explicit flush call?&lt;/p&gt;

&lt;p&gt;    If so, perhaps a more graceful solution here is to wait on a local object, and notify it to wake up in the asynchronous producer write call backs. After being notified, we check the `getOutstandingRecordsCount` agains the queueLimit, and either wait more or escape the loop.&lt;/p&gt;

&lt;p&gt;    What do you think?&lt;/p&gt;</comment>
                            <comment id="16480243" author="githubbot" created="Fri, 18 May 2018 06:50:21 +0000"  >&lt;p&gt;Github user bowenli86 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189174902&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189174902&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    probably rename it to something different, e.g  `enforceQueueLimit()`? because it clearly does things more than just &apos;check&apos;&lt;/p&gt;</comment>
                            <comment id="16480244" author="githubbot" created="Fri, 18 May 2018 06:50:21 +0000"  >&lt;p&gt;Github user bowenli86 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189175770&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189175770&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Iooks like &lt;span class=&quot;error&quot;&gt;&amp;#91;KinesisProducer&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer/src/main/java/com/amazonaws/services/kinesis/producer/KinesisProducer.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/awslabs/amazon-kinesis-producer/blob/master/java/amazon-kinesis-producer/src/main/java/com/amazonaws/services/kinesis/producer/KinesisProducer.java&lt;/a&gt;) doesn&apos;t have a way to get child process&apos;s callback. Or maybe I misunderstood your proposal, Gordon? &lt;/p&gt;</comment>
                            <comment id="16480245" author="githubbot" created="Fri, 18 May 2018 06:50:21 +0000"  >&lt;p&gt;Github user bowenli86 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189176320&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189176320&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    +			try &lt;/p&gt;
{
    +				Thread.sleep(500);
    +			}
&lt;p&gt; catch (InterruptedException e) {&lt;br/&gt;
    +				LOG.warn(&quot;Flushing was interrupted.&quot;);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    you can remove this two lines, they don&apos;t provide much value. After removal, it will be almost exactly how `KinesisProducer#flushSync` works&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
    // KinesisProducer.java&lt;br/&gt;
    @Override&lt;br/&gt;
        public void flushSync() {&lt;br/&gt;
            while (getOutstandingRecordsCount() &amp;gt; 0) {&lt;br/&gt;
                flush();&lt;br/&gt;
                try &lt;/p&gt;
{
                    Thread.sleep(500);
                }
&lt;p&gt; catch (InterruptedException e) { }&lt;br/&gt;
            }&lt;br/&gt;
        }&lt;br/&gt;
    ```&lt;/p&gt;</comment>
                            <comment id="16480246" author="githubbot" created="Fri, 18 May 2018 06:50:21 +0000"  >&lt;p&gt;Github user bowenli86 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189176708&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189176708&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    A more important thing I would count and log here is how many times it has already tried to flush within a single call of `enforceQueueLimit()`. We can set a threshold, say 10 times, and then log a message saying that KPL is leading to backpressure&lt;/p&gt;</comment>
                            <comment id="16480250" author="githubbot" created="Fri, 18 May 2018 06:53:22 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189177308&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189177308&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    When we add a record to the producer queue via `producer.addUserRecord(...)`, we get a callback. We can use that callback to notify the blocking operation in `checkQueueLimit`.&lt;/p&gt;</comment>
                            <comment id="16480251" author="githubbot" created="Fri, 18 May 2018 06:53:46 +0000"  >&lt;p&gt;Github user bowenli86 commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai adding docs to educate users on tuning KPL performance would be good. I has quite some experience on it (as you may have know &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Ping me if you start working on it before I do, and I&apos;ll be glad to help contribute&lt;/p&gt;</comment>
                            <comment id="16481606" author="githubbot" created="Sat, 19 May 2018 12:15:14 +0000"  >&lt;p&gt;Github user fmthoma commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai I agree on adding additional docs, where do you suggest I should put them? In the Javadoc on `setQueueLimit()`?&lt;/p&gt;

&lt;p&gt;    My current suggestion is to look at the size of your individual records, and choose the queue limit so that about 10MB per shard are aggregated. 1MB would be too small (since the KPL aggregates the user records to 1MB batches). But I&apos;ll run some more performance tests, in particular also with the `wait()`/`notify()` change you suggested above.&lt;/p&gt;</comment>
                            <comment id="16481609" author="githubbot" created="Sat, 19 May 2018 12:28:44 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189432726&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189432726&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    &amp;gt; Do we have to do a flush here? Shouldn&apos;t the KPL child process process the user records in the background without an explicit flush call?&lt;/p&gt;

&lt;p&gt;    I don&apos;t know for sure, but here&apos;s what I think: The KPL aggregates records into batches of 1MB before sending them out, in order to achieve maximum throughput. If we reach the queue limit before 1MB batch is full, the KPL may wait for some time before sending the aggregated record anyway. The `flush()` should trigger that immediately.&lt;/p&gt;

&lt;p&gt;    Also, according to the Javadocs on `flush()`:&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
        /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Instruct the child process to perform a flush, sending some of the&lt;/li&gt;
	&lt;li&gt;records it has buffered. Applies to all streams.&lt;/li&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;&lt;/li&gt;
	&lt;li&gt;This does not guarantee that all buffered records will be sent, only that&lt;/li&gt;
	&lt;li&gt;most of them will; to flush all records and wait for completion, use&lt;/li&gt;
	&lt;li&gt;{@link #flushSync}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;&lt;/li&gt;
	&lt;li&gt;This method returns immediately without blocking.&lt;br/&gt;
    ```&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    So I think that `flush()` is still the right thing to do, although it might make sense to reduce the wait time. `notify()`ing a lock in the callback instead of waiting a fixed time might make more sense nevertheless, I will look into that.&lt;/p&gt;</comment>
                            <comment id="16481610" author="githubbot" created="Sat, 19 May 2018 12:28:44 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189432920&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189432920&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You mean, log a message if we have checked more than 10 times (5 seconds) for one record? That makes sense. But we shouldn&apos;t log every time we reach the threshold, that would lead to log spam.&lt;/p&gt;</comment>
                            <comment id="16481611" author="githubbot" created="Sat, 19 May 2018 12:28:44 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189432794&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189432794&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    +			try &lt;/p&gt;
{
    +				Thread.sleep(500);
    +			}
&lt;p&gt; catch (InterruptedException e) {&lt;br/&gt;
    +				LOG.warn(&quot;Flushing was interrupted.&quot;);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I don&apos;t think so, `flushSync()` will just swallow the interrupt and block again until the queue is empty. `checkQueueLimit()` OTOH aborts immediately on the first interrupt. So there is a difference, although we could of course discuss which one makes more sense.&lt;/p&gt;</comment>
                            <comment id="16481612" author="githubbot" created="Sat, 19 May 2018 12:28:45 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189432840&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189432840&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -218,6 +232,8 @@ public void invoke(OUT value, Context context) throws Exception &lt;/p&gt;
{
     			throw new RuntimeException(&quot;Kinesis producer has been closed&quot;);
     		}

&lt;p&gt;    +		checkAndPropagateAsyncError();&lt;br/&gt;
    +		checkQueueLimit();&lt;br/&gt;
     		checkAndPropagateAsyncError();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `snapshotState()` also checks twice explicitly, and I think it makes sense to have the two checks on the same level. But I won&apos;t insist on that, if you prefer having it more implicitly.&lt;/p&gt;</comment>
                            <comment id="16481613" author="githubbot" created="Sat, 19 May 2018 12:28:45 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189433306&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189433306&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    So I&apos;d suggest to add `producer.notifyAll()` to both `onSuccess()` and `onFailure()` in the callback, and replace the `Thread.sleep(500)` by `producer.wait(500)`. This way we re-check with every record sent out, or at most after 0.5 seconds.&lt;/p&gt;</comment>
                            <comment id="16481614" author="githubbot" created="Sat, 19 May 2018 12:28:45 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r189432802&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r189432802&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I agree.&lt;/p&gt;</comment>
                            <comment id="16486801" author="githubbot" created="Wed, 23 May 2018 06:51:49 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @fmthoma I think this might benefit from an actual documentation, not only Javadocs.&lt;/p&gt;</comment>
                            <comment id="16486875" author="githubbot" created="Wed, 23 May 2018 07:59:37 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r190154347&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r190154347&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +342,24 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void checkQueueLimit() {&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			producer.flush();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    @tzulitai @bowenli86 I&apos;ve given this some more thought. `wait()`/`notify()` requires a `synchronized` block. So if we just notify some lock in the callback, this would lead to synchronization overhead. We&apos;d have to recognize a transition from &#187;queue size &amp;gt; queue limit&#171; to &#187;queue size &amp;lt;= queue limit&#171; and only synchronize then, which adds a lot of complexity.&lt;/p&gt;

&lt;p&gt;    On the other hand: Kinesis accepts up to 1MB per second per shard. The queue limit should be chosen so that some data can be accumulated still before sending, i.e. more than a second of data (more than 1MB per shard). If the queue limit is chosen adequately, then the `Thread.sleep(500)` does not harm, as the queued records take more than one second to flush anyway. If the queue limit is chosen too low, then sleeping half a second may be too long, but we would not reach maximum throughput anyway because of the limitation on the number of `Put` requests.&lt;/p&gt;

&lt;p&gt;    I think it&apos;s not worth the additional complexity.&lt;/p&gt;</comment>
                            <comment id="16486876" author="githubbot" created="Wed, 23 May 2018 08:02:16 +0000"  >&lt;p&gt;Github user fmthoma commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai I believe the right location is `docs/dev/connectors/kinesis.md`? I&apos;ll add some docs there.&lt;/p&gt;</comment>
                            <comment id="16486879" author="githubbot" created="Wed, 23 May 2018 08:04:27 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @fmthoma yes, that would be great.&lt;/p&gt;</comment>
                            <comment id="16487102" author="githubbot" created="Wed, 23 May 2018 11:25:19 +0000"  >&lt;p&gt;Github user fmthoma commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai I added some docs.&lt;/p&gt;

&lt;p&gt;    As for the `flush()` vs. just waiting: As I see it, the &lt;span class=&quot;error&quot;&gt;&amp;#91;`RecordMaxBufferedTime`&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://github.com/awslabs/amazon-kinesis-producer/blob/ce77505306c104a6016b0c081df4715d05ac9201/java/amazon-kinesis-producer-sample/default_config.properties#L239&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/awslabs/amazon-kinesis-producer/blob/ce77505306c104a6016b0c081df4715d05ac9201/java/amazon-kinesis-producer-sample/default_config.properties#L239&lt;/a&gt;) option (default: 100 milliseconds) limits the time a record should be kept in the queue in the absence of pressure. Hence I think that the `flush()` is indeed not necessary, unless a user purposefully sets the `queueLimit` too low &lt;b&gt;and&lt;/b&gt; the `RecordMaxBufferedTime` too high.&lt;/p&gt;

&lt;p&gt;    Also, I added &lt;span class=&quot;error&quot;&gt;&amp;#91;another comment&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r190154347&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r190154347&lt;/a&gt;) concerning the `sleep` vs `wait`, that github unfortunately displays as &#187;outdated&#171;.&lt;/p&gt;</comment>
                            <comment id="16499878" author="githubbot" created="Mon, 4 Jun 2018 08:20:40 +0000"  >&lt;p&gt;Github user fmthoma commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai @bowenli86 I&apos;ve made some more changes while investigating awslabs/amazon-kinesis-producer#183:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I&apos;ve followed your suggestion and used `wait()` instead of `Thread.sleep()`, see `TimeoutLatch`. This allows much smaller queue sizes.&lt;/li&gt;
	&lt;li&gt;The timeout of 500ms is too high, i&apos;ve lowered it to 100ms.&lt;/li&gt;
	&lt;li&gt;I&apos;ve added two metrics: A `Gauge` for the `outstandingRecordsCount`, and a `Counter` for the backpressure cycles (i.e. the number of times the check `outstandingRecordsCount &amp;lt;= queueLimit` fails).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I updated the documentation, the recommended queue limit is now much lower.&lt;/p&gt;</comment>
                            <comment id="16500678" author="githubbot" created="Mon, 4 Jun 2018 18:27:45 +0000"  >&lt;p&gt;Github user bowenli86 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r192834879&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r192834879&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/util/TimeoutLatch.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,41 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kinesis.util;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TimeoutLatch {&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Object lock = new Object();&lt;br/&gt;
    +	private volatile boolean waiting;&lt;br/&gt;
    +&lt;br/&gt;
    +	public void await(long timeout) throws InterruptedException {&lt;br/&gt;
    +		synchronized (lock) &lt;/p&gt;
{
    +			waiting = true;
    +			lock.wait(timeout);
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	public void trigger() {&lt;br/&gt;
    +		if (waiting) {&lt;br/&gt;
    +			synchronized (lock) {&lt;br/&gt;
    +				waiting = false;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    needs another `if (waiting)` here inside the synchronized block, to ensure no one chimes in between line 34 and 35&lt;/p&gt;</comment>
                            <comment id="16500679" author="githubbot" created="Mon, 4 Jun 2018 18:27:45 +0000"  >&lt;p&gt;Github user bowenli86 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r192837000&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r192837000&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -180,9 +204,16 @@ public void open(Configuration parameters) throws Exception {&lt;br/&gt;
     		KinesisProducerConfiguration producerConfig = KinesisConfigUtil.getValidatedProducerConfiguration(configProps);&lt;/p&gt;

&lt;p&gt;     		producer = getKinesisProducer(producerConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final MetricGroup kinesisMectricGroup = getRuntimeContext().getMetricGroup().addGroup(&quot;kinesisProducer&quot;);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    minor: better to make these three strings constant (static final String) for easier maintenance.&lt;/p&gt;</comment>
                            <comment id="16500778" author="githubbot" created="Mon, 4 Jun 2018 19:55:02 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r192861127&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r192861127&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/util/TimeoutLatch.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,41 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kinesis.util;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TimeoutLatch {&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Object lock = new Object();&lt;br/&gt;
    +	private volatile boolean waiting;&lt;br/&gt;
    +&lt;br/&gt;
    +	public void await(long timeout) throws InterruptedException {&lt;br/&gt;
    +		synchronized (lock) &lt;/p&gt;
{
    +			waiting = true;
    +			lock.wait(timeout);
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	public void trigger() {&lt;br/&gt;
    +		if (waiting) {&lt;br/&gt;
    +			synchronized (lock) {&lt;br/&gt;
    +				waiting = false;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why? I don&apos;t think a double-check lock is necessary here: There is no harm in setting a variable to `false` that is already `false`, and neither in `notify`ing a lock for which nobody is `wait`ing. But sure, it wouldn&apos;t harm, either. Do you insist?&lt;/p&gt;</comment>
                            <comment id="16500780" author="githubbot" created="Mon, 4 Jun 2018 19:55:43 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r192861304&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r192861304&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -180,9 +204,16 @@ public void open(Configuration parameters) throws Exception {&lt;br/&gt;
     		KinesisProducerConfiguration producerConfig = KinesisConfigUtil.getValidatedProducerConfiguration(configProps);&lt;/p&gt;

&lt;p&gt;     		producer = getKinesisProducer(producerConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		final MetricGroup kinesisMectricGroup = getRuntimeContext().getMetricGroup().addGroup(&quot;kinesisProducer&quot;);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Sure.&lt;/p&gt;</comment>
                            <comment id="16518590" author="githubbot" created="Wed, 20 Jun 2018 20:58:07 +0000"  >&lt;p&gt;Github user gliu6 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r196940135&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r196940135&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I wonder whether we could adjust the queue limit dynamically. &lt;br/&gt;
    you mentioned that `queue limit = (number of shards * queue size per shard) / record size`.&lt;br/&gt;
    except record size, all others are relatively easy to set. For me, I don&apos;t really know the record size until the application starts. Also, what is the record size varies over time?&lt;br/&gt;
    So how about add a queueLimit supplier function here to allow user to supply how the queueLimit is calculated dynamically? &lt;/p&gt;
</comment>
                            <comment id="16518631" author="githubbot" created="Wed, 20 Jun 2018 21:42:44 +0000"  >&lt;p&gt;Github user gliu6 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r196952063&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r196952063&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Btw, I am not requesting any changes, pr looks good to me for it defined purpose.&lt;/p&gt;

&lt;p&gt;    Just wonder how to config easily. Now I think about this a bit more. Will it be better if we expose `queue size` to the user instead  of `queue limit (number)`, thus, Inside of the FKP class, define an integer recordSize, and inside of the invoke function, do a moving average calculation of the recordSize with `serialized.remaining()` dynamically. &lt;/p&gt;</comment>
                            <comment id="16519112" author="githubbot" created="Thu, 21 Jun 2018 09:14:53 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197063764&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197063764&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    A user-provided queue limit supplier function sounds like a good idea.&lt;br/&gt;
    As you mentioned, this can come as a follow-up PR.&lt;/p&gt;</comment>
                            <comment id="16519113" author="githubbot" created="Thu, 21 Jun 2018 09:18:17 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197064931&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197064931&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The moving average calculation, that you described, could maybe just be a implementation of the limit supplier function.&lt;/p&gt;</comment>
                            <comment id="16519138" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197065961&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197065961&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -144,6 +163,17 @@ public void setFailOnError(boolean failOnError) &lt;/p&gt;
{
     		this.failOnError = failOnError;
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * The &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; holds an unbounded queue internally. To avoid memory&lt;br/&gt;
    +	 * problems under high loads, a limit can be employed above which the internal queue&lt;br/&gt;
    +	 * will be flushed, thereby applying backpressure.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @param queueLimit The maximum length of the internal queue before backpressuring&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	public void setQueueLimit(int queueLimit) {&lt;br/&gt;
    +		this.queueLimit = queueLimit;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Will need argument checks on the given `queueLimit`.&lt;/p&gt;</comment>
                            <comment id="16519139" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197065346&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197065346&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -55,6 +58,13 @@&lt;br/&gt;
     @PublicEvolving&lt;br/&gt;
     public class FlinkKinesisProducer&amp;lt;OUT&amp;gt; extends RichSinkFunction&amp;lt;OUT&amp;gt; implements CheckpointedFunction {&lt;/p&gt;

&lt;p&gt;    +	public static final String KINESIS_PRODUCER_METRIC_GROUP = &quot;kinesisProducer&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	public static final String METRIC_BACKPRESSURE_CYCLES = &quot;backpressureCycles&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	public static final String METRIC_OUTSTANDING_RECORDS_COUNT = &quot;outstandingRecordsCount&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    nit: unnecessary line&lt;/p&gt;</comment>
                            <comment id="16519140" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197067136&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197067136&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    +		int attempt = 0;&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			backpressureCycles.inc();&lt;br/&gt;
    +			if (attempt &amp;gt;= 10) {&lt;br/&gt;
    +				LOG.warn(&quot;Waiting for the queue length to drop below the limit takes unusually long, still not done after {} attempts.&quot;, attempt);&lt;br/&gt;
    +			}&lt;br/&gt;
    +			attempt++;&lt;br/&gt;
    +			try {&lt;br/&gt;
    +				backpressureLatch.await(100);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I like this implementation a lot better now &#128077; &lt;/p&gt;</comment>
                            <comment id="16519141" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197068370&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197068370&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/util/TimeoutLatch.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,41 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kinesis.util;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TimeoutLatch {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This needs to be annotated as `@Internal`&lt;/p&gt;</comment>
                            <comment id="16519142" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197070282&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197070282&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -267,6 +268,79 @@ public void go() throws Exception &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer blocks if the queue limit is exceeded,&lt;br/&gt;
    +	 * until the queue length drops below the limit;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 10000)&lt;br/&gt;
    +	public void testBackpressure() throws Throwable {&lt;br/&gt;
    +		final DummyFlinkKinesisProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKinesisProducer&amp;lt;&amp;gt;(new SimpleStringSchema());&lt;br/&gt;
    +		producer.setQueueLimit(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +				new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		UserRecordResult result = mock(UserRecordResult.class);&lt;br/&gt;
    +		when(result.isSuccessful()).thenReturn(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		CheckedThread msg1 = new CheckedThread() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void go() throws Exception &lt;/p&gt;
{
    +				testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));
    +			}
&lt;p&gt;    +		};&lt;br/&gt;
    +		msg1.start();&lt;br/&gt;
    +		msg1.trySync(100);&lt;br/&gt;
    +		assertFalse(&quot;Flush triggered before reaching queue limit&quot;, msg1.isAlive());&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I wonder if this would introduce flakiness in the test.&lt;br/&gt;
    @fmthoma could you elaborate a bit here?&lt;/p&gt;</comment>
                            <comment id="16519143" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197067733&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197067733&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    +		int attempt = 0;&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			backpressureCycles.inc();&lt;br/&gt;
    +			if (attempt &amp;gt;= 10) {&lt;br/&gt;
    +				LOG.warn(&quot;Waiting for the queue length to drop below the limit takes unusually long, still not done after {} attempts.&quot;, attempt);&lt;br/&gt;
    +			}&lt;br/&gt;
    +			attempt++;&lt;br/&gt;
    +			try {&lt;br/&gt;
    +				backpressureLatch.await(100);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    We might want to make the wait time configurable? (as a separate PR)&lt;br/&gt;
    My reasoning is that it directly affects how long until the &quot;flush taking unusually long&quot; message starts popping up.&lt;/p&gt;</comment>
                            <comment id="16519144" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197071117&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197071117&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Would like to request one more slight change here:&lt;br/&gt;
    Let this method return a boolean that indicates whether or not flushing occurred.&lt;/p&gt;

&lt;p&gt;    The caller of this method can then use the flag to decide whether or not `checkAndPropagateAsyncError` is required.&lt;/p&gt;</comment>
                            <comment id="16519145" author="githubbot" created="Thu, 21 Jun 2018 09:40:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197069244&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197069244&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/util/TimeoutLatch.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,41 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kinesis.util;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TimeoutLatch {&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Object lock = new Object();&lt;br/&gt;
    +	private volatile boolean waiting;&lt;br/&gt;
    +&lt;br/&gt;
    +	public void await(long timeout) throws InterruptedException {&lt;br/&gt;
    +		synchronized (lock) &lt;/p&gt;
{
    +			waiting = true;
    +			lock.wait(timeout);
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	public void trigger() {&lt;br/&gt;
    +		if (waiting) {&lt;br/&gt;
    +			synchronized (lock) {&lt;br/&gt;
    +				waiting = false;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I agree with @fmthoma here.&lt;/p&gt;</comment>
                            <comment id="16519376" author="githubbot" created="Thu, 21 Jun 2018 13:42:52 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197137205&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197137205&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -267,6 +268,79 @@ public void go() throws Exception &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer blocks if the queue limit is exceeded,&lt;br/&gt;
    +	 * until the queue length drops below the limit;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 10000)&lt;br/&gt;
    +	public void testBackpressure() throws Throwable {&lt;br/&gt;
    +		final DummyFlinkKinesisProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKinesisProducer&amp;lt;&amp;gt;(new SimpleStringSchema());&lt;br/&gt;
    +		producer.setQueueLimit(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +				new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		UserRecordResult result = mock(UserRecordResult.class);&lt;br/&gt;
    +		when(result.isSuccessful()).thenReturn(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		CheckedThread msg1 = new CheckedThread() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void go() throws Exception &lt;/p&gt;
{
    +				testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));
    +			}
&lt;p&gt;    +		};&lt;br/&gt;
    +		msg1.start();&lt;br/&gt;
    +		msg1.trySync(100);&lt;br/&gt;
    +		assertFalse(&quot;Flush triggered before reaching queue limit&quot;, msg1.isAlive());&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    @tzulitai In principle, yes, if the call `testHarness.processElement(&#8230;)` takes more than 100 milliseconds. However, I believe this is very unlikely even on slow systems, since the operation is mostly (entirely?) CPU bound. If test failures occur nevertheless, it should be no problem to increase the timeout for `msg1` and `msg2`.&lt;/p&gt;</comment>
                            <comment id="16519386" author="githubbot" created="Thu, 21 Jun 2018 13:54:55 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197141591&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197141591&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -55,6 +58,13 @@&lt;br/&gt;
     @PublicEvolving&lt;br/&gt;
     public class FlinkKinesisProducer&amp;lt;OUT&amp;gt; extends RichSinkFunction&amp;lt;OUT&amp;gt; implements CheckpointedFunction {&lt;/p&gt;

&lt;p&gt;    +	public static final String KINESIS_PRODUCER_METRIC_GROUP = &quot;kinesisProducer&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	public static final String METRIC_BACKPRESSURE_CYCLES = &quot;backpressureCycles&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	public static final String METRIC_OUTSTANDING_RECORDS_COUNT = &quot;outstandingRecordsCount&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    &#10004;&lt;/p&gt;</comment>
                            <comment id="16519390" author="githubbot" created="Thu, 21 Jun 2018 13:57:40 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197142648&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197142648&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -144,6 +163,17 @@ public void setFailOnError(boolean failOnError) &lt;/p&gt;
{
     		this.failOnError = failOnError;
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * The &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; holds an unbounded queue internally. To avoid memory&lt;br/&gt;
    +	 * problems under high loads, a limit can be employed above which the internal queue&lt;br/&gt;
    +	 * will be flushed, thereby applying backpressure.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @param queueLimit The maximum length of the internal queue before backpressuring&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	public void setQueueLimit(int queueLimit) {&lt;br/&gt;
    +		this.queueLimit = queueLimit;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    &#10004; (`queueLimit &amp;gt; 0`)&lt;/p&gt;</comment>
                            <comment id="16519395" author="githubbot" created="Thu, 21 Jun 2018 13:59:16 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197143254&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197143254&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    +		int attempt = 0;&lt;br/&gt;
    +		while (producer.getOutstandingRecordsCount() &amp;gt;= queueLimit) {&lt;br/&gt;
    +			backpressureCycles.inc();&lt;br/&gt;
    +			if (attempt &amp;gt;= 10) {&lt;br/&gt;
    +				LOG.warn(&quot;Waiting for the queue length to drop below the limit takes unusually long, still not done after {} attempts.&quot;, attempt);&lt;br/&gt;
    +			}&lt;br/&gt;
    +			attempt++;&lt;br/&gt;
    +			try {&lt;br/&gt;
    +				backpressureLatch.await(100);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It does, but if we make it configurable, I&apos;d rather keep the warning threshold at one second, i.e. `if (attempt &amp;gt;= 1000 / waitTime) &lt;/p&gt;
{ &#8230; }
&lt;p&gt;`.&lt;/p&gt;</comment>
                            <comment id="16519396" author="githubbot" created="Thu, 21 Jun 2018 13:59:24 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197143312&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197143312&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/util/TimeoutLatch.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,41 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kinesis.util;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TimeoutLatch {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    &#10004;&lt;/p&gt;</comment>
                            <comment id="16519397" author="githubbot" created="Thu, 21 Jun 2018 13:59:45 +0000"  >&lt;p&gt;Github user fmthoma commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021#discussion_r197143428&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021#discussion_r197143428&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kinesis/src/main/java/org/apache/flink/streaming/connectors/kinesis/FlinkKinesisProducer.java &amp;#8212;&lt;br/&gt;
    @@ -326,6 +366,29 @@ private void checkAndPropagateAsyncError() throws Exception {&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * If the internal queue of the &lt;/p&gt;
{@link KinesisProducer}
&lt;p&gt; gets too long,&lt;br/&gt;
    +	 * flush some of the records until we are below the limit again.&lt;br/&gt;
    +	 * We don&apos;t want to flush &lt;em&gt;all&lt;/em&gt; records at this point since that would&lt;br/&gt;
    +	 * break record aggregation.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private void enforceQueueLimit() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    &#10004;&lt;/p&gt;</comment>
                            <comment id="16519402" author="githubbot" created="Thu, 21 Jun 2018 14:05:07 +0000"  >&lt;p&gt;Github user fmthoma commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai Thanks for your last review comments! I addressed them, and rebased the branch against master.&lt;/p&gt;</comment>
                            <comment id="16519412" author="githubbot" created="Thu, 21 Jun 2018 14:12:53 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks @fmthoma, will proceed to merge this ..&lt;/p&gt;</comment>
                            <comment id="16520157" author="tzulitai" created="Fri, 22 Jun 2018 09:26:43 +0000"  >&lt;p&gt;Merged&lt;/p&gt;

&lt;p&gt;1.6.0:&#160;7d034d4ef6986ba5ccda6f5e8c587b8fdd88be8e&lt;br/&gt;
1.5.1:&#160;b725982e5758043ba3aa53bde1615569336e451e&lt;/p&gt;

&lt;p&gt;Thanks a lot for the contribution &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fmthoma&quot; class=&quot;user-hover&quot; rel=&quot;fmthoma&quot;&gt;fmthoma&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="16520160" author="githubbot" created="Fri, 22 Jun 2018 09:31:46 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @fmthoma I&apos;ve merged this manually. Thanks for the contribution.&lt;br/&gt;
    Could you close this PR?&lt;/p&gt;</comment>
                            <comment id="16520243" author="githubbot" created="Fri, 22 Jun 2018 10:55:39 +0000"  >&lt;p&gt;Github user fmthoma commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Merged manually by squashing: 7d034d4&lt;/p&gt;</comment>
                            <comment id="16520244" author="githubbot" created="Fri, 22 Jun 2018 10:55:39 +0000"  >&lt;p&gt;Github user fmthoma closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/6021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6021&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12923610" name="after.png" size="22263" author="fmthoma" created="Wed, 16 May 2018 07:47:05 +0000"/>
                            <attachment id="12923611" name="before.png" size="27708" author="fmthoma" created="Wed, 16 May 2018 07:46:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 21 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3trlz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>