<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:35:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10354] Savepoints should be counted as retained checkpoints</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10354</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;This task is about reverting &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The problem is that you can get incorrect results with exactly-once sinks if there is a failure after taking a savepoint but before taking the next checkpoint because the savepoint will also have manifested side effects to the sink.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13185500">FLINK-10354</key>
            <summary>Savepoints should be counted as retained checkpoints</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dwysakowicz">Dawid Wysakowicz</assignee>
                                    <reporter username="dwysakowicz">Dawid Wysakowicz</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 17 Sep 2018 12:35:23 +0000</created>
                <updated>Wed, 21 Nov 2018 16:47:05 +0000</updated>
                            <resolved>Wed, 21 Nov 2018 16:46:56 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>1.5.5</fixVersion>
                    <fixVersion>1.6.2</fixVersion>
                    <fixVersion>1.7.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16617458" author="githubbot" created="Mon, 17 Sep 2018 12:46:06 +0000"  >&lt;p&gt;dawidwys opened a new pull request #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This reverts commit 6f570e7b6810e1645a4f7094f17ab9e8559fa139. &lt;/p&gt;

&lt;p&gt;   Savepoints are once again counted as checkpoint, so that if failure happens between savepoint and next checkpoint, side effects on exactly one sinks manifested during savepoint, are taken into account.&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;The serializers: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (*&lt;b&gt;yes&lt;/b&gt;* / no / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (*&lt;b&gt;not applicable&lt;/b&gt;* / docs / JavaDocs / not documented)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16617542" author="githubbot" created="Mon, 17 Sep 2018 13:47:16 +0000"  >&lt;p&gt;tillrohrmann commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-422023140&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-422023140&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   How do we handle the situation when a savepoint is moved and cannot be recovered from anymore?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16617551" author="githubbot" created="Mon, 17 Sep 2018 13:54:02 +0000"  >&lt;p&gt;dawidwys commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-422025668&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-422025668&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Unfortunately we will fail the recovery in this situation , but as discussed with @aljoscha this is a better situation than breaking consistency guarantees. This would be a faulty situation introduced by the user, but one the user can recover from manually.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16617571" author="githubbot" created="Mon, 17 Sep 2018 14:06:46 +0000"  >&lt;p&gt;dawidwys commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-422030744&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-422030744&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   In the long term, the plan is to differentiate between two kinds of savepoints: with(cancel-with-savepoint) and without side-effects (without cancel). The latter would be equivalent to last taken checkpoint, while the first one would stop the job creating a consistent savepoint.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16620299" author="githubbot" created="Wed, 19 Sep 2018 08:42:49 +0000"  >&lt;p&gt;tzulitai commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-422712305&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-422712305&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   The reverted changes looks good by itself, but I personally don&apos;t feel too comfortable giving a +1 here. Perhaps Till should give the final approval here.&lt;/p&gt;

&lt;p&gt;   If we do plan to revert this, we should at least have a big warning in the savepoints document page about how things could break.&lt;/p&gt;

&lt;p&gt;   Also as a side note, in the original JIRA discussion, it was mentioned that if we had &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; title=&quot;Automatic fallback to earlier checkpoints when checkpoint restore fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4815&quot;&gt;FLINK-4815&lt;/a&gt; merged, then it can be considered that we readd savepoints to the CompletedCheckpointsStore. How would that relate to the long-term solution that @dawidwys mentioned?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16623403" author="till.rohrmann" created="Fri, 21 Sep 2018 10:47:10 +0000"  >&lt;p&gt;This looks like a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9983&quot; title=&quot;Savepoints should count as checkpoints when recovering&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-9983&quot;&gt;&lt;del&gt;FLINK-9983&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="16623465" author="dawidwys" created="Fri, 21 Sep 2018 11:58:23 +0000"  >&lt;p&gt;You&apos;re right, haven&apos;t seen the other one. Will close the other one as this have PR opened already.&lt;/p&gt;</comment>
                            <comment id="16625871" author="githubbot" created="Mon, 24 Sep 2018 14:12:53 +0000"  >&lt;p&gt;aljoscha commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-423989035&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-423989035&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   How simple was the revert? I.e. is it just a `git revert` or what did you need to adapt?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16625875" author="githubbot" created="Mon, 24 Sep 2018 14:13:48 +0000"  >&lt;p&gt;dawidwys commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-423989342&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-423989342&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Yes, it was just a revert, I did not need to adapt anything.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16625914" author="githubbot" created="Mon, 24 Sep 2018 14:40:58 +0000"  >&lt;p&gt;aljoscha commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-423998830&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-423998830&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   I think falling back to earlier checkpoints/savepoints is orthogonal to this and covered in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-4815&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;   As it is currently, you can have the (quite possible) scenario where you do a savepoint and then your job fails. This leads to data duplication in the sink.&lt;/p&gt;

&lt;p&gt;   I think the scenario where you do a savepoint, then delete that savepoint, and then try to recover is unlikely. And even if it does happen you can manually fix the situation by editing ZooKeeper entries (I think). There is no possible manual recovery for the above scenario (downstream systems possible have already consumed the emitted and committed data).&lt;/p&gt;

&lt;p&gt;   What do you think?&lt;/p&gt;

&lt;p&gt;   @tillrohrmann Is this &quot;revert&quot; still valid or where there changes in the meantime that could break things?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16635651" author="githubbot" created="Tue, 2 Oct 2018 15:04:24 +0000"  >&lt;p&gt;aljoscha commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-426308841&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-426308841&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @dawidwys I looked at the code again and I think it&apos;s good to merge. It&apos;s a serious bug when it comes to exactly-once sinks.&lt;/p&gt;

&lt;p&gt;   Could you please also check and merge it on 1.5.x and 1.6.x so that we release the fix when we release new versions of these branches?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16636942" author="githubbot" created="Wed, 3 Oct 2018 13:24:01 +0000"  >&lt;p&gt;tillrohrmann commented on issue #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704#issuecomment-426635766&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704#issuecomment-426635766&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   @aljoscha I&apos;m not aware of any changes in the meantime which could break things. I think this is the task of the reviewer to guarantee that this is not the case.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16638099" author="githubbot" created="Thu, 4 Oct 2018 11:35:30 +0000"  >&lt;p&gt;dawidwys closed pull request #6704: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; Revert &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;chkPts&amp;#93;&lt;/span&gt; Don&apos;t add savepoints to CompletedCheckpointStore&quot;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6704&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/docs/ops/state/savepoints.md b/docs/ops/state/savepoints.md&lt;br/&gt;
index 6dd5154c5e6..d31063ee2c5 100644&lt;br/&gt;
&amp;#8212; a/docs/ops/state/savepoints.md&lt;br/&gt;
+++ b/docs/ops/state/savepoints.md&lt;br/&gt;
@@ -106,6 +106,11 @@ Please follow &amp;lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5778&quot;&amp;gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5&quot; title=&quot;[GitHub] Configurable Iteration Aggregators&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5&quot;&gt;&lt;del&gt;FLINK-5&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; Note that if you use the `MemoryStateBackend`, metadata &lt;b&gt;and&lt;/b&gt; savepoint state will be stored in the `_metadata` file. Since it is self-contained, you may move the file and restore from any location.&lt;/p&gt;

&lt;p&gt;+&amp;lt;div class=&quot;alert alert-warning&quot;&amp;gt;&lt;br/&gt;
+  &amp;lt;strong&amp;gt;Attention:&amp;lt;/strong&amp;gt; It is discouraged to move or delete last savepoint of a running job, cause this might interfere with failure-recovery. Savepoints have side-effects on exactly-once sinks, therefore &lt;br/&gt;
+  to ensure exactly-once semantics, if there is no checkpoint after the last savepoint, the savepoint will be used for recovery. &lt;br/&gt;
+&amp;lt;/div&amp;gt;&lt;br/&gt;
+&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;
			&lt;ol&gt;
				&lt;li&gt;Trigger a Savepoint&lt;/li&gt;
			&lt;/ol&gt;
			&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


 {% highlight shell %}
&lt;p&gt;diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
index e936b246222..57337b6286f 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
@@ -839,28 +839,22 @@ private void completePendingCheckpoint(PendingCheckpoint pendingCheckpoint) thro&lt;br/&gt;
 			// the pending checkpoint must be discarded after the finalization&lt;br/&gt;
 			Preconditions.checkState(pendingCheckpoint.isDiscarded() &amp;amp;&amp;amp; completedCheckpoint != null);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// TODO: add savepoints to completed checkpoint store once &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; title=&quot;Automatic fallback to earlier checkpoints when checkpoint restore fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4815&quot;&gt;FLINK-4815&lt;/a&gt; has been completed&lt;/li&gt;
	&lt;li&gt;if (!completedCheckpoint.getProperties().isSavepoint()) {&lt;/li&gt;
	&lt;li&gt;try 
{
-					completedCheckpointStore.addCheckpoint(completedCheckpoint);
-				}
&lt;p&gt; catch (Exception exception) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// we failed to store the completed checkpoint. Let&apos;s clean up&lt;/li&gt;
	&lt;li&gt;executor.execute(new Runnable() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void run() {&lt;/li&gt;
	&lt;li&gt;try 
{
-								completedCheckpoint.discardOnFailedStoring();
-							}
&lt;p&gt; catch (Throwable t) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not properly discard completed checkpoint {} of job {}.&quot;, completedCheckpoint.getCheckpointID(), job, t);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
+			try 
{
+				completedCheckpointStore.addCheckpoint(completedCheckpoint);
+			}
&lt;p&gt; catch (Exception exception) {&lt;br/&gt;
+				// we failed to store the completed checkpoint. Let&apos;s clean up&lt;br/&gt;
+				executor.execute(new Runnable() {&lt;br/&gt;
+					@Override&lt;br/&gt;
+					public void run() {&lt;br/&gt;
+						try &lt;/p&gt;
{
+							completedCheckpoint.discardOnFailedStoring();
+						}
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
+							LOG.warn(&quot;Could not properly discard completed checkpoint {}.&quot;, completedCheckpoint.getCheckpointID(), t);&lt;br/&gt;
 						}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;});&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;throw new CheckpointException(&quot;Could not complete the pending checkpoint &quot; + checkpointId + &apos;.&apos;, exception);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
+					}&lt;br/&gt;
+				});&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// drop those pending checkpoints that are at prior to the completed one&lt;/li&gt;
	&lt;li&gt;dropSubsumedCheckpoints(checkpointId);&lt;br/&gt;
+				throw new CheckpointException(&quot;Could not complete the pending checkpoint &quot; + checkpointId + &apos;.&apos;, exception);&lt;br/&gt;
 			}&lt;br/&gt;
 		} finally {&lt;br/&gt;
 			pendingCheckpoints.remove(checkpointId);&lt;br/&gt;
@@ -870,6 +864,9 @@ public void run() {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		rememberRecentCheckpointId(checkpointId);&lt;/p&gt;

&lt;p&gt;+		// drop those pending checkpoints that are at prior to the completed one&lt;br/&gt;
+		dropSubsumedCheckpoints(checkpointId);&lt;br/&gt;
+&lt;br/&gt;
 		// record the time when this was completed, to calculate&lt;br/&gt;
 		// the &apos;min delay between checkpoints&apos;&lt;br/&gt;
 		lastCheckpointCompletionNanos = System.nanoTime();&lt;br/&gt;
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
index b113e12ef69..3650f43066d 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
@@ -1494,8 +1494,8 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;br/&gt;
 		assertTrue(pending.isDiscarded());&lt;br/&gt;
 		assertTrue(savepointFuture.isDone());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the now the savepoint should be completed but not added to the completed checkpoint store&lt;/li&gt;
	&lt;li&gt;assertEquals(0, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		// the now we should have a completed checkpoint&lt;br/&gt;
+		assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
 		assertEquals(0, coord.getNumberOfPendingCheckpoints());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		// validate that the relevant tasks got a confirmation message&lt;br/&gt;
@@ -1510,7 +1510,7 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception &lt;/p&gt;
{
 			verify(subtaskState2, times(1)).registerSharedStates(any(SharedStateRegistry.class));
 		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CompletedCheckpoint success = savepointFuture.get();&lt;br/&gt;
+		CompletedCheckpoint success = coord.getSuccessfulCheckpoints().get(0);&lt;br/&gt;
 		assertEquals(jid, success.getJobId());&lt;br/&gt;
 		assertEquals(timestamp, success.getTimestamp());&lt;br/&gt;
 		assertEquals(pending.getCheckpointId(), success.getCheckpointID());&lt;br/&gt;
@@ -1528,9 +1528,9 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, checkpointIdNew));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertEquals(0, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(0, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CompletedCheckpoint successNew = savepointFuture.get();&lt;br/&gt;
+		CompletedCheckpoint successNew = coord.getSuccessfulCheckpoints().get(0);&lt;br/&gt;
 		assertEquals(jid, successNew.getJobId());&lt;br/&gt;
 		assertEquals(timestampNew, successNew.getTimestamp());&lt;br/&gt;
 		assertEquals(checkpointIdNew, successNew.getCheckpointID());&lt;br/&gt;
@@ -1557,7 +1557,7 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Triggers a savepoint and two checkpoints. The second checkpoint completes&lt;/li&gt;
	&lt;li&gt;and subsumes the first checkpoint, but not the first savepoint. Then we&lt;/li&gt;
	&lt;li&gt;trigger another checkpoint and savepoint. The 2nd savepoint completes and&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* does neither subsume the last checkpoint nor the first savepoint.&lt;br/&gt;
+	 * subsumes the last checkpoint, but not the first savepoint.&lt;br/&gt;
 	 */&lt;br/&gt;
 	@Test&lt;br/&gt;
 	public void testSavepointsAreNotSubsumed() throws Exception {&lt;br/&gt;
@@ -1614,19 +1614,18 @@ public void testSavepointsAreNotSubsumed() throws Exception {&lt;br/&gt;
 		assertFalse(savepointFuture1.isDone());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertTrue(coord.triggerCheckpoint(timestamp + 3, false));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;long checkpointId3 = counter.getLast();&lt;br/&gt;
 		assertEquals(2, coord.getNumberOfPendingCheckpoints());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		CompletableFuture&amp;lt;CompletedCheckpoint&amp;gt; savepointFuture2 = coord.triggerSavepoint(timestamp + 4, savepointDir);&lt;br/&gt;
 		long savepointId2 = counter.getLast();&lt;br/&gt;
 		assertEquals(3, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// 2nd savepoint should not subsume the last checkpoint and the 1st savepoint&lt;br/&gt;
+		// 2nd savepoint should subsume the last checkpoint, but not the 1st savepoint&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, savepointId2));&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, savepointId2));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(2, coord.getNumberOfPendingCheckpoints());&lt;/li&gt;
	&lt;li&gt;assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		assertEquals(1, coord.getNumberOfPendingCheckpoints());&lt;br/&gt;
+		assertEquals(2, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
 		assertFalse(coord.getPendingCheckpoints().get(savepointId1).isDiscarded());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertFalse(savepointFuture1.isDone());&lt;br/&gt;
@@ -1636,15 +1635,9 @@ public void testSavepointsAreNotSubsumed() throws Exception &lt;/p&gt;
{
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, savepointId1));
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, savepointId1));
 
-		assertEquals(1, coord.getNumberOfPendingCheckpoints());
-		assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());
-		assertTrue(savepointFuture1.isDone());
-
-		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, checkpointId3));
-		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, checkpointId3));
-
 		assertEquals(0, coord.getNumberOfPendingCheckpoints());
-		assertEquals(2, coord.getNumberOfRetainedSuccessfulCheckpoints());
+		assertEquals(3, coord.getNumberOfRetainedSuccessfulCheckpoints());
+		assertTrue(savepointFuture1.isDone());
 	}

&lt;p&gt; 	private void testMaxConcurrentAttempts(int maxConcurrentAttempts) {&lt;br/&gt;
@@ -3467,92 +3460,6 @@ public void testCheckpointStatsTrackerRestoreCallback() throws Exception &lt;/p&gt;
{
 			.reportRestoredCheckpoint(any(RestoredCheckpointStats.class));
 	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Tests that savepoints are not added to the 
{@link CompletedCheckpointStore}
&lt;p&gt; and,&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* thus, are not subject to job recovery. The reason that we don&apos;t want that (until&lt;/li&gt;
	&lt;li&gt;* &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; title=&quot;Automatic fallback to earlier checkpoints when checkpoint restore fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4815&quot;&gt;FLINK-4815&lt;/a&gt; has been finished) is that the lifecycle of savepoints is not controlled&lt;/li&gt;
	&lt;li&gt;* by the 
{@link CheckpointCoordinator}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void testSavepointsAreNotAddedToCompletedCheckpointStore() throws Exception {&lt;/li&gt;
	&lt;li&gt;final JobID jobId = new JobID();&lt;/li&gt;
	&lt;li&gt;final ExecutionAttemptID executionAttemptId = new ExecutionAttemptID();&lt;/li&gt;
	&lt;li&gt;final ExecutionVertex vertex1 = mockExecutionVertex(executionAttemptId);&lt;/li&gt;
	&lt;li&gt;final CompletedCheckpointStore completedCheckpointStore = new StandaloneCompletedCheckpointStore(1);&lt;/li&gt;
	&lt;li&gt;final long checkpointTimestamp1 = 1L;&lt;/li&gt;
	&lt;li&gt;final long savepointTimestamp = 2L;&lt;/li&gt;
	&lt;li&gt;final long checkpointTimestamp2 = 3L;&lt;/li&gt;
	&lt;li&gt;final String savepointDir = tmpFolder.newFolder().getAbsolutePath();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;final StandaloneCheckpointIDCounter checkpointIDCounter = new StandaloneCheckpointIDCounter();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;CheckpointCoordinator checkpointCoordinator = new CheckpointCoordinator(&lt;/li&gt;
	&lt;li&gt;jobId,&lt;/li&gt;
	&lt;li&gt;600000L,&lt;/li&gt;
	&lt;li&gt;600000L,&lt;/li&gt;
	&lt;li&gt;0L,&lt;/li&gt;
	&lt;li&gt;Integer.MAX_VALUE,&lt;/li&gt;
	&lt;li&gt;CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION,&lt;/li&gt;
	&lt;li&gt;new ExecutionVertex[]
{vertex1},&lt;br/&gt;
-			new ExecutionVertex[]{vertex1}
&lt;p&gt;,&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;new ExecutionVertex[]
{vertex1}
&lt;p&gt;,&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;checkpointIDCounter,&lt;/li&gt;
	&lt;li&gt;completedCheckpointStore,&lt;/li&gt;
	&lt;li&gt;new MemoryStateBackend(),&lt;/li&gt;
	&lt;li&gt;Executors.directExecutor(),&lt;/li&gt;
	&lt;li&gt;SharedStateRegistry.DEFAULT_FACTORY);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// trigger a first checkpoint&lt;/li&gt;
	&lt;li&gt;assertTrue(&lt;/li&gt;
	&lt;li&gt;&quot;Triggering of a checkpoint should work.&quot;,&lt;/li&gt;
	&lt;li&gt;checkpointCoordinator.triggerCheckpoint(checkpointTimestamp1, false));&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;assertTrue(0 == completedCheckpointStore.getNumberOfRetainedCheckpoints());&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// complete the 1st checkpoint&lt;/li&gt;
	&lt;li&gt;checkpointCoordinator.receiveAcknowledgeMessage(&lt;/li&gt;
	&lt;li&gt;new AcknowledgeCheckpoint(&lt;/li&gt;
	&lt;li&gt;jobId,&lt;/li&gt;
	&lt;li&gt;executionAttemptId,&lt;/li&gt;
	&lt;li&gt;checkpointIDCounter.getLast()));&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// check that the checkpoint has been completed&lt;/li&gt;
	&lt;li&gt;assertTrue(1 == completedCheckpointStore.getNumberOfRetainedCheckpoints());&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// trigger a savepoint --&amp;gt; this should not have any effect on the CompletedCheckpointStore&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;CompletedCheckpoint&amp;gt; savepointFuture = checkpointCoordinator.triggerSavepoint(savepointTimestamp, savepointDir);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;checkpointCoordinator.receiveAcknowledgeMessage(&lt;/li&gt;
	&lt;li&gt;new AcknowledgeCheckpoint(&lt;/li&gt;
	&lt;li&gt;jobId,&lt;/li&gt;
	&lt;li&gt;executionAttemptId,&lt;/li&gt;
	&lt;li&gt;checkpointIDCounter.getLast()));&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// check that no errors occurred&lt;/li&gt;
	&lt;li&gt;final CompletedCheckpoint savepoint = savepointFuture.get();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;assertFalse(&lt;/li&gt;
	&lt;li&gt;&quot;The savepoint should not have been added to the completed checkpoint store&quot;,&lt;/li&gt;
	&lt;li&gt;savepoint.getCheckpointID() == completedCheckpointStore.getLatestCheckpoint().getCheckpointID());&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;assertTrue(&lt;/li&gt;
	&lt;li&gt;&quot;Triggering of a checkpoint should work.&quot;,&lt;/li&gt;
	&lt;li&gt;checkpointCoordinator.triggerCheckpoint(checkpointTimestamp2, false));&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// complete the 2nd checkpoint&lt;/li&gt;
	&lt;li&gt;checkpointCoordinator.receiveAcknowledgeMessage(&lt;/li&gt;
	&lt;li&gt;new AcknowledgeCheckpoint(&lt;/li&gt;
	&lt;li&gt;jobId,&lt;/li&gt;
	&lt;li&gt;executionAttemptId,&lt;/li&gt;
	&lt;li&gt;checkpointIDCounter.getLast()));&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;assertTrue(&lt;/li&gt;
	&lt;li&gt;&quot;The latest completed (proper) checkpoint should have been added to the completed checkpoint store.&quot;,&lt;/li&gt;
	&lt;li&gt;completedCheckpointStore.getLatestCheckpoint().getCheckpointID() == checkpointIDCounter.getLast());&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
 	@Test&lt;br/&gt;
 	public void testSharedStateRegistrationOnRestore() throws Exception {&lt;/li&gt;
&lt;/ul&gt;






&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16638162" author="dawidwys" created="Thu, 4 Oct 2018 12:36:25 +0000"  >&lt;p&gt;Fixed in master: 93c87ea58e7f8bcf530be5a1bf7fa89a1e976f07&lt;br/&gt;
Fixed in 1.6.2: 6f8b43f9cfb962820d07778feff7bb0689c9fdf1&lt;br/&gt;
Fixed in 1.5.5: 972ab83b23440a8134acd5f211e286552321a25e&lt;/p&gt;</comment>
                            <comment id="16651633" author="githubbot" created="Tue, 16 Oct 2018 12:59:38 +0000"  >&lt;p&gt;tillrohrmann opened a new pull request #6858: Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10247&quot; title=&quot;Run MetricQueryService in separate thread pool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10247&quot;&gt;&lt;del&gt;FLINK-10247&lt;/del&gt;&lt;/a&gt; for release-1.5&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6858&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6858&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10247&quot; title=&quot;Run MetricQueryService in separate thread pool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10247&quot;&gt;&lt;del&gt;FLINK-10247&lt;/del&gt;&lt;/a&gt; for `release-1.5`&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16651637" author="githubbot" created="Tue, 16 Oct 2018 13:00:45 +0000"  >&lt;p&gt;tillrohrmann opened a new pull request #6859: Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10247&quot; title=&quot;Run MetricQueryService in separate thread pool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10247&quot;&gt;&lt;del&gt;FLINK-10247&lt;/del&gt;&lt;/a&gt; for release-1.6&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6859&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6859&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10247&quot; title=&quot;Run MetricQueryService in separate thread pool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10247&quot;&gt;&lt;del&gt;FLINK-10247&lt;/del&gt;&lt;/a&gt; for `release-1.6`.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16652462" author="githubbot" created="Tue, 16 Oct 2018 21:21:26 +0000"  >&lt;p&gt;asfgit closed pull request #6859: Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10247&quot; title=&quot;Run MetricQueryService in separate thread pool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10247&quot;&gt;&lt;del&gt;FLINK-10247&lt;/del&gt;&lt;/a&gt; for release-1.6&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6859&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6859&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/docs/_includes/generated/metric_configuration.html b/docs/_includes/generated/metric_configuration.html&lt;br/&gt;
index 5f52abd38ed..0fe9d0c36f8 100644&lt;br/&gt;
&amp;#8212; a/docs/_includes/generated/metric_configuration.html&lt;br/&gt;
+++ b/docs/_includes/generated/metric_configuration.html&lt;br/&gt;
@@ -7,11 +7,6 @@&lt;br/&gt;
         &amp;lt;/tr&amp;gt;&lt;br/&gt;
     &amp;lt;/thead&amp;gt;&lt;br/&gt;
     &amp;lt;tbody&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;tr&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;td&amp;gt;&amp;lt;h5&amp;gt;metrics.internal.query-service.port&amp;lt;/h5&amp;gt;&amp;lt;/td&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;td style=&quot;word-wrap: break-word;&quot;&amp;gt;&quot;0&quot;&amp;lt;/td&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;td&amp;gt;The port range used for Flink&apos;s internal metric query service. Accepts a list of ports (&#8220;50100,50101&#8221;), ranges(&#8220;50100-50200&#8221;) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Flink components are running on the same machine. Per default Flink will pick a random port.&amp;lt;/td&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/tr&amp;gt;&lt;br/&gt;
         &amp;lt;tr&amp;gt;&lt;br/&gt;
             &amp;lt;td&amp;gt;&amp;lt;h5&amp;gt;metrics.latency.granularity&amp;lt;/h5&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
             &amp;lt;td style=&quot;word-wrap: break-word;&quot;&amp;gt;&quot;subtask&quot;&amp;lt;/td&amp;gt;&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java b/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java&lt;br/&gt;
index e76b7f2dbbe..fc6b3c14c46 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java&lt;br/&gt;
+++ b/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java&lt;br/&gt;
@@ -130,18 +130,6 @@&lt;br/&gt;
 			.defaultValue(128)&lt;br/&gt;
 			.withDescription(&quot;Defines the number of measured latencies to maintain at each operator.&quot;);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* The default network port range for Flink&apos;s internal metric query service. The 
{@code &quot;0&quot;}
&lt;p&gt; means that&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* Flink searches for a free port.&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static final ConfigOption&amp;lt;String&amp;gt; QUERY_SERVICE_PORT =&lt;/li&gt;
	&lt;li&gt;key(&quot;metrics.internal.query-service.port&quot;)&lt;/li&gt;
	&lt;li&gt;.defaultValue(&quot;0&quot;)&lt;/li&gt;
	&lt;li&gt;.withDescription(&quot;The port range used for Flink&apos;s internal metric query service. Accepts a list of ports &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;(&#8220;50100,50101&#8221;), ranges(&#8220;50100-50200&#8221;) or a combination of both. It is recommended to set a range of &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;ports to avoid collisions when multiple Flink components are running on the same machine. Per default &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;Flink will pick a random port.&quot;);&lt;br/&gt;
-&lt;br/&gt;
 	private MetricOptions() {&lt;br/&gt;
 	}&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/types/SerializableOptional.java b/flink-core/src/main/java/org/apache/flink/types/SerializableOptional.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 89dcea45093..00000000000
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-core/src/main/java/org/apache/flink/types/SerializableOptional.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,86 +0,0 @@&lt;br/&gt;
-/*&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one&lt;/li&gt;
	&lt;li&gt;* or more contributor license agreements.  See the NOTICE file&lt;/li&gt;
	&lt;li&gt;* distributed with this work for additional information&lt;/li&gt;
	&lt;li&gt;* regarding copyright ownership.  The ASF licenses this file&lt;/li&gt;
	&lt;li&gt;* to you under the Apache License, Version 2.0 (the&lt;/li&gt;
	&lt;li&gt;* &quot;License&quot;); you may not use this file except in compliance&lt;/li&gt;
	&lt;li&gt;* with the License.  You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;*     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-&lt;br/&gt;
-package org.apache.flink.types;&lt;br/&gt;
-&lt;br/&gt;
-import javax.annotation.Nonnull;&lt;br/&gt;
-import javax.annotation.Nullable;&lt;br/&gt;
-&lt;br/&gt;
-import java.io.Serializable;&lt;br/&gt;
-import java.util.NoSuchElementException;&lt;br/&gt;
-import java.util.Optional;&lt;br/&gt;
-import java.util.function.Consumer;&lt;br/&gt;
-import java.util.function.Function;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;/li&gt;
	&lt;li&gt;* Serializable 
{@link Optional}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-public final class SerializableOptional&amp;lt;T extends Serializable&amp;gt; implements Serializable {&lt;/li&gt;
	&lt;li&gt;private static final long serialVersionUID = -3312769593551775940L;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static final SerializableOptional&amp;lt;?&amp;gt; EMPTY = new SerializableOptional&amp;lt;&amp;gt;(null);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@Nullable&lt;/li&gt;
	&lt;li&gt;private final T value;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private SerializableOptional(@Nullable T value) 
{
-		this.value = value;
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public T get() {&lt;/li&gt;
	&lt;li&gt;if (value == null) 
{
-			throw new NoSuchElementException(&quot;No value present&quot;);
-		}&lt;/li&gt;
	&lt;li&gt;return value;&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public boolean isPresent() 
{
-		return value != null;
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public void ifPresent(Consumer&amp;lt;? super T&amp;gt; consumer) {&lt;/li&gt;
	&lt;li&gt;if (value != null) 
{
-			consumer.accept(value);
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public &amp;lt;R&amp;gt; Optional&amp;lt;R&amp;gt; map(Function&amp;lt;? super T, ? extends R&amp;gt; mapper) {&lt;/li&gt;
	&lt;li&gt;if (value == null) 
{
-			return Optional.empty();
-		}
&lt;p&gt; else &lt;/p&gt;
{
-			return Optional.ofNullable(mapper.apply(value));
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;T extends Serializable&amp;gt; SerializableOptional&amp;lt;T&amp;gt; of(@Nonnull T value) 
{
-		return new SerializableOptional&amp;lt;&amp;gt;(value);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;T extends Serializable&amp;gt; SerializableOptional&amp;lt;T&amp;gt; ofNullable(@Nullable T value) {&lt;/li&gt;
	&lt;li&gt;if (value == null) 
{
-			return empty();
-		}
&lt;p&gt; else &lt;/p&gt;
{
-			return of(value);
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;T extends Serializable&amp;gt; SerializableOptional&amp;lt;T&amp;gt; empty() 
{
-		return (SerializableOptional&amp;lt;T&amp;gt;) EMPTY;
-	}
&lt;p&gt;-}&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
index 57337b6286f..e936b246222 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
@@ -839,22 +839,28 @@ private void completePendingCheckpoint(PendingCheckpoint pendingCheckpoint) thro&lt;br/&gt;
 			// the pending checkpoint must be discarded after the finalization&lt;br/&gt;
 			Preconditions.checkState(pendingCheckpoint.isDiscarded() &amp;amp;&amp;amp; completedCheckpoint != null);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
-				completedCheckpointStore.addCheckpoint(completedCheckpoint);
-			}
&lt;p&gt; catch (Exception exception) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// we failed to store the completed checkpoint. Let&apos;s clean up&lt;/li&gt;
	&lt;li&gt;executor.execute(new Runnable() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void run() {&lt;/li&gt;
	&lt;li&gt;try 
{
-							completedCheckpoint.discardOnFailedStoring();
-						}
&lt;p&gt; catch (Throwable t) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not properly discard completed checkpoint {}.&quot;, completedCheckpoint.getCheckpointID(), t);&lt;br/&gt;
+			// TODO: add savepoints to completed checkpoint store once &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; title=&quot;Automatic fallback to earlier checkpoints when checkpoint restore fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4815&quot;&gt;FLINK-4815&lt;/a&gt; has been completed&lt;br/&gt;
+			if (!completedCheckpoint.getProperties().isSavepoint()) {&lt;br/&gt;
+				try 
{
+					completedCheckpointStore.addCheckpoint(completedCheckpoint);
+				}
&lt;p&gt; catch (Exception exception) {&lt;br/&gt;
+					// we failed to store the completed checkpoint. Let&apos;s clean up&lt;br/&gt;
+					executor.execute(new Runnable() {&lt;br/&gt;
+						@Override&lt;br/&gt;
+						public void run() {&lt;br/&gt;
+							try &lt;/p&gt;
{
+								completedCheckpoint.discardOnFailedStoring();
+							}
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
+								LOG.warn(&quot;Could not properly discard completed checkpoint {} of job {}.&quot;, completedCheckpoint.getCheckpointID(), job, t);&lt;br/&gt;
+							}&lt;br/&gt;
 						}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;});&lt;br/&gt;
+					});&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;throw new CheckpointException(&quot;Could not complete the pending checkpoint &quot; + checkpointId + &apos;.&apos;, exception);&lt;br/&gt;
+					throw new CheckpointException(&quot;Could not complete the pending checkpoint &quot; + checkpointId + &apos;.&apos;, exception);&lt;br/&gt;
+				}&lt;br/&gt;
+&lt;br/&gt;
+				// drop those pending checkpoints that are at prior to the completed one&lt;br/&gt;
+				dropSubsumedCheckpoints(checkpointId);&lt;br/&gt;
 			}&lt;br/&gt;
 		} finally {&lt;br/&gt;
 			pendingCheckpoints.remove(checkpointId);&lt;br/&gt;
@@ -864,9 +870,6 @@ public void run() {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		rememberRecentCheckpointId(checkpointId);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// drop those pending checkpoints that are at prior to the completed one&lt;/li&gt;
	&lt;li&gt;dropSubsumedCheckpoints(checkpointId);&lt;br/&gt;
-&lt;br/&gt;
 		// record the time when this was completed, to calculate&lt;br/&gt;
 		// the &apos;min delay between checkpoints&apos;&lt;br/&gt;
 		lastCheckpointCompletionNanos = System.nanoTime();&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java b/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java&lt;br/&gt;
index 00b61737d20..56e45762263 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java&lt;br/&gt;
@@ -46,7 +46,6 @@&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import javax.annotation.Nonnull;&lt;br/&gt;
 import javax.annotation.Nullable;&lt;/p&gt;

&lt;p&gt; import java.io.File;&lt;br/&gt;
@@ -86,66 +85,13 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@param portRangeDefinition The port range to choose a port from.&lt;/li&gt;
	&lt;li&gt;@param logger The logger to output log information.&lt;/li&gt;
	&lt;li&gt;@return The ActorSystem which has been started&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @throws Exception Thrown when actor system cannot be started in specified port range&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static ActorSystem startActorSystem(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String listeningAddress,&lt;/li&gt;
	&lt;li&gt;String portRangeDefinition,&lt;/li&gt;
	&lt;li&gt;Logger logger) throws Exception 
{
-		return startActorSystem(
-			configuration,
-			listeningAddress,
-			portRangeDefinition,
-			logger,
-			ActorSystemExecutorMode.FORK_JOIN_EXECUTOR);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Starts an ActorSystem with the given configuration listening at the address/ports.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration The Flink configuration&lt;/li&gt;
	&lt;li&gt;* @param listeningAddress The address to listen at.&lt;/li&gt;
	&lt;li&gt;* @param portRangeDefinition The port range to choose a port from.&lt;/li&gt;
	&lt;li&gt;* @param logger The logger to output log information.&lt;/li&gt;
	&lt;li&gt;* @param executorMode The executor mode of Akka actor system.&lt;/li&gt;
	&lt;li&gt;* @return The ActorSystem which has been started&lt;/li&gt;
	&lt;li&gt;* @throws Exception Thrown when actor system cannot be started in specified port range&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static ActorSystem startActorSystem(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String listeningAddress,&lt;/li&gt;
	&lt;li&gt;String portRangeDefinition,&lt;/li&gt;
	&lt;li&gt;Logger logger,&lt;/li&gt;
	&lt;li&gt;@Nonnull ActorSystemExecutorMode executorMode) throws Exception 
{
-		return startActorSystem(
-			configuration,
-			AkkaUtils.getFlinkActorSystemName(),
-			listeningAddress,
-			portRangeDefinition,
-			logger,
-			executorMode);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Starts an ActorSystem with the given configuration listening at the address/ports.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration The Flink configuration&lt;/li&gt;
	&lt;li&gt;* @param actorSystemName Name of the started 
{@link ActorSystem}&lt;br/&gt;
-	 * @param listeningAddress The address to listen at.&lt;br/&gt;
-	 * @param portRangeDefinition The port range to choose a port from.&lt;br/&gt;
-	 * @param logger The logger to output log information.&lt;br/&gt;
-	 * @param executorMode The executor mode of Akka actor system.&lt;br/&gt;
-	 * @return The ActorSystem which has been started&lt;br/&gt;
-	 * @throws Exception Thrown when actor system cannot be started in specified port range&lt;br/&gt;
+	 * @throws Exception&lt;br/&gt;
 	 */&lt;br/&gt;
 	public static ActorSystem startActorSystem(&lt;br/&gt;
 			Configuration configuration,&lt;br/&gt;
-			String actorSystemName,&lt;br/&gt;
 			String listeningAddress,&lt;br/&gt;
 			String portRangeDefinition,&lt;br/&gt;
-			Logger logger,&lt;br/&gt;
-			@Nonnull ActorSystemExecutorMode executorMode) throws Exception {&lt;br/&gt;
+			Logger logger) throws Exception {
 
 		// parse port range definition and create port iterator
 		Iterator&amp;lt;Integer&amp;gt; portsIterator;
@@ -171,13 +117,7 @@ public static ActorSystem startActorSystem(
 			}&lt;br/&gt;
 &lt;br/&gt;
 			try {
-				return startActorSystem(
-					configuration,
-					actorSystemName,
-					listeningAddress,
-					port,
-					logger,
-					executorMode);
+				return startActorSystem(configuration, listeningAddress, port, logger);
 			}&lt;br/&gt;
 			catch (Exception e) {&lt;br/&gt;
 				// we can continue to try if this contains a netty channel exception&lt;br/&gt;
@@ -196,7 +136,6 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 &lt;br/&gt;
 	/**&lt;br/&gt;
 	 * Starts an Actor System at a specific port.&lt;br/&gt;
-	 *&lt;br/&gt;
 	 * @param configuration The Flink configuration.&lt;br/&gt;
 	 * @param listeningAddress The address to listen at.&lt;br/&gt;
 	 * @param listeningPort The port to listen at.&lt;br/&gt;
@@ -204,57 +143,11 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 	 * @return The ActorSystem which has been started.&lt;br/&gt;
 	 * @throws Exception&lt;br/&gt;
 	 */&lt;br/&gt;
-	public static ActorSystem startActorSystem(&lt;br/&gt;
-		Configuration configuration,&lt;br/&gt;
-		String listeningAddress,&lt;br/&gt;
-		int listeningPort,&lt;br/&gt;
-		Logger logger) throws Exception {
-		return startActorSystem(configuration, listeningAddress, listeningPort, logger, ActorSystemExecutorMode.FORK_JOIN_EXECUTOR);
-	}&lt;br/&gt;
-&lt;br/&gt;
-	/**&lt;br/&gt;
-	 * Starts an Actor System at a specific port.&lt;br/&gt;
-	 * @param configuration The Flink configuration.&lt;br/&gt;
-	 * @param listeningAddress The address to listen at.&lt;br/&gt;
-	 * @param listeningPort The port to listen at.&lt;br/&gt;
-	 * @param logger the logger to output log information.&lt;br/&gt;
-	 * @param executorMode The executor mode of Akka actor system.&lt;br/&gt;
-	 * @return The ActorSystem which has been started.&lt;br/&gt;
-	 * @throws Exception&lt;br/&gt;
-	 */&lt;br/&gt;
 	public static ActorSystem startActorSystem(&lt;br/&gt;
 				Configuration configuration,&lt;br/&gt;
 				String listeningAddress,&lt;br/&gt;
 				int listeningPort,&lt;br/&gt;
-				Logger logger,&lt;br/&gt;
-				ActorSystemExecutorMode executorMode) throws Exception {
-		return startActorSystem(
-			configuration,
-			AkkaUtils.getFlinkActorSystemName(),
-			listeningAddress,
-			listeningPort,
-			logger,
-			executorMode);
-	}&lt;br/&gt;
-&lt;br/&gt;
-	/**&lt;br/&gt;
-	 * Starts an Actor System at a specific port.&lt;br/&gt;
-	 * @param configuration The Flink configuration.&lt;br/&gt;
-	 * @param actorSystemName Name of the started {@link ActorSystem}&lt;/li&gt;
	&lt;li&gt;* @param listeningAddress The address to listen at.&lt;/li&gt;
	&lt;li&gt;* @param listeningPort The port to listen at.&lt;/li&gt;
	&lt;li&gt;* @param logger the logger to output log information.&lt;/li&gt;
	&lt;li&gt;* @param executorMode The executor mode of Akka actor system.&lt;/li&gt;
	&lt;li&gt;* @return The ActorSystem which has been started.&lt;/li&gt;
	&lt;li&gt;* @throws Exception&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static ActorSystem startActorSystem(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String actorSystemName,&lt;/li&gt;
	&lt;li&gt;String listeningAddress,&lt;/li&gt;
	&lt;li&gt;int listeningPort,&lt;/li&gt;
	&lt;li&gt;Logger logger,&lt;/li&gt;
	&lt;li&gt;ActorSystemExecutorMode executorMode) throws Exception {&lt;br/&gt;
+				Logger logger) throws Exception {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		String hostPortUrl = NetUtils.unresolvedHostAndPortToNormalizedString(listeningAddress, listeningPort);&lt;br/&gt;
 		logger.info(&quot;Trying to start actor system at {}&quot;, hostPortUrl);&lt;br/&gt;
@@ -262,13 +155,12 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 		try {&lt;br/&gt;
 			Config akkaConfig = AkkaUtils.getAkkaConfig(&lt;br/&gt;
 				configuration,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new Some&amp;lt;&amp;gt;(new Tuple2&amp;lt;&amp;gt;(listeningAddress, listeningPort)),&lt;/li&gt;
	&lt;li&gt;getExecutorConfigByExecutorMode(configuration, executorMode)&lt;br/&gt;
+				new Some&amp;lt;&amp;gt;(new Tuple2&amp;lt;&amp;gt;(listeningAddress, listeningPort))&lt;br/&gt;
 			);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			logger.debug(&quot;Using akka configuration\n {}&quot;, akkaConfig);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ActorSystem actorSystem = AkkaUtils.createActorSystem(actorSystemName, akkaConfig);&lt;br/&gt;
+			ActorSystem actorSystem = AkkaUtils.createActorSystem(akkaConfig);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			logger.info(&quot;Actor system started at {}&quot;, AkkaUtils.getAddress(actorSystem));&lt;br/&gt;
 			return actorSystem;&lt;br/&gt;
@@ -278,24 +170,13 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 				Throwable cause = t.getCause();&lt;br/&gt;
 				if (cause != null &amp;amp;&amp;amp; t.getCause() instanceof BindException) &lt;/p&gt;
{
 					throw new IOException(&quot;Unable to create ActorSystem at address &quot; + hostPortUrl +
-						&quot; : &quot; + cause.getMessage(), t);
+							&quot; : &quot; + cause.getMessage(), t);
 				}
&lt;p&gt; 			}&lt;br/&gt;
 			throw new Exception(&quot;Could not create actor system&quot;, t);&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static Config getExecutorConfigByExecutorMode(Configuration configuration, ActorSystemExecutorMode executorMode) {&lt;/li&gt;
	&lt;li&gt;switch (executorMode) 
{
-			case FORK_JOIN_EXECUTOR:
-				return AkkaUtils.getForkJoinExecutorConfig(configuration);
-			case FIXED_THREAD_POOL_EXECUTOR:
-				return AkkaUtils.getThreadPoolExecutorConfig();
-			default:
-				throw new IllegalArgumentException(String.format(&quot;Unknown ActorSystemExecutorMode %s.&quot;, executorMode));
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
 	/**&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Starts the web frontend.&lt;br/&gt;
 	 *&lt;br/&gt;
@@ -623,14 +504,4 @@ public static Configuration cloneConfiguration(Configuration configuration) 
{
 
 		return clonedConfiguration;
 	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Options to specify which executor to use in an 
{@link ActorSystem}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public enum ActorSystemExecutorMode 
{
-		/** Used by default, use dispatcher with fork-join-executor. **/
-		FORK_JOIN_EXECUTOR,
-		/** Use dispatcher with fixed thread pool executor. **/
-		FIXED_THREAD_POOL_EXECUTOR
-	}
&lt;p&gt; }&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java&lt;br/&gt;
index 2a9baa925ff..fd0a0a1d39f 100755&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java&lt;br/&gt;
@@ -96,8 +96,6 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import scala.concurrent.duration.FiniteDuration;&lt;/p&gt;

&lt;p&gt;-import static org.apache.flink.runtime.clusterframework.BootstrapTools.ActorSystemExecutorMode.FORK_JOIN_EXECUTOR;&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Base class for the Flink cluster entry points.&lt;br/&gt;
  *&lt;br/&gt;
@@ -156,9 +154,6 @@&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private WebMonitorEndpoint&amp;lt;?&amp;gt; webMonitorEndpoint;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@GuardedBy(&quot;lock&quot;)&lt;/li&gt;
	&lt;li&gt;private ActorSystem metricQueryServiceActorSystem;&lt;br/&gt;
-&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private ArchivedExecutionGraphStore archivedExecutionGraphStore;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -281,9 +276,9 @@ protected void initializeServices(Configuration configuration) throws Exception&lt;br/&gt;
 			metricRegistry = createMetricRegistry(configuration);&lt;/p&gt;

&lt;p&gt; 			// TODO: This is a temporary hack until we have ported the MetricQueryService to the new RpcEndpoint&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Start actor system for metric query service on any available port&lt;/li&gt;
	&lt;li&gt;metricQueryServiceActorSystem = MetricUtils.startMetricsActorSystem(configuration, bindAddress, LOG);&lt;/li&gt;
	&lt;li&gt;metricRegistry.startQueryService(metricQueryServiceActorSystem, null);&lt;br/&gt;
+			// start the MetricQueryService&lt;br/&gt;
+			final ActorSystem actorSystem = ((AkkaRpcService) commonRpcService).getActorSystem();&lt;br/&gt;
+			metricRegistry.startQueryService(actorSystem, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			archivedExecutionGraphStore = createSerializableExecutionGraphStore(configuration, commonRpcService.getScheduledExecutor());&lt;/p&gt;

&lt;p&gt;@@ -401,7 +396,7 @@ protected RpcService createRpcService(&lt;br/&gt;
 			Configuration configuration,&lt;br/&gt;
 			String bindAddress,&lt;br/&gt;
 			String portRange) throws Exception &lt;/p&gt;
{
-		ActorSystem actorSystem = BootstrapTools.startActorSystem(configuration, bindAddress, portRange, LOG, FORK_JOIN_EXECUTOR);
+		ActorSystem actorSystem = BootstrapTools.startActorSystem(configuration, bindAddress, portRange, LOG);
 		FiniteDuration duration = AkkaUtils.getTimeout(configuration);
 		return new AkkaRpcService(actorSystem, Time.of(duration.length(), duration.unit()));
 	}
&lt;p&gt;@@ -469,10 +464,6 @@ protected MetricRegistryImpl createMetricRegistry(Configuration configuration) &lt;/p&gt;
{
 				terminationFutures.add(metricRegistry.shutdown());
 			}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (metricQueryServiceActorSystem != null) 
{
-				terminationFutures.add(AkkaUtils.terminateActorSystem(metricQueryServiceActorSystem));
-			}&lt;br/&gt;
-&lt;br/&gt;
 			if (commonRpcService != null) {
 				terminationFutures.add(commonRpcService.stopService());
 			}&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java&lt;br/&gt;
index 39e5f44583c..3fd268a1aeb 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java&lt;br/&gt;
@@ -18,11 +18,8 @@&lt;br/&gt;
 &lt;br/&gt;
 package org.apache.flink.runtime.metrics.util;&lt;br/&gt;
 &lt;br/&gt;
-import org.apache.flink.configuration.Configuration;&lt;br/&gt;
-import org.apache.flink.configuration.MetricOptions;&lt;br/&gt;
 import org.apache.flink.metrics.Gauge;&lt;br/&gt;
 import org.apache.flink.metrics.MetricGroup;&lt;br/&gt;
-import org.apache.flink.runtime.clusterframework.BootstrapTools;&lt;br/&gt;
 import org.apache.flink.runtime.io.network.NetworkEnvironment;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.MetricRegistry;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;&lt;br/&gt;
@@ -30,7 +27,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskManagerLocation;&lt;br/&gt;
 import org.apache.flink.util.Preconditions;&lt;br/&gt;
 &lt;br/&gt;
-import akka.actor.ActorSystem;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;br/&gt;
 &lt;br/&gt;
@@ -49,15 +45,12 @@&lt;br/&gt;
 import java.lang.management.ThreadMXBean;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 &lt;br/&gt;
-import static org.apache.flink.runtime.clusterframework.BootstrapTools.ActorSystemExecutorMode.FIXED_THREAD_POOL_EXECUTOR;&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;br/&gt;
  * Utility class to register pre-defined metric sets.&lt;br/&gt;
  */&lt;br/&gt;
 public class MetricUtils {&lt;br/&gt;
 	private static final Logger LOG = LoggerFactory.getLogger(MetricUtils.class);&lt;br/&gt;
 	private static final String METRIC_GROUP_STATUS_NAME = &quot;Status&quot;;&lt;br/&gt;
-	private static final String METRICS_ACTOR_SYSTEM_NAME = &quot;flink-metrics&quot;;&lt;br/&gt;
 &lt;br/&gt;
 	private MetricUtils() {&lt;br/&gt;
 	}&lt;br/&gt;
@@ -109,17 +102,6 @@ public static void instantiateStatusMetrics(&lt;br/&gt;
 		instantiateCPUMetrics(jvm.addGroup(&quot;CPU&quot;));&lt;br/&gt;
 	}&lt;br/&gt;
 &lt;br/&gt;
-	public static ActorSystem startMetricsActorSystem(Configuration configuration, String hostname, Logger logger) throws Exception {
-		final String portRange = configuration.getString(MetricOptions.QUERY_SERVICE_PORT);
-		return BootstrapTools.startActorSystem(
-			configuration,
-			METRICS_ACTOR_SYSTEM_NAME,
-			hostname,
-			portRange,
-			logger,
-			FIXED_THREAD_POOL_EXECUTOR);
-	}&lt;br/&gt;
-&lt;br/&gt;
 	private static void instantiateNetworkMetrics(&lt;br/&gt;
 		MetricGroup metrics,&lt;br/&gt;
 		final NetworkEnvironment network) {&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java b/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java&lt;br/&gt;
index bcd4c7b93fb..4bfdb25c4d6 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java&lt;br/&gt;
@@ -133,9 +133,6 @@&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private RpcService resourceManagerRpcService;&lt;br/&gt;
 &lt;br/&gt;
-	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
-	private ActorSystem metricQueryServiceActorSystem;&lt;br/&gt;
-&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private HighAvailabilityServices haServices;&lt;br/&gt;
 &lt;br/&gt;
@@ -255,11 +252,8 @@ public void start() throws Exception {&lt;br/&gt;
 				commonRpcService = createRpcService(configuration, rpcTimeout, false, null);&lt;br/&gt;
 &lt;br/&gt;
 				// TODO: Temporary hack until the metric query service is ported to the RpcEndpoint&lt;br/&gt;
-				metricQueryServiceActorSystem = MetricUtils.startMetricsActorSystem(&lt;br/&gt;
-					configuration,&lt;br/&gt;
-					commonRpcService.getAddress(),&lt;br/&gt;
-					LOG);&lt;br/&gt;
-				metricRegistry.startQueryService(metricQueryServiceActorSystem, null);&lt;br/&gt;
+				final ActorSystem actorSystem = ((AkkaRpcService) commonRpcService).getActorSystem();&lt;br/&gt;
+				metricRegistry.startQueryService(actorSystem, null);&lt;br/&gt;
 &lt;br/&gt;
 				if (useSingleRpcService) {&lt;br/&gt;
 					for (int i = 0; i &amp;lt; numTaskManagers; i++) {&lt;br/&gt;
@@ -356,7 +350,7 @@ public void start() throws Exception {&lt;br/&gt;
 						configuration.getInteger(RestOptions.SERVER_NUM_THREADS, 1),&lt;br/&gt;
 						&quot;DispatcherRestEndpoint&quot;),&lt;br/&gt;
 					new AkkaQueryServiceRetriever(&lt;br/&gt;
-						metricQueryServiceActorSystem,&lt;br/&gt;
+						actorSystem,&lt;br/&gt;
 						Time.milliseconds(configuration.getLong(WebOptions.TIMEOUT))),&lt;br/&gt;
 					haServices.getWebMonitorLeaderElectionService(),&lt;br/&gt;
 					new ShutDownFatalErrorHandler());&lt;br/&gt;
@@ -453,12 +447,24 @@ public void start() throws Exception {&lt;br/&gt;
 &lt;br/&gt;
 					final FutureUtils.ConjunctFuture&amp;lt;Void&amp;gt; componentsTerminationFuture = FutureUtils.completeAll(componentTerminationFutures);&lt;br/&gt;
 &lt;br/&gt;
-					final CompletableFuture&amp;lt;Void&amp;gt; metricSystemTerminationFuture = FutureUtils.composeAfterwards(&lt;br/&gt;
+					final CompletableFuture&amp;lt;Void&amp;gt; metricRegistryTerminationFuture = FutureUtils.runAfterwards(&lt;br/&gt;
 						componentsTerminationFuture,&lt;br/&gt;
-						this::closeMetricSystem);&lt;br/&gt;
+						() -&amp;gt; {&lt;br/&gt;
+							synchronized (lock) {&lt;br/&gt;
+								if (jobManagerMetricGroup != null) {
+									jobManagerMetricGroup.close();
+									jobManagerMetricGroup = null;
+								}&lt;br/&gt;
+								// metrics shutdown&lt;br/&gt;
+								if (metricRegistry != null) {
+									metricRegistry.shutdown();
+									metricRegistry = null;
+								}&lt;br/&gt;
+							}&lt;br/&gt;
+						});&lt;br/&gt;
 &lt;br/&gt;
 					// shut down the RpcServices&lt;br/&gt;
-					final CompletableFuture&amp;lt;Void&amp;gt; rpcServicesTerminationFuture = metricSystemTerminationFuture&lt;br/&gt;
+					final CompletableFuture&amp;lt;Void&amp;gt; rpcServicesTerminationFuture = metricRegistryTerminationFuture&lt;br/&gt;
 						.thenCompose((Void ignored) -&amp;gt; terminateRpcServices());&lt;br/&gt;
 &lt;br/&gt;
 					final CompletableFuture&amp;lt;Void&amp;gt; remainingServicesTerminationFuture = FutureUtils.runAfterwards(&lt;br/&gt;
@@ -482,29 +488,6 @@ public void start() throws Exception {&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;br/&gt;
 &lt;br/&gt;
-	private CompletableFuture&amp;lt;Void&amp;gt; closeMetricSystem() {&lt;br/&gt;
-		synchronized (lock) {&lt;br/&gt;
-			if (jobManagerMetricGroup != null) {
-				jobManagerMetricGroup.close();
-				jobManagerMetricGroup = null;
-			}&lt;br/&gt;
-&lt;br/&gt;
-			final ArrayList&amp;lt;CompletableFuture&amp;lt;Void&amp;gt;&amp;gt; terminationFutures = new ArrayList&amp;lt;&amp;gt;(2);&lt;br/&gt;
-&lt;br/&gt;
-			// metrics shutdown&lt;br/&gt;
-			if (metricRegistry != null) {
-				terminationFutures.add(metricRegistry.shutdown());
-				metricRegistry = null;
-			}&lt;br/&gt;
-&lt;br/&gt;
-			if (metricQueryServiceActorSystem != null) {-				terminationFutures.add(AkkaUtils.terminateActorSystem(metricQueryServiceActorSystem));-			}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;return FutureUtils.completeAll(terminationFutures);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;br/&gt;
 	//  Accessing jobs&lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java b/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java&lt;br/&gt;
index a3a075d0f98..d78e3465ec4 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java&lt;br/&gt;
@@ -48,6 +48,7 @@&lt;br/&gt;
 import org.apache.flink.runtime.messages.Acknowledge;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.MetricNames;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.MetricRegistry;&lt;br/&gt;
+import org.apache.flink.runtime.metrics.dump.MetricQueryService;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;&lt;br/&gt;
 import org.apache.flink.runtime.registration.RegistrationResponse;&lt;br/&gt;
 import org.apache.flink.runtime.resourcemanager.exceptions.ResourceManagerException;&lt;br/&gt;
@@ -75,13 +76,11 @@&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Objects;&lt;br/&gt;
-import java.util.Optional;&lt;br/&gt;
 import java.util.UUID;&lt;br/&gt;
 import java.util.concurrent.CompletableFuture;&lt;br/&gt;
 import java.util.concurrent.ConcurrentHashMap;&lt;br/&gt;
 import java.util.concurrent.ConcurrentMap;&lt;br/&gt;
 import java.util.concurrent.TimeoutException;&lt;br/&gt;
-import java.util.stream.Collectors;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import static org.apache.flink.util.Preconditions.checkNotNull;&lt;/p&gt;

&lt;p&gt;@@ -594,26 +593,19 @@ public void unRegisterInfoMessageListener(final String address) {&lt;/p&gt;

&lt;p&gt; 	@Override&lt;br/&gt;
 	public CompletableFuture&amp;lt;Collection&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt;&amp;gt; requestTaskManagerMetricQueryServicePaths(Time timeout) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ArrayList&amp;lt;CompletableFuture&amp;lt;Optional&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt;&amp;gt;&amp;gt; metricQueryServicePathFutures = new ArrayList&amp;lt;&amp;gt;(taskExecutors.size());&lt;br/&gt;
+		final ArrayList&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt; metricQueryServicePaths = new ArrayList&amp;lt;&amp;gt;(taskExecutors.size());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		for (Map.Entry&amp;lt;ResourceID, WorkerRegistration&amp;lt;WorkerType&amp;gt;&amp;gt; workerRegistrationEntry : taskExecutors.entrySet()) &lt;/p&gt;
{
 			final ResourceID tmResourceId = workerRegistrationEntry.getKey();
 			final WorkerRegistration&amp;lt;WorkerType&amp;gt; workerRegistration = workerRegistrationEntry.getValue();
-			final TaskExecutorGateway taskExecutorGateway = workerRegistration.getTaskExecutorGateway();
+			final String taskManagerAddress = workerRegistration.getTaskExecutorGateway().getAddress();
+			final String tmMetricQueryServicePath = taskManagerAddress.substring(0, taskManagerAddress.lastIndexOf(&apos;/&apos;) + 1) +
+				MetricQueryService.METRIC_QUERY_SERVICE_NAME + &apos;_&apos; + tmResourceId.getResourceIdString();
 
-			final CompletableFuture&amp;lt;Optional&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt;&amp;gt; metricQueryServicePathFuture = taskExecutorGateway
-				.requestMetricQueryServiceAddress(timeout)
-				.thenApply(optional -&amp;gt; optional.map(path -&amp;gt; Tuple2.of(tmResourceId, path)));
-
-			metricQueryServicePathFutures.add(metricQueryServicePathFuture);
+			metricQueryServicePaths.add(Tuple2.of(tmResourceId, tmMetricQueryServicePath));
 		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return FutureUtils.combineAll(metricQueryServicePathFutures).thenApply(&lt;/li&gt;
	&lt;li&gt;collection -&amp;gt; collection&lt;/li&gt;
	&lt;li&gt;.stream()&lt;/li&gt;
	&lt;li&gt;.filter(Optional::isPresent)&lt;/li&gt;
	&lt;li&gt;.map(Optional::get)&lt;/li&gt;
	&lt;li&gt;.collect(Collectors.toList()));&lt;br/&gt;
+		return CompletableFuture.completedFuture(metricQueryServicePaths);&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	@Override&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java b/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java&lt;br/&gt;
index 3ee7641f717..3a626986361 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java&lt;br/&gt;
@@ -70,10 +70,7 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@throws IOException      Thrown, if the actor system can not bind to the address&lt;/li&gt;
	&lt;li&gt;@throws Exception      Thrown is some other error occurs while creating akka actor system&lt;br/&gt;
 	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static RpcService createRpcService(&lt;/li&gt;
	&lt;li&gt;String hostname,&lt;/li&gt;
	&lt;li&gt;int port,&lt;/li&gt;
	&lt;li&gt;Configuration configuration) throws Exception {&lt;br/&gt;
+	public static RpcService createRpcService(String hostname, int port, Configuration configuration) throws Exception {&lt;br/&gt;
 		LOG.info(&quot;Starting AkkaRpcService at {}.&quot;, NetUtils.unresolvedHostAndPortToNormalizedString(hostname, port));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		final ActorSystem actorSystem;&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java&lt;br/&gt;
index f90e939bc01..33db7e13076 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java&lt;br/&gt;
@@ -102,7 +102,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskExecutionState;&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskManagerActions;&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskManagerLocation;&lt;br/&gt;
-import org.apache.flink.types.SerializableOptional;&lt;br/&gt;
 import org.apache.flink.util.ExceptionUtils;&lt;br/&gt;
 import org.apache.flink.util.FlinkException;&lt;/p&gt;

&lt;p&gt;@@ -158,10 +157,6 @@&lt;/p&gt;

&lt;p&gt; 	private final BlobCacheService blobCacheService;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/** The path to metric query service on this Task Manager. */&lt;/li&gt;
	&lt;li&gt;@Nullable&lt;/li&gt;
	&lt;li&gt;private final String metricQueryServicePath;&lt;br/&gt;
-&lt;br/&gt;
 	// --------- TaskManager services --------&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	/** The connection information of this task manager. */&lt;br/&gt;
@@ -216,7 +211,6 @@ public TaskExecutor(&lt;br/&gt;
 			TaskManagerServices taskExecutorServices,&lt;br/&gt;
 			HeartbeatServices heartbeatServices,&lt;br/&gt;
 			TaskManagerMetricGroup taskManagerMetricGroup,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Nullable String metricQueryServicePath,&lt;br/&gt;
 			BlobCacheService blobCacheService,&lt;br/&gt;
 			FatalErrorHandler fatalErrorHandler) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -230,7 +224,6 @@ public TaskExecutor(&lt;br/&gt;
 		this.fatalErrorHandler = checkNotNull(fatalErrorHandler);&lt;br/&gt;
 		this.taskManagerMetricGroup = checkNotNull(taskManagerMetricGroup);&lt;br/&gt;
 		this.blobCacheService = checkNotNull(blobCacheService);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.metricQueryServicePath = metricQueryServicePath;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		this.taskSlotTable = taskExecutorServices.getTaskSlotTable();&lt;br/&gt;
 		this.jobManagerTable = taskExecutorServices.getJobManagerTable();&lt;br/&gt;
@@ -854,11 +847,6 @@ public void heartbeatFromResourceManager(ResourceID resourceID) {&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public CompletableFuture&amp;lt;SerializableOptional&amp;lt;String&amp;gt;&amp;gt; requestMetricQueryServiceAddress(Time timeout) 
{
-		return CompletableFuture.completedFuture(SerializableOptional.ofNullable(metricQueryServicePath));
-	}
&lt;p&gt;-&lt;br/&gt;
 	// ----------------------------------------------------------------------&lt;br/&gt;
 	// Disconnection RPCs&lt;br/&gt;
 	// ----------------------------------------------------------------------&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java&lt;br/&gt;
index d6b9e152e8f..4f792896216 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java&lt;br/&gt;
@@ -36,7 +36,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.rpc.RpcGateway;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.RpcTimeout;&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.Task;&lt;br/&gt;
-import org.apache.flink.types.SerializableOptional;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.util.concurrent.CompletableFuture;&lt;/p&gt;

&lt;p&gt;@@ -196,11 +195,4 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@return Future which is completed with the 
{@link TransientBlobKey}
&lt;p&gt; of the uploaded file.&lt;br/&gt;
 	 */&lt;br/&gt;
 	CompletableFuture&amp;lt;TransientBlobKey&amp;gt; requestFileUpload(FileType fileType, @RpcTimeout Time timeout);&lt;br/&gt;
-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Returns the fully qualified address of Metric Query Service on the TaskManager.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return Future String with Fully qualified (RPC) address of Metric Query Service on the TaskManager.&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;SerializableOptional&amp;lt;String&amp;gt;&amp;gt; requestMetricQueryServiceAddress(@RpcTimeout Time timeout);&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java&lt;br/&gt;
index f830ae1968a..42fe5bf658b 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java&lt;br/&gt;
@@ -43,6 +43,7 @@&lt;br/&gt;
 import org.apache.flink.runtime.metrics.util.MetricUtils;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.FatalErrorHandler;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.RpcService;&lt;br/&gt;
+import org.apache.flink.runtime.rpc.akka.AkkaRpcService;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils;&lt;br/&gt;
 import org.apache.flink.runtime.security.SecurityConfiguration;&lt;br/&gt;
 import org.apache.flink.runtime.security.SecurityUtils;&lt;br/&gt;
@@ -100,8 +101,6 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	private final RpcService rpcService;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final ActorSystem metricQueryServiceActorSystem;&lt;br/&gt;
-&lt;br/&gt;
 	private final HighAvailabilityServices highAvailabilityServices;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	private final MetricRegistryImpl metricRegistry;&lt;br/&gt;
@@ -133,14 +132,14 @@ public TaskManagerRunner(Configuration configuration, ResourceID resourceId) thr&lt;br/&gt;
 			HighAvailabilityServicesUtils.AddressResolution.TRY_ADDRESS_RESOLUTION);&lt;/p&gt;

&lt;p&gt; 		rpcService = createRpcService(configuration, highAvailabilityServices);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;metricQueryServiceActorSystem = MetricUtils.startMetricsActorSystem(configuration, rpcService.getAddress(), LOG);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		HeartbeatServices heartbeatServices = HeartbeatServices.fromConfiguration(configuration);&lt;/p&gt;

&lt;p&gt; 		metricRegistry = new MetricRegistryImpl(MetricRegistryConfiguration.fromConfiguration(configuration));&lt;/p&gt;

&lt;p&gt; 		// TODO: Temporary hack until the MetricQueryService has been ported to RpcEndpoint&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;metricRegistry.startQueryService(metricQueryServiceActorSystem, resourceId);&lt;br/&gt;
+		final ActorSystem actorSystem = ((AkkaRpcService) rpcService).getActorSystem();&lt;br/&gt;
+		metricRegistry.startQueryService(actorSystem, resourceId);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		blobCacheService = new BlobCacheService(&lt;br/&gt;
 			configuration, highAvailabilityServices.createBlobStore(), null&lt;br/&gt;
@@ -160,7 +159,7 @@ public TaskManagerRunner(Configuration configuration, ResourceID resourceId) thr&lt;br/&gt;
 		this.terminationFuture = new CompletableFuture&amp;lt;&amp;gt;();&lt;br/&gt;
 		this.shutdown = false;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;MemoryLogger.startIfConfigured(LOG, configuration, metricQueryServiceActorSystem);&lt;br/&gt;
+		MemoryLogger.startIfConfigured(LOG, configuration, actorSystem);&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	// --------------------------------------------------------------------------------------------&lt;br/&gt;
@@ -215,10 +214,6 @@ public void start() throws Exception &lt;/p&gt;
{
 				exception = ExceptionUtils.firstOrSuppressed(e, exception);
 			}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (metricQueryServiceActorSystem != null) 
{
-				terminationFutures.add(AkkaUtils.terminateActorSystem(metricQueryServiceActorSystem));
-			}
&lt;p&gt;-&lt;br/&gt;
 			try &lt;/p&gt;
{
 				highAvailabilityServices.close();
 			}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
@@ -378,8 +373,6 @@ public static TaskExecutor startTaskManager(
 
 		TaskManagerConfiguration taskManagerConfiguration = TaskManagerConfiguration.fromConfiguration(configuration);
 
-		String metricQueryServicePath = metricRegistry.getMetricQueryServicePath();
-
 		return new TaskExecutor(
 			rpcService,
 			taskManagerConfiguration,
@@ -387,7 +380,6 @@ public static TaskExecutor startTaskManager(
 			taskManagerServices,
 			heartbeatServices,
 			taskManagerMetricGroup,
-			metricQueryServicePath,
 			blobCacheService,
 			fatalErrorHandler);
 	}
&lt;p&gt;@@ -424,14 +416,6 @@ public static RpcService createRpcService(&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		final String portRangeDefinition = configuration.getString(TaskManagerOptions.RPC_PORT);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return bindWithPort(configuration, taskManagerHostname, portRangeDefinition);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static RpcService bindWithPort(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String taskManagerHostname,&lt;/li&gt;
	&lt;li&gt;String portRangeDefinition) throws Exception{&lt;br/&gt;
-&lt;br/&gt;
 		// parse port range definition and create port iterator&lt;br/&gt;
 		Iterator&amp;lt;Integer&amp;gt; portsIterator;&lt;br/&gt;
 		try {&lt;br/&gt;
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala&lt;br/&gt;
index 2b0c939e574..dcf0fdd9bdf 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala&lt;br/&gt;
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala&lt;br/&gt;
@@ -50,12 +50,6 @@ object AkkaUtils {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   val INF_TIMEOUT: FiniteDuration = 21474835 seconds&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val FLINK_ACTOR_SYSTEM_NAME = &quot;flink&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def getFlinkActorSystemName = 
{
-    FLINK_ACTOR_SYSTEM_NAME
-  }
&lt;p&gt;-&lt;br/&gt;
   /**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Creates a local actor system without remoting.&lt;br/&gt;
    *&lt;br/&gt;
@@ -109,19 +103,9 @@ object AkkaUtils {&lt;/li&gt;
	&lt;li&gt;@return created actor system&lt;br/&gt;
    */&lt;br/&gt;
   def createActorSystem(akkaConfig: Config): ActorSystem = 
{
-    createActorSystem(FLINK_ACTOR_SYSTEM_NAME, akkaConfig)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Creates an actor system with the given akka config.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param akkaConfig configuration for the actor system&lt;/li&gt;
	&lt;li&gt;* @return created actor system&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;def createActorSystem(actorSystemName: String, akkaConfig: Config): ActorSystem = 
{
     // Initialize slf4j as logger of Akka&apos;s Netty instead of java.util.logging (FLINK-1650)
     InternalLoggerFactory.setDefaultFactory(new Slf4JLoggerFactory)
-    ActorSystem.create(actorSystemName, akkaConfig)
+    ActorSystem.create(&quot;flink&quot;, akkaConfig)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;br/&gt;
@@ -135,23 +119,7 @@ object AkkaUtils {&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;   /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Returns a remote Akka config for the given configuration values.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration containing the user provided configuration values&lt;/li&gt;
	&lt;li&gt;* @param hostname to bind against. If null, then the loopback interface is used&lt;/li&gt;
	&lt;li&gt;* @param port to bind against&lt;/li&gt;
	&lt;li&gt;* @param executorMode containing the user specified mode of executor&lt;/li&gt;
	&lt;li&gt;* @return A remote Akka config&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;def getAkkaConfig(configuration: Configuration,&lt;/li&gt;
	&lt;li&gt;hostname: String,&lt;/li&gt;
	&lt;li&gt;port: Int,&lt;/li&gt;
	&lt;li&gt;executorConfig: Config): Config = 
{
-    getAkkaConfig(configuration, Some((hostname, port)), executorConfig)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Returns a remote Akka config for the given configuration values.&lt;br/&gt;
+    * Return a remote Akka config for the given configuration values.&lt;br/&gt;
     *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param configuration containing the user provided configuration values&lt;/li&gt;
	&lt;li&gt;@param hostname to bind against. If null, then the loopback interface is used&lt;br/&gt;
@@ -187,25 +155,7 @@ object AkkaUtils {&lt;br/&gt;
   @throws(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;UnknownHostException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
   def getAkkaConfig(configuration: Configuration,&lt;br/&gt;
                     externalAddress: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;(String, Int)&amp;#93;&lt;/span&gt;): Config = 
{
-    getAkkaConfig(configuration, externalAddress, getForkJoinExecutorConfig(configuration))
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Creates an akka config with the provided configuration values. If the listening address is&lt;/li&gt;
	&lt;li&gt;* specified, then the actor system will listen on the respective address.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration instance containing the user provided configuration values&lt;/li&gt;
	&lt;li&gt;* @param externalAddress optional tuple of bindAddress and port to be reachable at.&lt;/li&gt;
	&lt;li&gt;*                        If None is given, then an Akka config for local actor system&lt;/li&gt;
	&lt;li&gt;*                        will be returned&lt;/li&gt;
	&lt;li&gt;* @param executorConfig config defining the used executor by the default dispatcher&lt;/li&gt;
	&lt;li&gt;* @return Akka config&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;@throws(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;UnknownHostException&amp;#93;&lt;/span&gt;)&lt;/li&gt;
	&lt;li&gt;def getAkkaConfig(configuration: Configuration,&lt;/li&gt;
	&lt;li&gt;externalAddress: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;(String, Int)&amp;#93;&lt;/span&gt;,&lt;/li&gt;
	&lt;li&gt;executorConfig: Config): Config = {&lt;/li&gt;
	&lt;li&gt;val defaultConfig = getBasicAkkaConfig(configuration).withFallback(executorConfig)&lt;br/&gt;
+    val defaultConfig = getBasicAkkaConfig(configuration)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     externalAddress match {&lt;/p&gt;

&lt;p&gt;@@ -257,6 +207,24 @@ object AkkaUtils {&lt;br/&gt;
     val supervisorStrategy = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;StoppingSupervisorWithoutLoggingActorKilledExceptionStrategy&amp;#93;&lt;/span&gt;&lt;br/&gt;
       .getCanonicalName&lt;/p&gt;

&lt;p&gt;+    val forkJoinExecutorParallelismFactor =&lt;br/&gt;
+      configuration.getDouble(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_FACTOR)&lt;br/&gt;
+&lt;br/&gt;
+    val forkJoinExecutorParallelismMin =&lt;br/&gt;
+      configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MIN)&lt;br/&gt;
+&lt;br/&gt;
+    val forkJoinExecutorParallelismMax =&lt;br/&gt;
+      configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MAX)&lt;br/&gt;
+&lt;br/&gt;
+    val forkJoinExecutorConfig =&lt;br/&gt;
+      s&quot;&quot;&quot;&lt;br/&gt;
+         | fork-join-executor &lt;/p&gt;
{
+         |   parallelism-factor = $forkJoinExecutorParallelismFactor
+         |   parallelism-min = $forkJoinExecutorParallelismMin
+         |   parallelism-max = $forkJoinExecutorParallelismMax
+         | }
&lt;p&gt;+       &quot;&quot;&quot;.stripMargin&lt;br/&gt;
+&lt;br/&gt;
     val config =&lt;br/&gt;
       s&quot;&quot;&quot;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;akka {&lt;br/&gt;
@@ -283,6 +251,8 @@ object AkkaUtils {&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   default-dispatcher 
{
         |     throughput = $akkaThroughput
+        |
+        |   $forkJoinExecutorConfig
         |   }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;}&lt;br/&gt;
@@ -291,53 +261,6 @@ object AkkaUtils 
{
     ConfigFactory.parseString(config)
   }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def getThreadPoolExecutorConfig: Config = {&lt;/li&gt;
	&lt;li&gt;val configString = s&quot;&quot;&quot;&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;akka {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  actor {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    default-dispatcher {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      executor = &quot;thread-pool-executor&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      thread-pool-executor 
{
-       |        core-pool-size-min = 2
-       |        core-pool-size-factor = 2.0
-       |        core-pool-size-max = 4
-       |      }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;.&lt;/li&gt;
	&lt;li&gt;stripMargin&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;ConfigFactory.parseString(configString)&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def getForkJoinExecutorConfig(configuration: Configuration): Config = {&lt;/li&gt;
	&lt;li&gt;val forkJoinExecutorParallelismFactor =&lt;/li&gt;
	&lt;li&gt;configuration.getDouble(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_FACTOR)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val forkJoinExecutorParallelismMin =&lt;/li&gt;
	&lt;li&gt;configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MIN)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val forkJoinExecutorParallelismMax =&lt;/li&gt;
	&lt;li&gt;configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MAX)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val configString = s&quot;&quot;&quot;&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;akka {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  actor {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    default-dispatcher {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      executor = &quot;fork-join-executor&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      fork-join-executor 
{
-       |        parallelism-factor = $forkJoinExecutorParallelismFactor
-       |        parallelism-min = $forkJoinExecutorParallelismMin
-       |        parallelism-max = $forkJoinExecutorParallelismMax
-       |      }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;}&quot;&quot;&quot;.stripMargin&lt;br/&gt;
-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;ConfigFactory.parseString(configString)&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
   def testDispatcherConfig: Config = {&lt;br/&gt;
     val config =&lt;br/&gt;
       s&quot;&quot;&quot;&lt;br/&gt;
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
index 3650f43066d..b113e12ef69 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
@@ -1494,8 +1494,8 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;br/&gt;
 		assertTrue(pending.isDiscarded());&lt;br/&gt;
 		assertTrue(savepointFuture.isDone());&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the now we should have a completed checkpoint&lt;/li&gt;
	&lt;li&gt;assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		// the now the savepoint should be completed but not added to the completed checkpoint store&lt;br/&gt;
+		assertEquals(0, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
 		assertEquals(0, coord.getNumberOfPendingCheckpoints());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		// validate that the relevant tasks got a confirmation message&lt;br/&gt;
@@ -1510,7 +1510,7 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception &lt;/p&gt;
{
 			verify(subtaskState2, times(1)).registerSharedStates(any(SharedStateRegistry.class));
 		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CompletedCheckpoint success = coord.getSuccessfulCheckpoints().get(0);&lt;br/&gt;
+		CompletedCheckpoint success = savepointFuture.get();&lt;br/&gt;
 		assertEquals(jid, success.getJobId());&lt;br/&gt;
 		assertEquals(timestamp, success.getTimestamp());&lt;br/&gt;
 		assertEquals(pending.getCheckpointId(), success.getCheckpointID());&lt;br/&gt;
@@ -1528,9 +1528,9 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, checkpointIdNew));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertEquals(0, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		assertEquals(0, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CompletedCheckpoint successNew = coord.getSuccessfulCheckpoints().get(0);&lt;br/&gt;
+		CompletedCheckpoint successNew = savepointFuture.get();&lt;br/&gt;
 		assertEquals(jid, successNew.getJobId());&lt;br/&gt;
 		assertEquals(timestampNew, successNew.getTimestamp());&lt;br/&gt;
 		assertEquals(checkpointIdNew, successNew.getCheckpointID());&lt;br/&gt;
@@ -1557,7 +1557,7 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Triggers a savepoint and two checkpoints. The second checkpoint completes&lt;/li&gt;
	&lt;li&gt;and subsumes the first checkpoint, but not the first savepoint. Then we&lt;/li&gt;
	&lt;li&gt;trigger another checkpoint and savepoint. The 2nd savepoint completes and&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* subsumes the last checkpoint, but not the first savepoint.&lt;br/&gt;
+	 * does neither subsume the last checkpoint nor the first savepoint.&lt;br/&gt;
 	 */&lt;br/&gt;
 	@Test&lt;br/&gt;
 	public void testSavepointsAreNotSubsumed() throws Exception {&lt;br/&gt;
@@ -1614,18 +1614,19 @@ public void testSavepointsAreNotSubsumed() throws Exception {&lt;br/&gt;
 		assertFalse(savepointFuture1.isDone());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertTrue(coord.triggerCheckpoint(timestamp + 3, false));&lt;br/&gt;
+		long checkpointId3 = counter.getLast();&lt;br/&gt;
 		assertEquals(2, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;

&lt;p&gt; 		CompletableFuture&amp;lt;CompletedCheckpoint&amp;gt; savepointFuture2 = coord.triggerSavepoint(timestamp + 4, savepointDir);&lt;br/&gt;
 		long savepointId2 = counter.getLast();&lt;br/&gt;
 		assertEquals(3, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// 2nd savepoint should subsume the last checkpoint, but not the 1st savepoint&lt;br/&gt;
+		// 2nd savepoint should not subsume the last checkpoint and the 1st savepoint&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, savepointId2));&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, savepointId2));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(1, coord.getNumberOfPendingCheckpoints());&lt;/li&gt;
	&lt;li&gt;assertEquals(2, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		assertEquals(2, coord.getNumberOfPendingCheckpoints());&lt;br/&gt;
+		assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
 		assertFalse(coord.getPendingCheckpoints().get(savepointId1).isDiscarded());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertFalse(savepointFuture1.isDone());&lt;br/&gt;
@@ -1635,9 +1636,15 @@ public void testSavepointsAreNotSubsumed() throws Exception &lt;/p&gt;
{
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, savepointId1));
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, savepointId1));
 
-		assertEquals(0, coord.getNumberOfPendingCheckpoints());
-		assertEquals(3, coord.getNumberOfRetainedSuccessfulCheckpoints());
+		assertEquals(1, coord.getNumberOfPendingCheckpoints());
+		assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());
 		assertTrue(savepointFuture1.isDone());
+
+		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, checkpointId3));
+		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, checkpointId3));
+
+		assertEquals(0, coord.getNumberOfPendingCheckpoints());
+		assertEquals(2, coord.getNumberOfRetainedSuccessfulCheckpoints());
 	}

&lt;p&gt; 	private void testMaxConcurrentAttempts(int maxConcurrentAttempts) {&lt;br/&gt;
@@ -3460,6 +3467,92 @@ public void testCheckpointStatsTrackerRestoreCallback() throws Exception &lt;/p&gt;
{
 			.reportRestoredCheckpoint(any(RestoredCheckpointStats.class));
 	}

&lt;p&gt;+	/**&lt;br/&gt;
+	 * &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
+	 *&lt;br/&gt;
+	 * Tests that savepoints are not added to the &lt;/p&gt;
{@link CompletedCheckpointStore}
&lt;p&gt; and,&lt;br/&gt;
+	 * thus, are not subject to job recovery. The reason that we don&apos;t want that (until&lt;br/&gt;
+	 * &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; title=&quot;Automatic fallback to earlier checkpoints when checkpoint restore fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4815&quot;&gt;FLINK-4815&lt;/a&gt; has been finished) is that the lifecycle of savepoints is not controlled&lt;br/&gt;
+	 * by the &lt;/p&gt;
{@link CheckpointCoordinator}
&lt;p&gt;.&lt;br/&gt;
+	 */&lt;br/&gt;
+	@Test&lt;br/&gt;
+	public void testSavepointsAreNotAddedToCompletedCheckpointStore() throws Exception {&lt;br/&gt;
+		final JobID jobId = new JobID();&lt;br/&gt;
+		final ExecutionAttemptID executionAttemptId = new ExecutionAttemptID();&lt;br/&gt;
+		final ExecutionVertex vertex1 = mockExecutionVertex(executionAttemptId);&lt;br/&gt;
+		final CompletedCheckpointStore completedCheckpointStore = new StandaloneCompletedCheckpointStore(1);&lt;br/&gt;
+		final long checkpointTimestamp1 = 1L;&lt;br/&gt;
+		final long savepointTimestamp = 2L;&lt;br/&gt;
+		final long checkpointTimestamp2 = 3L;&lt;br/&gt;
+		final String savepointDir = tmpFolder.newFolder().getAbsolutePath();&lt;br/&gt;
+&lt;br/&gt;
+		final StandaloneCheckpointIDCounter checkpointIDCounter = new StandaloneCheckpointIDCounter();&lt;br/&gt;
+&lt;br/&gt;
+		CheckpointCoordinator checkpointCoordinator = new CheckpointCoordinator(&lt;br/&gt;
+			jobId,&lt;br/&gt;
+			600000L,&lt;br/&gt;
+			600000L,&lt;br/&gt;
+			0L,&lt;br/&gt;
+			Integer.MAX_VALUE,&lt;br/&gt;
+			CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION,&lt;br/&gt;
+			new ExecutionVertex[]&lt;/p&gt;
{vertex1},&lt;br/&gt;
+			new ExecutionVertex[]{vertex1}
&lt;p&gt;,&lt;br/&gt;
+			new ExecutionVertex[]&lt;/p&gt;
{vertex1}
&lt;p&gt;,&lt;br/&gt;
+			checkpointIDCounter,&lt;br/&gt;
+			completedCheckpointStore,&lt;br/&gt;
+			new MemoryStateBackend(),&lt;br/&gt;
+			Executors.directExecutor(),&lt;br/&gt;
+			SharedStateRegistry.DEFAULT_FACTORY);&lt;br/&gt;
+&lt;br/&gt;
+		// trigger a first checkpoint&lt;br/&gt;
+		assertTrue(&lt;br/&gt;
+			&quot;Triggering of a checkpoint should work.&quot;,&lt;br/&gt;
+			checkpointCoordinator.triggerCheckpoint(checkpointTimestamp1, false));&lt;br/&gt;
+&lt;br/&gt;
+		assertTrue(0 == completedCheckpointStore.getNumberOfRetainedCheckpoints());&lt;br/&gt;
+&lt;br/&gt;
+		// complete the 1st checkpoint&lt;br/&gt;
+		checkpointCoordinator.receiveAcknowledgeMessage(&lt;br/&gt;
+			new AcknowledgeCheckpoint(&lt;br/&gt;
+				jobId,&lt;br/&gt;
+				executionAttemptId,&lt;br/&gt;
+				checkpointIDCounter.getLast()));&lt;br/&gt;
+&lt;br/&gt;
+		// check that the checkpoint has been completed&lt;br/&gt;
+		assertTrue(1 == completedCheckpointStore.getNumberOfRetainedCheckpoints());&lt;br/&gt;
+&lt;br/&gt;
+		// trigger a savepoint --&amp;gt; this should not have any effect on the CompletedCheckpointStore&lt;br/&gt;
+		CompletableFuture&amp;lt;CompletedCheckpoint&amp;gt; savepointFuture = checkpointCoordinator.triggerSavepoint(savepointTimestamp, savepointDir);&lt;br/&gt;
+&lt;br/&gt;
+		checkpointCoordinator.receiveAcknowledgeMessage(&lt;br/&gt;
+			new AcknowledgeCheckpoint(&lt;br/&gt;
+				jobId,&lt;br/&gt;
+				executionAttemptId,&lt;br/&gt;
+				checkpointIDCounter.getLast()));&lt;br/&gt;
+&lt;br/&gt;
+		// check that no errors occurred&lt;br/&gt;
+		final CompletedCheckpoint savepoint = savepointFuture.get();&lt;br/&gt;
+&lt;br/&gt;
+		assertFalse(&lt;br/&gt;
+			&quot;The savepoint should not have been added to the completed checkpoint store&quot;,&lt;br/&gt;
+			savepoint.getCheckpointID() == completedCheckpointStore.getLatestCheckpoint().getCheckpointID());&lt;br/&gt;
+&lt;br/&gt;
+		assertTrue(&lt;br/&gt;
+			&quot;Triggering of a checkpoint should work.&quot;,&lt;br/&gt;
+			checkpointCoordinator.triggerCheckpoint(checkpointTimestamp2, false));&lt;br/&gt;
+&lt;br/&gt;
+		// complete the 2nd checkpoint&lt;br/&gt;
+		checkpointCoordinator.receiveAcknowledgeMessage(&lt;br/&gt;
+			new AcknowledgeCheckpoint(&lt;br/&gt;
+				jobId,&lt;br/&gt;
+				executionAttemptId,&lt;br/&gt;
+				checkpointIDCounter.getLast()));&lt;br/&gt;
+&lt;br/&gt;
+		assertTrue(&lt;br/&gt;
+			&quot;The latest completed (proper) checkpoint should have been added to the completed checkpoint store.&quot;,&lt;br/&gt;
+			completedCheckpointStore.getLatestCheckpoint().getCheckpointID() == checkpointIDCounter.getLast());&lt;br/&gt;
+	}&lt;br/&gt;
+&lt;br/&gt;
 	@Test&lt;br/&gt;
 	public void testSharedStateRegistrationOnRestore() throws Exception {&lt;/p&gt;

&lt;p&gt;diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java&lt;br/&gt;
index 3ee1b927b53..6e0f9c5c638 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java&lt;br/&gt;
@@ -165,7 +165,6 @@ public void testSlotAllocation() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			new BlobCacheService(&lt;br/&gt;
 				configuration,&lt;br/&gt;
 				new VoidBlobStore(),&lt;br/&gt;
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java&lt;br/&gt;
index 179dea27835..4af052978f9 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java&lt;br/&gt;
@@ -279,7 +279,6 @@ public void testHeartbeatTimeoutWithJobManager() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -370,7 +369,6 @@ public void testHeartbeatTimeoutWithResourceManager() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -486,7 +484,6 @@ public void testHeartbeatSlotReporting() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -565,7 +562,6 @@ public void testImmediatelyRegistersIfLeaderIsKnown() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -629,7 +625,6 @@ public void testTriggerRegistrationOnLeaderChange() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -752,7 +747,6 @@ public void testTaskSubmission() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -852,7 +846,6 @@ public void testJobLeaderDetection() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -884,7 +877,7 @@ public void testJobLeaderDetection() throws Exception &lt;/p&gt;
{
 			// the job leader should get the allocation id offered
 			verify(jobMasterGateway, Mockito.timeout(timeout.toMilliseconds())).offerSlots(
 					any(ResourceID.class),
-					(Collection&amp;lt;SlotOffer&amp;gt;)Matchers.argThat(contains(slotOffer)),
+					(Collection&amp;lt;SlotOffer&amp;gt;) Matchers.argThat(contains(slotOffer)),
 					any(Time.class));
 		}
&lt;p&gt; finally {&lt;br/&gt;
 			RpcUtils.terminateRpcEndpoint(taskManager, timeout);&lt;br/&gt;
@@ -967,7 +960,6 @@ public void testSlotAcceptance() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1062,7 +1054,6 @@ public void testSubmitTaskBeforeAcceptSlot() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1169,7 +1160,6 @@ public void testFilterOutDuplicateJobMasterRegistrations() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServicesMock,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1243,7 +1233,6 @@ public void testRMHeartbeatStopWhenLeadershipRevoked() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1300,7 +1289,6 @@ public void testRemoveJobFromJobLeaderService() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1393,7 +1381,6 @@ public void testMaximumRegistrationDurationAfterConnectionLoss() throws Exceptio&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(heartbeatInterval, 10L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1501,7 +1488,6 @@ public void testReconnectionAttemptIfExplicitlyDisconnected() throws Exception &lt;/p&gt;
{
 				.build(),
 			new HeartbeatServices(heartbeatInterval, 1000L),
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),
-			null,
 			dummyBlobCacheService,
 			testingFatalErrorHandler);
 
@@ -1713,7 +1699,6 @@ private TaskExecutor createTaskExecutor(TaskManagerServices taskManagerServices)
 			taskManagerServices,
 			new HeartbeatServices(1000L, 1000L),
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),
-			null,
 			dummyBlobCacheService,
 			testingFatalErrorHandler);
 	}
&lt;p&gt;diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java&lt;br/&gt;
index 5fd12a84ac4..a9e99495e34 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java&lt;br/&gt;
@@ -34,7 +34,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.messages.Acknowledge;&lt;br/&gt;
 import org.apache.flink.runtime.messages.StackTraceSampleResponse;&lt;br/&gt;
 import org.apache.flink.runtime.resourcemanager.ResourceManagerId;&lt;br/&gt;
-import org.apache.flink.types.SerializableOptional;&lt;br/&gt;
 import org.apache.flink.util.Preconditions;&lt;/p&gt;

&lt;p&gt; import java.util.concurrent.CompletableFuture;&lt;br/&gt;
@@ -150,11 +149,6 @@ public void disconnectResourceManager(Exception cause) &lt;/p&gt;
{
 		return FutureUtils.completedExceptionally(new UnsupportedOperationException());
 	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public CompletableFuture&amp;lt;SerializableOptional&amp;lt;String&amp;gt;&amp;gt; requestMetricQueryServiceAddress(Time timeout) 
{
-		return CompletableFuture.completedFuture(SerializableOptional.of(address));
-	}
&lt;p&gt;-&lt;br/&gt;
 	@Override&lt;br/&gt;
 	public String getAddress() {&lt;br/&gt;
 		return address;&lt;br/&gt;
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala&lt;br/&gt;
index e5c1668df0a..d02a55483bf 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala&lt;br/&gt;
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala&lt;br/&gt;
@@ -18,7 +18,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package org.apache.flink.runtime.akka&lt;/p&gt;

&lt;p&gt;-import java.net.&lt;/p&gt;
{InetAddress, InetSocketAddress}
&lt;p&gt;+import java.net.InetSocketAddress&lt;/p&gt;

&lt;p&gt; import org.apache.flink.configuration.&lt;/p&gt;
{AkkaOptions, Configuration, IllegalConfigurationException}
&lt;p&gt; import org.apache.flink.runtime.highavailability.HighAvailabilityServicesUtils.AddressResolution&lt;br/&gt;
@@ -167,30 +167,4 @@ class AkkaUtilsTest&lt;br/&gt;
     akkaConfig.getString(&quot;akka.remote.netty.tcp.hostname&quot;) should&lt;br/&gt;
       equal(NetUtils.unresolvedHostToNormalizedString(hostname))&lt;br/&gt;
   }&lt;br/&gt;
-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;test(&quot;null hostname should go to localhost&quot;) 
{
-    val configure = AkkaUtils.getAkkaConfig(new Configuration(), Some((null, 1772)))
-
-    val hostname = configure.getString(&quot;akka.remote.netty.tcp.hostname&quot;)
-
-    InetAddress.getByName(hostname).isLoopbackAddress should be(true)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;test(&quot;getAkkaConfig defaults to fork-join-executor&quot;) 
{
-    val akkaConfig = AkkaUtils.getAkkaConfig(new Configuration())
-
-    akkaConfig.getString(&quot;akka.actor.default-dispatcher.executor&quot;) should
-      equal(&quot;fork-join-executor&quot;)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;test(&quot;getAkkaConfig respects executor config&quot;) 
{
-    val akkaConfig = AkkaUtils.getAkkaConfig(
-      new Configuration(),
-      &quot;localhost&quot;,
-      1234,
-      AkkaUtils.getThreadPoolExecutorConfig)
-
-    akkaConfig.getString(&quot;akka.actor.default-dispatcher.executor&quot;) should
-      equal(&quot;thread-pool-executor&quot;)
-  }
&lt;p&gt; }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16652463" author="githubbot" created="Tue, 16 Oct 2018 21:22:00 +0000"  >&lt;p&gt;asfgit closed pull request #6858: Revert &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10354&quot; title=&quot;Savepoints should be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10354&quot;&gt;&lt;del&gt;FLINK-10354&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10247&quot; title=&quot;Run MetricQueryService in separate thread pool&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10247&quot;&gt;&lt;del&gt;FLINK-10247&lt;/del&gt;&lt;/a&gt; for release-1.5&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6858&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6858&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/docs/_includes/generated/metric_configuration.html b/docs/_includes/generated/metric_configuration.html&lt;br/&gt;
index cba93e47c54..99992b2c7ea 100644&lt;br/&gt;
&amp;#8212; a/docs/_includes/generated/metric_configuration.html&lt;br/&gt;
+++ b/docs/_includes/generated/metric_configuration.html&lt;br/&gt;
@@ -7,11 +7,6 @@&lt;br/&gt;
         &amp;lt;/tr&amp;gt;&lt;br/&gt;
     &amp;lt;/thead&amp;gt;&lt;br/&gt;
     &amp;lt;tbody&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;tr&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;td&amp;gt;&amp;lt;h5&amp;gt;metrics.internal.query-service.port&amp;lt;/h5&amp;gt;&amp;lt;/td&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;td style=&quot;word-wrap: break-word;&quot;&amp;gt;&quot;0&quot;&amp;lt;/td&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;td&amp;gt;The port range used for Flink&apos;s internal metric query service. Accepts a list of ports (&#8220;50100,50101&#8221;), ranges(&#8220;50100-50200&#8221;) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Flink components are running on the same machine. Per default Flink will pick a random port.&amp;lt;/td&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/tr&amp;gt;&lt;br/&gt;
         &amp;lt;tr&amp;gt;&lt;br/&gt;
             &amp;lt;td&amp;gt;&amp;lt;h5&amp;gt;metrics.latency.granularity&amp;lt;/h5&amp;gt;&amp;lt;/td&amp;gt;&lt;br/&gt;
             &amp;lt;td style=&quot;word-wrap: break-word;&quot;&amp;gt;&quot;subtask&quot;&amp;lt;/td&amp;gt;&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java b/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java&lt;br/&gt;
index bbf06eb1784..81744a28d77 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java&lt;br/&gt;
+++ b/flink-core/src/main/java/org/apache/flink/configuration/MetricOptions.java&lt;br/&gt;
@@ -125,18 +125,6 @@&lt;br/&gt;
 			.defaultValue(128)&lt;br/&gt;
 			.withDescription(&quot;Defines the number of measured latencies to maintain at each operator.&quot;);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* The default network port range for Flink&apos;s internal metric query service. The 
{@code &quot;0&quot;}
&lt;p&gt; means that&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* Flink searches for a free port.&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static final ConfigOption&amp;lt;String&amp;gt; QUERY_SERVICE_PORT =&lt;/li&gt;
	&lt;li&gt;key(&quot;metrics.internal.query-service.port&quot;)&lt;/li&gt;
	&lt;li&gt;.defaultValue(&quot;0&quot;)&lt;/li&gt;
	&lt;li&gt;.withDescription(&quot;The port range used for Flink&apos;s internal metric query service. Accepts a list of ports &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;(&#8220;50100,50101&#8221;), ranges(&#8220;50100-50200&#8221;) or a combination of both. It is recommended to set a range of &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;ports to avoid collisions when multiple Flink components are running on the same machine. Per default &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;Flink will pick a random port.&quot;);&lt;br/&gt;
-&lt;br/&gt;
 	private MetricOptions() {&lt;br/&gt;
 	}&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-core/src/main/java/org/apache/flink/types/SerializableOptional.java b/flink-core/src/main/java/org/apache/flink/types/SerializableOptional.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 89dcea45093..00000000000
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-core/src/main/java/org/apache/flink/types/SerializableOptional.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,86 +0,0 @@&lt;br/&gt;
-/*&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one&lt;/li&gt;
	&lt;li&gt;* or more contributor license agreements.  See the NOTICE file&lt;/li&gt;
	&lt;li&gt;* distributed with this work for additional information&lt;/li&gt;
	&lt;li&gt;* regarding copyright ownership.  The ASF licenses this file&lt;/li&gt;
	&lt;li&gt;* to you under the Apache License, Version 2.0 (the&lt;/li&gt;
	&lt;li&gt;* &quot;License&quot;); you may not use this file except in compliance&lt;/li&gt;
	&lt;li&gt;* with the License.  You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;*     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-&lt;br/&gt;
-package org.apache.flink.types;&lt;br/&gt;
-&lt;br/&gt;
-import javax.annotation.Nonnull;&lt;br/&gt;
-import javax.annotation.Nullable;&lt;br/&gt;
-&lt;br/&gt;
-import java.io.Serializable;&lt;br/&gt;
-import java.util.NoSuchElementException;&lt;br/&gt;
-import java.util.Optional;&lt;br/&gt;
-import java.util.function.Consumer;&lt;br/&gt;
-import java.util.function.Function;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;/li&gt;
	&lt;li&gt;* Serializable 
{@link Optional}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-public final class SerializableOptional&amp;lt;T extends Serializable&amp;gt; implements Serializable {&lt;/li&gt;
	&lt;li&gt;private static final long serialVersionUID = -3312769593551775940L;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static final SerializableOptional&amp;lt;?&amp;gt; EMPTY = new SerializableOptional&amp;lt;&amp;gt;(null);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@Nullable&lt;/li&gt;
	&lt;li&gt;private final T value;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private SerializableOptional(@Nullable T value) 
{
-		this.value = value;
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public T get() {&lt;/li&gt;
	&lt;li&gt;if (value == null) 
{
-			throw new NoSuchElementException(&quot;No value present&quot;);
-		}&lt;/li&gt;
	&lt;li&gt;return value;&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public boolean isPresent() 
{
-		return value != null;
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public void ifPresent(Consumer&amp;lt;? super T&amp;gt; consumer) {&lt;/li&gt;
	&lt;li&gt;if (value != null) 
{
-			consumer.accept(value);
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public &amp;lt;R&amp;gt; Optional&amp;lt;R&amp;gt; map(Function&amp;lt;? super T, ? extends R&amp;gt; mapper) {&lt;/li&gt;
	&lt;li&gt;if (value == null) 
{
-			return Optional.empty();
-		}
&lt;p&gt; else &lt;/p&gt;
{
-			return Optional.ofNullable(mapper.apply(value));
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;T extends Serializable&amp;gt; SerializableOptional&amp;lt;T&amp;gt; of(@Nonnull T value) 
{
-		return new SerializableOptional&amp;lt;&amp;gt;(value);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;T extends Serializable&amp;gt; SerializableOptional&amp;lt;T&amp;gt; ofNullable(@Nullable T value) {&lt;/li&gt;
	&lt;li&gt;if (value == null) 
{
-			return empty();
-		}
&lt;p&gt; else &lt;/p&gt;
{
-			return of(value);
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;T extends Serializable&amp;gt; SerializableOptional&amp;lt;T&amp;gt; empty() 
{
-		return (SerializableOptional&amp;lt;T&amp;gt;) EMPTY;
-	}
&lt;p&gt;-}&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
index 1ee2eceffe7..82227cdae98 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java&lt;br/&gt;
@@ -838,22 +838,28 @@ private void completePendingCheckpoint(PendingCheckpoint pendingCheckpoint) thro&lt;br/&gt;
 			// the pending checkpoint must be discarded after the finalization&lt;br/&gt;
 			Preconditions.checkState(pendingCheckpoint.isDiscarded() &amp;amp;&amp;amp; completedCheckpoint != null);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
-				completedCheckpointStore.addCheckpoint(completedCheckpoint);
-			}
&lt;p&gt; catch (Exception exception) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// we failed to store the completed checkpoint. Let&apos;s clean up&lt;/li&gt;
	&lt;li&gt;executor.execute(new Runnable() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void run() {&lt;/li&gt;
	&lt;li&gt;try 
{
-							completedCheckpoint.discardOnFailedStoring();
-						}
&lt;p&gt; catch (Throwable t) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not properly discard completed checkpoint {}.&quot;, completedCheckpoint.getCheckpointID(), t);&lt;br/&gt;
+			// TODO: add savepoints to completed checkpoint store once &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; title=&quot;Automatic fallback to earlier checkpoints when checkpoint restore fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4815&quot;&gt;FLINK-4815&lt;/a&gt; has been completed&lt;br/&gt;
+			if (!completedCheckpoint.getProperties().isSavepoint()) {&lt;br/&gt;
+				try 
{
+					completedCheckpointStore.addCheckpoint(completedCheckpoint);
+				}
&lt;p&gt; catch (Exception exception) {&lt;br/&gt;
+					// we failed to store the completed checkpoint. Let&apos;s clean up&lt;br/&gt;
+					executor.execute(new Runnable() {&lt;br/&gt;
+						@Override&lt;br/&gt;
+						public void run() {&lt;br/&gt;
+							try &lt;/p&gt;
{
+								completedCheckpoint.discardOnFailedStoring();
+							}
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
+								LOG.warn(&quot;Could not properly discard completed checkpoint {} of job {}.&quot;, completedCheckpoint.getCheckpointID(), job, t);&lt;br/&gt;
+							}&lt;br/&gt;
 						}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;});&lt;br/&gt;
+					});&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;throw new CheckpointException(&quot;Could not complete the pending checkpoint &quot; + checkpointId + &apos;.&apos;, exception);&lt;br/&gt;
+					throw new CheckpointException(&quot;Could not complete the pending checkpoint &quot; + checkpointId + &apos;.&apos;, exception);&lt;br/&gt;
+				}&lt;br/&gt;
+&lt;br/&gt;
+				// drop those pending checkpoints that are at prior to the completed one&lt;br/&gt;
+				dropSubsumedCheckpoints(checkpointId);&lt;br/&gt;
 			}&lt;br/&gt;
 		} finally {&lt;br/&gt;
 			pendingCheckpoints.remove(checkpointId);&lt;br/&gt;
@@ -863,9 +869,6 @@ public void run() {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		rememberRecentCheckpointId(checkpointId);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// drop those pending checkpoints that are at prior to the completed one&lt;/li&gt;
	&lt;li&gt;dropSubsumedCheckpoints(checkpointId);&lt;br/&gt;
-&lt;br/&gt;
 		// record the time when this was completed, to calculate&lt;br/&gt;
 		// the &apos;min delay between checkpoints&apos;&lt;br/&gt;
 		lastCheckpointCompletionNanos = System.nanoTime();&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java b/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java&lt;br/&gt;
index 00b61737d20..56e45762263 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/BootstrapTools.java&lt;br/&gt;
@@ -46,7 +46,6 @@&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import javax.annotation.Nonnull;&lt;br/&gt;
 import javax.annotation.Nullable;&lt;/p&gt;

&lt;p&gt; import java.io.File;&lt;br/&gt;
@@ -86,66 +85,13 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@param portRangeDefinition The port range to choose a port from.&lt;/li&gt;
	&lt;li&gt;@param logger The logger to output log information.&lt;/li&gt;
	&lt;li&gt;@return The ActorSystem which has been started&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @throws Exception Thrown when actor system cannot be started in specified port range&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static ActorSystem startActorSystem(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String listeningAddress,&lt;/li&gt;
	&lt;li&gt;String portRangeDefinition,&lt;/li&gt;
	&lt;li&gt;Logger logger) throws Exception 
{
-		return startActorSystem(
-			configuration,
-			listeningAddress,
-			portRangeDefinition,
-			logger,
-			ActorSystemExecutorMode.FORK_JOIN_EXECUTOR);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Starts an ActorSystem with the given configuration listening at the address/ports.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration The Flink configuration&lt;/li&gt;
	&lt;li&gt;* @param listeningAddress The address to listen at.&lt;/li&gt;
	&lt;li&gt;* @param portRangeDefinition The port range to choose a port from.&lt;/li&gt;
	&lt;li&gt;* @param logger The logger to output log information.&lt;/li&gt;
	&lt;li&gt;* @param executorMode The executor mode of Akka actor system.&lt;/li&gt;
	&lt;li&gt;* @return The ActorSystem which has been started&lt;/li&gt;
	&lt;li&gt;* @throws Exception Thrown when actor system cannot be started in specified port range&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static ActorSystem startActorSystem(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String listeningAddress,&lt;/li&gt;
	&lt;li&gt;String portRangeDefinition,&lt;/li&gt;
	&lt;li&gt;Logger logger,&lt;/li&gt;
	&lt;li&gt;@Nonnull ActorSystemExecutorMode executorMode) throws Exception 
{
-		return startActorSystem(
-			configuration,
-			AkkaUtils.getFlinkActorSystemName(),
-			listeningAddress,
-			portRangeDefinition,
-			logger,
-			executorMode);
-	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Starts an ActorSystem with the given configuration listening at the address/ports.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration The Flink configuration&lt;/li&gt;
	&lt;li&gt;* @param actorSystemName Name of the started 
{@link ActorSystem}&lt;br/&gt;
-	 * @param listeningAddress The address to listen at.&lt;br/&gt;
-	 * @param portRangeDefinition The port range to choose a port from.&lt;br/&gt;
-	 * @param logger The logger to output log information.&lt;br/&gt;
-	 * @param executorMode The executor mode of Akka actor system.&lt;br/&gt;
-	 * @return The ActorSystem which has been started&lt;br/&gt;
-	 * @throws Exception Thrown when actor system cannot be started in specified port range&lt;br/&gt;
+	 * @throws Exception&lt;br/&gt;
 	 */&lt;br/&gt;
 	public static ActorSystem startActorSystem(&lt;br/&gt;
 			Configuration configuration,&lt;br/&gt;
-			String actorSystemName,&lt;br/&gt;
 			String listeningAddress,&lt;br/&gt;
 			String portRangeDefinition,&lt;br/&gt;
-			Logger logger,&lt;br/&gt;
-			@Nonnull ActorSystemExecutorMode executorMode) throws Exception {&lt;br/&gt;
+			Logger logger) throws Exception {
 
 		// parse port range definition and create port iterator
 		Iterator&amp;lt;Integer&amp;gt; portsIterator;
@@ -171,13 +117,7 @@ public static ActorSystem startActorSystem(
 			}&lt;br/&gt;
 &lt;br/&gt;
 			try {
-				return startActorSystem(
-					configuration,
-					actorSystemName,
-					listeningAddress,
-					port,
-					logger,
-					executorMode);
+				return startActorSystem(configuration, listeningAddress, port, logger);
 			}&lt;br/&gt;
 			catch (Exception e) {&lt;br/&gt;
 				// we can continue to try if this contains a netty channel exception&lt;br/&gt;
@@ -196,7 +136,6 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 &lt;br/&gt;
 	/**&lt;br/&gt;
 	 * Starts an Actor System at a specific port.&lt;br/&gt;
-	 *&lt;br/&gt;
 	 * @param configuration The Flink configuration.&lt;br/&gt;
 	 * @param listeningAddress The address to listen at.&lt;br/&gt;
 	 * @param listeningPort The port to listen at.&lt;br/&gt;
@@ -204,57 +143,11 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 	 * @return The ActorSystem which has been started.&lt;br/&gt;
 	 * @throws Exception&lt;br/&gt;
 	 */&lt;br/&gt;
-	public static ActorSystem startActorSystem(&lt;br/&gt;
-		Configuration configuration,&lt;br/&gt;
-		String listeningAddress,&lt;br/&gt;
-		int listeningPort,&lt;br/&gt;
-		Logger logger) throws Exception {
-		return startActorSystem(configuration, listeningAddress, listeningPort, logger, ActorSystemExecutorMode.FORK_JOIN_EXECUTOR);
-	}&lt;br/&gt;
-&lt;br/&gt;
-	/**&lt;br/&gt;
-	 * Starts an Actor System at a specific port.&lt;br/&gt;
-	 * @param configuration The Flink configuration.&lt;br/&gt;
-	 * @param listeningAddress The address to listen at.&lt;br/&gt;
-	 * @param listeningPort The port to listen at.&lt;br/&gt;
-	 * @param logger the logger to output log information.&lt;br/&gt;
-	 * @param executorMode The executor mode of Akka actor system.&lt;br/&gt;
-	 * @return The ActorSystem which has been started.&lt;br/&gt;
-	 * @throws Exception&lt;br/&gt;
-	 */&lt;br/&gt;
 	public static ActorSystem startActorSystem(&lt;br/&gt;
 				Configuration configuration,&lt;br/&gt;
 				String listeningAddress,&lt;br/&gt;
 				int listeningPort,&lt;br/&gt;
-				Logger logger,&lt;br/&gt;
-				ActorSystemExecutorMode executorMode) throws Exception {
-		return startActorSystem(
-			configuration,
-			AkkaUtils.getFlinkActorSystemName(),
-			listeningAddress,
-			listeningPort,
-			logger,
-			executorMode);
-	}&lt;br/&gt;
-&lt;br/&gt;
-	/**&lt;br/&gt;
-	 * Starts an Actor System at a specific port.&lt;br/&gt;
-	 * @param configuration The Flink configuration.&lt;br/&gt;
-	 * @param actorSystemName Name of the started {@link ActorSystem}&lt;/li&gt;
	&lt;li&gt;* @param listeningAddress The address to listen at.&lt;/li&gt;
	&lt;li&gt;* @param listeningPort The port to listen at.&lt;/li&gt;
	&lt;li&gt;* @param logger the logger to output log information.&lt;/li&gt;
	&lt;li&gt;* @param executorMode The executor mode of Akka actor system.&lt;/li&gt;
	&lt;li&gt;* @return The ActorSystem which has been started.&lt;/li&gt;
	&lt;li&gt;* @throws Exception&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public static ActorSystem startActorSystem(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String actorSystemName,&lt;/li&gt;
	&lt;li&gt;String listeningAddress,&lt;/li&gt;
	&lt;li&gt;int listeningPort,&lt;/li&gt;
	&lt;li&gt;Logger logger,&lt;/li&gt;
	&lt;li&gt;ActorSystemExecutorMode executorMode) throws Exception {&lt;br/&gt;
+				Logger logger) throws Exception {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		String hostPortUrl = NetUtils.unresolvedHostAndPortToNormalizedString(listeningAddress, listeningPort);&lt;br/&gt;
 		logger.info(&quot;Trying to start actor system at {}&quot;, hostPortUrl);&lt;br/&gt;
@@ -262,13 +155,12 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 		try {&lt;br/&gt;
 			Config akkaConfig = AkkaUtils.getAkkaConfig(&lt;br/&gt;
 				configuration,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new Some&amp;lt;&amp;gt;(new Tuple2&amp;lt;&amp;gt;(listeningAddress, listeningPort)),&lt;/li&gt;
	&lt;li&gt;getExecutorConfigByExecutorMode(configuration, executorMode)&lt;br/&gt;
+				new Some&amp;lt;&amp;gt;(new Tuple2&amp;lt;&amp;gt;(listeningAddress, listeningPort))&lt;br/&gt;
 			);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			logger.debug(&quot;Using akka configuration\n {}&quot;, akkaConfig);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ActorSystem actorSystem = AkkaUtils.createActorSystem(actorSystemName, akkaConfig);&lt;br/&gt;
+			ActorSystem actorSystem = AkkaUtils.createActorSystem(akkaConfig);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			logger.info(&quot;Actor system started at {}&quot;, AkkaUtils.getAddress(actorSystem));&lt;br/&gt;
 			return actorSystem;&lt;br/&gt;
@@ -278,24 +170,13 @@ public static ActorSystem startActorSystem(&lt;br/&gt;
 				Throwable cause = t.getCause();&lt;br/&gt;
 				if (cause != null &amp;amp;&amp;amp; t.getCause() instanceof BindException) &lt;/p&gt;
{
 					throw new IOException(&quot;Unable to create ActorSystem at address &quot; + hostPortUrl +
-						&quot; : &quot; + cause.getMessage(), t);
+							&quot; : &quot; + cause.getMessage(), t);
 				}
&lt;p&gt; 			}&lt;br/&gt;
 			throw new Exception(&quot;Could not create actor system&quot;, t);&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static Config getExecutorConfigByExecutorMode(Configuration configuration, ActorSystemExecutorMode executorMode) {&lt;/li&gt;
	&lt;li&gt;switch (executorMode) 
{
-			case FORK_JOIN_EXECUTOR:
-				return AkkaUtils.getForkJoinExecutorConfig(configuration);
-			case FIXED_THREAD_POOL_EXECUTOR:
-				return AkkaUtils.getThreadPoolExecutorConfig();
-			default:
-				throw new IllegalArgumentException(String.format(&quot;Unknown ActorSystemExecutorMode %s.&quot;, executorMode));
-		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
 	/**&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Starts the web frontend.&lt;br/&gt;
 	 *&lt;br/&gt;
@@ -623,14 +504,4 @@ public static Configuration cloneConfiguration(Configuration configuration) 
{
 
 		return clonedConfiguration;
 	}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Options to specify which executor to use in an 
{@link ActorSystem}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;public enum ActorSystemExecutorMode 
{
-		/** Used by default, use dispatcher with fork-join-executor. **/
-		FORK_JOIN_EXECUTOR,
-		/** Use dispatcher with fixed thread pool executor. **/
-		FIXED_THREAD_POOL_EXECUTOR
-	}
&lt;p&gt; }&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java&lt;br/&gt;
index 53349e2f2c8..2c34b530804 100755&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java&lt;br/&gt;
@@ -95,8 +95,6 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import scala.concurrent.duration.FiniteDuration;&lt;/p&gt;

&lt;p&gt;-import static org.apache.flink.runtime.clusterframework.BootstrapTools.ActorSystemExecutorMode.FORK_JOIN_EXECUTOR;&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Base class for the Flink cluster entry points.&lt;br/&gt;
  *&lt;br/&gt;
@@ -155,9 +153,6 @@&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private WebMonitorEndpoint&amp;lt;?&amp;gt; webMonitorEndpoint;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@GuardedBy(&quot;lock&quot;)&lt;/li&gt;
	&lt;li&gt;private ActorSystem metricQueryServiceActorSystem;&lt;br/&gt;
-&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private ArchivedExecutionGraphStore archivedExecutionGraphStore;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -280,9 +275,9 @@ protected void initializeServices(Configuration configuration) throws Exception&lt;br/&gt;
 			metricRegistry = createMetricRegistry(configuration);&lt;/p&gt;

&lt;p&gt; 			// TODO: This is a temporary hack until we have ported the MetricQueryService to the new RpcEndpoint&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Start actor system for metric query service on any available port&lt;/li&gt;
	&lt;li&gt;metricQueryServiceActorSystem = MetricUtils.startMetricsActorSystem(configuration, bindAddress, LOG);&lt;/li&gt;
	&lt;li&gt;metricRegistry.startQueryService(metricQueryServiceActorSystem, null);&lt;br/&gt;
+			// start the MetricQueryService&lt;br/&gt;
+			final ActorSystem actorSystem = ((AkkaRpcService) commonRpcService).getActorSystem();&lt;br/&gt;
+			metricRegistry.startQueryService(actorSystem, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 			archivedExecutionGraphStore = createSerializableExecutionGraphStore(configuration, commonRpcService.getScheduledExecutor());&lt;/p&gt;

&lt;p&gt;@@ -400,7 +395,7 @@ protected RpcService createRpcService(&lt;br/&gt;
 			Configuration configuration,&lt;br/&gt;
 			String bindAddress,&lt;br/&gt;
 			String portRange) throws Exception &lt;/p&gt;
{
-		ActorSystem actorSystem = BootstrapTools.startActorSystem(configuration, bindAddress, portRange, LOG, FORK_JOIN_EXECUTOR);
+		ActorSystem actorSystem = BootstrapTools.startActorSystem(configuration, bindAddress, portRange, LOG);
 		FiniteDuration duration = AkkaUtils.getTimeout(configuration);
 		return new AkkaRpcService(actorSystem, Time.of(duration.length(), duration.unit()));
 	}
&lt;p&gt;@@ -468,10 +463,6 @@ protected MetricRegistryImpl createMetricRegistry(Configuration configuration) &lt;/p&gt;
{
 				terminationFutures.add(metricRegistry.shutdown());
 			}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (metricQueryServiceActorSystem != null) 
{
-				terminationFutures.add(AkkaUtils.terminateActorSystem(metricQueryServiceActorSystem));
-			}&lt;br/&gt;
-&lt;br/&gt;
 			if (commonRpcService != null) {
 				terminationFutures.add(commonRpcService.stopService());
 			}&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java&lt;br/&gt;
index 39e5f44583c..3fd268a1aeb 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/util/MetricUtils.java&lt;br/&gt;
@@ -18,11 +18,8 @@&lt;br/&gt;
 &lt;br/&gt;
 package org.apache.flink.runtime.metrics.util;&lt;br/&gt;
 &lt;br/&gt;
-import org.apache.flink.configuration.Configuration;&lt;br/&gt;
-import org.apache.flink.configuration.MetricOptions;&lt;br/&gt;
 import org.apache.flink.metrics.Gauge;&lt;br/&gt;
 import org.apache.flink.metrics.MetricGroup;&lt;br/&gt;
-import org.apache.flink.runtime.clusterframework.BootstrapTools;&lt;br/&gt;
 import org.apache.flink.runtime.io.network.NetworkEnvironment;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.MetricRegistry;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;&lt;br/&gt;
@@ -30,7 +27,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskManagerLocation;&lt;br/&gt;
 import org.apache.flink.util.Preconditions;&lt;br/&gt;
 &lt;br/&gt;
-import akka.actor.ActorSystem;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;br/&gt;
 &lt;br/&gt;
@@ -49,15 +45,12 @@&lt;br/&gt;
 import java.lang.management.ThreadMXBean;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 &lt;br/&gt;
-import static org.apache.flink.runtime.clusterframework.BootstrapTools.ActorSystemExecutorMode.FIXED_THREAD_POOL_EXECUTOR;&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;br/&gt;
  * Utility class to register pre-defined metric sets.&lt;br/&gt;
  */&lt;br/&gt;
 public class MetricUtils {&lt;br/&gt;
 	private static final Logger LOG = LoggerFactory.getLogger(MetricUtils.class);&lt;br/&gt;
 	private static final String METRIC_GROUP_STATUS_NAME = &quot;Status&quot;;&lt;br/&gt;
-	private static final String METRICS_ACTOR_SYSTEM_NAME = &quot;flink-metrics&quot;;&lt;br/&gt;
 &lt;br/&gt;
 	private MetricUtils() {&lt;br/&gt;
 	}&lt;br/&gt;
@@ -109,17 +102,6 @@ public static void instantiateStatusMetrics(&lt;br/&gt;
 		instantiateCPUMetrics(jvm.addGroup(&quot;CPU&quot;));&lt;br/&gt;
 	}&lt;br/&gt;
 &lt;br/&gt;
-	public static ActorSystem startMetricsActorSystem(Configuration configuration, String hostname, Logger logger) throws Exception {
-		final String portRange = configuration.getString(MetricOptions.QUERY_SERVICE_PORT);
-		return BootstrapTools.startActorSystem(
-			configuration,
-			METRICS_ACTOR_SYSTEM_NAME,
-			hostname,
-			portRange,
-			logger,
-			FIXED_THREAD_POOL_EXECUTOR);
-	}&lt;br/&gt;
-&lt;br/&gt;
 	private static void instantiateNetworkMetrics(&lt;br/&gt;
 		MetricGroup metrics,&lt;br/&gt;
 		final NetworkEnvironment network) {&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java b/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java&lt;br/&gt;
index 46f7ec3a3a2..a7840d64830 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/minicluster/MiniCluster.java&lt;br/&gt;
@@ -135,9 +135,6 @@&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private RpcService resourceManagerRpcService;&lt;br/&gt;
 &lt;br/&gt;
-	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
-	private ActorSystem metricQueryServiceActorSystem;&lt;br/&gt;
-&lt;br/&gt;
 	@GuardedBy(&quot;lock&quot;)&lt;br/&gt;
 	private HighAvailabilityServices haServices;&lt;br/&gt;
 &lt;br/&gt;
@@ -257,11 +254,8 @@ public void start() throws Exception {&lt;br/&gt;
 				commonRpcService = createRpcService(configuration, rpcTimeout, false, null);&lt;br/&gt;
 &lt;br/&gt;
 				// TODO: Temporary hack until the metric query service is ported to the RpcEndpoint&lt;br/&gt;
-				metricQueryServiceActorSystem = MetricUtils.startMetricsActorSystem(&lt;br/&gt;
-					configuration,&lt;br/&gt;
-					commonRpcService.getAddress(),&lt;br/&gt;
-					LOG);&lt;br/&gt;
-				metricRegistry.startQueryService(metricQueryServiceActorSystem, null);&lt;br/&gt;
+				final ActorSystem actorSystem = ((AkkaRpcService) commonRpcService).getActorSystem();&lt;br/&gt;
+				metricRegistry.startQueryService(actorSystem, null);&lt;br/&gt;
 &lt;br/&gt;
 				if (useSingleRpcService) {&lt;br/&gt;
 					for (int i = 0; i &amp;lt; numTaskManagers; i++) {&lt;br/&gt;
@@ -358,7 +352,7 @@ public void start() throws Exception {&lt;br/&gt;
 						configuration.getInteger(RestOptions.SERVER_NUM_THREADS, 1),&lt;br/&gt;
 						&quot;DispatcherRestEndpoint&quot;),&lt;br/&gt;
 					new AkkaQueryServiceRetriever(&lt;br/&gt;
-						metricQueryServiceActorSystem,&lt;br/&gt;
+						actorSystem,&lt;br/&gt;
 						Time.milliseconds(configuration.getLong(WebOptions.TIMEOUT))),&lt;br/&gt;
 					haServices.getWebMonitorLeaderElectionService(),&lt;br/&gt;
 					new ShutDownFatalErrorHandler());&lt;br/&gt;
@@ -455,12 +449,24 @@ public void start() throws Exception {&lt;br/&gt;
 &lt;br/&gt;
 					final FutureUtils.ConjunctFuture&amp;lt;Void&amp;gt; componentsTerminationFuture = FutureUtils.completeAll(componentTerminationFutures);&lt;br/&gt;
 &lt;br/&gt;
-					final CompletableFuture&amp;lt;Void&amp;gt; metricSystemTerminationFuture = FutureUtils.composeAfterwards(&lt;br/&gt;
+					final CompletableFuture&amp;lt;Void&amp;gt; metricRegistryTerminationFuture = FutureUtils.runAfterwards(&lt;br/&gt;
 						componentsTerminationFuture,&lt;br/&gt;
-						this::closeMetricSystem);&lt;br/&gt;
+						() -&amp;gt; {&lt;br/&gt;
+							synchronized (lock) {&lt;br/&gt;
+								if (jobManagerMetricGroup != null) {
+									jobManagerMetricGroup.close();
+									jobManagerMetricGroup = null;
+								}&lt;br/&gt;
+								// metrics shutdown&lt;br/&gt;
+								if (metricRegistry != null) {
+									metricRegistry.shutdown();
+									metricRegistry = null;
+								}&lt;br/&gt;
+							}&lt;br/&gt;
+						});&lt;br/&gt;
 &lt;br/&gt;
 					// shut down the RpcServices&lt;br/&gt;
-					final CompletableFuture&amp;lt;Void&amp;gt; rpcServicesTerminationFuture = metricSystemTerminationFuture&lt;br/&gt;
+					final CompletableFuture&amp;lt;Void&amp;gt; rpcServicesTerminationFuture = metricRegistryTerminationFuture&lt;br/&gt;
 						.thenCompose((Void ignored) -&amp;gt; terminateRpcServices());&lt;br/&gt;
 &lt;br/&gt;
 					final CompletableFuture&amp;lt;Void&amp;gt; remainingServicesTerminationFuture = FutureUtils.runAfterwards(&lt;br/&gt;
@@ -484,29 +490,6 @@ public void start() throws Exception {&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;br/&gt;
 &lt;br/&gt;
-	private CompletableFuture&amp;lt;Void&amp;gt; closeMetricSystem() {&lt;br/&gt;
-		synchronized (lock) {&lt;br/&gt;
-			if (jobManagerMetricGroup != null) {
-				jobManagerMetricGroup.close();
-				jobManagerMetricGroup = null;
-			}&lt;br/&gt;
-&lt;br/&gt;
-			final ArrayList&amp;lt;CompletableFuture&amp;lt;Void&amp;gt;&amp;gt; terminationFutures = new ArrayList&amp;lt;&amp;gt;(2);&lt;br/&gt;
-&lt;br/&gt;
-			// metrics shutdown&lt;br/&gt;
-			if (metricRegistry != null) {
-				terminationFutures.add(metricRegistry.shutdown());
-				metricRegistry = null;
-			}&lt;br/&gt;
-&lt;br/&gt;
-			if (metricQueryServiceActorSystem != null) {-				terminationFutures.add(AkkaUtils.terminateActorSystem(metricQueryServiceActorSystem));-			}
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;return FutureUtils.completeAll(terminationFutures);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;br/&gt;
 	//  Accessing jobs&lt;br/&gt;
 	// ------------------------------------------------------------------------&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java b/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java&lt;br/&gt;
index a3a075d0f98..d78e3465ec4 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/resourcemanager/ResourceManager.java&lt;br/&gt;
@@ -48,6 +48,7 @@&lt;br/&gt;
 import org.apache.flink.runtime.messages.Acknowledge;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.MetricNames;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.MetricRegistry;&lt;br/&gt;
+import org.apache.flink.runtime.metrics.dump.MetricQueryService;&lt;br/&gt;
 import org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;&lt;br/&gt;
 import org.apache.flink.runtime.registration.RegistrationResponse;&lt;br/&gt;
 import org.apache.flink.runtime.resourcemanager.exceptions.ResourceManagerException;&lt;br/&gt;
@@ -75,13 +76,11 @@&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Objects;&lt;br/&gt;
-import java.util.Optional;&lt;br/&gt;
 import java.util.UUID;&lt;br/&gt;
 import java.util.concurrent.CompletableFuture;&lt;br/&gt;
 import java.util.concurrent.ConcurrentHashMap;&lt;br/&gt;
 import java.util.concurrent.ConcurrentMap;&lt;br/&gt;
 import java.util.concurrent.TimeoutException;&lt;br/&gt;
-import java.util.stream.Collectors;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import static org.apache.flink.util.Preconditions.checkNotNull;&lt;/p&gt;

&lt;p&gt;@@ -594,26 +593,19 @@ public void unRegisterInfoMessageListener(final String address) {&lt;/p&gt;

&lt;p&gt; 	@Override&lt;br/&gt;
 	public CompletableFuture&amp;lt;Collection&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt;&amp;gt; requestTaskManagerMetricQueryServicePaths(Time timeout) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ArrayList&amp;lt;CompletableFuture&amp;lt;Optional&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt;&amp;gt;&amp;gt; metricQueryServicePathFutures = new ArrayList&amp;lt;&amp;gt;(taskExecutors.size());&lt;br/&gt;
+		final ArrayList&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt; metricQueryServicePaths = new ArrayList&amp;lt;&amp;gt;(taskExecutors.size());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		for (Map.Entry&amp;lt;ResourceID, WorkerRegistration&amp;lt;WorkerType&amp;gt;&amp;gt; workerRegistrationEntry : taskExecutors.entrySet()) &lt;/p&gt;
{
 			final ResourceID tmResourceId = workerRegistrationEntry.getKey();
 			final WorkerRegistration&amp;lt;WorkerType&amp;gt; workerRegistration = workerRegistrationEntry.getValue();
-			final TaskExecutorGateway taskExecutorGateway = workerRegistration.getTaskExecutorGateway();
+			final String taskManagerAddress = workerRegistration.getTaskExecutorGateway().getAddress();
+			final String tmMetricQueryServicePath = taskManagerAddress.substring(0, taskManagerAddress.lastIndexOf(&apos;/&apos;) + 1) +
+				MetricQueryService.METRIC_QUERY_SERVICE_NAME + &apos;_&apos; + tmResourceId.getResourceIdString();
 
-			final CompletableFuture&amp;lt;Optional&amp;lt;Tuple2&amp;lt;ResourceID, String&amp;gt;&amp;gt;&amp;gt; metricQueryServicePathFuture = taskExecutorGateway
-				.requestMetricQueryServiceAddress(timeout)
-				.thenApply(optional -&amp;gt; optional.map(path -&amp;gt; Tuple2.of(tmResourceId, path)));
-
-			metricQueryServicePathFutures.add(metricQueryServicePathFuture);
+			metricQueryServicePaths.add(Tuple2.of(tmResourceId, tmMetricQueryServicePath));
 		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return FutureUtils.combineAll(metricQueryServicePathFutures).thenApply(&lt;/li&gt;
	&lt;li&gt;collection -&amp;gt; collection&lt;/li&gt;
	&lt;li&gt;.stream()&lt;/li&gt;
	&lt;li&gt;.filter(Optional::isPresent)&lt;/li&gt;
	&lt;li&gt;.map(Optional::get)&lt;/li&gt;
	&lt;li&gt;.collect(Collectors.toList()));&lt;br/&gt;
+		return CompletableFuture.completedFuture(metricQueryServicePaths);&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	@Override&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java b/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java&lt;br/&gt;
index ac1a1873782..1f7ec12388e 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/rpc/akka/AkkaRpcServiceUtils.java&lt;br/&gt;
@@ -70,10 +70,7 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@throws IOException      Thrown, if the actor system can not bind to the address&lt;/li&gt;
	&lt;li&gt;@throws Exception      Thrown is some other error occurs while creating akka actor system&lt;br/&gt;
 	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static RpcService createRpcService(&lt;/li&gt;
	&lt;li&gt;String hostname,&lt;/li&gt;
	&lt;li&gt;int port,&lt;/li&gt;
	&lt;li&gt;Configuration configuration) throws Exception {&lt;br/&gt;
+	public static RpcService createRpcService(String hostname, int port, Configuration configuration) throws Exception {&lt;br/&gt;
 		LOG.info(&quot;Starting AkkaRpcService at {}.&quot;, NetUtils.unresolvedHostAndPortToNormalizedString(hostname, port));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		final ActorSystem actorSystem;&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java&lt;br/&gt;
index 3d06efda85e..665f07293c7 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutor.java&lt;br/&gt;
@@ -101,7 +101,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskExecutionState;&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskManagerActions;&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.TaskManagerLocation;&lt;br/&gt;
-import org.apache.flink.types.SerializableOptional;&lt;br/&gt;
 import org.apache.flink.util.ExceptionUtils;&lt;br/&gt;
 import org.apache.flink.util.FlinkException;&lt;/p&gt;

&lt;p&gt;@@ -157,10 +156,6 @@&lt;/p&gt;

&lt;p&gt; 	private final BlobCacheService blobCacheService;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/** The path to metric query service on this Task Manager. */&lt;/li&gt;
	&lt;li&gt;@Nullable&lt;/li&gt;
	&lt;li&gt;private final String metricQueryServicePath;&lt;br/&gt;
-&lt;br/&gt;
 	// --------- TaskManager services --------&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	/** The connection information of this task manager. */&lt;br/&gt;
@@ -213,7 +208,6 @@ public TaskExecutor(&lt;br/&gt;
 			TaskManagerServices taskExecutorServices,&lt;br/&gt;
 			HeartbeatServices heartbeatServices,&lt;br/&gt;
 			TaskManagerMetricGroup taskManagerMetricGroup,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Nullable String metricQueryServicePath,&lt;br/&gt;
 			BlobCacheService blobCacheService,&lt;br/&gt;
 			FatalErrorHandler fatalErrorHandler) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -227,7 +221,6 @@ public TaskExecutor(&lt;br/&gt;
 		this.fatalErrorHandler = checkNotNull(fatalErrorHandler);&lt;br/&gt;
 		this.taskManagerMetricGroup = checkNotNull(taskManagerMetricGroup);&lt;br/&gt;
 		this.blobCacheService = checkNotNull(blobCacheService);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.metricQueryServicePath = metricQueryServicePath;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		this.taskSlotTable = taskExecutorServices.getTaskSlotTable();&lt;br/&gt;
 		this.jobManagerTable = taskExecutorServices.getJobManagerTable();&lt;br/&gt;
@@ -848,11 +841,6 @@ public void heartbeatFromResourceManager(ResourceID resourceID) {&lt;br/&gt;
 		}&lt;br/&gt;
 	}&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public CompletableFuture&amp;lt;SerializableOptional&amp;lt;String&amp;gt;&amp;gt; requestMetricQueryServiceAddress(Time timeout) 
{
-		return CompletableFuture.completedFuture(SerializableOptional.ofNullable(metricQueryServicePath));
-	}
&lt;p&gt;-&lt;br/&gt;
 	// ----------------------------------------------------------------------&lt;br/&gt;
 	// Disconnection RPCs&lt;br/&gt;
 	// ----------------------------------------------------------------------&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java&lt;br/&gt;
index d6b9e152e8f..4f792896216 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskExecutorGateway.java&lt;br/&gt;
@@ -36,7 +36,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.rpc.RpcGateway;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.RpcTimeout;&lt;br/&gt;
 import org.apache.flink.runtime.taskmanager.Task;&lt;br/&gt;
-import org.apache.flink.types.SerializableOptional;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.util.concurrent.CompletableFuture;&lt;/p&gt;

&lt;p&gt;@@ -196,11 +195,4 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@return Future which is completed with the 
{@link TransientBlobKey}
&lt;p&gt; of the uploaded file.&lt;br/&gt;
 	 */&lt;br/&gt;
 	CompletableFuture&amp;lt;TransientBlobKey&amp;gt; requestFileUpload(FileType fileType, @RpcTimeout Time timeout);&lt;br/&gt;
-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Returns the fully qualified address of Metric Query Service on the TaskManager.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @return Future String with Fully qualified (RPC) address of Metric Query Service on the TaskManager.&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;CompletableFuture&amp;lt;SerializableOptional&amp;lt;String&amp;gt;&amp;gt; requestMetricQueryServiceAddress(@RpcTimeout Time timeout);&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java&lt;br/&gt;
index 2d17883a606..1cd61fea17f 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java&lt;br/&gt;
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java&lt;br/&gt;
@@ -39,6 +39,7 @@&lt;br/&gt;
 import org.apache.flink.runtime.metrics.util.MetricUtils;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.FatalErrorHandler;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.RpcService;&lt;br/&gt;
+import org.apache.flink.runtime.rpc.akka.AkkaRpcService;&lt;br/&gt;
 import org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils;&lt;br/&gt;
 import org.apache.flink.runtime.security.SecurityConfiguration;&lt;br/&gt;
 import org.apache.flink.runtime.security.SecurityUtils;&lt;br/&gt;
@@ -96,8 +97,6 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	private final RpcService rpcService;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final ActorSystem metricQueryServiceActorSystem;&lt;br/&gt;
-&lt;br/&gt;
 	private final HighAvailabilityServices highAvailabilityServices;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	private final MetricRegistryImpl metricRegistry;&lt;br/&gt;
@@ -129,14 +128,14 @@ public TaskManagerRunner(Configuration configuration, ResourceID resourceId) thr&lt;br/&gt;
 			HighAvailabilityServicesUtils.AddressResolution.TRY_ADDRESS_RESOLUTION);&lt;/p&gt;

&lt;p&gt; 		rpcService = createRpcService(configuration, highAvailabilityServices);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;metricQueryServiceActorSystem = MetricUtils.startMetricsActorSystem(configuration, rpcService.getAddress(), LOG);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		HeartbeatServices heartbeatServices = HeartbeatServices.fromConfiguration(configuration);&lt;/p&gt;

&lt;p&gt; 		metricRegistry = new MetricRegistryImpl(MetricRegistryConfiguration.fromConfiguration(configuration));&lt;/p&gt;

&lt;p&gt; 		// TODO: Temporary hack until the MetricQueryService has been ported to RpcEndpoint&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;metricRegistry.startQueryService(metricQueryServiceActorSystem, resourceId);&lt;br/&gt;
+		final ActorSystem actorSystem = ((AkkaRpcService) rpcService).getActorSystem();&lt;br/&gt;
+		metricRegistry.startQueryService(actorSystem, resourceId);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		blobCacheService = new BlobCacheService(&lt;br/&gt;
 			configuration, highAvailabilityServices.createBlobStore(), null&lt;br/&gt;
@@ -156,7 +155,7 @@ public TaskManagerRunner(Configuration configuration, ResourceID resourceId) thr&lt;br/&gt;
 		this.terminationFuture = new CompletableFuture&amp;lt;&amp;gt;();&lt;br/&gt;
 		this.shutdown = false;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;MemoryLogger.startIfConfigured(LOG, configuration, metricQueryServiceActorSystem);&lt;br/&gt;
+		MemoryLogger.startIfConfigured(LOG, configuration, actorSystem);&lt;br/&gt;
 	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	// --------------------------------------------------------------------------------------------&lt;br/&gt;
@@ -211,10 +210,6 @@ public void start() throws Exception &lt;/p&gt;
{
 				exception = ExceptionUtils.firstOrSuppressed(e, exception);
 			}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (metricQueryServiceActorSystem != null) 
{
-				terminationFutures.add(AkkaUtils.terminateActorSystem(metricQueryServiceActorSystem));
-			}
&lt;p&gt;-&lt;br/&gt;
 			try &lt;/p&gt;
{
 				highAvailabilityServices.close();
 			}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
@@ -361,8 +356,6 @@ public static TaskExecutor startTaskManager(
 
 		TaskManagerConfiguration taskManagerConfiguration = TaskManagerConfiguration.fromConfiguration(configuration);
 
-		String metricQueryServicePath = metricRegistry.getMetricQueryServicePath();
-
 		return new TaskExecutor(
 			rpcService,
 			taskManagerConfiguration,
@@ -370,7 +363,6 @@ public static TaskExecutor startTaskManager(
 			taskManagerServices,
 			heartbeatServices,
 			taskManagerMetricGroup,
-			metricQueryServicePath,
 			blobCacheService,
 			fatalErrorHandler);
 	}
&lt;p&gt;@@ -407,14 +399,6 @@ public static RpcService createRpcService(&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		final String portRangeDefinition = configuration.getString(TaskManagerOptions.RPC_PORT);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return bindWithPort(configuration, taskManagerHostname, portRangeDefinition);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static RpcService bindWithPort(&lt;/li&gt;
	&lt;li&gt;Configuration configuration,&lt;/li&gt;
	&lt;li&gt;String taskManagerHostname,&lt;/li&gt;
	&lt;li&gt;String portRangeDefinition) throws Exception{&lt;br/&gt;
-&lt;br/&gt;
 		// parse port range definition and create port iterator&lt;br/&gt;
 		Iterator&amp;lt;Integer&amp;gt; portsIterator;&lt;br/&gt;
 		try {&lt;br/&gt;
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala&lt;br/&gt;
index 39b287e2d30..6e161f78091 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala&lt;br/&gt;
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala&lt;br/&gt;
@@ -50,12 +50,6 @@ object AkkaUtils {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   val INF_TIMEOUT: FiniteDuration = 21474835 seconds&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val FLINK_ACTOR_SYSTEM_NAME = &quot;flink&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def getFlinkActorSystemName = 
{
-    FLINK_ACTOR_SYSTEM_NAME
-  }
&lt;p&gt;-&lt;br/&gt;
   /**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Creates a local actor system without remoting.&lt;br/&gt;
    *&lt;br/&gt;
@@ -109,19 +103,9 @@ object AkkaUtils {&lt;/li&gt;
	&lt;li&gt;@return created actor system&lt;br/&gt;
    */&lt;br/&gt;
   def createActorSystem(akkaConfig: Config): ActorSystem = 
{
-    createActorSystem(FLINK_ACTOR_SYSTEM_NAME, akkaConfig)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Creates an actor system with the given akka config.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param akkaConfig configuration for the actor system&lt;/li&gt;
	&lt;li&gt;* @return created actor system&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;def createActorSystem(actorSystemName: String, akkaConfig: Config): ActorSystem = 
{
     // Initialize slf4j as logger of Akka&apos;s Netty instead of java.util.logging (FLINK-1650)
     InternalLoggerFactory.setDefaultFactory(new Slf4JLoggerFactory)
-    ActorSystem.create(actorSystemName, akkaConfig)
+    ActorSystem.create(&quot;flink&quot;, akkaConfig)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;br/&gt;
@@ -135,23 +119,7 @@ object AkkaUtils {&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;   /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Returns a remote Akka config for the given configuration values.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration containing the user provided configuration values&lt;/li&gt;
	&lt;li&gt;* @param hostname to bind against. If null, then the loopback interface is used&lt;/li&gt;
	&lt;li&gt;* @param port to bind against&lt;/li&gt;
	&lt;li&gt;* @param executorMode containing the user specified mode of executor&lt;/li&gt;
	&lt;li&gt;* @return A remote Akka config&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;def getAkkaConfig(configuration: Configuration,&lt;/li&gt;
	&lt;li&gt;hostname: String,&lt;/li&gt;
	&lt;li&gt;port: Int,&lt;/li&gt;
	&lt;li&gt;executorConfig: Config): Config = 
{
-    getAkkaConfig(configuration, Some((hostname, port)), executorConfig)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Returns a remote Akka config for the given configuration values.&lt;br/&gt;
+    * Return a remote Akka config for the given configuration values.&lt;br/&gt;
     *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param configuration containing the user provided configuration values&lt;/li&gt;
	&lt;li&gt;@param hostname to bind against. If null, then the loopback interface is used&lt;br/&gt;
@@ -187,25 +155,7 @@ object AkkaUtils {&lt;br/&gt;
   @throws(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;UnknownHostException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
   def getAkkaConfig(configuration: Configuration,&lt;br/&gt;
                     externalAddress: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;(String, Int)&amp;#93;&lt;/span&gt;): Config = 
{
-    getAkkaConfig(configuration, externalAddress, getForkJoinExecutorConfig(configuration))
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Creates an akka config with the provided configuration values. If the listening address is&lt;/li&gt;
	&lt;li&gt;* specified, then the actor system will listen on the respective address.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param configuration instance containing the user provided configuration values&lt;/li&gt;
	&lt;li&gt;* @param externalAddress optional tuple of bindAddress and port to be reachable at.&lt;/li&gt;
	&lt;li&gt;*                        If None is given, then an Akka config for local actor system&lt;/li&gt;
	&lt;li&gt;*                        will be returned&lt;/li&gt;
	&lt;li&gt;* @param executorConfig config defining the used executor by the default dispatcher&lt;/li&gt;
	&lt;li&gt;* @return Akka config&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;@throws(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;UnknownHostException&amp;#93;&lt;/span&gt;)&lt;/li&gt;
	&lt;li&gt;def getAkkaConfig(configuration: Configuration,&lt;/li&gt;
	&lt;li&gt;externalAddress: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;(String, Int)&amp;#93;&lt;/span&gt;,&lt;/li&gt;
	&lt;li&gt;executorConfig: Config): Config = {&lt;/li&gt;
	&lt;li&gt;val defaultConfig = getBasicAkkaConfig(configuration).withFallback(executorConfig)&lt;br/&gt;
+    val defaultConfig = getBasicAkkaConfig(configuration)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     externalAddress match {&lt;/p&gt;

&lt;p&gt;@@ -257,6 +207,24 @@ object AkkaUtils {&lt;br/&gt;
     val supervisorStrategy = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;StoppingSupervisorWithoutLoggingActorKilledExceptionStrategy&amp;#93;&lt;/span&gt;&lt;br/&gt;
       .getCanonicalName&lt;/p&gt;

&lt;p&gt;+    val forkJoinExecutorParallelismFactor =&lt;br/&gt;
+      configuration.getDouble(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_FACTOR)&lt;br/&gt;
+&lt;br/&gt;
+    val forkJoinExecutorParallelismMin =&lt;br/&gt;
+      configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MIN)&lt;br/&gt;
+&lt;br/&gt;
+    val forkJoinExecutorParallelismMax =&lt;br/&gt;
+      configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MAX)&lt;br/&gt;
+&lt;br/&gt;
+    val forkJoinExecutorConfig =&lt;br/&gt;
+      s&quot;&quot;&quot;&lt;br/&gt;
+         | fork-join-executor &lt;/p&gt;
{
+         |   parallelism-factor = $forkJoinExecutorParallelismFactor
+         |   parallelism-min = $forkJoinExecutorParallelismMin
+         |   parallelism-max = $forkJoinExecutorParallelismMax
+         | }
&lt;p&gt;+       &quot;&quot;&quot;.stripMargin&lt;br/&gt;
+&lt;br/&gt;
     val config =&lt;br/&gt;
       s&quot;&quot;&quot;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;akka {&lt;br/&gt;
@@ -283,6 +251,8 @@ object AkkaUtils {&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   default-dispatcher 
{
         |     throughput = $akkaThroughput
+        |
+        |   $forkJoinExecutorConfig
         |   }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;}&lt;br/&gt;
@@ -291,53 +261,6 @@ object AkkaUtils 
{
     ConfigFactory.parseString(config)
   }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def getThreadPoolExecutorConfig: Config = {&lt;/li&gt;
	&lt;li&gt;val configString = s&quot;&quot;&quot;&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;akka {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  actor {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    default-dispatcher {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      executor = &quot;thread-pool-executor&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      thread-pool-executor 
{
-       |        core-pool-size-min = 2
-       |        core-pool-size-factor = 2.0
-       |        core-pool-size-max = 4
-       |      }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;.&lt;/li&gt;
	&lt;li&gt;stripMargin&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;ConfigFactory.parseString(configString)&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def getForkJoinExecutorConfig(configuration: Configuration): Config = {&lt;/li&gt;
	&lt;li&gt;val forkJoinExecutorParallelismFactor =&lt;/li&gt;
	&lt;li&gt;configuration.getDouble(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_FACTOR)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val forkJoinExecutorParallelismMin =&lt;/li&gt;
	&lt;li&gt;configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MIN)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val forkJoinExecutorParallelismMax =&lt;/li&gt;
	&lt;li&gt;configuration.getInteger(AkkaOptions.FORK_JOIN_EXECUTOR_PARALLELISM_MAX)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val configString = s&quot;&quot;&quot;&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;akka {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  actor {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    default-dispatcher {&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      executor = &quot;fork-join-executor&quot;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      fork-join-executor 
{
-       |        parallelism-factor = $forkJoinExecutorParallelismFactor
-       |        parallelism-min = $forkJoinExecutorParallelismMin
-       |        parallelism-max = $forkJoinExecutorParallelismMax
-       |      }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;}&quot;&quot;&quot;.stripMargin&lt;br/&gt;
-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;ConfigFactory.parseString(configString)&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
   def testDispatcherConfig: Config = {&lt;br/&gt;
     val config =&lt;br/&gt;
       s&quot;&quot;&quot;&lt;br/&gt;
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
index 502b2bf9b40..1b2062a7481 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinatorTest.java&lt;br/&gt;
@@ -1493,8 +1493,8 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;br/&gt;
 		assertTrue(pending.isDiscarded());&lt;br/&gt;
 		assertTrue(savepointFuture.isDone());&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the now we should have a completed checkpoint&lt;/li&gt;
	&lt;li&gt;assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		// the now the savepoint should be completed but not added to the completed checkpoint store&lt;br/&gt;
+		assertEquals(0, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
 		assertEquals(0, coord.getNumberOfPendingCheckpoints());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		// validate that the relevant tasks got a confirmation message&lt;br/&gt;
@@ -1509,7 +1509,7 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception &lt;/p&gt;
{
 			verify(subtaskState2, times(1)).registerSharedStates(any(SharedStateRegistry.class));
 		}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CompletedCheckpoint success = coord.getSuccessfulCheckpoints().get(0);&lt;br/&gt;
+		CompletedCheckpoint success = savepointFuture.get();&lt;br/&gt;
 		assertEquals(jid, success.getJobId());&lt;br/&gt;
 		assertEquals(timestamp, success.getTimestamp());&lt;br/&gt;
 		assertEquals(pending.getCheckpointId(), success.getCheckpointID());&lt;br/&gt;
@@ -1527,9 +1527,9 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, checkpointIdNew));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertEquals(0, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		assertEquals(0, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CompletedCheckpoint successNew = coord.getSuccessfulCheckpoints().get(0);&lt;br/&gt;
+		CompletedCheckpoint successNew = savepointFuture.get();&lt;br/&gt;
 		assertEquals(jid, successNew.getJobId());&lt;br/&gt;
 		assertEquals(timestampNew, successNew.getTimestamp());&lt;br/&gt;
 		assertEquals(checkpointIdNew, successNew.getCheckpointID());&lt;br/&gt;
@@ -1556,7 +1556,7 @@ public void testTriggerAndConfirmSimpleSavepoint() throws Exception {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Triggers a savepoint and two checkpoints. The second checkpoint completes&lt;/li&gt;
	&lt;li&gt;and subsumes the first checkpoint, but not the first savepoint. Then we&lt;/li&gt;
	&lt;li&gt;trigger another checkpoint and savepoint. The 2nd savepoint completes and&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* subsumes the last checkpoint, but not the first savepoint.&lt;br/&gt;
+	 * does neither subsume the last checkpoint nor the first savepoint.&lt;br/&gt;
 	 */&lt;br/&gt;
 	@Test&lt;br/&gt;
 	public void testSavepointsAreNotSubsumed() throws Exception {&lt;br/&gt;
@@ -1613,18 +1613,19 @@ public void testSavepointsAreNotSubsumed() throws Exception {&lt;br/&gt;
 		assertFalse(savepointFuture1.isDone());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertTrue(coord.triggerCheckpoint(timestamp + 3, false));&lt;br/&gt;
+		long checkpointId3 = counter.getLast();&lt;br/&gt;
 		assertEquals(2, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;

&lt;p&gt; 		CompletableFuture&amp;lt;CompletedCheckpoint&amp;gt; savepointFuture2 = coord.triggerSavepoint(timestamp + 4, savepointDir);&lt;br/&gt;
 		long savepointId2 = counter.getLast();&lt;br/&gt;
 		assertEquals(3, coord.getNumberOfPendingCheckpoints());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// 2nd savepoint should subsume the last checkpoint, but not the 1st savepoint&lt;br/&gt;
+		// 2nd savepoint should not subsume the last checkpoint and the 1st savepoint&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, savepointId2));&lt;br/&gt;
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, savepointId2));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(1, coord.getNumberOfPendingCheckpoints());&lt;/li&gt;
	&lt;li&gt;assertEquals(2, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
+		assertEquals(2, coord.getNumberOfPendingCheckpoints());&lt;br/&gt;
+		assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());&lt;br/&gt;
 		assertFalse(coord.getPendingCheckpoints().get(savepointId1).isDiscarded());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 		assertFalse(savepointFuture1.isDone());&lt;br/&gt;
@@ -1634,9 +1635,15 @@ public void testSavepointsAreNotSubsumed() throws Exception &lt;/p&gt;
{
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, savepointId1));
 		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, savepointId1));
 
-		assertEquals(0, coord.getNumberOfPendingCheckpoints());
-		assertEquals(3, coord.getNumberOfRetainedSuccessfulCheckpoints());
+		assertEquals(1, coord.getNumberOfPendingCheckpoints());
+		assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());
 		assertTrue(savepointFuture1.isDone());
+
+		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID1, checkpointId3));
+		coord.receiveAcknowledgeMessage(new AcknowledgeCheckpoint(jid, attemptID2, checkpointId3));
+
+		assertEquals(0, coord.getNumberOfPendingCheckpoints());
+		assertEquals(2, coord.getNumberOfRetainedSuccessfulCheckpoints());
 	}

&lt;p&gt; 	private void testMaxConcurrentAttempts(int maxConcurrentAttempts) {&lt;br/&gt;
@@ -3459,6 +3466,92 @@ public void testCheckpointStatsTrackerRestoreCallback() throws Exception &lt;/p&gt;
{
 			.reportRestoredCheckpoint(any(RestoredCheckpointStats.class));
 	}

&lt;p&gt;+	/**&lt;br/&gt;
+	 * &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6328&quot; title=&quot;Savepoints must not be counted as retained checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6328&quot;&gt;&lt;del&gt;FLINK-6328&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
+	 *&lt;br/&gt;
+	 * Tests that savepoints are not added to the &lt;/p&gt;
{@link CompletedCheckpointStore}
&lt;p&gt; and,&lt;br/&gt;
+	 * thus, are not subject to job recovery. The reason that we don&apos;t want that (until&lt;br/&gt;
+	 * &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4815&quot; title=&quot;Automatic fallback to earlier checkpoints when checkpoint restore fails&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4815&quot;&gt;FLINK-4815&lt;/a&gt; has been finished) is that the lifecycle of savepoints is not controlled&lt;br/&gt;
+	 * by the &lt;/p&gt;
{@link CheckpointCoordinator}
&lt;p&gt;.&lt;br/&gt;
+	 */&lt;br/&gt;
+	@Test&lt;br/&gt;
+	public void testSavepointsAreNotAddedToCompletedCheckpointStore() throws Exception {&lt;br/&gt;
+		final JobID jobId = new JobID();&lt;br/&gt;
+		final ExecutionAttemptID executionAttemptId = new ExecutionAttemptID();&lt;br/&gt;
+		final ExecutionVertex vertex1 = mockExecutionVertex(executionAttemptId);&lt;br/&gt;
+		final CompletedCheckpointStore completedCheckpointStore = new StandaloneCompletedCheckpointStore(1);&lt;br/&gt;
+		final long checkpointTimestamp1 = 1L;&lt;br/&gt;
+		final long savepointTimestamp = 2L;&lt;br/&gt;
+		final long checkpointTimestamp2 = 3L;&lt;br/&gt;
+		final String savepointDir = tmpFolder.newFolder().getAbsolutePath();&lt;br/&gt;
+&lt;br/&gt;
+		final StandaloneCheckpointIDCounter checkpointIDCounter = new StandaloneCheckpointIDCounter();&lt;br/&gt;
+&lt;br/&gt;
+		CheckpointCoordinator checkpointCoordinator = new CheckpointCoordinator(&lt;br/&gt;
+			jobId,&lt;br/&gt;
+			600000L,&lt;br/&gt;
+			600000L,&lt;br/&gt;
+			0L,&lt;br/&gt;
+			Integer.MAX_VALUE,&lt;br/&gt;
+			CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION,&lt;br/&gt;
+			new ExecutionVertex[]&lt;/p&gt;
{vertex1},&lt;br/&gt;
+			new ExecutionVertex[]{vertex1}
&lt;p&gt;,&lt;br/&gt;
+			new ExecutionVertex[]&lt;/p&gt;
{vertex1}
&lt;p&gt;,&lt;br/&gt;
+			checkpointIDCounter,&lt;br/&gt;
+			completedCheckpointStore,&lt;br/&gt;
+			new MemoryStateBackend(),&lt;br/&gt;
+			Executors.directExecutor(),&lt;br/&gt;
+			SharedStateRegistry.DEFAULT_FACTORY);&lt;br/&gt;
+&lt;br/&gt;
+		// trigger a first checkpoint&lt;br/&gt;
+		assertTrue(&lt;br/&gt;
+			&quot;Triggering of a checkpoint should work.&quot;,&lt;br/&gt;
+			checkpointCoordinator.triggerCheckpoint(checkpointTimestamp1, false));&lt;br/&gt;
+&lt;br/&gt;
+		assertTrue(0 == completedCheckpointStore.getNumberOfRetainedCheckpoints());&lt;br/&gt;
+&lt;br/&gt;
+		// complete the 1st checkpoint&lt;br/&gt;
+		checkpointCoordinator.receiveAcknowledgeMessage(&lt;br/&gt;
+			new AcknowledgeCheckpoint(&lt;br/&gt;
+				jobId,&lt;br/&gt;
+				executionAttemptId,&lt;br/&gt;
+				checkpointIDCounter.getLast()));&lt;br/&gt;
+&lt;br/&gt;
+		// check that the checkpoint has been completed&lt;br/&gt;
+		assertTrue(1 == completedCheckpointStore.getNumberOfRetainedCheckpoints());&lt;br/&gt;
+&lt;br/&gt;
+		// trigger a savepoint --&amp;gt; this should not have any effect on the CompletedCheckpointStore&lt;br/&gt;
+		CompletableFuture&amp;lt;CompletedCheckpoint&amp;gt; savepointFuture = checkpointCoordinator.triggerSavepoint(savepointTimestamp, savepointDir);&lt;br/&gt;
+&lt;br/&gt;
+		checkpointCoordinator.receiveAcknowledgeMessage(&lt;br/&gt;
+			new AcknowledgeCheckpoint(&lt;br/&gt;
+				jobId,&lt;br/&gt;
+				executionAttemptId,&lt;br/&gt;
+				checkpointIDCounter.getLast()));&lt;br/&gt;
+&lt;br/&gt;
+		// check that no errors occurred&lt;br/&gt;
+		final CompletedCheckpoint savepoint = savepointFuture.get();&lt;br/&gt;
+&lt;br/&gt;
+		assertFalse(&lt;br/&gt;
+			&quot;The savepoint should not have been added to the completed checkpoint store&quot;,&lt;br/&gt;
+			savepoint.getCheckpointID() == completedCheckpointStore.getLatestCheckpoint().getCheckpointID());&lt;br/&gt;
+&lt;br/&gt;
+		assertTrue(&lt;br/&gt;
+			&quot;Triggering of a checkpoint should work.&quot;,&lt;br/&gt;
+			checkpointCoordinator.triggerCheckpoint(checkpointTimestamp2, false));&lt;br/&gt;
+&lt;br/&gt;
+		// complete the 2nd checkpoint&lt;br/&gt;
+		checkpointCoordinator.receiveAcknowledgeMessage(&lt;br/&gt;
+			new AcknowledgeCheckpoint(&lt;br/&gt;
+				jobId,&lt;br/&gt;
+				executionAttemptId,&lt;br/&gt;
+				checkpointIDCounter.getLast()));&lt;br/&gt;
+&lt;br/&gt;
+		assertTrue(&lt;br/&gt;
+			&quot;The latest completed (proper) checkpoint should have been added to the completed checkpoint store.&quot;,&lt;br/&gt;
+			completedCheckpointStore.getLatestCheckpoint().getCheckpointID() == checkpointIDCounter.getLast());&lt;br/&gt;
+	}&lt;br/&gt;
+&lt;br/&gt;
 	@Test&lt;br/&gt;
 	public void testSharedStateRegistrationOnRestore() throws Exception {&lt;/p&gt;

&lt;p&gt;diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java&lt;br/&gt;
index 3ee1b927b53..6e0f9c5c638 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorITCase.java&lt;br/&gt;
@@ -165,7 +165,6 @@ public void testSlotAllocation() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			new BlobCacheService(&lt;br/&gt;
 				configuration,&lt;br/&gt;
 				new VoidBlobStore(),&lt;br/&gt;
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java&lt;br/&gt;
index 179dea27835..4af052978f9 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskExecutorTest.java&lt;br/&gt;
@@ -279,7 +279,6 @@ public void testHeartbeatTimeoutWithJobManager() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -370,7 +369,6 @@ public void testHeartbeatTimeoutWithResourceManager() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -486,7 +484,6 @@ public void testHeartbeatSlotReporting() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -565,7 +562,6 @@ public void testImmediatelyRegistersIfLeaderIsKnown() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -629,7 +625,6 @@ public void testTriggerRegistrationOnLeaderChange() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -752,7 +747,6 @@ public void testTaskSubmission() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -852,7 +846,6 @@ public void testJobLeaderDetection() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -884,7 +877,7 @@ public void testJobLeaderDetection() throws Exception &lt;/p&gt;
{
 			// the job leader should get the allocation id offered
 			verify(jobMasterGateway, Mockito.timeout(timeout.toMilliseconds())).offerSlots(
 					any(ResourceID.class),
-					(Collection&amp;lt;SlotOffer&amp;gt;)Matchers.argThat(contains(slotOffer)),
+					(Collection&amp;lt;SlotOffer&amp;gt;) Matchers.argThat(contains(slotOffer)),
 					any(Time.class));
 		}
&lt;p&gt; finally {&lt;br/&gt;
 			RpcUtils.terminateRpcEndpoint(taskManager, timeout);&lt;br/&gt;
@@ -967,7 +960,6 @@ public void testSlotAcceptance() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1062,7 +1054,6 @@ public void testSubmitTaskBeforeAcceptSlot() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1169,7 +1160,6 @@ public void testFilterOutDuplicateJobMasterRegistrations() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServicesMock,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1243,7 +1233,6 @@ public void testRMHeartbeatStopWhenLeadershipRevoked() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			heartbeatServices,&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1300,7 +1289,6 @@ public void testRemoveJobFromJobLeaderService() throws Exception {&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(1000L, 1000L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1393,7 +1381,6 @@ public void testMaximumRegistrationDurationAfterConnectionLoss() throws Exceptio&lt;br/&gt;
 			taskManagerServices,&lt;br/&gt;
 			new HeartbeatServices(heartbeatInterval, 10L),&lt;br/&gt;
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;null,&lt;br/&gt;
 			dummyBlobCacheService,&lt;br/&gt;
 			testingFatalErrorHandler);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1501,7 +1488,6 @@ public void testReconnectionAttemptIfExplicitlyDisconnected() throws Exception &lt;/p&gt;
{
 				.build(),
 			new HeartbeatServices(heartbeatInterval, 1000L),
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),
-			null,
 			dummyBlobCacheService,
 			testingFatalErrorHandler);
 
@@ -1713,7 +1699,6 @@ private TaskExecutor createTaskExecutor(TaskManagerServices taskManagerServices)
 			taskManagerServices,
 			new HeartbeatServices(1000L, 1000L),
 			UnregisteredMetricGroups.createUnregisteredTaskManagerMetricGroup(),
-			null,
 			dummyBlobCacheService,
 			testingFatalErrorHandler);
 	}
&lt;p&gt;diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java&lt;br/&gt;
index 5fd12a84ac4..a9e99495e34 100644&lt;br/&gt;
&amp;#8212; a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java&lt;br/&gt;
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TestingTaskExecutorGateway.java&lt;br/&gt;
@@ -34,7 +34,6 @@&lt;br/&gt;
 import org.apache.flink.runtime.messages.Acknowledge;&lt;br/&gt;
 import org.apache.flink.runtime.messages.StackTraceSampleResponse;&lt;br/&gt;
 import org.apache.flink.runtime.resourcemanager.ResourceManagerId;&lt;br/&gt;
-import org.apache.flink.types.SerializableOptional;&lt;br/&gt;
 import org.apache.flink.util.Preconditions;&lt;/p&gt;

&lt;p&gt; import java.util.concurrent.CompletableFuture;&lt;br/&gt;
@@ -150,11 +149,6 @@ public void disconnectResourceManager(Exception cause) &lt;/p&gt;
{
 		return FutureUtils.completedExceptionally(new UnsupportedOperationException());
 	}

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public CompletableFuture&amp;lt;SerializableOptional&amp;lt;String&amp;gt;&amp;gt; requestMetricQueryServiceAddress(Time timeout) 
{
-		return CompletableFuture.completedFuture(SerializableOptional.of(address));
-	}
&lt;p&gt;-&lt;br/&gt;
 	@Override&lt;br/&gt;
 	public String getAddress() {&lt;br/&gt;
 		return address;&lt;br/&gt;
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala&lt;br/&gt;
index e5c1668df0a..d02a55483bf 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala&lt;br/&gt;
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/akka/AkkaUtilsTest.scala&lt;br/&gt;
@@ -18,7 +18,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package org.apache.flink.runtime.akka&lt;/p&gt;

&lt;p&gt;-import java.net.&lt;/p&gt;
{InetAddress, InetSocketAddress}
&lt;p&gt;+import java.net.InetSocketAddress&lt;/p&gt;

&lt;p&gt; import org.apache.flink.configuration.&lt;/p&gt;
{AkkaOptions, Configuration, IllegalConfigurationException}
&lt;p&gt; import org.apache.flink.runtime.highavailability.HighAvailabilityServicesUtils.AddressResolution&lt;br/&gt;
@@ -167,30 +167,4 @@ class AkkaUtilsTest&lt;br/&gt;
     akkaConfig.getString(&quot;akka.remote.netty.tcp.hostname&quot;) should&lt;br/&gt;
       equal(NetUtils.unresolvedHostToNormalizedString(hostname))&lt;br/&gt;
   }&lt;br/&gt;
-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;test(&quot;null hostname should go to localhost&quot;) 
{
-    val configure = AkkaUtils.getAkkaConfig(new Configuration(), Some((null, 1772)))
-
-    val hostname = configure.getString(&quot;akka.remote.netty.tcp.hostname&quot;)
-
-    InetAddress.getByName(hostname).isLoopbackAddress should be(true)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;test(&quot;getAkkaConfig defaults to fork-join-executor&quot;) 
{
-    val akkaConfig = AkkaUtils.getAkkaConfig(new Configuration())
-
-    akkaConfig.getString(&quot;akka.actor.default-dispatcher.executor&quot;) should
-      equal(&quot;fork-join-executor&quot;)
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;test(&quot;getAkkaConfig respects executor config&quot;) 
{
-    val akkaConfig = AkkaUtils.getAkkaConfig(
-      new Configuration(),
-      &quot;localhost&quot;,
-      1234,
-      AkkaUtils.getThreadPoolExecutorConfig)
-
-    akkaConfig.getString(&quot;akka.actor.default-dispatcher.executor&quot;) should
-      equal(&quot;thread-pool-executor&quot;)
-  }
&lt;p&gt; }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13175150">FLINK-9983</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 4 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3y5s7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12310192" key="com.atlassian.jira.plugin.system.customfieldtypes:textarea">
                        <customfieldname>Release Note</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Savepoints are now used while recovering. Previously when using exactly-once sink one could get into problems with duplicate output data when a failure occured after a savepoint was taken but before the next checkpoint occured.&lt;br/&gt;
This results in the fact that savepoints are no longer exclusively under the control of the user. Savepoint should not be moved nor deleted if there was no newer checkpoint or savepoint taken.</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>