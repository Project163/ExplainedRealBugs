<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:25:19 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-4311] TableInputFormat fails when reused on next split</title>
                <link>https://issues.apache.org/jira/browse/FLINK-4311</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;We have written a batch job that uses data from HBase by means of using the TableInputFormat.&lt;/p&gt;

&lt;p&gt;We have found that this class sometimes fails with this exception:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;java.lang.RuntimeException: java.util.concurrent.RejectedExecutionException: Task org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture@4f4efe4b rejected from java.util.concurrent.ThreadPoolExecutor@7872d5c1&lt;span class=&quot;error&quot;&gt;&amp;#91;Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1165&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:208)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ClientScanner.&amp;lt;init&amp;gt;(ClientScanner.java:155)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:821)&lt;br/&gt;
	at org.apache.flink.addons.hbase.TableInputFormat.open(TableInputFormat.java:152)&lt;br/&gt;
	at org.apache.flink.addons.hbase.TableInputFormat.open(TableInputFormat.java:47)&lt;br/&gt;
	at org.apache.flink.runtime.operators.DataSourceTask.invoke(DataSourceTask.java:147)&lt;br/&gt;
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:559)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.util.concurrent.RejectedExecutionException: Task org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture@4f4efe4b rejected from java.util.concurrent.ThreadPoolExecutor@7872d5c1&lt;span class=&quot;error&quot;&gt;&amp;#91;Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1165&amp;#93;&lt;/span&gt;&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ResultBoundedCompletionService.submit(ResultBoundedCompletionService.java:142)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.addCallsForCurrentReplica(ScannerCallableWithReplicas.java:269)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:165)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:59)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)&lt;br/&gt;
	... 10 more&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As you can see the ThreadPoolExecutor was terminated at this point.&lt;/p&gt;

&lt;p&gt;We tracked it down to the fact that &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;the configure method opens the table&lt;/li&gt;
	&lt;li&gt;the open method obtains the result scanner&lt;/li&gt;
	&lt;li&gt;the closes method closes the table.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;If a second split arrives on the same instance then the open method will fail because the table has already been closed.&lt;/p&gt;

&lt;p&gt;We also found that this error varies with the versions of HBase that are used. I have also seen this exception:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Caused by: java.io.IOException: hconnection-0x19d37183 closed&lt;br/&gt;
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1146)&lt;br/&gt;
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:300)&lt;br/&gt;
	... 37 more&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I found that in the &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/api/java/org/apache/flink/api/common/io/InputFormat.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;documentation of the InputFormat interface&lt;/a&gt; is clearly states&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;IMPORTANT NOTE: Input formats must be written such that an instance can be opened again after it was closed. That is due to the fact that the input format is used for potentially multiple splits. After a split is done, the format&apos;s close function is invoked and, if another split is available, the open function is invoked afterwards for the next split.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It appears that this specific InputFormat has not been checked against this constraint.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12994576">FLINK-4311</key>
            <summary>TableInputFormat fails when reused on next split</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nielsbasjes">Niels Basjes</assignee>
                                    <reporter username="nielsbasjes">Niels Basjes</reporter>
                        <labels>
                    </labels>
                <created>Wed, 3 Aug 2016 12:29:30 +0000</created>
                <updated>Mon, 10 Oct 2016 18:56:38 +0000</updated>
                            <resolved>Mon, 10 Oct 2016 18:56:38 +0000</resolved>
                                    <version>1.0.3</version>
                                    <fixVersion>1.1.3</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15405893" author="githubbot" created="Wed, 3 Aug 2016 13:07:55 +0000"  >&lt;p&gt;GitHub user nielsbasjes opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4311&quot; title=&quot;TableInputFormat fails when reused on next split&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4311&quot;&gt;&lt;del&gt;FLINK-4311&lt;/del&gt;&lt;/a&gt; Fixed several problems in TableInputFormat&lt;/p&gt;

&lt;p&gt;    Question: Do you guys want a unit test for this?&lt;br/&gt;
    In HBase itself I have done this in the past yet this required a large chunk of additional software to start and stop an HBase minicluster during the unit tests.&lt;br/&gt;
    I.e. pull in this thing: &lt;br/&gt;
    &lt;a href=&quot;https://github.com/apache/hbase/blob/master/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/FilterTestingCluster.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hbase/blob/master/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/FilterTestingCluster.java&lt;/a&gt;&lt;br/&gt;
    and then do something like this:&lt;br/&gt;
    &lt;a href=&quot;https://github.com/apache/hbase/blob/master/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestScanRowPrefix.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hbase/blob/master/hbase-server/src/test/java/org/apache/hadoop/hbase/filter/TestScanRowPrefix.java&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/nielsbasjes/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/nielsbasjes/flink&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4311&quot; title=&quot;TableInputFormat fails when reused on next split&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4311&quot;&gt;&lt;del&gt;FLINK-4311&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2330&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 5c3d53c810f8df6d5544685ef3f1004c46541daf&lt;br/&gt;
Author: Niels Basjes &amp;lt;nbasjes@bol.com&amp;gt;&lt;br/&gt;
Date:   2016-08-03T12:54:34Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4311&quot; title=&quot;TableInputFormat fails when reused on next split&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4311&quot;&gt;&lt;del&gt;FLINK-4311&lt;/del&gt;&lt;/a&gt; TableInputFormat can handle reuse for next input split&lt;/p&gt;

&lt;p&gt;commit 8696f5e257c7434d62e662c4c97f4ede2da5411b&lt;br/&gt;
Author: Niels Basjes &amp;lt;nbasjes@bol.com&amp;gt;&lt;br/&gt;
Date:   2016-08-03T12:56:01Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4311&quot; title=&quot;TableInputFormat fails when reused on next split&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4311&quot;&gt;&lt;del&gt;FLINK-4311&lt;/del&gt;&lt;/a&gt; Cannot override a static member function.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15405896" author="githubbot" created="Wed, 3 Aug 2016 13:13:19 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Oh damn, &lt;br/&gt;
    I just noticed a major issue in this: In order to create the input splits the table needs to be available &quot;before&quot; the call to the &apos;open&apos; method.&lt;/p&gt;

</comment>
                            <comment id="15405912" author="githubbot" created="Wed, 3 Aug 2016 13:25:41 +0000"  >&lt;p&gt;Github user zentol commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    maybe you can move the table initialization into `openInputFormat()` (called once before all splits) and close it in `closeInputFormat()` (called once after all splits).&lt;/p&gt;</comment>
                            <comment id="15405918" author="githubbot" created="Wed, 3 Aug 2016 13:34:16 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Yes, that is indeed the right place to do this. &lt;br/&gt;
    Bummer this method does not allow throwing exceptions.&lt;/p&gt;</comment>
                            <comment id="15405928" author="githubbot" created="Wed, 3 Aug 2016 13:41:17 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Now I see why I missed these two; They are newer than the 1.0.3 I was working with.&lt;br/&gt;
    Is it a good idea to add &apos; throws IOException&apos; to these two in RichInputFormat ?&lt;/p&gt;</comment>
                            <comment id="15405932" author="githubbot" created="Wed, 3 Aug 2016 13:45:42 +0000"  >&lt;p&gt;Github user zentol commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I would say yes, since `open()` and `close()` can also throw an `IOException`.&lt;/p&gt;</comment>
                            <comment id="15406043" author="githubbot" created="Wed, 3 Aug 2016 15:10:25 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Note that this version still assumes that the single instance will only see multiple splits for the same table. Is that a safe assumption?&lt;/p&gt;</comment>
                            <comment id="15406281" author="githubbot" created="Wed, 3 Aug 2016 17:37:15 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r73381826&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r73381826&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperator.java &amp;#8212;&lt;br/&gt;
    @@ -328,7 +328,11 @@ public void run() {&lt;br/&gt;
     				synchronized (checkpointLock) {&lt;br/&gt;
     					LOG.info(&quot;Reader terminated, and exiting...&quot;);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.format.closeInputFormat();&lt;br/&gt;
    +					try 
{
    +						this.format.closeInputFormat();
    +					}
&lt;p&gt; catch (IOException e) {&lt;br/&gt;
    +						// Ignoring&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    it would be good to log the exception&lt;/p&gt;</comment>
                            <comment id="15406284" author="githubbot" created="Wed, 3 Aug 2016 17:38:14 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r73382033&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r73382033&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -237,7 +244,7 @@ private void logSplitInfo(String action, TableInputSplit split) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;End key of the region&lt;/li&gt;
	&lt;li&gt;@return true, if this region needs to be included as part of the input (default).&lt;br/&gt;
     	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static boolean includeRegionInSplit(final byte[] startKey, final byte[] endKey) {&lt;br/&gt;
    +	protected boolean includeRegionInSplit(final byte[] startKey, final byte[] endKey) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    why are you changing this?&lt;/p&gt;</comment>
                            <comment id="15406293" author="githubbot" created="Wed, 3 Aug 2016 17:43:07 +0000"  >&lt;p&gt;Github user zentol commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I don&apos;t know, and it seems the InputFormat itself doesn&apos;t know either. If we go by the previous implementation then yes, there will only be one table. However, based on the comments on Line 64: `// abstract methods allow for multiple table and scanners in the same job` we have to conclude that there can be different tables.&lt;/p&gt;

&lt;p&gt;    I&apos;d be curious what @twalthr thinks about this.&lt;/p&gt;</comment>
                            <comment id="15407394" author="githubbot" created="Thu, 4 Aug 2016 08:22:41 +0000"  >&lt;p&gt;Github user nielsbasjes commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r73480826&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r73480826&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -237,7 +244,7 @@ private void logSplitInfo(String action, TableInputSplit split) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;End key of the region&lt;/li&gt;
	&lt;li&gt;@return true, if this region needs to be included as part of the input (default).&lt;br/&gt;
     	 */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static boolean includeRegionInSplit(final byte[] startKey, final byte[] endKey) {&lt;br/&gt;
    +	protected boolean includeRegionInSplit(final byte[] startKey, final byte[] endKey) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    This function is according to the documentation intended so people can override it in a subclass. You cannot overrule a static function (and especially not if it is private).&lt;br/&gt;
    &lt;a href=&quot;http://stackoverflow.com/questions/2223386/why-doesnt-java-allow-overriding-of-static-methods&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stackoverflow.com/questions/2223386/why-doesnt-java-allow-overriding-of-static-methods&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15407410" author="githubbot" created="Thu, 4 Aug 2016 08:32:10 +0000"  >&lt;p&gt;Github user nielsbasjes commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r73482199&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r73482199&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperator.java &amp;#8212;&lt;br/&gt;
    @@ -328,7 +328,11 @@ public void run() {&lt;br/&gt;
     				synchronized (checkpointLock) {&lt;br/&gt;
     					LOG.info(&quot;Reader terminated, and exiting...&quot;);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.format.closeInputFormat();&lt;br/&gt;
    +					try 
{
    +						this.format.closeInputFormat();
    +					}
&lt;p&gt; catch (IOException e) {&lt;br/&gt;
    +						// Ignoring&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Done&lt;/p&gt;</comment>
                            <comment id="15407443" author="githubbot" created="Thu, 4 Aug 2016 08:53:48 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I had another look at the &quot;multiple tables&quot; question. The name of the table comes from the getTableName method that is to be implemented by the subclass. I consider it to be extremely unlikely that multiple calls to that method in a single instance will yield different table names.&lt;/p&gt;</comment>
                            <comment id="15413108" author="githubbot" created="Tue, 9 Aug 2016 07:33:23 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Question: Is this change good? &lt;br/&gt;
    Or do you have more things that I need to change before it can be committed?&lt;/p&gt;</comment>
                            <comment id="15415291" author="githubbot" created="Wed, 10 Aug 2016 13:52:13 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I will add a unit test for this.&lt;/p&gt;</comment>
                            <comment id="15436952" author="githubbot" created="Thu, 25 Aug 2016 14:16:41 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I did a few serious attempts to create a unit test that fires the HBaseMiniCluster ... and failed.&lt;/p&gt;</comment>
                            <comment id="15439102" author="githubbot" created="Fri, 26 Aug 2016 14:12:45 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I managed to resolve the problems with running these unit tests. &lt;br/&gt;
    These problems were caused by version conflicts in guava.&lt;br/&gt;
    Now we have a HBaseMiniCluster that is started, a table with multiple regions is created. And the TableInputFormat is used to extract the rows again. By setting the paralellism to 1 the same TableInputFormat instance is used for multiple regions and succeeds (the problem this all started with).&lt;/p&gt;

&lt;p&gt;    Please review.&lt;/p&gt;</comment>
                            <comment id="15445391" author="githubbot" created="Mon, 29 Aug 2016 09:41:11 +0000"  >&lt;p&gt;Github user nielsbasjes commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Current version has a problem in building the shaded jars.&lt;br/&gt;
    I runs into an infinite loop in creating the dependency-reduced-pom.xml as described here: &lt;/p&gt;

&lt;p&gt;    *&lt;b&gt;Shade Plugin gets stuck in infinite loop building dependency reduced POM&lt;/b&gt;* &lt;a href=&quot;https://issues.apache.org/jira/browse/MSHADE-148&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/MSHADE-148&lt;/a&gt;&lt;br/&gt;
    Although all my versions are newer than the fix described there I still see the problem.&lt;/p&gt;
</comment>
                            <comment id="15504562" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79469573&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79469573&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -131,37 +153,27 @@ public T nextRecord(T reuse) throws IOException {&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;     	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void open(TableInputSplit split) throws IOException {&lt;/li&gt;
	&lt;li&gt;if (split == null)
{
    -			throw new IOException(&quot;Input split is null!&quot;);
    -		}&lt;/li&gt;
	&lt;li&gt;if (table == null)
{
    -			throw new IOException(&quot;No HTable provided!&quot;);
    -		}&lt;/li&gt;
	&lt;li&gt;if (scan == null){&lt;/li&gt;
	&lt;li&gt;throw new IOException(&quot;No Scan instance provided&quot;);&lt;br/&gt;
    +	public void close() throws IOException {&lt;br/&gt;
    +		LOG.info(&quot;Closing split (scanned {} rows)&quot;, scannedRows);&lt;br/&gt;
    +		this.lastRow = null;&lt;br/&gt;
    +		try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			if(resultScanner !=null) {
    +				this.resultScanner.close();
    +			}    +		}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; finally &lt;/p&gt;
{
    +			this.resultScanner = null;
     		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;logSplitInfo(&quot;opening&quot;, split);&lt;/li&gt;
	&lt;li&gt;scan.setStartRow(split.getStartRow());&lt;/li&gt;
	&lt;li&gt;lastRow = split.getEndRow();&lt;/li&gt;
	&lt;li&gt;scan.setStopRow(lastRow);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;this.rs = table.getScanner(scan);&lt;/li&gt;
	&lt;li&gt;this.endReached = false;&lt;/li&gt;
	&lt;li&gt;this.scannedRows = 0;&lt;br/&gt;
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void close() throws IOException {&lt;/li&gt;
	&lt;li&gt;if(rs!=null)
{
    -			this.rs.close();
    -		}&lt;/li&gt;
	&lt;li&gt;if(table!=null){&lt;/li&gt;
	&lt;li&gt;this.table.close();&lt;br/&gt;
    +	public void closeInputFormat() throws IOException {&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			if(table!=null) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    insert spaces&lt;/p&gt;</comment>
                            <comment id="15504563" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79469513&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79469513&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -131,37 +153,27 @@ public T nextRecord(T reuse) throws IOException {&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;     	@Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void open(TableInputSplit split) throws IOException {&lt;/li&gt;
	&lt;li&gt;if (split == null)
{
    -			throw new IOException(&quot;Input split is null!&quot;);
    -		}&lt;/li&gt;
	&lt;li&gt;if (table == null)
{
    -			throw new IOException(&quot;No HTable provided!&quot;);
    -		}&lt;/li&gt;
	&lt;li&gt;if (scan == null){&lt;/li&gt;
	&lt;li&gt;throw new IOException(&quot;No Scan instance provided&quot;);&lt;br/&gt;
    +	public void close() throws IOException {&lt;br/&gt;
    +		LOG.info(&quot;Closing split (scanned {} rows)&quot;, scannedRows);&lt;br/&gt;
    +		this.lastRow = null;&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			if(resultScanner !=null) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    insert space between `!=` and `null`&lt;/p&gt;</comment>
                            <comment id="15504564" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79468879&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79468879&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -67,15 +67,24 @@&lt;br/&gt;
     	protected abstract T mapResultToTuple(Result r);&lt;/p&gt;

&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* creates a 
{@link Scan} object and a {@link HTable} connection&lt;br/&gt;
    -	 *&lt;br/&gt;
    -	 * @param parameters&lt;br/&gt;
    +	 * Creates a {@link Scan}
&lt;p&gt; object and opens the &lt;/p&gt;
{@link HTable}
&lt;p&gt; connection.&lt;br/&gt;
    +	 * These are opened here because they are needed in the createInputSplits&lt;br/&gt;
    +	 * which is called before the openInputFormat method.&lt;br/&gt;
    +	 * So the connection is opened in &lt;/p&gt;
{@link #configure(Configuration)}
&lt;p&gt; and closed in &lt;/p&gt;
{@link #closeInputFormat()}
&lt;p&gt;.&lt;br/&gt;
    +	 * @param parameters The configuration that is to be used&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@see Configuration&lt;br/&gt;
     	 */&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public void configure(Configuration parameters) 
{
    -		this.table = createTable();
    -		this.scan = getScanner();
    +		table = createTable();
    +		scan = getScanner();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Do nothing.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public void openInputFormat() throws IOException {&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    No need to override this method.&lt;/p&gt;</comment>
                            <comment id="15504566" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79477333&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79477333&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/resources/hbase-site.xml &amp;#8212;&lt;br/&gt;
    @@ -1,43 +0,0 @@&lt;br/&gt;
    -&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;&lt;br/&gt;
    -&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;&lt;br/&gt;
    &lt;del&gt;&amp;lt;!&lt;/del&gt;-&lt;br/&gt;
    -/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one&lt;/li&gt;
	&lt;li&gt;* or more contributor license agreements.  See the NOTICE file&lt;/li&gt;
	&lt;li&gt;* distributed with this work for additional information&lt;/li&gt;
	&lt;li&gt;* regarding copyright ownership.  The ASF licenses this file&lt;/li&gt;
	&lt;li&gt;* to you under the Apache License, Version 2.0 (the&lt;/li&gt;
	&lt;li&gt;* &quot;License&quot;); you may not use this file except in compliance&lt;/li&gt;
	&lt;li&gt;* with the License.  You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;*     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
    ---&amp;gt;&lt;br/&gt;
    -&amp;lt;configuration&amp;gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I&apos;m not so familiar with HBase. Is the config no longer required for HBase 1.1.2 or why did you remove it?&lt;/p&gt;</comment>
                            <comment id="15504565" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79472506&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79472506&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/java/org/apache/flink/addons/hbase/TestTableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,112 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.addons.hbase;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
    +import org.apache.flink.api.java.DataSet;&lt;br/&gt;
    +import org.apache.flink.api.java.ExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.api.java.io.LocalCollectionOutputFormat;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.hadoop.hbase.TableName;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.HTable;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Put;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Scan;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Before;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TestTableInputFormat extends HBaseTestingClusterAutostarter {&lt;br/&gt;
    +	private static final String TEST_TABLE_NAME = &quot;TableInputFormatTestTable&quot;;&lt;br/&gt;
    +	private static final byte[] TEST_TABLE_FAMILY_NAME = &quot;F&quot;.getBytes();&lt;br/&gt;
    +	private static final byte[] TEST_TABLE_COLUMN_NAME = &quot;Col&quot;.getBytes();&lt;br/&gt;
    +&lt;br/&gt;
    +	// These are the row ids AND also the values we will put in the test table&lt;br/&gt;
    +	private static final String[] ROW_IDS = &lt;/p&gt;
{&quot;000&quot;, &quot;111&quot;, &quot;222&quot;, &quot;333&quot;, &quot;444&quot;, &quot;555&quot;, &quot;666&quot;, &quot;777&quot;, &quot;888&quot;, &quot;999&quot;}
&lt;p&gt;;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Before&lt;br/&gt;
    +	public void createTestTable() throws IOException {&lt;br/&gt;
    +		TableName tableName = TableName.valueOf(TEST_TABLE_NAME);&lt;br/&gt;
    +		byte[][] splitKeys = &lt;/p&gt;
{&quot;0&quot;.getBytes(), &quot;3&quot;.getBytes(), &quot;6&quot;.getBytes(), &quot;9&quot;.getBytes()}
&lt;p&gt;;&lt;br/&gt;
    +		createTable(tableName, TEST_TABLE_FAMILY_NAME, splitKeys);&lt;br/&gt;
    +		HTable table = openTable(tableName);&lt;br/&gt;
    +&lt;br/&gt;
    +		for (String rowId : ROW_IDS) &lt;/p&gt;
{
    +			byte[] rowIdBytes = rowId.getBytes();
    +			Put p = new Put(rowIdBytes);
    +			// Use the rowId as the value to facilitate the testing better
    +			p.add(TEST_TABLE_FAMILY_NAME, TEST_TABLE_COLUMN_NAME, rowIdBytes);
    +			table.put(p);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		table.close();&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	class InputFormatForTestTable extends TableInputFormat&amp;lt;Tuple1&amp;lt;String&amp;gt;&amp;gt; {&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected Scan getScanner() &lt;/p&gt;
{
    +			return new Scan();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected String getTableName() &lt;/p&gt;
{
    +			return TEST_TABLE_NAME;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected Tuple1&amp;lt;String&amp;gt; mapResultToTuple(Result r) &lt;/p&gt;
{
    +			return new Tuple1&amp;lt;&amp;gt;(new String(r.getValue(TEST_TABLE_FAMILY_NAME, TEST_TABLE_COLUMN_NAME)));
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testTableInputFormat() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can we make this test a bit more lightweight and not execute a Flink program?&lt;br/&gt;
    Instead we could test the interface methods of the InputFormat such as:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;createInputSplits&lt;/li&gt;
	&lt;li&gt;configure&lt;/li&gt;
	&lt;li&gt;open&lt;/li&gt;
	&lt;li&gt;nextRecord&lt;/li&gt;
	&lt;li&gt;close&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    etc.&lt;/p&gt;

&lt;p&gt;    if you split the test into several methods, please make sure that HBase is only initalized once with `@BeforeClass`.&lt;/p&gt;</comment>
                            <comment id="15504567" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79470876&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79470876&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/java/org/apache/flink/addons/hbase/TestTableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,112 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.addons.hbase;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
    +import org.apache.flink.api.java.DataSet;&lt;br/&gt;
    +import org.apache.flink.api.java.ExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.api.java.io.LocalCollectionOutputFormat;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.hadoop.hbase.TableName;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.HTable;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Put;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Scan;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Before;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TestTableInputFormat extends HBaseTestingClusterAutostarter {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Long running integration tests have to follow the `*ITCase` naming pattern. This will cause them to be executed in Maven&apos;s verify phase.&lt;/p&gt;</comment>
                            <comment id="15504568" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79477173&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79477173&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/resources/log4j-test.properties &amp;#8212;&lt;br/&gt;
    @@ -15,9 +15,16 @@&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;specific language governing permissions and limitations&lt;/li&gt;
	&lt;li&gt;under the License.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    -log4j.rootLogger=${hadoop.root.logger}&lt;br/&gt;
    -hadoop.root.logger=INFO,console&lt;br/&gt;
    -log4j.appender.console=org.apache.log4j.ConsoleAppender&lt;br/&gt;
    -log4j.appender.console.target=System.err&lt;br/&gt;
    -log4j.appender.console.layout=org.apache.log4j.PatternLayout&lt;br/&gt;
    -log4j.appender.console.layout.ConversionPattern=%d&lt;/p&gt;
{yy/MM/dd HH:mm:ss}
&lt;p&gt; %p %c&lt;/p&gt;
{2}
&lt;p&gt;: %m%n&lt;br/&gt;
    +log4j.rootLogger=DEBUG, stdout, file&lt;br/&gt;
    +log4j.appender.stdout=org.apache.log4j.ConsoleAppender&lt;br/&gt;
    +log4j.appender.stdout.Target=System.out&lt;br/&gt;
    +log4j.appender.stdout.threshold=INFO&lt;br/&gt;
    +log4j.appender.stdout.layout=org.apache.log4j.PatternLayout&lt;br/&gt;
    +log4j.appender.stdout.layout.ConversionPattern=%d&lt;/p&gt;
{ABSOLUTE}
&lt;p&gt; %-5p %30c&lt;/p&gt;
{1}
&lt;p&gt;:%4L - %m%n&lt;br/&gt;
    +## file appender&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can you remove the file appender configuration? This creates a 3.5 MB file and make the test heavier. We are suffering from long build times and try to keep new tests as lightweight as possible. Thanks&lt;/p&gt;</comment>
                            <comment id="15504569" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79469241&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79469241&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -93,32 +102,45 @@ private HTable createTable() {&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
    +	public void open(TableInputSplit split) throws IOException {&lt;br/&gt;
    +		if (split == null) &lt;/p&gt;
{
    +			throw new IOException(&quot;Input split is null!&quot;);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		logSplitInfo(&quot;opening&quot;, split);&lt;br/&gt;
    +		scan.setStartRow(split.getStartRow());&lt;br/&gt;
    +		lastRow = split.getEndRow();&lt;br/&gt;
    +		scan.setStopRow(lastRow);&lt;br/&gt;
    +&lt;br/&gt;
    +		resultScanner = table.getScanner(scan);&lt;br/&gt;
    +		endReached = false;&lt;br/&gt;
    +		scannedRows = 0;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
     	public boolean reachedEnd() throws IOException &lt;/p&gt;
{
     		return this.endReached;
     	}

&lt;p&gt;     	@Override&lt;br/&gt;
     	public T nextRecord(T reuse) throws IOException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (this.rs == null){&lt;br/&gt;
    +		if (this.resultScanner == null)
{
     			throw new IOException(&quot;No table result scanner provided!&quot;);
     		}
&lt;p&gt;     		try{&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    insert space&lt;/p&gt;</comment>
                            <comment id="15504570" author="githubbot" created="Mon, 19 Sep 2016 20:16:38 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79469197&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79469197&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -93,32 +102,45 @@ private HTable createTable() {&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;     	@Override&lt;br/&gt;
    +	public void open(TableInputSplit split) throws IOException {&lt;br/&gt;
    +		if (split == null) &lt;/p&gt;
{
    +			throw new IOException(&quot;Input split is null!&quot;);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		logSplitInfo(&quot;opening&quot;, split);&lt;br/&gt;
    +		scan.setStartRow(split.getStartRow());&lt;br/&gt;
    +		lastRow = split.getEndRow();&lt;br/&gt;
    +		scan.setStopRow(lastRow);&lt;br/&gt;
    +&lt;br/&gt;
    +		resultScanner = table.getScanner(scan);&lt;br/&gt;
    +		endReached = false;&lt;br/&gt;
    +		scannedRows = 0;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
     	public boolean reachedEnd() throws IOException &lt;/p&gt;
{
     		return this.endReached;
     	}

&lt;p&gt;     	@Override&lt;br/&gt;
     	public T nextRecord(T reuse) throws IOException {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (this.rs == null){&lt;br/&gt;
    +		if (this.resultScanner == null){
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    add a space before `{`&lt;/p&gt;</comment>
                            <comment id="15509368" author="githubbot" created="Wed, 21 Sep 2016 09:32:48 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79791682&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79791682&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/java/org/apache/flink/addons/hbase/TestTableInputFormatITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,112 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.addons.hbase;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
    +import org.apache.flink.api.java.DataSet;&lt;br/&gt;
    +import org.apache.flink.api.java.ExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.api.java.io.LocalCollectionOutputFormat;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.hadoop.hbase.TableName;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.HTable;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Put;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Scan;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Before;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TestTableInputFormatITCase extends HBaseTestingClusterAutostarter {&lt;br/&gt;
    +	private static final String TEST_TABLE_NAME = &quot;TableInputFormatTestTable&quot;;&lt;br/&gt;
    +	private static final byte[] TEST_TABLE_FAMILY_NAME = &quot;F&quot;.getBytes();&lt;br/&gt;
    +	private static final byte[] TEST_TABLE_COLUMN_NAME = &quot;Col&quot;.getBytes();&lt;br/&gt;
    +&lt;br/&gt;
    +	// These are the row ids AND also the values we will put in the test table&lt;br/&gt;
    +	private static final String[] ROW_IDS = &lt;/p&gt;
{&quot;000&quot;, &quot;111&quot;, &quot;222&quot;, &quot;333&quot;, &quot;444&quot;, &quot;555&quot;, &quot;666&quot;, &quot;777&quot;, &quot;888&quot;, &quot;999&quot;}
&lt;p&gt;;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Before&lt;br/&gt;
    +	public void createTestTable() throws IOException {&lt;br/&gt;
    +		TableName tableName = TableName.valueOf(TEST_TABLE_NAME);&lt;br/&gt;
    +		byte[][] splitKeys = &lt;/p&gt;
{&quot;0&quot;.getBytes(), &quot;3&quot;.getBytes(), &quot;6&quot;.getBytes(), &quot;9&quot;.getBytes()}
&lt;p&gt;;&lt;br/&gt;
    +		createTable(tableName, TEST_TABLE_FAMILY_NAME, splitKeys);&lt;br/&gt;
    +		HTable table = openTable(tableName);&lt;br/&gt;
    +&lt;br/&gt;
    +		for (String rowId : ROW_IDS) &lt;/p&gt;
{
    +			byte[] rowIdBytes = rowId.getBytes();
    +			Put p = new Put(rowIdBytes);
    +			// Use the rowId as the value to facilitate the testing better
    +			p.add(TEST_TABLE_FAMILY_NAME, TEST_TABLE_COLUMN_NAME, rowIdBytes);
    +			table.put(p);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		table.close();&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	class InputFormatForTestTable extends TableInputFormat&amp;lt;Tuple1&amp;lt;String&amp;gt;&amp;gt; {&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected Scan getScanner() &lt;/p&gt;
{
    +			return new Scan();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected String getTableName() &lt;/p&gt;
{
    +			return TEST_TABLE_NAME;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected Tuple1&amp;lt;String&amp;gt; mapResultToTuple(Result r) &lt;/p&gt;
{
    +			return new Tuple1&amp;lt;&amp;gt;(new String(r.getValue(TEST_TABLE_FAMILY_NAME, TEST_TABLE_COLUMN_NAME)));
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testTableInputFormat() {&lt;br/&gt;
    +		ExecutionEnvironment environment = ExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		environment.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		DataSet&amp;lt;String&amp;gt; resultDataSet =&lt;br/&gt;
    +			environment.createInput(new InputFormatForTestTable()).map(new MapFunction&amp;lt;Tuple1&amp;lt;String&amp;gt;, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String map(Tuple1&amp;lt;String&amp;gt; value) throws Exception &lt;/p&gt;
{
    +					return value.f0;
    +				}
&lt;p&gt;    +			});&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;String&amp;gt; resultSet = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		resultDataSet.output(new LocalCollectionOutputFormat&amp;lt;&amp;gt;(resultSet));&lt;br/&gt;
    +&lt;br/&gt;
    +		try &lt;/p&gt;
{
    +			environment.execute(&quot;HBase InputFormat Test&quot;);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			Assert.fail(&quot;HBase InputFormat test failed. &quot; + e.getMessage());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for (String rowId : ROW_IDS) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Please add a check that `ROW_IDS` and `resultSet` have the same size to ensure that each record is read exactly once.&lt;/p&gt;</comment>
                            <comment id="15509366" author="githubbot" created="Wed, 21 Sep 2016 09:32:48 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79791053&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79791053&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -67,18 +66,23 @@&lt;br/&gt;
     	protected abstract T mapResultToTuple(Result r);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can we remove the confusing comment `&quot;abstract methods allow for multiple table and scanners in the same job&quot;` and add JavaDocs to all abstract methods that describe what is expected from their implementation?&lt;/p&gt;

&lt;p&gt;    A `TableInputFormat` instance should only scan a single table. In case more tables need to be read, each could be read with a separate `TableInputFormat` instance and the output of those could be unioned if needed.&lt;/p&gt;</comment>
                            <comment id="15509367" author="githubbot" created="Wed, 21 Sep 2016 09:32:48 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79791290&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79791290&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/java/org/apache/flink/addons/hbase/TestTableInputFormatITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,112 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.addons.hbase;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
    +import org.apache.flink.api.java.DataSet;&lt;br/&gt;
    +import org.apache.flink.api.java.ExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.api.java.io.LocalCollectionOutputFormat;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.hadoop.hbase.TableName;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.HTable;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Put;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Scan;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Before;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TestTableInputFormatITCase extends HBaseTestingClusterAutostarter {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Please rename to `TableInputFormatITCase`.&lt;/p&gt;</comment>
                            <comment id="15509369" author="githubbot" created="Wed, 21 Sep 2016 09:32:48 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79791990&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79791990&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/resources/hbase-site.xml &amp;#8212;&lt;br/&gt;
    @@ -1,43 +0,0 @@&lt;br/&gt;
    -&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;&lt;br/&gt;
    -&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;&lt;br/&gt;
    &lt;del&gt;&amp;lt;!&lt;/del&gt;-&lt;br/&gt;
    -/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one&lt;/li&gt;
	&lt;li&gt;* or more contributor license agreements.  See the NOTICE file&lt;/li&gt;
	&lt;li&gt;* distributed with this work for additional information&lt;/li&gt;
	&lt;li&gt;* regarding copyright ownership.  The ASF licenses this file&lt;/li&gt;
	&lt;li&gt;* to you under the Apache License, Version 2.0 (the&lt;/li&gt;
	&lt;li&gt;* &quot;License&quot;); you may not use this file except in compliance&lt;/li&gt;
	&lt;li&gt;* with the License.  You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;*     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
    ---&amp;gt;&lt;br/&gt;
    -&amp;lt;configuration&amp;gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I see, thanks.&lt;br/&gt;
    I think so far this file has been used as a template. Not sure how valuable it is to have.&lt;/p&gt;</comment>
                            <comment id="15509370" author="githubbot" created="Wed, 21 Sep 2016 09:32:48 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79791171&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79791171&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -67,18 +66,23 @@&lt;br/&gt;
     	protected abstract T mapResultToTuple(Result r);&lt;/p&gt;

&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* creates a 
{@link Scan} object and a {@link HTable} connection&lt;br/&gt;
    +	 * Creates a {@link Scan}
&lt;p&gt; object and opens the &lt;/p&gt;
{@link HTable}
&lt;p&gt; connection.&lt;br/&gt;
    +	 * These are opened here because they are needed in the createInputSplits&lt;br/&gt;
    +	 * which is called before the openInputFormat method.&lt;br/&gt;
    +	 * So the connection is opened in &lt;/p&gt;
{@link #configure(Configuration)}
&lt;p&gt; and closed in &lt;/p&gt;
{@link #closeInputFormat()}
&lt;p&gt;.&lt;br/&gt;
     	 *&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* @param parameters&lt;br/&gt;
    +	 * @param parameters The configuration that is to be used&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@see Configuration&lt;br/&gt;
     	 */&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public void configure(Configuration parameters) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.table = createTable();&lt;/li&gt;
	&lt;li&gt;this.scan = getScanner();&lt;br/&gt;
    +		table = createTable();&lt;br/&gt;
    +		scan = getScanner();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Can you add a check that `table` and `scan` are properly initialized, i.e., `!= null`?&lt;/p&gt;</comment>
                            <comment id="15509694" author="githubbot" created="Wed, 21 Sep 2016 11:57:41 +0000"  >&lt;p&gt;Github user nielsbasjes commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79816123&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79816123&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/main/java/org/apache/flink/addons/hbase/TableInputFormat.java &amp;#8212;&lt;br/&gt;
    @@ -67,18 +66,23 @@&lt;br/&gt;
     	protected abstract T mapResultToTuple(Result r);&lt;/p&gt;

&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* creates a 
{@link Scan} object and a {@link HTable} connection&lt;br/&gt;
    +	 * Creates a {@link Scan}
&lt;p&gt; object and opens the &lt;/p&gt;
{@link HTable}
&lt;p&gt; connection.&lt;br/&gt;
    +	 * These are opened here because they are needed in the createInputSplits&lt;br/&gt;
    +	 * which is called before the openInputFormat method.&lt;br/&gt;
    +	 * So the connection is opened in &lt;/p&gt;
{@link #configure(Configuration)}
&lt;p&gt; and closed in &lt;/p&gt;
{@link #closeInputFormat()}
&lt;p&gt;.&lt;br/&gt;
     	 *&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* @param parameters&lt;br/&gt;
    +	 * @param parameters The configuration that is to be used&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@see Configuration&lt;br/&gt;
     	 */&lt;br/&gt;
     	@Override&lt;br/&gt;
     	public void configure(Configuration parameters) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.table = createTable();&lt;/li&gt;
	&lt;li&gt;this.scan = getScanner();&lt;br/&gt;
    +		table = createTable();&lt;br/&gt;
    +		scan = getScanner();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Done. Yet because &apos;configure()&apos; doesn&apos;t have a way to fail nicely I added those checks to the other methods.&lt;/p&gt;</comment>
                            <comment id="15509695" author="githubbot" created="Wed, 21 Sep 2016 11:57:45 +0000"  >&lt;p&gt;Github user nielsbasjes commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79816134&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79816134&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/java/org/apache/flink/addons/hbase/TestTableInputFormatITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,112 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.addons.hbase;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
    +import org.apache.flink.api.java.DataSet;&lt;br/&gt;
    +import org.apache.flink.api.java.ExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.api.java.io.LocalCollectionOutputFormat;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.hadoop.hbase.TableName;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.HTable;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Put;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Scan;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Before;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TestTableInputFormatITCase extends HBaseTestingClusterAutostarter {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Done&lt;/p&gt;</comment>
                            <comment id="15509696" author="githubbot" created="Wed, 21 Sep 2016 11:57:51 +0000"  >&lt;p&gt;Github user nielsbasjes commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330#discussion_r79816145&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330#discussion_r79816145&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-batch-connectors/flink-hbase/src/test/java/org/apache/flink/addons/hbase/TestTableInputFormatITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,112 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.addons.hbase;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.functions.MapFunction;&lt;br/&gt;
    +import org.apache.flink.api.java.DataSet;&lt;br/&gt;
    +import org.apache.flink.api.java.ExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.api.java.io.LocalCollectionOutputFormat;&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.hadoop.hbase.TableName;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.HTable;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Put;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Result;&lt;br/&gt;
    +import org.apache.hadoop.hbase.client.Scan;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Before;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +public class TestTableInputFormatITCase extends HBaseTestingClusterAutostarter {&lt;br/&gt;
    +	private static final String TEST_TABLE_NAME = &quot;TableInputFormatTestTable&quot;;&lt;br/&gt;
    +	private static final byte[] TEST_TABLE_FAMILY_NAME = &quot;F&quot;.getBytes();&lt;br/&gt;
    +	private static final byte[] TEST_TABLE_COLUMN_NAME = &quot;Col&quot;.getBytes();&lt;br/&gt;
    +&lt;br/&gt;
    +	// These are the row ids AND also the values we will put in the test table&lt;br/&gt;
    +	private static final String[] ROW_IDS = &lt;/p&gt;
{&quot;000&quot;, &quot;111&quot;, &quot;222&quot;, &quot;333&quot;, &quot;444&quot;, &quot;555&quot;, &quot;666&quot;, &quot;777&quot;, &quot;888&quot;, &quot;999&quot;}
&lt;p&gt;;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Before&lt;br/&gt;
    +	public void createTestTable() throws IOException {&lt;br/&gt;
    +		TableName tableName = TableName.valueOf(TEST_TABLE_NAME);&lt;br/&gt;
    +		byte[][] splitKeys = &lt;/p&gt;
{&quot;0&quot;.getBytes(), &quot;3&quot;.getBytes(), &quot;6&quot;.getBytes(), &quot;9&quot;.getBytes()}
&lt;p&gt;;&lt;br/&gt;
    +		createTable(tableName, TEST_TABLE_FAMILY_NAME, splitKeys);&lt;br/&gt;
    +		HTable table = openTable(tableName);&lt;br/&gt;
    +&lt;br/&gt;
    +		for (String rowId : ROW_IDS) &lt;/p&gt;
{
    +			byte[] rowIdBytes = rowId.getBytes();
    +			Put p = new Put(rowIdBytes);
    +			// Use the rowId as the value to facilitate the testing better
    +			p.add(TEST_TABLE_FAMILY_NAME, TEST_TABLE_COLUMN_NAME, rowIdBytes);
    +			table.put(p);
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		table.close();&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	class InputFormatForTestTable extends TableInputFormat&amp;lt;Tuple1&amp;lt;String&amp;gt;&amp;gt; {&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected Scan getScanner() &lt;/p&gt;
{
    +			return new Scan();
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected String getTableName() &lt;/p&gt;
{
    +			return TEST_TABLE_NAME;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		protected Tuple1&amp;lt;String&amp;gt; mapResultToTuple(Result r) &lt;/p&gt;
{
    +			return new Tuple1&amp;lt;&amp;gt;(new String(r.getValue(TEST_TABLE_FAMILY_NAME, TEST_TABLE_COLUMN_NAME)));
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testTableInputFormat() {&lt;br/&gt;
    +		ExecutionEnvironment environment = ExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		environment.setParallelism(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		DataSet&amp;lt;String&amp;gt; resultDataSet =&lt;br/&gt;
    +			environment.createInput(new InputFormatForTestTable()).map(new MapFunction&amp;lt;Tuple1&amp;lt;String&amp;gt;, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String map(Tuple1&amp;lt;String&amp;gt; value) throws Exception &lt;/p&gt;
{
    +					return value.f0;
    +				}
&lt;p&gt;    +			});&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;String&amp;gt; resultSet = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		resultDataSet.output(new LocalCollectionOutputFormat&amp;lt;&amp;gt;(resultSet));&lt;br/&gt;
    +&lt;br/&gt;
    +		try &lt;/p&gt;
{
    +			environment.execute(&quot;HBase InputFormat Test&quot;);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			Assert.fail(&quot;HBase InputFormat test failed. &quot; + e.getMessage());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		for (String rowId : ROW_IDS) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Done&lt;/p&gt;</comment>
                            <comment id="15512604" author="githubbot" created="Thu, 22 Sep 2016 08:27:20 +0000"  >&lt;p&gt;Github user fhueske commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hi @nielsbasjes, thanks for fixing and cleaning up the `TableInputFormat`. &lt;br/&gt;
    This PR is good to merge.&lt;/p&gt;</comment>
                            <comment id="15544916" author="githubbot" created="Tue, 4 Oct 2016 09:44:35 +0000"  >&lt;p&gt;Github user fhueske commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hi @nielsbasjes, I just posted to the dev mailinglist and proposed to update the HBase dependency to 1.2.3 (as &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2765&quot; title=&quot;Upgrade hbase version for hadoop-2 to 1.2 release&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-2765&quot;&gt;&lt;del&gt;FLINK-2765&lt;/del&gt;&lt;/a&gt;(&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-2765&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-2765&lt;/a&gt;) suggests). By the end of the week we have a decision and I will merge this PR to the master branch.&lt;/p&gt;

&lt;p&gt;    In the meantime, I will merge the fixed TableInputFormat changes to the Flink 1.1 branch and revert all breaking changes (pom.xml, RichInputFormat, hbase-site.xml, tests, ...). &lt;br/&gt;
    For Flink 1.2.0 we want these changes.&lt;/p&gt;

&lt;p&gt;    Thanks, Fabian&lt;/p&gt;</comment>
                            <comment id="15545404" author="fhueske" created="Tue, 4 Oct 2016 13:54:10 +0000"  >&lt;p&gt;Merged for Flink 1.1 as 98b399d4b4ddc9ab5d01e40dcb9ab0889f0d1067&lt;/p&gt;</comment>
                            <comment id="15560672" author="githubbot" created="Sun, 9 Oct 2016 21:41:59 +0000"  >&lt;p&gt;Github user fhueske commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I noticed building this PR for hadoop1 (`mvn clean install -Dhadoop.profile=1`) fails:&lt;/p&gt;

&lt;p&gt;    &amp;gt; The following artifacts could not be resolved: org.apache.hadoop:hadoop-hdfs:jar:tests:1.2.1, org.apache.hbase:hbase-hadoop2-compat:jar:tests:0.98.11-hadoop1: Could not find artifact org.apache.hadoop:hadoop-hdfs:jar:tests:1.2.1 in central&lt;/p&gt;

&lt;p&gt;    I&apos;m not a Maven guru. Is it possible to disable compiling and executing the tests for the hadoop1 profile?&lt;/p&gt;</comment>
                            <comment id="15561703" author="githubbot" created="Mon, 10 Oct 2016 09:00:35 +0000"  >&lt;p&gt;Github user fhueske commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I&apos;ll propose to drop the hadoop1 builds on the dev ML.&lt;/p&gt;</comment>
                            <comment id="15561846" author="githubbot" created="Mon, 10 Oct 2016 09:56:50 +0000"  >&lt;p&gt;Github user fhueske commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I disabled tests for the hadoop1 profile. &lt;br/&gt;
    Will build the PR one more time and merge if everything passes.&lt;/p&gt;</comment>
                            <comment id="15562203" author="githubbot" created="Mon, 10 Oct 2016 12:43:15 +0000"  >&lt;p&gt;Github user fhueske commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Merging&lt;/p&gt;</comment>
                            <comment id="15563131" author="githubbot" created="Mon, 10 Oct 2016 18:50:58 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2330&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2330&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15563144" author="fhueske" created="Mon, 10 Oct 2016 18:56:38 +0000"  >&lt;p&gt;Fixed for 1.2.0 with 3f8727921e944d1d89714f5885c2de63681d51b2&lt;/p&gt;

&lt;p&gt;Thanks for the fix &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nielsbasjes&quot; class=&quot;user-hover&quot; rel=&quot;nielsbasjes&quot;&gt;nielsbasjes&lt;/a&gt;!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 6 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i31uqf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>