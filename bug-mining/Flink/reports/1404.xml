<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:26:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-5364] Rework JAAS configuration to support user-supplied entries</title>
                <link>https://issues.apache.org/jira/browse/FLINK-5364</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Recent issues (see linked) have brought to light a critical deficiency in the handling of JAAS configuration.   &lt;/p&gt;

&lt;p&gt;1. the MapR distribution relies on an explicit JAAS conf, rather than in-memory conf used by stock Hadoop.&lt;br/&gt;
2. the ZK/Kafka/Hadoop security configuration is supposed to be independent (one can enable each element separately) but isn&apos;t.&lt;/p&gt;

&lt;p&gt;Perhaps we should rework the JAAS conf code to merge any user-supplied configuration with our defaults, rather than using an all-or-nothing approach.   &lt;/p&gt;

&lt;p&gt;We should also address some recent regressions:&lt;/p&gt;

&lt;p&gt;1. The HadoopSecurityContext should be installed regardless of auth mode, to login with UserGroupInformation, which:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;handles the HADOOP_USER_NAME variable.&lt;/li&gt;
	&lt;li&gt;installs an OS-specific user principal (from UnixLoginModule etc.) unrelated to Kerberos.&lt;/li&gt;
	&lt;li&gt;picks up the HDFS/HBASE delegation tokens.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2. Fix the use of alternative authentication methods - delegation tokens and Kerberos ticket cache.&lt;/p&gt;

</description>
                <environment></environment>
        <key id="13029028">FLINK-5364</key>
            <summary>Rework JAAS configuration to support user-supplied entries</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="eronwright">Eron Wright</assignee>
                                    <reporter username="eronwright">Eron Wright</reporter>
                        <labels>
                            <label>kerberos</label>
                            <label>security</label>
                    </labels>
                <created>Mon, 19 Dec 2016 00:50:44 +0000</created>
                <updated>Thu, 28 Feb 2019 14:12:57 +0000</updated>
                            <resolved>Wed, 11 Jan 2017 20:21:41 +0000</resolved>
                                                    <fixVersion>1.2.0</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>Runtime / Coordination</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15761960" author="eronwright" created="Mon, 19 Dec 2016 18:42:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann@apache.org&quot;&gt;trohrmann@apache.org&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mxm&quot; class=&quot;user-hover&quot; rel=&quot;mxm&quot;&gt;mxm&lt;/a&gt; Bringing this to your attention as a critical fix for Flink 1.2.&lt;/p&gt;</comment>
                            <comment id="15763722" author="eronwright" created="Tue, 20 Dec 2016 09:16:10 +0000"  >&lt;p&gt;Here&apos;s a WIP to show how I plan to fix the problem.    Basically this patch:&lt;br/&gt;
a) makes it explicit how the login credentials are shared with connectors&lt;br/&gt;
b) allows for the use of a user-suppled JAAS config (which fixes the MapR issue of &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5055&quot; title=&quot;Security feature crashes JM for certain Hadoop versions even though using no Kerberos&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5055&quot;&gt;&lt;del&gt;FLINK-5055&lt;/del&gt;&lt;/a&gt;)&lt;br/&gt;
c) decouples the various aspects into independent &apos;modules&apos;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/EronWright/flink/pull/3&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/EronWright/flink/pull/3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Additional test work is needed.&lt;/p&gt;

&lt;p&gt;CC &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vijikarthi&quot; class=&quot;user-hover&quot; rel=&quot;vijikarthi&quot;&gt;vijikarthi&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15767065" author="till.rohrmann" created="Wed, 21 Dec 2016 13:33:02 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eronwright&quot; class=&quot;user-hover&quot; rel=&quot;eronwright&quot;&gt;eronwright&lt;/a&gt;, I think you&apos;re right and we should definitely try to fix it for the final 1.2 release. Great that you&apos;re looking into it.&lt;/p&gt;

&lt;p&gt;Do you want to open the PR against the Flink Github repository? I guess we can already make a first round of review work.&lt;/p&gt;</comment>
                            <comment id="15797211" author="githubbot" created="Wed, 4 Jan 2017 05:20:55 +0000"  >&lt;p&gt;GitHub user EronWright opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5364&quot; title=&quot;Rework JAAS configuration to support user-supplied entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5364&quot;&gt;&lt;del&gt;FLINK-5364&lt;/del&gt;&lt;/a&gt; Rework JAAS configuration to support user-supplied entries&lt;/p&gt;

&lt;p&gt;    Fixes &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5364&quot; title=&quot;Rework JAAS configuration to support user-supplied entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5364&quot;&gt;&lt;del&gt;FLINK-5364&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5361&quot; title=&quot;Flink shouldn&amp;#39;t require Kerberos credentials&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5361&quot;&gt;&lt;del&gt;FLINK-5361&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5350&quot; title=&quot;Don&amp;#39;t overwrite existing Jaas config property&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5350&quot;&gt;&lt;del&gt;FLINK-5350&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5055&quot; title=&quot;Security feature crashes JM for certain Hadoop versions even though using no Kerberos&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5055&quot;&gt;&lt;del&gt;FLINK-5055&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    CC @tillrohrmann &lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/EronWright/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/EronWright/flink&lt;/a&gt; feature-&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5364&quot; title=&quot;Rework JAAS configuration to support user-supplied entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5364&quot;&gt;&lt;del&gt;FLINK-5364&lt;/del&gt;&lt;/a&gt;-rebase&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3057&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 4acf43624c16627aaa89560c8361fe4bf9a19fa6&lt;br/&gt;
Author: wrighe3 &amp;lt;eron.wright@emc.com&amp;gt;&lt;br/&gt;
Date:   2016-12-20T09:07:38Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5364&quot; title=&quot;Rework JAAS configuration to support user-supplied entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5364&quot;&gt;&lt;del&gt;FLINK-5364&lt;/del&gt;&lt;/a&gt; Rework JAAS configuration to support user-supplied entries&lt;/p&gt;

&lt;p&gt;    Fixes &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5364&quot; title=&quot;Rework JAAS configuration to support user-supplied entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5364&quot;&gt;&lt;del&gt;FLINK-5364&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5361&quot; title=&quot;Flink shouldn&amp;#39;t require Kerberos credentials&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5361&quot;&gt;&lt;del&gt;FLINK-5361&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5350&quot; title=&quot;Don&amp;#39;t overwrite existing Jaas config property&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5350&quot;&gt;&lt;del&gt;FLINK-5350&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5055&quot; title=&quot;Security feature crashes JM for certain Hadoop versions even though using no Kerberos&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5055&quot;&gt;&lt;del&gt;FLINK-5055&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;commit 2d56de9fe1da2e0ecdfd02498b71a8477e9295b3&lt;br/&gt;
Author: wrighe3 &amp;lt;eron.wright@emc.com&amp;gt;&lt;br/&gt;
Date:   2017-01-04T05:18:12Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5364&quot; title=&quot;Rework JAAS configuration to support user-supplied entries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5364&quot;&gt;&lt;del&gt;FLINK-5364&lt;/del&gt;&lt;/a&gt; Rework JAAS configuration to support user-supplied entries&lt;/p&gt;

&lt;p&gt;    Minor fixes and doc changes.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15805194" author="githubbot" created="Fri, 6 Jan 2017 18:17:20 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @EronWright thanks a lot for this fix, I am looking though it now.&lt;/p&gt;

&lt;p&gt;    From the description in the JIRAs, I take that this adds the logic that reads custom JAAS security configurations and uses Flink&apos;s internal one (Hadoop UGI based) for fallback default?&lt;/p&gt;

&lt;p&gt;    This should be relevant for the `master` and the 1.2 release branch, correct?&lt;/p&gt;
</comment>
                            <comment id="15805599" author="githubbot" created="Fri, 6 Jan 2017 20:07:55 +0000"  >&lt;p&gt;Github user EronWright commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen yes, this PR does the following:&lt;br/&gt;
    1. isolate the configuration of kerberos credentials from how those credentials are used&lt;br/&gt;
    2. modularize the security code to reflect the independent aspects of configuring Hadoop vs. JAAS based on the credential.&lt;br/&gt;
    3. make explicit as to which JAAS login contexts are provided the cluster&apos;s credential&lt;br/&gt;
    4. incorporate the user-supplied JAAS (to satisfy the MapR scenario)&lt;br/&gt;
    5. update `config.md` and `internals/security.md`&lt;/p&gt;

&lt;p&gt;    The main user impact is that one must explicitly share the credential with specific contexts - the &apos;KafkaClient&apos; login context, ZooKeeper &apos;Client&apos; context, etc, based on whether the corresponding service is kerberized.  Earlier we had tried to always share the credential to all JAAS contexts, but this caused problems.     &lt;/p&gt;

&lt;p&gt;    With this patch, I believe the design goal is met of allowing Kerberos to be independently enabled for any external connection.  For example, a Kerberized Kafka + a non-Kerberized Hadoop is a valid scenario.&lt;/p&gt;

</comment>
                            <comment id="15805600" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95009232&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95009232&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/SecurityUtils.java &amp;#8212;&lt;br/&gt;
    @@ -71,163 +64,93 @@&lt;br/&gt;
     	 */&lt;br/&gt;
     	public static void install(SecurityConfiguration config) throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!config.securityIsEnabled()) 
{
    -			// do not perform any initialization if no Kerberos crendetails are provided
    -			return;
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// establish the JAAS config&lt;/li&gt;
	&lt;li&gt;JaasConfiguration jaasConfig = new JaasConfiguration(config.keytab, config.principal);&lt;/li&gt;
	&lt;li&gt;javax.security.auth.login.Configuration.setConfiguration(jaasConfig);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;populateSystemSecurityProperties(config.flinkConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// establish the UGI login user&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.setConfiguration(config.hadoopConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// only configure Hadoop security if we have security enabled&lt;/li&gt;
	&lt;li&gt;if (UserGroupInformation.isSecurityEnabled()) {&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;final UserGroupInformation loginUser;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (config.keytab != null &amp;amp;&amp;amp; !StringUtils.isBlank(config.principal)) {&lt;/li&gt;
	&lt;li&gt;String keytabPath = (new File(config.keytab)).getAbsolutePath();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.loginUserFromKeytab(config.principal, keytabPath);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// supplement with any available tokens&lt;/li&gt;
	&lt;li&gt;String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);&lt;/li&gt;
	&lt;li&gt;if (fileLocation != null) {&lt;/li&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* Use reflection API since the API semantics are not available in Hadoop1 profile. Below APIs are&lt;/li&gt;
	&lt;li&gt;* used in the context of reading the stored tokens from UGI.&lt;/li&gt;
	&lt;li&gt;* Credentials cred = Credentials.readTokenStorageFile(new File(fileLocation), config.hadoopConf);&lt;/li&gt;
	&lt;li&gt;* loginUser.addCredentials(cred);&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;try 
{
    -						Method readTokenStorageFileMethod = Credentials.class.getMethod(&quot;readTokenStorageFile&quot;,
    -							File.class, org.apache.hadoop.conf.Configuration.class);
    -						Credentials cred = (Credentials) readTokenStorageFileMethod.invoke(null, new File(fileLocation),
    -							config.hadoopConf);
    -						Method addCredentialsMethod = UserGroupInformation.class.getMethod(&quot;addCredentials&quot;,
    -							Credentials.class);
    -						addCredentialsMethod.invoke(loginUser, cred);
    -					}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;} else {&lt;/li&gt;
	&lt;li&gt;// login with current user credentials (e.g. ticket cache)&lt;/li&gt;
	&lt;li&gt;try 
{
    -					//Use reflection API to get the login user object
    -					//UserGroupInformation.loginUserFromSubject(null);
    -					Method loginUserFromSubjectMethod = UserGroupInformation.class.getMethod(&quot;loginUserFromSubject&quot;, Subject.class);
    -					Subject subject = null;
    -					loginUserFromSubjectMethod.invoke(null, subject);
    -				}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// note that the stored tokens are read automatically&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		// install the security modules&lt;br/&gt;
    +		List&amp;lt;SecurityModule&amp;gt; modules = new ArrayList();&lt;br/&gt;
    +		try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			for (Class&amp;lt;? extends SecurityModule&amp;gt; moduleClass }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		catch(Exception ex) &lt;/p&gt;
{
    +			throw new Exception(&quot;unable to establish the security context&quot;, ex);
    +		}
&lt;p&gt;    +		installedModules = modules;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LOG.info(&quot;Hadoop user set to {}&quot;, loginUser.toString());&lt;br/&gt;
    +		// install a security context&lt;br/&gt;
    +		// use the Hadoop login user as the subject of the installed security context&lt;br/&gt;
    +		if (!(installedContext instanceof NoOpSecurityContext)) 
{
    +			LOG.warn(&quot;overriding previous security context&quot;);
    +		}
&lt;p&gt;    +		UserGroupInformation loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		installedContext = new HadoopSecurityContext(loginUser);&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean delegationToken = false;&lt;/li&gt;
	&lt;li&gt;final Text HDFS_DELEGATION_KIND = new Text(&quot;HDFS_DELEGATION_TOKEN&quot;);&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;Token&amp;lt;? extends TokenIdentifier&amp;gt;&amp;gt; usrTok = loginUser.getTokens();&lt;/li&gt;
	&lt;li&gt;for (Token&amp;lt;? extends TokenIdentifier&amp;gt; token : usrTok) {&lt;/li&gt;
	&lt;li&gt;final Text id = new Text(token.getIdentifier());&lt;/li&gt;
	&lt;li&gt;LOG.debug(&quot;Found user token &quot; + id + &quot; with &quot; + token);&lt;/li&gt;
	&lt;li&gt;if (token.getKind().equals(HDFS_DELEGATION_KIND)) {&lt;/li&gt;
	&lt;li&gt;delegationToken = true;&lt;br/&gt;
    +	static void uninstall() {&lt;br/&gt;
    +		if(installedModules != null) {&lt;br/&gt;
    +			for (SecurityModule module : Lists.reverse(installedModules)) {&lt;br/&gt;
    +				try 
{
    +					module.uninstall();
     				}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (!loginUser.hasKerberosCredentials()) {&lt;/li&gt;
	&lt;li&gt;//throw an error in non-yarn deployment if kerberos cache is not available&lt;/li&gt;
	&lt;li&gt;if (!delegationToken) {&lt;/li&gt;
	&lt;li&gt;LOG.error(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;/li&gt;
	&lt;li&gt;throw new RuntimeException(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;br/&gt;
    +				catch(UnsupportedOperationException e) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    It seems uninstalling in not really supported by some modules. Why do they throw an exception if the exception is ignored anyways? Can they not simply do nothing, maybe log a warning? Does it make sense to add a method `supportsUninstall()` to `SecurityModule`?&lt;/p&gt;</comment>
                            <comment id="15805601" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r94997957&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r94997957&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: docs/internals/flink_security.md &amp;#8212;&lt;br/&gt;
    @@ -24,64 +24,109 @@ specific language governing permissions and limitations&lt;br/&gt;
     under the License.&lt;br/&gt;
     --&amp;gt;&lt;/p&gt;

&lt;p&gt;    -This document briefly describes how Flink security works in the context of various deployment mechanism (Standalone/Cluster vs YARN) &lt;br/&gt;
    -and the connectors that participates in Flink Job execution stage. This documentation can be helpful for both administrators and developers &lt;br/&gt;
    -who plans to run Flink on a secure environment.&lt;br/&gt;
    +This document briefly describes how Flink security works in the context of various deployment mechanisms (Standalone, YARN, or Mesos), &lt;br/&gt;
    +filesystems, connectors, and state backends.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Objective&lt;br/&gt;
    +The primary goals of the Flink Kerberos security infrastructure are:&lt;br/&gt;
    +1. to enable secure data access for jobs within a cluster via connectors (e.g. Kafka)&lt;br/&gt;
    +2. to authenticate to ZooKeeper (if configured to use SASL)&lt;br/&gt;
    +3. to authenticate to Hadoop components (e.g. HDFS, HBase) &lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    -The primary goal of Flink security model is to enable secure data access for jobs within a cluster via connectors. In a production deployment scenario, &lt;br/&gt;
    -streaming jobs are understood to run for longer period of time (days/weeks/months) and the system must be  able to authenticate against secure &lt;br/&gt;
    -data sources throughout the life of the job. The current implementation supports running Flink clusters (Job Manager/Task Manager/Jobs) under the &lt;br/&gt;
    -context of a Kerberos identity based on Keytab credential supplied during deployment time. Any jobs submitted will continue to run in the identity of the cluster.&lt;br/&gt;
    +In a production deployment scenario, streaming jobs are understood to run for long periods of time (days/weeks/months) and be able to authenticate to secure &lt;br/&gt;
    +data sources throughout the life of the job.  Kerberos keytabs do not expire in that timeframe, unlike a Hadoop delegation token&lt;br/&gt;
    +or ticket cache entry.&lt;br/&gt;
    +&lt;br/&gt;
    +The current implementation supports running Flink clusters (Job Manager/Task Manager/jobs) with either a configured keytab credential&lt;br/&gt;
    +or with Hadoop delegation tokens.   Keep in mind that all jobs share the credential configured for a given cluster.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;How Flink Security works&lt;br/&gt;
    -Flink deployment includes running Job Manager/ZooKeeper, Task Manager(s), Web UI and Job(s). Jobs (user code) can be submitted through web UI and/or CLI. &lt;br/&gt;
    -A Job program may use one or more connectors (Kafka, HDFS, Cassandra, Flume, Kinesis etc.,) and each connector may have a specific security &lt;br/&gt;
    -requirements (Kerberos, database based, SSL/TLS, custom etc.,). While satisfying the security requirements for all the connectors evolves over a period &lt;br/&gt;
    -of time, at this time of writing, the following connectors/services are tested for Kerberos/Keytab based security.&lt;br/&gt;
    +In concept, a Flink program may use first- or third-party connectors (Kafka, HDFS, Cassandra, Flume, Kinesis etc.) necessitating arbitrary authentication methods (Kerberos, SSL/TLS, username/password, etc.).  While satisfying the security requirements for all connectors is an ongoing effort,&lt;br/&gt;
    +Flink provides first-class support for Kerberos authentication only.  The following services and connectors are tested for Kerberos authentication:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    &amp;#8211; Kafka (0.9)&lt;br/&gt;
    &lt;ins&gt;- Kafka (0.9&lt;/ins&gt;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;HDFS&lt;br/&gt;
    +- HBase&lt;/li&gt;
	&lt;li&gt;ZooKeeper&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -Hadoop uses the UserGroupInformation (UGI) class to manage security. UGI is a static implementation that takes care of handling Kerberos authentication. The Flink bootstrap implementation&lt;br/&gt;
    -(JM/TM/CLI) takes care of instantiating UGI with the appropriate security credentials to establish the necessary security context.&lt;br/&gt;
    +Note that it is possible to enable the use of Kerberos independently for each service or connector.  For example, the user may enable &lt;br/&gt;
    +Hadoop security without necessitating the use of Kerberos for ZooKeeper, or vice versa.    The shared element is the configuration of &lt;br/&gt;
    +Kerbreros credentials, which is then explicitly used by each component.&lt;br/&gt;
    +&lt;br/&gt;
    +The internal architecture is based on security modules (implementing `org.apache.flink.runtime.security.modules.SecurityModule`) which&lt;br/&gt;
    +are installed at startup.  The next section describes each security module.&lt;br/&gt;
    +&lt;br/&gt;
    +### Hadoop Security Module&lt;br/&gt;
    +This module uses the Hadoop `UserGroupInformation` (UGI) class to establish a process-wide &lt;b&gt;login user&lt;/b&gt; context.   The login user is&lt;br/&gt;
    +then used for all interactions with Hadoop, including HDFS, HBase, and YARN.&lt;br/&gt;
    +&lt;br/&gt;
    +If Hadoop security is enabled (in `core-site.xml`), the login user will have whatever Kerberos credential is configured.  Otherwise,&lt;br/&gt;
    +the login user conveys only the user identity of the OS account that launched the cluster.&lt;br/&gt;
    +&lt;br/&gt;
    +### JAAS Security Module&lt;br/&gt;
    +This module provides a dynamic JAAS configuration to the cluster, making available the configured Kerberos credential to ZooKeeper,&lt;br/&gt;
    +Kafka, and other such components that rely on JAAS.&lt;br/&gt;
    +&lt;br/&gt;
    +Note that the user may also provide a static JAAS configuration file using the mechanisms described in the &lt;span class=&quot;error&quot;&gt;&amp;#91;Java SE Documentation&amp;#93;&lt;/span&gt;(&lt;a href=&quot;http://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/LoginConfigFile.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/LoginConfigFile.html&lt;/a&gt;).   Static entries override any&lt;br/&gt;
    +dynamic entries provided by this module.&lt;br/&gt;
    +&lt;br/&gt;
    +### ZooKeeper Security Module&lt;br/&gt;
    +This module configures certain process-wide ZooKeeper security-related settings, namely the ZooKeeper service name (default: `zookeeper`)&lt;br/&gt;
    +and the JAAS login context name (default: `Client`).&lt;br/&gt;
    +&lt;br/&gt;
    +## Security Configuration&lt;br/&gt;
    +&lt;br/&gt;
    +### Flink Configuration&lt;br/&gt;
    +The user&apos;s Kerberos ticket cache (managed with `kinit`) is used automatically, based on the following configuration option:&lt;br/&gt;
    +&lt;br/&gt;
    +- `security.kerberos.login.use-ticket-cache`: Indicates whether to read from the user&apos;s Kerberos ticket cache (default: `true`).&lt;br/&gt;
    +&lt;br/&gt;
    +A Kerberos keytab can be supplied by adding below configuration elements to the Flink configuration file:&lt;br/&gt;
    +&lt;br/&gt;
    +- `security.kerberos.login.keytab`: Absolute path to a Kerberos keytab file that contains the user credentials.&lt;br/&gt;
    +&lt;br/&gt;
    +- `security.kerberos.login.principal`: Kerberos principal name associated with the keytab.&lt;br/&gt;
    +&lt;br/&gt;
    +These configuration options establish a cluster-wide credential to be used in a Hadoop and/or JAAS context.  Whether the credential is used in a Hadoop context is based on the Hadoop configuration (see next section).   To be used in a JAAS context, the configuration specifies which JAAS &lt;b&gt;login contexts&lt;/b&gt; (or &lt;b&gt;applications&lt;/b&gt;) are enabled with the following configuration option:&lt;br/&gt;
    +&lt;br/&gt;
    +- `security.kerberos.login.contexts`: A comma-separated list of login contexts to provide the Kerberos credentials to (for example, `Client` to use the credentials for ZooKeeper authentication).&lt;/p&gt;

&lt;p&gt;    -Services like Kafka and ZooKeeper use SASL/JAAS based authentication mechanism to authenticate against a Kerberos server. It expects JAAS configuration with a platform-specific login &lt;br/&gt;
    -module &lt;b&gt;name&lt;/b&gt; to be provided. Managing per-connector configuration files will be an overhead and to overcome this requirement, a process-wide JAAS configuration object is &lt;br/&gt;
    -instantiated which serves standard ApplicationConfigurationEntry for the connectors that authenticates using SASL/JAAS mechanism.&lt;br/&gt;
    +ZooKeeper-related configuration overrides:&lt;/p&gt;

&lt;p&gt;    -It is important to understand that the Flink processes (JM/TM/UI/Jobs) itself uses UGI&apos;s doAS() implementation to run under a specific user context, i.e. if Hadoop security is enabled &lt;br/&gt;
    -then the Flink processes will be running under a secure user account or else it will run as the OS login user account who starts the Flink cluster.&lt;br/&gt;
    +- `zookeeper.sasl.service-name`: The Kerberos service name that the ZooKeeper cluster is configured to use (default: `zookeeper`). Facilitates mutual-authentication between the client (Flink) and server.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Security Configurations&lt;br/&gt;
    +- `zookeeper.sasl.login-context-name`: The JAAS login context name that the ZooKeeper client uses to request the login context (default: `Client`). Should match&lt;br/&gt;
    +one of the values specified in `security.kerberos.login.contexts`.&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -Secure credentials can be supplied by adding below configuration elements to Flink configuration file:&lt;br/&gt;
    +### Hadoop Configuration&lt;/p&gt;

&lt;p&gt;    &amp;#8211; `security.keytab`: Absolute path to Kerberos keytab file that contains the user credentials/secret.&lt;br/&gt;
    +The Hadoop configuration is located via the `HADOOP_CONF_DIR` environment variable and by other means (see `org.apache.flink.api.java.hadoop.mapred.utils.HadoopUtils`).   The Kerberos credential (configured above) is used automatically if Hadoop security is enabled.&lt;/p&gt;

&lt;p&gt;    &amp;#8211; `security.principal`: User principal name that the Flink cluster should run as.&lt;br/&gt;
    +Note that Kerberos credentials found in the ticket cache aren&apos;t transferrable to other hosts.   In this scenario, the Flink CLI acquires Hadoop&lt;br/&gt;
    +delegation tokens (for HDFS and for HBase).&lt;/p&gt;

&lt;p&gt;    -The delegation token mechanism (&lt;b&gt;kinit cache&lt;/b&gt;) is still supported for backward compatibility but enabling security using &lt;b&gt;keytab&lt;/b&gt; configuration is the preferred and recommended approach.&lt;br/&gt;
    +## Deployment Modes&lt;br/&gt;
    +Here is some information specific to each deployment mode.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Standalone Mode:&lt;br/&gt;
    +### Standalone Mode&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     Steps to run a secure Flink cluster in standalone/cluster mode:&lt;br/&gt;
    &amp;#8211; Add security configurations to Flink configuration file (on all cluster nodes) &lt;br/&gt;
    &amp;#8211; Make sure the Keytab file exist in the path as indicated in &lt;b&gt;security.keytab&lt;/b&gt; configuration on all cluster nodes&lt;br/&gt;
    &amp;#8211; Deploy Flink cluster using cluster start/stop scripts or CLI&lt;br/&gt;
    +1. Add security-related configuration options to the Flink configuration file (on all cluster nodes).&lt;br/&gt;
    +2. Ensure that the keytab file exists at the path indicated by `security.kerberos.login.keytab` on all cluster nodes.&lt;br/&gt;
    +3. Deploy Flink cluster as normal.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Yarn Mode:&lt;br/&gt;
    +### YARN/Mesos Mode&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -Steps to run secure Flink cluster in Yarn mode:&lt;br/&gt;
    &amp;#8211; Add security configurations to Flink configuration file (on the node from where cluster will be provisioned using Flink/Yarn CLI) &lt;br/&gt;
    &amp;#8211; Make sure the Keytab file exist in the path as indicated in &lt;b&gt;security.keytab&lt;/b&gt; configuration&lt;br/&gt;
    &amp;#8211; Deploy Flink cluster using CLI&lt;br/&gt;
    +Steps to run a secure Flink cluster in YARN/Mesos mode:&lt;br/&gt;
    +1. Add security-related configuration options to the Flink configuration file on the client.&lt;br/&gt;
    +2. Ensure that the keytab file exists at the path as indicated by `security.kerberos.login.keytab` on the client node.&lt;br/&gt;
    +3. Deploy Flink cluster as normal.&lt;/p&gt;

&lt;p&gt;    -In Yarn mode, the user supplied keytab will be copied over to the Yarn containers (App Master/JM and TM) as the Yarn local resource file.&lt;br/&gt;
    -Security implementation details are based on &amp;lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/markdown/YarnApplicationSecurity.md&quot;&amp;gt;Yarn security&amp;lt;/a&amp;gt; &lt;br/&gt;
    +In YARN/Mesos mode, the keytab is automatically copied from the client to the Flink containers.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Token Renewal&lt;br/&gt;
    +For more information, see &amp;lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/markdown/YarnApplicationSecurity.md&quot;&amp;gt;YARN security&amp;lt;/a&amp;gt; documentation.&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    -UGI and Kafka/ZK login module implementations takes care of auto-renewing the tickets upon reaching expiry and no further action is needed on the part of Flink.&lt;br/&gt;
    \ No newline at end of file&lt;br/&gt;
    +## Further Details&lt;br/&gt;
    +### Ticket Renewal&lt;br/&gt;
    +Each component that uses Kerberos is independently responsible for renewing the Kerberos TGT.   Hadoop, ZooKeeper, and Kafka all do so, &lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I would add a sentence here that this requires specifying a keytab to work. Hadoop credentials will expire is only ticket cache / delegation tokens are used.&lt;/p&gt;</comment>
                            <comment id="15805602" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r94994079&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r94994079&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: docs/internals/flink_security.md &amp;#8212;&lt;br/&gt;
    @@ -24,64 +24,109 @@ specific language governing permissions and limitations&lt;br/&gt;
     under the License.&lt;br/&gt;
     --&amp;gt;&lt;/p&gt;

&lt;p&gt;    -This document briefly describes how Flink security works in the context of various deployment mechanism (Standalone/Cluster vs YARN) &lt;br/&gt;
    -and the connectors that participates in Flink Job execution stage. This documentation can be helpful for both administrators and developers &lt;br/&gt;
    -who plans to run Flink on a secure environment.&lt;br/&gt;
    +This document briefly describes how Flink security works in the context of various deployment mechanisms (Standalone, YARN, or Mesos), &lt;br/&gt;
    +filesystems, connectors, and state backends.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Objective&lt;br/&gt;
    +The primary goals of the Flink Kerberos security infrastructure are:&lt;br/&gt;
    +1. to enable secure data access for jobs within a cluster via connectors (e.g. Kafka)&lt;br/&gt;
    +2. to authenticate to ZooKeeper (if configured to use SASL)&lt;br/&gt;
    +3. to authenticate to Hadoop components (e.g. HDFS, HBase) &lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;    -The primary goal of Flink security model is to enable secure data access for jobs within a cluster via connectors. In a production deployment scenario, &lt;br/&gt;
    -streaming jobs are understood to run for longer period of time (days/weeks/months) and the system must be  able to authenticate against secure &lt;br/&gt;
    -data sources throughout the life of the job. The current implementation supports running Flink clusters (Job Manager/Task Manager/Jobs) under the &lt;br/&gt;
    -context of a Kerberos identity based on Keytab credential supplied during deployment time. Any jobs submitted will continue to run in the identity of the cluster.&lt;br/&gt;
    +In a production deployment scenario, streaming jobs are understood to run for long periods of time (days/weeks/months) and be able to authenticate to secure &lt;br/&gt;
    +data sources throughout the life of the job.  Kerberos keytabs do not expire in that timeframe, unlike a Hadoop delegation token&lt;br/&gt;
    +or ticket cache entry.&lt;br/&gt;
    +&lt;br/&gt;
    +The current implementation supports running Flink clusters (Job Manager/Task Manager/jobs) with either a configured keytab credential&lt;br/&gt;
    +or with Hadoop delegation tokens.   Keep in mind that all jobs share the credential configured for a given cluster.&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Maybe point out here that this refers to a &quot;Flink Cluster&quot; (a set of JobManager/TaskManager processes). One can run different jobs with different credentials next to each other in YARN by starting different per-job-clusters or Yarn/Mesos sessions.&lt;/p&gt;</comment>
                            <comment id="15805603" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95007256&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95007256&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/SecurityUtils.java &amp;#8212;&lt;br/&gt;
    @@ -71,163 +64,93 @@&lt;br/&gt;
     	 */&lt;br/&gt;
     	public static void install(SecurityConfiguration config) throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!config.securityIsEnabled()) 
{
    -			// do not perform any initialization if no Kerberos crendetails are provided
    -			return;
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// establish the JAAS config&lt;/li&gt;
	&lt;li&gt;JaasConfiguration jaasConfig = new JaasConfiguration(config.keytab, config.principal);&lt;/li&gt;
	&lt;li&gt;javax.security.auth.login.Configuration.setConfiguration(jaasConfig);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;populateSystemSecurityProperties(config.flinkConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// establish the UGI login user&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.setConfiguration(config.hadoopConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// only configure Hadoop security if we have security enabled&lt;/li&gt;
	&lt;li&gt;if (UserGroupInformation.isSecurityEnabled()) {&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;final UserGroupInformation loginUser;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (config.keytab != null &amp;amp;&amp;amp; !StringUtils.isBlank(config.principal)) {&lt;/li&gt;
	&lt;li&gt;String keytabPath = (new File(config.keytab)).getAbsolutePath();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.loginUserFromKeytab(config.principal, keytabPath);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// supplement with any available tokens&lt;/li&gt;
	&lt;li&gt;String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);&lt;/li&gt;
	&lt;li&gt;if (fileLocation != null) {&lt;/li&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* Use reflection API since the API semantics are not available in Hadoop1 profile. Below APIs are&lt;/li&gt;
	&lt;li&gt;* used in the context of reading the stored tokens from UGI.&lt;/li&gt;
	&lt;li&gt;* Credentials cred = Credentials.readTokenStorageFile(new File(fileLocation), config.hadoopConf);&lt;/li&gt;
	&lt;li&gt;* loginUser.addCredentials(cred);&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;try 
{
    -						Method readTokenStorageFileMethod = Credentials.class.getMethod(&quot;readTokenStorageFile&quot;,
    -							File.class, org.apache.hadoop.conf.Configuration.class);
    -						Credentials cred = (Credentials) readTokenStorageFileMethod.invoke(null, new File(fileLocation),
    -							config.hadoopConf);
    -						Method addCredentialsMethod = UserGroupInformation.class.getMethod(&quot;addCredentials&quot;,
    -							Credentials.class);
    -						addCredentialsMethod.invoke(loginUser, cred);
    -					}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;} else {&lt;/li&gt;
	&lt;li&gt;// login with current user credentials (e.g. ticket cache)&lt;/li&gt;
	&lt;li&gt;try 
{
    -					//Use reflection API to get the login user object
    -					//UserGroupInformation.loginUserFromSubject(null);
    -					Method loginUserFromSubjectMethod = UserGroupInformation.class.getMethod(&quot;loginUserFromSubject&quot;, Subject.class);
    -					Subject subject = null;
    -					loginUserFromSubjectMethod.invoke(null, subject);
    -				}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// note that the stored tokens are read automatically&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		// install the security modules&lt;br/&gt;
    +		List&amp;lt;SecurityModule&amp;gt; modules = new ArrayList();&lt;br/&gt;
    +		try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			for (Class&amp;lt;? extends SecurityModule&amp;gt; moduleClass }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		catch(Exception ex) &lt;/p&gt;
{
    +			throw new Exception(&quot;unable to establish the security context&quot;, ex);
    +		}
&lt;p&gt;    +		installedModules = modules;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LOG.info(&quot;Hadoop user set to {}&quot;, loginUser.toString());&lt;br/&gt;
    +		// install a security context&lt;br/&gt;
    +		// use the Hadoop login user as the subject of the installed security context&lt;br/&gt;
    +		if (!(installedContext instanceof NoOpSecurityContext)) 
{
    +			LOG.warn(&quot;overriding previous security context&quot;);
    +		}
&lt;p&gt;    +		UserGroupInformation loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		installedContext = new HadoopSecurityContext(loginUser);&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean delegationToken = false;&lt;/li&gt;
	&lt;li&gt;final Text HDFS_DELEGATION_KIND = new Text(&quot;HDFS_DELEGATION_TOKEN&quot;);&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;Token&amp;lt;? extends TokenIdentifier&amp;gt;&amp;gt; usrTok = loginUser.getTokens();&lt;/li&gt;
	&lt;li&gt;for (Token&amp;lt;? extends TokenIdentifier&amp;gt; token : usrTok) {&lt;/li&gt;
	&lt;li&gt;final Text id = new Text(token.getIdentifier());&lt;/li&gt;
	&lt;li&gt;LOG.debug(&quot;Found user token &quot; + id + &quot; with &quot; + token);&lt;/li&gt;
	&lt;li&gt;if (token.getKind().equals(HDFS_DELEGATION_KIND)) {&lt;/li&gt;
	&lt;li&gt;delegationToken = true;&lt;br/&gt;
    +	static void uninstall() {&lt;br/&gt;
    +		if(installedModules != null) {&lt;br/&gt;
    +			for (SecurityModule module : Lists.reverse(installedModules)) {&lt;br/&gt;
    +				try 
{
    +					module.uninstall();
     				}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (!loginUser.hasKerberosCredentials()) {&lt;/li&gt;
	&lt;li&gt;//throw an error in non-yarn deployment if kerberos cache is not available&lt;/li&gt;
	&lt;li&gt;if (!delegationToken) {&lt;/li&gt;
	&lt;li&gt;LOG.error(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;/li&gt;
	&lt;li&gt;throw new RuntimeException(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;br/&gt;
    +				catch(UnsupportedOperationException e) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Can you call this `catch (UnsupportedOperationException ignored) {`? Helps to avoid some warnings.&lt;/p&gt;</comment>
                            <comment id="15805604" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95009675&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95009675&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/modules/HadoopModule.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,120 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.runtime.security.modules;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.commons.lang3.StringUtils;&lt;br/&gt;
    +import org.apache.flink.api.java.hadoop.mapred.utils.HadoopUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.security.SecurityUtils;&lt;br/&gt;
    +import org.apache.hadoop.security.Credentials;&lt;br/&gt;
    +import org.apache.hadoop.security.UserGroupInformation;&lt;br/&gt;
    +import org.slf4j.Logger;&lt;br/&gt;
    +import org.slf4j.LoggerFactory;&lt;br/&gt;
    +&lt;br/&gt;
    +import javax.security.auth.Subject;&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.lang.reflect.InvocationTargetException;&lt;br/&gt;
    +import java.lang.reflect.Method;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Responsible for installing a Hadoop login user.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class HadoopModule implements SecurityModule {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Logger LOG = LoggerFactory.getLogger(HadoopModule.class);&lt;br/&gt;
    +&lt;br/&gt;
    +	UserGroupInformation loginUser;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public void install(SecurityUtils.SecurityConfiguration securityConfig) {&lt;br/&gt;
    +&lt;br/&gt;
    +		UserGroupInformation.setConfiguration(securityConfig.getHadoopConfiguration());&lt;br/&gt;
    +&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			if (UserGroupInformation.isSecurityEnabled() &amp;amp;&amp;amp;&lt;br/&gt;
    +				!StringUtils.isBlank(securityConfig.getKeytab()) &amp;amp;&amp;amp; !StringUtils.isBlank(securityConfig.getPrincipal())) {&lt;br/&gt;
    +				String keytabPath = (new File(securityConfig.getKeytab())).getAbsolutePath();&lt;br/&gt;
    +&lt;br/&gt;
    +				UserGroupInformation.loginUserFromKeytab(securityConfig.getPrincipal(), keytabPath);&lt;br/&gt;
    +&lt;br/&gt;
    +				loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +&lt;br/&gt;
    +				// supplement with any available tokens&lt;br/&gt;
    +				String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);&lt;br/&gt;
    +				if (fileLocation != null) {&lt;br/&gt;
    +					/*&lt;br/&gt;
    +					 * Use reflection API since the API semantics are not available in Hadoop1 profile. Below APIs are&lt;br/&gt;
    +					 * used in the context of reading the stored tokens from UGI.&lt;br/&gt;
    +					 * Credentials cred = Credentials.readTokenStorageFile(new File(fileLocation), config.hadoopConf);&lt;br/&gt;
    +					 * loginUser.addCredentials(cred);&lt;br/&gt;
    +					*/&lt;br/&gt;
    +					try &lt;/p&gt;
{
    +						Method readTokenStorageFileMethod = Credentials.class.getMethod(&quot;readTokenStorageFile&quot;,
    +							File.class, org.apache.hadoop.conf.Configuration.class);
    +						Credentials cred = (Credentials) readTokenStorageFileMethod.invoke(null, new File(fileLocation),
    +							securityConfig.getHadoopConfiguration());
    +						Method addCredentialsMethod = UserGroupInformation.class.getMethod(&quot;addCredentials&quot;,
    +							Credentials.class);
    +						addCredentialsMethod.invoke(loginUser, cred);
    +					}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;br/&gt;
    +						LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;br/&gt;
    +					} catch (InvocationTargetException e) &lt;/p&gt;
{
    +						throw e.getTargetException();
    +					}
&lt;p&gt;    +				}&lt;br/&gt;
    +			} else {&lt;br/&gt;
    +				// login with current user credentials (e.g. ticket cache, OS login)&lt;br/&gt;
    +				// note that the stored tokens are read automatically&lt;br/&gt;
    +				try &lt;/p&gt;
{
    +					//Use reflection API to get the login user object
    +					//UserGroupInformation.loginUserFromSubject(null);
    +					Method loginUserFromSubjectMethod = UserGroupInformation.class.getMethod(&quot;loginUserFromSubject&quot;, Subject.class);
    +					Subject subject = null;
    +					loginUserFromSubjectMethod.invoke(null, subject);
    +				}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;br/&gt;
    +					LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;br/&gt;
    +				} catch (InvocationTargetException e) &lt;/p&gt;
{
    +					throw e.getTargetException();
    +				}
&lt;p&gt;    +&lt;br/&gt;
    +				loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			if (UserGroupInformation.isSecurityEnabled()) {&lt;br/&gt;
    +				// note: UGI::hasKerberosCredentials inaccurately reports false&lt;br/&gt;
    +				// for logins based on a keytab (fixed in Hadoop 2.6.1, see &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10786&quot; title=&quot;Fix UGI#reloginFromKeytab on Java 8&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10786&quot;&gt;&lt;del&gt;HADOOP-10786&lt;/del&gt;&lt;/a&gt;),&lt;br/&gt;
    +				// so we check only in ticket cache scenario.&lt;br/&gt;
    +				if (securityConfig.useTicketCache() &amp;amp;&amp;amp; !loginUser.hasKerberosCredentials()) {&lt;br/&gt;
    +					// a delegation token is an adequate substitute in most cases&lt;br/&gt;
    +					if (!HadoopUtils.hasHDFSDelegationToken()) &lt;/p&gt;
{
    +						LOG.warn(&quot;Hadoop security is enabled but current login user does not have Kerberos credentials&quot;);
    +					}
&lt;p&gt;    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +&lt;br/&gt;
    +			LOG.info(&quot;Hadoop user set to {}&quot;, loginUser);&lt;br/&gt;
    +&lt;br/&gt;
    +		} catch (Throwable ex) {&lt;br/&gt;
    +			throw new RuntimeException(&quot;Hadoop login failure&quot;, ex);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think throwing `RuntimeException` is sort of an antipattern. In this case here, the exception is not a &quot;programming error&quot; type of exception and should be explicitly declared and handled  - calling methods should be aware that this method can fail and decide how to handle that. I would declare a `SecurityException` or so in the signature.&lt;/p&gt;

&lt;p&gt;    (parts of the existing Flink code are also guilty of doing that)&lt;/p&gt;</comment>
                            <comment id="15805605" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95008182&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95008182&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/SecurityUtils.java &amp;#8212;&lt;br/&gt;
    @@ -71,163 +64,93 @@&lt;br/&gt;
     	 */&lt;br/&gt;
     	public static void install(SecurityConfiguration config) throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!config.securityIsEnabled()) 
{
    -			// do not perform any initialization if no Kerberos crendetails are provided
    -			return;
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// establish the JAAS config&lt;/li&gt;
	&lt;li&gt;JaasConfiguration jaasConfig = new JaasConfiguration(config.keytab, config.principal);&lt;/li&gt;
	&lt;li&gt;javax.security.auth.login.Configuration.setConfiguration(jaasConfig);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;populateSystemSecurityProperties(config.flinkConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// establish the UGI login user&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.setConfiguration(config.hadoopConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// only configure Hadoop security if we have security enabled&lt;/li&gt;
	&lt;li&gt;if (UserGroupInformation.isSecurityEnabled()) {&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;final UserGroupInformation loginUser;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (config.keytab != null &amp;amp;&amp;amp; !StringUtils.isBlank(config.principal)) {&lt;/li&gt;
	&lt;li&gt;String keytabPath = (new File(config.keytab)).getAbsolutePath();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.loginUserFromKeytab(config.principal, keytabPath);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// supplement with any available tokens&lt;/li&gt;
	&lt;li&gt;String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);&lt;/li&gt;
	&lt;li&gt;if (fileLocation != null) {&lt;/li&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* Use reflection API since the API semantics are not available in Hadoop1 profile. Below APIs are&lt;/li&gt;
	&lt;li&gt;* used in the context of reading the stored tokens from UGI.&lt;/li&gt;
	&lt;li&gt;* Credentials cred = Credentials.readTokenStorageFile(new File(fileLocation), config.hadoopConf);&lt;/li&gt;
	&lt;li&gt;* loginUser.addCredentials(cred);&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;try 
{
    -						Method readTokenStorageFileMethod = Credentials.class.getMethod(&quot;readTokenStorageFile&quot;,
    -							File.class, org.apache.hadoop.conf.Configuration.class);
    -						Credentials cred = (Credentials) readTokenStorageFileMethod.invoke(null, new File(fileLocation),
    -							config.hadoopConf);
    -						Method addCredentialsMethod = UserGroupInformation.class.getMethod(&quot;addCredentials&quot;,
    -							Credentials.class);
    -						addCredentialsMethod.invoke(loginUser, cred);
    -					}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;} else {&lt;/li&gt;
	&lt;li&gt;// login with current user credentials (e.g. ticket cache)&lt;/li&gt;
	&lt;li&gt;try 
{
    -					//Use reflection API to get the login user object
    -					//UserGroupInformation.loginUserFromSubject(null);
    -					Method loginUserFromSubjectMethod = UserGroupInformation.class.getMethod(&quot;loginUserFromSubject&quot;, Subject.class);
    -					Subject subject = null;
    -					loginUserFromSubjectMethod.invoke(null, subject);
    -				}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// note that the stored tokens are read automatically&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		// install the security modules&lt;br/&gt;
    +		List&amp;lt;SecurityModule&amp;gt; modules = new ArrayList();&lt;br/&gt;
    +		try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			for (Class&amp;lt;? extends SecurityModule&amp;gt; moduleClass }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		catch(Exception ex) &lt;/p&gt;
{
    +			throw new Exception(&quot;unable to establish the security context&quot;, ex);
    +		}
&lt;p&gt;    +		installedModules = modules;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LOG.info(&quot;Hadoop user set to {}&quot;, loginUser.toString());&lt;br/&gt;
    +		// install a security context&lt;br/&gt;
    +		// use the Hadoop login user as the subject of the installed security context&lt;br/&gt;
    +		if (!(installedContext instanceof NoOpSecurityContext)) 
{
    +			LOG.warn(&quot;overriding previous security context&quot;);
    +		}
&lt;p&gt;    +		UserGroupInformation loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		installedContext = new HadoopSecurityContext(loginUser);&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean delegationToken = false;&lt;/li&gt;
	&lt;li&gt;final Text HDFS_DELEGATION_KIND = new Text(&quot;HDFS_DELEGATION_TOKEN&quot;);&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;Token&amp;lt;? extends TokenIdentifier&amp;gt;&amp;gt; usrTok = loginUser.getTokens();&lt;/li&gt;
	&lt;li&gt;for (Token&amp;lt;? extends TokenIdentifier&amp;gt; token : usrTok) {&lt;/li&gt;
	&lt;li&gt;final Text id = new Text(token.getIdentifier());&lt;/li&gt;
	&lt;li&gt;LOG.debug(&quot;Found user token &quot; + id + &quot; with &quot; + token);&lt;/li&gt;
	&lt;li&gt;if (token.getKind().equals(HDFS_DELEGATION_KIND)) {&lt;/li&gt;
	&lt;li&gt;delegationToken = true;&lt;br/&gt;
    +	static void uninstall() {&lt;br/&gt;
    +		if(installedModules != null) {&lt;br/&gt;
    +			for (SecurityModule module : Lists.reverse(installedModules)) {&lt;br/&gt;
    +				try 
{
    +					module.uninstall();
     				}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (!loginUser.hasKerberosCredentials()) {&lt;/li&gt;
	&lt;li&gt;//throw an error in non-yarn deployment if kerberos cache is not available&lt;/li&gt;
	&lt;li&gt;if (!delegationToken) {&lt;/li&gt;
	&lt;li&gt;LOG.error(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;/li&gt;
	&lt;li&gt;throw new RuntimeException(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;br/&gt;
    +				catch(UnsupportedOperationException e) {&lt;br/&gt;
     				}&lt;br/&gt;
     			}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (!(installedContext instanceof NoOpSecurityContext)) 
{
    -				LOG.warn(&quot;overriding previous security context&quot;);
    -			}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;installedContext = new HadoopSecurityContext(loginUser);&lt;br/&gt;
    +			installedModules = null;&lt;br/&gt;
     		}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;static void clearContext() 
{
     		installedContext = new NoOpSecurityContext();
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* This method configures some of the system properties that are require for ZK and Kafka SASL authentication&lt;/li&gt;
	&lt;li&gt;* See: &lt;a href=&quot;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;* See: &lt;a href=&quot;https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L900&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L900&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;* In this method, setting java.security.auth.login.config configuration is configured only to support ZK and&lt;/li&gt;
	&lt;li&gt;* Kafka current code behavior.&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * The global security configuration.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * See 
{@link SecurityOptions}
&lt;p&gt; for corresponding configuration options.&lt;br/&gt;
     	 */&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private static void populateSystemSecurityProperties(Configuration configuration) {&lt;/li&gt;
	&lt;li&gt;Preconditions.checkNotNull(configuration, &quot;The supplied configuration was null&quot;);&lt;br/&gt;
    +	public static class SecurityConfiguration {&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean disableSaslClient = configuration.getBoolean(HighAvailabilityOptions.ZOOKEEPER_SASL_DISABLE);&lt;br/&gt;
    +		private static final List&amp;lt;Class&amp;lt;? extends SecurityModule&amp;gt;&amp;gt; DEFAULT_MODULES = Collections.unmodifiableList(&lt;br/&gt;
    +			new ArrayList&amp;lt;Class&amp;lt;? extends SecurityModule&amp;gt;&amp;gt;() {{&lt;br/&gt;
    +				add(HadoopModule.class);&lt;br/&gt;
    +				add(JaasModule.class);&lt;br/&gt;
    +				add(ZooKeeperModule.class);&lt;br/&gt;
    +			}});&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (disableSaslClient) 
{
    -			LOG.info(&quot;SASL client auth for ZK will be disabled&quot;);
    -			//SASL auth is disabled by default but will be enabled if specified in configuration
    -			System.setProperty(ZOOKEEPER_SASL_CLIENT,&quot;false&quot;);
    -			return;
    -		}
&lt;p&gt;    +		private final org.apache.hadoop.conf.Configuration hadoopConf;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// load Jaas config file to initialize SASL&lt;/li&gt;
	&lt;li&gt;final File jaasConfFile;&lt;/li&gt;
	&lt;li&gt;try 
{
    -			Path jaasConfPath = Files.createTempFile(JAAS_CONF_FILENAME, &quot;&quot;);
    -			InputStream jaasConfStream = SecurityUtils.class.getClassLoader().getResourceAsStream(JAAS_CONF_FILENAME);
    -			Files.copy(jaasConfStream, jaasConfPath, StandardCopyOption.REPLACE_EXISTING);
    -			jaasConfFile = jaasConfPath.toFile();
    -			jaasConfFile.deleteOnExit();
    -			jaasConfStream.close();
    -		}
&lt;p&gt; catch (IOException e) &lt;/p&gt;
{
    -			throw new RuntimeException(&quot;SASL auth is enabled for ZK but unable to &quot; +
    -				&quot;locate pseudo Jaas config provided with Flink&quot;, e);
    -		}
&lt;p&gt;    +		private final boolean useTicketCache;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LOG.info(&quot;Enabling {} property with pseudo JAAS config file: {}&quot;,&lt;/li&gt;
	&lt;li&gt;JAVA_SECURITY_AUTH_LOGIN_CONFIG, jaasConfFile.getAbsolutePath());&lt;br/&gt;
    +		private final String keytab;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;//ZK client module lookup the configuration to handle SASL.&lt;/li&gt;
	&lt;li&gt;//&lt;a href=&quot;https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L900&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L900&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;System.setProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG, jaasConfFile.getAbsolutePath());&lt;/li&gt;
	&lt;li&gt;System.setProperty(ZOOKEEPER_SASL_CLIENT, &quot;true&quot;);&lt;br/&gt;
    +		private final String principal;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;String zkSaslServiceName = configuration.getValue(HighAvailabilityOptions.ZOOKEEPER_SASL_SERVICE_NAME);&lt;/li&gt;
	&lt;li&gt;if (!StringUtils.isBlank(zkSaslServiceName)) {&lt;/li&gt;
	&lt;li&gt;LOG.info(&quot;ZK SASL service name: {} is provided in the configuration&quot;, zkSaslServiceName);&lt;/li&gt;
	&lt;li&gt;System.setProperty(ZOOKEEPER_SASL_CLIENT_USERNAME, zkSaslServiceName);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    +		private List&amp;lt;String&amp;gt; loginContextNames;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;}&lt;br/&gt;
    +		private String zkServiceName;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Some fields are finals others not. Can all be final here?&lt;/p&gt;</comment>
                            <comment id="15805606" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95007601&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95007601&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/SecurityUtils.java &amp;#8212;&lt;br/&gt;
    @@ -71,163 +64,93 @@&lt;br/&gt;
     	 */&lt;br/&gt;
     	public static void install(SecurityConfiguration config) throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!config.securityIsEnabled()) 
{
    -			// do not perform any initialization if no Kerberos crendetails are provided
    -			return;
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// establish the JAAS config&lt;/li&gt;
	&lt;li&gt;JaasConfiguration jaasConfig = new JaasConfiguration(config.keytab, config.principal);&lt;/li&gt;
	&lt;li&gt;javax.security.auth.login.Configuration.setConfiguration(jaasConfig);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;populateSystemSecurityProperties(config.flinkConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// establish the UGI login user&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.setConfiguration(config.hadoopConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// only configure Hadoop security if we have security enabled&lt;/li&gt;
	&lt;li&gt;if (UserGroupInformation.isSecurityEnabled()) {&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;final UserGroupInformation loginUser;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (config.keytab != null &amp;amp;&amp;amp; !StringUtils.isBlank(config.principal)) {&lt;/li&gt;
	&lt;li&gt;String keytabPath = (new File(config.keytab)).getAbsolutePath();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.loginUserFromKeytab(config.principal, keytabPath);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// supplement with any available tokens&lt;/li&gt;
	&lt;li&gt;String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);&lt;/li&gt;
	&lt;li&gt;if (fileLocation != null) {&lt;/li&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* Use reflection API since the API semantics are not available in Hadoop1 profile. Below APIs are&lt;/li&gt;
	&lt;li&gt;* used in the context of reading the stored tokens from UGI.&lt;/li&gt;
	&lt;li&gt;* Credentials cred = Credentials.readTokenStorageFile(new File(fileLocation), config.hadoopConf);&lt;/li&gt;
	&lt;li&gt;* loginUser.addCredentials(cred);&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;try 
{
    -						Method readTokenStorageFileMethod = Credentials.class.getMethod(&quot;readTokenStorageFile&quot;,
    -							File.class, org.apache.hadoop.conf.Configuration.class);
    -						Credentials cred = (Credentials) readTokenStorageFileMethod.invoke(null, new File(fileLocation),
    -							config.hadoopConf);
    -						Method addCredentialsMethod = UserGroupInformation.class.getMethod(&quot;addCredentials&quot;,
    -							Credentials.class);
    -						addCredentialsMethod.invoke(loginUser, cred);
    -					}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;} else {&lt;/li&gt;
	&lt;li&gt;// login with current user credentials (e.g. ticket cache)&lt;/li&gt;
	&lt;li&gt;try 
{
    -					//Use reflection API to get the login user object
    -					//UserGroupInformation.loginUserFromSubject(null);
    -					Method loginUserFromSubjectMethod = UserGroupInformation.class.getMethod(&quot;loginUserFromSubject&quot;, Subject.class);
    -					Subject subject = null;
    -					loginUserFromSubjectMethod.invoke(null, subject);
    -				}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// note that the stored tokens are read automatically&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		// install the security modules&lt;br/&gt;
    +		List&amp;lt;SecurityModule&amp;gt; modules = new ArrayList();&lt;br/&gt;
    +		try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			for (Class&amp;lt;? extends SecurityModule&amp;gt; moduleClass }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		catch(Exception ex) &lt;/p&gt;
{
    +			throw new Exception(&quot;unable to establish the security context&quot;, ex);
    +		}
&lt;p&gt;    +		installedModules = modules;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LOG.info(&quot;Hadoop user set to {}&quot;, loginUser.toString());&lt;br/&gt;
    +		// install a security context&lt;br/&gt;
    +		// use the Hadoop login user as the subject of the installed security context&lt;br/&gt;
    +		if (!(installedContext instanceof NoOpSecurityContext)) 
{
    +			LOG.warn(&quot;overriding previous security context&quot;);
    +		}
&lt;p&gt;    +		UserGroupInformation loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		installedContext = new HadoopSecurityContext(loginUser);&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean delegationToken = false;&lt;/li&gt;
	&lt;li&gt;final Text HDFS_DELEGATION_KIND = new Text(&quot;HDFS_DELEGATION_TOKEN&quot;);&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;Token&amp;lt;? extends TokenIdentifier&amp;gt;&amp;gt; usrTok = loginUser.getTokens();&lt;/li&gt;
	&lt;li&gt;for (Token&amp;lt;? extends TokenIdentifier&amp;gt; token : usrTok) {&lt;/li&gt;
	&lt;li&gt;final Text id = new Text(token.getIdentifier());&lt;/li&gt;
	&lt;li&gt;LOG.debug(&quot;Found user token &quot; + id + &quot; with &quot; + token);&lt;/li&gt;
	&lt;li&gt;if (token.getKind().equals(HDFS_DELEGATION_KIND)) {&lt;/li&gt;
	&lt;li&gt;delegationToken = true;&lt;br/&gt;
    +	static void uninstall() {&lt;br/&gt;
    +		if(installedModules != null) {&lt;br/&gt;
    +			for (SecurityModule module : Lists.reverse(installedModules)) {&lt;br/&gt;
    +				try 
{
    +					module.uninstall();
     				}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (!loginUser.hasKerberosCredentials()) {&lt;/li&gt;
	&lt;li&gt;//throw an error in non-yarn deployment if kerberos cache is not available&lt;/li&gt;
	&lt;li&gt;if (!delegationToken) {&lt;/li&gt;
	&lt;li&gt;LOG.error(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;/li&gt;
	&lt;li&gt;throw new RuntimeException(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;br/&gt;
    +				catch(UnsupportedOperationException e) {&lt;br/&gt;
     				}&lt;br/&gt;
     			}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (!(installedContext instanceof NoOpSecurityContext)) 
{
    -				LOG.warn(&quot;overriding previous security context&quot;);
    -			}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;installedContext = new HadoopSecurityContext(loginUser);&lt;br/&gt;
    +			installedModules = null;&lt;br/&gt;
     		}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;static void clearContext() 
{
     		installedContext = new NoOpSecurityContext();
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* This method configures some of the system properties that are require for ZK and Kafka SASL authentication&lt;/li&gt;
	&lt;li&gt;* See: &lt;a href=&quot;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;* See: &lt;a href=&quot;https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L900&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L900&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;* In this method, setting java.security.auth.login.config configuration is configured only to support ZK and&lt;/li&gt;
	&lt;li&gt;* Kafka current code behavior.&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * The global security configuration.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * See 
{@link SecurityOptions}
&lt;p&gt; for corresponding configuration options.&lt;br/&gt;
     	 */&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private static void populateSystemSecurityProperties(Configuration configuration) {&lt;/li&gt;
	&lt;li&gt;Preconditions.checkNotNull(configuration, &quot;The supplied configuration was null&quot;);&lt;br/&gt;
    +	public static class SecurityConfiguration {&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean disableSaslClient = configuration.getBoolean(HighAvailabilityOptions.ZOOKEEPER_SASL_DISABLE);&lt;br/&gt;
    +		private static final List&amp;lt;Class&amp;lt;? extends SecurityModule&amp;gt;&amp;gt; DEFAULT_MODULES = Collections.unmodifiableList(&lt;br/&gt;
    +			new ArrayList&amp;lt;Class&amp;lt;? extends SecurityModule&amp;gt;&amp;gt;() {{
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I think you can use `Arrays.asList(...)` here, instead of creating an anonymous subclass.&lt;/p&gt;</comment>
                            <comment id="15805607" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95007014&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95007014&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/SecurityUtils.java &amp;#8212;&lt;br/&gt;
    @@ -71,163 +64,93 @@&lt;br/&gt;
     	 */&lt;br/&gt;
     	public static void install(SecurityConfiguration config) throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!config.securityIsEnabled()) 
{
    -			// do not perform any initialization if no Kerberos crendetails are provided
    -			return;
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// establish the JAAS config&lt;/li&gt;
	&lt;li&gt;JaasConfiguration jaasConfig = new JaasConfiguration(config.keytab, config.principal);&lt;/li&gt;
	&lt;li&gt;javax.security.auth.login.Configuration.setConfiguration(jaasConfig);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;populateSystemSecurityProperties(config.flinkConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// establish the UGI login user&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.setConfiguration(config.hadoopConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// only configure Hadoop security if we have security enabled&lt;/li&gt;
	&lt;li&gt;if (UserGroupInformation.isSecurityEnabled()) {&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;final UserGroupInformation loginUser;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (config.keytab != null &amp;amp;&amp;amp; !StringUtils.isBlank(config.principal)) {&lt;/li&gt;
	&lt;li&gt;String keytabPath = (new File(config.keytab)).getAbsolutePath();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.loginUserFromKeytab(config.principal, keytabPath);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// supplement with any available tokens&lt;/li&gt;
	&lt;li&gt;String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);&lt;/li&gt;
	&lt;li&gt;if (fileLocation != null) {&lt;/li&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* Use reflection API since the API semantics are not available in Hadoop1 profile. Below APIs are&lt;/li&gt;
	&lt;li&gt;* used in the context of reading the stored tokens from UGI.&lt;/li&gt;
	&lt;li&gt;* Credentials cred = Credentials.readTokenStorageFile(new File(fileLocation), config.hadoopConf);&lt;/li&gt;
	&lt;li&gt;* loginUser.addCredentials(cred);&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;try 
{
    -						Method readTokenStorageFileMethod = Credentials.class.getMethod(&quot;readTokenStorageFile&quot;,
    -							File.class, org.apache.hadoop.conf.Configuration.class);
    -						Credentials cred = (Credentials) readTokenStorageFileMethod.invoke(null, new File(fileLocation),
    -							config.hadoopConf);
    -						Method addCredentialsMethod = UserGroupInformation.class.getMethod(&quot;addCredentials&quot;,
    -							Credentials.class);
    -						addCredentialsMethod.invoke(loginUser, cred);
    -					}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;} else {&lt;/li&gt;
	&lt;li&gt;// login with current user credentials (e.g. ticket cache)&lt;/li&gt;
	&lt;li&gt;try 
{
    -					//Use reflection API to get the login user object
    -					//UserGroupInformation.loginUserFromSubject(null);
    -					Method loginUserFromSubjectMethod = UserGroupInformation.class.getMethod(&quot;loginUserFromSubject&quot;, Subject.class);
    -					Subject subject = null;
    -					loginUserFromSubjectMethod.invoke(null, subject);
    -				}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// note that the stored tokens are read automatically&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		// install the security modules&lt;br/&gt;
    +		List&amp;lt;SecurityModule&amp;gt; modules = new ArrayList();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Can you use `new ArrayList&amp;lt;&amp;gt;()` here? In general, it would be nice to make a pass over the code with warnings according to generics and serializability enabled. I get a lot of warnings printed when compiling this. Minimizing these kinds of warnings helps to spot the warnings that inform about actual subtle bugs.&lt;/p&gt;</comment>
                            <comment id="15805608" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95010038&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95010038&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/modules/JaasModule.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,147 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.runtime.security.modules;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.annotation.Internal;&lt;br/&gt;
    +import org.apache.flink.runtime.security.DynamicConfiguration;&lt;br/&gt;
    +import org.apache.flink.runtime.security.KerberosUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.security.SecurityUtils;&lt;br/&gt;
    +import org.slf4j.Logger;&lt;br/&gt;
    +import org.slf4j.LoggerFactory;&lt;br/&gt;
    +&lt;br/&gt;
    +import javax.security.auth.login.AppConfigurationEntry;&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.io.InputStream;&lt;br/&gt;
    +import java.nio.file.Files;&lt;br/&gt;
    +import java.nio.file.Path;&lt;br/&gt;
    +import java.nio.file.StandardCopyOption;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Responsible for installing a process-wide JAAS configuration.&lt;br/&gt;
    + * &amp;lt;p&amp;gt;&lt;br/&gt;
    + * The installed configuration combines login modules based on:&lt;br/&gt;
    + * - the user-supplied JAAS configuration file, if any&lt;br/&gt;
    + * - a Kerberos keytab, if configured&lt;br/&gt;
    + * - any cached Kerberos credentials from the current environment&lt;br/&gt;
    + * &amp;lt;p&amp;gt;&lt;br/&gt;
    + * The module also installs a default JAAS config file (if necessary) for&lt;br/&gt;
    + * compatibility with ZK and Kafka.  Note that the JRE actually draws on numerous file locations.&lt;br/&gt;
    + * See: &lt;a href=&quot;https://docs.oracle.com/javase/7/docs/jre/api/security/jaas/spec/com/sun/security/auth/login/ConfigFile.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.oracle.com/javase/7/docs/jre/api/security/jaas/spec/com/sun/security/auth/login/ConfigFile.html&lt;/a&gt;&lt;br/&gt;
    + * See: &lt;a href=&quot;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&lt;/a&gt;&lt;br/&gt;
    + */&lt;br/&gt;
    +@Internal&lt;br/&gt;
    +public class JaasModule implements SecurityModule {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Logger LOG = LoggerFactory.getLogger(JaasModule.class);&lt;br/&gt;
    +&lt;br/&gt;
    +	static final String JAVA_SECURITY_AUTH_LOGIN_CONFIG = &quot;java.security.auth.login.config&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	static final String JAAS_CONF_RESOURCE_NAME = &quot;flink-jaas.conf&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	private String priorConfigFile;&lt;br/&gt;
    +	private javax.security.auth.login.Configuration priorConfig;&lt;br/&gt;
    +&lt;br/&gt;
    +	private DynamicConfiguration currentConfig;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public void install(SecurityUtils.SecurityConfiguration securityConfig) {&lt;br/&gt;
    +&lt;br/&gt;
    +		// ensure that a config file is always defined, for compatibility with&lt;br/&gt;
    +		// ZK and Kafka which check for the system property and existence of the file&lt;br/&gt;
    +		priorConfigFile = System.getProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG, null);&lt;br/&gt;
    +		if (priorConfigFile == null) &lt;/p&gt;
{
    +			File configFile = generateDefaultConfigFile();
    +			System.setProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG, configFile.getAbsolutePath());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		// read the JAAS configuration file&lt;br/&gt;
    +		priorConfig = javax.security.auth.login.Configuration.getConfiguration();&lt;br/&gt;
    +&lt;br/&gt;
    +		// construct a dynamic JAAS configuration&lt;br/&gt;
    +		currentConfig = new DynamicConfiguration(priorConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wire up the configured JAAS login contexts to use the krb5 entries&lt;br/&gt;
    +		AppConfigurationEntry[] krb5Entries = getAppConfigurationEntries(securityConfig);&lt;br/&gt;
    +		if(krb5Entries != null) {&lt;br/&gt;
    +			for (String app : securityConfig.getLoginContextNames()) &lt;/p&gt;
{
    +				currentConfig.addAppConfigurationEntry(app, krb5Entries);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		javax.security.auth.login.Configuration.setConfiguration(currentConfig);&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public void uninstall() {&lt;br/&gt;
    +		if(priorConfigFile != null) &lt;/p&gt;
{
    +			System.setProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG, priorConfigFile);
    +		}
&lt;p&gt; else &lt;/p&gt;
{
    +			System.clearProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG);
    +		}
&lt;p&gt;    +		javax.security.auth.login.Configuration.setConfiguration(priorConfig);&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	public DynamicConfiguration getCurrentConfiguration() &lt;/p&gt;
{
    +		return currentConfig;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private static AppConfigurationEntry[] getAppConfigurationEntries(SecurityUtils.SecurityConfiguration securityConfig) {&lt;br/&gt;
    +&lt;br/&gt;
    +		AppConfigurationEntry userKerberosAce = null;&lt;br/&gt;
    +		if (securityConfig.useTicketCache()) &lt;/p&gt;
{
    +			userKerberosAce = KerberosUtils.ticketCacheEntry();
    +		}
&lt;p&gt;    +		AppConfigurationEntry keytabKerberosAce = null;&lt;br/&gt;
    +		if (securityConfig.getKeytab() != null) &lt;/p&gt;
{
    +			keytabKerberosAce = KerberosUtils.keytabEntry(securityConfig.getKeytab(), securityConfig.getPrincipal());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		AppConfigurationEntry[] appConfigurationEntry;&lt;br/&gt;
    +		if (userKerberosAce != null &amp;amp;&amp;amp; keytabKerberosAce != null) {&lt;br/&gt;
    +			appConfigurationEntry = new AppConfigurationEntry[]&lt;/p&gt;
{keytabKerberosAce, userKerberosAce}
&lt;p&gt;;&lt;br/&gt;
    +		} else if (keytabKerberosAce != null) {&lt;br/&gt;
    +			appConfigurationEntry = new AppConfigurationEntry[]&lt;/p&gt;
{keytabKerberosAce}
&lt;p&gt;;&lt;br/&gt;
    +		} else if (userKerberosAce != null) {&lt;br/&gt;
    +			appConfigurationEntry = new AppConfigurationEntry[]&lt;/p&gt;
{userKerberosAce}
&lt;p&gt;;&lt;br/&gt;
    +		} else &lt;/p&gt;
{
    +			return null;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		return appConfigurationEntry;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Generate the default JAAS config file.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private static File generateDefaultConfigFile() {&lt;br/&gt;
    +		// load Jaas config file to initialize SASL&lt;br/&gt;
    +		final File jaasConfFile;&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			Path jaasConfPath = Files.createTempFile(&quot;jaas-&quot;, &quot;.conf&quot;);&lt;br/&gt;
    +			try (InputStream resourceStream = JaasModule.class.getClassLoader().getResourceAsStream(JAAS_CONF_RESOURCE_NAME)) &lt;/p&gt;
{
    +				Files.copy(resourceStream, jaasConfPath, StandardCopyOption.REPLACE_EXISTING);
    +			}
&lt;p&gt;    +			jaasConfFile = jaasConfPath.toFile();&lt;br/&gt;
    +			jaasConfFile.deleteOnExit();&lt;br/&gt;
    +		} catch (IOException e) {&lt;br/&gt;
    +			throw new RuntimeException(&quot;unable to generate a JAAS configuration file&quot;, e);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    See above - why not declare that this method may throw an `IOException`?&lt;/p&gt;</comment>
                            <comment id="15805609" author="githubbot" created="Fri, 6 Jan 2017 20:08:03 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95003470&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95003470&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/DynamicConfiguration.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,112 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.runtime.security;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.slf4j.Logger;&lt;br/&gt;
    +import org.slf4j.LoggerFactory;&lt;br/&gt;
    +import scala.Array;&lt;br/&gt;
    +&lt;br/&gt;
    +import javax.annotation.Nullable;&lt;br/&gt;
    +import javax.security.auth.login.AppConfigurationEntry;&lt;br/&gt;
    +import javax.security.auth.login.Configuration;&lt;br/&gt;
    +import java.util.Arrays;&lt;br/&gt;
    +import java.util.HashMap;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * A dynamic JAAS configuration.&lt;br/&gt;
    + *&lt;br/&gt;
    + * Makes it possible to define Application Configuration Entries (ACEs) at runtime, building upon&lt;br/&gt;
    + * an (optional) underlying configuration.   Entries from the underlying configuration take&lt;br/&gt;
    + * precedence over dynamic entries.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class DynamicConfiguration extends Configuration {&lt;br/&gt;
    +&lt;br/&gt;
    +	protected static final Logger LOG = LoggerFactory.getLogger(DynamicConfiguration.class);&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Configuration delegate;&lt;br/&gt;
    +&lt;br/&gt;
    +	private final Map&amp;lt;String,AppConfigurationEntry[]&amp;gt; dynamicEntries = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Create a dynamic configuration.&lt;br/&gt;
    +	 * @param delegate an underlying configuration to delegate to, or null.&lt;br/&gt;
    +     */&lt;br/&gt;
    +	public DynamicConfiguration(@Nullable Configuration delegate) &lt;/p&gt;
{
    +		this.delegate = delegate;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Add entries for the given application name.&lt;br/&gt;
    +     */&lt;br/&gt;
    +	public void addAppConfigurationEntry(String name, AppConfigurationEntry... entry) {&lt;br/&gt;
    +		final AppConfigurationEntry[] existing = dynamicEntries.get(name);&lt;br/&gt;
    +		final AppConfigurationEntry[] updated;&lt;br/&gt;
    +		if(existing == null) &lt;/p&gt;
{
    +			updated = Arrays.copyOf(entry, entry.length);
    +		}
&lt;p&gt;    +		else &lt;/p&gt;
{
    +			updated = merge(existing, entry);
    +		}
&lt;p&gt;    +		dynamicEntries.put(name, updated);&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Retrieve the AppConfigurationEntries for the specified &amp;lt;i&amp;gt;name&amp;lt;/i&amp;gt;&lt;br/&gt;
    +	 * from this Configuration.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @param name the name used to index the Configuration.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @return an array of AppConfigurationEntries for the specified &amp;lt;i&amp;gt;name&amp;lt;/i&amp;gt;&lt;br/&gt;
    +	 *          from this Configuration, or null if there are no entries&lt;br/&gt;
    +	 *          for the specified &amp;lt;i&amp;gt;name&amp;lt;/i&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public AppConfigurationEntry[] getAppConfigurationEntry(String name) {&lt;br/&gt;
    +		AppConfigurationEntry[] entry = null;&lt;br/&gt;
    +		if(delegate != null) &lt;/p&gt;
{
    +			entry = delegate.getAppConfigurationEntry(name);
    +		}
&lt;p&gt;    +		final AppConfigurationEntry[] existing = dynamicEntries.get(name);&lt;br/&gt;
    +		if(existing != null) {&lt;br/&gt;
    +			if(entry != null) &lt;/p&gt;
{
    +				entry = merge(entry, existing);
    +			}
&lt;p&gt;    +			else &lt;/p&gt;
{
    +				entry = Arrays.copyOf(existing, existing.length);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		return entry;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static AppConfigurationEntry[] merge(AppConfigurationEntry[] a, AppConfigurationEntry[] b) {&lt;br/&gt;
    +		AppConfigurationEntry[] merged = Arrays.copyOf(a, a.length + b.length);&lt;br/&gt;
    +		Array.copy(b, 0, merged, a.length, b.length);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can we use `System.arrayCopy()` here to avoid a dependency on Scala in this part of the code?&lt;/p&gt;</comment>
                            <comment id="15805618" author="githubbot" created="Fri, 6 Jan 2017 20:10:56 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @EronWright Thanks for explaining. It figured it out concurrently by looking at the updated documentation you wrote &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; The docs are good, helped a lot!&lt;/p&gt;</comment>
                            <comment id="15805812" author="githubbot" created="Fri, 6 Jan 2017 21:28:18 +0000"  >&lt;p&gt;Github user EronWright commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the review, I&apos;ll address these comments ASAP.&lt;/p&gt;</comment>
                            <comment id="15813113" author="githubbot" created="Mon, 9 Jan 2017 22:52:48 +0000"  >&lt;p&gt;Github user EronWright commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95265401&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95265401&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/SecurityUtils.java &amp;#8212;&lt;br/&gt;
    @@ -71,163 +64,93 @@&lt;br/&gt;
     	 */&lt;br/&gt;
     	public static void install(SecurityConfiguration config) throws Exception {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!config.securityIsEnabled()) 
{
    -			// do not perform any initialization if no Kerberos crendetails are provided
    -			return;
    -		}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// establish the JAAS config&lt;/li&gt;
	&lt;li&gt;JaasConfiguration jaasConfig = new JaasConfiguration(config.keytab, config.principal);&lt;/li&gt;
	&lt;li&gt;javax.security.auth.login.Configuration.setConfiguration(jaasConfig);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;populateSystemSecurityProperties(config.flinkConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// establish the UGI login user&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.setConfiguration(config.hadoopConf);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// only configure Hadoop security if we have security enabled&lt;/li&gt;
	&lt;li&gt;if (UserGroupInformation.isSecurityEnabled()) {&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;final UserGroupInformation loginUser;&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (config.keytab != null &amp;amp;&amp;amp; !StringUtils.isBlank(config.principal)) {&lt;/li&gt;
	&lt;li&gt;String keytabPath = (new File(config.keytab)).getAbsolutePath();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;UserGroupInformation.loginUserFromKeytab(config.principal, keytabPath);&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// supplement with any available tokens&lt;/li&gt;
	&lt;li&gt;String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);&lt;/li&gt;
	&lt;li&gt;if (fileLocation != null) {&lt;/li&gt;
	&lt;li&gt;/*&lt;/li&gt;
	&lt;li&gt;* Use reflection API since the API semantics are not available in Hadoop1 profile. Below APIs are&lt;/li&gt;
	&lt;li&gt;* used in the context of reading the stored tokens from UGI.&lt;/li&gt;
	&lt;li&gt;* Credentials cred = Credentials.readTokenStorageFile(new File(fileLocation), config.hadoopConf);&lt;/li&gt;
	&lt;li&gt;* loginUser.addCredentials(cred);&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;try 
{
    -						Method readTokenStorageFileMethod = Credentials.class.getMethod(&quot;readTokenStorageFile&quot;,
    -							File.class, org.apache.hadoop.conf.Configuration.class);
    -						Credentials cred = (Credentials) readTokenStorageFileMethod.invoke(null, new File(fileLocation),
    -							config.hadoopConf);
    -						Method addCredentialsMethod = UserGroupInformation.class.getMethod(&quot;addCredentials&quot;,
    -							Credentials.class);
    -						addCredentialsMethod.invoke(loginUser, cred);
    -					}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;} else {&lt;/li&gt;
	&lt;li&gt;// login with current user credentials (e.g. ticket cache)&lt;/li&gt;
	&lt;li&gt;try 
{
    -					//Use reflection API to get the login user object
    -					//UserGroupInformation.loginUserFromSubject(null);
    -					Method loginUserFromSubjectMethod = UserGroupInformation.class.getMethod(&quot;loginUserFromSubject&quot;, Subject.class);
    -					Subject subject = null;
    -					loginUserFromSubjectMethod.invoke(null, subject);
    -				}
&lt;p&gt; catch (NoSuchMethodException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;LOG.warn(&quot;Could not find method implementations in the shaded jar. Exception: {}&quot;, e);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// note that the stored tokens are read automatically&lt;/li&gt;
	&lt;li&gt;loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		// install the security modules&lt;br/&gt;
    +		List&amp;lt;SecurityModule&amp;gt; modules = new ArrayList();&lt;br/&gt;
    +		try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +			for (Class&amp;lt;? extends SecurityModule&amp;gt; moduleClass }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		catch(Exception ex) &lt;/p&gt;
{
    +			throw new Exception(&quot;unable to establish the security context&quot;, ex);
    +		}
&lt;p&gt;    +		installedModules = modules;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LOG.info(&quot;Hadoop user set to {}&quot;, loginUser.toString());&lt;br/&gt;
    +		// install a security context&lt;br/&gt;
    +		// use the Hadoop login user as the subject of the installed security context&lt;br/&gt;
    +		if (!(installedContext instanceof NoOpSecurityContext)) 
{
    +			LOG.warn(&quot;overriding previous security context&quot;);
    +		}
&lt;p&gt;    +		UserGroupInformation loginUser = UserGroupInformation.getLoginUser();&lt;br/&gt;
    +		installedContext = new HadoopSecurityContext(loginUser);&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;boolean delegationToken = false;&lt;/li&gt;
	&lt;li&gt;final Text HDFS_DELEGATION_KIND = new Text(&quot;HDFS_DELEGATION_TOKEN&quot;);&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;Token&amp;lt;? extends TokenIdentifier&amp;gt;&amp;gt; usrTok = loginUser.getTokens();&lt;/li&gt;
	&lt;li&gt;for (Token&amp;lt;? extends TokenIdentifier&amp;gt; token : usrTok) {&lt;/li&gt;
	&lt;li&gt;final Text id = new Text(token.getIdentifier());&lt;/li&gt;
	&lt;li&gt;LOG.debug(&quot;Found user token &quot; + id + &quot; with &quot; + token);&lt;/li&gt;
	&lt;li&gt;if (token.getKind().equals(HDFS_DELEGATION_KIND)) {&lt;/li&gt;
	&lt;li&gt;delegationToken = true;&lt;br/&gt;
    +	static void uninstall() {&lt;br/&gt;
    +		if(installedModules != null) {&lt;br/&gt;
    +			for (SecurityModule module : Lists.reverse(installedModules)) {&lt;br/&gt;
    +				try 
{
    +					module.uninstall();
     				}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;if (!loginUser.hasKerberosCredentials()) {&lt;/li&gt;
	&lt;li&gt;//throw an error in non-yarn deployment if kerberos cache is not available&lt;/li&gt;
	&lt;li&gt;if (!delegationToken) {&lt;/li&gt;
	&lt;li&gt;LOG.error(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;/li&gt;
	&lt;li&gt;throw new RuntimeException(&quot;Hadoop Security is enabled but current login user does not have Kerberos Credentials&quot;);&lt;br/&gt;
    +				catch(UnsupportedOperationException e) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    The uninstall isn&apos;t used in production, only in test code.   Throwing gives more information to the unit test.  Hopefully getting rid of the warning will suffice for now.&lt;/p&gt;</comment>
                            <comment id="15813450" author="githubbot" created="Tue, 10 Jan 2017 01:12:37 +0000"  >&lt;p&gt;Github user EronWright commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057#discussion_r95283348&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057#discussion_r95283348&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/security/modules/JaasModule.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,147 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.runtime.security.modules;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.annotation.Internal;&lt;br/&gt;
    +import org.apache.flink.runtime.security.DynamicConfiguration;&lt;br/&gt;
    +import org.apache.flink.runtime.security.KerberosUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.security.SecurityUtils;&lt;br/&gt;
    +import org.slf4j.Logger;&lt;br/&gt;
    +import org.slf4j.LoggerFactory;&lt;br/&gt;
    +&lt;br/&gt;
    +import javax.security.auth.login.AppConfigurationEntry;&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.io.InputStream;&lt;br/&gt;
    +import java.nio.file.Files;&lt;br/&gt;
    +import java.nio.file.Path;&lt;br/&gt;
    +import java.nio.file.StandardCopyOption;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Responsible for installing a process-wide JAAS configuration.&lt;br/&gt;
    + * &amp;lt;p&amp;gt;&lt;br/&gt;
    + * The installed configuration combines login modules based on:&lt;br/&gt;
    + * - the user-supplied JAAS configuration file, if any&lt;br/&gt;
    + * - a Kerberos keytab, if configured&lt;br/&gt;
    + * - any cached Kerberos credentials from the current environment&lt;br/&gt;
    + * &amp;lt;p&amp;gt;&lt;br/&gt;
    + * The module also installs a default JAAS config file (if necessary) for&lt;br/&gt;
    + * compatibility with ZK and Kafka.  Note that the JRE actually draws on numerous file locations.&lt;br/&gt;
    + * See: &lt;a href=&quot;https://docs.oracle.com/javase/7/docs/jre/api/security/jaas/spec/com/sun/security/auth/login/ConfigFile.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.oracle.com/javase/7/docs/jre/api/security/jaas/spec/com/sun/security/auth/login/ConfigFile.html&lt;/a&gt;&lt;br/&gt;
    + * See: &lt;a href=&quot;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/security/kerberos/Login.java#L289&lt;/a&gt;&lt;br/&gt;
    + */&lt;br/&gt;
    +@Internal&lt;br/&gt;
    +public class JaasModule implements SecurityModule {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Logger LOG = LoggerFactory.getLogger(JaasModule.class);&lt;br/&gt;
    +&lt;br/&gt;
    +	static final String JAVA_SECURITY_AUTH_LOGIN_CONFIG = &quot;java.security.auth.login.config&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	static final String JAAS_CONF_RESOURCE_NAME = &quot;flink-jaas.conf&quot;;&lt;br/&gt;
    +&lt;br/&gt;
    +	private String priorConfigFile;&lt;br/&gt;
    +	private javax.security.auth.login.Configuration priorConfig;&lt;br/&gt;
    +&lt;br/&gt;
    +	private DynamicConfiguration currentConfig;&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public void install(SecurityUtils.SecurityConfiguration securityConfig) {&lt;br/&gt;
    +&lt;br/&gt;
    +		// ensure that a config file is always defined, for compatibility with&lt;br/&gt;
    +		// ZK and Kafka which check for the system property and existence of the file&lt;br/&gt;
    +		priorConfigFile = System.getProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG, null);&lt;br/&gt;
    +		if (priorConfigFile == null) &lt;/p&gt;
{
    +			File configFile = generateDefaultConfigFile();
    +			System.setProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG, configFile.getAbsolutePath());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		// read the JAAS configuration file&lt;br/&gt;
    +		priorConfig = javax.security.auth.login.Configuration.getConfiguration();&lt;br/&gt;
    +&lt;br/&gt;
    +		// construct a dynamic JAAS configuration&lt;br/&gt;
    +		currentConfig = new DynamicConfiguration(priorConfig);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wire up the configured JAAS login contexts to use the krb5 entries&lt;br/&gt;
    +		AppConfigurationEntry[] krb5Entries = getAppConfigurationEntries(securityConfig);&lt;br/&gt;
    +		if(krb5Entries != null) {&lt;br/&gt;
    +			for (String app : securityConfig.getLoginContextNames()) &lt;/p&gt;
{
    +				currentConfig.addAppConfigurationEntry(app, krb5Entries);
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		javax.security.auth.login.Configuration.setConfiguration(currentConfig);&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public void uninstall() {&lt;br/&gt;
    +		if(priorConfigFile != null) &lt;/p&gt;
{
    +			System.setProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG, priorConfigFile);
    +		}
&lt;p&gt; else &lt;/p&gt;
{
    +			System.clearProperty(JAVA_SECURITY_AUTH_LOGIN_CONFIG);
    +		}
&lt;p&gt;    +		javax.security.auth.login.Configuration.setConfiguration(priorConfig);&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	public DynamicConfiguration getCurrentConfiguration() &lt;/p&gt;
{
    +		return currentConfig;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private static AppConfigurationEntry[] getAppConfigurationEntries(SecurityUtils.SecurityConfiguration securityConfig) {&lt;br/&gt;
    +&lt;br/&gt;
    +		AppConfigurationEntry userKerberosAce = null;&lt;br/&gt;
    +		if (securityConfig.useTicketCache()) &lt;/p&gt;
{
    +			userKerberosAce = KerberosUtils.ticketCacheEntry();
    +		}
&lt;p&gt;    +		AppConfigurationEntry keytabKerberosAce = null;&lt;br/&gt;
    +		if (securityConfig.getKeytab() != null) &lt;/p&gt;
{
    +			keytabKerberosAce = KerberosUtils.keytabEntry(securityConfig.getKeytab(), securityConfig.getPrincipal());
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		AppConfigurationEntry[] appConfigurationEntry;&lt;br/&gt;
    +		if (userKerberosAce != null &amp;amp;&amp;amp; keytabKerberosAce != null) {&lt;br/&gt;
    +			appConfigurationEntry = new AppConfigurationEntry[]&lt;/p&gt;
{keytabKerberosAce, userKerberosAce}
&lt;p&gt;;&lt;br/&gt;
    +		} else if (keytabKerberosAce != null) {&lt;br/&gt;
    +			appConfigurationEntry = new AppConfigurationEntry[]&lt;/p&gt;
{keytabKerberosAce}
&lt;p&gt;;&lt;br/&gt;
    +		} else if (userKerberosAce != null) {&lt;br/&gt;
    +			appConfigurationEntry = new AppConfigurationEntry[]&lt;/p&gt;
{userKerberosAce}
&lt;p&gt;;&lt;br/&gt;
    +		} else &lt;/p&gt;
{
    +			return null;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		return appConfigurationEntry;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Generate the default JAAS config file.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private static File generateDefaultConfigFile() {&lt;br/&gt;
    +		// load Jaas config file to initialize SASL&lt;br/&gt;
    +		final File jaasConfFile;&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			Path jaasConfPath = Files.createTempFile(&quot;jaas-&quot;, &quot;.conf&quot;);&lt;br/&gt;
    +			try (InputStream resourceStream = JaasModule.class.getClassLoader().getResourceAsStream(JAAS_CONF_RESOURCE_NAME)) &lt;/p&gt;
{
    +				Files.copy(resourceStream, jaasConfPath, StandardCopyOption.REPLACE_EXISTING);
    +			}
&lt;p&gt;    +			jaasConfFile = jaasConfPath.toFile();&lt;br/&gt;
    +			jaasConfFile.deleteOnExit();&lt;br/&gt;
    +		} catch (IOException e) {&lt;br/&gt;
    +			throw new RuntimeException(&quot;unable to generate a JAAS configuration file&quot;, e);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    In this case, I do consider a failure to generate the default config a programming error; it simply extracts an in-built resource as a temp file.   I definitely agree with your general point.&lt;/p&gt;</comment>
                            <comment id="15813707" author="githubbot" created="Tue, 10 Jan 2017 03:23:52 +0000"  >&lt;p&gt;Github user EronWright commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen updated based on feedback, thanks again.&lt;/p&gt;</comment>
                            <comment id="15819045" author="githubbot" created="Wed, 11 Jan 2017 20:21:00 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3057&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15819049" author="stephanewen" created="Wed, 11 Jan 2017 20:21:41 +0000"  >&lt;p&gt;Fixed in&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;1.2.0 via 00193f7e238340cc18c57a44c7e6377432839373&lt;/li&gt;
	&lt;li&gt;1.3.0 via fc3a778c0cafe1adc9efbd8796a8bd64122e4ad2&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13020111">FLINK-5055</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13029752">FLINK-5379</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13028632">FLINK-5350</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13028848">FLINK-5361</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 44 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i37r2v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>