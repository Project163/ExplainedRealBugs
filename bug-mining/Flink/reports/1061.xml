<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:24:08 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-4027] FlinkKafkaProducer09 sink can lose messages</title>
                <link>https://issues.apache.org/jira/browse/FLINK-4027</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The FlinkKafkaProducer09 sink appears to not offer at-least-once guarantees.&lt;/p&gt;

&lt;p&gt;The producer is publishing messages asynchronously.  A callback can record publishing errors, which will be raised when detected.  But as far as I can tell, there is no barrier to wait for async errors from the sink when checkpointing or to track the event time of acked messages to inform the checkpointing process.&lt;/p&gt;

&lt;p&gt;If a checkpoint occurs while there are pending publish requests, and the requests return a failure after the checkpoint occurred, those message will be lost as the checkpoint will consider them processed by the sink.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12976202">FLINK-4027</key>
            <summary>FlinkKafkaProducer09 sink can lose messages</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rmetzger">Robert Metzger</assignee>
                                    <reporter username="elevy">Elias Levy</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 Jun 2016 21:07:35 +0000</created>
                <updated>Mon, 4 Jul 2016 09:56:06 +0000</updated>
                            <resolved>Mon, 4 Jul 2016 09:55:45 +0000</resolved>
                                    <version>1.0.3</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15322509" author="aljoscha" created="Thu, 9 Jun 2016 13:38:44 +0000"  >&lt;p&gt;This is the mailing list thread about this: &lt;a href=&quot;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Kafka-producer-sink-message-loss-td7371.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Kafka-producer-sink-message-loss-td7371.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15332450" author="githubbot" created="Wed, 15 Jun 2016 20:08:09 +0000"  >&lt;p&gt;GitHub user rmetzger opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4027&quot; title=&quot;FlinkKafkaProducer09 sink can lose messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4027&quot;&gt;&lt;del&gt;FLINK-4027&lt;/del&gt;&lt;/a&gt; Flush FlinkKafkaProducer on checkpoints&lt;/p&gt;

&lt;p&gt;    A user on the mailing list raised the point that our Kafka producer can be made at-least-once quite easily.&lt;br/&gt;
    The current producer code doesn&apos;t have any guarantees &lt;/p&gt;

&lt;p&gt;    We are using the producer&apos;s callbacks to account for unacknowledged records. When a checkpoint barrier reaches the sink, it will confirm the checkpoint once all pending records have been acked.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/rmetzger/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/rmetzger/flink&lt;/a&gt; flink4027&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2108&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit d657ca8be1420a3e73c48bbbf65788fbd0b75c2c&lt;br/&gt;
Author: Robert Metzger &amp;lt;rmetzger@apache.org&amp;gt;&lt;br/&gt;
Date:   2016-06-15T15:50:38Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4027&quot; title=&quot;FlinkKafkaProducer09 sink can lose messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4027&quot;&gt;&lt;del&gt;FLINK-4027&lt;/del&gt;&lt;/a&gt; Flush FlinkKafkaProducer on checkpoints&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15332598" author="githubbot" created="Wed, 15 Jun 2016 21:20:34 +0000"  >&lt;p&gt;Github user eliaslevy commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67247830&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67247830&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -51,10 +54,11 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Flink Sink to produce data into a Kafka topic.&lt;br/&gt;
      *&lt;/li&gt;
	&lt;li&gt;Please note that this producer does not have any reliability guarantees.&lt;br/&gt;
    + * The producer implements the checkpointed interface for allowing synchronization on checkpoints.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    May want to change:&lt;/p&gt;

&lt;p&gt;    &amp;gt; note that this producer does not have any reliability guarantees.&lt;/p&gt;

&lt;p&gt;    to&lt;/p&gt;

&lt;p&gt;    &amp;gt; note that this producer provides at-least-once reliability guarantees when checkpoints are enabled.&lt;/p&gt;
</comment>
                            <comment id="15332616" author="githubbot" created="Wed, 15 Jun 2016 21:27:02 +0000"  >&lt;p&gt;Github user eliaslevy commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67248839&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67248839&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -276,6 +314,41 @@ public void close() throws Exception &lt;/p&gt;
{
     		checkErroneous();
     	}

&lt;p&gt;    +	// ------------------- Logic for handling checkpoint flushing -------------------------- //&lt;br/&gt;
    +&lt;br/&gt;
    +	private void acknowledgeMessage() {&lt;br/&gt;
    +		if(!flushOnCheckpoint) &lt;/p&gt;
{
    +			// the logic is disabled
    +			return;
    +		}
&lt;p&gt;    +		pendingRecords--;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public Serializable snapshotState(long checkpointId, long checkpointTimestamp) {&lt;br/&gt;
    +		if(flushOnCheckpoint) {&lt;br/&gt;
    +			// flushing is activated: We need to wait until pendingRecords is 0&lt;br/&gt;
    +			while(pendingRecords &amp;gt; 0) {&lt;br/&gt;
    +				try {&lt;br/&gt;
    +					Thread.sleep(10);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Any reason to sleep instead of calling producer.flush() to wait for the acks?&lt;/p&gt;</comment>
                            <comment id="15333260" author="githubbot" created="Thu, 16 Jun 2016 07:12:03 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67296678&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67296678&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -276,6 +314,41 @@ public void close() throws Exception &lt;/p&gt;
{
     		checkErroneous();
     	}

&lt;p&gt;    +	// ------------------- Logic for handling checkpoint flushing -------------------------- //&lt;br/&gt;
    +&lt;br/&gt;
    +	private void acknowledgeMessage() {&lt;br/&gt;
    +		if(!flushOnCheckpoint) &lt;/p&gt;
{
    +			// the logic is disabled
    +			return;
    +		}
&lt;p&gt;    +		pendingRecords--;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public Serializable snapshotState(long checkpointId, long checkpointTimestamp) {&lt;br/&gt;
    +		if(flushOnCheckpoint) {&lt;br/&gt;
    +			// flushing is activated: We need to wait until pendingRecords is 0&lt;br/&gt;
    +			while(pendingRecords &amp;gt; 0) {&lt;br/&gt;
    +				try {&lt;br/&gt;
    +					Thread.sleep(10);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The problem is that the `flush()` method is only implemented by the Kafka 0.9 producer, not by the 0.8 implementation.&lt;br/&gt;
    As you can see from the classname, its the shared base class between the two version specific implementations. I think for the 0.8 producer, there is no way around the waiting approach.&lt;/p&gt;

&lt;p&gt;    I&apos;ll update the pull request to call `flush()` on the 0.9 producer.&lt;/p&gt;</comment>
                            <comment id="15333492" author="githubbot" created="Thu, 16 Jun 2016 09:53:44 +0000"  >&lt;p&gt;Github user rmetzger commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thank you for the review @eliaslevy!&lt;/p&gt;</comment>
                            <comment id="15333497" author="githubbot" created="Thu, 16 Jun 2016 10:00:33 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67318603&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67318603&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-0.8/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducer08.java &amp;#8212;&lt;br/&gt;
    @@ -125,4 +125,17 @@ public FlinkKafkaProducer08(String topicId, KeyedSerializationSchema&amp;lt;IN&amp;gt; seriali&lt;br/&gt;
     		super(topicId, serializationSchema, producerConfig, customPartitioner);&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	@Override&lt;br/&gt;
    +	protected void flush() {&lt;br/&gt;
    +		// The Kafka 0.8 producer doesn&apos;t support flushing, therefore, we are using an inefficient&lt;br/&gt;
    +		// busy wait approach&lt;br/&gt;
    +		while(pendingRecords &amp;gt; 0) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    missing space after while&lt;/p&gt;</comment>
                            <comment id="15333498" author="githubbot" created="Thu, 16 Jun 2016 10:00:57 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67318672&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67318672&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-0.9/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducer09.java &amp;#8212;&lt;br/&gt;
    @@ -127,4 +127,11 @@ public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema&amp;lt;IN&amp;gt; seriali&lt;br/&gt;
     	public FlinkKafkaProducer09(String topicId, KeyedSerializationSchema&amp;lt;IN&amp;gt; serializationSchema, Properties producerConfig, KafkaPartitioner&amp;lt;IN&amp;gt; customPartitioner) &lt;/p&gt;
{
     		super(topicId, serializationSchema, producerConfig, customPartitioner);
     	}
&lt;p&gt;    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	protected void flush() {&lt;br/&gt;
    +		if(this.producer != null) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    missing space after if&lt;/p&gt;</comment>
                            <comment id="15333500" author="githubbot" created="Thu, 16 Jun 2016 10:01:31 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67318738&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67318738&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -261,7 +298,9 @@ public void invoke(IN next) throws Exception {&lt;br/&gt;
     		} else &lt;/p&gt;
{
     			record = new ProducerRecord&amp;lt;&amp;gt;(targetTopic, partitioner.partition(next, serializedKey, serializedValue, partitions.length), serializedKey, serializedValue);
     		}
&lt;p&gt;    -&lt;br/&gt;
    +		if(flushOnCheckpoint) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    missing space after if&lt;/p&gt;</comment>
                            <comment id="15333501" author="githubbot" created="Thu, 16 Jun 2016 10:01:49 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67318778&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67318778&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -276,6 +315,38 @@ public void close() throws Exception &lt;/p&gt;
{
     		checkErroneous();
     	}

&lt;p&gt;    +	// ------------------- Logic for handling checkpoint flushing -------------------------- //&lt;br/&gt;
    +&lt;br/&gt;
    +	private void acknowledgeMessage() {&lt;br/&gt;
    +		if(!flushOnCheckpoint) &lt;/p&gt;
{
    +			// the logic is disabled
    +			return;
    +		}
&lt;p&gt;    +		pendingRecords--;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	protected abstract void flush();&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public Serializable snapshotState(long checkpointId, long checkpointTimestamp) {&lt;br/&gt;
    +		if(flushOnCheckpoint) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    space&lt;/p&gt;</comment>
                            <comment id="15333502" author="githubbot" created="Thu, 16 Jun 2016 10:01:59 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67318807&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67318807&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -276,6 +315,38 @@ public void close() throws Exception &lt;/p&gt;
{
     		checkErroneous();
     	}

&lt;p&gt;    +	// ------------------- Logic for handling checkpoint flushing -------------------------- //&lt;br/&gt;
    +&lt;br/&gt;
    +	private void acknowledgeMessage() {&lt;br/&gt;
    +		if(!flushOnCheckpoint) &lt;/p&gt;
{
    +			// the logic is disabled
    +			return;
    +		}
&lt;p&gt;    +		pendingRecords--;&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	protected abstract void flush();&lt;br/&gt;
    +&lt;br/&gt;
    +	@Override&lt;br/&gt;
    +	public Serializable snapshotState(long checkpointId, long checkpointTimestamp) {&lt;br/&gt;
    +		if(flushOnCheckpoint) {&lt;br/&gt;
    +			// flushing is activated: We need to wait until pendingRecords is 0&lt;br/&gt;
    +			flush();&lt;br/&gt;
    +&lt;br/&gt;
    +			if(pendingRecords != 0) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    space&lt;/p&gt;</comment>
                            <comment id="15333503" author="githubbot" created="Thu, 16 Jun 2016 10:02:19 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67318851&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67318851&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -276,6 +315,38 @@ public void close() throws Exception &lt;/p&gt;
{
     		checkErroneous();
     	}

&lt;p&gt;    +	// ------------------- Logic for handling checkpoint flushing -------------------------- //&lt;br/&gt;
    +&lt;br/&gt;
    +	private void acknowledgeMessage() {&lt;br/&gt;
    +		if(!flushOnCheckpoint) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    space&lt;/p&gt;</comment>
                            <comment id="15333505" author="githubbot" created="Thu, 16 Jun 2016 10:02:47 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r67318905&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r67318905&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/AtLeastOnceProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,206 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.streaming.connectors.kafka.testutils.MockRuntimeContext;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchema;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.SimpleStringSchema;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Callback;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.KafkaProducer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Producer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.ProducerRecord;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.RecordMetadata;&lt;br/&gt;
    +import org.apache.kafka.common.Metric;&lt;br/&gt;
    +import org.apache.kafka.common.MetricName;&lt;br/&gt;
    +import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
    +import org.apache.kafka.common.serialization.ByteArraySerializer;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Properties;&lt;br/&gt;
    +import java.util.concurrent.Future;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Test ensuring that the producer is not dropping buffered records&lt;br/&gt;
    + */&lt;br/&gt;
    +@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +public class AtLeastOnceProducerTest {&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Exception &lt;/p&gt;
{
    +		runTest(true);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	// This test ensures that the actual test fails if the flushing is disabled&lt;br/&gt;
    +	@Test(expected = AssertionError.class)&lt;br/&gt;
    +	public void ensureTestFails() throws Exception &lt;/p&gt;
{
    +		runTest(false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private void runTest(boolean flushOnCheckpoint) throws Exception {&lt;br/&gt;
    +		Properties props = new Properties();&lt;br/&gt;
    +		final TestingKafkaProducer&amp;lt;String&amp;gt; producer = new TestingKafkaProducer&amp;lt;&amp;gt;(&quot;someTopic&quot;, new KeyedSerializationSchemaWrapper&amp;lt;&amp;gt;(new SimpleStringSchema()), props);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +		producer.setRuntimeContext(new MockRuntimeContext(0, 1));&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.open(new Configuration());&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; 100; i++) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    missing space after for&lt;/p&gt;</comment>
                            <comment id="15334636" author="githubbot" created="Thu, 16 Jun 2016 20:40:43 +0000"  >&lt;p&gt;Github user eliaslevy commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &#128077; &lt;/p&gt;</comment>
                            <comment id="15344598" author="githubbot" created="Wed, 22 Jun 2016 16:00:07 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68081660&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68081660&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -50,11 +53,13 @@&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Flink Sink to produce data into a Kafka topic.&lt;br/&gt;
      *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Please note that this producer does not have any reliability guarantees.&lt;br/&gt;
    + * Please note that this producer provides at-least-once reliability guarantees when&lt;br/&gt;
    + * checkpoints are enabled and setFlushOnCheckpoint(true) is set.&lt;br/&gt;
    + * Otherwise, the producer doesn&apos;t provide any reliability guarantees.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Does it make sense to completely remove the old behaviour and always enable flush on checkpoint? I&apos;m wondering, because who would like to use a KafkaProducer with not processing guarantees?&lt;/p&gt;</comment>
                            <comment id="15344621" author="githubbot" created="Wed, 22 Jun 2016 16:04:49 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68082639&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68082639&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -50,11 +53,13 @@&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Flink Sink to produce data into a Kafka topic.&lt;br/&gt;
      *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Please note that this producer does not have any reliability guarantees.&lt;br/&gt;
    + * Please note that this producer provides at-least-once reliability guarantees when&lt;br/&gt;
    + * checkpoints are enabled and setFlushOnCheckpoint(true) is set.&lt;br/&gt;
    + * Otherwise, the producer doesn&apos;t provide any reliability guarantees.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    My reasoning here was that we first provide this as an optional feature to those users who know what they are doing / what they need to give the feature exposure.&lt;br/&gt;
    I want to be certain that it works in all environments before we activate it by default.&lt;/p&gt;</comment>
                            <comment id="15344654" author="githubbot" created="Wed, 22 Jun 2016 16:22:10 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68085762&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68085762&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -113,6 +123,14 @@&lt;br/&gt;
     	/** Errors encountered in the async producer are stored here */&lt;br/&gt;
     	protected transient volatile Exception asyncException;&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * Number of unacknowledged records.&lt;br/&gt;
    +	 * There is no need to introduce additional locks because invoke() and snapshotState() are&lt;br/&gt;
    +	 * never called concurrently. So blocking the snapshotting will lock the invoke() method until all&lt;br/&gt;
    +	 * pending records have been confirmed.&lt;br/&gt;
    +	 */&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think the fact that `invoke` and `snapshotState` are mutually exclusive is not important for the semantics of the `pendingRecords` variable. The reason is that it will only be incremented in `invoke` and decremented in the `callbacks` of the Kafka producer.&lt;/p&gt;</comment>
                            <comment id="15344657" author="githubbot" created="Wed, 22 Jun 2016 16:23:29 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68086007&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68086007&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -261,7 +298,9 @@ public void invoke(IN next) throws Exception {&lt;br/&gt;
     		} else &lt;/p&gt;
{
     			record = new ProducerRecord&amp;lt;&amp;gt;(targetTopic, partitioner.partition(next, serializedKey, serializedValue, partitions.length), serializedKey, serializedValue);
     		}
&lt;p&gt;    -&lt;br/&gt;
    +		if(flushOnCheckpoint) {&lt;br/&gt;
    +			pendingRecords++;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The increment and decrement operations are not atomic. Thus, we have to guard them from concurrent access. Concurrent modifications can happen when you&apos;re in the `invoke` method and a callback is executed at the same time.&lt;/p&gt;</comment>
                            <comment id="15344658" author="githubbot" created="Wed, 22 Jun 2016 16:24:03 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68086118&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68086118&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -276,6 +315,38 @@ public void close() throws Exception &lt;/p&gt;
{
     		checkErroneous();
     	}

&lt;p&gt;    +	// ------------------- Logic for handling checkpoint flushing -------------------------- //&lt;br/&gt;
    +&lt;br/&gt;
    +	private void acknowledgeMessage() {&lt;br/&gt;
    +		if(!flushOnCheckpoint) &lt;/p&gt;
{
    +			// the logic is disabled
    +			return;
    +		}
&lt;p&gt;    +		pendingRecords--;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think it is necessary to guard against concurrent changes from the `invoke` method.&lt;/p&gt;</comment>
                            <comment id="15344660" author="githubbot" created="Wed, 22 Jun 2016 16:24:56 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68086261&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68086261&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-0.8/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducer08.java &amp;#8212;&lt;br/&gt;
    @@ -125,4 +125,17 @@ public FlinkKafkaProducer08(String topicId, KeyedSerializationSchema&amp;lt;IN&amp;gt; seriali&lt;br/&gt;
     		super(topicId, serializationSchema, producerConfig, customPartitioner);&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	@Override&lt;br/&gt;
    +	protected void flush() {&lt;br/&gt;
    +		// The Kafka 0.8 producer doesn&apos;t support flushing, therefore, we are using an inefficient&lt;br/&gt;
    +		// busy wait approach&lt;br/&gt;
    +		while(pendingRecords &amp;gt; 0) {&lt;br/&gt;
    +			try {&lt;br/&gt;
    +				Thread.sleep(10);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I&apos;m not a big fan of busy waiting. Can&apos;t we wait on the lock for accessing `pendingRecords` and let the callbacks call `notify` when the `pendingRecords == 0`?&lt;/p&gt;</comment>
                            <comment id="15344671" author="githubbot" created="Wed, 22 Jun 2016 16:29:07 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68087013&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68087013&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/AtLeastOnceProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,206 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.streaming.connectors.kafka.testutils.MockRuntimeContext;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchema;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.SimpleStringSchema;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Callback;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.KafkaProducer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Producer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.ProducerRecord;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.RecordMetadata;&lt;br/&gt;
    +import org.apache.kafka.common.Metric;&lt;br/&gt;
    +import org.apache.kafka.common.MetricName;&lt;br/&gt;
    +import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
    +import org.apache.kafka.common.serialization.ByteArraySerializer;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Properties;&lt;br/&gt;
    +import java.util.concurrent.Future;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Test ensuring that the producer is not dropping buffered records&lt;br/&gt;
    + */&lt;br/&gt;
    +@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +public class AtLeastOnceProducerTest {&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Exception &lt;/p&gt;
{
    +		runTest(true);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	// This test ensures that the actual test fails if the flushing is disabled&lt;br/&gt;
    +	@Test(expected = AssertionError.class)&lt;br/&gt;
    +	public void ensureTestFails() throws Exception &lt;/p&gt;
{
    +		runTest(false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private void runTest(boolean flushOnCheckpoint) throws Exception {&lt;br/&gt;
    +		Properties props = new Properties();&lt;br/&gt;
    +		final TestingKafkaProducer&amp;lt;String&amp;gt; producer = new TestingKafkaProducer&amp;lt;&amp;gt;(&quot;someTopic&quot;, new KeyedSerializationSchemaWrapper&amp;lt;&amp;gt;(new SimpleStringSchema()), props);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +		producer.setRuntimeContext(new MockRuntimeContext(0, 1));&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.open(new Configuration());&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			producer.invoke(&quot;msg-&quot; + i);
    +		}&lt;br/&gt;
    +		// start a thread confirming all pending records&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final AtomicBoolean markOne = new AtomicBoolean(false);&lt;br/&gt;
    +		Runnable confirmer = new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() {&lt;br/&gt;
    +				try {&lt;br/&gt;
    +					MockProducer mp = producer.getProducerInstance();&lt;br/&gt;
    +					List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +					// we ensure thread A is locked and didn&apos;t reach markOne&lt;br/&gt;
    +					// give thread A some time to really reach the snapshot state&lt;br/&gt;
    +					Thread.sleep(500);&lt;br/&gt;
    +					if(markOne.get()) {
    +						Assert.fail(&quot;Snapshot was confirmed even though messages &quot; +
    +								&quot;were still in the buffer&quot;);
    +					}&lt;br/&gt;
    +					Assert.assertEquals(100, pending.size());&lt;br/&gt;
    +&lt;br/&gt;
    +					// now confirm all checkpoints&lt;br/&gt;
    +					for(Callback c: pending) {
    +						c.onCompletion(null, null);
    +					}&lt;br/&gt;
    +					pending.clear();&lt;br/&gt;
    +					// wait for the snapshotState() method to return&lt;br/&gt;
    +					Thread.sleep(100);&lt;br/&gt;
    +					Assert.assertTrue(&quot;Snapshot state didn&apos;t return&quot;, markOne.get());&lt;br/&gt;
    +				} catch(Throwable t) {
    +					runnableError.f0 = t;
    +				}&lt;br/&gt;
    +			}&lt;br/&gt;
    +		};&lt;br/&gt;
    +		Thread threadB = new Thread(confirmer);&lt;br/&gt;
    +		threadB.start();&lt;br/&gt;
    +		// this should block:&lt;br/&gt;
    +		producer.snapshotState(0, 0);&lt;br/&gt;
    +		// once all pending callbacks are confirmed, we can set this marker to true&lt;br/&gt;
    +		markOne.set(true);&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; 99; i++) {    +			producer.invoke(&quot;msg-&quot; + i);    +		}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why do you invoke again the producer?&lt;/p&gt;</comment>
                            <comment id="15344679" author="githubbot" created="Wed, 22 Jun 2016 16:30:34 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68087265&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68087265&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/AtLeastOnceProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,206 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.streaming.connectors.kafka.testutils.MockRuntimeContext;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchema;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.SimpleStringSchema;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Callback;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.KafkaProducer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Producer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.ProducerRecord;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.RecordMetadata;&lt;br/&gt;
    +import org.apache.kafka.common.Metric;&lt;br/&gt;
    +import org.apache.kafka.common.MetricName;&lt;br/&gt;
    +import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
    +import org.apache.kafka.common.serialization.ByteArraySerializer;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Properties;&lt;br/&gt;
    +import java.util.concurrent.Future;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Test ensuring that the producer is not dropping buffered records&lt;br/&gt;
    + */&lt;br/&gt;
    +@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +public class AtLeastOnceProducerTest {&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Exception &lt;/p&gt;
{
    +		runTest(true);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	// This test ensures that the actual test fails if the flushing is disabled&lt;br/&gt;
    +	@Test(expected = AssertionError.class)&lt;br/&gt;
    +	public void ensureTestFails() throws Exception &lt;/p&gt;
{
    +		runTest(false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private void runTest(boolean flushOnCheckpoint) throws Exception {&lt;br/&gt;
    +		Properties props = new Properties();&lt;br/&gt;
    +		final TestingKafkaProducer&amp;lt;String&amp;gt; producer = new TestingKafkaProducer&amp;lt;&amp;gt;(&quot;someTopic&quot;, new KeyedSerializationSchemaWrapper&amp;lt;&amp;gt;(new SimpleStringSchema()), props);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +		producer.setRuntimeContext(new MockRuntimeContext(0, 1));&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.open(new Configuration());&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			producer.invoke(&quot;msg-&quot; + i);
    +		}
&lt;p&gt;    +		// start a thread confirming all pending records&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final AtomicBoolean markOne = new AtomicBoolean(false);&lt;br/&gt;
    +		Runnable confirmer = new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() {&lt;br/&gt;
    +				try {&lt;br/&gt;
    +					MockProducer mp = producer.getProducerInstance();&lt;br/&gt;
    +					List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +					// we ensure thread A is locked and didn&apos;t reach markOne&lt;br/&gt;
    +					// give thread A some time to really reach the snapshot state&lt;br/&gt;
    +					Thread.sleep(500);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Tests based on `Thread.sleep` are bound to become flakey on Travis. Usually it is better to synchronize on futures or locks.&lt;/p&gt;</comment>
                            <comment id="15344680" author="githubbot" created="Wed, 22 Jun 2016 16:31:14 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68087375&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68087375&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/AtLeastOnceProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,206 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.connectors.kafka;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.java.tuple.Tuple1;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.streaming.connectors.kafka.testutils.MockRuntimeContext;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchema;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.KeyedSerializationSchemaWrapper;&lt;br/&gt;
    +import org.apache.flink.streaming.util.serialization.SimpleStringSchema;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Callback;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.KafkaProducer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.Producer;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.ProducerRecord;&lt;br/&gt;
    +import org.apache.kafka.clients.producer.RecordMetadata;&lt;br/&gt;
    +import org.apache.kafka.common.Metric;&lt;br/&gt;
    +import org.apache.kafka.common.MetricName;&lt;br/&gt;
    +import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
    +import org.apache.kafka.common.serialization.ByteArraySerializer;&lt;br/&gt;
    +import org.junit.Assert;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.util.ArrayList;&lt;br/&gt;
    +import java.util.List;&lt;br/&gt;
    +import java.util.Map;&lt;br/&gt;
    +import java.util.Properties;&lt;br/&gt;
    +import java.util.concurrent.Future;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Test ensuring that the producer is not dropping buffered records&lt;br/&gt;
    + */&lt;br/&gt;
    +@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +public class AtLeastOnceProducerTest {&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Exception &lt;/p&gt;
{
    +		runTest(true);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	// This test ensures that the actual test fails if the flushing is disabled&lt;br/&gt;
    +	@Test(expected = AssertionError.class)&lt;br/&gt;
    +	public void ensureTestFails() throws Exception &lt;/p&gt;
{
    +		runTest(false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	private void runTest(boolean flushOnCheckpoint) throws Exception {&lt;br/&gt;
    +		Properties props = new Properties();&lt;br/&gt;
    +		final TestingKafkaProducer&amp;lt;String&amp;gt; producer = new TestingKafkaProducer&amp;lt;&amp;gt;(&quot;someTopic&quot;, new KeyedSerializationSchemaWrapper&amp;lt;&amp;gt;(new SimpleStringSchema()), props);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +		producer.setRuntimeContext(new MockRuntimeContext(0, 1));&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.open(new Configuration());&lt;br/&gt;
    +&lt;br/&gt;
    +		for(int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			producer.invoke(&quot;msg-&quot; + i);
    +		}
&lt;p&gt;    +		// start a thread confirming all pending records&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final AtomicBoolean markOne = new AtomicBoolean(false);&lt;br/&gt;
    +		Runnable confirmer = new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() {&lt;br/&gt;
    +				try {&lt;br/&gt;
    +					MockProducer mp = producer.getProducerInstance();&lt;br/&gt;
    +					List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +					// we ensure thread A is locked and didn&apos;t reach markOne&lt;br/&gt;
    +					// give thread A some time to really reach the snapshot state&lt;br/&gt;
    +					Thread.sleep(500);&lt;br/&gt;
    +					if(markOne.get()) &lt;/p&gt;
{
    +						Assert.fail(&quot;Snapshot was confirmed even though messages &quot; +
    +								&quot;were still in the buffer&quot;);
    +					}
&lt;p&gt;    +					Assert.assertEquals(100, pending.size());&lt;br/&gt;
    +&lt;br/&gt;
    +					// now confirm all checkpoints&lt;br/&gt;
    +					for(Callback c: pending) &lt;/p&gt;
{
    +						c.onCompletion(null, null);
    +					}
&lt;p&gt;    +					pending.clear();&lt;br/&gt;
    +					// wait for the snapshotState() method to return&lt;br/&gt;
    +					Thread.sleep(100);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Here again, who tells us that Thread A has progressed after 100 ms to the point where he set `markOne` to true.&lt;/p&gt;</comment>
                            <comment id="15344688" author="githubbot" created="Wed, 22 Jun 2016 16:33:03 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r68087686&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r68087686&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -50,11 +53,13 @@&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Flink Sink to produce data into a Kafka topic.&lt;br/&gt;
      *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Please note that this producer does not have any reliability guarantees.&lt;br/&gt;
    + * Please note that this producer provides at-least-once reliability guarantees when&lt;br/&gt;
    + * checkpoints are enabled and setFlushOnCheckpoint(true) is set.&lt;br/&gt;
    + * Otherwise, the producer doesn&apos;t provide any reliability guarantees.
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Alright, this makes totally sense&lt;/p&gt;</comment>
                            <comment id="15344690" author="githubbot" created="Wed, 22 Jun 2016 16:34:11 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Good work @rmetzger. Well documented code and a good idea to solve the problem. I had some comments concerning concurrent accesses to `pendingRecords` and test stability on Travis. Once we&apos;ve solved theses points, I think the PR is good to be merged &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15357044" author="githubbot" created="Thu, 30 Jun 2016 13:05:35 +0000"  >&lt;p&gt;Github user rmetzger commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thank you for your review @tillrohrmann and @zentol . I tried addressing all your concerns.&lt;br/&gt;
    Please let me know what you think about it.&lt;/p&gt;</comment>
                            <comment id="15357068" author="githubbot" created="Thu, 30 Jun 2016 13:21:44 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r69130106&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r69130106&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/AtLeastOnceProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -107,15 +115,16 @@ public void run() {&lt;br/&gt;
     		threadB.start();&lt;br/&gt;
     		// this should block:&lt;br/&gt;
     		producer.snapshotState(0, 0);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// once all pending callbacks are confirmed, we can set this marker to true&lt;/li&gt;
	&lt;li&gt;markOne.set(true);&lt;/li&gt;
	&lt;li&gt;for(int i = 0; i &amp;lt; 99; i++) {&lt;/li&gt;
	&lt;li&gt;producer.invoke(&quot;msg-&quot; + i);&lt;br/&gt;
    +		synchronized (threadA) 
{
    +			threadA.notifyAll(); // just in case, to let the test fail faster
     		}&lt;/li&gt;
	&lt;li&gt;// wait at most one second&lt;/li&gt;
	&lt;li&gt;threadB.join(800L);&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A reached this point too fast&quot;, threadB.isAlive());&lt;/li&gt;
	&lt;li&gt;if(runnableError.f0 != null) {&lt;br/&gt;
    +&lt;br/&gt;
    +		Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;br/&gt;
    +		while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    +			threadB.join(500);
    +		}
&lt;p&gt;    +		Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;br/&gt;
    +		if (runnableError.f0 != null) {&lt;br/&gt;
     			runnableError.f0.printStackTrace();&lt;br/&gt;
     			Assert.fail(&quot;Error from thread B: &quot; + runnableError.f0 );&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Printing the stack trace to stdout is imo not so good. The problem is that the stack trace will be intermingled with the rest of the testing log output. I think it&apos;s better to simply rethrow the `Throwable` here.&lt;/p&gt;</comment>
                            <comment id="15357110" author="githubbot" created="Thu, 30 Jun 2016 13:57:10 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r69136271&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r69136271&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/AtLeastOnceProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -35,69 +35,77 @@&lt;br/&gt;
     import org.apache.kafka.common.serialization.ByteArraySerializer;&lt;br/&gt;
     import org.junit.Assert;&lt;br/&gt;
     import org.junit.Test;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;/p&gt;

&lt;p&gt;    +import java.io.Serializable;&lt;br/&gt;
     import java.util.ArrayList;&lt;br/&gt;
     import java.util.List;&lt;br/&gt;
     import java.util.Map;&lt;br/&gt;
     import java.util.Properties;&lt;br/&gt;
     import java.util.concurrent.Future;&lt;br/&gt;
    -import java.util.concurrent.atomic.AtomicBoolean;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Test ensuring that the producer is not dropping buffered records&lt;br/&gt;
      */&lt;br/&gt;
     @SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
     public class AtLeastOnceProducerTest {&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;br/&gt;
    +	// we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
     	public void testAtLeastOnceProducer() throws Exception 
{
     		runTest(true);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	// This test ensures that the actual test fails if the flushing is disabled&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = AssertionError.class)&lt;br/&gt;
    +	@Test(expected = AssertionError.class, timeout=5000)&lt;br/&gt;
     	public void ensureTestFails() throws Exception 
{
     		runTest(false);
     	}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	private void runTest(boolean flushOnCheckpoint) throws Exception {&lt;br/&gt;
     		Properties props = new Properties();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final TestingKafkaProducer&amp;lt;String&amp;gt; producer = new TestingKafkaProducer&amp;lt;&amp;gt;(&quot;someTopic&quot;, new KeyedSerializationSchemaWrapper&amp;lt;&amp;gt;(new SimpleStringSchema()), props);&lt;br/&gt;
    +		final OneShotLatch snapshottingFinished = new OneShotLatch();&lt;br/&gt;
    +		final TestingKafkaProducer&amp;lt;String&amp;gt; producer = new TestingKafkaProducer&amp;lt;&amp;gt;(&quot;someTopic&quot;, new KeyedSerializationSchemaWrapper&amp;lt;&amp;gt;(new SimpleStringSchema()), props,&lt;br/&gt;
    +				snapshottingFinished);&lt;br/&gt;
     		producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
     		producer.setRuntimeContext(new MockRuntimeContext(0, 1));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for(int i = 0; i &amp;lt; 100; i++) {&lt;br/&gt;
    +		for (int i = 0; i &amp;lt; 100; i++) 
{
     			producer.invoke(&quot;msg-&quot; + i);
     		}
&lt;p&gt;     		// start a thread confirming all pending records&lt;br/&gt;
     		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean markOne = new AtomicBoolean(false);&lt;br/&gt;
    +		final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +&lt;br/&gt;
     		Runnable confirmer = new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;br/&gt;
     					MockProducer mp = producer.getProducerInstance();&lt;br/&gt;
     					List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// we ensure thread A is locked and didn&apos;t reach markOne&lt;/li&gt;
	&lt;li&gt;// give thread A some time to really reach the snapshot state&lt;/li&gt;
	&lt;li&gt;Thread.sleep(500);&lt;/li&gt;
	&lt;li&gt;if(markOne.get()) {&lt;/li&gt;
	&lt;li&gt;Assert.fail(&quot;Snapshot was confirmed even though messages &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;were still in the buffer&quot;);&lt;br/&gt;
    +					// we need to find out if the snapshot() method blocks forever&lt;br/&gt;
    +					// this is not possible. If snapshot() is running, it will&lt;br/&gt;
    +					// start removing elements from the pending list.&lt;br/&gt;
    +					synchronized (threadA) 
{
    +						threadA.wait(500L);
     					}
&lt;p&gt;    +					// we now check that no records have been confirmed yet&lt;br/&gt;
     					Assert.assertEquals(100, pending.size());&lt;br/&gt;
    +					Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;br/&gt;
    +							snapshottingFinished.hasTriggered());&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     					// now confirm all checkpoints&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for(Callback c: pending) {&lt;br/&gt;
    +					for (Callback c: pending) 
{
     						c.onCompletion(null, null);
     					}
&lt;p&gt;     					pending.clear();&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// wait for the snapshotState() method to return&lt;/li&gt;
	&lt;li&gt;Thread.sleep(100);&lt;/li&gt;
	&lt;li&gt;Assert.assertTrue(&quot;Snapshot state didn&apos;t return&quot;, markOne.get());&lt;br/&gt;
    +					// wait for the snapshotState() method to return. The will&lt;br/&gt;
    +					// fail if snapshotState never returns.&lt;br/&gt;
    +					snapshottingFinished.await();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I think you don&apos;t need this condition here. There are two possibilities: &lt;/p&gt;

&lt;p&gt;    1. ThreadA leaves `snapshotState` successfully and waits for `threadB`. Since it completed `snapshotState`, the `snapshottingFinished` will be triggered. Thus, there is no waiting.&lt;/p&gt;

&lt;p&gt;    2. ThreadA blocks in `snapshotState`. Then `threadB` does not have to block to trigger the timeout, because `threadA` is already blocked.&lt;/p&gt;

&lt;p&gt;    Consequently, I think you could replace the `OneShotLatch` with a volatile boolean.&lt;/p&gt;</comment>
                            <comment id="15357113" author="githubbot" created="Thu, 30 Jun 2016 13:58:12 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108#discussion_r69136462&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108#discussion_r69136462&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/AtLeastOnceProducerTest.java &amp;#8212;&lt;br/&gt;
    @@ -107,15 +115,16 @@ public void run() {&lt;br/&gt;
     		threadB.start();&lt;br/&gt;
     		// this should block:&lt;br/&gt;
     		producer.snapshotState(0, 0);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// once all pending callbacks are confirmed, we can set this marker to true&lt;/li&gt;
	&lt;li&gt;markOne.set(true);&lt;/li&gt;
	&lt;li&gt;for(int i = 0; i &amp;lt; 99; i++) {&lt;/li&gt;
	&lt;li&gt;producer.invoke(&quot;msg-&quot; + i);&lt;br/&gt;
    +		synchronized (threadA) 
{
    +			threadA.notifyAll(); // just in case, to let the test fail faster
     		}&lt;/li&gt;
	&lt;li&gt;// wait at most one second&lt;/li&gt;
	&lt;li&gt;threadB.join(800L);&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A reached this point too fast&quot;, threadB.isAlive());&lt;/li&gt;
	&lt;li&gt;if(runnableError.f0 != null) {&lt;br/&gt;
    +
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I would insert here an assertion which checks that the number of pendingRecords is `0`.&lt;/p&gt;</comment>
                            <comment id="15357114" author="githubbot" created="Thu, 30 Jun 2016 13:58:59 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Changes look good to me @rmetzger &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I had only some minor comments. +1 for merging after addressing the comments.&lt;/p&gt;</comment>
                            <comment id="15361108" author="rmetzger" created="Mon, 4 Jul 2016 09:55:45 +0000"  >&lt;p&gt;Resolved in &lt;a href=&quot;http://git-wip-us.apache.org/repos/asf/flink/commit/7206b0ed&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://git-wip-us.apache.org/repos/asf/flink/commit/7206b0ed&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15361109" author="githubbot" created="Mon, 4 Jul 2016 09:56:06 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2108&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 20 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2z1pj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>