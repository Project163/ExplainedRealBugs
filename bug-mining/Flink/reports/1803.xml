<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:28:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-6376] when deploy flink cluster on the yarn, it is lack of hdfs delegation token.</title>
                <link>https://issues.apache.org/jira/browse/FLINK-6376</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;1&#12289;I use the flink of version 1.2.0. And  I deploy the flink cluster on the yarn. The hadoop version is 2.7.2.&lt;br/&gt;
2&#12289;I use flink in security model with the keytab and principal. And the key configuration is :security.kerberos.login.keytab: /home/ketab/test.keytab &#12289;security.kerberos.login.principal: test.&lt;br/&gt;
3&#12289;The yarn configuration is default and enable the yarn log aggregation configuration&quot; yarn.log-aggregation-enable : true&quot;;&lt;br/&gt;
4&#12289; Deploying the flink cluster  on the yarn,  the yarn Node manager occur the following failure when aggregation the log in HDFS. The basic reason is lack of HDFS  delegation token. &lt;br/&gt;
 java.io.IOException: Failed on local exception: java.io.IOException: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:&lt;span class=&quot;error&quot;&gt;&amp;#91;TOKEN, KERBEROS&amp;#93;&lt;/span&gt;; Host Details : local host is: &quot;SZV1000258954/10.162.181.24&quot;; destination host is: &quot;SZV1000258954&quot;:25000;&lt;br/&gt;
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:796)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client.call(Client.java:1515)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client.call(Client.java:1447)&lt;br/&gt;
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)&lt;br/&gt;
        at com.sun.proxy.$Proxy26.getFileInfo(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:802)&lt;br/&gt;
        at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:201)&lt;br/&gt;
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)&lt;br/&gt;
        at com.sun.proxy.$Proxy27.getFileInfo(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1919)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1500)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1496)&lt;br/&gt;
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1496)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.checkExists(LogAggregationService.java:271)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.access$100(LogAggregationService.java:68)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$1.run(LogAggregationService.java:299)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1769)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.createAppDir(LogAggregationService.java:284)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initAppAggregator(LogAggregationService.java:390)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initApp(LogAggregationService.java:342)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:470)&lt;br/&gt;
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:68)&lt;br/&gt;
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:194)&lt;br/&gt;
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:120)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.io.IOException: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:&lt;span class=&quot;error&quot;&gt;&amp;#91;TOKEN, KERBEROS&amp;#93;&lt;/span&gt;&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:722)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1769)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:685)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:772)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:394)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1564)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client.call(Client.java:1486)&lt;br/&gt;
        ... 29 more&lt;br/&gt;
Caused by: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:&lt;span class=&quot;error&quot;&gt;&amp;#91;TOKEN, KERBEROS&amp;#93;&lt;/span&gt;&lt;br/&gt;
        at org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:177)&lt;br/&gt;
        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:404)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:581)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:394)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:764)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:760)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1769)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:759)&lt;br/&gt;
        ... 32 more&lt;br/&gt;
5&#12289;the hadoop fix the hadoop issue 14116(&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-14116&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-14116&lt;/a&gt;), if there is no HDFS  delegation token, it will try 20 times after sleeping 1 second. So it will cause the flink cluster deploy on yarn is very slowly, it will spent about 5 minutes to deploy the cluster with 2 taskmanagers.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13066561">FLINK-6376</key>
            <summary>when deploy flink cluster on the yarn, it is lack of hdfs delegation token.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cong">zhangrucong1982</assignee>
                                    <reporter username="cong">zhangrucong1982</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Apr 2017 02:25:58 +0000</created>
                <updated>Thu, 28 Feb 2019 11:31:29 +0000</updated>
                            <resolved>Sat, 1 Jul 2017 12:25:39 +0000</resolved>
                                                    <fixVersion>1.3.2</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>Deployment / YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15984204" author="githubbot" created="Wed, 26 Apr 2017 05:38:31 +0000"  >&lt;p&gt;GitHub user Rucongzhang opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6376&quot; title=&quot;when deploy flink cluster on the yarn, it is lack of hdfs delegation token.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6376&quot;&gt;&lt;del&gt;FLINK-6376&lt;/del&gt;&lt;/a&gt;when deploy flink cluster on the yarn, it is lack of hdfs delegation.&lt;/p&gt;

&lt;p&gt;    Thanks for contributing to Apache Flink. Before you open your pull request, please take the following check list into consideration.&lt;br/&gt;
    If your changes take all of the items into account, feel free to open your pull request. For more information and/or questions please refer to the &lt;span class=&quot;error&quot;&gt;&amp;#91;How To Contribute guide&amp;#93;&lt;/span&gt;(&lt;a href=&quot;http://flink.apache.org/how-to-contribute.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://flink.apache.org/how-to-contribute.html&lt;/a&gt;).&lt;br/&gt;
    In addition to going through the list, please provide a meaningful description of your changes.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] General&lt;/li&gt;
	&lt;li&gt;The pull request references the related JIRA issue (&quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;FLINK-XXX&amp;#93;&lt;/span&gt; Jira title text&quot;)&lt;/li&gt;
	&lt;li&gt;The pull request addresses only one issue&lt;/li&gt;
	&lt;li&gt;Each commit in the PR has a meaningful commit message (including the JIRA id)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Documentation&lt;/li&gt;
	&lt;li&gt;Documentation has been added for new functionality&lt;/li&gt;
	&lt;li&gt;Old documentation affected by the pull request has been updated&lt;/li&gt;
	&lt;li&gt;JavaDoc for public methods has been added&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Tests &amp;amp; Build&lt;/li&gt;
	&lt;li&gt;Functionality added by the pull request is covered by tests&lt;/li&gt;
	&lt;li&gt;`mvn clean verify` has been executed successfully locally or a Travis build has passed&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/Rucongzhang/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Rucongzhang/flink&lt;/a&gt; flink-6376&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3776&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 256f519cda73571c73914c98b3c9ff4381520907&lt;br/&gt;
Author: z00376786 &amp;lt;zhangrucong@huawei.com&amp;gt;&lt;br/&gt;
Date:   2017-04-26T03:36:43Z&lt;/p&gt;

&lt;p&gt;    when deploy flink cluster on the yarn, it is lack of hdfs delegation token&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15984431" author="githubbot" created="Wed, 26 Apr 2017 09:19:31 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Looks like a good fix.&lt;/p&gt;

&lt;p&gt;    I think it would be good to add secure yarn tests (IT Cases) that test this behavior. Otherwise it may soon be accidentally broken again...&lt;/p&gt;</comment>
                            <comment id="15988538" author="githubbot" created="Fri, 28 Apr 2017 09:46:02 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen , yes, i agree with you! I will see how to add the Yarn IT case.&lt;/p&gt;</comment>
                            <comment id="15994505" author="githubbot" created="Wed, 3 May 2017 09:01:51 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen , when I run the YARNHighAvailabilityITCase, occur the following error. I set the flie /etc/hosts as following:&lt;br/&gt;
    9.96.101.32 9-96-101-32 &lt;br/&gt;
    127.0.0.1 localhost&lt;/p&gt;

&lt;p&gt;    The hadoop version I use is master default version 2.7.0. Do you know how to fix the following error?Thanks a lot in advance!&lt;/p&gt;

&lt;p&gt;    Test testMultipleAMKill(org.apache.flink.yarn.YARNHighAvailabilityITCase) failed with:&lt;br/&gt;
    java.net.UnknownHostException: Invalid host name: local host is: (unknown); destination host is: &quot;9-96-101-32&quot;:8032; java.net.UnknownHostException; For more details see:  &lt;a href=&quot;http://wiki.apache.org/hadoop/UnknownHost&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://wiki.apache.org/hadoop/UnknownHost&lt;/a&gt;&lt;br/&gt;
    	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)&lt;br/&gt;
    	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)&lt;br/&gt;
    	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)&lt;br/&gt;
    	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)&lt;br/&gt;
    	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)&lt;br/&gt;
    	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:742)&lt;br/&gt;
    	at org.apache.hadoop.ipc.Client$Connection.&amp;lt;init&amp;gt;(Client.java:400)&lt;br/&gt;
    	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1448)&lt;br/&gt;
    	at org.apache.hadoop.ipc.Client.call(Client.java:1377)&lt;br/&gt;
    	at org.apache.hadoop.ipc.Client.call(Client.java:1359)&lt;br/&gt;
    	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)&lt;br/&gt;
    	at com.sun.proxy.$Proxy76.getApplications(Unknown Source)&lt;br/&gt;
    	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getApplications(ApplicationClientProtocolPBClientImpl.java:197)&lt;br/&gt;
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
    	at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
    	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)&lt;br/&gt;
    	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)&lt;br/&gt;
    	at com.sun.proxy.$Proxy77.getApplications(Unknown Source)&lt;br/&gt;
    	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplications(YarnClientImpl.java:285)&lt;br/&gt;
    	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplications(YarnClientImpl.java:262)&lt;br/&gt;
    	at org.apache.flink.yarn.YarnTestBase.checkClusterEmpty(YarnTestBase.java:194)&lt;br/&gt;
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
    	at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
    	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)&lt;br/&gt;
    	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)&lt;br/&gt;
    	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)&lt;br/&gt;
    	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)&lt;br/&gt;
    	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)&lt;br/&gt;
    	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)&lt;br/&gt;
    	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)&lt;br/&gt;
    	at org.junit.rules.RunRules.evaluate(RunRules.java:20)&lt;br/&gt;
    	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)&lt;br/&gt;
    	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)&lt;br/&gt;
    	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)&lt;br/&gt;
    	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)&lt;br/&gt;
    	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)&lt;br/&gt;
    	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)&lt;br/&gt;
    	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)&lt;br/&gt;
    	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)&lt;br/&gt;
    	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)&lt;br/&gt;
    	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)&lt;br/&gt;
    	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)&lt;br/&gt;
    	at org.junit.rules.RunRules.evaluate(RunRules.java:20)&lt;br/&gt;
    	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)&lt;br/&gt;
    	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)&lt;br/&gt;
    	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)&lt;br/&gt;
    	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)&lt;br/&gt;
    	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:237)&lt;br/&gt;
    	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)&lt;br/&gt;
    Caused by: java.net.UnknownHostException&lt;br/&gt;
    	... 47 more&lt;/p&gt;


</comment>
                            <comment id="15994529" author="githubbot" created="Wed, 3 May 2017 09:18:20 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    The Yarn tests cannot with with Hadoop 2.3.0, which is the default version of master.&lt;/p&gt;</comment>
                            <comment id="15994619" author="githubbot" created="Wed, 3 May 2017 10:14:17 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen , you mean the reason of this problem is the version of hadoop? The version of 2.7.2 is ok? Thanks!&lt;/p&gt;</comment>
                            <comment id="15996688" author="githubbot" created="Thu, 4 May 2017 13:03:27 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen , I can run the yarn IT case! Thanks very much. But, in the Yarn IT case:&lt;br/&gt;
    1&#12289; It uses the yarn mini cluster, which is for testing.I do not know whether it is  using HDFS Delegation token or not.&lt;br/&gt;
    2&#12289;And what&apos;s more, the HDFS Delegation Token is used by yarn node manager. It is difficult to judge whether to have this token or not in yarn client. The token is set into yarn application context,but the yarn client does not have API to get yarn application context.&lt;br/&gt;
    How do you think ? Thanks a lot!&lt;/p&gt;</comment>
                            <comment id="16000162" author="githubbot" created="Mon, 8 May 2017 01:30:57 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    After resolving this problem, we find another problem, when we configure the keytab &#12289;principal, and  add the HDFS delegation token,  the JM &#12289;TM also use this token, but not keytab when communication with HDFS. When token is expired, no one in flink to refresh the token.  &lt;br/&gt;
    But the purpose of adding this token , which is only used for  yarn node manager. We now is resolving this problem. Thanks!&lt;/p&gt;</comment>
                            <comment id="16000490" author="githubbot" created="Mon, 8 May 2017 09:21:01 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @Rucongzhang My understanding was that the Hadoop code should automatically renew delegation tokens when a Kerberos Keytab is present. @EronWright Can you comment on that assumption?&lt;/p&gt;</comment>
                            <comment id="16000625" author="githubbot" created="Mon, 8 May 2017 11:37:05 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen , yes, when configuration keytab,  the hadoop code automatically renew delegation tokens .But when token and keytab are available, the hadoop use the token first, but the keytab.&lt;/p&gt;</comment>
                            <comment id="16018301" author="githubbot" created="Sat, 20 May 2017 03:53:26 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen , we resolve this problem. We only add the HDFS delegation token in JM&#12289;TM yarn container context. And when we configuration the keytab, the JM&#12289;TM use the keytab to authentication with HDFS.&lt;/p&gt;</comment>
                            <comment id="16022454" author="githubbot" created="Wed, 24 May 2017 07:31:28 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Would like to follow up on this PR.&lt;/p&gt;

&lt;p&gt;    @Rucongzhang can you confirm my understanding of the problem?:&lt;br/&gt;
    So, the root cause of the issue is that when both token AND keytab is configured, we&apos;re incorrectly using the token for authentication?&lt;/p&gt;</comment>
                            <comment id="16025736" author="githubbot" created="Fri, 26 May 2017 03:02:29 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai , you are right. There are two problems in yarn cluster mode:    &lt;br/&gt;
    1&#12289;when we use the keytab&#65292;we do not set the HDFS delegation token to yarn container context, but yarn need.&lt;br/&gt;
    2&#12289;when we user keytab, and also get  HDFS delegation token. The UGI contains both, but UGI use token first to communication with HDFS. The default expire time of HDFS delegation token is 7 days. Flink does not refresh the token.&lt;br/&gt;
    So, I resolve this problem by following solution:&lt;br/&gt;
    1&#12289;we user keytab and also get HDFS delegation token.  The token is set to yarn container context. And the UGI only use keytab. &lt;br/&gt;
    Maybe the best solution I think the AM need refresh the token like spark. Maybe we can create a FILP to do this.&lt;/p&gt;</comment>
                            <comment id="16026726" author="githubbot" created="Fri, 26 May 2017 19:31:30 +0000"  >&lt;p&gt;Github user EronWright commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @Rucongzhang thanks for the contribution.  I think I understand the problem and your solution, which I will recap.  I also found &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-2704&quot; title=&quot; Localization and log-aggregation will fail if hdfs delegation token expired after token-max-life-time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;YARN-2704&quot;&gt;&lt;del&gt;YARN-2704&lt;/del&gt;&lt;/a&gt; to be useful background.&lt;/p&gt;

&lt;p&gt;    &lt;b&gt;Problem&lt;/b&gt;:&lt;br/&gt;
    1. YARN log aggregation depends on an HDFS delegation token, which it obtains from container token storage not from the UGI.  In keytab mode, the Flink client doesn&apos;t upload any delegation tokens, causing log aggregation to fail.&lt;br/&gt;
    2. The Flink cluster doesn&apos;t renew delegation tokens.  Note: Flink does renew &lt;em&gt;Kerberos tickets&lt;/em&gt; using the keytab.&lt;br/&gt;
    3. When the UGI contains both a delegation token and a Kerberos ticket, the delegation token is preferred.   After expiration, Flink does not fallback to using the ticket.&lt;/p&gt;

&lt;p&gt;    &lt;b&gt;Solution&lt;/b&gt;:&lt;br/&gt;
    1. Change Flink client to upload delegation tokens.  Addresses problem 1.&lt;br/&gt;
    2 Change Flink cluster to filter out the HDFS delegation token from the tokens loaded from storage when populating the UGI.  Addresses problem 3.&lt;br/&gt;
    3 Change JM to propagate its stored tokens to the TM, rather than the tokens from the UGI (which were filtered in (2).&lt;/p&gt;</comment>
                            <comment id="16027210" author="githubbot" created="Sat, 27 May 2017 05:32:04 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @EronWright &#65292;thank you very much . yes you are right. But about solutin 1. We need only add the HDFS delegation token in yarn container context , yarn client not need refresh the token, yarn resource manager can refresh it.&lt;/p&gt;</comment>
                            <comment id="16027507" author="githubbot" created="Sat, 27 May 2017 17:22:39 +0000"  >&lt;p&gt;Github user EronWright commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    +1&lt;/p&gt;</comment>
                            <comment id="16042418" author="githubbot" created="Thu, 8 Jun 2017 08:49:09 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen ,@tzulitai , please review the code ,if it is ok. Please help me to merge the PR. Thanks!&lt;/p&gt;</comment>
                            <comment id="16056938" author="githubbot" created="Wed, 21 Jun 2017 03:43:00 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @Rucongzhang @EronWright thanks for the explanations, the changes looks good to me then.&lt;br/&gt;
    I&apos;ll rebase this, perform some tests and then merge this if all goes well.&lt;/p&gt;</comment>
                            <comment id="16057023" author="githubbot" created="Wed, 21 Jun 2017 05:47:24 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai &#65292;When I have fixed the problem, I want to write a IT case. But, in the Yarn IT case:&lt;br/&gt;
    1&#12289; It uses the yarn mini cluster, which is for testing.I do not know whether it is using HDFS Delegation token or not.&lt;br/&gt;
    2&#12289;And what&apos;s more, the HDFS Delegation Token is used by yarn node manager. It is difficult to judge whether to have this token or not in yarn client. The token is set into yarn application context,but the yarn client does not have API to get yarn application context.&lt;br/&gt;
    How do you think ? Thanks a lot!&lt;/p&gt;</comment>
                            <comment id="16069621" author="githubbot" created="Fri, 30 Jun 2017 07:10:13 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @Rucongzhang ok, understood. I agree that in general the current `AbstractYarnClusterDescriptor` has poor separation of concerns, as is a bit hard to write contained tests. We should remember to add this perhaps when refactoring it for FLIP-6.&lt;/p&gt;

&lt;p&gt;    I&apos;ll give this a test run on YARN and then merge it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16069627" author="githubbot" created="Fri, 30 Jun 2017 07:14:13 +0000"  >&lt;p&gt;Github user Rucongzhang commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tzulitai ,ok,Thanks a lot!&lt;/p&gt;</comment>
                            <comment id="16071083" author="githubbot" created="Sat, 1 Jul 2017 07:37:06 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3776&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3776&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16071198" author="tzulitai" created="Sat, 1 Jul 2017 12:25:39 +0000"  >&lt;p&gt;Fixed for master via b1f3408f4cc5cca4536fe85300efcd5267eba73a&lt;br/&gt;
Fixed for 1.3 via 073852b0cb891e9c4a7bfb1f834875426dedd484.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13203625">FLINK-11126</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13192522">FLINK-10601</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 20 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3e1ov:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>