<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:52:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-21208] pyarrow exception when using window with pandas udaf</title>
                <link>https://issues.apache.org/jira/browse/FLINK-21208</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;I write a pyflink demo and execute in local environment, the logic is simple:generate records and aggerate in 100s tumle window, using a pandas udaf.&lt;br/&gt;
But the job failed after several minutes, I don&apos;t think it&apos;s a resource problem because the amount of data is small, here is the error trace.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: org.apache.flink.streaming.runtime.tasks.AsynchronousException: Caught exception &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; processing timer.
	at org.apache.flink.streaming.runtime.tasks.StreamTask$StreamTaskAsyncExceptionHandler.handleAsyncException(StreamTask.java:1108)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.handleAsyncException(StreamTask.java:1082)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invokeProcessingTimeCallback(StreamTask.java:1213)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;$17(StreamTask.java:1202)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:47)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:78)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:302)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:184)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:575)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:539)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:722)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:547)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: TimerException{java.lang.RuntimeException: Failed to close remote bundle}
	... 11 more
Caused by: java.lang.RuntimeException: Failed to close remote bundle
	at org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.finishBundle(BeamPythonFunctionRunner.java:371)
	at org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.flush(BeamPythonFunctionRunner.java:325)
	at org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.invokeFinishBundle(AbstractPythonFunctionOperator.java:291)
	at org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.checkInvokeFinishBundleByTime(AbstractPythonFunctionOperator.java:285)
	at org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.lambda$open$0(AbstractPythonFunctionOperator.java:134)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invokeProcessingTimeCallback(StreamTask.java:1211)
	... 10 more
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Error received from SDK harness &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; instruction 3: Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 253, in _execute
    response = task()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 310, in &amp;lt;lambda&amp;gt;
    lambda: self.create_worker().do_instruction(request), request)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 480, in do_instruction
    getattr(request, request_type), request.instruction_id)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 515, in process_bundle
    bundle_processor.process_bundle(instruction_id))
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/bundle_processor.py&quot;&lt;/span&gt;, line 978, in process_bundle
    element.data)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/bundle_processor.py&quot;&lt;/span&gt;, line 218, in process_encoded
    self.output(decoded_value)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 330, in apache_beam.runners.worker.operations.Operation.output
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 332, in apache_beam.runners.worker.operations.Operation.output
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 195, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 292, in apache_beam.runners.worker.operations.Operation.process
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_operations_slow.py&quot;&lt;/span&gt;, line 73, in process
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; value in o.value:
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_coder_impl_slow.py&quot;&lt;/span&gt;, line 625, in decode_from_stream
    yield self._decode_one_batch_from_stream(in_stream, in_stream.read_var_int64())
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_coder_impl_slow.py&quot;&lt;/span&gt;, line 636, in _decode_one_batch_from_stream
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; arrow_to_pandas(self._timezone, self._field_types, [next(self._batch_reader)])
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_coder_impl_slow.py&quot;&lt;/span&gt;, line 629, in _load_from_stream
    reader = pa.ipc.open_stream(stream)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyarrow/ipc.py&quot;&lt;/span&gt;, line 146, in open_stream
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; RecordBatchStreamReader(source)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyarrow/ipc.py&quot;&lt;/span&gt;, line 62, in __init__
    self._open(source)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/ipc.pxi&quot;&lt;/span&gt;, line 360, in pyarrow.lib._RecordBatchStreamReader._open
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/error.pxi&quot;&lt;/span&gt;, line 123, in pyarrow.lib.pyarrow_internal_check_status
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/error.pxi&quot;&lt;/span&gt;, line 100, in pyarrow.lib.check_status
OSError: Expected IPC message of type schema but got record batch

	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895)
	at org.apache.beam.sdk.util.MoreFutures.get(MoreFutures.java:57)
	at org.apache.beam.runners.fnexecution.control.SdkHarnessClient$BundleProcessor$ActiveBundle.close(SdkHarnessClient.java:458)
	at org.apache.beam.runners.fnexecution.control.DefaultJobBundleFactory$SimpleStageBundleFactory$1.close(DefaultJobBundleFactory.java:547)
	at org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner.finishBundle(BeamPythonFunctionRunner.java:369)
	... 15 more
Caused by: java.lang.RuntimeException: Error received from SDK harness &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; instruction 3: Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 253, in _execute
    response = task()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 310, in &amp;lt;lambda&amp;gt;
    lambda: self.create_worker().do_instruction(request), request)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 480, in do_instruction
    getattr(request, request_type), request.instruction_id)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/sdk_worker.py&quot;&lt;/span&gt;, line 515, in process_bundle
    bundle_processor.process_bundle(instruction_id))
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/bundle_processor.py&quot;&lt;/span&gt;, line 978, in process_bundle
    element.data)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/apache_beam/runners/worker/bundle_processor.py&quot;&lt;/span&gt;, line 218, in process_encoded
    self.output(decoded_value)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 330, in apache_beam.runners.worker.operations.Operation.output
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 332, in apache_beam.runners.worker.operations.Operation.output
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 195, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;apache_beam/runners/worker/operations.py&quot;&lt;/span&gt;, line 292, in apache_beam.runners.worker.operations.Operation.process
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_operations_slow.py&quot;&lt;/span&gt;, line 73, in process
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; value in o.value:
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_coder_impl_slow.py&quot;&lt;/span&gt;, line 625, in decode_from_stream
    yield self._decode_one_batch_from_stream(in_stream, in_stream.read_var_int64())
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_coder_impl_slow.py&quot;&lt;/span&gt;, line 636, in _decode_one_batch_from_stream
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; arrow_to_pandas(self._timezone, self._field_types, [next(self._batch_reader)])
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyflink/fn_execution/beam/beam_coder_impl_slow.py&quot;&lt;/span&gt;, line 629, in _load_from_stream
    reader = pa.ipc.open_stream(stream)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyarrow/ipc.py&quot;&lt;/span&gt;, line 146, in open_stream
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; RecordBatchStreamReader(source)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/lyf/Library/Python/3.7/lib/python/site-packages/pyarrow/ipc.py&quot;&lt;/span&gt;, line 62, in __init__
    self._open(source)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/ipc.pxi&quot;&lt;/span&gt;, line 360, in pyarrow.lib._RecordBatchStreamReader._open
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/error.pxi&quot;&lt;/span&gt;, line 123, in pyarrow.lib.pyarrow_internal_check_status
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/error.pxi&quot;&lt;/span&gt;, line 100, in pyarrow.lib.check_status
OSError: Expected IPC message of type schema but got record batch

	at org.apache.beam.runners.fnexecution.control.FnApiControlClient$ResponseStreamObserver.onNext(FnApiControlClient.java:177)
	at org.apache.beam.runners.fnexecution.control.FnApiControlClient$ResponseStreamObserver.onNext(FnApiControlClient.java:157)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Contexts$ContextualizedServerCallListener.onMessage(Contexts.java:76)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.beam.vendor.grpc.v1p26p0.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And my test code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; pyflink.datastream &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; StreamExecutionEnvironment
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; pyflink.table &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; *
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; pyflink.table.udf &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; udaf, AggregateFunction
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; pyflink.table.window &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; Tumble


&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;MyTestAggregateFunction(AggregateFunction):

    &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; get_value(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;, accumulator):
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; accumulator[0]

    &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; create_accumulator(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;):
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Row(0)

    &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; accumulate(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;, accumulator, *args):
        accumulator[0] = &lt;span class=&quot;code-object&quot;&gt;len&lt;/span&gt;(args[0])

    &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; get_result_type(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;):
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; DataTypes.BIGINT()


&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;__name__&lt;/span&gt; == &lt;span class=&quot;code-quote&quot;&gt;&apos;__main__&apos;&lt;/span&gt;:
    env = StreamExecutionEnvironment.get_execution_environment()
    f_s_settings = EnvironmentSettings.new_instance().use_blink_planner().in_streaming_mode().build()
    t_env = StreamTableEnvironment.create(env, &lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;None&lt;/span&gt;&lt;/span&gt;, f_s_settings)

    my_udaf = udaf(MyTestAggregateFunction(), func_type=&lt;span class=&quot;code-quote&quot;&gt;&quot;pandas&quot;&lt;/span&gt;)
    t_env.register_function(&lt;span class=&quot;code-quote&quot;&gt;&apos;my_udaf&apos;&lt;/span&gt;, my_udaf)
    t_env.sql_update(&quot;&quot;&quot;
    CREATE TABLE `source_table` (
        `header` STRING,
        ts AS PROCTIME()
    ) WITH (
          &lt;span class=&quot;code-quote&quot;&gt;&apos;connector&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;datagen&apos;&lt;/span&gt;,
          &lt;span class=&quot;code-quote&quot;&gt;&apos;rows-per-second&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;100&apos;&lt;/span&gt;
    )
    &quot;&quot;&quot;)
    t_env.sql_update(&quot;&quot;&quot;
    CREATE TABLE `sink_table` (
        `content` BIGINT,
        `wstart` TIMESTAMP(3)
    ) WITH (
        &lt;span class=&quot;code-quote&quot;&gt;&apos;connector&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-object&quot;&gt;print&lt;/span&gt;&apos;&lt;/span&gt;
    )
    &quot;&quot;&quot;)
    t_env.scan(&lt;span class=&quot;code-quote&quot;&gt;&quot;source_table&quot;&lt;/span&gt;) \
        .window(Tumble.over(&lt;span class=&quot;code-quote&quot;&gt;&quot;100.second&quot;&lt;/span&gt;).on(&lt;span class=&quot;code-quote&quot;&gt;&quot;ts&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;w&quot;&lt;/span&gt;)) \
        .group_by(&lt;span class=&quot;code-quote&quot;&gt;&apos;w&apos;&lt;/span&gt;) \
        .select(&lt;span class=&quot;code-quote&quot;&gt;&quot;my_udaf(header), w.start&quot;&lt;/span&gt;)\
        .insert_into(&lt;span class=&quot;code-quote&quot;&gt;&quot;sink_table&quot;&lt;/span&gt;)
    t_env.execute(&lt;span class=&quot;code-quote&quot;&gt;&quot;test_job&quot;&lt;/span&gt;)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment></environment>
        <key id="13355494">FLINK-21208</key>
            <summary>pyarrow exception when using window with pandas udaf</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hxbks2ks">Huang Xingbo</assignee>
                                    <reporter username="liuyufei">YufeiLiu</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 29 Jan 2021 17:48:40 +0000</created>
                <updated>Fri, 28 May 2021 08:58:14 +0000</updated>
                            <resolved>Mon, 8 Feb 2021 01:58:15 +0000</resolved>
                                    <version>1.11.0</version>
                    <version>1.12.0</version>
                    <version>1.12.1</version>
                                    <fixVersion>1.11.4</fixVersion>
                    <fixVersion>1.12.2</fixVersion>
                    <fixVersion>1.13.0</fixVersion>
                                    <component>API / Python</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17275661" author="liuyufei" created="Sat, 30 Jan 2021 15:58:41 +0000"  >&lt;p&gt;I&apos;ve made some discoveries, I found beam has a config &lt;tt&gt;DEFAULT_BUNDLE_PROCESSOR_CACHE_SHUTDOWN_THRESHOLD_S&lt;/tt&gt;=60s in &lt;tt&gt;sdk_worker.py&lt;/tt&gt;, periodicity shutdown inactive processor, and initialize a new processor need read schema data from the begining of the stream. The stream was generated by &lt;tt&gt;ArrowSerializer&lt;/tt&gt; in flink operator and only serialize schema data once, afterwards will only write records data.&lt;/p&gt;

&lt;p&gt;So, if processor was evict from cache, beam will try to initialize a new processor with the input stream(only records), and thow expected schema but was record batch.&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dian.fu&quot; class=&quot;user-hover&quot; rel=&quot;dian.fu&quot;&gt;dian.fu&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17276812" author="hxbks2ks" created="Tue, 2 Feb 2021 02:52:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liuyufei&quot; class=&quot;user-hover&quot; rel=&quot;liuyufei&quot;&gt;liuyufei&lt;/a&gt;&#160;Thanks a lot for reporting this issue. As you said, it is indeed because of `DEFAULT_BUNDLE_PROCESSOR_CACHE_SHUTDOWN_THRESHOLD_S` that the reused bundle processor was evicted. We need to reinitialize `ArrowSerializer` every time after finishing the bundle on the java side to let it write the schema information, and the coder on the python side should also be adapted accordingly to avoid the impact of the underlying beam cache. I will fix it as soon as possible.&lt;/p&gt;</comment>
                            <comment id="17277082" author="liuyufei" created="Tue, 2 Feb 2021 12:27:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hxbks2ks&quot; class=&quot;user-hover&quot; rel=&quot;hxbks2ks&quot;&gt;hxbks2ks&lt;/a&gt; I still have a question, I haven&apos;t use arrow before and don&apos;t know the implementation details. But if we already know schema of data, why should we transfer schema of every bundle?&lt;/p&gt;</comment>
                            <comment id="17279400" author="hxbks2ks" created="Fri, 5 Feb 2021 06:55:35 +0000"  >&lt;p&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liuyufei&quot; class=&quot;user-hover&quot; rel=&quot;liuyufei&quot;&gt;liuyufei&lt;/a&gt; The serialization protocol provided by arrow is to serialize the schema info into the header before transmitting data. This is actually a stateful serializer. But for beam, it requires your serializer to be stateless. Both of them are not wrong and have their own considerations, but when used in combination, there will be problems, unless you transmit a schema for each arrow batch.&lt;/p&gt;</comment>
                            <comment id="17280714" author="hxbks2ks" created="Mon, 8 Feb 2021 01:58:15 +0000"  >&lt;p&gt;Merged to master via 78f4b1f361333765dcf9b5cc41cccea77da9024c&lt;br/&gt;
Merged to release-1.12 via e7abfa037555095f061d4d7f3e06dc238e837df2&lt;br/&gt;
Merged to release-1.11 via 6f7fbb3702af65c4a63f532a1e8b1e25f6a479d4&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 40 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0n54g:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>