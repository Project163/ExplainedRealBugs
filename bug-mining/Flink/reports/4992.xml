<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:52:02 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10868] Flink&apos;s JobCluster ResourceManager doesn&apos;t use maximum-failed-containers as limit of resource acquirement</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10868</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Currently, YarnResourceManager does use&#160;yarn.maximum-failed-containers as limit of resource acquirement. In worse case, when new start containers consistently&#160;fail,&#160;YarnResourceManager will goes into an infinite resource acquirement process without failing the job. Together with the &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10848&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-10848&lt;/a&gt;,&#160;It will quick occupy all resources of yarn queue.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13198103">FLINK-10868</key>
            <summary>Flink&apos;s JobCluster ResourceManager doesn&apos;t use maximum-failed-containers as limit of resource acquirement</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hpeter">Zhenqiu Huang</assignee>
                                    <reporter username="ZhenqiuHuang">Zhenqiu Huang</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Tue, 13 Nov 2018 17:15:07 +0000</created>
                <updated>Sat, 19 Nov 2022 09:48:05 +0000</updated>
                            <resolved>Wed, 13 Jan 2021 01:09:19 +0000</resolved>
                                    <version>1.6.2</version>
                    <version>1.7.0</version>
                                    <fixVersion>1.13.0</fixVersion>
                                    <component>Deployment / Mesos</component>
                    <component>Deployment / YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1800">0.5h</timespent>
                                <comments>
                            <comment id="16692708" author="zhenqiuhuang" created="Tue, 20 Nov 2018 05:52:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am working on a fix in FlinkYarnResourceManager. In PerJob cluster mode, as mini dispatch will kill itself once the only job stops, it should be easy to stop the cluster by kill the only JobMaster registered in RM with&#160;JobMasterGateway. But in session mode, I can only stop each of registered JobMaster when failed containers larger than the threshold set in configuration. Do you have any suggestion to stop session cluster gracefully?&lt;/p&gt;</comment>
                            <comment id="16692892" author="till.rohrmann" created="Tue, 20 Nov 2018 09:12:24 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hpeter&quot; class=&quot;user-hover&quot; rel=&quot;hpeter&quot;&gt;hpeter&lt;/a&gt;, I think this is not super trivially to achieve because to detect this situation properly, the RM needs a communication channel to the &lt;tt&gt;Dispatcher&lt;/tt&gt; to tell him about the depleted resource requests. Moreover, we would need to fail all currently running jobs and wait for them to reach a global terminal state before we can shut down the cluster.&lt;/p&gt;

&lt;p&gt;At the moment, Flink assumes that the RM can acquire at some point the requested resources and that it should retry in case of a TM failure. In which scenario would you like to stop retrying if there is a chance to regain the resources and finish your job?&lt;/p&gt;</comment>
                            <comment id="16693833" author="suez1224" created="Tue, 20 Nov 2018 22:02:40 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt;, the following describes the the problem that we saw:&lt;br/&gt;
1) In YarnResourceManager, after container is allocated, it will start the container in onContainerAllocated().&lt;br/&gt;
2) In createTaskExecutorLaunchContext, it will try to call fs.getFileStatus in registerLocalResource which access the file status on HDFS.&lt;br/&gt;
3) In rare scenario when some of above files in HDFS was not accessible due to HDFS issues.  createTaskExecutorLaunchContext will throw an exception and cause YarnResourceManager to keep reacquiring resource due to container start failure because that the files are no longer accessible.&lt;/p&gt;

&lt;p&gt;In the above case, the job will be in a loop of acquiring new resources, since the files is already broken/missing, there is no way to recover by flink itself and we need to fail the job and fall back to the client side to fix the files and resubmit entirely.  &lt;/p&gt;

&lt;p&gt;Together with &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10848&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;FLINK-10848&lt;/a&gt;, it even exaggerate the problem and cause the entire YARN queue resource to get depleted. I&apos;ve submitted a PR to fix &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10848&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;FLINK-10848&lt;/a&gt;, could you please also help take a look?&lt;/p&gt;

&lt;p&gt;I am wondering if we could separate this JIRA into 2 part, one for PerJobCluster, one for session cluster. For this jira, we could&lt;br/&gt;
1) apply yarn.maximum-failed-containers for PerJobCluster mode&lt;br/&gt;
2) log a warning saying that yarn.maximum-failed-containers is not supported for session cluster.&lt;br/&gt;
3) update the documentation on yarn.maximum-failed-containers on website&lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                            <comment id="16697677" author="zhenqiuhuang" created="Sat, 24 Nov 2018 07:14:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=suez1224&quot; class=&quot;user-hover&quot; rel=&quot;suez1224&quot;&gt;suez1224&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Agree with Shuyi&apos;s proposal. As maximum-failed-containers is more a configuration for a job level rather than session cluster level. We may have a simple fix for Per Job cluster first to achieve feature parity with former release.&#160;&lt;/p&gt;

&lt;p&gt;1) I will add a boolean parameter to createResourceManager function to distinguish whether it runs for a per job cluster or session cluster. And also pass&#160;&#160;LeaderGatewayRetriever&amp;lt;DispatcherGateway&amp;gt; dispatcherGatewayRetriever as one of parameters&#160;createResourceManager function in ResourceManagerFactory.&lt;/p&gt;

&lt;p&gt;2) If it is per job cluster, One the&#160;threshold is hit, shutdownCluster by using&#160;DispatcherGateway.&#160;&lt;/p&gt;

&lt;p&gt;How do you think?&lt;/p&gt;</comment>
                            <comment id="16706928" author="till.rohrmann" created="Mon, 3 Dec 2018 10:09:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10848&quot; title=&quot;Flink&amp;#39;s Yarn ResourceManager can allocate too many excess containers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10848&quot;&gt;&lt;del&gt;FLINK-10848&lt;/del&gt;&lt;/a&gt; is definitely a problem which we should fix.&lt;/p&gt;

&lt;p&gt;For the other part I&apos;m a bit hesitant to introduce a new communication channel between the &lt;tt&gt;Dispatcher&lt;/tt&gt; and the &lt;tt&gt;ResourceManager&lt;/tt&gt; tbh. Instead a different way could be to let the &lt;tt&gt;RestartStrategy&lt;/tt&gt; handle the situation. For example, if the &lt;tt&gt;ResourceManager&lt;/tt&gt; notices that it cannot start new &lt;tt&gt;TaskExecutors&lt;/tt&gt;, it could fail all pending allocation requests with a special exception. This exception will be sent to all &lt;tt&gt;JobMasters&lt;/tt&gt; which have pending requests. They can then decide on their own whether they want to restart or fail the job permanently.&lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                            <comment id="16727294" author="zhenqiuhuang" created="Sat, 22 Dec 2018 08:52:03 +0000"  >&lt;p&gt;I like this idea. It is pretty clean. After failSlot in each JobMaster, the execution scheduling will fail on&#160;&lt;/p&gt;

&lt;p&gt;NoResourceAvailableException. Then, all of the logic will be handled by restart strategy. I will create a PR in coming days.&#160;&lt;/p&gt;</comment>
                            <comment id="16728594" author="zhenqiuhuang" created="Tue, 25 Dec 2018 05:27:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gjy&quot; class=&quot;user-hover&quot; rel=&quot;gjy&quot;&gt;gjy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Would you please have a look my PR after holiday?&#160; BTW, Merry Christmas!&lt;/p&gt;</comment>
                            <comment id="16742763" author="zhenqiuhuang" created="Tue, 15 Jan 2019 05:46:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When I test the PR in production, i found we not only need to reject all pending request, but also to reject any new slot request from slot pools. The only issue is when a user use a default fixed delay restart strategy, which is retry forever, resource manager will keep on rejecting new slot request. Do you think it is an expected behavior?&lt;/p&gt;</comment>
                            <comment id="16759111" author="zhenqiuhuang" created="Sat, 2 Feb 2019 17:15:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks for reviewing the PR. According to your suggestions. I changed as&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;As the feature is generic for both Yarn and Mesos, add only the maximum failure rate config option in resource manager config.&lt;/li&gt;
	&lt;li&gt;Put failure rate related logic into the TimestampBasedFailureRater which implements the FailureRater interface. As I don&apos;t want to mix two changes with different purpose in the same PR, we can make other code FailureRateRestartStrategy use it in another small PR.&lt;/li&gt;
	&lt;li&gt;For the failure rate test for RM, I tried to do in ResourceManagerTest. I found it is hard to mimic the behavior of registerSlotRequest without mocking lots components. And I also have to setup Test RM exactly like what YarnResourceManagerTest is doing. Thus, I still put the test cases separately in YarnResourceManagerTest and MesosResourceManagerTest.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="16770134" author="zhenqiuhuang" created="Sat, 16 Feb 2019 16:21:59 +0000"  >&lt;p&gt;@tillrohrmann &lt;br/&gt;
I tested the PR end to end in production. It works perfectly to handle hdfs unaccessible caused tm start failure. Please see the job log: &lt;a href=&quot;https://www.dropbox.com/s/o169th1tudgw2q2/jobmanager.log?dl=0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.dropbox.com/s/o169th1tudgw2q2/jobmanager.log?dl=0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I also merged with latest master. Please review it one more time. Thanks.&lt;/p&gt;</comment>
                            <comment id="16920778" author="anyang1024" created="Mon, 2 Sep 2019 11:01:03 +0000"  >&lt;p&gt;Hi Peter&amp;amp;Till:&lt;/p&gt;


&lt;p&gt;We have introduced the &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10868&quot; title=&quot;Flink&amp;#39;s JobCluster ResourceManager doesn&amp;#39;t use maximum-failed-containers as limit of resource acquirement&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10868&quot;&gt;&lt;del&gt;FLINK-10868&lt;/del&gt;&lt;/a&gt; patch (mainly batch tasks) online, we found that JM occasionally lost contact during use, and the use of &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-13184&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;multi-threaded start Container&lt;/a&gt;&#160; is mitigated.&lt;/p&gt;


&lt;p&gt;There are therefore two suggestions: &lt;br/&gt;
1. Parameter control time interval. At present, the default time interval of 1 min is used, which is too short for batch tasks; &lt;br/&gt;
2. Parameter Control When the failed Container number reaches MAXIMUM_WORKERS_FAILURE_RATE and JM disconnects whether to perform OnFatalError so that the batch tasks can exit as soon as possible.&lt;/p&gt;</comment>
                            <comment id="16923557" author="zhenqiuhuang" created="Thu, 5 Sep 2019 15:51:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Anyang1024&quot; class=&quot;user-hover&quot; rel=&quot;Anyang1024&quot;&gt;Anyang1024&lt;/a&gt; I think the request is reasonable from my perspective. How do you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=till.rohrmann&quot; class=&quot;user-hover&quot; rel=&quot;till.rohrmann&quot;&gt;till.rohrmann&lt;/a&gt;?&lt;/p&gt;
</comment>
                            <comment id="17245067" author="xintongsong" created="Mon, 7 Dec 2020 08:54:33 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hpeter&quot; class=&quot;user-hover&quot; rel=&quot;hpeter&quot;&gt;hpeter&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I&apos;ve gone through the previous discussions and the PR. Here&apos;s how I understand the problem and the proposed changes. Please correct me if I&apos;m wrong.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Problem
	&lt;ul&gt;
		&lt;li&gt;Flink may encounter failures trying to start new task managers. For some of these failures, an immediate retry may not help. E.g., files on HDFS are temporally/permanently unavailable.&lt;/li&gt;
		&lt;li&gt;In such cases, Flink will keep allocating new containers from Yarn and release them due to failures in starting them.
		&lt;ul&gt;
			&lt;li&gt;The retrying should no longer be infinite. It should stop when the slot requests are timed out, because Flink now always checks the pending requests before re-requesting resources.&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Solution
	&lt;ul&gt;
		&lt;li&gt;The proposed approach leverages a `FailureRater` that counts starting task manager failures within a certain time to decide whether the immediate retry is desired.&lt;/li&gt;
		&lt;li&gt;If a high container failure rate is detected recently, Flink stops allocating new containers by canceling all pending slot requests and stop accepting new requests for a while.&lt;/li&gt;
		&lt;li&gt;It leaves the decision whether and when to re-request resources to the job masters.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;FYI, we have encountered and solved a similar problem with Kubernetes API server being temporarily available. The two steps on Yarn, allocating and starting a container, are combined into one step on Kubernetes, adding a new pod. If the Kubernetes API server is&#160;temporarily unavailable (e.g., due to too much load), Flink&apos;s could retry immediately over and over again. This not only keeps the JM cpu busy, but also adds more load to the Kubernetes API server.&lt;/p&gt;

&lt;p&gt;We solved the problem with a different approach. Whenever an adding pod failure happened, Flink stops adding new pods for a &quot;cool down time&quot;, during which attempts to add new pods are cached and re-triggered after the cool down. In general, instead of canceling pending requests and rejecting new requests, it simply takes a break before retrying. See `KubernetesResourceManagerDriver#podCreationCoolDown` for details.&lt;/p&gt;

&lt;p&gt;We have kept the solution within `KubernetesResourceManagerDriver` because we thought it is specific to the native Kubernetes deployment. If Yarn/Mesos have similar problems, it makes sense to move the approach to the common `AbstractResourceManagerDriver` or `ActiveResourceManager`.&lt;/p&gt;

&lt;p&gt;I have a feeling that these two approaches can be&#160;complementary.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The idea of `FailureRater` is more advanced compared to reacting to every single failure. Allowing occasional failures are significant, especially on Yarn where Flink talks to many Yarn NMs and the problem might only exist for some of them.&lt;/li&gt;
	&lt;li&gt;I&apos;m not sure canceling slot requests and rejecting new requests are necessary. Wouldn&apos;t it be good enough to stop re-allocating resources for a while.
	&lt;ul&gt;
		&lt;li&gt;It reduces the workload on the external systems (Kubernetes/Yarn/Mesos).&lt;/li&gt;
		&lt;li&gt;It&apos;s less interrupting, without adding more complexity on the JobMasters.&lt;/li&gt;
		&lt;li&gt;JobMasters are still able to decide whether they still want the resources on slot request timeouts.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;WDYT?&lt;/p&gt;</comment>
                            <comment id="17251539" author="zhenqiuhuang" created="Fri, 18 Dec 2020 06:34:18 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I just found you commented on the jira ticket. Your summary of the problem and solution is accurate. Without the failure rate limit, the worst case we saw is that when a bad job that has the issue of download its job jar from hdfs, the Flink resource manager will consistently ask for more containers from yarn and then block the whole queue. In the outage, it blocks another critical pipeline to upgrade job and submit the same queue. Thus, in the current implementation, I choose the cancel all of the pending requests and killed the job. &lt;/p&gt;

&lt;p&gt;I agree that it could be a generic solution for both yarn and Kubernetes. Besides leveraging FailureRater for cool time management, I would suggest also add count metrics for the container failure. So that oncall engieer can handle the worst situation in time. How do you think? If we are on the same page, I would like the change PR accordingly. Thanks.&lt;/p&gt;






</comment>
                            <comment id="17251576" author="xintongsong" created="Fri, 18 Dec 2020 07:56:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ZhenqiuHuang&quot; class=&quot;user-hover&quot; rel=&quot;ZhenqiuHuang&quot;&gt;ZhenqiuHuang&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I think adding counting metrics for container failures is a good idea.&lt;/p&gt;

&lt;p&gt;Another question is how do we define a &lt;b&gt;container failure&lt;/b&gt;?&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In your PR, a container failure is recorded in &lt;tt&gt;ActiveResourceManager#requestNewWorker&lt;/tt&gt; when the &lt;tt&gt;requestResourceFuture&lt;/tt&gt; completes exceptionally.&lt;/li&gt;
	&lt;li&gt;There could be cases that the task manager process is launched and failed immediately during initialization. In such cases, the &lt;tt&gt;requestResourceFuture&lt;/tt&gt; will complete successfully, but the &lt;tt&gt;onWorkerTerminated&lt;/tt&gt; callback will be called before the worker is registered.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I would suggest to record the failure for all containers that are being requested but failed/terminated before registering to RM. WDYT?&lt;/p&gt;

&lt;p&gt;Apart from this question, I think we are on the same page.&lt;/p&gt;</comment>
                            <comment id="17252334" author="zhenqiuhuang" created="Sun, 20 Dec 2020 05:46:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&quot;record the failure for all containers that are being requested but failed/terminated before registering to RM&quot; is the right way. We are on the same page.&lt;/p&gt;</comment>
                            <comment id="17252354" author="zhenqiuhuang" created="Sun, 20 Dec 2020 08:13:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&lt;br/&gt;
I updated the PR accordingly. As the jira ticket is initially created for Yarn, I feel it will be better to create separate PR to replace Kubernetes&apos;s existing solution to the rate limiter. WDYT?&lt;/p&gt;</comment>
                            <comment id="17252628" author="zhenqiuhuang" created="Mon, 21 Dec 2020 06:03:31 +0000"  >&lt;p&gt;After looking into the Kubernetes driver implementation, I think it could be handled in the same PR. Basically, podCreationCoolDown is moved into the ActiveResourceManager. When the maximum failure rate hits,  rm will wait for an interval before issue a new request. Please review it when you have time.&lt;/p&gt;</comment>
                            <comment id="17252640" author="xintongsong" created="Mon, 21 Dec 2020 06:41:03 +0000"  >&lt;p&gt;Thanks for the updates. I&apos;ll try to take a look asap.&lt;/p&gt;</comment>
                            <comment id="17258635" author="zhenqiuhuang" created="Tue, 5 Jan 2021 02:57:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&lt;br/&gt;
Happy new year. I just rebased master and pushed again. Please review it at your most convenient time.&lt;/p&gt;</comment>
                            <comment id="17258652" author="xintongsong" created="Tue, 5 Jan 2021 04:52:31 +0000"  >&lt;p&gt;Thanks for the updates, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hpeter&quot; class=&quot;user-hover&quot; rel=&quot;hpeter&quot;&gt;hpeter&lt;/a&gt;.&lt;br/&gt;
Just to manage expectation, I probably won&apos;t have capacity this week. I&apos;ll try to take a look early next week.&lt;/p&gt;</comment>
                            <comment id="17261775" author="zhenqiuhuang" created="Sat, 9 Jan 2021 06:08:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&lt;br/&gt;
Thanks for the reply. No hurry. I am also busy with internal works. Let me know if you have any tasks I can help with.&lt;/p&gt;</comment>
                            <comment id="17263811" author="xintongsong" created="Wed, 13 Jan 2021 01:09:19 +0000"  >&lt;p&gt;Fixed via&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;master (1.13): 427b7cbd44c5f293a6bbe0098f8e9b65b17f1ab7&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310361">
                    <name>Blocked</name>
                                                                <inwardlinks description="Blocked">
                                        <issuelink>
            <issuekey id="13503737">FLINK-30095</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310660">
                    <name>Completes</name>
                                            <outwardlinks description="fixes">
                                        <issuelink>
            <issuekey id="13298181">FLINK-17127</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13354550">FLINK-21139</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 43 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s00fyo:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>