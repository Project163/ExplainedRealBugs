<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:27:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-5849] Kafka Consumer checkpointed state may contain undefined offsets</title>
                <link>https://issues.apache.org/jira/browse/FLINK-5849</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;This is a regression due to &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4280&quot; title=&quot;New Flink-specific option to set starting position of Kafka consumer without respecting external offsets in ZK / Broker&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4280&quot;&gt;&lt;del&gt;FLINK-4280&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4280&quot; title=&quot;New Flink-specific option to set starting position of Kafka consumer without respecting external offsets in ZK / Broker&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4280&quot;&gt;&lt;del&gt;FLINK-4280&lt;/del&gt;&lt;/a&gt;, all initial offset determination was refactored to be consolidated at the start of &lt;tt&gt;AbstractFetcher#runFetchLoop&lt;/tt&gt;. However, this caused checkpoints that were triggered before the method was ever reached to contain undefined partition offsets.&lt;/p&gt;

&lt;p&gt;Ref:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job execution failed.
    at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:427)
    at org.apache.flink.client.program.StandaloneClusterClient.submitJob(StandaloneClusterClient.java:101)
    at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:400)
    at org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:392)
    at org.apache.flink.streaming.api.environment.RemoteStreamEnvironment.executeRemotely(RemoteStreamEnvironment.java:209)
    at org.apache.flink.streaming.api.environment.RemoteStreamEnvironment.execute(RemoteStreamEnvironment.java:173)
    at org.apache.flink.test.util.TestUtils.tryExecute(TestUtils.java:32)
    at org.apache.flink.streaming.connectors.kafka.KafkaConsumerTestBase.runMultipleSourcesOnePartitionExactlyOnceTest(KafkaConsumerTestBase.java:942)
    at org.apache.flink.streaming.connectors.kafka.Kafka09ITCase.testMultipleSourcesOnePartition(Kafka09ITCase.java:76)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.
    at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply$mcV$sp(JobManager.scala:915)
    at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:858)
    at org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:858)
    at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
    at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
    at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
    at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.IllegalArgumentException: Restoring from a checkpoint / savepoint, but found a partition state Partition: KafkaTopicPartition{topic=&lt;span class=&quot;code-quote&quot;&gt;&apos;manyToOneTopic&apos;&lt;/span&gt;, partition=2}, KafkaPartitionHandle=manyToOneTopic-2, offset=(not set) that does not have a defined offset.
    at org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread.&amp;lt;init&amp;gt;(KafkaConsumerThread.java:133)
    at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.&amp;lt;init&amp;gt;(Kafka09Fetcher.java:113)
    at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09.createFetcher(FlinkKafkaConsumer09.java:182)
    at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:275)
    at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
    at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
    at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
    at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:265)
    at org.apache.flink.runtime.taskmanager.Task.run(Task.java:668)
    at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13044503">FLINK-5849</key>
            <summary>Kafka Consumer checkpointed state may contain undefined offsets</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tzulitai">Tzu-Li (Gordon) Tai</assignee>
                                    <reporter username="tzulitai">Tzu-Li (Gordon) Tai</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Feb 2017 09:57:41 +0000</created>
                <updated>Mon, 27 Feb 2017 17:51:40 +0000</updated>
                            <resolved>Mon, 27 Feb 2017 17:51:40 +0000</resolved>
                                                    <fixVersion>1.3.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15874714" author="tzulitai" created="Mon, 20 Feb 2017 15:42:12 +0000"  >&lt;p&gt;Some background context on the problem:&lt;br/&gt;
In &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4280&quot; title=&quot;New Flink-specific option to set starting position of Kafka consumer without respecting external offsets in ZK / Broker&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4280&quot;&gt;&lt;del&gt;FLINK-4280&lt;/del&gt;&lt;/a&gt;, the logic that fetcher&apos;s run at the start of &lt;tt&gt;runFetchLoop()&lt;/tt&gt; was changed to:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isRestored) {
    &lt;span class=&quot;code-comment&quot;&gt;// just use the offsets in the restored state as starting position
&lt;/span&gt;} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;code-comment&quot;&gt;// find out the starting offsets based on StartupMode (either EARLIEST, LATEST, or GROUP_OFFSETS),
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// and set the partition states with the discovered start offsets so that the state has defined offsets
&lt;/span&gt;}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, the change also assumed that on restore, the state should not have undefined offsets. As pointed out in the description of this JIRA, this is not true if a checkpoint was taken before &lt;tt&gt;runFetchLoop()&lt;/tt&gt; was reached.&lt;/p&gt;

&lt;p&gt;The approaches I see in fixing this:&lt;br/&gt;
1. The faster fix - also let the &lt;tt&gt;if (isRestored)&lt;/tt&gt; branch handle states that don&apos;t have defined offsets.&lt;br/&gt;
2. Rework the life cycle of &lt;tt&gt;AbstractFetcher&lt;/tt&gt;. We should instantiate &lt;tt&gt;AbstractFetcher&lt;/tt&gt; in the &lt;tt&gt;open()&lt;/tt&gt; method of the UDF, and let the startup offset determining process happen in the constructor of &lt;tt&gt;AbstractFetcher&lt;/tt&gt;. This assures that there will always be defined offsets when checkpointing happens.&lt;/p&gt;

&lt;p&gt;Option (2) will be more work, but I prefer that over (1) because it seems to be a more proper fix.&lt;br/&gt;
Option (1) will lead to more complicated start position determining logic and also make it less self-contained, since for partition states with undefined offsets, we need to &quot;fallback&quot; to the &lt;tt&gt;StartupMode&lt;/tt&gt; for that partition. This will be a problem for the &lt;tt&gt;LATEST&lt;/tt&gt; startup mode - we would be using the latest record &lt;b&gt;at the time the job was restored with that undefined offset&lt;/b&gt;, and not correctly at the time of the actual first execution of the job.&lt;/p&gt;</comment>
                            <comment id="15876139" author="githubbot" created="Tue, 21 Feb 2017 15:18:08 +0000"  >&lt;p&gt;GitHub user tzulitai opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5849&quot; title=&quot;Kafka Consumer checkpointed state may contain undefined offsets&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5849&quot;&gt;&lt;del&gt;FLINK-5849&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; Move FlinkKafkaConsumer start offset determination to open()&lt;/p&gt;

&lt;p&gt;    This PR fixes a regression due to the recently merged #2509 (&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4280&quot; title=&quot;New Flink-specific option to set starting position of Kafka consumer without respecting external offsets in ZK / Broker&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4280&quot;&gt;&lt;del&gt;FLINK-4280&lt;/del&gt;&lt;/a&gt;).&lt;br/&gt;
    The new start position feature added in #2509 needed to assume that on restore, all offsets are defined. This was not true, if a restored checkpoint was taken before the fetcher was ever initialized or run.&lt;/p&gt;

&lt;p&gt;    This PR fixes this by changing the following:&lt;br/&gt;
    1. Move the start position determination logic to `open()`. This assures that when `snapshotState()` is called, we will always have defined offsets.&lt;br/&gt;
    2. Introduce special &quot;magic offset values&quot; to represent that a partition is to be started from either `EARLIEST`, `LATEST`, or `GROUP_OFFSETS`. These values are set as placeholders in `open()`. The consumer follows a lazy evaluation approach to only replace these magic values with actual offsets when the fetcher actually starts running.&lt;/p&gt;

&lt;p&gt;    Therefore, with this PR, if a checkpoint happens before a fetcher fully starts consuming all of its subscribed partitions, it will at least contain the &quot;magic offset value&quot; in the state, instead of an undefined offset like before.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/tzulitai/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/tzulitai/flink&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5849&quot; title=&quot;Kafka Consumer checkpointed state may contain undefined offsets&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5849&quot;&gt;&lt;del&gt;FLINK-5849&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3378&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 7e7bf1d106d4dc0d24fa6746e94ccdadbc06088e&lt;br/&gt;
Author: Tzu-Li (Gordon) Tai &amp;lt;tzulitai@apache.org&amp;gt;&lt;br/&gt;
Date:   2017-02-21T15:05:32Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5849&quot; title=&quot;Kafka Consumer checkpointed state may contain undefined offsets&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5849&quot;&gt;&lt;del&gt;FLINK-5849&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; Move FlinkKafkaConsumer start offset determination to open()&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15885602" author="githubbot" created="Mon, 27 Feb 2017 11:16:15 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Rebased on `master`.&lt;/p&gt;

&lt;p&gt;    Note about changes to partition assignment logic in deleted lines 538 - 553 and added lines 563 -565 of `FlinkKafkaConsumerBase`:&lt;br/&gt;
    The change is irrelevant to this issue, but something I stumbled across when touching that part of the code. Problems:&lt;/p&gt;

&lt;p&gt;    1. The `KafkaConsumerPartitionAssignmentTest` was testing a no-longer used `assignPartitions` method, so the tests actually never covered the actual behaviour.&lt;/p&gt;

&lt;p&gt;    2. Previously, the partition assignment was changed from using the &quot;modulo on KafkaTopicPartition hashes&quot; approach to &quot;pre-sorting the partition list and round-robin assigning&quot;. This change should actually breaks the tests in `KafkaConsumerPartitionAssignmentTest`, but didn&apos;t because as mentioned above, the tests were testing an unused method. The current approach will also be problematic for dynamically growing subscribed partition lists, because the sorting order will change as the list grows with newly discovered partitions.&lt;/p&gt;</comment>
                            <comment id="15885704" author="githubbot" created="Mon, 27 Feb 2017 12:42:51 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378#discussion_r103196367&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378#discussion_r103196367&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.java &amp;#8212;&lt;br/&gt;
    @@ -330,8 +315,49 @@ public void cancel() {&lt;br/&gt;
     	public void open(Configuration configuration) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I wonder if it makes sense to move the method above the run() method.&lt;br/&gt;
    Then its more logical going through the source code.&lt;/p&gt;</comment>
                            <comment id="15885705" author="githubbot" created="Mon, 27 Feb 2017 12:42:51 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378#discussion_r103197252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378#discussion_r103197252&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -42,13 +43,7 @@&lt;/p&gt;

&lt;p&gt;     import java.io.Serializable;&lt;br/&gt;
     import java.lang.reflect.Field;&lt;br/&gt;
    -import java.util.ArrayList;&lt;br/&gt;
    -import java.util.Arrays;&lt;br/&gt;
    -import java.util.Collections;&lt;br/&gt;
    -import java.util.HashMap;&lt;br/&gt;
    -import java.util.HashSet;&lt;br/&gt;
    -import java.util.List;&lt;br/&gt;
    -import java.util.Set;&lt;br/&gt;
    +import java.util.*;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Star imports are not wanted in Flink &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15885719" author="githubbot" created="Mon, 27 Feb 2017 12:57:11 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378#discussion_r103199655&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378#discussion_r103199655&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -42,13 +43,7 @@&lt;/p&gt;

&lt;p&gt;     import java.io.Serializable;&lt;br/&gt;
     import java.lang.reflect.Field;&lt;br/&gt;
    -import java.util.ArrayList;&lt;br/&gt;
    -import java.util.Arrays;&lt;br/&gt;
    -import java.util.Collections;&lt;br/&gt;
    -import java.util.HashMap;&lt;br/&gt;
    -import java.util.HashSet;&lt;br/&gt;
    -import java.util.List;&lt;br/&gt;
    -import java.util.Set;&lt;br/&gt;
    +import java.util.*;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yikes, second time :/&lt;br/&gt;
    I think there&apos;s a settings to disable star imports in Intellij, will try to use it!&lt;/p&gt;</comment>
                            <comment id="15885720" author="githubbot" created="Mon, 27 Feb 2017 12:57:41 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378#discussion_r103199733&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378#discussion_r103199733&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumerBase.java &amp;#8212;&lt;br/&gt;
    @@ -330,8 +315,49 @@ public void cancel() {&lt;br/&gt;
     	public void open(Configuration configuration) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Makes sense, will change this.&lt;/p&gt;</comment>
                            <comment id="15886122" author="githubbot" created="Mon, 27 Feb 2017 17:01:14 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the review @rmetzger!&lt;br/&gt;
    For the moving of `open()` to before `run()`, I&apos;ve included that as the commit tagged with &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5849&quot; title=&quot;Kafka Consumer checkpointed state may contain undefined offsets&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5849&quot;&gt;&lt;del&gt;FLINK-5849&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
    For the star import fix, I&apos;m going to include that within a follow-up hotfix that cleansup all Flink Kafka connector tests of star &amp;amp; unused imports.&lt;/p&gt;

&lt;p&gt;    Doing one final Travis run locally and merging this to `master` once it turns green.&lt;/p&gt;</comment>
                            <comment id="15886210" author="githubbot" created="Mon, 27 Feb 2017 17:47:39 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Tests pass, merging ..&lt;/p&gt;</comment>
                            <comment id="15886214" author="githubbot" created="Mon, 27 Feb 2017 17:50:32 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3378&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3378&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15886216" author="tzulitai" created="Mon, 27 Feb 2017 17:51:40 +0000"  >&lt;p&gt;Resolved for &lt;tt&gt;master&lt;/tt&gt; via &lt;a href=&quot;http://git-wip-us.apache.org/repos/asf/flink/commit/ed68fed&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://git-wip-us.apache.org/repos/asf/flink/commit/ed68fed&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 38 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3abk7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>