<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:17:34 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-32008] Protobuf format cannot work with FileSystem Connector</title>
                <link>https://issues.apache.org/jira/browse/FLINK-32008</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;The protobuf format throws exception when working with Map data type. I uploaded a example project to reproduce the problem.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.RuntimeException: One or more fetchers have encountered exception
&#160; &#160; at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.checkErrors(SplitFetcherManager.java:261)
&#160; &#160; at org.apache.flink.connector.base.source.reader.SourceReaderBase.getNextFetch(SourceReaderBase.java:169)
&#160; &#160; at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:131)
&#160; &#160; at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:417)
&#160; &#160; at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)
&#160; &#160; at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
&#160; &#160; at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550)
&#160; &#160; at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
&#160; &#160; at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
&#160; &#160; at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
&#160; &#160; at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
&#160; &#160; at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
&#160; &#160; at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
&#160; &#160; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
&#160; &#160; at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: java.lang.RuntimeException: SplitFetcher thread 0 received unexpected exception &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; polling the records
&#160; &#160; at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:165)
&#160; &#160; at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.run(SplitFetcher.java:114)
&#160; &#160; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
&#160; &#160; at java.util.concurrent.FutureTask.run(FutureTask.java:266)
&#160; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
&#160; &#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
&#160; &#160; ... 1 more
Caused by: java.io.IOException: Failed to deserialize PB object.
&#160; &#160; at org.apache.flink.formats.protobuf.deserialize.PbRowDataDeserializationSchema.deserialize(PbRowDataDeserializationSchema.java:75)
&#160; &#160; at org.apache.flink.formats.protobuf.deserialize.PbRowDataDeserializationSchema.deserialize(PbRowDataDeserializationSchema.java:42)
&#160; &#160; at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82)
&#160; &#160; at org.apache.flink.connector.file.table.DeserializationSchemaAdapter$LineBytesInputFormat.readRecord(DeserializationSchemaAdapter.java:197)
&#160; &#160; at org.apache.flink.connector.file.table.DeserializationSchemaAdapter$LineBytesInputFormat.nextRecord(DeserializationSchemaAdapter.java:210)
&#160; &#160; at org.apache.flink.connector.file.table.DeserializationSchemaAdapter$Reader.readBatch(DeserializationSchemaAdapter.java:124)
&#160; &#160; at org.apache.flink.connector.file.src.util.RecordMapperWrapperRecordIterator$1.readBatch(RecordMapperWrapperRecordIterator.java:82)
&#160; &#160; at org.apache.flink.connector.file.src.impl.FileSourceSplitReader.fetch(FileSourceSplitReader.java:67)
&#160; &#160; at org.apache.flink.connector.base.source.reader.fetcher.FetchTask.run(FetchTask.java:58)
&#160; &#160; at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher.runOnce(SplitFetcher.java:162)
&#160; &#160; ... 6 more
Caused by: java.lang.reflect.InvocationTargetException
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
&#160; &#160; at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
&#160; &#160; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
&#160; &#160; at java.lang.reflect.Method.invoke(Method.java:498)
&#160; &#160; at org.apache.flink.formats.protobuf.deserialize.ProtoToRowConverter.convertProtoBinaryToRow(ProtoToRowConverter.java:129)
&#160; &#160; at org.apache.flink.formats.protobuf.deserialize.PbRowDataDeserializationSchema.deserialize(PbRowDataDeserializationSchema.java:70)
&#160; &#160; ... 15 more
Caused by: com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field. &#160;This could mean either that the input has been truncated or that an embedded message misreported its own length.
&#160; &#160; at com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
&#160; &#160; at com.google.protobuf.CodedInputStream$ArrayDecoder.pushLimit(CodedInputStream.java:1196)
&#160; &#160; at com.google.protobuf.CodedInputStream$ArrayDecoder.readMessage(CodedInputStream.java:887)
&#160; &#160; at com.example.proto.MapMessage.&amp;lt;init&amp;gt;(MapMessage.java:64)
&#160; &#160; at com.example.proto.MapMessage.&amp;lt;init&amp;gt;(MapMessage.java:9)
&#160; &#160; at com.example.proto.MapMessage$1.parsePartialFrom(MapMessage.java:756)
&#160; &#160; at com.example.proto.MapMessage$1.parsePartialFrom(MapMessage.java:750)
&#160; &#160; at com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
&#160; &#160; at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
&#160; &#160; at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
&#160; &#160; at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
&#160; &#160; at com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
&#160; &#160; at com.example.proto.MapMessage.parseFrom(MapMessage.java:320)
&#160; &#160; ... 21 more &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13535096">FLINK-32008</key>
            <summary>Protobuf format cannot work with FileSystem Connector</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rskraba">Ryan Skraba</assignee>
                                    <reporter username="sxnan">Xuannan Su</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 5 May 2023 06:22:29 +0000</created>
                <updated>Fri, 18 Oct 2024 19:36:14 +0000</updated>
                            <resolved>Sat, 17 Jun 2023 14:55:45 +0000</resolved>
                                    <version>1.17.0</version>
                                    <fixVersion>1.18.0</fixVersion>
                                    <component>Formats (JSON, Avro, Parquet, ORC, SequenceFile)</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17719700" author="libenchao" created="Fri, 5 May 2023 07:13:48 +0000"  >&lt;p&gt;CC &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maosuhan&quot; class=&quot;user-hover&quot; rel=&quot;maosuhan&quot;&gt;maosuhan&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17725197" author="maosuhan" created="Tue, 23 May 2023 04:29:11 +0000"  >&lt;p&gt;I think the error is related to corrupt data.&lt;br/&gt;
&#160;&lt;/p&gt;</comment>
                            <comment id="17726311" author="ryanskraba" created="Thu, 25 May 2023 16:53:23 +0000"  >&lt;p&gt;Hello, thanks for the example project!  That&apos;s so helpful to reproduce and debug.&lt;/p&gt;

&lt;p&gt;The &lt;b&gt;current&lt;/b&gt; file strategy for protobuf in Flink is to write one record serialized as binary per line, adding a &lt;b&gt;&lt;tt&gt;0x0a&lt;/tt&gt;&lt;/b&gt;.  Your example message is serialized as:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
12 06 0a 01 61 12 01 62 0a
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first &lt;b&gt;&lt;tt&gt;0a&lt;/tt&gt;&lt;/b&gt; is the protobuf encoding for the key field in the map.  The last &lt;b&gt;&lt;tt&gt;0a&lt;/tt&gt;&lt;/b&gt; is a new line (which probably shouldn&apos;t be there).&lt;/p&gt;

&lt;p&gt;When reading, from a file, splits are calculated and assigned to tasks using the &lt;b&gt;&lt;tt&gt;0a&lt;/tt&gt;&lt;/b&gt; as a delimiter, which is very, very likely to fail and a fault in the protobuf file implementation of Flink.&lt;/p&gt;

&lt;p&gt;I&apos;m guessing this isn&apos;t limited to maps, we can expect this delimiter byte to occur many different ways in the protobuf binary.&lt;/p&gt;

&lt;p&gt;If this hasn&apos;t been addressed, it&apos;s probably because it&apos;s pretty rare to store protobuf messages in a file container (as opposed to in a single message packet, or a table cell).  Do you have a good use case that we can use to guide what we expect Flink to do with protobuf files?&lt;/p&gt;

&lt;p&gt;For info, nothing in the Protobuf encoding that can be used to &lt;a href=&quot;https://protobuf.dev/programming-guides/techniques/#streaming&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;distinguish the start or end&lt;/a&gt; of a message.  If we want to store multiple messages in the same container (file or any sequence of bytes), we have to manage the indices ourselves  The above link recommends writing the message size followed by the binary (in Java, this is using &lt;tt&gt;writeDelimitedTo&lt;/tt&gt;/&lt;tt&gt;parseDelimitedFrom&lt;/tt&gt; instead of &lt;tt&gt;writeTo&lt;/tt&gt;/&lt;tt&gt;parseFrom&lt;/tt&gt;, for example).&lt;/p&gt;</comment>
                            <comment id="17726314" author="ryanskraba" created="Thu, 25 May 2023 17:03:44 +0000"  >&lt;p&gt;Oh, just taking a quick look &#8211; protobuf isn&apos;t supported by the filesystem connector in the &lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/filesystem/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Flink&lt;/a&gt; docs.&#160; The real bug here might be that filesystem + protobuf doesn&apos;t fail immediately as an unsupported option!&lt;/p&gt;</comment>
                            <comment id="17726448" author="libenchao" created="Fri, 26 May 2023 02:29:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rskraba&quot; class=&quot;user-hover&quot; rel=&quot;rskraba&quot;&gt;rskraba&lt;/a&gt; Thanks for the digging. I agree that currently FileSystem&apos;s fallback (de)serializer does not fit for all formats, this should be one of them. It might be worth to add support to implement a &lt;tt&gt;BulkReaderFormatFactory&lt;/tt&gt; for protobuf format.&lt;/p&gt;</comment>
                            <comment id="17726567" author="ryanskraba" created="Fri, 26 May 2023 09:56:56 +0000"  >&lt;p&gt;It&apos;s probably worth checking in with the community to see what we expect of a bulk format, or if it would be an interesting thing to add!&#160; &lt;a href=&quot;https://lists.apache.org/thread/z9tqdqrhj12c17wqsdbm5fhzonqq5kp0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;I&apos;ll ask on the mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I took a quick look but didn&apos;t see any related JIRA (outside of &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-12149&quot; title=&quot;Support Proto for Streaming File Sink &quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-12149&quot;&gt;FLINK-12149&lt;/a&gt;, which proposes using the protobuf API to interact with parquet files).&#160; Can a committer change the title of this JIRA to better reflect the issue?&#160; Something like &quot;Protobuf format on filesystem is faulty&quot;&lt;/p&gt;</comment>
                            <comment id="17726583" author="libenchao" created="Fri, 26 May 2023 10:55:40 +0000"  >&lt;p&gt;I&apos;ve changed the title.&lt;/p&gt;</comment>
                            <comment id="17733618" author="ryanskraba" created="Fri, 16 Jun 2023 17:53:50 +0000"  >&lt;p&gt;I&apos;ve created a PR that prevents the protobuf format from being used to write bulk files.  (I used the error message &lt;tt&gt;&quot;The &apos;protobuf&apos; format is not supported for the &apos;filesystem&apos; connector.&quot;&lt;/tt&gt;, but this could be refined.)&lt;/p&gt;

&lt;p&gt;In my experience and with the responses on the mailing list, I don&apos;t think that create a custom BulkReaderFormatFactory/BulkWriterFormatFactory would be used.  At the minimum, we should fail quickly (instead of generating unreadable files silently).&lt;/p&gt;

&lt;p&gt;If there&apos;s a future need to create our own protobuf-oriented file format (for temporary storage?) or if someone makes a protobuf file container in the future, we can probably revisit this strategy!  In the meantime, I&apos;d probably recommend using something like parquet (with the protobuf-message-oriented API) to persist bulk records in a file.  What do you think?&lt;/p&gt;</comment>
                            <comment id="17733777" author="libenchao" created="Sat, 17 Jun 2023 14:47:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rskraba&quot; class=&quot;user-hover&quot; rel=&quot;rskraba&quot;&gt;rskraba&lt;/a&gt; Thanks, I agree with your proposal, I&apos;ll review it.&lt;/p&gt;</comment>
                            <comment id="17733781" author="libenchao" created="Sat, 17 Jun 2023 14:55:45 +0000"  >&lt;p&gt;Fixed via &lt;a href=&quot;https://github.com/apache/flink/commit/7d4ee28e85aad4abc8ad126c4d953d0e921ea07e&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/commit/7d4ee28e85aad4abc8ad126c4d953d0e921ea07e&lt;/a&gt; (master)&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13534107">FLINK-31944</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13057850" name="flink-protobuf-example.zip" size="11159" author="xuannan" created="Fri, 5 May 2023 06:17:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 21 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1hpi8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>