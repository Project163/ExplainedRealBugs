<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:35:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10220] StreamSQL E2E test fails on travis</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10220</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://travis-ci.org/zentol/flink-ci/jobs/420972344&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://travis-ci.org/zentol/flink-ci/jobs/420972344&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[FAIL] &lt;span class=&quot;code-quote&quot;&gt;&apos;Streaming SQL end-to-end test&apos;&lt;/span&gt; failed after 1 minutes and 49 seconds! Test exited with exit code 0 but the logs contained errors, exceptions or non-empty .out files

2018-08-27 07:34:36,311 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - window: (TumblingGroupWindow(&lt;span class=&quot;code-quote&quot;&gt;&apos;w$, &apos;&lt;/span&gt;rowtime, 20000.millis)), select: ($SUM0(correct) AS correct, start(&lt;span class=&quot;code-quote&quot;&gt;&apos;w$) AS w$start, end(&apos;&lt;/span&gt;w$) AS w$end, rowtime(&lt;span class=&quot;code-quote&quot;&gt;&apos;w$) AS w$rowtime, proctime(&apos;&lt;/span&gt;w$) AS w$proctime) -&amp;gt; select: (correct, w$start AS rowtime) -&amp;gt; to: Row -&amp;gt; Map -&amp;gt; Sink: Unnamed (1/1) (97d055e4661ff3361a504626257d406d) switched from RUNNING to FAILED.
java.lang.RuntimeException: Exception occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; processing valve output watermark: 
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor$ForwardingValveOutputHandler.handleWatermark(StreamInputProcessor.java:265)
	at org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve.findAndOutputNewMinWatermarkAcrossAlignedChannels(StatusWatermarkValve.java:189)
	at org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve.inputWatermark(StatusWatermarkValve.java:111)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:184)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:596)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at org.apache.flink.table.runtime.aggregate.TimeWindowPropertyCollector.collect(TimeWindowPropertyCollector.scala:65)
	at org.apache.flink.table.runtime.aggregate.IncrementalAggregateAllWindowFunction.apply(IncrementalAggregateAllWindowFunction.scala:62)
	at org.apache.flink.table.runtime.aggregate.IncrementalAggregateAllTimeWindowFunction.apply(IncrementalAggregateAllTimeWindowFunction.scala:65)
	at org.apache.flink.table.runtime.aggregate.IncrementalAggregateAllTimeWindowFunction.apply(IncrementalAggregateAllTimeWindowFunction.scala:37)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueAllWindowFunction.process(InternalSingleValueAllWindowFunction.java:46)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueAllWindowFunction.process(InternalSingleValueAllWindowFunction.java:34)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:546)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:454)
	at org.apache.flink.streaming.api.operators.InternalTimerServiceImpl.advanceWatermark(InternalTimerServiceImpl.java:251)
	at org.apache.flink.streaming.api.operators.InternalTimeServiceManager.advanceWatermark(InternalTimeServiceManager.java:128)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:746)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor$ForwardingValveOutputHandler.handleWatermark(StreamInputProcessor.java:262)
	... 7 more
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:596)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at org.apache.flink.table.runtime.CRowWrappingCollector.collect(CRowWrappingCollector.scala:37)
	at org.apache.flink.table.runtime.CRowWrappingCollector.collect(CRowWrappingCollector.scala:28)
	at DataStreamCalcRule$100.processElement(Unknown Source)
	at org.apache.flink.table.runtime.CRowProcessRunner.processElement(CRowProcessRunner.scala:66)
	at org.apache.flink.table.runtime.CRowProcessRunner.processElement(CRowProcessRunner.scala:35)
	at org.apache.flink.streaming.api.operators.ProcessOperator.processElement(ProcessOperator.java:66)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	... 24 more
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:596)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	... 36 more
Caused by: java.lang.RuntimeException: Kill &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; Job!
	at org.apache.flink.sql.tests.StreamSQLTestProgram$KillMapper.map(StreamSQLTestProgram.java:286)
	at org.apache.flink.sql.tests.StreamSQLTestProgram$KillMapper.map(StreamSQLTestProgram.java:274)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	... 42 more
2018-08-27 07:34:36,320 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Job Flink Streaming Job (fbe12c5fb19e16f1575ae412acc810a7) switched from state RUNNING to FAILING.
java.lang.RuntimeException: Exception occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; processing valve output watermark: 
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor$ForwardingValveOutputHandler.handleWatermark(StreamInputProcessor.java:265)
	at org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve.findAndOutputNewMinWatermarkAcrossAlignedChannels(StatusWatermarkValve.java:189)
	at org.apache.flink.streaming.runtime.streamstatus.StatusWatermarkValve.inputWatermark(StatusWatermarkValve.java:111)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:184)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:596)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at org.apache.flink.table.runtime.aggregate.TimeWindowPropertyCollector.collect(TimeWindowPropertyCollector.scala:65)
	at org.apache.flink.table.runtime.aggregate.IncrementalAggregateAllWindowFunction.apply(IncrementalAggregateAllWindowFunction.scala:62)
	at org.apache.flink.table.runtime.aggregate.IncrementalAggregateAllTimeWindowFunction.apply(IncrementalAggregateAllTimeWindowFunction.scala:65)
	at org.apache.flink.table.runtime.aggregate.IncrementalAggregateAllTimeWindowFunction.apply(IncrementalAggregateAllTimeWindowFunction.scala:37)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueAllWindowFunction.process(InternalSingleValueAllWindowFunction.java:46)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueAllWindowFunction.process(InternalSingleValueAllWindowFunction.java:34)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:546)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:454)
	at org.apache.flink.streaming.api.operators.InternalTimerServiceImpl.advanceWatermark(InternalTimerServiceImpl.java:251)
	at org.apache.flink.streaming.api.operators.InternalTimeServiceManager.advanceWatermark(InternalTimeServiceManager.java:128)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:746)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor$ForwardingValveOutputHandler.handleWatermark(StreamInputProcessor.java:262)
	... 7 more
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:596)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at org.apache.flink.table.runtime.CRowWrappingCollector.collect(CRowWrappingCollector.scala:37)
	at org.apache.flink.table.runtime.CRowWrappingCollector.collect(CRowWrappingCollector.scala:28)
	at DataStreamCalcRule$100.processElement(Unknown Source)
	at org.apache.flink.table.runtime.CRowProcessRunner.processElement(CRowProcessRunner.scala:66)
	at org.apache.flink.table.runtime.CRowProcessRunner.processElement(CRowProcessRunner.scala:35)
	at org.apache.flink.streaming.api.operators.ProcessOperator.processElement(ProcessOperator.java:66)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	... 24 more
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:596)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:554)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:534)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:689)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:667)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	... 36 more
Caused by: java.lang.RuntimeException: Kill &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; Job!
	at org.apache.flink.sql.tests.StreamSQLTestProgram$KillMapper.map(StreamSQLTestProgram.java:286)
	at org.apache.flink.sql.tests.StreamSQLTestProgram$KillMapper.map(StreamSQLTestProgram.java:274)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:579)
	... 42 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13181255">FLINK-10220</key>
            <summary>StreamSQL E2E test fails on travis</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hequn8128">Hequn Cheng</assignee>
                                    <reporter username="chesnay">Chesnay Schepler</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 27 Aug 2018 08:06:07 +0000</created>
                <updated>Wed, 24 Oct 2018 16:05:44 +0000</updated>
                            <resolved>Wed, 24 Oct 2018 16:05:44 +0000</resolved>
                                    <version>1.7.0</version>
                                    <fixVersion>1.7.0</fixVersion>
                                    <component>Table SQL / API</component>
                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16608814" author="till.rohrmann" created="Mon, 10 Sep 2018 07:14:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=twalthr&quot; class=&quot;user-hover&quot; rel=&quot;twalthr&quot;&gt;twalthr&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fhueske&quot; class=&quot;user-hover&quot; rel=&quot;fhueske&quot;&gt;fhueske&lt;/a&gt; do you have any insights why this test could fail?&lt;/p&gt;</comment>
                            <comment id="16648915" author="hequn8128" created="Sat, 13 Oct 2018 12:24:04 +0000"  >&lt;p&gt;Should we continue to look into this problem or close it? It seems there is no such fails on travis now.&lt;/p&gt;</comment>
                            <comment id="16649913" author="till.rohrmann" created="Mon, 15 Oct 2018 08:56:52 +0000"  >&lt;p&gt;Have you tried to run this test in a loop on your local machine or some cloud instance? Usually, I could provoke test failures like this before &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hequn8128&quot; class=&quot;user-hover&quot; rel=&quot;hequn8128&quot;&gt;hequn8128&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16660814" author="githubbot" created="Tue, 23 Oct 2018 15:15:53 +0000"  >&lt;p&gt;dawidwys opened a new pull request #6908: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10220&quot; title=&quot;StreamSQL E2E test fails on travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10220&quot;&gt;&lt;del&gt;FLINK-10220&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Removing logs for streaming sql e2e test before validation&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6908&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6908&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul&gt;
	&lt;li&gt;It properly checks logs for exception &amp;amp; errors (previously it was nondeterministic)&lt;/li&gt;
	&lt;li&gt;Removing logs for streaming sql e2e test, because exceptions there are expected&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   Explanation for this change:&lt;br/&gt;
   Previously the last grep command had `-iq` flag which was terminated after first occurance of exception/error, which resulted in pipe failure and the whole assertion not working.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;The serializers: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (yes / *&lt;b&gt;no&lt;/b&gt;* / don&apos;t know)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (yes / *&lt;b&gt;no&lt;/b&gt;*)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (*&lt;b&gt;not applicable&lt;/b&gt;* / docs / JavaDocs / not documented)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16662192" author="githubbot" created="Wed, 24 Oct 2018 12:06:15 +0000"  >&lt;p&gt;pnowojski commented on a change in pull request #6908: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10220&quot; title=&quot;StreamSQL E2E test fails on travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10220&quot;&gt;&lt;del&gt;FLINK-10220&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Removing logs for streaming sql e2e test before validation&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6908#discussion_r227758726&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6908#discussion_r227758726&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-end-to-end-tests/test-scripts/common.sh&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -300,7 +300,7 @@ function start_and_wait_for_tm {&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt; function check_logs_for_errors {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if grep -rv &quot;GroupCoordinatorNotAvailableException&quot; $FLINK_DIR/log \&lt;br/&gt;
+  error_count=$(grep -rv &quot;GroupCoordinatorNotAvailableException&quot; $FLINK_DIR/log \&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   Please add the description to the commit message why this change was needed. Maybe a bit extended description from the PR?&lt;/p&gt;

&lt;p&gt;   Btw, is this a hotfix and it doesn&apos;t have Jira ticket?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16662284" author="githubbot" created="Wed, 24 Oct 2018 13:21:16 +0000"  >&lt;p&gt;dawidwys closed pull request #6908: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10220&quot; title=&quot;StreamSQL E2E test fails on travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10220&quot;&gt;&lt;del&gt;FLINK-10220&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;e2e&amp;#93;&lt;/span&gt; Removing logs for streaming sql e2e test before validation&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6908&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6908&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-end-to-end-tests/test-scripts/common.sh b/flink-end-to-end-tests/test-scripts/common.sh&lt;br/&gt;
index 1dbe89a44ce..618aae8da9a 100644&lt;br/&gt;
&amp;#8212; a/flink-end-to-end-tests/test-scripts/common.sh&lt;br/&gt;
+++ b/flink-end-to-end-tests/test-scripts/common.sh&lt;br/&gt;
@@ -300,7 +300,7 @@ function start_and_wait_for_tm {&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt; function check_logs_for_errors {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if grep -rv &quot;GroupCoordinatorNotAvailableException&quot; $FLINK_DIR/log \&lt;br/&gt;
+  error_count=$(grep -rv &quot;GroupCoordinatorNotAvailableException&quot; $FLINK_DIR/log \
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;RetriableCommitFailedException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;NoAvailableBrokersException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Async Kafka commit failed&quot; \&lt;br/&gt;
@@ -315,7 +315,8 @@ function check_logs_for_errors {&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/exceptions/YarnException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;org.apache.flink.fs.shaded.hadoop3.org.apache.commons.beanutils.FluentPropertyBeanIntrospector  - Error when creating PropertyDescriptor for public final void org.apache.flink.fs.shaded.hadoop3.org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -iq &quot;error&quot;; then&lt;br/&gt;
+      &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -ic &quot;error&quot;)&lt;br/&gt;
+  if [[ ${error_count} -gt 0 ]]; then&lt;br/&gt;
     echo &quot;Found error in log files:&quot;&lt;br/&gt;
     cat $FLINK_DIR/log/*&lt;br/&gt;
     EXIT_CODE=1&lt;br/&gt;
@@ -323,24 +324,25 @@ function check_logs_for_errors {&lt;br/&gt;
 }&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; function check_logs_for_exceptions {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if grep -rv &quot;GroupCoordinatorNotAvailableException&quot; $FLINK_DIR/log \&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;RetriableCommitFailedException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;NoAvailableBrokersException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Async Kafka commit failed&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;DisconnectException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;AskTimeoutException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;WARN  akka.remote.transport.netty.NettyTransport&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v  &quot;WARN  org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &apos;^INFO:.&lt;b&gt;AWSErrorCode=[400 Bad Request].*ServiceEndpoint=[https://.&lt;/b&gt;\.s3\.amazonaws\.com].*RequestType=[HeadBucketRequest]&apos; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;RejectedExecutionException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;An exception was thrown by an exception handler&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.yarn.exceptions.YarnException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/exceptions/YarnException&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.Exception: Execution was suspended&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Caused by: java.lang.Exception: JobManager is shutting down&quot; \&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -iq &quot;exception&quot;; then&lt;br/&gt;
+  exception_count=$(grep -rv &quot;GroupCoordinatorNotAvailableException&quot; $FLINK_DIR/log \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;RetriableCommitFailedException&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;NoAvailableBrokersException&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Async Kafka commit failed&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;DisconnectException&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;AskTimeoutException&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;WARN  akka.remote.transport.netty.NettyTransport&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v  &quot;WARN  org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &apos;^INFO:.&lt;b&gt;AWSErrorCode=[400 Bad Request].*ServiceEndpoint=[https://.&lt;/b&gt;\.s3\.amazonaws\.com].*RequestType=[HeadBucketRequest]&apos; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;RejectedExecutionException&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;An exception was thrown by an exception handler&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.yarn.exceptions.YarnException&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/exceptions/YarnException&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;java.lang.Exception: Execution was suspended&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -v &quot;Caused by: java.lang.Exception: JobManager is shutting down&quot; \&lt;br/&gt;
+   &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; grep -ic &quot;exception&quot;)&lt;br/&gt;
+  if [[ ${exception_count} -gt 0 ]]; then&lt;br/&gt;
     echo &quot;Found exception in log files:&quot;&lt;br/&gt;
     cat $FLINK_DIR/log/*&lt;br/&gt;
     EXIT_CODE=1&lt;br/&gt;
diff --git a/flink-end-to-end-tests/test-scripts/test_streaming_sql.sh b/flink-end-to-end-tests/test-scripts/test_streaming_sql.sh&lt;br/&gt;
index 5aca0e54f94..0aa931ef2d3 100755&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-end-to-end-tests/test-scripts/test_streaming_sql.sh&lt;br/&gt;
+++ b/flink-end-to-end-tests/test-scripts/test_streaming_sql.sh&lt;br/&gt;
@@ -42,6 +42,9 @@ function sql_cleanup() 
{
 
   # remove flink-table from lib folder
   rm $FLINK_DIR/lib/flink-table*jar
+
+  # remove logs cause they contain exceptions that shouldn&apos;t fail the test
+  rm $FLINK_DIR/log/*
 }
&lt;p&gt; trap sql_cleanup INT&lt;br/&gt;
 trap sql_cleanup EXIT&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13153275">FLINK-9200</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 3 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3xfvz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>