<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:35:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10451] TableFunctionCollector should handle the life cycle of ScalarFunction</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10451</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Considering the following query:&lt;/p&gt;

&lt;p&gt;table.join(udtf(&apos;a)).where(udf(&apos;b))&lt;/p&gt;

&lt;p&gt;the filter will be pushed into DataSetCorrelate/DataStreamCorrelate without triggering open() and close()&lt;/p&gt;</description>
                <environment></environment>
        <key id="13187865">FLINK-10451</key>
            <summary>TableFunctionCollector should handle the life cycle of ScalarFunction</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="RuidongLi">Ruidong Li</assignee>
                                    <reporter username="RuidongLi">Ruidong Li</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Thu, 27 Sep 2018 10:46:57 +0000</created>
                <updated>Wed, 17 Oct 2018 08:44:43 +0000</updated>
                            <resolved>Tue, 2 Oct 2018 10:33:13 +0000</resolved>
                                                    <fixVersion>1.5.5</fixVersion>
                    <fixVersion>1.6.2</fixVersion>
                    <fixVersion>1.7.0</fixVersion>
                                    <component>Table SQL / API</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16630193" author="githubbot" created="Thu, 27 Sep 2018 10:53:05 +0000"  >&lt;p&gt;Xpray opened a new pull request #6771: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10451&quot; title=&quot;TableFunctionCollector should handle the life cycle of ScalarFunction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10451&quot;&gt;&lt;del&gt;FLINK-10451&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; TableFunctionCollector should handle the life cycle of ScalarFunction&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6771&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6771&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   TableFunctionCollector should handle the life cycle of ScalarFunction&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul&gt;
	&lt;li&gt;Make `TableFunctionCollector` extends `AbstractRichFunction`&lt;/li&gt;
	&lt;li&gt;do open() and close()&lt;/li&gt;
&lt;/ul&gt;



&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This change added tests and can be verified as follows:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;`org.apache.flink.table.runtime.batch.table.CorrelateITCase#testTableFunctionWithFilterInside`&lt;/li&gt;
	&lt;li&gt;`org.apache.flink.table.runtime.stream.table.CorrelateITCase#testTableFunctionWithFilterInside`
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency):  no&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`:  no&lt;/li&gt;
	&lt;li&gt;The serializers:  no&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive):  no&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper:  no&lt;/li&gt;
	&lt;li&gt;The S3 file system connector:  no&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature?  no&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented?  not documented&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16635248" author="githubbot" created="Tue, 2 Oct 2018 10:13:58 +0000"  >&lt;p&gt;asfgit closed pull request #6771: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10451&quot; title=&quot;TableFunctionCollector should handle the life cycle of ScalarFunction&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10451&quot;&gt;&lt;del&gt;FLINK-10451&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; TableFunctionCollector should handle the life cycle of ScalarFunction&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6771&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6771&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CollectorCodeGenerator.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CollectorCodeGenerator.scala&lt;br/&gt;
index 9fc76e32983..85d858fb75b 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CollectorCodeGenerator.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CollectorCodeGenerator.scala&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.flink.table.codegen&lt;/p&gt;

&lt;p&gt; import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
+import org.apache.flink.configuration.Configuration&lt;br/&gt;
 import org.apache.flink.table.api.TableConfig&lt;br/&gt;
 import org.apache.flink.table.codegen.CodeGenUtils.&lt;/p&gt;
{boxedTypeTermForTypeInfo, newName}
&lt;p&gt; import org.apache.flink.table.codegen.Indenter.toISC&lt;br/&gt;
@@ -63,7 +64,8 @@ class CollectorCodeGenerator(&lt;br/&gt;
   def generateTableFunctionCollector(&lt;br/&gt;
       name: String,&lt;br/&gt;
       bodyCode: String,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;collectedType: TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;Any&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+      collectedType: TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;Any&amp;#93;&lt;/span&gt;,&lt;br/&gt;
+      codeGenerator: CodeGenerator)&lt;br/&gt;
     : GeneratedCollector = 
{
 
     val className = newName(name)
@@ -95,6 +97,11 @@ class CollectorCodeGenerator(
       |  }
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  @Override&lt;br/&gt;
+      &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  public void open(${classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Configuration&amp;#93;&lt;/span&gt;.getCanonicalName} parameters) throws Exception {&lt;br/&gt;
+      &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    ${codeGenerator.reuseOpenCode()}&lt;br/&gt;
+      &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  }&lt;br/&gt;
+      &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;+      |  @Override&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  public void collect(Object record) throws Exception 
{
       |    super.collect(record);
       |    $input1TypeClass $input1Term = ($input1TypeClass) getInput();
@@ -105,7 +112,8 @@ class CollectorCodeGenerator(
       |  }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  @Override&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  public void close() {&lt;br/&gt;
+      &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  public void close() throws Exception {&lt;br/&gt;
+      &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    ${codeGenerator.reuseCloseCode()}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  }&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;&quot;&quot;.stripMargin&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/CommonCorrelate.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/CommonCorrelate.scala&lt;br/&gt;
index 43314577ab8..3475e1901e9 100644&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/CommonCorrelate.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/CommonCorrelate.scala&lt;br/&gt;
@@ -136,6 +136,13 @@ trait CommonCorrelate {&lt;br/&gt;
       returnSchema.typeInfo,&lt;br/&gt;
       returnSchema.fieldNames)&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+    val filterGenerator = new FunctionCodeGenerator(&lt;br/&gt;
+      config,&lt;br/&gt;
+      false,&lt;br/&gt;
+      udtfTypeInfo,&lt;br/&gt;
+      None,&lt;br/&gt;
+      pojoFieldMapping)&lt;br/&gt;
+&lt;br/&gt;
     val collectorCode = if (condition.isEmpty) {&lt;br/&gt;
       s&quot;&quot;&quot;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;${crossResultExpr.code}&lt;br/&gt;
@@ -153,13 +160,6 @@ trait CommonCorrelate {&lt;br/&gt;
       //   The generated expression is discarded.&lt;br/&gt;
       generator.generateExpression(condition.get.accept(changeInputRefIndexShuttle))&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val filterGenerator = new FunctionCodeGenerator(&lt;/li&gt;
	&lt;li&gt;config,&lt;/li&gt;
	&lt;li&gt;false,&lt;/li&gt;
	&lt;li&gt;udtfTypeInfo,&lt;/li&gt;
	&lt;li&gt;None,&lt;/li&gt;
	&lt;li&gt;pojoFieldMapping)&lt;br/&gt;
-&lt;br/&gt;
       filterGenerator.input1Term = filterGenerator.input2Term&lt;br/&gt;
       val filterCondition = filterGenerator.generateExpression(condition.get)&lt;br/&gt;
       s&quot;&quot;&quot;&lt;br/&gt;
@@ -175,7 +175,8 @@ trait CommonCorrelate 
{
     generator.generateTableFunctionCollector(
       &quot;TableFunctionCollector&quot;,
       collectorCode,
-      udtfTypeInfo)
+      udtfTypeInfo,
+      filterGenerator)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def selectToString(rowType: RelDataType): String = &lt;/p&gt;
{
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CRowCorrelateProcessRunner.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CRowCorrelateProcessRunner.scala
index 2553d9cd67b..747828cedbd 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CRowCorrelateProcessRunner.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CRowCorrelateProcessRunner.scala
@@ -59,7 +59,9 @@ class CRowCorrelateProcessRunner(
     val constructor = processClazz.getConstructor(classOf[TableFunctionCollector[_]])
     LOG.debug(&quot;Instantiating ProcessFunction.&quot;)
     function = constructor.newInstance(collector).asInstanceOf[ProcessFunction[Row, Row]]
+    FunctionUtils.setFunctionRuntimeContext(collector, getRuntimeContext)
     FunctionUtils.setFunctionRuntimeContext(function, getRuntimeContext)
+    FunctionUtils.openFunction(collector, parameters)
     FunctionUtils.openFunction(function, parameters)
   }

&lt;p&gt;@@ -85,6 +87,7 @@ class CRowCorrelateProcessRunner(&lt;br/&gt;
   override def getProducedType: TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;CRow&amp;#93;&lt;/span&gt; = returnType&lt;/p&gt;

&lt;p&gt;   override def close(): Unit = &lt;/p&gt;
{
+    FunctionUtils.closeFunction(collector)
     FunctionUtils.closeFunction(function)
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CorrelateFlatMapRunner.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CorrelateFlatMapRunner.scala&lt;br/&gt;
index e2f5e611336..811169bcdc5 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CorrelateFlatMapRunner.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/CorrelateFlatMapRunner.scala&lt;br/&gt;
@@ -52,7 +52,9 @@ class CorrelateFlatMapRunner&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;(&lt;br/&gt;
     val constructor = flatMapClazz.getConstructor(classOf[TableFunctionCollector&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;])&lt;br/&gt;
     LOG.debug(&quot;Instantiating FlatMapFunction.&quot;)&lt;br/&gt;
     function = constructor.newInstance(collector).asInstanceOf[FlatMapFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;]&lt;br/&gt;
+    FunctionUtils.setFunctionRuntimeContext(collector, getRuntimeContext)&lt;br/&gt;
     FunctionUtils.setFunctionRuntimeContext(function, getRuntimeContext)&lt;br/&gt;
+    FunctionUtils.openFunction(collector, parameters)&lt;br/&gt;
     FunctionUtils.openFunction(function, parameters)&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
@@ -66,6 +68,7 @@ class CorrelateFlatMapRunner&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;(&lt;br/&gt;
   override def getProducedType: TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;OUT&amp;#93;&lt;/span&gt; = returnType&lt;br/&gt;
 &lt;br/&gt;
   override def close(): Unit = {+    FunctionUtils.closeFunction(collector)     FunctionUtils.closeFunction(function)   }
&lt;p&gt; }&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/TableFunctionCollector.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/TableFunctionCollector.scala&lt;br/&gt;
index c9cca47d165..7db424489a5 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/TableFunctionCollector.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/TableFunctionCollector.scala&lt;br/&gt;
@@ -17,12 +17,13 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.flink.table.runtime&lt;/p&gt;

&lt;p&gt;+import org.apache.flink.api.common.functions.AbstractRichFunction&lt;br/&gt;
 import org.apache.flink.util.Collector&lt;/p&gt;

&lt;p&gt; /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The basic implementation of collector for [&lt;span class=&quot;error&quot;&gt;&amp;#91;org.apache.flink.table.functions.TableFunction&amp;#93;&lt;/span&gt;].&lt;br/&gt;
   */&lt;br/&gt;
-abstract class TableFunctionCollector&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; extends Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; {&lt;br/&gt;
+abstract class TableFunctionCollector&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; extends AbstractRichFunction with Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt; {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private var input: Any = _&lt;br/&gt;
   private var collector: Collector&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala&lt;br/&gt;
index 32e5d71662e..6d02afca510 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala&lt;br/&gt;
@@ -290,6 +290,23 @@ object Func19 extends ScalarFunction {&lt;/p&gt;

&lt;p&gt; }&lt;/p&gt;

&lt;p&gt;+class Func20 extends ScalarFunction {&lt;br/&gt;
+&lt;br/&gt;
+  private var permitted: Boolean = false&lt;br/&gt;
+&lt;br/&gt;
+  override def open(context: FunctionContext): Unit = &lt;/p&gt;
{
+    permitted = true
+  }
&lt;p&gt;+&lt;br/&gt;
+  def eval(x: Int): Boolean = &lt;/p&gt;
{
+    permitted
+  }
&lt;p&gt;+&lt;br/&gt;
+  override def close(): Unit = &lt;/p&gt;
{
+    permitted = false
+  }
&lt;p&gt;+}&lt;br/&gt;
+&lt;br/&gt;
 class SplitUDF(deterministic: Boolean) extends ScalarFunction {&lt;br/&gt;
   def eval(x: String, sep: String, index: Int): String = {&lt;br/&gt;
     val splits = StringUtils.splitByWholeSeparator(x, sep)&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/batch/table/CorrelateITCase.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/batch/table/CorrelateITCase.scala&lt;br/&gt;
index b385015102c..4a0a08222e2 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/batch/table/CorrelateITCase.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/batch/table/CorrelateITCase.scala&lt;br/&gt;
@@ -24,7 +24,7 @@ import org.apache.flink.api.scala._&lt;br/&gt;
 import org.apache.flink.api.scala.util.CollectionDataSets&lt;br/&gt;
 import org.apache.flink.table.api.scala._&lt;br/&gt;
 import org.apache.flink.table.api.&lt;/p&gt;
{TableEnvironment, Types, ValidationException}&lt;br/&gt;
-import org.apache.flink.table.expressions.utils.{Func1, Func18, RichFunc2}&lt;br/&gt;
+import org.apache.flink.table.expressions.utils.{Func1, Func18, Func20, RichFunc2}&lt;br/&gt;
 import org.apache.flink.table.runtime.utils.JavaUserDefinedTableFunctions.JavaTableFunc0&lt;br/&gt;
 import org.apache.flink.table.runtime.utils.TableProgramsTestBase.TableConfigMode&lt;br/&gt;
 import org.apache.flink.table.runtime.utils.{TableProgramsClusterTestBase, _}&lt;br/&gt;
@@ -367,6 +367,33 @@ class CorrelateITCase(&lt;br/&gt;
     assertTrue(results0.isEmpty)&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testTableFunctionWithFilterInside(): Unit = {
+    val env = ExecutionEnvironment.getExecutionEnvironment
+    val tableEnv = TableEnvironment.getTableEnvironment(env, config)
+    val t = testData(env).toTable(tableEnv).as(&apos;a, &apos;b, &apos;c)
+    val func0 = new TableFunc0
+    val func20 = new Func20
+
+    val result = t
+      .join(func0(&apos;c) as(&apos;d, &apos;e))
+      .where(func20(&apos;e))
+      .select(&apos;c, &apos;d, &apos;e)
+
+    val results = result.toDataSet[Row].collect()
+
+    val expected = Seq (
+      &quot;Jack#22,Jack,22&quot;,
+      &quot;John#19,John,19&quot;,
+      &quot;Anna#44,Anna,44&quot;
+    )
+
+    TestBaseUtils.compareResultAsText(
+      results.asJava,
+      expected.sorted.mkString(&quot;\n&quot;)
+    )
+  }&lt;br/&gt;
+&lt;br/&gt;
   private def testData(&lt;br/&gt;
       env: ExecutionEnvironment)&lt;br/&gt;
     : DataSet&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, Long, String)&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/table/CorrelateITCase.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/table/CorrelateITCase.scala&lt;br/&gt;
index 0f563e61f64..d71742d0def 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/table/CorrelateITCase.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/table/CorrelateITCase.scala&lt;br/&gt;
@@ -23,7 +23,7 @@ import org.apache.flink.api.scala._&lt;br/&gt;
 import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}&lt;br/&gt;
 import org.apache.flink.table.api.scala._&lt;br/&gt;
 import org.apache.flink.table.api.{TableEnvironment, Types, ValidationException}
&lt;p&gt;-import org.apache.flink.table.expressions.utils.&lt;/p&gt;
{Func18, RichFunc2}
&lt;p&gt;+import org.apache.flink.table.expressions.utils.&lt;/p&gt;
{Func18, Func20, RichFunc2}
&lt;p&gt; import org.apache.flink.table.runtime.utils.&lt;/p&gt;
{StreamITCase, StreamTestData, _}
&lt;p&gt; import org.apache.flink.table.utils._&lt;br/&gt;
 import org.apache.flink.test.util.AbstractTestBase&lt;br/&gt;
@@ -257,6 +257,33 @@ class CorrelateITCase extends AbstractTestBase &lt;/p&gt;
{
     assertEquals(expected.sorted, StreamITCase.testResults.sorted)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testTableFunctionWithFilterInside(): Unit = &lt;/p&gt;
{
+    val t = testData(env).toTable(tEnv).as(&apos;a, &apos;b, &apos;c)
+    val func0 = new TableFunc0
+    val func20 = new Func20
+
+    val result = t
+      .join(func0(&apos;c) as(&apos;d, &apos;e))
+      .where(func20(&apos;e))
+      .select(&apos;c, &apos;d, &apos;e)
+      .toAppendStream[Row]
+
+    result.addSink(new StreamITCase.StringSink[Row])
+    env.execute()
+
+    val expected = Seq (
+      &quot;Jack#22,Jack,22&quot;,
+      &quot;John#19,John,19&quot;,
+      &quot;Anna#44,Anna,44&quot;
+    )
+
+    assertEquals(
+      expected.sorted,
+      StreamITCase.testResults.sorted
+    )
+  }
&lt;p&gt;+&lt;br/&gt;
   private def testData(&lt;br/&gt;
       env: StreamExecutionEnvironment)&lt;br/&gt;
     : DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, Long, String)&amp;#93;&lt;/span&gt; = {&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16635266" author="twalthr" created="Tue, 2 Oct 2018 10:33:13 +0000"  >&lt;p&gt;Fixed in 1.7.0: 22613b7392f6f9b344291bb3a5cec84c9aa40926&lt;br/&gt;
Fixed in 1.6.2: 7fb980ec74b95d7e6e27d6414af54deb9010e134&lt;br/&gt;
Fixed in 1.5.5: 9a1f0c5e05ef50f115c8f92aac9fc156cdf54249&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 7 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3ykbr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>