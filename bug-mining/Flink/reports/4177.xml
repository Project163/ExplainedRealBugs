<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:46:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-17923] It will throw MemoryAllocationException if rocksdb statebackend and Python UDF are used in the same slot  </title>
                <link>https://issues.apache.org/jira/browse/FLINK-17923</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;For the following job:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; logging
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; os
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; shutil
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; sys
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; tempfile

from pyflink.datastream &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; StreamExecutionEnvironment
from pyflink.table &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; TableConfig, StreamTableEnvironment, DataTypes
from pyflink.table.udf &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; udf


def word_count():
    content = &lt;span class=&quot;code-quote&quot;&gt;&quot;line Licensed to the Apache Software Foundation ASF under one &quot;&lt;/span&gt; \
              &lt;span class=&quot;code-quote&quot;&gt;&quot;line or more contributor license agreements See the NOTICE file &quot;&lt;/span&gt; \
              &lt;span class=&quot;code-quote&quot;&gt;&quot;line distributed with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; work &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; additional information &quot;&lt;/span&gt; \
              &lt;span class=&quot;code-quote&quot;&gt;&quot;line regarding copyright ownership The ASF licenses &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; file &quot;&lt;/span&gt; \
              &lt;span class=&quot;code-quote&quot;&gt;&quot;to you under the Apache License Version the &quot;&lt;/span&gt; \
              &lt;span class=&quot;code-quote&quot;&gt;&quot;License you may not use &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; file except in compliance &quot;&lt;/span&gt; \
              &lt;span class=&quot;code-quote&quot;&gt;&quot;with the License&quot;&lt;/span&gt;

    t_config = TableConfig()
    env = StreamExecutionEnvironment.get_execution_environment()
    t_env = StreamTableEnvironment.create(env, t_config)

    # register Results table in table environment
    tmp_dir = tempfile.gettempdir()
    result_path = tmp_dir + &lt;span class=&quot;code-quote&quot;&gt;&apos;/result&apos;&lt;/span&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; os.path.exists(result_path):
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;:
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; os.path.isfile(result_path):
                os.remove(result_path)
            &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
                shutil.rmtree(result_path)
        except OSError as e:
            logging.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;Error removing directory: %s - %s.&quot;&lt;/span&gt;, e.filename, e.strerror)

    logging.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Results directory: %s&quot;&lt;/span&gt;, result_path)

    sink_ddl = &quot;&quot;&quot;
        create table Results(
            word VARCHAR,
            `count` BIGINT
        ) with (
            &lt;span class=&quot;code-quote&quot;&gt;&apos;connector&apos;&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&apos;blackhole&apos;&lt;/span&gt;
        )
        &quot;&quot;&quot;
    t_env.sql_update(sink_ddl)

    @udf(input_types=[DataTypes.BIGINT()], result_type=DataTypes.BIGINT())
    def inc(count):
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; count + 1
    t_env.register_function(&lt;span class=&quot;code-quote&quot;&gt;&quot;inc&quot;&lt;/span&gt;, inc)

    elements = [(word, 1) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; word in content.split(&lt;span class=&quot;code-quote&quot;&gt;&quot; &quot;&lt;/span&gt;)]
    t_env.from_elements(elements, [&lt;span class=&quot;code-quote&quot;&gt;&quot;word&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;count&quot;&lt;/span&gt;]) \
         .group_by(&lt;span class=&quot;code-quote&quot;&gt;&quot;word&quot;&lt;/span&gt;) \
         .select(&lt;span class=&quot;code-quote&quot;&gt;&quot;word, count(1) as count&quot;&lt;/span&gt;) \
         .select(&lt;span class=&quot;code-quote&quot;&gt;&quot;word, inc(count) as count&quot;&lt;/span&gt;) \
         .insert_into(&lt;span class=&quot;code-quote&quot;&gt;&quot;Results&quot;&lt;/span&gt;)

    t_env.execute(&lt;span class=&quot;code-quote&quot;&gt;&quot;word_count&quot;&lt;/span&gt;)


&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; __name__ == &lt;span class=&quot;code-quote&quot;&gt;&apos;__main__&apos;&lt;/span&gt;:
    logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;%(message)s&quot;&lt;/span&gt;)

    word_count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It will throw the following exception if rocksdb state backend is used:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: org.apache.flink.util.FlinkException: Could not restore keyed state backend &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; KeyedProcessOperator_c27dcf7b54ef6bfd6cff02ca8870b681_(1/1) from any of the 1 provided restore options.
	at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:135)
	at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:317)
	at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:144)
	... 9 more
Caused by: java.io.IOException: Failed to acquire shared cache resource &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; RocksDB
	at org.apache.flink.contrib.streaming.state.RocksDBOperationUtils.allocateSharedCachesIfConfigured(RocksDBOperationUtils.java:212)
	at org.apache.flink.contrib.streaming.state.RocksDBStateBackend.createKeyedStateBackend(RocksDBStateBackend.java:516)
	at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.lambda$keyedStatedBackend$1(StreamTaskStateInitializerImpl.java:301)
	at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:142)
	at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:121)
	... 11 more
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not created the shared memory resource of size 536870920. Not enough memory left to reserve from the slot&apos;s managed memory.
	at org.apache.flink.runtime.memory.MemoryManager.lambda$getSharedMemoryResourceForManagedMemory$8(MemoryManager.java:603)
	at org.apache.flink.runtime.memory.SharedResources.createResource(SharedResources.java:130)
	at org.apache.flink.runtime.memory.SharedResources.getOrAllocateSharedResource(SharedResources.java:72)
	at org.apache.flink.runtime.memory.MemoryManager.getSharedMemoryResourceForManagedMemory(MemoryManager.java:617)
	at org.apache.flink.runtime.memory.MemoryManager.getSharedMemoryResourceForManagedMemory(MemoryManager.java:566)
	at org.apache.flink.contrib.streaming.state.RocksDBOperationUtils.allocateSharedCachesIfConfigured(RocksDBOperationUtils.java:208)
	... 15 more
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 536870920 bytes. Only 454033416 bytes are remaining.
	at org.apache.flink.runtime.memory.MemoryManager.reserveMemory(MemoryManager.java:461)
	at org.apache.flink.runtime.memory.MemoryManager.lambda$getSharedMemoryResourceForManagedMemory$8(MemoryManager.java:601)
	... 20 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13307194">FLINK-17923</key>
            <summary>It will throw MemoryAllocationException if rocksdb statebackend and Python UDF are used in the same slot  </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dian.fu">Dian Fu</assignee>
                                    <reporter username="dian.fu">Dian Fu</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 25 May 2020 09:33:51 +0000</created>
                <updated>Tue, 28 Jul 2020 07:56:15 +0000</updated>
                            <resolved>Wed, 3 Jun 2020 01:56:24 +0000</resolved>
                                    <version>1.10.0</version>
                    <version>1.11.0</version>
                                    <fixVersion>1.11.0</fixVersion>
                                    <component>API / Python</component>
                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="17116500" author="xintongsong" created="Tue, 26 May 2020 07:08:16 +0000"  >&lt;p&gt;The problem is that RocksDB assumes it is the only managed memory consumer in streaming scenarios, and tries to take all the managed memory in the slot, while actually Python UDF might also reserve managed memory in streaming scenarios.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;Morebackgrounds&quot;&gt;&lt;/a&gt;More backgrounds&lt;/h3&gt;
&lt;p&gt;With FLIP-53, when generating the stream graph, we make a plan on how managed memory should be shared by operators within a slot.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;For batch jobs, we calculate a fraction for each operator, representing what fraction of the slot&apos;s managed memory the operator should use. Operators will read this fraction in runtime, and reserve the corresponding memory from the memory manager.&lt;/li&gt;
	&lt;li&gt;For streaming jobs, we assumed the only managed memory consumer is RocksDBStateBackend. Therefore, calculation of the fraction (when generating stream graph) is omitted. RocksDBStateBackend will always reserve all (fraction = 1) the managed memory from the memory manager.&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;&lt;a name=&quot;Potentialsolutions&quot;&gt;&lt;/a&gt;Potential solutions&lt;/h3&gt;
&lt;p&gt;There was an offline discussion between &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dian.fu&quot; class=&quot;user-hover&quot; rel=&quot;dian.fu&quot;&gt;dian.fu&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yunta&quot; class=&quot;user-hover&quot; rel=&quot;yunta&quot;&gt;yunta&lt;/a&gt; and me. And here are some ideas we came up with.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;We can say that ATM we do not support Python UDF and RocksDBStateBackend work together. We can add a check at compiling time and throw an exception / warning if they are used together. Given that release 1.11 is already frozen, this could avoid rushing significant changes in the last minute. The drawback is obviously we loose a large portion of steaming Python UDF use cases for release 1.11.&lt;/li&gt;
	&lt;li&gt;We can make Python UDF not reserve managed memory. Basically, Python UDF uses memory in the same way how other user codes use off-heap memory. Users need to explicitly configure larger task off-heap memory. The drawbacks for this solutions are 1) it requires more user involvement, 2) it breaks the current 1.10 behavior in batch scenarios where such user involvement was not needed, and 3) we might need to revert the changes in future.&lt;/li&gt;
	&lt;li&gt;We can also calculate a fraction for RocksDBStateBackend, making it properly share managed memory with Python UDFs. This is probably the most proper solution. The problem is there are still some open questions, such as how to calculate the fraction (because RocksDBStateBackend allocates managed memory in a per-slot way rather than per-operator), and how to pass the fraction to the state backend. We are not sure whether this is doable in the 1.11 release cycle, given that it&apos;s already frozen.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;We would like to hear more opinions from the community. Many Thanks.&lt;/p&gt;</comment>
                            <comment id="17116503" author="xintongsong" created="Tue, 26 May 2020 07:12:38 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jincheng&quot; class=&quot;user-hover&quot; rel=&quot;jincheng&quot;&gt;jincheng&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liyu&quot; class=&quot;user-hover&quot; rel=&quot;liyu&quot;&gt;liyu&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17116614" author="sunjincheng121" created="Tue, 26 May 2020 10:40:34 +0000"  >&lt;p&gt;It&apos;s a pity that we do not find this issue earlier(We also need to improve the e2e test for PyFlink after fixing this issue). This is a very critical problem for PyFlink as it means that Python UDF could not be used in most streaming jobs(with state).So I think we should address this problem in 1.11.&#160;&lt;/p&gt;

&lt;p&gt;We( &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yunta&quot; class=&quot;user-hover&quot; rel=&quot;yunta&quot;&gt;yunta&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dian.fu&quot; class=&quot;user-hover&quot; rel=&quot;dian.fu&quot;&gt;dian.fu&lt;/a&gt;&#160;and me) have a further discussion about this problem and will update the status later.&lt;/p&gt;

&lt;p&gt;Appreciate if you can pay attention to this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pnowojski&quot; class=&quot;user-hover&quot; rel=&quot;pnowojski&quot;&gt;pnowojski&lt;/a&gt;&#160; and&#160;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjwang&quot; class=&quot;user-hover&quot; rel=&quot;zjwang&quot;&gt;zjwang&lt;/a&gt; .&#160;&#160;&lt;/p&gt;</comment>
                            <comment id="17116758" author="pnowojski" created="Tue, 26 May 2020 13:49:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt; it sounds to me like option 2. is not a proper temporary hotfix. It might be problematic to rush currently with a proper solution, like option 3. (or some other proposal?). &lt;/p&gt;

&lt;p&gt;I see it affects also 1.10, so it is not a new issue, right? In that case, I don&apos;t think it should be a release blocker for 1.11. We could fix it for 1.12 and if it&apos;s important and fix won&apos;t be invasive and causing other side effects, we could also back port it to 1.11.1. &lt;/p&gt;</comment>
                            <comment id="17116772" author="sunjincheng121" created="Tue, 26 May 2020 14:17:00 +0000"  >&lt;p&gt;At present, users can&apos;t start jobs as long as they use rocksDB + Python UDF. The core scenario of our Flink is stream computing. In stream computing, as long as it&apos;s an analytical application, it needs to use AGG. In this case, if it&apos;s a Python User, the demand for Python UDF is our core function of 1.10/1.11. At present, we have china users waiting to use this feature.&lt;/p&gt;

&lt;p&gt;We discussed the details of using option 3 today. Later &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt; will share the design document with you. We can discuss the design first and evaluate whether put this fixing to 1.11 is reasonable.&lt;/p&gt;</comment>
                            <comment id="17117260" author="xintongsong" created="Wed, 27 May 2020 02:52:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pnowojski&quot; class=&quot;user-hover&quot; rel=&quot;pnowojski&quot;&gt;pnowojski&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I posted all the 3 options that were mentioned in our offline discussion, for public visibility.&lt;/p&gt;

&lt;p&gt;Personally, I&apos;m not a fan of option 2), because I also think it is an improper temporary fix.&lt;/p&gt;

&lt;p&gt;For option 3), as Jincheng mentioned, Zhu is already preparing a design doc (ETA today). I understand that having people evaluating the design is already a distraction from solving the release blockers. However, in this case I think it would be ok to at least take a look at the design proposal before deciding whether this should be fixed in 1.11.0, for its importance for python use cases and the fact that people mostly involved with the proposed change (Jincheng &amp;amp; Zhu) do not have much workload related to the release testing (that&apos;s what I see from the current burndown board).&lt;/p&gt;

&lt;p&gt;Additionally, if this fix does not make into 1.11.0 at the end, I would suggest a really quick release 1.11.1 (potentially right after fixing this issue). IIUC, the fix of this issue ideally should not affect any other scenarios except for running both RocksDB &amp;amp; Python UDF together (which currently doesn&apos;t work).&lt;/p&gt;</comment>
                            <comment id="17117512" author="zhuzh" created="Wed, 27 May 2020 08:35:30 +0000"  >&lt;p&gt;We(&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yunta&quot; class=&quot;user-hover&quot; rel=&quot;yunta&quot;&gt;yunta&lt;/a&gt;) just find that we can also have option #4 that users set &quot;state.backend.rocksdb.memory.fixed-per-slot&quot; for python+RocksDB jobs to let RocksDB instances use off-heap memory instead of managed memory. There would be no managed memory reservation exception since only python operators will reserve managed memory.&lt;/p&gt;</comment>
                            <comment id="17117598" author="xintongsong" created="Wed, 27 May 2020 10:00:55 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yunta&quot; class=&quot;user-hover&quot; rel=&quot;yunta&quot;&gt;yunta&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The option 4) sounds a good workaround for release 1.11.0. IIUC, it does not require code modifications, just the users have to apply some specific configurations in order to use rocksdb and python udf at the same time. I think that would be fair enough. We can mention this as limitations / known issues in the release notes, and take our time to properly fix it in the next release.&lt;/p&gt;</comment>
                            <comment id="17117620" author="dian.fu" created="Wed, 27 May 2020 10:27:11 +0000"  >&lt;p&gt;Based on option #4, we can also have option #5 to add a switch to allow Python UDF to use off-heap memory instead of managed memory. The memory needed by the Python process is fixed according to our tests and so it will be easy to set a meaningful default value for Python jobs which could work in most scenarios. Regarding to option #4, as the memory needed by RocksDB has relationship with the memory size of the TM (please correct me if my understanding isn&apos;t correct) and so it will be difficult to set a meaningful default value for Python jobs.&#160;&lt;/p&gt;</comment>
                            <comment id="17117629" author="sunjincheng121" created="Wed, 27 May 2020 10:37:59 +0000"  >&lt;p&gt;Our consensus is that The final solution is both Python and RocksDB should be managed by Resource Management(using managed memory) . I think both #4 and #5 works for PyFlink, I prefer #5 due to it&apos;s much&#160;flexible, if we cannot have #3 in 1.11.0 release.&lt;/p&gt;</comment>
                            <comment id="17118330" author="dian.fu" created="Thu, 28 May 2020 05:43:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sunjincheng121&quot; class=&quot;user-hover&quot; rel=&quot;sunjincheng121&quot;&gt;sunjincheng121&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt;&#160;I have submitted a PR according to option #5. Appreciated if you could take a look.&lt;/p&gt;</comment>
                            <comment id="17118341" author="sunjincheng121" created="Thu, 28 May 2020 06:02:16 +0000"  >&lt;p&gt;Thanks for the PR Dian Fu.&#160; Overall, It&apos;s looks good.&#160;If others also agree to this solution for 1.11, we can merge it as soon as possible and also CP to 1.10 branch. What to you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhuzh&quot; class=&quot;user-hover&quot; rel=&quot;zhuzh&quot;&gt;zhuzh&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pnowojski&quot; class=&quot;user-hover&quot; rel=&quot;pnowojski&quot;&gt;pnowojski&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjwang&quot; class=&quot;user-hover&quot; rel=&quot;zjwang&quot;&gt;zjwang&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17118460" author="xintongsong" created="Thu, 28 May 2020 08:47:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dian.fu&quot; class=&quot;user-hover&quot; rel=&quot;dian.fu&quot;&gt;dian.fu&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sunjincheng121&quot; class=&quot;user-hover&quot; rel=&quot;sunjincheng121&quot;&gt;sunjincheng121&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m not familiar with the flink-python code base, thus I cannot speak much to the PR.&lt;/p&gt;

&lt;p&gt;My only concern is regarding auto-magically setting task.off-heap.size for users. I wonder whether we are trying to be a bit over-smart. It might save some user efforts in many cases, but could also make things hard to understand in other cases. It is one of the main motivations for FLIP-49 to make sure all the memory calculations happen at one place, without such kind of implicit logics.&lt;/p&gt;

&lt;p&gt;I would suggest not to override the task.off-heap.size configuration. Instead, we can suggest how to set this configuration in both memory configuration and python udf docs. This is similar to RocksDBStateBackend, when managed memory is disabled users need to explicitly make sure enough native memory is reserved for RocksDB.&lt;/p&gt;

&lt;p&gt;WDYT?&lt;/p&gt;</comment>
                            <comment id="17118478" author="dian.fu" created="Thu, 28 May 2020 09:16:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&#160;Appreciated your suggestions. It makes sense to me.&lt;br/&gt;
I want to adjust the PR a bit as following:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Set Python UDF to use managed memory by default.&lt;/li&gt;
	&lt;li&gt;If Python UDF and RocksDB is used together and both Python UDF and RocksDB are configured to use managed memory, throw exceptions with meaningful suggestions.&lt;/li&gt;
	&lt;li&gt;If Python UDF is configured to use off-heap memory and the task off-heap memory could not meet the requirement, throw exceptions with&#160;meaningful suggestions.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In this case, when we support to let Python UDF and RocksDB both use managed memory in the future, we could just remove the checks and there will be no potential backward compatibility issues.&lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                            <comment id="17118481" author="stephanewen" created="Thu, 28 May 2020 09:21:13 +0000"  >&lt;p&gt;Thank you for the active discussion.&lt;/p&gt;

&lt;p&gt;One question for clarification: Does Python have one process per TaskManager (shared by all tasks) or one process per slot (shared by all operators) or one process per operator?&lt;/p&gt;</comment>
                            <comment id="17118484" author="dian.fu" created="Thu, 28 May 2020 09:23:18 +0000"  >&lt;p&gt;Currently, there will be one process per operator. It may support to share the Python process among multiple operators in the future.&lt;/p&gt;</comment>
                            <comment id="17118489" author="xintongsong" created="Thu, 28 May 2020 09:28:37 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dian.fu&quot; class=&quot;user-hover&quot; rel=&quot;dian.fu&quot;&gt;dian.fu&lt;/a&gt;, that sounds good to me.&lt;/p&gt;</comment>
                            <comment id="17118622" author="stephanewen" created="Thu, 28 May 2020 12:41:54 +0000"  >&lt;p&gt;I think that before resolving this in a way that changes RocksDBs memory management, we need to first clarify what out future model for the Python Processes is.&lt;/p&gt;

&lt;p&gt;I am somewhat skeptical that the current approach where the Python process takes managed memory by default is the right one.&lt;/p&gt;

&lt;p&gt;For example, the Beam/Flink users really like to deploy the Python interpreter in separate containers. For streaming scenarios that is the most robust setup, I think. In that case, the Flink TaskManager cannot dedicate its managed memory to the Python process.&lt;/p&gt;

&lt;p&gt;The current model seems also somewhat unpredictable when it comes to performance. If you have many slots and operators, each process&apos;s memory budget gets very small. It may eventually start swapping even.&lt;/p&gt;</comment>
                            <comment id="17119209" author="sunjincheng121" created="Fri, 29 May 2020 02:23:17 +0000"  >&lt;p&gt;We can have another way to manage the resource for docker and external mode, but for now TM should manage the resource as we only support the Python worker to run in process mode. So, we can fix this issue by #5. And I think you are right that may be we should set the default value of managed should be set as false if we prefer to use docker or external mode for Python worker in the future.&lt;/p&gt;</comment>
                            <comment id="17119211" author="xintongsong" created="Fri, 29 May 2020 02:24:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;&lt;del&gt;I agree with you that python processes use managed memory by default should be the right approach for long term.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;I think ideally we want RocksDB and Python processes share the managed memory, wrt the planned fractions. This is the option #3 that we discussed. For this approach, the changes required are mainly on the runtime &amp;amp; rocksdb side, i.e., calculating fractions for operators with rocksdb states and reserve managed memory wrt the fractions, while no changes are needed on the python side. The concern for this approach is that, the required changes might be too significant for the release testing period.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;A feasible workaround is to make either RocksDB or Python not using managed memory. The workaround is &lt;b&gt;only needed when RocksDB &amp;amp; python are used together.&lt;/b&gt;&lt;/del&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;del&gt;For RocksDB, there&apos;s already a configuration option allowing user to enable/disable reserving managed memory. We only need to tell users to disable this switch when working together with Python and no code changes are needed. This is the option option #4 we discussed.&lt;/del&gt;&lt;/li&gt;
	&lt;li&gt;&lt;del&gt;For Python, I think the option #5 that Dian &amp;amp; Jincheng suggested is to introduce a similar switch for Python that allows users to enable/disable reserving managed memory. By default, Python still uses managed memory. The benefit for introducing this switch is to allow users to choose between RocksDB and Python for which managed memory is disabled.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;del&gt;One problem I see in option #5 is that, the default configuration does not work when RocksDB and Python UDF are used together. In that case, a meaningful error message is provided and users have to manually modify the configurations. But I think this is the right thing to do, that we admit there&apos;s a problem and provide a workaround to users, rather than trying to &quot;fix&quot; it in a way that may also affect other unproblematic use cases.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Nevermind. Seems I haven&apos;t understand your point correctly.&lt;/p&gt;</comment>
                            <comment id="17119450" author="dian.fu" created="Fri, 29 May 2020 09:48:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sunjincheng121&quot; class=&quot;user-hover&quot; rel=&quot;sunjincheng121&quot;&gt;sunjincheng121&lt;/a&gt;&#160;Do you think it makes sense to fix this issue in 1.11 by letting the&#160;Python worker to not use managed memory by default? This allows us to run Python worker in separate containers which are not managed by TM in the future. We could further discuss whether to change the memory management to allow both Python worker and RocksDB to use managed memory in the next release.&lt;/p&gt;</comment>
                            <comment id="17119453" author="sunjincheng121" created="Fri, 29 May 2020 09:52:37 +0000"  >&lt;p&gt;+1 from my points of view.&#160;&lt;/p&gt;</comment>
                            <comment id="17119880" author="stephanewen" created="Fri, 29 May 2020 19:21:53 +0000"  >&lt;p&gt;We could think about making the Python Processes the responsibility of the deployment framework.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The Kubernetes resource manager would deploy pods with multiple containers (one TM and multiple Python processes, one per slot for example).&lt;/li&gt;
	&lt;li&gt;The Yarn resource manager would ask for larger resource containers, to accommodate the additional memory that the python processes require.&lt;/li&gt;
	&lt;li&gt;In standalone, the machine simply needs to have enough memory, the same way as when starting a standalone session. It is the user&apos;s responsibility when they set up Flink.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In that case the managed memory would all go to RocksDB or to the batch algorithms.&lt;/p&gt;

&lt;p&gt;As hinted above, this probably needs a change that there is one Python process per TaskManager, or at least one Python process per slot. Then the deployment/resource manager can reason about this well. I am not sure what the implications of that change are for the Python language layer.&lt;/p&gt;</comment>
                            <comment id="17119883" author="stephanewen" created="Fri, 29 May 2020 19:23:52 +0000"  >&lt;p&gt;I think my suggestion from above is not a feasible for for 1.11.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dian.fu&quot; class=&quot;user-hover&quot; rel=&quot;dian.fu&quot;&gt;dian.fu&lt;/a&gt; changing Python to not use managed memory - would it still work on Yarn then? Or would we expect that the TM gets killed very often, for using too much memory?&lt;/p&gt;</comment>
                            <comment id="17119890" author="dian.fu" created="Fri, 29 May 2020 19:38:10 +0000"  >&lt;p&gt;We assume that the Python worker uses task off-heap memory in this case and so it will still work on YARN.&lt;/p&gt;</comment>
                            <comment id="17120728" author="xintongsong" created="Mon, 1 Jun 2020 02:50:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I&apos;m still trying to understand, what is the benefit of making Python processes the responsibility of the deployment framework.&lt;/p&gt;

&lt;p&gt;I&apos;m not saying this is not the right approach.&#160;I&apos;m asking because, I have several concerns on this approach. These concerns are probably resolvable,&#160;in one way or another. But first I would like to understand whether what we gain worth the efforts.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;1. The resources reserved for Python UDFs (python process containers on K8s, and the additional memory on Yarn) might be wasted in use cases without Python UDFs.&lt;/b&gt; I think one of the reasons we make RocksDB uses managed memory in FLIP-49 is that, we want the default configuration works for all use cases while not leaving part of the memory unused. As for Python, if we reserve resources by default, these resources will be wasted in non-python use cases. If we don&apos;t reserve resources by default, then the default configuration does not work for python use cases.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;2. Which component is responsible for managing lifecycles for Python Processes?&lt;/b&gt; Do we consider the python processes as part of the Flink framework? If so, the lifecycle of python processes should be decoupled from a job&apos;s lifecycle. If the user code does something wrong that makes the python process fail, Flink should be able to bring it back up. This could be achieved naturally on Kubernetes, but not on Yarn. On Yarn, once a container is started the YarnResourceManager can no longer start another process on it. We probably need to start another service in YarnTaskExecutorRunner to start/monitor/recover/stop the python processes. That sounds similarly to just have the TaskManager managing the Python processes.&lt;/p&gt;</comment>
                            <comment id="17123782" author="stephanewen" created="Tue, 2 Jun 2020 13:25:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt; Just for clarification: I am not saying that the Resource Manager is always responsible for launching the Python Process, but that the resources going to the Python process are planned by the ResourceManager, and not implictly reused from the TaskManager.&lt;/p&gt;

&lt;p&gt;But there is definitely an open question in how to handle the Python Process in the first place.&lt;br/&gt;
If we want to support the containerized Python processes on K8s, we need the resource manager to be aware of Python and change the deployment specification. The TM then does not need to do anything (just connect to an existing process). On Yarn, on the other hand, things are different. The RM only needs to increase the task offheap memory, the TM needs to launch the process.&lt;/p&gt;</comment>
                            <comment id="17123783" author="stephanewen" created="Tue, 2 Jun 2020 13:26:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dian.fu&quot; class=&quot;user-hover&quot; rel=&quot;dian.fu&quot;&gt;dian.fu&lt;/a&gt; Using Task off-heap memory is probably a good workaround for now.&lt;/p&gt;</comment>
                            <comment id="17124514" author="dian.fu" created="Wed, 3 Jun 2020 01:55:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt;&#160;Thanks for the confirmation.&#160;&lt;/p&gt;

&lt;p&gt;Merged to master via&#160;77e5494c1c252ba2dd458078380ee862fa423e4e and release-1.11 via c366ea690f75d809f7c7129c5341ca5b8062e6fc&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13319694">FLINK-18738</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 23 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0dtzw:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>