<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:56:48 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-22424] Writing to already released buffers potentially causing data corruption during job failover/cancellation</title>
                <link>https://issues.apache.org/jira/browse/FLINK-22424</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;I modified the code to not re-use the same memory segments, but on recycling always free up the segment. And what I have observed is a similar problem as reported in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-21181&quot; title=&quot;Buffer pool is destroyed error when outputting data over a timer after cancellation.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-21181&quot;&gt;&lt;del&gt;FLINK-21181&lt;/del&gt;&lt;/a&gt; ticket, but even more severe:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: java.lang.RuntimeException: segment has been freed
	at org.apache.flink.streaming.runtime.io.RecordWriterOutput.pushToRecordWriter(RecordWriterOutput.java:109)
	at org.apache.flink.streaming.runtime.io.RecordWriterOutput.collect(RecordWriterOutput.java:93)
	at org.apache.flink.streaming.runtime.io.RecordWriterOutput.collect(RecordWriterOutput.java:44)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50)
	at org.apache.flink.test.checkpointing.UnalignedCheckpointStressITCase$ReEmitAll.process(UnalignedCheckpointStressITCase.java:477)
	at org.apache.flink.test.checkpointing.UnalignedCheckpointStressITCase$ReEmitAll.process(UnalignedCheckpointStressITCase.java:468)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableProcessWindowFunction.process(InternalIterableProcessWindowFunction.java:57)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableProcessWindowFunction.process(InternalIterableProcessWindowFunction.java:32)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:577)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onProcessingTime(WindowOperator.java:533)
	at org.apache.flink.streaming.api.operators.InternalTimerServiceImpl.onProcessingTime(InternalTimerServiceImpl.java:284)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invokeProcessingTimeCallback(StreamTask.java:1395)
	... 11 more
Caused by: java.lang.IllegalStateException: segment has been freed
	at org.apache.flink.core.memory.MemorySegment.put(MemorySegment.java:483)
	at org.apache.flink.core.memory.MemorySegment.put(MemorySegment.java:1398)
	at org.apache.flink.runtime.io.network.buffer.BufferBuilder.append(BufferBuilder.java:100)
	at org.apache.flink.runtime.io.network.buffer.BufferBuilder.appendAndCommit(BufferBuilder.java:82)
	at org.apache.flink.runtime.io.network.partition.BufferWritingResultPartition.appendUnicastDataForNewRecord(BufferWritingResultPartition.java:250)
	at org.apache.flink.runtime.io.network.partition.BufferWritingResultPartition.emitRecord(BufferWritingResultPartition.java:142)
	at org.apache.flink.runtime.io.network.api.writer.RecordWriter.emit(RecordWriter.java:104)
	at org.apache.flink.runtime.io.network.api.writer.ChannelSelectorRecordWriter.emit(ChannelSelectorRecordWriter.java:54)
	at org.apache.flink.streaming.runtime.io.RecordWriterOutput.pushToRecordWriter(RecordWriterOutput.java:107)
	... 24 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;That&apos;s happening also during cancellation/job failover. It&apos;s failing when trying to write to already `free`&apos;ed up buffer. Without my changes, this code would silently write some data to a buffer that has already been recycled/returned to the pool. If someone else would pick up this buffer, it would easily lead to the data corruption.&lt;/p&gt;

&lt;p&gt;As far as I can tell, the exact reason behind this is that the buffer to which timer attempts to write to, has been released from `ResultSubpartition#onConsumedSubpartition`, causing `BufferConsumer` to be closed (which recycles/frees underlying memory segment ), while matching `BufferBuilder` is still being used...&lt;/p&gt;</description>
                <environment></environment>
        <key id="13374581">FLINK-22424</key>
            <summary>Writing to already released buffers potentially causing data corruption during job failover/cancellation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pnowojski">Piotr Nowojski</assignee>
                                    <reporter username="pnowojski">Piotr Nowojski</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 23 Apr 2021 07:38:45 +0000</created>
                <updated>Fri, 28 May 2021 11:06:06 +0000</updated>
                            <resolved>Fri, 30 Apr 2021 14:42:54 +0000</resolved>
                                    <version>1.6.4</version>
                    <version>1.7.2</version>
                    <version>1.8.3</version>
                    <version>1.9.3</version>
                    <version>1.10.3</version>
                    <version>1.11.3</version>
                    <version>1.12.2</version>
                    <version>1.13.0</version>
                                    <fixVersion>1.11.4</fixVersion>
                    <fixVersion>1.14.0</fixVersion>
                    <fixVersion>1.13.1</fixVersion>
                    <fixVersion>1.12.4</fixVersion>
                                    <component>Runtime / Network</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="17330071" author="pnowojski" created="Fri, 23 Apr 2021 07:42:47 +0000"  >&lt;p&gt;As of now, I don&apos;t understand why is this issue popping up only from triggering processing timers. If that&apos;s the case, it would mean this issue is probably younger, and not affecting versions before 1.10.x or so.&lt;/p&gt;

&lt;p&gt;Also I think the impact might be only for setups when there is more than one job running on the same cluster.&lt;/p&gt;</comment>
                            <comment id="17330091" author="till.rohrmann" created="Fri, 23 Apr 2021 07:58:28 +0000"  >&lt;p&gt;Why would the problem only occur if multiple jobs run on the same cluster &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pnowojski&quot; class=&quot;user-hover&quot; rel=&quot;pnowojski&quot;&gt;pnowojski&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="17330105" author="pnowojski" created="Fri, 23 Apr 2021 08:01:40 +0000"  >&lt;p&gt;Because writing to those released memory segments happens only while the job is already being cancelled/failing. For this data corruption to be visible, another task, from another job (or different failover region?) would had to be present and keep running. And also that 2nd task would need to immediately acquire this just released buffer. So impact is limited.&lt;/p&gt;</comment>
                            <comment id="17330369" author="till.rohrmann" created="Fri, 23 Apr 2021 10:20:56 +0000"  >&lt;p&gt;Sorry for asking these stupid questions but are you sure about the fact that it needs a terminating job? What about a second &lt;tt&gt;Task&lt;/tt&gt; from the same job which is deployed to the TM where the first &lt;tt&gt;Task&lt;/tt&gt; just finished (e.g. when processing a bounded stream)?&lt;/p&gt;</comment>
                            <comment id="17330417" author="pnowojski" created="Fri, 23 Apr 2021 12:22:56 +0000"  >&lt;p&gt;Because if the first task is finished, it wouldn&apos;t be able to write anything and wouldn&apos;t be able to corrupt anything. So it can only happen during cancelation/failing over. For the bug to happen, downstream task must fail/cancel first and release subpartition view, while upstream task is keep writing more data.&lt;/p&gt;</comment>
                            <comment id="17330430" author="pnowojski" created="Fri, 23 Apr 2021 12:44:09 +0000"  >&lt;p&gt;One more finding. It appears that this bug affects only &lt;tt&gt;PipelinedResultPartition&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="17332007" author="pnowojski" created="Mon, 26 Apr 2021 11:01:40 +0000"  >&lt;p&gt;merged commit 19ca330 into apache:master&lt;br/&gt;
merged commit 2b7bb05a4db into release-1.12&lt;br/&gt;
merged commit 0c1af6c into apache:release-1.11&lt;/p&gt;</comment>
                            <comment id="17337432" author="pnowojski" created="Fri, 30 Apr 2021 14:42:54 +0000"  >&lt;p&gt;merged to release-1.13 as da26733e484 and 65319b256c8&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13355112">FLINK-21181</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 28 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0qdd4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>