<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:24:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-3466] Job might get stuck in restoreState() from HDFS due to interrupt</title>
                <link>https://issues.apache.org/jira/browse/FLINK-3466</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;A user reported the following issue with a failing job:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;10:46:09,223 WARN  org.apache.flink.runtime.taskmanager.Task                     - Task &lt;span class=&quot;code-quote&quot;&gt;&apos;XXX -&amp;gt; YYY (3/5)&apos;&lt;/span&gt; did not react to cancelling signal, but is stuck in method:
sun.misc.Unsafe.park(Native Method)
java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitUninterruptibly(AbstractQueuedSynchronizer.java:1979)
org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DfsClientShmManager.java:255)
org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager.allocSlot(DfsClientShmManager.java:434)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.allocShmSlot(ShortCircuitCache.java:1016)
org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:477)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:783)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:717)
org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:421)
org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:332)
org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:576)
org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:800)
org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:848)
java.io.DataInputStream.read(DataInputStream.java:149)
org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.read(HadoopDataInputStream.java:69)
java.io.ObjectInputStream$PeekInputStream.read(ObjectInputStream.java:2310)
java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2323)
java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
org.apache.flink.util.InstantiationUtil$ClassLoaderObjectInputStream.&amp;lt;init&amp;gt;(InstantiationUtil.java:55)
org.apache.flink.runtime.state.filesystem.FileSerializableStateHandle.getState(FileSerializableStateHandle.java:52)
org.apache.flink.runtime.state.filesystem.FileSerializableStateHandle.getState(FileSerializableStateHandle.java:35)
org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.restoreState(AbstractUdfStreamOperator.java:162)
org.apache.flink.streaming.runtime.tasks.StreamTask.restoreState(StreamTask.java:440)
org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:208)
org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;10:46:09,223 WARN  org.apache.flink.runtime.taskmanager.Task                     - Task &lt;span class=&quot;code-quote&quot;&gt;&apos;XXX -&amp;gt; YYY (3/5)&apos;&lt;/span&gt; did not react to cancelling signal, but is stuck in method:
java.lang.Throwable.fillInStackTrace(Native Method)
java.lang.Throwable.fillInStackTrace(Throwable.java:783)
java.lang.Throwable.&amp;lt;init&amp;gt;(Throwable.java:250)
java.lang.Exception.&amp;lt;init&amp;gt;(Exception.java:54)
java.lang.InterruptedException.&amp;lt;init&amp;gt;(InterruptedException.java:57)
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2038)
org.apache.hadoop.net.unix.DomainSocketWatcher.add(DomainSocketWatcher.java:325)
org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DfsClientShmManager.java:266)
org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager.allocSlot(DfsClientShmManager.java:434)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.allocShmSlot(ShortCircuitCache.java:1016)
org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:477)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:783)
org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:717)
org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:421)
org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:332)
org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:576)
org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:800)
org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:848)
java.io.DataInputStream.read(DataInputStream.java:149)
org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.read(HadoopDataInputStream.java:69)
java.io.ObjectInputStream$PeekInputStream.read(ObjectInputStream.java:2310)
java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2323)
java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
org.apache.flink.util.InstantiationUtil$ClassLoaderObjectInputStream.&amp;lt;init&amp;gt;(InstantiationUtil.java:55)
org.apache.flink.runtime.state.filesystem.FileSerializableStateHandle.getState(FileSerializableStateHandle.java:52)
org.apache.flink.runtime.state.filesystem.FileSerializableStateHandle.getState(FileSerializableStateHandle.java:35)
org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.restoreState(AbstractUdfStreamOperator.java:162)
org.apache.flink.streaming.runtime.tasks.StreamTask.restoreState(StreamTask.java:440)
org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:208)
org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The issue is most likely that the HDFS client gets stuck in the &quot;org.apache.flink.runtime.fs.hdfs.HadoopDataInputStream.read()&quot; call when it receives an interrupt.&lt;br/&gt;
By putting the call into a separate thread, the TaskInterrupt would not break the HadoopReadThread.&lt;/p&gt;

&lt;p&gt;The HadoopReadThread would stop eventually with an error or after the read operation has finished.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12941069">FLINK-3466</key>
            <summary>Job might get stuck in restoreState() from HDFS due to interrupt</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sewen">Stephan Ewen</assignee>
                                    <reporter username="rmetzger">Robert Metzger</reporter>
                        <labels>
                    </labels>
                <created>Mon, 22 Feb 2016 14:43:17 +0000</created>
                <updated>Mon, 27 Mar 2017 12:40:54 +0000</updated>
                            <resolved>Fri, 15 Jul 2016 15:24:24 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15375397" author="stephanewen" created="Wed, 13 Jul 2016 17:29:59 +0000"  >&lt;p&gt;Here is a Unit test that minimally reproduces getting stuck in interrupt sensitive state handles (like those reading from HDFS)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;InterruptSensitiveRestoreTest {

	&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; OneShotLatch IN_RESTORE_LATCH = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; OneShotLatch();

	@Test
	&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testRestoreWithInterrupt() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {

		Configuration taskConfig = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration();
		StreamConfig cfg = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StreamConfig(taskConfig);
		cfg.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);

		TaskDeploymentDescriptor tdd = createTaskDeploymentDescriptor(taskConfig, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; InterruptLockingStateHandle());
		Task task = createTask(tdd);

		&lt;span class=&quot;code-comment&quot;&gt;// start the task and wait until it is in &lt;span class=&quot;code-quote&quot;&gt;&quot;restore&quot;&lt;/span&gt;
&lt;/span&gt;		task.startTaskThread();
		IN_RESTORE_LATCH.await();

		&lt;span class=&quot;code-comment&quot;&gt;// trigger cancellation and signal to &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt;
&lt;/span&gt;		task.cancelExecution();

		task.getExecutingThread().join(30000);

		&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (task.getExecutionState() == ExecutionState.CANCELING) {
			fail(&lt;span class=&quot;code-quote&quot;&gt;&quot;Task is stuck and not canceling&quot;&lt;/span&gt;);
		}

		assertEquals(ExecutionState.CANCELED, task.getExecutionState());
		assertNull(task.getFailureCause());
	}

	&lt;span class=&quot;code-comment&quot;&gt;// ------------------------------------------------------------------------
&lt;/span&gt;	&lt;span class=&quot;code-comment&quot;&gt;//  Utilities
&lt;/span&gt;	&lt;span class=&quot;code-comment&quot;&gt;// ------------------------------------------------------------------------
&lt;/span&gt;
	&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; TaskDeploymentDescriptor createTaskDeploymentDescriptor(
			Configuration taskConfig,
			StateHandle&amp;lt;?&amp;gt; state) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
		&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TaskDeploymentDescriptor(
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; JobID(),
				&lt;span class=&quot;code-quote&quot;&gt;&quot;test job name&quot;&lt;/span&gt;,
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; JobVertexID(),
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ExecutionAttemptID(),
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SerializedValue&amp;lt;&amp;gt;(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ExecutionConfig()),
				&lt;span class=&quot;code-quote&quot;&gt;&quot;test task name&quot;&lt;/span&gt;,
				0, 1, 0,
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(),
				taskConfig,
				SourceStreamTask.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;getName(),
				Collections.&amp;lt;ResultPartitionDeploymentDescriptor&amp;gt;emptyList(),
				Collections.&amp;lt;InputGateDeploymentDescriptor&amp;gt;emptyList(),
				Collections.&amp;lt;BlobKey&amp;gt;emptyList(),
				Collections.&amp;lt;URL&amp;gt;emptyList(),
				0,
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SerializedValue&amp;lt;StateHandle&amp;lt;?&amp;gt;&amp;gt;(state));
	}
	
	&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; Task createTask(TaskDeploymentDescriptor tdd) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
		&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Task(
				tdd,
				mock(MemoryManager.class),
				mock(IOManager.class),
				mock(NetworkEnvironment.class),
				mock(BroadcastVariableManager.class),
				mock(ActorGateway.class),
				mock(ActorGateway.class),
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FiniteDuration(10, TimeUnit.SECONDS),
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FallbackLibraryCacheManager(),
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FileCache(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration()),
				&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TaskManagerRuntimeInfo(
						&lt;span class=&quot;code-quote&quot;&gt;&quot;localhost&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Configuration(), EnvironmentInformation.getTemporaryFileDirectory()),
				mock(TaskMetricGroup.class));
		
	}

	@SuppressWarnings(&lt;span class=&quot;code-quote&quot;&gt;&quot;serial&quot;&lt;/span&gt;)
	&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;InterruptLockingStateHandle &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; StreamTaskStateList {

		&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; InterruptLockingStateHandle() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
			&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StreamTaskState[0]);
		}

		@Override
		&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; StreamTaskState[] getState(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt; userCodeClassLoader) {
			IN_RESTORE_LATCH.trigger();
			
			&lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; mimics what happens in the HDFS client code.
&lt;/span&gt;			&lt;span class=&quot;code-comment&quot;&gt;// an interrupt on a waiting object leads to an infinite loop
&lt;/span&gt;			&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
				&lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
					wait();
				}
			}
			&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException e) {
				&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) {
					&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
						&lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
							wait();
						}
					} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException ignored) {}
				}
			}
			
			&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;.getState(userCodeClassLoader);
		}
	}
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15378350" author="githubbot" created="Thu, 14 Jul 2016 20:50:34 +0000"  >&lt;p&gt;GitHub user StephanEwen opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-3466&quot; title=&quot;Job might get stuck in restoreState() from HDFS due to interrupt&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-3466&quot;&gt;&lt;del&gt;FLINK-3466&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;runtime&amp;#93;&lt;/span&gt; Cancel state handled on state restore&lt;/p&gt;

&lt;p&gt;    This pull request fixes the issue that state restore operations can get stuck when tasks are cancelled during state restore. That happens due to a bug in HDFS, which deadlocks (or livelocks) when the reading thread is interrupted.&lt;/p&gt;

&lt;p&gt;    This introduces two things:&lt;/p&gt;

&lt;p&gt;      1. All state handles and key/value snapshots are now `Closable`. This does not delete any checkpoint data, but simply closes pending streams and data fetch handles. Operations concurrently accessing the state handles state should fail.&lt;/p&gt;

&lt;p&gt;      2. The `StreamTask` holds a set of &quot;Closables&quot; that it closes upon cancellation. This is a cleaner way of stopping in-progress work than relying on &quot;interrupt()&quot; to interrupt that work.&lt;/p&gt;

&lt;p&gt;    This mechanism should eventually be extended to also cancel operators and state handles pending asynchronous materialization.&lt;/p&gt;

&lt;p&gt;    There is a test that has an interrupt sensitive state handle (mimicking HDFS&apos;s deadlock behavior) that causes a stall without this pull request and cleanly finishes with the changes in this pull request.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/StephanEwen/incubator-flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/StephanEwen/incubator-flink&lt;/a&gt; state_handle_cancellation&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2252&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 224503b86c2864f604a7c519ea5f415c57f35ff3&lt;br/&gt;
Author: Stephan Ewen &amp;lt;sewen@apache.org&amp;gt;&lt;br/&gt;
Date:   2016-07-14T13:14:12Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-3466&quot; title=&quot;Job might get stuck in restoreState() from HDFS due to interrupt&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-3466&quot;&gt;&lt;del&gt;FLINK-3466&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;tests&amp;#93;&lt;/span&gt; Add serialization validation for state handles&lt;/p&gt;

&lt;p&gt;commit c411b379381ab1390e2166356232a33165c1abd9&lt;br/&gt;
Author: Stephan Ewen &amp;lt;sewen@apache.org&amp;gt;&lt;br/&gt;
Date:   2016-07-13T19:32:40Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-3466&quot; title=&quot;Job might get stuck in restoreState() from HDFS due to interrupt&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-3466&quot;&gt;&lt;del&gt;FLINK-3466&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;runtime&amp;#93;&lt;/span&gt; Make state handles cancelable.&lt;/p&gt;

&lt;p&gt;    State handles are cancelable, to make sure long running checkpoint restore operations do&lt;br/&gt;
    finish early on cancallation, even if the code does not properly react to interrupts.&lt;/p&gt;

&lt;p&gt;    This is especially important since HDFS client code is so buggy that it deadlocks when&lt;br/&gt;
    interrupted without closing.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15379078" author="githubbot" created="Fri, 15 Jul 2016 09:12:42 +0000"  >&lt;p&gt;Github user uce commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70943314&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70943314&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractCloseableHandle.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,131 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.runtime.state;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.Closeable;&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.io.Serializable;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * A simple base for closable handles.&lt;br/&gt;
    + * &lt;br/&gt;
    + * Offers to register a stream (or other closable object) that close calls are delegated to if&lt;br/&gt;
    + * the handel is closed or was already closed.&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    typo: handel =&amp;gt; handle&lt;/p&gt;</comment>
                            <comment id="15379086" author="githubbot" created="Fri, 15 Jul 2016 09:18:57 +0000"  >&lt;p&gt;Github user uce commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70944104&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70944104&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/AbstractFileStateHandle.java &amp;#8212;&lt;br/&gt;
    @@ -20,18 +20,21 @@&lt;/p&gt;

&lt;p&gt;     import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
     import org.apache.flink.core.fs.Path;&lt;br/&gt;
    +import org.apache.flink.runtime.state.AbstractCloseableHandle;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateObject;&lt;/p&gt;

&lt;p&gt;     import java.io.IOException;&lt;br/&gt;
    +import java.io.Serializable;&lt;/p&gt;

&lt;p&gt;     import static java.util.Objects.requireNonNull;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Base class for state that is stored in a file.&lt;br/&gt;
      */&lt;br/&gt;
    -public abstract class AbstractFileStateHandle implements java.io.Serializable {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;p&gt;    +public abstract class AbstractFileStateHandle extends AbstractCloseableHandle implements StateObject, Serializable {&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Makes no difference, but we can remove the `Serializable` here&lt;/p&gt;</comment>
                            <comment id="15379113" author="githubbot" created="Fri, 15 Jul 2016 09:34:36 +0000"  >&lt;p&gt;Github user uce commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70946219&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70946219&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/InterruptSensitiveRestoreTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,223 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.runtime.tasks;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.ExecutionConfig;&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.blob.BlobKey;&lt;br/&gt;
    +import org.apache.flink.runtime.broadcast.BroadcastVariableManager;&lt;br/&gt;
    +import org.apache.flink.runtime.deployment.InputGateDeploymentDescriptor;&lt;br/&gt;
    +import org.apache.flink.runtime.deployment.ResultPartitionDeploymentDescriptor;&lt;br/&gt;
    +import org.apache.flink.runtime.deployment.TaskDeploymentDescriptor;&lt;br/&gt;
    +import org.apache.flink.runtime.execution.ExecutionState;&lt;br/&gt;
    +import org.apache.flink.runtime.execution.librarycache.FallbackLibraryCacheManager;&lt;br/&gt;
    +import org.apache.flink.runtime.executiongraph.ExecutionAttemptID;&lt;br/&gt;
    +import org.apache.flink.runtime.filecache.FileCache;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.io.disk.iomanager.IOManager;&lt;br/&gt;
    +import org.apache.flink.runtime.io.network.NetworkEnvironment;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobVertexID;&lt;br/&gt;
    +import org.apache.flink.runtime.memory.MemoryManager;&lt;br/&gt;
    +import org.apache.flink.runtime.operators.testutils.UnregisteredTaskMetricsGroup;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateHandle;&lt;br/&gt;
    +import org.apache.flink.runtime.taskmanager.Task;&lt;br/&gt;
    +import org.apache.flink.runtime.taskmanager.TaskManagerRuntimeInfo;&lt;br/&gt;
    +import org.apache.flink.runtime.util.EnvironmentInformation;&lt;br/&gt;
    +import org.apache.flink.runtime.util.SerializableObject;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.Checkpointed;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.graph.StreamConfig;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.StreamSource;&lt;br/&gt;
    +import org.apache.flink.util.SerializedValue;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.io.Serializable;&lt;br/&gt;
    +import java.net.URL;&lt;br/&gt;
    +import java.util.Collections;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.*;&lt;br/&gt;
    +import static org.mockito.Mockito.*;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * This test checks that task restores that get stuck in the presence of interrupts&lt;br/&gt;
    + * are handled properly.&lt;br/&gt;
    + *&lt;br/&gt;
    + * In practice, reading from HDFS is interrupt sensitive: The HDFS code frequently deadlocks&lt;br/&gt;
    + * or livelocks if it is interrupted.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class InterruptSensitiveRestoreTest {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final OneShotLatch IN_RESTORE_LATCH = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testRestoreWithInterrupt() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		Configuration taskConfig = new Configuration();&lt;br/&gt;
    +		StreamConfig cfg = new StreamConfig(taskConfig);&lt;br/&gt;
    +		cfg.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);&lt;br/&gt;
    +		cfg.setStreamOperator(new StreamSource&amp;lt;&amp;gt;(new TestSource()));&lt;br/&gt;
    +&lt;br/&gt;
    +		StateHandle&amp;lt;Serializable&amp;gt; lockingHandle = new InterruptLockingStateHandle();&lt;br/&gt;
    +		StreamTaskState opState = new StreamTaskState();&lt;br/&gt;
    +		opState.setFunctionState(lockingHandle);&lt;br/&gt;
    +		StreamTaskStateList taskState = new StreamTaskStateList(new StreamTaskState[] &lt;/p&gt;
{ opState }
&lt;p&gt;);&lt;br/&gt;
    +&lt;br/&gt;
    +		TaskDeploymentDescriptor tdd = createTaskDeploymentDescriptor(taskConfig, taskState);&lt;br/&gt;
    +		Task task = createTask(tdd);&lt;br/&gt;
    +&lt;br/&gt;
    +		// start the task and wait until it is in &quot;restore&quot;&lt;br/&gt;
    +		task.startTaskThread();&lt;br/&gt;
    +		IN_RESTORE_LATCH.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// trigger cancellation and signal to continue&lt;br/&gt;
    +		task.cancelExecution();&lt;br/&gt;
    +&lt;br/&gt;
    +		task.getExecutingThread().join(30000);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think there is a race in the test: if the task is interrupted before entering the first wait, it will just wait there until the 30 seconds are over and the test will fail.&lt;/p&gt;</comment>
                            <comment id="15379121" author="githubbot" created="Fri, 15 Jul 2016 09:40:16 +0000"  >&lt;p&gt;Github user uce commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70946878&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70946878&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/AbstractMemStateSnapshot.java &amp;#8212;&lt;br/&gt;
    @@ -54,6 +56,8 @@&lt;/p&gt;

&lt;p&gt;     	/** The serialized data of the state key/value pairs */&lt;br/&gt;
     	private final byte[] data;&lt;br/&gt;
    +	&lt;br/&gt;
    +	private transient boolean closed;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Missing `volatile`?&lt;/p&gt;</comment>
                            <comment id="15379124" author="githubbot" created="Fri, 15 Jul 2016 09:42:36 +0000"  >&lt;p&gt;Github user uce commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Looks very good! The test failures seem unrelated:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ClientTest: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4220&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-4220&lt;/a&gt; (newly created)&lt;/li&gt;
	&lt;li&gt;JobManagerHACheckpointRecoveryITCase: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-3516&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-3516&lt;/a&gt; (known instability)&lt;/li&gt;
	&lt;li&gt;Travis Scala dependency issue&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    The added tests and refactorings are very readable.&lt;/p&gt;

&lt;p&gt;    I think this is good to merge mod some minor inline comments.&lt;/p&gt;</comment>
                            <comment id="15379245" author="githubbot" created="Fri, 15 Jul 2016 11:09:34 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70956526&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70956526&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/AbstractMemStateSnapshot.java &amp;#8212;&lt;br/&gt;
    @@ -54,6 +56,8 @@&lt;/p&gt;

&lt;p&gt;     	/** The serialized data of the state key/value pairs */&lt;br/&gt;
     	private final byte[] data;&lt;br/&gt;
    +	&lt;br/&gt;
    +	private transient boolean closed;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think it is not crucial to have a strict barrier here. If the reading thread eventually notices the flag, it is enough. And since volatile accesses are much more expensive, I wanted to avoid that.&lt;/p&gt;</comment>
                            <comment id="15379247" author="githubbot" created="Fri, 15 Jul 2016 11:13:04 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70956813&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70956813&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/InterruptSensitiveRestoreTest.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,223 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.streaming.runtime.tasks;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.ExecutionConfig;&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.blob.BlobKey;&lt;br/&gt;
    +import org.apache.flink.runtime.broadcast.BroadcastVariableManager;&lt;br/&gt;
    +import org.apache.flink.runtime.deployment.InputGateDeploymentDescriptor;&lt;br/&gt;
    +import org.apache.flink.runtime.deployment.ResultPartitionDeploymentDescriptor;&lt;br/&gt;
    +import org.apache.flink.runtime.deployment.TaskDeploymentDescriptor;&lt;br/&gt;
    +import org.apache.flink.runtime.execution.ExecutionState;&lt;br/&gt;
    +import org.apache.flink.runtime.execution.librarycache.FallbackLibraryCacheManager;&lt;br/&gt;
    +import org.apache.flink.runtime.executiongraph.ExecutionAttemptID;&lt;br/&gt;
    +import org.apache.flink.runtime.filecache.FileCache;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.io.disk.iomanager.IOManager;&lt;br/&gt;
    +import org.apache.flink.runtime.io.network.NetworkEnvironment;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobVertexID;&lt;br/&gt;
    +import org.apache.flink.runtime.memory.MemoryManager;&lt;br/&gt;
    +import org.apache.flink.runtime.operators.testutils.UnregisteredTaskMetricsGroup;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateHandle;&lt;br/&gt;
    +import org.apache.flink.runtime.taskmanager.Task;&lt;br/&gt;
    +import org.apache.flink.runtime.taskmanager.TaskManagerRuntimeInfo;&lt;br/&gt;
    +import org.apache.flink.runtime.util.EnvironmentInformation;&lt;br/&gt;
    +import org.apache.flink.runtime.util.SerializableObject;&lt;br/&gt;
    +import org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.Checkpointed;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.graph.StreamConfig;&lt;br/&gt;
    +import org.apache.flink.streaming.api.operators.StreamSource;&lt;br/&gt;
    +import org.apache.flink.util.SerializedValue;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.io.Serializable;&lt;br/&gt;
    +import java.net.URL;&lt;br/&gt;
    +import java.util.Collections;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.junit.Assert.*;&lt;br/&gt;
    +import static org.mockito.Mockito.*;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * This test checks that task restores that get stuck in the presence of interrupts&lt;br/&gt;
    + * are handled properly.&lt;br/&gt;
    + *&lt;br/&gt;
    + * In practice, reading from HDFS is interrupt sensitive: The HDFS code frequently deadlocks&lt;br/&gt;
    + * or livelocks if it is interrupted.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class InterruptSensitiveRestoreTest {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final OneShotLatch IN_RESTORE_LATCH = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testRestoreWithInterrupt() throws Exception {&lt;br/&gt;
    +&lt;br/&gt;
    +		Configuration taskConfig = new Configuration();&lt;br/&gt;
    +		StreamConfig cfg = new StreamConfig(taskConfig);&lt;br/&gt;
    +		cfg.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);&lt;br/&gt;
    +		cfg.setStreamOperator(new StreamSource&amp;lt;&amp;gt;(new TestSource()));&lt;br/&gt;
    +&lt;br/&gt;
    +		StateHandle&amp;lt;Serializable&amp;gt; lockingHandle = new InterruptLockingStateHandle();&lt;br/&gt;
    +		StreamTaskState opState = new StreamTaskState();&lt;br/&gt;
    +		opState.setFunctionState(lockingHandle);&lt;br/&gt;
    +		StreamTaskStateList taskState = new StreamTaskStateList(new StreamTaskState[] &lt;/p&gt;
{ opState }
&lt;p&gt;);&lt;br/&gt;
    +&lt;br/&gt;
    +		TaskDeploymentDescriptor tdd = createTaskDeploymentDescriptor(taskConfig, taskState);&lt;br/&gt;
    +		Task task = createTask(tdd);&lt;br/&gt;
    +&lt;br/&gt;
    +		// start the task and wait until it is in &quot;restore&quot;&lt;br/&gt;
    +		task.startTaskThread();&lt;br/&gt;
    +		IN_RESTORE_LATCH.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// trigger cancellation and signal to continue&lt;br/&gt;
    +		task.cancelExecution();&lt;br/&gt;
    +&lt;br/&gt;
    +		task.getExecutingThread().join(30000);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think it should not be a race. On interruption, the thread&apos;s &apos;interrupt&apos; flag will be set and, upon entering `wait()`, it should immediately throw an `InterruptedException`.&lt;/p&gt;

&lt;p&gt;    Also, the cancellation sends periodic interrupts.&lt;/p&gt;</comment>
                            <comment id="15379248" author="githubbot" created="Fri, 15 Jul 2016 11:13:16 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70956828&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70956828&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/state/AbstractCloseableHandle.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,131 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.runtime.state;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.Closeable;&lt;br/&gt;
    +import java.io.IOException;&lt;br/&gt;
    +import java.io.Serializable;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * A simple base for closable handles.&lt;br/&gt;
    + * &lt;br/&gt;
    + * Offers to register a stream (or other closable object) that close calls are delegated to if&lt;br/&gt;
    + * the handel is closed or was already closed.&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Thanks, will fix it.&lt;/p&gt;</comment>
                            <comment id="15379249" author="githubbot" created="Fri, 15 Jul 2016 11:13:26 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252#discussion_r70956861&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252#discussion_r70956861&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/AbstractFileStateHandle.java &amp;#8212;&lt;br/&gt;
    @@ -20,18 +20,21 @@&lt;/p&gt;

&lt;p&gt;     import org.apache.flink.core.fs.FileSystem;&lt;br/&gt;
     import org.apache.flink.core.fs.Path;&lt;br/&gt;
    +import org.apache.flink.runtime.state.AbstractCloseableHandle;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateObject;&lt;/p&gt;

&lt;p&gt;     import java.io.IOException;&lt;br/&gt;
    +import java.io.Serializable;&lt;/p&gt;

&lt;p&gt;     import static java.util.Objects.requireNonNull;&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Base class for state that is stored in a file.&lt;br/&gt;
      */&lt;br/&gt;
    -public abstract class AbstractFileStateHandle implements java.io.Serializable {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;p&gt;    +public abstract class AbstractFileStateHandle extends AbstractCloseableHandle implements StateObject, Serializable {&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    True, will remove this.&lt;/p&gt;</comment>
                            <comment id="15379270" author="githubbot" created="Fri, 15 Jul 2016 11:38:00 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks, I&apos;ll address your comments and merge this...&lt;/p&gt;</comment>
                            <comment id="15379552" author="githubbot" created="Fri, 15 Jul 2016 15:23:22 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Manually merged in e9f660d1ff5540c7ef829f2de5bb870b787c18b7&lt;/p&gt;</comment>
                            <comment id="15379553" author="githubbot" created="Fri, 15 Jul 2016 15:23:22 +0000"  >&lt;p&gt;Github user StephanEwen closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15379554" author="stephanewen" created="Fri, 15 Jul 2016 15:24:24 +0000"  >&lt;p&gt;Fixed in e9f660d1ff5540c7ef829f2de5bb870b787c18b7&lt;/p&gt;</comment>
                            <comment id="15937040" author="githubbot" created="Wed, 22 Mar 2017 20:11:03 +0000"  >&lt;p&gt;Github user liuml07 commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Is this related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-14214?&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-14214?&lt;/a&gt; Thanks,&lt;/p&gt;</comment>
                            <comment id="15943177" author="githubbot" created="Mon, 27 Mar 2017 12:40:54 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2252&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I think it is yes. We worked around it in the meantime...&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13058378">HADOOP-14214</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 34 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2t5rj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>