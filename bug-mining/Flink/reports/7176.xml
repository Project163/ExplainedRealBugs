<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:18:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-32731] SqlGatewayE2ECase.testHiveServer2ExecuteStatement failed due to MetaException</title>
                <link>https://issues.apache.org/jira/browse/FLINK-32731</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=51891&amp;amp;view=logs&amp;amp;j=fb37c667-81b7-5c22-dd91-846535e99a97&amp;amp;t=011e961e-597c-5c96-04fe-7941c8b83f23&amp;amp;l=10987&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=51891&amp;amp;view=logs&amp;amp;j=fb37c667-81b7-5c22-dd91-846535e99a97&amp;amp;t=011e961e-597c-5c96-04fe-7941c8b83f23&amp;amp;l=10987&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Aug 02 02:14:04 02:14:04.957 [ERROR] Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 198.658 s &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.flink.table.gateway.SqlGatewayE2ECase
Aug 02 02:14:04 02:14:04.966 [ERROR] org.apache.flink.table.gateway.SqlGatewayE2ECase.testHiveServer2ExecuteStatement  Time elapsed: 31.437 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
Aug 02 02:14:04 java.util.concurrent.ExecutionException: 
Aug 02 02:14:04 java.sql.SQLException: org.apache.flink.table.gateway.service.utils.SqlExecutionException: Failed to execute the operation d440e6e7-0fed-49c9-933e-c7be5bbae50d.
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager$Operation.processThrowable(OperationManager.java:414)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager$Operation.lambda$run$0(OperationManager.java:267)
Aug 02 02:14:04 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
Aug 02 02:14:04 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
Aug 02 02:14:04 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
Aug 02 02:14:04 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
Aug 02 02:14:04 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
Aug 02 02:14:04 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
Aug 02 02:14:04 	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:750)
Aug 02 02:14:04 Caused by: org.apache.flink.table.api.TableException: Could not execute CreateTable in path `hive`.`&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;`.`CsvTable`
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.execute(CatalogManager.java:1289)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.createTable(CatalogManager.java:939)
Aug 02 02:14:04 	at org.apache.flink.table.operations.ddl.CreateTableOperation.execute(CreateTableOperation.java:84)
Aug 02 02:14:04 	at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1080)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationExecutor.callOperation(OperationExecutor.java:570)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationExecutor.executeOperation(OperationExecutor.java:458)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationExecutor.executeStatement(OperationExecutor.java:210)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.SqlGatewayServiceImpl.lambda$executeStatement$1(SqlGatewayServiceImpl.java:212)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager.lambda$submitOperation$1(OperationManager.java:119)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager$Operation.lambda$run$0(OperationManager.java:258)
Aug 02 02:14:04 	... 7 more
Aug 02 02:14:04 Caused by: org.apache.flink.table.catalog.exceptions.CatalogException: Failed to create table &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.CsvTable
Aug 02 02:14:04 	at org.apache.flink.table.catalog.hive.HiveCatalog.createTable(HiveCatalog.java:547)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.lambda$createTable$16(CatalogManager.java:950)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.execute(CatalogManager.java:1283)
Aug 02 02:14:04 	... 16 more
Aug 02 02:14:04 Caused by: MetaException(message:Got exception: java.net.ConnectException Call From 70d5c7217fe8/172.17.0.2 to hadoop-master:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http:&lt;span class=&quot;code-comment&quot;&gt;//wiki.apache.org/hadoop/ConnectionRefused)
&lt;/span&gt;Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42225)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42193)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result.read(ThriftHiveMetastore.java:42119)
Aug 02 02:14:04 	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:86)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_table_with_environment_context(ThriftHiveMetastore.java:1203)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_table_with_environment_context(ThriftHiveMetastore.java:1189)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table_with_environment_context(HiveMetaStoreClient.java:2396)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:750)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:738)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
Aug 02 02:14:04 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Aug 02 02:14:04 	at java.lang.reflect.Method.invoke(Method.java:498)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:169)
Aug 02 02:14:04 	at com.sun.proxy.$Proxy26.createTable(Unknown Source)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
Aug 02 02:14:04 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Aug 02 02:14:04 	at java.lang.reflect.Method.invoke(Method.java:498)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2327)
Aug 02 02:14:04 	at com.sun.proxy.$Proxy26.createTable(Unknown Source)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.hive.client.HiveMetastoreClientWrapper.createTable(HiveMetastoreClientWrapper.java:174)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.hive.HiveCatalog.createTable(HiveCatalog.java:539)
Aug 02 02:14:04 	... 18 more
Aug 02 02:14:04 
Aug 02 02:14:04 	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
Aug 02 02:14:04 	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
Aug 02 02:14:04 	at org.apache.flink.tests.util.flink.FlinkDistribution.submitSQL(FlinkDistribution.java:341)
Aug 02 02:14:04 	at org.apache.flink.tests.util.flink.FlinkDistribution.submitSQLJob(FlinkDistribution.java:281)
Aug 02 02:14:04 	at org.apache.flink.tests.util.flink.LocalStandaloneFlinkResource$GatewayClusterControllerImpl.submitSQLJob(LocalStandaloneFlinkResource.java:220)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.SqlGatewayE2ECase.executeStatement(SqlGatewayE2ECase.java:133)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.SqlGatewayE2ECase.testHiveServer2ExecuteStatement(SqlGatewayE2ECase.java:107)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
Aug 02 02:14:04 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Aug 02 02:14:04 	at java.lang.reflect.Method.invoke(Method.java:498)
Aug 02 02:14:04 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
Aug 02 02:14:04 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
Aug 02 02:14:04 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
Aug 02 02:14:04 	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
Aug 02 02:14:04 	at org.apache.flink.util.ExternalResource$1.evaluate(ExternalResource.java:48)
Aug 02 02:14:04 	at org.apache.flink.util.TestNameProvider$1.evaluate(TestNameProvider.java:45)
Aug 02 02:14:04 	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
Aug 02 02:14:04 	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
Aug 02 02:14:04 	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
Aug 02 02:14:04 	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
Aug 02 02:14:04 	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
Aug 02 02:14:04 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
Aug 02 02:14:04 	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)
Aug 02 02:14:04 	at org.testcontainers.containers.FailureDetectingExternalResource$1.evaluate(FailureDetectingExternalResource.java:29)
Aug 02 02:14:04 	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
Aug 02 02:14:04 	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
Aug 02 02:14:04 	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
Aug 02 02:14:04 	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
Aug 02 02:14:04 	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:42)
Aug 02 02:14:04 	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:80)
Aug 02 02:14:04 	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:72)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
Aug 02 02:14:04 	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
Aug 02 02:14:04 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
Aug 02 02:14:04 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
Aug 02 02:14:04 	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
Aug 02 02:14:04 	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
Aug 02 02:14:04 	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
Aug 02 02:14:04 	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
Aug 02 02:14:04 	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
Aug 02 02:14:04 Caused by: java.sql.SQLException: org.apache.flink.table.gateway.service.utils.SqlExecutionException: Failed to execute the operation d440e6e7-0fed-49c9-933e-c7be5bbae50d.
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager$Operation.processThrowable(OperationManager.java:414)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager$Operation.lambda$run$0(OperationManager.java:267)
Aug 02 02:14:04 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
Aug 02 02:14:04 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
Aug 02 02:14:04 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
Aug 02 02:14:04 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
Aug 02 02:14:04 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
Aug 02 02:14:04 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
Aug 02 02:14:04 	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:750)
Aug 02 02:14:04 Caused by: org.apache.flink.table.api.TableException: Could not execute CreateTable in path `hive`.`&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;`.`CsvTable`
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.execute(CatalogManager.java:1289)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.createTable(CatalogManager.java:939)
Aug 02 02:14:04 	at org.apache.flink.table.operations.ddl.CreateTableOperation.execute(CreateTableOperation.java:84)
Aug 02 02:14:04 	at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1080)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationExecutor.callOperation(OperationExecutor.java:570)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationExecutor.executeOperation(OperationExecutor.java:458)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationExecutor.executeStatement(OperationExecutor.java:210)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.SqlGatewayServiceImpl.lambda$executeStatement$1(SqlGatewayServiceImpl.java:212)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager.lambda$submitOperation$1(OperationManager.java:119)
Aug 02 02:14:04 	at org.apache.flink.table.gateway.service.operation.OperationManager$Operation.lambda$run$0(OperationManager.java:258)
Aug 02 02:14:04 	... 7 more
Aug 02 02:14:04 Caused by: org.apache.flink.table.catalog.exceptions.CatalogException: Failed to create table &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.CsvTable
Aug 02 02:14:04 	at org.apache.flink.table.catalog.hive.HiveCatalog.createTable(HiveCatalog.java:547)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.lambda$createTable$16(CatalogManager.java:950)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.CatalogManager.execute(CatalogManager.java:1283)
Aug 02 02:14:04 	... 16 more
Aug 02 02:14:04 Caused by: MetaException(message:Got exception: java.net.ConnectException Call From 70d5c7217fe8/172.17.0.2 to hadoop-master:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http:&lt;span class=&quot;code-comment&quot;&gt;//wiki.apache.org/hadoop/ConnectionRefused)
&lt;/span&gt;Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42225)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42193)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result.read(ThriftHiveMetastore.java:42119)
Aug 02 02:14:04 	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:86)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_table_with_environment_context(ThriftHiveMetastore.java:1203)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_table_with_environment_context(ThriftHiveMetastore.java:1189)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table_with_environment_context(HiveMetaStoreClient.java:2396)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:750)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:738)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
Aug 02 02:14:04 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Aug 02 02:14:04 	at java.lang.reflect.Method.invoke(Method.java:498)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:169)
Aug 02 02:14:04 	at com.sun.proxy.$Proxy26.createTable(Unknown Source)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Aug 02 02:14:04 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
Aug 02 02:14:04 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Aug 02 02:14:04 	at java.lang.reflect.Method.invoke(Method.java:498)
Aug 02 02:14:04 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2327)
Aug 02 02:14:04 	at com.sun.proxy.$Proxy26.createTable(Unknown Source)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.hive.client.HiveMetastoreClientWrapper.createTable(HiveMetastoreClientWrapper.java:174)
Aug 02 02:14:04 	at org.apache.flink.table.catalog.hive.HiveCatalog.createTable(HiveCatalog.java:539)
Aug 02 02:14:04 	... 18 more
Aug 02 02:14:04 
Aug 02 02:14:04 	at org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:385)
Aug 02 02:14:04 	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:254)
Aug 02 02:14:04 	at org.apache.flink.tests.util.flink.FlinkDistribution.lambda$submitSQLJob$6(FlinkDistribution.java:293)
Aug 02 02:14:04 	at org.apache.flink.util.function.FunctionUtils.lambda$asCallable$5(FunctionUtils.java:126)
Aug 02 02:14:04 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
Aug 02 02:14:04 	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:750)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13545797">FLINK-32731</key>
            <summary>SqlGatewayE2ECase.testHiveServer2ExecuteStatement failed due to MetaException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="fsk119">Shengkai Fang</assignee>
                                    <reporter username="mapohl">Matthias Pohl</reporter>
                        <labels>
                            <label>pull-request-available</label>
                            <label>test-stability</label>
                    </labels>
                <created>Wed, 2 Aug 2023 06:51:40 +0000</created>
                <updated>Thu, 2 Nov 2023 13:30:54 +0000</updated>
                            <resolved>Tue, 12 Sep 2023 07:23:30 +0000</resolved>
                                    <version>1.18.0</version>
                                    <fixVersion>1.18.0</fixVersion>
                    <fixVersion>1.19.0</fixVersion>
                                    <component>Table SQL / Gateway</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17750143" author="mapohl" created="Wed, 2 Aug 2023 06:53:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fsk119&quot; class=&quot;user-hover&quot; rel=&quot;fsk119&quot;&gt;fsk119&lt;/a&gt; can you look at this issue or delegate it to the right person. This seems to be a new problem. Feel free to lower the priority if you think it shouldn&apos;t block the release.&lt;/p&gt;</comment>
                            <comment id="17751683" author="fsk119" created="Mon, 7 Aug 2023 13:47:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mapohl&quot; class=&quot;user-hover&quot; rel=&quot;mapohl&quot;&gt;mapohl&lt;/a&gt; hi. I think the failed test is because the test failed to start the hive container. We can find the container has the following message:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
02:13:03,693 [docker-java-stream--148018928] INFO  org.apache.flink.table.gateway.containers.HiveContainer      [] - STDOUT: 2023-08-02 07:58:03,693 INFO gave up: hdfs-namenode entered FATAL state, too many start retries too quickly
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Because it&apos;s just a test issue and the current information doesn&apos;t help us to understand why namenode fails to start up, I think can reduce the priority. I will open a PR to back up the namenode and metastore logs when test fails again.&lt;/p&gt;
</comment>
                            <comment id="17752306" author="fsk119" created="Wed, 9 Aug 2023 07:46:57 +0000"  >&lt;p&gt;Merged into master: 5654eb798c744c924aff93d68ec3c4e413e75232 &lt;/p&gt;

&lt;p&gt;Waiting for more details.&lt;/p&gt;</comment>
                            <comment id="17753955" author="sergey nuyanzin" created="Mon, 14 Aug 2023 08:58:43 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fsk119&quot; class=&quot;user-hover&quot; rel=&quot;fsk119&quot;&gt;fsk119&lt;/a&gt;&lt;br/&gt;
it seems there is another reproduction on AZP&lt;br/&gt;
&lt;a href=&quot;https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=52200&amp;amp;view=logs&amp;amp;j=af184cdd-c6d8-5084-0b69-7e9c67b35f7a&amp;amp;t=0f3adb59-eefa-51c6-2858-3654d9e0749d&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://dev.azure.com/apache-flink/apache-flink/_build/results?buildId=52200&amp;amp;view=logs&amp;amp;j=af184cdd-c6d8-5084-0b69-7e9c67b35f7a&amp;amp;t=0f3adb59-eefa-51c6-2858-3654d9e0749d&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Aug 11 12:11:05 Caused by: MetaException(message:Got exception: java.net.ConnectException Call From 2c2d0325a890/172.17.0.2 to hadoop-master:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42225)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result$create_table_with_environment_context_resultStandardScheme.read(ThriftHiveMetastore.java:42193)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$create_table_with_environment_context_result.read(ThriftHiveMetastore.java:42119)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_table_with_environment_context(ThriftHiveMetastore.java:1189)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.create_table_with_environment_context(HiveMetaStoreClient.java:2396)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:750)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:738)
Aug 11 12:11:05 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Aug 11 12:11:05 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
Aug 11 12:11:05 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Aug 11 12:11:05 	at java.lang.reflect.Method.invoke(Method.java:498)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:169)
Aug 11 12:11:05 	at com.sun.proxy.$Proxy26.createTable(Unknown Source)
Aug 11 12:11:05 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Aug 11 12:11:05 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
Aug 11 12:11:05 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Aug 11 12:11:05 	at java.lang.reflect.Method.invoke(Method.java:498)
Aug 11 12:11:05 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2327)
Aug 11 12:11:05 	at com.sun.proxy.$Proxy26.createTable(Unknown Source)
Aug 11 12:11:05 	at org.apache.flink.table.catalog.hive.client.HiveMetastoreClientWrapper.createTable(HiveMetastoreClientWrapper.java:174)
Aug 11 12:11:05 	at org.apache.flink.table.catalog.hive.HiveCatalog.createTable(HiveCatalog.java:539)
Aug 11 12:11:05 	... 18 more
Aug 11 12:11:05 
Aug 11 12:11:05 	at org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:385)
Aug 11 12:11:05 	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:254)
Aug 11 12:11:05 	at org.apache.flink.tests.util.flink.FlinkDistribution.lambda$submitSQLJob$6(FlinkDistribution.java:293)
Aug 11 12:11:05 	at org.apache.flink.util.function.FunctionUtils.lambda$asCallable$5(FunctionUtils.java:126)
Aug 11 12:11:05 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
Aug 11 12:11:05 	at java.lang.Thread.run(Thread.java:750)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17757780" author="fsk119" created="Wed, 23 Aug 2023 03:01:39 +0000"  >&lt;p&gt;Thanks for the sharing. I think we should add some retry mechanism to restart the container when namenode fails. I will open a PR to fix this soon.&lt;/p&gt;</comment>
                            <comment id="17759404" author="fsk119" created="Mon, 28 Aug 2023 01:42:13 +0000"  >&lt;p&gt;Merged into master: 4b84b6cd5983ae8f058fae731eb0f4af6214b738&lt;/p&gt;

&lt;p&gt;Waiting to check whether it works...&lt;/p&gt;</comment>
                            <comment id="17760421" author="mapohl" created="Wed, 30 Aug 2023 14:09:31 +0000"  >&lt;p&gt;Thanks for looking into it, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fsk119&quot; class=&quot;user-hover&quot; rel=&quot;fsk119&quot;&gt;fsk119&lt;/a&gt;. How do you find out whether &quot;it works&quot;? Should we provide backports for this test instability as well? It affects 1.18 but the change you documented was only merged to &lt;tt&gt;master&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="17760705" author="fsk119" created="Thu, 31 Aug 2023 03:43:59 +0000"  >&lt;p&gt;&amp;gt; How do you find out whether &quot;it works&quot;?&lt;/p&gt;

&lt;p&gt;I just try to observe whether the test fails again in the daily run tests. But I find I can not find the flink-ci.flink-master-mirror pipeline anymore..&lt;/p&gt;

&lt;p&gt;&amp;gt;  It affects 1.18 but the change you documented was only merged to master.&lt;/p&gt;

&lt;p&gt;Sure. I will cherry-pick this to release-1.18&lt;/p&gt;</comment>
                            <comment id="17760744" author="mapohl" created="Thu, 31 Aug 2023 06:45:15 +0000"  >&lt;p&gt;Yeah, the Pipeline overview went away. We have to check what&apos;s wrong there. In the meantime, you can use &lt;a href=&quot;https://dev.azure.com/apache-flink/apache-flink/_build?view=runs&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this overview&lt;/a&gt; which includes not only the &lt;tt&gt;master&lt;/tt&gt; and release branches builds but also the PR builds. That&apos;s a bit annoying.&lt;/p&gt;</comment>
                            <comment id="17762307" author="jingge" created="Wed, 6 Sep 2023 08:30:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fsk119&quot; class=&quot;user-hover&quot; rel=&quot;fsk119&quot;&gt;fsk119&lt;/a&gt; do you have time to move forward? Thanks!&lt;/p&gt;</comment>
                            <comment id="17762682" author="fsk119" created="Thu, 7 Sep 2023 09:59:40 +0000"  >&lt;p&gt;The current fix doesn&apos;t work in the hive3 envrionment. I have opened a PR to fix this. But the fix works in the hive2 environment.&lt;/p&gt;</comment>
                            <comment id="17764050" author="fsk119" created="Tue, 12 Sep 2023 07:23:16 +0000"  >&lt;p&gt;Merged into release-1.18: &lt;br/&gt;
3dcdc7f29384bc399e65ce46253975570e93481f&lt;br/&gt;
9e5659ea65278b2b699ab0c0f0eafc918a0107bc&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13556281">FLINK-33418</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13548931">FLINK-32988</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 9 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1jj6o:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>