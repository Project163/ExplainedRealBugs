<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:25:14 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-4618] FlinkKafkaConsumer09 should start from the next record on startup from offsets in Kafka</title>
                <link>https://issues.apache.org/jira/browse/FLINK-4618</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;*&lt;b&gt;Original reported ticket title: Last kafka message gets consumed twice when restarting job&lt;/b&gt;*&lt;/p&gt;

&lt;p&gt;There seem to be an issue with the offset management in Flink. When a job is stopped and startet again, a message from the previous offset is read again.&lt;br/&gt;
I enabled checkpoints (EXACTLY_ONCE) and FsStateBackend. I started with a new consumer group and emitted one record.&lt;/p&gt;

&lt;p&gt;You can cleary see, that the consumer waits for a new record at offset 4848911, which is correct. After restarting, it consumes a record at 4848910, causing the record to be consumed more than once.&lt;/p&gt;

&lt;p&gt;I checked the offset with the Kafka CMD tools, the commited offset in zookeeper is 4848910.&lt;/p&gt;

&lt;p&gt;Here is my log output:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;10:29:24,225 DEBUG org.apache.kafka.clients.NetworkClient                        - Initiating connection to node 2147482646 at hdp1:6667.
10:29:24,225 DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - Fetching committed offsets &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partitions: [myTopic-0]
10:29:24,228 DEBUG org.apache.kafka.clients.NetworkClient                        - Completed connection to node 2147482646
10:29:24,234 DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - No committed offset &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0
10:29:24,238 DEBUG org.apache.kafka.clients.consumer.internals.Fetcher           - Resetting offset &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 to latest offset.
10:29:24,244 DEBUG org.apache.kafka.clients.consumer.internals.Fetcher           - Fetched offset 4848910 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0
10:29:24,245 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848910
10:29:24,773 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848910
10:29:25,276 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848910

-- Inserting a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; event here

10:30:22,447 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Adding fetched record &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 with offset 4848910 to buffered record list
10:30:22,448 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Returning fetched records at offset 4848910 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; assigned partition myTopic-0 and update position to 4848911
10:30:22,451 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:30:22,953 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:30:23,456 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:30:23,887 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator     - Triggering checkpoint 6 @ 1473841823887
10:30:23,957 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:30:23,996 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator     - Completed checkpoint 6 (in 96 ms)
10:30:24,196 TRACE org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - Sending offset-commit request with {myTopic-0=OffsetAndMetadata{offset=4848910, metadata=&apos;&apos;}} to Node(2147482646, hdp1, 6667)
10:30:24,204 DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - Committed offset 4848910 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0
10:30:24,460 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:30:24,963 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:30:48,057 INFO  org.apache.flink.runtime.blob.BlobServer                      - Stopped BLOB server at 0.0.0.0:2946

-- Restarting job

10:32:01,672 DEBUG org.apache.kafka.clients.NetworkClient                        - Initiating connection to node 2147482646 at hdp1:6667.
10:32:01,673 DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - Fetching committed offsets &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partitions: [myTopic-0]
10:32:01,677 DEBUG org.apache.kafka.clients.NetworkClient                        - Completed connection to node 2147482646
&lt;span class=&quot;code-comment&quot;&gt;// See below! Shouldn&apos;t the offset be 4848911?
&lt;/span&gt;10:32:01,682 DEBUG org.apache.kafka.clients.consumer.internals.Fetcher           - Resetting offset &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 to the committed offset 4848910
10:32:01,683 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848910
10:32:01,685 DEBUG org.apache.kafka.clients.NetworkClient                        - Initiating connection to node 1001 at hdp1:6667.
10:32:01,687 DEBUG org.apache.kafka.clients.NetworkClient                        - Completed connection to node 1001
&lt;span class=&quot;code-comment&quot;&gt;// Here record 4848910 gets consumed again!
&lt;/span&gt;10:32:01,707 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Adding fetched record &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 with offset 4848910 to buffered record list
10:32:01,708 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Returning fetched records at offset 4848910 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; assigned partition myTopic-0 and update position to 4848911
10:32:03,721 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:32:04,224 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:32:04,726 TRACE org.apache.kafka.clients.consumer.internals.Fetcher           - Added fetch request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition myTopic-0 at offset 4848911
10:32:04,894 INFO  org.apache.flink.runtime.blob.BlobCache                       - Shutting down BlobCache
10:32:04,903 INFO  org.apache.flink.runtime.blob.BlobServer                      - Stopped BLOB server at 0.0.0.0:3079
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Flink 1.1.2&lt;br/&gt;
Kafka Broker 0.10.0&lt;br/&gt;
Hadoop 2.7.0&lt;/p&gt;</environment>
        <key id="13004817">FLINK-4618</key>
            <summary>FlinkKafkaConsumer09 should start from the next record on startup from offsets in Kafka</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="melmoth">static-max</reporter>
                        <labels>
                    </labels>
                <created>Wed, 14 Sep 2016 09:01:24 +0000</created>
                <updated>Sat, 1 Oct 2016 10:24:39 +0000</updated>
                            <resolved>Sat, 1 Oct 2016 10:24:37 +0000</resolved>
                                    <version>1.1.2</version>
                                    <fixVersion>1.1.3</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15489901" author="tzulitai" created="Wed, 14 Sep 2016 09:15:11 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt;,&lt;br/&gt;
Flink achieves exactly-once guarantees by working with offsets that are checkpointed internally in Flink, not the offsets that are committed back to ZK / Kafka. This offset committing back to ZK is either done periodically or on Flink checkpointing, depending on the consumer configuration, and merely serves as a purpose of exposing a measure of progress to the outside world (wrt Flink).&lt;/p&gt;

&lt;p&gt;On a &quot;fresh&quot; startup of a job (&quot;fresh&quot; startup meaning that the execution of the job is not an automatic restore from previous failure - a manual restart of a job is a fresh startup), the Kafka consumer respects any existing offsets committed in ZK as starting points.&lt;br/&gt;
So, if I am correct, what is actually happening is that, on your second execution of the job, the Kafka consumer is simply just starting from the offsets it finds in ZK.&lt;/p&gt;

&lt;p&gt;If you want exactly-once for manual job restarts, you would use Flink savepoints. See &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/setup/savepoints.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-master/setup/savepoints.html&lt;/a&gt; for more detail.&lt;br/&gt;
Otherwise, the exactly-once guarantee refers to job automatic restores across job failures.&lt;/p&gt;</comment>
                            <comment id="15490110" author="melmoth" created="Wed, 14 Sep 2016 10:47:06 +0000"  >&lt;p&gt;Hi Gordon,&lt;/p&gt;

&lt;p&gt;what if I update/change the job and re-submit it? Why can&apos;t the correct offset from ZK be used for that?&lt;br/&gt;
It seems rather easy to fix by incrementing the offset by one, or am I missing a point? I don&apos;t want to use the commandline or add additional de-duplication in my downstream apps. That would make it very complex for my usecase.&lt;br/&gt;
Or am I using Flink wrong?&lt;/p&gt;</comment>
                            <comment id="15490153" author="tzulitai" created="Wed, 14 Sep 2016 11:09:32 +0000"  >&lt;p&gt;I&apos;m answering your questions in SO, so that we can keep the discussion over there &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15490506" author="melmoth" created="Wed, 14 Sep 2016 13:59:08 +0000"  >&lt;p&gt;No bug, use savepoints before canceling a task.&lt;br/&gt;
See Gordons comments.&lt;/p&gt;</comment>
                            <comment id="15493845" author="tzulitai" created="Thu, 15 Sep 2016 16:31:43 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt;,&lt;br/&gt;
I&apos;ve revisited this issue, and I think this may actually be a bug.&lt;br/&gt;
Like what you mentioned in SO, the Kafka consumer is either committing 1 less offset back to ZK, or that it&apos;s supposed to start from the next record when starting from offsets found in ZK.&lt;br/&gt;
Note that this still has nothing to do with Flink&apos;s exactly-once guarantee though; this is simply that the consumer isn&apos;t starting at the right place when starting with offsets found from ZK. The savepoint / exactly-once descriptions I described before still holds. I&apos;m sorry for making a wrong conclusion on this bug in the first place.&lt;/p&gt;

&lt;p&gt;I&apos;ll update information in this ticket once I confirm the bug! &lt;/p&gt;</comment>
                            <comment id="15493927" author="tzulitai" created="Thu, 15 Sep 2016 16:57:47 +0000"  >&lt;p&gt;I&apos;ve confirmed that the problem only exists in the 0.9 consumer.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbarlocker&quot; class=&quot;user-hover&quot; rel=&quot;mbarlocker&quot;&gt;mbarlocker&lt;/a&gt;, since you were the original reporters of the bug, would any one of you want to work on fixing it and open a PR? You can ping me to help review when you&apos;re ready &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Otherwise I can also pick it up. In any case, let me know &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15493956" author="mbarlocker" created="Thu, 15 Sep 2016 17:06:44 +0000"  >&lt;p&gt;Nice find &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tzulitai&quot; class=&quot;user-hover&quot; rel=&quot;tzulitai&quot;&gt;tzulitai&lt;/a&gt; - I don&apos;t know the code well enough to feel confident making the change or testing the fix. Please feel free. I started learning Flink about a week ago, and have put a solid 3 hours into it. &lt;/p&gt;</comment>
                            <comment id="15503281" author="melmoth" created="Mon, 19 Sep 2016 12:34:08 +0000"  >&lt;p&gt;I will try to fix the bug, but I&apos;m also a Flink newbie &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;</comment>
                            <comment id="15503766" author="tzulitai" created="Mon, 19 Sep 2016 15:27:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt; Great to hear, thanks for picking up the issue!&lt;br/&gt;
I&apos;ve been working on the Kafka connector recently and am quite familiar with the code, so if you need any input or help, feel free to just tag / ping me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15503798" author="melmoth" created="Mon, 19 Sep 2016 15:40:32 +0000"  >&lt;p&gt;The offset handling seems to be done by the Kafka client library outside of Flink (org.apache.kafka.clients.consumer.KafkaConsumer&amp;lt;K, V&amp;gt;). The commited offset seems to be correct, AFAIK the last read offset gets commited to ZK.&lt;/p&gt;

&lt;p&gt;However, the 0.9 consumer seems to have a workaround in the run() method that increments the offset by one, but that code does not get called as partition.isOffsetDefined() returns false.&lt;/p&gt;

&lt;p&gt;(line 194):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// seek the consumer to the initial offsets
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (KafkaTopicPartitionState&amp;lt;TopicPartition&amp;gt; partition : subscribedPartitions()) {
	&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (partition.isOffsetDefined()) {
		consumer.seek(partition.getKafkaPartitionHandle(), partition.getOffset() + 1);
	}
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I don&apos;t think the Kafka library is broken, any ideas?&lt;/p&gt;</comment>
                            <comment id="15503822" author="tzulitai" created="Mon, 19 Sep 2016 15:51:32 +0000"  >&lt;p&gt;&lt;tt&gt;partition.isOffsetDefined()&lt;/tt&gt; in this part of the code only returns true when the job is started from a checkpoint / savepoint.&lt;br/&gt;
The bug here seems to be that on a fresh startup (not from checkpoint/savepoint) and the consumer uses offsets committed in ZK, it&apos;s not starting from the next unread record.&lt;br/&gt;
AFAIK, I think the 0.9 KafkaConsumer handles fetching offsets from ZK and using them as starting points as part of the client library. So, on a fresh startup, &lt;tt&gt;consumer.seek(...)&lt;/tt&gt; isn&apos;t called at all, and it seems like we&apos;re simply letting the KafkaConsumer client do the work.&lt;/p&gt;</comment>
                            <comment id="15503837" author="tzulitai" created="Mon, 19 Sep 2016 15:55:08 +0000"  >&lt;p&gt;I&apos;m not entirely sure of whether the KafkaConsumer starts &quot;at&quot; or &quot;after&quot; the found offsets in ZK though. Correctly, it should be &quot;after&quot;. Perhaps something works as unexpected here, and we need to workaround the behaviour?&lt;/p&gt;</comment>
                            <comment id="15529466" author="tzulitai" created="Wed, 28 Sep 2016 12:36:15 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I just had a look at the Kafka 0.9 API, and it seems like when committing offsets using the new `KafkaConsumer` API, the correct value to commit back to Kafka is &lt;tt&gt;lastProcessedOffset + 1&lt;/tt&gt; (&lt;a href=&quot;https://kafka.apache.org/090/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync(java.util.Map&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://kafka.apache.org/090/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync(java.util.Map&lt;/a&gt;)).&lt;br/&gt;
I believe correcting this should fix the issue &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Let me know if you bump into any other problems.&lt;/p&gt;</comment>
                            <comment id="15535151" author="tzulitai" created="Fri, 30 Sep 2016 06:04:53 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I&apos;d like to make sure this bug is fixed in the upcoming 1.1.3 bugfix release.&lt;br/&gt;
Let me know if you&apos;d like to continue working on this &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Otherwise I can pick it up soon.&lt;/p&gt;</comment>
                            <comment id="15536832" author="melmoth" created="Fri, 30 Sep 2016 19:36:21 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tzulitai&quot; class=&quot;user-hover&quot; rel=&quot;tzulitai&quot;&gt;tzulitai&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I will give it a try this weekend.&lt;/p&gt;</comment>
                            <comment id="15537079" author="githubbot" created="Fri, 30 Sep 2016 21:07:51 +0000"  >&lt;p&gt;GitHub user static-max opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2579&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2579&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4618&quot; title=&quot;FlinkKafkaConsumer09 should start from the next record on startup from offsets in Kafka&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4618&quot;&gt;&lt;del&gt;FLINK-4618&lt;/del&gt;&lt;/a&gt; FlinkKafkaConsumer09 should start from the next record on startup from offsets in Kafka&lt;/p&gt;

&lt;p&gt;    This PR addresses &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4618&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-4618&lt;/a&gt;, which causes the last message to be read again from Kafka after a fresh start of the job.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/static-max/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/static-max/flink&lt;/a&gt; flink-connector-kafka-0.9-fix-duplicate-messages&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2579.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2579.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2579&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 0b564203cdae3b21b00bb499b85feb799136e29b&lt;br/&gt;
Author: static-max &amp;lt;max.kuklinski@live.de&amp;gt;&lt;br/&gt;
Date:   2016-09-30T19:45:38Z&lt;/p&gt;

&lt;p&gt;    Merge pull request #1 from apache/master&lt;/p&gt;

&lt;p&gt;    Pull from origin&lt;/p&gt;

&lt;p&gt;commit 3618f5053e0ffb0ec1f789c56d878ed400e27056&lt;br/&gt;
Author: Max Kuklinski &amp;lt;max.kuklinski@live.de&amp;gt;&lt;br/&gt;
Date:   2016-09-30T21:03:30Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-4618&quot; title=&quot;FlinkKafkaConsumer09 should start from the next record on startup from offsets in Kafka&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-4618&quot;&gt;&lt;del&gt;FLINK-4618&lt;/del&gt;&lt;/a&gt; Incremented the commited offset by one to avoid duplicate read message.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15537081" author="melmoth" created="Fri, 30 Sep 2016 21:08:13 +0000"  >&lt;p&gt;I made a PR: &lt;a href=&quot;https://github.com/apache/flink/pull/2579&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2579&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15537605" author="githubbot" created="Sat, 1 Oct 2016 01:19:04 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2579&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2579&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thank you for working on this @static-max! Changes look good, will merge this.&lt;/p&gt;

&lt;p&gt;    I&apos;ll also add an IT test when merging to ensure that the Kafka consumer is starting at the right place.&lt;/p&gt;</comment>
                            <comment id="15537627" author="githubbot" created="Sat, 1 Oct 2016 01:36:58 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2579&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2579&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Btw, just a small tip: the Flink community usually use git rebase on the current master before submitting PRs to reduce the unnecessary merge commit &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15538287" author="githubbot" created="Sat, 1 Oct 2016 10:08:19 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2579&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2579&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Merging ...&lt;/p&gt;</comment>
                            <comment id="15538292" author="githubbot" created="Sat, 1 Oct 2016 10:12:02 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/2579&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/2579&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15538306" author="tzulitai" created="Sat, 1 Oct 2016 10:23:55 +0000"  >&lt;p&gt;Resolved for master via &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf/flink/commit/9dbd1e3f&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf/flink/commit/9dbd1e3f&lt;/a&gt;&lt;br/&gt;
Resolved for 1.1.3 via &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf/flink/commit/400c49ca&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf/flink/commit/400c49ca&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thank you for your contribution &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=melmoth&quot; class=&quot;user-hover&quot; rel=&quot;melmoth&quot;&gt;melmoth&lt;/a&gt;!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 7 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33lvz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>