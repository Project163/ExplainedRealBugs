<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:51:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-20241] Improve exception message when hive deps are missing on JM/TM</title>
                <link>https://issues.apache.org/jira/browse/FLINK-20241</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;I followed the setup here: &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-master/dev/table/hive/#dependencies&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-master/dev/table/hive/#dependencies&lt;/a&gt;&lt;br/&gt;
I put the flink-sql-connector-hive-2.3.6 in the \lib directory&lt;/p&gt;

&lt;p&gt;I tried running queries against an ORC table in hive from sql-client:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
SET table.sql-dialect=hive;
 CREATE TABLE hive_table_orc (
   user_id STRING,
   order_amount DOUBLE
 ) PARTITIONED BY (dt STRING, hr STRING) STORED AS orc TBLPROPERTIES (
   &lt;span class=&quot;code-quote&quot;&gt;&apos;partition.time-extractor.timestamp-pattern&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;$dt $hr:00:00&apos;&lt;/span&gt;,
   &lt;span class=&quot;code-quote&quot;&gt;&apos;sink.partition-commit.trigger&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;partition-time&apos;&lt;/span&gt;,
   &lt;span class=&quot;code-quote&quot;&gt;&apos;sink.partition-commit.delay&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;1 s&apos;&lt;/span&gt;,
   &lt;span class=&quot;code-quote&quot;&gt;&apos;sink.partition-commit.policy.kind&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;metastore,success-file&apos;&lt;/span&gt;,
   &lt;span class=&quot;code-quote&quot;&gt;&apos;streaming-source.enable&apos;&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&apos;&lt;/span&gt;);

SET table.sql-dialect=&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;;
insert into hive_table_orc VALUES (&lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt;, 123.0, &lt;span class=&quot;code-quote&quot;&gt;&apos;2020-11-11&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;12&apos;&lt;/span&gt;);
&lt;span class=&quot;code-comment&quot;&gt;// or 
&lt;/span&gt;SELECT * FROM hive_table_orc;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but I am getting:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:116)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:78)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:224)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:217)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:208)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:534)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:89)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:419)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:286)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:201)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:154)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot instantiate user function.
	at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:325)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.&amp;lt;init&amp;gt;(OperatorChain.java:146)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:485)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:530)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:722)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:547)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: java.io.StreamCorruptedException: unexpected block data
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1549)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2125)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2125)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.flink.util.InstantiationUtil.deserializeObject(InstantiationUtil.java:576)
	at org.apache.flink.util.InstantiationUtil.deserializeObject(InstantiationUtil.java:562)
	at org.apache.flink.util.InstantiationUtil.deserializeObject(InstantiationUtil.java:550)
	at org.apache.flink.util.InstantiationUtil.readObjectFromConfig(InstantiationUtil.java:511)
	at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:310)
	... 6 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13341558">FLINK-20241</key>
            <summary>Improve exception message when hive deps are missing on JM/TM</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lirui">Rui Li</assignee>
                                    <reporter username="dwysakowicz">Dawid Wysakowicz</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Thu, 19 Nov 2020 11:06:35 +0000</created>
                <updated>Tue, 1 Dec 2020 02:54:27 +0000</updated>
                            <resolved>Fri, 27 Nov 2020 02:44:25 +0000</resolved>
                                    <version>1.12.0</version>
                                    <fixVersion>1.12.0</fixVersion>
                                    <component>Connectors / Hive</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="17235369" author="dawidwys" created="Thu, 19 Nov 2020 11:48:32 +0000"  >&lt;p&gt;I checked that I get the same behaviour with &lt;tt&gt;TEXTFILE&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="17237776" author="dian.fu" created="Tue, 24 Nov 2020 01:30:40 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lzljs3620320&quot; class=&quot;user-hover&quot; rel=&quot;lzljs3620320&quot;&gt;lzljs3620320&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lirui&quot; class=&quot;user-hover&quot; rel=&quot;lirui&quot;&gt;lirui&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17237909" author="lzljs3620320" created="Tue, 24 Nov 2020 07:04:01 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dwysakowicz&quot; class=&quot;user-hover&quot; rel=&quot;dwysakowicz&quot;&gt;dwysakowicz&lt;/a&gt;&#160;for reporting.&lt;/p&gt;

&lt;p&gt;works fine in my cluster, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dwysakowicz&quot; class=&quot;user-hover&quot; rel=&quot;dwysakowicz&quot;&gt;dwysakowicz&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;are Hadoop related dependencies ready?&lt;/p&gt;</comment>
                            <comment id="17237923" author="lirui" created="Tue, 24 Nov 2020 07:31:58 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dwysakowicz&quot; class=&quot;user-hover&quot; rel=&quot;dwysakowicz&quot;&gt;dwysakowicz&lt;/a&gt; thanks for testing and reporting the issue. I tried both standalone and yarn-session mode on my laptop and didn&apos;t reproduce the issue. Could you let me know which kind of cluster you&apos;re using?&lt;/p&gt;</comment>
                            <comment id="17237959" author="dawidwys" created="Tue, 24 Nov 2020 08:43:18 +0000"  >&lt;p&gt;I&apos;ve tried it again. In the end it was my fault as I did not copy over the &lt;tt&gt;hive-exec&lt;/tt&gt;. I assumed it is on the classpath as returned by&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
export HADOOP_CLASSPATH=`hadoop classpath`
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After copying over the &lt;tt&gt;hive-exec&lt;/tt&gt; it works. Sorry again for the confusion.&lt;/p&gt;</comment>
                            <comment id="17237969" author="lirui" created="Tue, 24 Nov 2020 08:58:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dwysakowicz&quot; class=&quot;user-hover&quot; rel=&quot;dwysakowicz&quot;&gt;dwysakowicz&lt;/a&gt; No problem at all. However, if you already put &lt;tt&gt;flink-sql-connector-hive-2.3.6&lt;/tt&gt; under the lib folder, you shouldn&apos;t be needing to copy hive-exec because it&apos;s included in that uber jar.&lt;/p&gt;

&lt;p&gt;The purpose of the &lt;tt&gt;flink-sql-connector-hive-x.x.x&lt;/tt&gt; jars is to make it easier for users to add dependencies (although the name is admittedly a little confusing). Each &lt;tt&gt;flink-sql-connector-hive-x.x.x&lt;/tt&gt; can be considered as &quot;&lt;tt&gt;flink-connector-hive&lt;/tt&gt; + &lt;tt&gt;hive-exec/hive-metastore&lt;/tt&gt; + &lt;tt&gt;orc/parquet&lt;/tt&gt;&quot;.&lt;/p&gt;</comment>
                            <comment id="17237975" author="rmetzger" created="Tue, 24 Nov 2020 09:05:45 +0000"  >&lt;p&gt;Great to hear that this is not a real issue. I&apos;m wondering if we can improve the error reporting a bit? Failing with a serialization issue because a dependency is missing doesn&apos;t sound like a great user experience.&lt;/p&gt;</comment>
                            <comment id="17237997" author="stephanewen" created="Tue, 24 Nov 2020 09:50:58 +0000"  >&lt;p&gt;Yes, I think the problem is the pattern where data is directly written to the ObjectOutputStream. That always creates hard to understand error messages:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;This results in bad messages: &lt;a href=&quot;https://github.com/apache/flink/blob/master/flink-formats/flink-sequence-file/src/main/java/org/apache/flink/formats/sequencefile/SerializableHadoopConfiguration.java#L47&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/blob/master/flink-formats/flink-sequence-file/src/main/java/org/apache/flink/formats/sequencefile/SerializableHadoopConfiguration.java#L47&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;This results in good messages: &lt;a href=&quot;https://github.com/apache/flink/blob/master/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/util/SerializableHadoopConfigWrapper.java#L52&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/blob/master/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/util/SerializableHadoopConfigWrapper.java#L52&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think we should change all parts where config / code is serialized to the second pattern, to make errors better.&lt;/p&gt;</comment>
                            <comment id="17237999" author="stephanewen" created="Tue, 24 Nov 2020 09:51:40 +0000"  >&lt;p&gt;I reopened this as a blocker, because it is impossible for users to understand and debug this error.&lt;/p&gt;</comment>
                            <comment id="17239493" author="lzljs3620320" created="Fri, 27 Nov 2020 02:44:25 +0000"  >&lt;p&gt;master (1.13):&#160;fad84798d9b66ae3b43fb3d4940a1e5c3b26600e&lt;/p&gt;

&lt;p&gt;release-1.12:&#160;598386763115cb9fa3de29a5e70ec9fd0e0faf57&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13340535">FLINK-20151</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 50 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0kr0w:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>