<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:34:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-10261] INSERT INTO does not work with ORDER BY clause</title>
                <link>https://issues.apache.org/jira/browse/FLINK-10261</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;It seems that INSERT INTO and ORDER BY do not work well together.&lt;/p&gt;

&lt;p&gt;An AssertionError is thrown and the ORDER BY clause is duplicated. I guess this is a Calcite issue.&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Test
  def testInsertIntoMemoryTable(): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    val tEnv = TableEnvironment.getTableEnvironment(env)
    MemoryTableSourceSinkUtil.clear()

    val t = StreamTestData.getSmall3TupleDataStream(env)
        .assignAscendingTimestamps(x =&amp;gt; x._2)
      .toTable(tEnv, &lt;span class=&quot;code-quote&quot;&gt;&apos;a, &apos;&lt;/span&gt;b, &lt;span class=&quot;code-quote&quot;&gt;&apos;c, &apos;&lt;/span&gt;rowtime.rowtime)
    tEnv.registerTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;sourceTable&quot;&lt;/span&gt;, t)

    val fieldNames = Array(&lt;span class=&quot;code-quote&quot;&gt;&quot;d&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;e&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;f&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;t&quot;&lt;/span&gt;)
    val fieldTypes = Array(Types.INT, Types.LONG, Types.STRING, Types.SQL_TIMESTAMP)
      .asInstanceOf[Array[TypeInformation[_]]]
    val sink = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MemoryTableSourceSinkUtil.UnsafeMemoryAppendTableSink
    tEnv.registerTableSink(&lt;span class=&quot;code-quote&quot;&gt;&quot;targetTable&quot;&lt;/span&gt;, fieldNames, fieldTypes, sink)

    val sql = &lt;span class=&quot;code-quote&quot;&gt;&quot;INSERT INTO targetTable SELECT a, b, c, rowtime FROM sourceTable ORDER BY a&quot;&lt;/span&gt;
    tEnv.sqlUpdate(sql)
    env.execute()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Error:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.AssertionError: not a query: SELECT `sourceTable`.`a`, `sourceTable`.`b`, `sourceTable`.`c`, `sourceTable`.`rowtime`
FROM `sourceTable` AS `sourceTable`
ORDER BY `a`
ORDER BY `a`

	at org.apache.calcite.sql2rel.SqlToRelConverter.convertQueryRecursive(SqlToRelConverter.java:3069)
	at org.apache.calcite.sql2rel.SqlToRelConverter.convertQuery(SqlToRelConverter.java:557)
	at org.apache.flink.table.calcite.FlinkPlannerImpl.rel(FlinkPlannerImpl.scala:104)
	at org.apache.flink.table.api.TableEnvironment.sqlUpdate(TableEnvironment.scala:717)
	at org.apache.flink.table.api.TableEnvironment.sqlUpdate(TableEnvironment.scala:683)
	at org.apache.flink.table.runtime.stream.sql.SqlITCase.testInsertIntoMemoryTable(SqlITCase.scala:735)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13182154">FLINK-10261</key>
            <summary>INSERT INTO does not work with ORDER BY clause</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="xueyu">xueyu</assignee>
                                    <reporter username="twalthr">Timo Walther</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Thu, 30 Aug 2018 15:18:14 +0000</created>
                <updated>Thu, 6 Sep 2018 14:44:26 +0000</updated>
                            <resolved>Thu, 6 Sep 2018 14:44:26 +0000</resolved>
                                                    <fixVersion>1.5.4</fixVersion>
                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>1.7.0</fixVersion>
                                    <component>Table SQL / API</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16601797" author="xueyu" created="Mon, 3 Sep 2018 06:16:06 +0000"  >&lt;p&gt;It was caused by calcite validate rewrite and change SqlNode in some cases such as ORDER_BY sql kind. In these special cases validate return new SqlNode with different kind, however, flink does not use this new SqlNode.&lt;/p&gt;

&lt;p&gt;Though this sql could be executed, however in `testInsertIntoMemoryTableOrderBy` test case I added, it is weird the result looks a little random... So when comparing the result, I use `sorted` both..&lt;/p&gt;</comment>
                            <comment id="16601802" author="githubbot" created="Mon, 3 Sep 2018 06:27:01 +0000"  >&lt;p&gt;xueyumusic opened a new pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648&lt;/a&gt;&lt;/p&gt;



&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What is the purpose of the change&lt;br/&gt;
   This PR tried to fix insert into with order by. It was caused by calcite validate rewrite and change SqlNode in some cases such as ORDER_BY sql kind. In these special cases validate return new SqlNode with different kind, however, flink does not use this new SqlNode.&lt;br/&gt;
   In addition, `DataStreamSortRule` seems require the first sort attributes is time attributes and order is ascending&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Brief change log&lt;br/&gt;
   TableEnvironment validate&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Verifying this change&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   test case&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Does this pull request potentially affect one of the following parts:&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Dependencies (does it add or upgrade a dependency): (no)&lt;/li&gt;
	&lt;li&gt;The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)&lt;/li&gt;
	&lt;li&gt;The serializers: (no)&lt;/li&gt;
	&lt;li&gt;The runtime per-record code paths (performance sensitive): (no)&lt;/li&gt;
	&lt;li&gt;Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (no)&lt;/li&gt;
	&lt;li&gt;The S3 file system connector: (no)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Documentation&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this pull request introduce a new feature? (no)&lt;/li&gt;
	&lt;li&gt;If yes, how is the feature documented? (not documented)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16601803" author="xueyu" created="Mon, 3 Sep 2018 06:27:14 +0000"  >&lt;p&gt;In addition, `DataStreamSortRule` seems require the first sort attributes is time attributes and order is ascending&lt;/p&gt;</comment>
                            <comment id="16602548" author="githubbot" created="Tue, 4 Sep 2018 02:22:07 +0000"  >&lt;p&gt;hequn8128 commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r214773269&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r214773269&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SqlITCase.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -742,6 +742,36 @@ class SqlITCase extends StreamingWithStateTestBase &lt;/p&gt;
{
     assertEquals(expected.sorted, MemoryTableSourceSinkUtil.tableDataStrings.sorted)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testInsertIntoMemoryTableOrderBy(): Unit = {&lt;br/&gt;
+    val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
+    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)&lt;br/&gt;
+    val tEnv = TableEnvironment.getTableEnvironment(env)&lt;br/&gt;
+    MemoryTableSourceSinkUtil.clear()&lt;br/&gt;
+&lt;br/&gt;
+    val t = StreamTestData.getSmall3TupleDataStream(env)&lt;br/&gt;
+        .assignAscendingTimestamps(x =&amp;gt; x._2)&lt;br/&gt;
+      .toTable(tEnv, &apos;a, &apos;b, &apos;c, &apos;rowtime.rowtime)&lt;br/&gt;
+    tEnv.registerTable(&quot;sourceTable&quot;, t)&lt;br/&gt;
+&lt;br/&gt;
+    val fieldNames = Array(&quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;t&quot;)&lt;br/&gt;
+    val fieldTypes = Array(Types.INT, Types.LONG, Types.STRING, Types.SQL_TIMESTAMP)&lt;br/&gt;
+      .asInstanceOf[Array[TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;]]&lt;br/&gt;
+    val sink = new MemoryTableSourceSinkUtil.UnsafeMemoryAppendTableSink&lt;br/&gt;
+    tEnv.registerTableSink(&quot;targetTable&quot;, fieldNames, fieldTypes, sink)&lt;br/&gt;
+&lt;br/&gt;
+    val sql = &quot;INSERT INTO targetTable SELECT a, b, c, rowtime &quot; +&lt;br/&gt;
+      &quot;FROM sourceTable order by rowtime, a desc&quot;&lt;br/&gt;
+    tEnv.sqlUpdate(sql)&lt;br/&gt;
+    env.execute()&lt;br/&gt;
+&lt;br/&gt;
+    val expected = List(&lt;br/&gt;
+      &quot;1,1,Hi,1970-01-01 00:00:00.001&quot;,&lt;br/&gt;
+      &quot;3,2,Hello world,1970-01-01 00:00:00.002&quot;,&lt;br/&gt;
+      &quot;2,2,Hello,1970-01-01 00:00:00.002&quot;)&lt;br/&gt;
+    assertEquals(expected.sorted, MemoryTableSourceSinkUtil.tableDataStrings.sorted)&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   The reason why output randomly is sink tasks have not been chained with the sort task. We can correct the `emitDataStream` in `UnsafeMemoryAppendTableSink` with:&lt;br/&gt;
   ```&lt;br/&gt;
       override def emitDataStream(dataStream: DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;Row&amp;#93;&lt;/span&gt;): Unit = &lt;/p&gt;
{
         val inputParallelism = dataStream.getParallelism
         dataStream
           .addSink(new MemoryAppendSink)
           .setParallelism(inputParallelism)
           .name(TableConnectorUtil.generateRuntimeName(this.getClass, getFieldNames))
       }
&lt;p&gt;   ```&lt;br/&gt;
   Once we correct it, remove `sorted` in `assertEquals `.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16602549" author="githubbot" created="Tue, 4 Sep 2018 02:22:07 +0000"  >&lt;p&gt;hequn8128 commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r214773258&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r214773258&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/InsertIntoValidationTest.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -47,6 +48,27 @@ class InsertIntoValidationTest &lt;/p&gt;
{
     tEnv.sqlUpdate(sql)
   }

&lt;p&gt;+  @Test(expected = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;TableException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+  def testNonTimeOrderByInsert(): Unit = {&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   This test is used to test order by without time field. Would it better move it into `org.apache.flink.table.api.stream.sql.validation.SortValidationTest` ?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16602550" author="githubbot" created="Tue, 4 Sep 2018 02:22:07 +0000"  >&lt;p&gt;hequn8128 commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r214773263&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r214773263&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SqlITCase.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -742,6 +742,36 @@ class SqlITCase extends StreamingWithStateTestBase &lt;/p&gt;
{
     assertEquals(expected.sorted, MemoryTableSourceSinkUtil.tableDataStrings.sorted)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testInsertIntoMemoryTableOrderBy(): Unit = {&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Would better move this test into `org.apache.flink.table.runtime.stream.sql.SortITCase` ?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16603020" author="githubbot" created="Tue, 4 Sep 2018 13:09:49 +0000"  >&lt;p&gt;xueyumusic commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r214906564&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r214906564&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/InsertIntoValidationTest.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -47,6 +48,27 @@ class InsertIntoValidationTest &lt;/p&gt;
{
     tEnv.sqlUpdate(sql)
   }

&lt;p&gt;+  @Test(expected = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;TableException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+  def testNonTimeOrderByInsert(): Unit = {&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   yes, SortValidationTest has similar time field order tests&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16603024" author="githubbot" created="Tue, 4 Sep 2018 13:11:47 +0000"  >&lt;p&gt;xueyumusic commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r214907206&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r214907206&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SqlITCase.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -742,6 +742,36 @@ class SqlITCase extends StreamingWithStateTestBase &lt;/p&gt;
{
     assertEquals(expected.sorted, MemoryTableSourceSinkUtil.tableDataStrings.sorted)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testInsertIntoMemoryTableOrderBy(): Unit = {&lt;br/&gt;
+    val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
+    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)&lt;br/&gt;
+    val tEnv = TableEnvironment.getTableEnvironment(env)&lt;br/&gt;
+    MemoryTableSourceSinkUtil.clear()&lt;br/&gt;
+&lt;br/&gt;
+    val t = StreamTestData.getSmall3TupleDataStream(env)&lt;br/&gt;
+        .assignAscendingTimestamps(x =&amp;gt; x._2)&lt;br/&gt;
+      .toTable(tEnv, &apos;a, &apos;b, &apos;c, &apos;rowtime.rowtime)&lt;br/&gt;
+    tEnv.registerTable(&quot;sourceTable&quot;, t)&lt;br/&gt;
+&lt;br/&gt;
+    val fieldNames = Array(&quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;t&quot;)&lt;br/&gt;
+    val fieldTypes = Array(Types.INT, Types.LONG, Types.STRING, Types.SQL_TIMESTAMP)&lt;br/&gt;
+      .asInstanceOf[Array[TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;]]&lt;br/&gt;
+    val sink = new MemoryTableSourceSinkUtil.UnsafeMemoryAppendTableSink&lt;br/&gt;
+    tEnv.registerTableSink(&quot;targetTable&quot;, fieldNames, fieldTypes, sink)&lt;br/&gt;
+&lt;br/&gt;
+    val sql = &quot;INSERT INTO targetTable SELECT a, b, c, rowtime &quot; +&lt;br/&gt;
+      &quot;FROM sourceTable order by rowtime, a desc&quot;&lt;br/&gt;
+    tEnv.sqlUpdate(sql)&lt;br/&gt;
+    env.execute()&lt;br/&gt;
+&lt;br/&gt;
+    val expected = List(&lt;br/&gt;
+      &quot;1,1,Hi,1970-01-01 00:00:00.001&quot;,&lt;br/&gt;
+      &quot;3,2,Hello world,1970-01-01 00:00:00.002&quot;,&lt;br/&gt;
+      &quot;2,2,Hello,1970-01-01 00:00:00.002&quot;)&lt;br/&gt;
+    assertEquals(expected.sorted, MemoryTableSourceSinkUtil.tableDataStrings.sorted)&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Thanks! @hequn8128 , updated the code.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16604589" author="githubbot" created="Wed, 5 Sep 2018 15:52:29 +0000"  >&lt;p&gt;yanghua commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r215327517&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r215327517&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/SortValidationTest.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -54,4 +53,12 @@ class SortValidationTest extends TableTestBase &lt;/p&gt;
{
     val sqlQuery = &quot;SELECT a FROM MyTable LIMIT 3&quot;
     streamUtil.verifySql(sqlQuery, &quot;&quot;)
   }
&lt;p&gt;+&lt;br/&gt;
+  // test should fail because time is not order field&lt;br/&gt;
+  @Test(expected = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;TableException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+  def testNonTimeSorting(): Unit = {&lt;br/&gt;
+&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   Remove this empty line looks better.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16604590" author="githubbot" created="Wed, 5 Sep 2018 15:52:29 +0000"  >&lt;p&gt;yanghua commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r215327606&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r215327606&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SortITCase.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -105,6 +107,36 @@ class SortITCase extends StreamingWithStateTestBase &lt;/p&gt;
{
       &quot;20&quot;)
     assertEquals(expected, SortITCase.testResults)
   }
&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testInsertIntoMemoryTableOrderBy(): Unit = {&lt;br/&gt;
+    val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
+    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)&lt;br/&gt;
+    val tEnv = TableEnvironment.getTableEnvironment(env)&lt;br/&gt;
+    MemoryTableSourceSinkUtil.clear()&lt;br/&gt;
+&lt;br/&gt;
+    val t = StreamTestData.getSmall3TupleDataStream(env)&lt;br/&gt;
+        .assignAscendingTimestamps(x =&amp;gt; x._2)&lt;br/&gt;
+      .toTable(tEnv, &apos;a, &apos;b, &apos;c, &apos;rowtime.rowtime)&lt;br/&gt;
+    tEnv.registerTable(&quot;sourceTable&quot;, t)&lt;br/&gt;
+&lt;br/&gt;
+    val fieldNames = Array(&quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;t&quot;)&lt;br/&gt;
+    val fieldTypes = Array(Types.INT, Types.LONG, Types.STRING, Types.SQL_TIMESTAMP)&lt;br/&gt;
+      .asInstanceOf[Array[TypeInformation&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;]]&lt;br/&gt;
+    val sink = new MemoryTableSourceSinkUtil.UnsafeMemoryAppendTableSink&lt;br/&gt;
+    tEnv.registerTableSink(&quot;targetTable&quot;, fieldNames, fieldTypes, sink)&lt;br/&gt;
+&lt;br/&gt;
+    val sql = &quot;INSERT INTO targetTable SELECT a, b, c, rowtime &quot; +&lt;br/&gt;
+      &quot;FROM sourceTable order by rowtime, a desc&quot;&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   SQL keyword (`ORDER BY`) upper case looks better to me.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16604591" author="githubbot" created="Wed, 5 Sep 2018 15:52:29 +0000"  >&lt;p&gt;yanghua commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r215327571&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r215327571&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SortITCase.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -105,6 +107,36 @@ class SortITCase extends StreamingWithStateTestBase &lt;/p&gt;
{
       &quot;20&quot;)
     assertEquals(expected, SortITCase.testResults)
   }
&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testInsertIntoMemoryTableOrderBy(): Unit = {&lt;br/&gt;
+    val env = StreamExecutionEnvironment.getExecutionEnvironment&lt;br/&gt;
+    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)&lt;br/&gt;
+    val tEnv = TableEnvironment.getTableEnvironment(env)&lt;br/&gt;
+    MemoryTableSourceSinkUtil.clear()&lt;br/&gt;
+&lt;br/&gt;
+    val t = StreamTestData.getSmall3TupleDataStream(env)&lt;br/&gt;
+        .assignAscendingTimestamps(x =&amp;gt; x._2)&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   The &quot;.&quot; aligns with the next line looks better?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16605780" author="githubbot" created="Thu, 6 Sep 2018 13:40:15 +0000"  >&lt;p&gt;twalthr commented on a change in pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648#discussion_r215628550&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648#discussion_r215628550&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/SortValidationTest.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -54,4 +53,12 @@ class SortValidationTest extends TableTestBase &lt;/p&gt;
{
     val sqlQuery = &quot;SELECT a FROM MyTable LIMIT 3&quot;
     streamUtil.verifySql(sqlQuery, &quot;&quot;)
   }
&lt;p&gt;+&lt;br/&gt;
+  // test should fail because time is not order field&lt;br/&gt;
+  @Test(expected = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;TableException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+  def testNonTimeSorting(): Unit = {&lt;/p&gt;

&lt;p&gt; Review comment:&lt;br/&gt;
   This test is not testing what it is supposed to test. I will remove it.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16605842" author="githubbot" created="Thu, 6 Sep 2018 14:22:13 +0000"  >&lt;p&gt;asfgit closed pull request #6648: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-10261&quot; title=&quot;INSERT INTO does not work with ORDER BY clause&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-10261&quot;&gt;&lt;del&gt;FLINK-10261&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; fix insert into with order by&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/flink/pull/6648&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/6648&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/TableEnvironment.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/TableEnvironment.scala&lt;br/&gt;
index 37f6d024a07..195812d1d1c 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/TableEnvironment.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/TableEnvironment.scala&lt;br/&gt;
@@ -711,10 +711,10 @@ abstract class TableEnvironment(val config: TableConfig) {&lt;br/&gt;
       case insert: SqlInsert =&amp;gt;&lt;br/&gt;
         // validate the SQL query&lt;br/&gt;
         val query = insert.getSource&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;planner.validate(query)&lt;br/&gt;
+        val validatedQuery = planner.validate(query)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // get query result as Table&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val queryResult = new Table(this, LogicalRelNode(planner.rel(query).rel))&lt;br/&gt;
+        val queryResult = new Table(this, LogicalRelNode(planner.rel(validatedQuery).rel))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // get name of sink table&lt;br/&gt;
         val targetTableName = insert.getTargetTable.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;SqlIdentifier&amp;#93;&lt;/span&gt;.names.get(0)&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/SortValidationTest.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/SortValidationTest.scala&lt;br/&gt;
index 083ed9468bf..644b0c3fb83 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/SortValidationTest.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/stream/sql/validation/SortValidationTest.scala&lt;br/&gt;
@@ -38,7 +38,6 @@ class SortValidationTest extends TableTestBase &lt;/p&gt;
{
     streamUtil.verifySql(sqlQuery, &quot;&quot;)
   }

&lt;p&gt;-&lt;br/&gt;
   // test should fail because time is not the primary order field&lt;br/&gt;
   @Test(expected = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;TableException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
   def testSortProcessingTimeSecondaryField(): Unit = {&lt;br/&gt;
@@ -54,4 +53,12 @@ class SortValidationTest extends TableTestBase &lt;/p&gt;
{
     val sqlQuery = &quot;SELECT a FROM MyTable LIMIT 3&quot;
     streamUtil.verifySql(sqlQuery, &quot;&quot;)
   }
&lt;p&gt;+&lt;br/&gt;
+  // test should fail because time is not order field&lt;br/&gt;
+  @Test(expected = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;TableException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+  def testNonTimeSorting(): Unit = &lt;/p&gt;
{
+
+    val sqlQuery = &quot;INSERT INTO targetTable SELECT a, b, c, rowtime FROM sourceTable ORDER BY a&quot;
+    streamUtil.verifySql(sqlQuery, &quot;&quot;)
+  }
&lt;p&gt; }&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SortITCase.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SortITCase.scala&lt;br/&gt;
index 19db2a031b4..e7b79a5a196 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SortITCase.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SortITCase.scala&lt;br/&gt;
@@ -18,15 +18,17 @@&lt;/p&gt;

&lt;p&gt; package org.apache.flink.table.runtime.stream.sql&lt;/p&gt;

&lt;p&gt;+import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
 import org.apache.flink.api.scala._&lt;br/&gt;
 import org.apache.flink.streaming.api.TimeCharacteristic&lt;br/&gt;
 import org.apache.flink.streaming.api.functions.sink.RichSinkFunction&lt;br/&gt;
 import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment&lt;br/&gt;
-import org.apache.flink.table.api.TableEnvironment&lt;br/&gt;
+import org.apache.flink.table.api.&lt;/p&gt;
{TableEnvironment, Types}
&lt;p&gt; import org.apache.flink.table.api.scala._&lt;br/&gt;
 import org.apache.flink.table.runtime.utils.TimeTestUtil.EventTimeSourceFunction&lt;br/&gt;
 import org.apache.flink.table.runtime.stream.sql.SortITCase.StringRowSelectorSink&lt;br/&gt;
-import org.apache.flink.table.runtime.utils.&lt;/p&gt;
{StreamITCase, StreamingWithStateTestBase}
&lt;p&gt;+import org.apache.flink.table.runtime.utils.&lt;/p&gt;
{StreamITCase, StreamTestData, StreamingWithStateTestBase}
&lt;p&gt;+import org.apache.flink.table.utils.MemoryTableSourceSinkUtil&lt;br/&gt;
 import org.apache.flink.types.Row&lt;br/&gt;
 import org.junit.Assert._&lt;br/&gt;
 import org.junit._&lt;br/&gt;
@@ -105,6 +107,36 @@ class SortITCase extends StreamingWithStateTestBase &lt;/p&gt;
{
       &quot;20&quot;)
     assertEquals(expected, SortITCase.testResults)
   }
&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testInsertIntoMemoryTableOrderBy(): Unit = &lt;/p&gt;
{
+    val env = StreamExecutionEnvironment.getExecutionEnvironment
+    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
+    val tEnv = TableEnvironment.getTableEnvironment(env)
+    MemoryTableSourceSinkUtil.clear()
+
+    val t = StreamTestData.getSmall3TupleDataStream(env)
+      .assignAscendingTimestamps(x =&amp;gt; x._2)
+      .toTable(tEnv, &apos;a, &apos;b, &apos;c, &apos;rowtime.rowtime)
+    tEnv.registerTable(&quot;sourceTable&quot;, t)
+
+    val fieldNames = Array(&quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;t&quot;)
+    val fieldTypes = Array(Types.INT, Types.LONG, Types.STRING, Types.SQL_TIMESTAMP)
+      .asInstanceOf[Array[TypeInformation[_]]]
+    val sink = new MemoryTableSourceSinkUtil.UnsafeMemoryAppendTableSink
+    tEnv.registerTableSink(&quot;targetTable&quot;, fieldNames, fieldTypes, sink)
+
+    val sql = &quot;INSERT INTO targetTable SELECT a, b, c, rowtime &quot; +
+      &quot;FROM sourceTable ORDER BY rowtime, a desc&quot;
+    tEnv.sqlUpdate(sql)
+    env.execute()
+
+    val expected = List(
+      &quot;1,1,Hi,1970-01-01 00:00:00.001&quot;,
+      &quot;3,2,Hello world,1970-01-01 00:00:00.002&quot;,
+      &quot;2,2,Hello,1970-01-01 00:00:00.002&quot;)
+    assertEquals(expected, MemoryTableSourceSinkUtil.tableDataStrings)
+  }
&lt;p&gt; }&lt;/p&gt;

&lt;p&gt; object SortITCase {&lt;br/&gt;
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/MemoryTableSourceSinkUtil.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/MemoryTableSourceSinkUtil.scala&lt;br/&gt;
index cb0ad436a18..1edd79fca56 100644&lt;br/&gt;
&amp;#8212; a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/MemoryTableSourceSinkUtil.scala&lt;br/&gt;
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/utils/MemoryTableSourceSinkUtil.scala&lt;br/&gt;
@@ -119,8 +119,10 @@ object MemoryTableSourceSinkUtil {&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     override def emitDataStream(dataStream: DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;Row&amp;#93;&lt;/span&gt;): Unit = &lt;/p&gt;
{
+      val inputParallelism = dataStream.getParallelism
       dataStream
         .addSink(new MemoryAppendSink)
+        .setParallelism(inputParallelism)
         .name(TableConnectorUtil.generateRuntimeName(this.getClass, getFieldNames))
     }
&lt;p&gt;   }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16605858" author="twalthr" created="Thu, 6 Sep 2018 14:44:26 +0000"  >&lt;p&gt;Fixed in 1.7.0: d036417985d3e2b1ca63909007db9710e842abf4&lt;br/&gt;
Fixed in 1.6.1: ddc2a987b07806ecaa748866353f34f1e3c5f0a6&lt;br/&gt;
Fixed in 1.5.4: a1cc687f0bdcb6708d12e793b35e6f2a9674a106&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 10 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3xlfb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>