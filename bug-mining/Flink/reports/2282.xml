<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:32:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-8487] State loss after multiple restart attempts</title>
                <link>https://issues.apache.org/jira/browse/FLINK-8487</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;A user &lt;a href=&quot;https://lists.apache.org/thread.html/9dc9b719cf8449067ad01114fedb75d1beac7b4dff171acdcc24903d@%3Cuser.flink.apache.org%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;reported this issue&lt;/a&gt; on the user@f.a.o mailing list and analyzed the situation.&lt;/p&gt;

&lt;p&gt;Scenario:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;A program that reads from Kafka and computes counts in a keyed 15 minute tumbling window.  StateBackend is RocksDB and checkpointing is enabled.&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
keyBy(0)
        .timeWindow(Time.of(window_size, TimeUnit.MINUTES))
        .allowedLateness(Time.of(late_by, TimeUnit.SECONDS))
        .reduce(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ReduceFunction(), &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WindowFunction())
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;At some point HDFS went into a safe mode due to NameNode issues&lt;/li&gt;
	&lt;li&gt;The following exception was thrown&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category WRITE is not supported in state standby. Visit https:&lt;span class=&quot;code-comment&quot;&gt;//s.apache.org/sbnn-error
&lt;/span&gt;    ..................

    at org.apache.flink.runtime.fs.hdfs.HadoopFileSystem.mkdirs(HadoopFileSystem.java:453)
        at org.apache.flink.core.fs.SafetyNetWrapperFileSystem.mkdirs(SafetyNetWrapperFileSystem.java:111)
        at org.apache.flink.runtime.state.filesystem.FsCheckpointStreamFactory.createBasePath(FsCheckpointStreamFactory.java:132)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The pipeline came back after a few restarts and checkpoint failures, after the HDFS issues were resolved.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It was evident that operator state was lost. Either it was the Kafka consumer that kept on advancing it&apos;s offset between a start and the next checkpoint failure (a minute&apos;s worth) or the the operator that had partial aggregates was lost.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The user did some in-depth analysis (see &lt;a href=&quot;https://lists.apache.org/thread.html/9dc9b719cf8449067ad01114fedb75d1beac7b4dff171acdcc24903d@%3Cuser.flink.apache.org%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;mail thread&lt;/a&gt;) and might have (according to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aljoscha&quot; class=&quot;user-hover&quot; rel=&quot;aljoscha&quot;&gt;aljoscha&lt;/a&gt;) identified the problem.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stefanrichter83%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;stefanrichter83@gmail.com&quot;&gt;stefanrichter83@gmail.com&lt;/a&gt;, can you have a look at this issue and check if it is relevant?&lt;/p&gt;</description>
                <environment></environment>
        <key id="13132983">FLINK-8487</key>
            <summary>State loss after multiple restart attempts</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="aljoscha">Aljoscha Krettek</assignee>
                                    <reporter username="fhueske">Fabian Hueske</reporter>
                        <labels>
                    </labels>
                <created>Tue, 23 Jan 2018 09:12:57 +0000</created>
                <updated>Sun, 11 Mar 2018 15:44:54 +0000</updated>
                            <resolved>Sun, 11 Mar 2018 15:44:54 +0000</resolved>
                                    <version>1.3.2</version>
                                    <fixVersion>1.3.3</fixVersion>
                    <fixVersion>1.4.3</fixVersion>
                    <fixVersion>1.5.0</fixVersion>
                                    <component>Runtime / State Backends</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16335551" author="srichter" created="Tue, 23 Jan 2018 09:19:38 +0000"  >&lt;p&gt;Afaik &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aljoscha&quot; class=&quot;user-hover&quot; rel=&quot;aljoscha&quot;&gt;aljoscha&lt;/a&gt; already fixed this in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-7783&quot; title=&quot;Don&amp;#39;t always remove checkpoints in ZooKeeperCompletedCheckpointStore#recover()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-7783&quot;&gt;&lt;del&gt;FLINK-7783&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="16357294" author="tzulitai" created="Thu, 8 Feb 2018 17:46:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aljoscha&quot; class=&quot;user-hover&quot; rel=&quot;aljoscha&quot;&gt;aljoscha&lt;/a&gt; can you confirm?&lt;/p&gt;</comment>
                            <comment id="16389580" author="githubbot" created="Wed, 7 Mar 2018 14:03:21 +0000"  >&lt;p&gt;GitHub user aljoscha opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8487&quot; title=&quot;State loss after multiple restart attempts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8487&quot;&gt;&lt;del&gt;FLINK-8487&lt;/del&gt;&lt;/a&gt; Verify ZooKeeper checkpoint store behaviour with ITCase&lt;/p&gt;

&lt;p&gt;    R: @zentol &lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/aljoscha/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/aljoscha/flink&lt;/a&gt; jira-8487-zookeeper-it-case-release-13&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #5654&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 62c6695c61c628ef842c6a29dbb517d71e50ca59&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-03-03T08:34:56Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8487&quot; title=&quot;State loss after multiple restart attempts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8487&quot;&gt;&lt;del&gt;FLINK-8487&lt;/del&gt;&lt;/a&gt; Verify ZooKeeper checkpoint store behaviour with ITCase&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16389583" author="githubbot" created="Wed, 7 Mar 2018 14:04:45 +0000"  >&lt;p&gt;GitHub user aljoscha opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5655&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5655&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8487&quot; title=&quot;State loss after multiple restart attempts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8487&quot;&gt;&lt;del&gt;FLINK-8487&lt;/del&gt;&lt;/a&gt; Verify ZooKeeper checkpoint store behaviour with ITCase&lt;/p&gt;

&lt;p&gt;    R: @zentol @StephanEwen &lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/aljoscha/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/aljoscha/flink&lt;/a&gt; jira-8487-zookeeper-it-case-release-14&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5655.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5655.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #5655&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit b93b8c407580fff60158b0e5390fb4036a5c90ba&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-03-03T08:34:56Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8487&quot; title=&quot;State loss after multiple restart attempts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8487&quot;&gt;&lt;del&gt;FLINK-8487&lt;/del&gt;&lt;/a&gt; Verify ZooKeeper checkpoint store behaviour with ITCase&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16389591" author="githubbot" created="Wed, 7 Mar 2018 14:10:42 +0000"  >&lt;p&gt;GitHub user aljoscha opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;     &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8487&quot; title=&quot;State loss after multiple restart attempts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8487&quot;&gt;&lt;del&gt;FLINK-8487&lt;/del&gt;&lt;/a&gt; Verify ZooKeeper checkpoint store behaviour with ITCase (master/1.5)&lt;/p&gt;

&lt;p&gt;    R: @zentol @StephanEwen &lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/aljoscha/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/aljoscha/flink&lt;/a&gt; jira-8487-zookeeper-it-case&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #5656&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit a0cbd2433bd90806ee1639d8fd7745cf6ecd5eab&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-26T09:12:44Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8758&quot; title=&quot;Expose method for non-blocking job submission on ClusterClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8758&quot;&gt;&lt;del&gt;FLINK-8758&lt;/del&gt;&lt;/a&gt; Add getters to JobDetailsInfo&lt;/p&gt;

&lt;p&gt;commit f21d3d95677cf4c9e10b44027b556e5063e8ac4c&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-26T11:29:23Z&lt;/p&gt;

&lt;p&gt;    Add proper toString() on JsonResponse in RestClient&lt;/p&gt;

&lt;p&gt;commit 903febcf255dc5e86e1f306e8d3c12f6f3f6ad3b&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-26T10:44:57Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8757&quot; title=&quot;Add MiniClusterResource.getClusterClient()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8757&quot;&gt;&lt;del&gt;FLINK-8757&lt;/del&gt;&lt;/a&gt; Add MiniClusterResource.getClusterClient()&lt;/p&gt;

&lt;p&gt;commit 4e47f877b6d51b7f1d22bd3acf11cf8b9a5b3744&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-26T10:52:50Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8758&quot; title=&quot;Expose method for non-blocking job submission on ClusterClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8758&quot;&gt;&lt;del&gt;FLINK-8758&lt;/del&gt;&lt;/a&gt; Make non-blocking ClusterClient.submitJob() public&lt;/p&gt;

&lt;p&gt;commit 6a1a0d58b2c9000f5cf7d489a01debd9b7e32e4d&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-26T10:53:47Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8758&quot; title=&quot;Expose method for non-blocking job submission on ClusterClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8758&quot;&gt;&lt;del&gt;FLINK-8758&lt;/del&gt;&lt;/a&gt; Add ClusterClient.getJobStatus()&lt;/p&gt;

&lt;p&gt;commit 80581cf3f4847d889655c3ff070ebf73c772a03c&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-27T12:40:51Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8758&quot; title=&quot;Expose method for non-blocking job submission on ClusterClient&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8758&quot;&gt;&lt;del&gt;FLINK-8758&lt;/del&gt;&lt;/a&gt; Add FutureUtils.retrySuccessfulWithDelay()&lt;/p&gt;

&lt;p&gt;    This retries getting a result until it matches a given predicate or&lt;br/&gt;
    until we run out of retries.&lt;/p&gt;

&lt;p&gt;commit c7d298e261942a8b145b7c47f2eedbc597b75ea4&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-28T14:06:59Z&lt;/p&gt;

&lt;p&gt;    Add our own Deadline implementation&lt;/p&gt;

&lt;p&gt;commit b09cd9b92b7f3d3eda07964e139dc8dba7b01116&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-27T12:42:09Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8797&quot; title=&quot;Port AbstractOperatorRestoreTestBase to MiniClusterResource&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8797&quot;&gt;&lt;del&gt;FLINK-8797&lt;/del&gt;&lt;/a&gt; Port AbstractOperatorRestoreTestBase to MiniClusterResource&lt;/p&gt;

&lt;p&gt;commit 46ebb586074ac35f153a9b2e98880b29d51f0abb&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-02-26T10:55:14Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8778&quot; title=&quot;Migrate queryable state ITCases to use MiniClusterResource&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8778&quot;&gt;&lt;del&gt;FLINK-8778&lt;/del&gt;&lt;/a&gt; Port queryable state ITCases to use MiniClusterResource&lt;/p&gt;

&lt;p&gt;commit 7c382e45243ee96b8d64715ca5d10e3822add7d7&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-03-03T08:34:56Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-8487&quot; title=&quot;State loss after multiple restart attempts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-8487&quot;&gt;&lt;del&gt;FLINK-8487&lt;/del&gt;&lt;/a&gt; Verify ZooKeeper checkpoint store behaviour with ITCase&lt;/p&gt;

&lt;p&gt;commit d7bf4070d03985b54c479d05c8c0f5534b820e61&lt;br/&gt;
Author: Aljoscha Krettek &amp;lt;aljoscha.krettek@...&amp;gt;&lt;br/&gt;
Date:   2018-03-06T15:29:48Z&lt;/p&gt;

&lt;p&gt;    Incorporate Stephan suggestions&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16389606" author="githubbot" created="Wed, 7 Mar 2018 14:15:50 +0000"  >&lt;p&gt;Github user zentol commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    should probably clean this branch from the restore/QS tests, and rebase it once.&lt;/p&gt;</comment>
                            <comment id="16389650" author="githubbot" created="Wed, 7 Mar 2018 14:53:15 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172856770&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172856770&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory and make it non-writable&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    you&apos;re never making the directory non-writable; you should also check that this is possible in the first place&lt;/p&gt;</comment>
                            <comment id="16389651" author="githubbot" created="Wed, 7 Mar 2018 14:53:16 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172857716&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172857716&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory and make it non-writable&lt;br/&gt;
    +	 *       to make creating and restoring from checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    given that there is only a single test we could also make the static latches final.&lt;/p&gt;</comment>
                            <comment id="16389652" author="githubbot" created="Wed, 7 Mar 2018 14:53:18 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    We shouldn&apos;t look at this one anyways because we can&apos;t merge it on master unless the other stuff is in. Because the test will not work.&lt;/p&gt;</comment>
                            <comment id="16389701" author="githubbot" created="Wed, 7 Mar 2018 15:37:28 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172882495&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172882495&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory and make it non-writable&lt;br/&gt;
    +	 *       to make creating and restoring from checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I did it like this because it allows running the test in a loop in IntelliJ, which doesn&apos;t start a new JVM for each execution, meaning the static fields are not re-initialized.&lt;/p&gt;</comment>
                            <comment id="16389702" author="githubbot" created="Wed, 7 Mar 2018 15:38:15 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172882773&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172882773&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory and make it non-writable&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Ah, I had that in an earlier version but I removed it because it was a bit to fancy because I had a suspicion that wasn&apos;t true in the end. I will remove this comment, WDYT?&lt;/p&gt;</comment>
                            <comment id="16389740" author="githubbot" created="Wed, 7 Mar 2018 16:05:31 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172893235&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172893235&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory and make it non-writable&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    +1 for removing it&lt;/p&gt;</comment>
                            <comment id="16389742" author="githubbot" created="Wed, 7 Mar 2018 16:06:16 +0000"  >&lt;p&gt;Github user zentol commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172893483&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172893483&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory and make it non-writable&lt;br/&gt;
    +	 *       to make creating and restoring from checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    i see, that makes sense.&lt;/p&gt;</comment>
                            <comment id="16390152" author="githubbot" created="Wed, 7 Mar 2018 20:24:31 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r172972120&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r172972120&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Requests the &lt;/p&gt;
{@link JobStatus}
&lt;p&gt; of the job with the given &lt;/p&gt;
{@link JobID}
&lt;p&gt;.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private Future&amp;lt;JobStatus&amp;gt; getJobStatus(&lt;br/&gt;
    +		final ActorGateway jobManager,&lt;br/&gt;
    +		final JobID jobId,&lt;br/&gt;
    +		final FiniteDuration timeout) {&lt;br/&gt;
    +&lt;br/&gt;
    +		scala.concurrent.Future&amp;lt;Object&amp;gt; response =&lt;br/&gt;
    +			jobManager.ask(JobManagerMessages.getRequestJobStatus(jobId), timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		FlinkFuture&amp;lt;Object&amp;gt; flinkFuture = new FlinkFuture&amp;lt;&amp;gt;(response);&lt;br/&gt;
    +&lt;br/&gt;
    +		return flinkFuture.thenApply(new ApplyFunction&amp;lt;Object, JobStatus&amp;gt;() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public JobStatus apply(Object value) {&lt;br/&gt;
    +				if (value instanceof JobManagerMessages.CurrentJobStatus) &lt;/p&gt;
{
    +					return ((JobManagerMessages.CurrentJobStatus) value).status();
    +				}
&lt;p&gt; else if (value instanceof JobManagerMessages.JobNotFound) &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Could not find job with JobId &quot; + jobId));
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Unknown JobManager response of type &quot; + value.getClass()));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class UnboundedSource implements SourceFunction&amp;lt;String&amp;gt; {&lt;br/&gt;
    +		private boolean running = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;String&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +			while (running) {&lt;br/&gt;
    +				ctx.collect(&quot;hello&quot;);&lt;br/&gt;
    +				// don&apos;t overdo it ... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
    +				Thread.sleep(50);&lt;br/&gt;
    +				if (CheckpointBlockingFunction.afterMessWithZooKeeper.get()) &lt;/p&gt;
{
    +					break;
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			running = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointBlockingFunction&lt;br/&gt;
    +			extends RichMapFunction&amp;lt;String, String&amp;gt;&lt;br/&gt;
    +			implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		// verify that we only call initializeState()&lt;br/&gt;
    +		// once with isRestored() == false. All other invocations must have isRestored() == true. This&lt;br/&gt;
    +		// verifies that we don&apos;t restart a job from scratch in case the CompletedCheckpoints can&apos;t&lt;br/&gt;
    +		// be read.&lt;br/&gt;
    +		static AtomicInteger allowedInitializeCallsWithoutRestore = new AtomicInteger(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		// we count when we see restores that are not allowed. We only&lt;br/&gt;
    +		// allow restores once we messed with the HA directory and moved it back again&lt;br/&gt;
    +		static AtomicInteger illegalRestores = new AtomicInteger(0);&lt;br/&gt;
    +		static AtomicInteger successfulRestores = new AtomicInteger(0);&lt;br/&gt;
    +&lt;br/&gt;
    +		// whether we are after the phase where we messed with the ZooKeeper HA directory, i.e.&lt;br/&gt;
    +		// whether it&apos;s now ok for a restore to happen&lt;br/&gt;
    +		static AtomicBoolean afterMessWithZooKeeper = new AtomicBoolean(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		static AtomicBoolean failedAlready = new AtomicBoolean(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		// also have some state to write to the checkpoint&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;&amp;gt;(&quot;state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public String map(String value) throws Exception &lt;/p&gt;
{
    +			getRuntimeContext().getState(stateDescriptor).update(&quot;42&quot;);
    +			return value;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			if (context.getCheckpointId() &amp;gt; 5) {&lt;br/&gt;
    +				waitForCheckpointLatch.trigger();&lt;br/&gt;
    +				failInCheckpointLatch.await();&lt;br/&gt;
    +				if (!failedAlready.getAndSet(true)) &lt;/p&gt;
{
    +					throw new RuntimeException(&quot;Failing on purpose.&quot;);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) {&lt;br/&gt;
    +			if (!context.isRestored()) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I am wondering if you can get rid of the `allowedInitializeCallsWithoutRestore` completely and simply make this an `assertEquals(afterMessWithZooKeeper, context.isRestored())`.&lt;/p&gt;</comment>
                            <comment id="16390153" author="githubbot" created="Wed, 7 Mar 2018 20:24:31 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r172963487&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r172963487&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Requests the &lt;/p&gt;
{@link JobStatus}
&lt;p&gt; of the job with the given &lt;/p&gt;
{@link JobID}
&lt;p&gt;.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private Future&amp;lt;JobStatus&amp;gt; getJobStatus(&lt;br/&gt;
    +		final ActorGateway jobManager,&lt;br/&gt;
    +		final JobID jobId,&lt;br/&gt;
    +		final FiniteDuration timeout) {&lt;br/&gt;
    +&lt;br/&gt;
    +		scala.concurrent.Future&amp;lt;Object&amp;gt; response =&lt;br/&gt;
    +			jobManager.ask(JobManagerMessages.getRequestJobStatus(jobId), timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		FlinkFuture&amp;lt;Object&amp;gt; flinkFuture = new FlinkFuture&amp;lt;&amp;gt;(response);&lt;br/&gt;
    +&lt;br/&gt;
    +		return flinkFuture.thenApply(new ApplyFunction&amp;lt;Object, JobStatus&amp;gt;() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public JobStatus apply(Object value) {&lt;br/&gt;
    +				if (value instanceof JobManagerMessages.CurrentJobStatus) &lt;/p&gt;
{
    +					return ((JobManagerMessages.CurrentJobStatus) value).status();
    +				}
&lt;p&gt; else if (value instanceof JobManagerMessages.JobNotFound) &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Could not find job with JobId &quot; + jobId));
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Unknown JobManager response of type &quot; + value.getClass()));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class UnboundedSource implements SourceFunction&amp;lt;String&amp;gt; {&lt;br/&gt;
    +		private boolean running = true;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Must be volatile, to be on the safe side. Otherwise, JIT may choose to inline this...&lt;/p&gt;</comment>
                            <comment id="16390154" author="githubbot" created="Wed, 7 Mar 2018 20:24:31 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r172972943&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r172972943&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Or drop the `illegalRestores` - may not be necessary, see above. &lt;/p&gt;</comment>
                            <comment id="16390155" author="githubbot" created="Wed, 7 Mar 2018 20:24:31 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r172972736&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r172972736&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    assertEquals? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16390156" author="githubbot" created="Wed, 7 Mar 2018 20:24:31 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r172972454&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r172972454&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Requests the &lt;/p&gt;
{@link JobStatus}
&lt;p&gt; of the job with the given &lt;/p&gt;
{@link JobID}
&lt;p&gt;.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private Future&amp;lt;JobStatus&amp;gt; getJobStatus(&lt;br/&gt;
    +		final ActorGateway jobManager,&lt;br/&gt;
    +		final JobID jobId,&lt;br/&gt;
    +		final FiniteDuration timeout) {&lt;br/&gt;
    +&lt;br/&gt;
    +		scala.concurrent.Future&amp;lt;Object&amp;gt; response =&lt;br/&gt;
    +			jobManager.ask(JobManagerMessages.getRequestJobStatus(jobId), timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		FlinkFuture&amp;lt;Object&amp;gt; flinkFuture = new FlinkFuture&amp;lt;&amp;gt;(response);&lt;br/&gt;
    +&lt;br/&gt;
    +		return flinkFuture.thenApply(new ApplyFunction&amp;lt;Object, JobStatus&amp;gt;() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public JobStatus apply(Object value) {&lt;br/&gt;
    +				if (value instanceof JobManagerMessages.CurrentJobStatus) &lt;/p&gt;
{
    +					return ((JobManagerMessages.CurrentJobStatus) value).status();
    +				}
&lt;p&gt; else if (value instanceof JobManagerMessages.JobNotFound) &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Could not find job with JobId &quot; + jobId));
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Unknown JobManager response of type &quot; + value.getClass()));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class UnboundedSource implements SourceFunction&amp;lt;String&amp;gt; {&lt;br/&gt;
    +		private boolean running = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;String&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +			while (running) {&lt;br/&gt;
    +				ctx.collect(&quot;hello&quot;);&lt;br/&gt;
    +				// don&apos;t overdo it ... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
    +				Thread.sleep(50);&lt;br/&gt;
    +				if (CheckpointBlockingFunction.afterMessWithZooKeeper.get()) &lt;/p&gt;
{
    +					break;
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			running = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointBlockingFunction&lt;br/&gt;
    +			extends RichMapFunction&amp;lt;String, String&amp;gt;&lt;br/&gt;
    +			implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		// verify that we only call initializeState()&lt;br/&gt;
    +		// once with isRestored() == false. All other invocations must have isRestored() == true. This&lt;br/&gt;
    +		// verifies that we don&apos;t restart a job from scratch in case the CompletedCheckpoints can&apos;t&lt;br/&gt;
    +		// be read.&lt;br/&gt;
    +		static AtomicInteger allowedInitializeCallsWithoutRestore = new AtomicInteger(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		// we count when we see restores that are not allowed. We only&lt;br/&gt;
    +		// allow restores once we messed with the HA directory and moved it back again&lt;br/&gt;
    +		static AtomicInteger illegalRestores = new AtomicInteger(0);&lt;br/&gt;
    +		static AtomicInteger successfulRestores = new AtomicInteger(0);&lt;br/&gt;
    +&lt;br/&gt;
    +		// whether we are after the phase where we messed with the ZooKeeper HA directory, i.e.&lt;br/&gt;
    +		// whether it&apos;s now ok for a restore to happen&lt;br/&gt;
    +		static AtomicBoolean afterMessWithZooKeeper = new AtomicBoolean(false);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I was initially confused why all of these are Atomic booleans/integers, etc. Could they not be simple volatile variables? Not that the performance matters, but I was just wondering whether something here assumes atomicity.&lt;/p&gt;</comment>
                            <comment id="16390157" author="githubbot" created="Wed, 7 Mar 2018 20:24:31 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r172972678&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r172972678&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    If you are in state `FINISHED` here, you must have successfully restored. If you did not successfully restore, this latch will block forever and the test will time out.&lt;/p&gt;</comment>
                            <comment id="16390174" author="githubbot" created="Wed, 7 Mar 2018 20:38:16 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5655&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5655&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    This code is (except for lambdas) identical to #5654&lt;br/&gt;
    Please apply the same changes here as to the other PR (with regard to the review comments).&lt;/p&gt;</comment>
                            <comment id="16390175" author="githubbot" created="Wed, 7 Mar 2018 20:39:01 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r172977111&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r172977111&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Requests the &lt;/p&gt;
{@link JobStatus}
&lt;p&gt; of the job with the given &lt;/p&gt;
{@link JobID}
&lt;p&gt;.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private Future&amp;lt;JobStatus&amp;gt; getJobStatus(&lt;br/&gt;
    +		final ActorGateway jobManager,&lt;br/&gt;
    +		final JobID jobId,&lt;br/&gt;
    +		final FiniteDuration timeout) {&lt;br/&gt;
    +&lt;br/&gt;
    +		scala.concurrent.Future&amp;lt;Object&amp;gt; response =&lt;br/&gt;
    +			jobManager.ask(JobManagerMessages.getRequestJobStatus(jobId), timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		FlinkFuture&amp;lt;Object&amp;gt; flinkFuture = new FlinkFuture&amp;lt;&amp;gt;(response);&lt;br/&gt;
    +&lt;br/&gt;
    +		return flinkFuture.thenApply(new ApplyFunction&amp;lt;Object, JobStatus&amp;gt;() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public JobStatus apply(Object value) {&lt;br/&gt;
    +				if (value instanceof JobManagerMessages.CurrentJobStatus) &lt;/p&gt;
{
    +					return ((JobManagerMessages.CurrentJobStatus) value).status();
    +				}
&lt;p&gt; else if (value instanceof JobManagerMessages.JobNotFound) &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Could not find job with JobId &quot; + jobId));
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Unknown JobManager response of type &quot; + value.getClass()));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class UnboundedSource implements SourceFunction&amp;lt;String&amp;gt; {&lt;br/&gt;
    +		private boolean running = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;String&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +			while (running) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    `while (running &amp;amp;&amp;amp; !CheckpointBlockingFunction.afterMessWithZooKeeper.get())`?&lt;/p&gt;</comment>
                            <comment id="16390204" author="githubbot" created="Wed, 7 Mar 2018 20:53:14 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172978556&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172978556&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-core/src/main/java/org/apache/flink/api/common/time/Deadline.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,68 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.common.time;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.annotation.Internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * This class stores a deadline, as obtained via &lt;/p&gt;
{@link #now()}
&lt;p&gt; or from &lt;/p&gt;
{@link #plus(Duration)}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +@Internal&lt;br/&gt;
    +public class Deadline {&lt;br/&gt;
    +	private final Duration time;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I find this a bit confusing to use `Duration` here, because it really does not hold a duration, but an absolute point in time (in the future) evaluated against `System.nanoTime()`. I would simply use a `long deadlineNanos` here, which also makes the `isOverdue()` check (the most frequent one) cheaper.&lt;/p&gt;

&lt;p&gt;    You can (and should) still use `Duration` for the arithmetic (adding time, etc) - simply convert to nanos.&lt;/p&gt;
</comment>
                            <comment id="16390205" author="githubbot" created="Wed, 7 Mar 2018 20:53:14 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172980021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172980021&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		ClusterClient&amp;lt;?&amp;gt; clusterClient = miniClusterResource.getClusterClient();&lt;br/&gt;
    +		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT);&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend((StateBackend) new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy((str) -&amp;gt; str)&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		clusterClient.setDetached(true);&lt;br/&gt;
    +		clusterClient.submitJob(jobGraph, ZooKeeperHighAvailabilityITCase.class.getClassLoader());&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		// Note to future developers: This will break when we change Flink to not put the&lt;br/&gt;
    +		// checkpoint metadata into the HA directory but instead rely on the fact that the&lt;br/&gt;
    +		// actual checkpoint directory on DFS contains the checkpoint metadata. In this case,&lt;br/&gt;
    +		// ZooKeeper will only contain a &quot;handle&quot; (read: String) that points to the metadata&lt;br/&gt;
    +		// in DFS. The likely solution will be that we have to go directly to ZooKeeper, find&lt;br/&gt;
    +		// out where the checkpoint is stored and mess with that.&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The solution would be to rename the checkpoint directory directly.&lt;/p&gt;</comment>
                            <comment id="16390206" author="githubbot" created="Wed, 7 Mar 2018 20:53:14 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172978813&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172978813&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-core/src/main/java/org/apache/flink/api/common/time/Deadline.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,68 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.api.common.time;&lt;br/&gt;
    +&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.annotation.Internal;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * This class stores a deadline, as obtained via &lt;/p&gt;
{@link #now()}
&lt;p&gt; or from &lt;/p&gt;
{@link #plus(Duration)}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +@Internal&lt;br/&gt;
    +public class Deadline {&lt;br/&gt;
    +	private final Duration time;&lt;br/&gt;
    +&lt;br/&gt;
    +	private Deadline(Duration time) &lt;/p&gt;
{
    +		this.time = time;
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	public Deadline plus(Duration other) &lt;/p&gt;
{
    +		return new Deadline(time.plus(other));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Returns the time left between the deadline and now.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	public Duration timeLeft() {&lt;br/&gt;
    +		return time.minus(Duration.ofNanos(System.nanoTime()));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Is this expected to go negative, or simply stay at 0 when overdue?&lt;/p&gt;</comment>
                            <comment id="16390207" author="githubbot" created="Wed, 7 Mar 2018 20:53:14 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172979459&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172979459&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/concurrent/FutureUtils.java &amp;#8212;&lt;br/&gt;
    @@ -223,6 +224,81 @@&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * Retry the given operation with the given delay in between successful completions where the&lt;br/&gt;
    +	 * result does not match a given predicate.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @param operation to retry&lt;br/&gt;
    +	 * @param retryDelay delay between retries&lt;br/&gt;
    +	 * @param deadline A deadline that specifies at what point we should stop retrying&lt;br/&gt;
    +	 * @param acceptancePredicate Predicate to test whether the result is acceptable&lt;br/&gt;
    +	 * @param scheduledExecutor executor to be used for the retry operation&lt;br/&gt;
    +	 * @param &amp;lt;T&amp;gt; type of the result&lt;br/&gt;
    +	 * @return Future which retries the given operation a given amount of times and delays the retry&lt;br/&gt;
    +	 *   in case the predicate isn&apos;t matched&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	public static &amp;lt;T&amp;gt; CompletableFuture&amp;lt;T&amp;gt; retrySuccesfulWithDelay(&lt;br/&gt;
    +		final Supplier&amp;lt;CompletableFuture&amp;lt;T&amp;gt;&amp;gt; operation,&lt;br/&gt;
    +		final Time retryDelay,&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Deadline uses `Duration`, this method uses `Time`.&lt;/p&gt;</comment>
                            <comment id="16390208" author="githubbot" created="Wed, 7 Mar 2018 20:53:14 +0000"  >&lt;p&gt;Github user StephanEwen commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r172980585&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r172980585&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I have similar comments for this test as for #5654 - the test is fins in general, but can probably be simplified slightly, plus a bit of code style cleanup.&lt;/p&gt;</comment>
                            <comment id="16391115" author="githubbot" created="Thu, 8 Mar 2018 11:35:20 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r173134300&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r173134300&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Requests the &lt;/p&gt;
{@link JobStatus}
&lt;p&gt; of the job with the given &lt;/p&gt;
{@link JobID}
&lt;p&gt;.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private Future&amp;lt;JobStatus&amp;gt; getJobStatus(&lt;br/&gt;
    +		final ActorGateway jobManager,&lt;br/&gt;
    +		final JobID jobId,&lt;br/&gt;
    +		final FiniteDuration timeout) {&lt;br/&gt;
    +&lt;br/&gt;
    +		scala.concurrent.Future&amp;lt;Object&amp;gt; response =&lt;br/&gt;
    +			jobManager.ask(JobManagerMessages.getRequestJobStatus(jobId), timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		FlinkFuture&amp;lt;Object&amp;gt; flinkFuture = new FlinkFuture&amp;lt;&amp;gt;(response);&lt;br/&gt;
    +&lt;br/&gt;
    +		return flinkFuture.thenApply(new ApplyFunction&amp;lt;Object, JobStatus&amp;gt;() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public JobStatus apply(Object value) {&lt;br/&gt;
    +				if (value instanceof JobManagerMessages.CurrentJobStatus) &lt;/p&gt;
{
    +					return ((JobManagerMessages.CurrentJobStatus) value).status();
    +				}
&lt;p&gt; else if (value instanceof JobManagerMessages.JobNotFound) &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Could not find job with JobId &quot; + jobId));
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Unknown JobManager response of type &quot; + value.getClass()));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class UnboundedSource implements SourceFunction&amp;lt;String&amp;gt; {&lt;br/&gt;
    +		private boolean running = true;&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    fixing&lt;/p&gt;</comment>
                            <comment id="16391117" author="githubbot" created="Thu, 8 Mar 2018 11:35:46 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r173134402&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r173134402&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Requests the &lt;/p&gt;
{@link JobStatus}
&lt;p&gt; of the job with the given &lt;/p&gt;
{@link JobID}
&lt;p&gt;.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private Future&amp;lt;JobStatus&amp;gt; getJobStatus(&lt;br/&gt;
    +		final ActorGateway jobManager,&lt;br/&gt;
    +		final JobID jobId,&lt;br/&gt;
    +		final FiniteDuration timeout) {&lt;br/&gt;
    +&lt;br/&gt;
    +		scala.concurrent.Future&amp;lt;Object&amp;gt; response =&lt;br/&gt;
    +			jobManager.ask(JobManagerMessages.getRequestJobStatus(jobId), timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		FlinkFuture&amp;lt;Object&amp;gt; flinkFuture = new FlinkFuture&amp;lt;&amp;gt;(response);&lt;br/&gt;
    +&lt;br/&gt;
    +		return flinkFuture.thenApply(new ApplyFunction&amp;lt;Object, JobStatus&amp;gt;() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public JobStatus apply(Object value) {&lt;br/&gt;
    +				if (value instanceof JobManagerMessages.CurrentJobStatus) &lt;/p&gt;
{
    +					return ((JobManagerMessages.CurrentJobStatus) value).status();
    +				}
&lt;p&gt; else if (value instanceof JobManagerMessages.JobNotFound) &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Could not find job with JobId &quot; + jobId));
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Unknown JobManager response of type &quot; + value.getClass()));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class UnboundedSource implements SourceFunction&amp;lt;String&amp;gt; {&lt;br/&gt;
    +		private boolean running = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;String&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +			while (running) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I had this in an earlier version, but then I did some messing around. Fixing&lt;/p&gt;</comment>
                            <comment id="16391167" author="githubbot" created="Thu, 8 Mar 2018 12:22:38 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r173142759&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r173142759&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Requests the &lt;/p&gt;
{@link JobStatus}
&lt;p&gt; of the job with the given &lt;/p&gt;
{@link JobID}
&lt;p&gt;.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	private Future&amp;lt;JobStatus&amp;gt; getJobStatus(&lt;br/&gt;
    +		final ActorGateway jobManager,&lt;br/&gt;
    +		final JobID jobId,&lt;br/&gt;
    +		final FiniteDuration timeout) {&lt;br/&gt;
    +&lt;br/&gt;
    +		scala.concurrent.Future&amp;lt;Object&amp;gt; response =&lt;br/&gt;
    +			jobManager.ask(JobManagerMessages.getRequestJobStatus(jobId), timeout);&lt;br/&gt;
    +&lt;br/&gt;
    +		FlinkFuture&amp;lt;Object&amp;gt; flinkFuture = new FlinkFuture&amp;lt;&amp;gt;(response);&lt;br/&gt;
    +&lt;br/&gt;
    +		return flinkFuture.thenApply(new ApplyFunction&amp;lt;Object, JobStatus&amp;gt;() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public JobStatus apply(Object value) {&lt;br/&gt;
    +				if (value instanceof JobManagerMessages.CurrentJobStatus) &lt;/p&gt;
{
    +					return ((JobManagerMessages.CurrentJobStatus) value).status();
    +				}
&lt;p&gt; else if (value instanceof JobManagerMessages.JobNotFound) &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Could not find job with JobId &quot; + jobId));
    +				}
&lt;p&gt; else &lt;/p&gt;
{
    +					throw new RuntimeException(
    +						new IllegalStateException(&quot;Unknown JobManager response of type &quot; + value.getClass()));
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class UnboundedSource implements SourceFunction&amp;lt;String&amp;gt; {&lt;br/&gt;
    +		private boolean running = true;&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void run(SourceContext&amp;lt;String&amp;gt; ctx) throws Exception {&lt;br/&gt;
    +			while (running) {&lt;br/&gt;
    +				ctx.collect(&quot;hello&quot;);&lt;br/&gt;
    +				// don&apos;t overdo it ... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
    +				Thread.sleep(50);&lt;br/&gt;
    +				if (CheckpointBlockingFunction.afterMessWithZooKeeper.get()) &lt;/p&gt;
{
    +					break;
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void cancel() &lt;/p&gt;
{
    +			running = false;
    +		}
&lt;p&gt;    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	private static class CheckpointBlockingFunction&lt;br/&gt;
    +			extends RichMapFunction&amp;lt;String, String&amp;gt;&lt;br/&gt;
    +			implements CheckpointedFunction {&lt;br/&gt;
    +&lt;br/&gt;
    +		// verify that we only call initializeState()&lt;br/&gt;
    +		// once with isRestored() == false. All other invocations must have isRestored() == true. This&lt;br/&gt;
    +		// verifies that we don&apos;t restart a job from scratch in case the CompletedCheckpoints can&apos;t&lt;br/&gt;
    +		// be read.&lt;br/&gt;
    +		static AtomicInteger allowedInitializeCallsWithoutRestore = new AtomicInteger(1);&lt;br/&gt;
    +&lt;br/&gt;
    +		// we count when we see restores that are not allowed. We only&lt;br/&gt;
    +		// allow restores once we messed with the HA directory and moved it back again&lt;br/&gt;
    +		static AtomicInteger illegalRestores = new AtomicInteger(0);&lt;br/&gt;
    +		static AtomicInteger successfulRestores = new AtomicInteger(0);&lt;br/&gt;
    +&lt;br/&gt;
    +		// whether we are after the phase where we messed with the ZooKeeper HA directory, i.e.&lt;br/&gt;
    +		// whether it&apos;s now ok for a restore to happen&lt;br/&gt;
    +		static AtomicBoolean afterMessWithZooKeeper = new AtomicBoolean(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		static AtomicBoolean failedAlready = new AtomicBoolean(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		// also have some state to write to the checkpoint&lt;br/&gt;
    +		private final ValueStateDescriptor&amp;lt;String&amp;gt; stateDescriptor =&lt;br/&gt;
    +			new ValueStateDescriptor&amp;lt;&amp;gt;(&quot;state&quot;, StringSerializer.INSTANCE);&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public String map(String value) throws Exception &lt;/p&gt;
{
    +			getRuntimeContext().getState(stateDescriptor).update(&quot;42&quot;);
    +			return value;
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void snapshotState(FunctionSnapshotContext context) throws Exception {&lt;br/&gt;
    +			if (context.getCheckpointId() &amp;gt; 5) {&lt;br/&gt;
    +				waitForCheckpointLatch.trigger();&lt;br/&gt;
    +				failInCheckpointLatch.await();&lt;br/&gt;
    +				if (!failedAlready.getAndSet(true)) &lt;/p&gt;
{
    +					throw new RuntimeException(&quot;Failing on purpose.&quot;);
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		@Override&lt;br/&gt;
    +		public void initializeState(FunctionInitializationContext context) {&lt;br/&gt;
    +			if (!context.isRestored()) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    No, this is exactly the thing we want to test. If we didn&apos;t have this check we would allow the case where ZooKeeper cannot read any of the state handles and will start the job from scratch.&lt;/p&gt;

&lt;p&gt;    There might be other ways around it but I like this explicit way. What do you think?&lt;/p&gt;</comment>
                            <comment id="16391169" author="githubbot" created="Thu, 8 Mar 2018 12:23:29 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r173142937&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r173142937&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes, I&apos;ll remove that.&lt;/p&gt;</comment>
                            <comment id="16391171" author="githubbot" created="Thu, 8 Mar 2018 12:24:43 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654#discussion_r173143151&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654#discussion_r173143151&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,387 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.FilterFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.ApplyFunction;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.Future;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.impl.FlinkFuture;&lt;br/&gt;
    +import org.apache.flink.runtime.instance.ActorGateway;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.messages.JobManagerMessages;&lt;br/&gt;
    +import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.TestBaseUtils;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.Callable;&lt;br/&gt;
    +import java.util.concurrent.TimeUnit;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import scala.concurrent.Await;&lt;br/&gt;
    +import scala.concurrent.duration.Deadline;&lt;br/&gt;
    +import scala.concurrent.duration.FiniteDuration;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestBaseUtils {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final FiniteDuration TEST_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static LocalFlinkMiniCluster cluster = null;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		cluster = TestBaseUtils.startCluster(config, false);
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		stopCluster(cluster, TestBaseUtils.DEFAULT_TIMEOUT);
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final Deadline deadline = TEST_TIMEOUT.fromNow();&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend(new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy(new KeySelector&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public String getKey(String value) &lt;/p&gt;
{
    +					return value;
    +				}
&lt;p&gt;    +			})&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		final JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		// Retrieve the job manager&lt;br/&gt;
    +		final ActorGateway jobManager = Await.result(cluster.leaderGateway().future(), deadline.timeLeft());&lt;br/&gt;
    +&lt;br/&gt;
    +		cluster.submitJobDetached(jobGraph);&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		assertTrue(numCheckpoints &amp;gt; 0);&lt;br/&gt;
    +&lt;br/&gt;
    +		failInCheckpointLatch.trigger();&lt;br/&gt;
    +&lt;br/&gt;
    +		// Ensure that we see at least one cycle where the job tries to restart and fails.&lt;br/&gt;
    +		Future&amp;lt;JobStatus&amp;gt; jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call()&lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus){
    +					return jobStatus == JobStatus.RESTARTING;
    +				}&lt;br/&gt;
    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.RESTARTING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() {    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FAILING;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FAILING, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// move back the HA directory so that the job can restore&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		files = movedCheckpointLocation.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(haStorageDir, file.getName())));
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +&lt;br/&gt;
    +		// now the job should be able to go to RUNNING again and then eventually to FINISHED&lt;br/&gt;
    +		jobStatusFuture = FutureUtils.retrySuccessful(&lt;br/&gt;
    +			new Callable&amp;lt;Future&amp;lt;JobStatus&amp;gt;&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public Future&amp;lt;JobStatus&amp;gt; call() &lt;/p&gt;
{
    +					return getJobStatus(jobManager, jobID, TEST_TIMEOUT);
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			new FilterFunction&amp;lt;JobStatus&amp;gt;() {&lt;br/&gt;
    +				@Override&lt;br/&gt;
    +				public boolean filter(JobStatus jobStatus) &lt;/p&gt;
{
    +					return jobStatus == JobStatus.FINISHED;
    +				}
&lt;p&gt;    +			},&lt;br/&gt;
    +			deadline,&lt;br/&gt;
    +			TestingUtils.defaultExecutor());&lt;br/&gt;
    +		assertEquals(JobStatus.FINISHED, jobStatusFuture.get());&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure we saw a successful restore&lt;br/&gt;
    +		successfulRestoreLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		assertThat(&quot;We saw illegal restores.&quot;, CheckpointBlockingFunction.illegalRestores.get(), is(0));&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I think it is necessary, without more in-depth re-writing of the test, see comment above.&lt;/p&gt;

&lt;p&gt;    Regarding `assertThat`, I like it because it reads more like a sentence but I can also change it.&lt;/p&gt;</comment>
                            <comment id="16391261" author="githubbot" created="Thu, 8 Mar 2018 13:55:41 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @StephanEwen pushed some changes&lt;/p&gt;</comment>
                            <comment id="16391268" author="githubbot" created="Thu, 8 Mar 2018 14:00:57 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r173164690&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r173164690&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-tests/src/test/java/org/apache/flink/test/checkpointing/ZooKeeperHighAvailabilityITCase.java &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,333 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +&lt;br/&gt;
    +package org.apache.flink.test.checkpointing;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.flink.api.common.JobID;&lt;br/&gt;
    +import org.apache.flink.api.common.functions.RichMapFunction;&lt;br/&gt;
    +import org.apache.flink.api.common.restartstrategy.RestartStrategies;&lt;br/&gt;
    +import org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Deadline;&lt;br/&gt;
    +import org.apache.flink.api.common.time.Time;&lt;br/&gt;
    +import org.apache.flink.api.common.typeutils.base.StringSerializer;&lt;br/&gt;
    +import org.apache.flink.client.program.ClusterClient;&lt;br/&gt;
    +import org.apache.flink.configuration.ConfigConstants;&lt;br/&gt;
    +import org.apache.flink.configuration.Configuration;&lt;br/&gt;
    +import org.apache.flink.configuration.HighAvailabilityOptions;&lt;br/&gt;
    +import org.apache.flink.configuration.TaskManagerOptions;&lt;br/&gt;
    +import org.apache.flink.core.testutils.OneShotLatch;&lt;br/&gt;
    +import org.apache.flink.runtime.concurrent.FutureUtils;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobGraph;&lt;br/&gt;
    +import org.apache.flink.runtime.jobgraph.JobStatus;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionInitializationContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.FunctionSnapshotContext;&lt;br/&gt;
    +import org.apache.flink.runtime.state.StateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.state.filesystem.FsStateBackend;&lt;br/&gt;
    +import org.apache.flink.runtime.testingUtils.TestingUtils;&lt;br/&gt;
    +import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;&lt;br/&gt;
    +import org.apache.flink.streaming.api.datastream.DataStreamSource;&lt;br/&gt;
    +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;
    +import org.apache.flink.test.util.MiniClusterResource;&lt;br/&gt;
    +import org.apache.flink.util.Preconditions;&lt;br/&gt;
    +import org.apache.flink.util.TestLogger;&lt;br/&gt;
    +&lt;br/&gt;
    +import org.apache.curator.test.TestingServer;&lt;br/&gt;
    +import org.junit.AfterClass;&lt;br/&gt;
    +import org.junit.BeforeClass;&lt;br/&gt;
    +import org.junit.ClassRule;&lt;br/&gt;
    +import org.junit.Test;&lt;br/&gt;
    +import org.junit.rules.TemporaryFolder;&lt;br/&gt;
    +&lt;br/&gt;
    +import java.io.File;&lt;br/&gt;
    +import java.time.Duration;&lt;br/&gt;
    +import java.util.UUID;&lt;br/&gt;
    +import java.util.concurrent.CompletableFuture;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
    +import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
    +&lt;br/&gt;
    +import static org.hamcrest.core.Is.is;&lt;br/&gt;
    +import static org.junit.Assert.assertEquals;&lt;br/&gt;
    +import static org.junit.Assert.assertNotNull;&lt;br/&gt;
    +import static org.junit.Assert.assertThat;&lt;br/&gt;
    +import static org.junit.Assert.assertTrue;&lt;br/&gt;
    +&lt;br/&gt;
    +/**&lt;br/&gt;
    + * Integration tests for &lt;/p&gt;
{@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}
&lt;p&gt;.&lt;br/&gt;
    + */&lt;br/&gt;
    +public class ZooKeeperHighAvailabilityITCase extends TestLogger {&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final Duration TEST_TIMEOUT = Duration.ofSeconds(10000L);&lt;br/&gt;
    +&lt;br/&gt;
    +	private static final int NUM_JMS = 1;&lt;br/&gt;
    +	private static final int NUM_TMS = 1;&lt;br/&gt;
    +	private static final int NUM_SLOTS_PER_TM = 1;&lt;br/&gt;
    +&lt;br/&gt;
    +	@ClassRule&lt;br/&gt;
    +	public static final TemporaryFolder temporaryFolder = new TemporaryFolder();&lt;br/&gt;
    +&lt;br/&gt;
    +	private static File haStorageDir;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static TestingServer zkServer;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static MiniClusterResource miniClusterResource;&lt;br/&gt;
    +&lt;br/&gt;
    +	private static OneShotLatch waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +	private static OneShotLatch successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +	@BeforeClass&lt;br/&gt;
    +	public static void setup() throws Exception &lt;/p&gt;
{
    +		zkServer = new TestingServer();
    +
    +		Configuration config = new Configuration();
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, NUM_JMS);
    +		config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS);
    +		config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM);
    +
    +		haStorageDir = temporaryFolder.newFolder();
    +
    +		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, haStorageDir.toString());
    +		config.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
    +		config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString());
    +		config.setString(HighAvailabilityOptions.HA_MODE, &quot;zookeeper&quot;);
    +
    +		// we have to manage this manually because we have to create the ZooKeeper server
    +		// ahead of this
    +		miniClusterResource = new MiniClusterResource(
    +			new MiniClusterResource.MiniClusterResourceConfiguration(
    +				config,
    +				NUM_TMS,
    +				NUM_SLOTS_PER_TM));
    +
    +		miniClusterResource.before();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	@AfterClass&lt;br/&gt;
    +	public static void tearDown() throws Exception &lt;/p&gt;
{
    +		miniClusterResource.after();
    +
    +		zkServer.stop();
    +		zkServer.close();
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Verify that we don&apos;t start a job from scratch if we cannot restore any of the&lt;br/&gt;
    +	 * CompletedCheckpoints.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;Synchronization for the different steps and things we want to observe happens via&lt;br/&gt;
    +	 * latches in the test method and the methods of &lt;/p&gt;
{@link CheckpointBlockingFunction}
&lt;p&gt;.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * &amp;lt;p&amp;gt;The test follows these steps:&lt;br/&gt;
    +	 * &amp;lt;ol&amp;gt;&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Start job and block on a latch until we have done some checkpoints&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Block in the special function&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move away the contents of the ZooKeeper HA directory to make restoring from&lt;br/&gt;
    +	 *       checkpoints impossible&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Unblock the special function, which now induces a failure&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job does not recover successfully&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Move back the HA directory&lt;br/&gt;
    +	 *     &amp;lt;li&amp;gt;Make sure that the job recovers, we use a latch to ensure that the operator&lt;br/&gt;
    +	 *       restored successfully&lt;br/&gt;
    +	 * &amp;lt;/ol&amp;gt;&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout = 120_000L)&lt;br/&gt;
    +	public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {&lt;br/&gt;
    +		CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);&lt;br/&gt;
    +		CheckpointBlockingFunction.successfulRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.illegalRestores.set(0);&lt;br/&gt;
    +		CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);&lt;br/&gt;
    +		CheckpointBlockingFunction.failedAlready.set(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		waitForCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		failInCheckpointLatch = new OneShotLatch();&lt;br/&gt;
    +		successfulRestoreLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		ClusterClient&amp;lt;?&amp;gt; clusterClient = miniClusterResource.getClusterClient();&lt;br/&gt;
    +		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT);&lt;br/&gt;
    +&lt;br/&gt;
    +		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;
    +		env.setParallelism(1);&lt;br/&gt;
    +		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0));&lt;br/&gt;
    +		env.enableCheckpointing(10); // Flink doesn&apos;t allow lower than 10 ms&lt;br/&gt;
    +&lt;br/&gt;
    +		File checkpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		env.setStateBackend((StateBackend) new FsStateBackend(checkpointLocation.toURI()));&lt;br/&gt;
    +&lt;br/&gt;
    +		DataStreamSource&amp;lt;String&amp;gt; source = env.addSource(new UnboundedSource());&lt;br/&gt;
    +&lt;br/&gt;
    +		source&lt;br/&gt;
    +			.keyBy((str) -&amp;gt; str)&lt;br/&gt;
    +			.map(new CheckpointBlockingFunction());&lt;br/&gt;
    +&lt;br/&gt;
    +		JobGraph jobGraph = env.getStreamGraph().getJobGraph();&lt;br/&gt;
    +		JobID jobID = Preconditions.checkNotNull(jobGraph.getJobID());&lt;br/&gt;
    +&lt;br/&gt;
    +		clusterClient.setDetached(true);&lt;br/&gt;
    +		clusterClient.submitJob(jobGraph, ZooKeeperHighAvailabilityITCase.class.getClassLoader());&lt;br/&gt;
    +&lt;br/&gt;
    +		// wait until we did some checkpoints&lt;br/&gt;
    +		waitForCheckpointLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// mess with the HA directory so that the job cannot restore&lt;br/&gt;
    +		File movedCheckpointLocation = temporaryFolder.newFolder();&lt;br/&gt;
    +		int numCheckpoints = 0;&lt;br/&gt;
    +		File[] files = haStorageDir.listFiles();&lt;br/&gt;
    +		assertNotNull(files);&lt;br/&gt;
    +		for (File file : files) {&lt;br/&gt;
    +			if (file.getName().startsWith(&quot;completedCheckpoint&quot;)) &lt;/p&gt;
{
    +				assertTrue(file.renameTo(new File(movedCheckpointLocation, file.getName())));
    +				numCheckpoints++;
    +			}
&lt;p&gt;    +		}&lt;br/&gt;
    +		// Note to future developers: This will break when we change Flink to not put the&lt;br/&gt;
    +		// checkpoint metadata into the HA directory but instead rely on the fact that the&lt;br/&gt;
    +		// actual checkpoint directory on DFS contains the checkpoint metadata. In this case,&lt;br/&gt;
    +		// ZooKeeper will only contain a &quot;handle&quot; (read: String) that points to the metadata&lt;br/&gt;
    +		// in DFS. The likely solution will be that we have to go directly to ZooKeeper, find&lt;br/&gt;
    +		// out where the checkpoint is stored and mess with that.&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You mean for now or for the future? I did that in an initial version but I wanted to verify that there are actually checkpoints that I&apos;m moving and also there is other stuff in the HA directory that I don&apos;t want to move to not interfere with the test.&lt;/p&gt;</comment>
                            <comment id="16391428" author="aljoscha" created="Thu, 8 Mar 2018 15:54:32 +0000"  >&lt;p&gt;ITCase added on release-1.3 in&lt;br/&gt;
b6cfe7baaf22cd0ab6d3f57ef247434e1ec44f6f&lt;/p&gt;</comment>
                            <comment id="16391429" author="githubbot" created="Thu, 8 Mar 2018 15:55:11 +0000"  >&lt;p&gt;Github user aljoscha closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16391512" author="githubbot" created="Thu, 8 Mar 2018 16:55:15 +0000"  >&lt;p&gt;Github user aljoscha closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5655&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5655&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16391533" author="aljoscha" created="Thu, 8 Mar 2018 17:09:29 +0000"  >&lt;p&gt;ITCase added on release-1.4 in&lt;br/&gt;
72b3ddad1df86f383ea4f75e3dd597a07374df65&lt;/p&gt;</comment>
                            <comment id="16391534" author="githubbot" created="Thu, 8 Mar 2018 17:09:45 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5654&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5654&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    merged&lt;/p&gt;</comment>
                            <comment id="16391556" author="githubbot" created="Thu, 8 Mar 2018 17:17:14 +0000"  >&lt;p&gt;Github user aljoscha commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656#discussion_r173227736&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656#discussion_r173227736&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-runtime/src/main/java/org/apache/flink/runtime/concurrent/FutureUtils.java &amp;#8212;&lt;br/&gt;
    @@ -223,6 +224,81 @@&lt;br/&gt;
     		}&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * Retry the given operation with the given delay in between successful completions where the&lt;br/&gt;
    +	 * result does not match a given predicate.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * @param operation to retry&lt;br/&gt;
    +	 * @param retryDelay delay between retries&lt;br/&gt;
    +	 * @param deadline A deadline that specifies at what point we should stop retrying&lt;br/&gt;
    +	 * @param acceptancePredicate Predicate to test whether the result is acceptable&lt;br/&gt;
    +	 * @param scheduledExecutor executor to be used for the retry operation&lt;br/&gt;
    +	 * @param &amp;lt;T&amp;gt; type of the result&lt;br/&gt;
    +	 * @return Future which retries the given operation a given amount of times and delays the retry&lt;br/&gt;
    +	 *   in case the predicate isn&apos;t matched&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	public static &amp;lt;T&amp;gt; CompletableFuture&amp;lt;T&amp;gt; retrySuccesfulWithDelay(&lt;br/&gt;
    +		final Supplier&amp;lt;CompletableFuture&amp;lt;T&amp;gt;&amp;gt; operation,&lt;br/&gt;
    +		final Time retryDelay,&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The reason is that the other methods in this class use `Time`, but I can switch the new ones to `Duration`.&lt;/p&gt;</comment>
                            <comment id="16391619" author="githubbot" created="Thu, 8 Mar 2018 17:49:08 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    rebased&lt;/p&gt;
</comment>
                            <comment id="16392682" author="githubbot" created="Fri, 9 Mar 2018 10:31:26 +0000"  >&lt;p&gt;Github user StephanEwen commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Looks good to me now.&lt;/p&gt;

&lt;p&gt;    +1&lt;/p&gt;</comment>
                            <comment id="16394544" author="githubbot" created="Sun, 11 Mar 2018 15:44:20 +0000"  >&lt;p&gt;Github user aljoscha commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    merged&lt;/p&gt;</comment>
                            <comment id="16394545" author="githubbot" created="Sun, 11 Mar 2018 15:44:20 +0000"  >&lt;p&gt;Github user aljoscha closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/5656&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/5656&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16394546" author="aljoscha" created="Sun, 11 Mar 2018 15:44:54 +0000"  >&lt;p&gt;Added final tests.&lt;/p&gt;

&lt;p&gt;on release-1.5&lt;br/&gt;
b4f9e61b5d061f2fa9166bc5ea83ef6cd80eb0e6&lt;/p&gt;

&lt;p&gt;on master&lt;br/&gt;
4c85b74016a1e6587038053f576b8293aa72126e&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 36 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3p8j3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>