<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:52:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-20663] Managed memory may not be released in time when operators use managed memory frequently</title>
                <link>https://issues.apache.org/jira/browse/FLINK-20663</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Some batch operators (like sort merge join or hash aggregate) use managed memory frequently. When these operators are chained together and the cluster load is a bit heavy, it is very likely that the following exception occurs:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2020-12-18 10:04:32
java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:85)
	at org.apache.flink.runtime.io.disk.SimpleCollectingOutputView.&amp;lt;init&amp;gt;(SimpleCollectingOutputView.java:49)
	at org.apache.flink.table.runtime.operators.aggregate.BytesHashMap$RecordArea.&amp;lt;init&amp;gt;(BytesHashMap.java:297)
	at org.apache.flink.table.runtime.operators.aggregate.BytesHashMap.&amp;lt;init&amp;gt;(BytesHashMap.java:103)
	at org.apache.flink.table.runtime.operators.aggregate.BytesHashMap.&amp;lt;init&amp;gt;(BytesHashMap.java:90)
	at LocalHashAggregateWithKeys$209161.open(Unknown Source)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:401)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:506)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$SynchronizedStreamTaskActionExecutor.runThrowing(StreamTaskActionExecutor.java:92)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:501)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:530)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:722)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:547)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:834)
	Suppressed: java.lang.NullPointerException
		at LocalHashAggregateWithKeys$209161.close(Unknown Source)
		at org.apache.flink.table.runtime.operators.TableStreamOperator.dispose(TableStreamOperator.java:46)
		at org.apache.flink.streaming.runtime.tasks.StreamTask.disposeAllOperators(StreamTask.java:739)
		at org.apache.flink.streaming.runtime.tasks.StreamTask.runAndSuppressThrowable(StreamTask.java:719)
		at org.apache.flink.streaming.runtime.tasks.StreamTask.cleanUpInvoke(StreamTask.java:642)
		at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:551)
		... 3 more
		Suppressed: java.lang.NullPointerException
			at LocalHashAggregateWithKeys$209766.close(Unknown Source)
			... 8 more
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:231)
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:83)
	... 13 more
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 9961487 bytes are remaining. This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; running on an old Java version.
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:164)
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:80)
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:229)
	... 14 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems that this is caused by relying on GC to release managed memory, as &lt;tt&gt;System.gc()&lt;/tt&gt; may not trigger GC in time. See &lt;tt&gt;UnsafeMemoryBudget.java&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13346693">FLINK-20663</key>
            <summary>Managed memory may not be released in time when operators use managed memory frequently</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="xtsong">Xintong Song</assignee>
                                    <reporter username="TsReaper">Caizhi Weng</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 18 Dec 2020 02:31:55 +0000</created>
                <updated>Fri, 9 Apr 2021 11:43:47 +0000</updated>
                            <resolved>Mon, 15 Feb 2021 15:24:20 +0000</resolved>
                                    <version>1.12.0</version>
                                    <fixVersion>1.12.2</fixVersion>
                    <fixVersion>1.13.0</fixVersion>
                                    <component>Runtime / Task</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="17272753" author="xintongsong" created="Wed, 27 Jan 2021 10:34:09 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;According to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ykt836&quot; class=&quot;user-hover&quot; rel=&quot;ykt836&quot;&gt;ykt836&lt;/a&gt;, this has become a severe problem for batch processing, especially the OLAP scenarios.&lt;/p&gt;

&lt;p&gt;I traced the discussions and changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-15758&quot; title=&quot;Investigate potential out-of-memory problems due to managed unsafe memory allocation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-15758&quot;&gt;&lt;del&gt;FLINK-15758&lt;/del&gt;&lt;/a&gt; and other related issues. It seems to me that we do not concretely see any problem in accessing the memory after the segment being released, except for the verifications in `MemorySegmentTestBase#testByteBufferWrapping`.&lt;/p&gt;

&lt;p&gt;I&apos;m currently working with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ykt836&quot; class=&quot;user-hover&quot; rel=&quot;ykt836&quot;&gt;ykt836&lt;/a&gt;&apos;s team on some internal experiments see if actively deallocate memory on the segment being freed indeed cause any trouble. Do you think it would be possible that, if the experiments go well, we bring the active releasing back at least for the use cases that is currently suffering from this issue?&lt;/p&gt;</comment>
                            <comment id="17272763" author="ykt836" created="Wed, 27 Jan 2021 10:50:58 +0000"  >&lt;p&gt;It&apos;s not necessarily be OLAP scenario, but normal batch job will trigger this problem, if the TM will be reused by several tasks. The root cause is relying on GC to release memory is not only slow but time consuming. We have observed performance regression, high full gc counts and also causing OOM triggering unnecessary job failure.&#160;&lt;/p&gt;

&lt;p&gt;Most importantly, we didn&apos;t get benefit from such complex design... I would suggest we fallback to a simpler way, just like Flink did in the old days. (AFAIK, we didn&apos;t suffer any mis using issue before we changed this mechanism).&#160;&lt;/p&gt;

&lt;p&gt;cc&#160;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sewen&quot; class=&quot;user-hover&quot; rel=&quot;sewen&quot;&gt;sewen&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17273080" author="till.rohrmann" created="Wed, 27 Jan 2021 18:38:11 +0000"  >&lt;p&gt;Thanks for reporting this issue. Which Java version are you using when this problem occurs? Versions below jdk8u72 don&apos;t reliably work (&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-18581&quot; title=&quot;Cannot find GC cleaner with java version previous jdk8u72(-b01)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-18581&quot;&gt;&lt;del&gt;FLINK-18581&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Can you reproduce the same problem when using the DataSet API? I just want to make sure that we don&apos;t have a resource leak somewhere. Maybe drawing a heap dump could help shine some light on the problem.&lt;/p&gt;

&lt;p&gt;Just to give a bit of background: The problem &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-15758&quot; title=&quot;Investigate potential out-of-memory problems due to managed unsafe memory allocation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-15758&quot;&gt;&lt;del&gt;FLINK-15758&lt;/del&gt;&lt;/a&gt; is supposed to solve is &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-14894&quot; title=&quot;HybridOffHeapUnsafeMemorySegmentTest#testByteBufferWrap failed on Travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-14894&quot;&gt;&lt;del&gt;FLINK-14894&lt;/del&gt;&lt;/a&gt;. Since we don&apos;t do ref counting for the &lt;tt&gt;MemorySegments&lt;/tt&gt; it is hard to know when we can truly release a &lt;tt&gt;MemorySegment&lt;/tt&gt;. If we release a segment and we still have an owner which accesses this segment, then this can potentially lead to memory corruption. It is best described here: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-14894?focusedCommentId=17023015&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17023015&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-14894?focusedCommentId=17023015&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17023015&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17273247" author="ykt836" created="Thu, 28 Jan 2021 01:25:10 +0000"  >&lt;p&gt;IIRC in the past, users of managed memory (operators, data structures) are required to know the contract when using memory segment, which is when they release the memory segments, they can just return the object back to memory manager, and don&apos;t access it ever again.&#160;&lt;/p&gt;

&lt;p&gt;And &lt;tt&gt;HybridMemorySegment&lt;/tt&gt;&#160;and &lt;tt&gt;MemorySegment&lt;/tt&gt; also provided some protection after being released in their free() method. The only exception is wrap() method, which caused &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-14894&quot; title=&quot;HybridOffHeapUnsafeMemorySegmentTest#testByteBufferWrap failed on Travis&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-14894&quot;&gt;&lt;del&gt;FLINK-14894&lt;/del&gt;&lt;/a&gt;. But wrap() method is not that popular, and half of them are used by network buffer which is not even managed (they are unpooled segments). Other than this, all other methods are safe to use and will raise exception if being misused.&lt;/p&gt;

&lt;p&gt;So my thought is, instead of relying on such inefficient and complex way (Full GC) to protect only one usage about memory segment, we can change this to much simpler way (like the old behaviors) and we pay enough attention of the wrap() method, e.g. adding some comments or find some way to protect the wrapped ByteBuffer.&#160;&lt;/p&gt;</comment>
                            <comment id="17273493" author="xintongsong" created="Thu, 28 Jan 2021 10:45:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;If we release a segment and we still have an owner which accesses this segment, then this can potentially lead to memory corruption.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I understand the concern and thus the current GC-based memory releasing. And I&apos;m also not sure whether the segment may indeed get accessed after being released. However, if a segment is accessed after being freed, wouldn&apos;t it already cause problems when previously heap/direct memory segments are reused (with the memory pre-allocation) across jobs/tasks?&lt;/p&gt;</comment>
                            <comment id="17273762" author="till.rohrmann" created="Thu, 28 Jan 2021 14:27:03 +0000"  >&lt;p&gt;I understand that the current approach is not ideal in terms of performance. Before jumping to conclusions, can we verify whether we don&apos;t have a resource leak somewhere? I just wanna make sure that we don&apos;t overlook something in this discussion.&lt;/p&gt;

&lt;p&gt;In general, I think that implicit contracts such as when using &lt;tt&gt;wrap()&lt;/tt&gt; you have to make sure that you don&apos;t access the &lt;tt&gt;ByteBuffer&lt;/tt&gt; after releasing the owning &lt;tt&gt;MemorySegment&lt;/tt&gt; are bound to break eventually. Also comments won&apos;t really help against the problem. I also think that it does not make a difference whether the segment is pooled or unpooled. The only proper way I see at the moment is to make sure that accesses to &lt;tt&gt;ByteBuffer&lt;/tt&gt; fail when the owning &lt;tt&gt;MemorySegment&lt;/tt&gt; is released. &lt;/p&gt;

&lt;p&gt;At the moment, the &lt;tt&gt;MemorySegmentTestBase.testByteBufferWrapping&lt;/tt&gt; ensures explicitly that we can access &lt;tt&gt;ByteBuffers&lt;/tt&gt; after the &lt;tt&gt;MemorySegment&lt;/tt&gt; has been released. Hence, I cannot rule out that we don&apos;t rely on this contract somewhere. We would have to hunt these places down and change the behaviour with a proper lifecycle management of the underlying memory.&lt;/p&gt;

&lt;p&gt;If I remember correctly, then the problem is that we wouldn&apos;t necessarily see an illegal access because the underlying memory could have been allocated by a different &lt;tt&gt;MemorySegment&lt;/tt&gt; in the same JVM. In this case, the access could silently corrupt some data w/o us ever realizing. I also think that we no longer allocate all the memory from the get go but only once the &lt;tt&gt;TaskSlots&lt;/tt&gt; are created.&lt;/p&gt;</comment>
                            <comment id="17274107" author="ykt836" created="Fri, 29 Jan 2021 01:58:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;Before jumping to conclusions, can we verify whether we don&apos;t have a resource leak somewhere? I just wanna make sure that we don&apos;t overlook something in this discussion.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, we should definitely do this. We have modified this internally and running a bunch of cases to see whether there are some memory rats.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;I understand that the current approach is not ideal in terms of performance.&#160;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;From our experience, it only only affects performance but also cause instability. For streaming jobs, it might be okay, since they only allocate / free memory occasionally,&#160; like when starting or stopping the job. For batch jobs, there will be much more frequent allocation/free. It will cause much more full GC, sometimes it will throw OOM exception if JVM can&apos;t free the memory enough quickly, and we also see full GC blocking some RPC thread and causing a bunch of timeout.&lt;/p&gt;

&lt;p&gt;I also see the potential dangerous of &quot;unmanaged&quot; wrap() call will cause risk in the future. The ideal way would be we make it simple and straightforward for those memory users who follow the contract correctly (no more relying on GC for these), and we also have some safety net to hunt down the bad guys.&#160;&#160;&lt;/p&gt;

&lt;p&gt;Right now, we are using the safety net as the only option. No matter how correct you follow the contract, you still need to wait for GC to really free the memory you want to return, causing issues &amp;amp; instability for the job. Thus I think it&apos;s kind of unfair.&#160;&lt;/p&gt;</comment>
                            <comment id="17276114" author="tsreaper" created="Mon, 1 Feb 2021 07:47:57 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&apos;ve tested the patch &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt; provided on some large batch SQL jobs and the memory problem didn&apos;t occur anymore (these jobs will frequently fail with memory problem every 10 minutes or so without the patch), so from the test results I think this is a decent solution.&lt;/p&gt;</comment>
                            <comment id="17276298" author="ykt836" created="Mon, 1 Feb 2021 12:52:40 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=TsReaper&quot; class=&quot;user-hover&quot; rel=&quot;TsReaper&quot;&gt;TsReaper&lt;/a&gt;&#160;for the testing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;&#160;I see following choices we have now:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Revert the GC based memory free mechanism and simply rely on the memory usage contract&lt;/li&gt;
	&lt;li&gt;Choose 1 and find a way to protect the exception (wrap() method in this case)&lt;/li&gt;
	&lt;li&gt;Further improve current mechanism to avoid performance &amp;amp; stability regression&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I personally don&apos;t want to go with option 3 because it&apos;s already quite complex now. And most importantly, such mechanism doesn&apos;t create any value for now, only regression. What&apos;s your opinion?&lt;/p&gt;</comment>
                            <comment id="17276797" author="xintongsong" created="Tue, 2 Feb 2021 02:15:31 +0000"  >&lt;p&gt;I think option 2) might be a good way to go.&lt;/p&gt;

&lt;p&gt;It looks like the underlying native memory of a segment is always accessed through the wrapped ByteBuffers. We could implement something like a WrappedByteBuffer. All read / write operations should be forwarded to the original ByteBuffer before the underlying memory is released, and fail after the memory is released. A ReadWriteLock is needed to make sure the freeing the segment is visible to all the wrapped ByteBuffers immediately.&lt;/p&gt;

&lt;p&gt;I&apos;m still looking into this. There&apos;re a few things to be checked.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Impact on performance due to the lock-based synchronization&lt;/li&gt;
	&lt;li&gt;Potential read/write API changes on ByteBuffer between different Java versions&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;If this can work, I would suggest the following actions.&lt;br/&gt;
1. Fail explicitly on attempts to access the memory after it&apos;s freed&lt;br/&gt;
2. By default release the memory when the segment is freed. This would make the potential access-after-release issues surface.&lt;br/&gt;
3. Keep the configuration option to disable releasing memory when the segment is freed and fallback to GC, in case users indeed run into access-after-release issues.&lt;br/&gt;
4. Remove the configuration option once we are confidence that there&apos;s no more access-after-release issues. This is optional. We could also keep it incase new access-after-release issues are introduced in future.&lt;/p&gt;</comment>
                            <comment id="17276801" author="ykt836" created="Tue, 2 Feb 2021 02:32:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&#160;It doesn&apos;t need to be such complex. We can still use `DirectByteBuffer` after being wrapped, and record down it into a list. When free then parent segment, we can iterate the wrapped list to either:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;call limit(0)&lt;/li&gt;
	&lt;li&gt;set address to -1 with reflection&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17276823" author="xintongsong" created="Tue, 2 Feb 2021 03:10:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ykt836&quot; class=&quot;user-hover&quot; rel=&quot;ykt836&quot;&gt;ykt836&lt;/a&gt;,&lt;br/&gt;
I don&apos;t think that works.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ByteBuffer bb1 = segment.wrap(offset, size);
ByteBuffer bb2 = bb1.duplicate();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In the above example, &lt;tt&gt;bb2&lt;/tt&gt; will not be added to the recording list, thus can still access the memory. With our own `WrappedByteBuffer` implementation, we can make sure calling `duplicate()` on it will also return a `WrappedByteBuffer`.&lt;/p&gt;

&lt;p&gt;Also, I don&apos;t think `DirectByteBuffer` is thread safe, thus changing its `limit` or `address` will not be visible to other threads immediately.&lt;/p&gt;</comment>
                            <comment id="17276827" author="ykt836" created="Tue, 2 Feb 2021 03:32:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&#160;You are correct.&#160;&lt;/p&gt;

&lt;p&gt;Regarding to the lock part, do we really need this? Neither MemorySegment or ByteBuffer is thread safe, why suddenly we have to provide a thread-safe version?&#160;&lt;/p&gt;</comment>
                            <comment id="17276841" author="xintongsong" created="Tue, 2 Feb 2021 03:56:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;Regarding to the lock part, do we really need this? Neither MemorySegment or ByteBuffer is thread safe, why suddenly we have to provide a thread-safe version?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s a good point. I&apos;d be glad to see if we don&apos;t need the lock, which solves the performance concern. However, I would need a bit more investigation to confirm that.&lt;/p&gt;</comment>
                            <comment id="17276849" author="ykt836" created="Tue, 2 Feb 2021 04:15:11 +0000"  >&lt;p&gt;One more comment to hint that we are pretty safe when using managed memory.&lt;/p&gt;

&lt;p&gt;With Flink &amp;lt;= 1.9, the default managed memory type &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; is heap memory, which will use HeapMemorySegment. With HeapMemorySegment, even if it is wrapped, they will still share the underlying byte[]. We haven&apos;t heard any memory illegal access before.&#160;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;&#160;&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.9/ops/config.html#taskmanager-memory-off-heap&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-release-1.9/ops/config.html#taskmanager-memory-off-heap&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17277008" author="till.rohrmann" created="Tue, 2 Feb 2021 10:07:01 +0000"  >&lt;p&gt;Thanks for driving the discussion. I feel that I lack a bit of context here. &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Which patch did you test and what does it do &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=TsReaper&quot; class=&quot;user-hover&quot; rel=&quot;TsReaper&quot;&gt;TsReaper&lt;/a&gt;?&lt;/li&gt;
	&lt;li&gt;Does this test ensure that we don&apos;t have a memory leak?&lt;/li&gt;
	&lt;li&gt;If not, have we checked that we don&apos;t have a memory leak somewhere in our code?&lt;/li&gt;
	&lt;li&gt;Have we been able to reproduce the problem with the &lt;tt&gt;DataSet/DataStream&lt;/tt&gt; API only?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Again, before jumping to conclusions and action plans, I would like to make sure that we don&apos;t overlook things here.&lt;/p&gt;

&lt;p&gt;Concerning the action plan, I agree that option 2) is the best option here. But maybe there is also a fourth option: Try to establish a clear memory ownership where we don&apos;t hand ByteBuffers into components and then release the memory in a different component.&lt;/p&gt;

&lt;p&gt;Concerning the thread-safety I think this might be needed if we hand a &lt;tt&gt;ByteBuffer&lt;/tt&gt; to a different thread and release the underlying &lt;tt&gt;MemorySegment&lt;/tt&gt; in another thread. That is the problem of unclear ownership we might have in the code base. Maybe the check behaviour could be made configurable if we realize that this a bottleneck for performance.&lt;/p&gt;

&lt;p&gt;Just because the existing code base didn&apos;t make the &lt;tt&gt;MemorySegment&lt;/tt&gt; and &lt;tt&gt;ByteBuffer&lt;/tt&gt; thread safe, does not necessarily mean that this is correct. Moreover, just because something didn&apos;t crash before, does not mean that it was working either.&lt;/p&gt;

</comment>
                            <comment id="17277032" author="ykt836" created="Tue, 2 Feb 2021 10:49:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;&#160;Things are becoming more interesting. If I understand this correctly, I think the old design is exactly your forth option. Even the old design wasn&apos;t perfect, but it had clear memory ownership (at least to my understanding).&#160;Whoever allocate the memory should take care the whole lifecycle of these memory segments, including the wrapped ones. In this case, all allocators should be careful enough, and should never deliver them to, let&apos;s say another thread and loose the control ship. It caused some extra burden of the memory users but I think that&apos;s the price one have to pay for using managed memory of our own.&#160;&lt;/p&gt;</comment>
                            <comment id="17277273" author="till.rohrmann" created="Tue, 2 Feb 2021 16:41:23 +0000"  >&lt;p&gt;I am not sure whether the fourth option is really the old design. Looking again at &lt;tt&gt;MemorySegmentTestBase.testByteBufferWrapping&lt;/tt&gt;, we guard that we can reuse a &lt;tt&gt;ByteBuffer&lt;/tt&gt; after its underlying &lt;tt&gt;MemorySegment&lt;/tt&gt; has been freed. Hence, I cannot tell for sure that we don&apos;t rely on this contract in our code base.&lt;/p&gt;

&lt;p&gt;In general I also think that we should have an assertion making sure that nobody breaks our contract. This assertion should at least be active in our test runs. Given this, my fourth option is actually Xintong&apos;s second option. Sorry for the confusion.&lt;/p&gt;</comment>
                            <comment id="17277577" author="ykt836" created="Wed, 3 Feb 2021 01:09:04 +0000"  >&lt;p&gt;I&apos;m fine to add safety net for WrappedBuffer, read-write lock, memory fencing, GC or whatever you think is necessary to protect illegal memory access. But I&apos;m still against to protect other memory de-allocation with GC:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;We already have enough protection for these in MemorySegment#free() and HybridMemorySegment#free()&lt;/li&gt;
	&lt;li&gt;It slows down memory circulation between tasks, and maybe operators if we want memory be used more dynamically in the future&lt;/li&gt;
	&lt;li&gt;It creates extra complexity for nothing&lt;/li&gt;
	&lt;li&gt;It causes instability which we are currently suffering&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="17277878" author="till.rohrmann" created="Wed, 3 Feb 2021 10:18:27 +0000"  >&lt;p&gt;I understand the problems you are facing and I also see that the current solution (relying on GC) can potentially cause the problems. In order to move forward, could you please answer my questions I&apos;ve posted to this thread? I really would like to rule out that we have a memory leak somewhere by accident and I would be happy to have the same context as you guys seem to have.&lt;/p&gt;</comment>
                            <comment id="17277896" author="ykt836" created="Wed, 3 Feb 2021 10:42:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;Which patch did you test and what does it do&#160;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=TsReaper&quot; class=&quot;user-hover&quot; rel=&quot;TsReaper&quot;&gt;TsReaper&lt;/a&gt;?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Xingtong gave us a patch to release memory directly, just like before we change it to relying on GC.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;font color=&quot;#172b4d&quot;&gt;Does this test ensure that we don&apos;t have a memory leak?&lt;/font&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t think so. We only observed there are no out-of-managed-memory anymore.&#160;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;font color=&quot;#172b4d&quot;&gt;If not, have we checked that we don&apos;t have a memory leak somewhere in our code?&lt;/font&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I have checked the codes, didn&apos;t find any suspicious places. As discussed, the only possible leak is &lt;b&gt;memory segment owned by memory manager&lt;/b&gt; and &lt;b&gt;wrapped memory segments&lt;/b&gt;. All these wrapped segments are actually just want to turn memory segment into ByteBuffer and then call some nio functions.&#160;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;font color=&quot;#172b4d&quot;&gt;Have we been able to reproduce the problem with the&#160;&lt;/font&gt;&lt;tt&gt;DataSet/DataStream&lt;/tt&gt;&lt;font color=&quot;#172b4d&quot;&gt;&#160;API only?&lt;/font&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;DataStream won&apos;t be affected since it doesn&apos;t use managed memory. We didn&apos;t check DataSet but according to the usage of wrapped memory segment, I don&apos;t see a problem also.&#160;&lt;/p&gt;</comment>
                            <comment id="17278000" author="till.rohrmann" created="Wed, 3 Feb 2021 13:30:55 +0000"  >&lt;p&gt;Thanks for answering my questions. So to sum it up, we don&apos;t really know for sure whether there isn&apos;t a component which is kept alive and keeps a reference to a &lt;tt&gt;ByteBuffer&lt;/tt&gt; which prevents it from being garbage collected later. Could we maybe create a heap dump of a run where it fails? This could help with the analysis.&lt;/p&gt;

&lt;p&gt;Other than that, we can look into how to introduce the safety net and investigate which components need to be changed if we remove the contract that &lt;tt&gt;ByteBuffers&lt;/tt&gt; cannot be used after their originating &lt;tt&gt;MemorySegment&lt;/tt&gt; is released.&lt;/p&gt;</comment>
                            <comment id="17278457" author="xintongsong" created="Thu, 4 Feb 2021 01:31:13 +0000"  >&lt;p&gt;Regarding the safety net, I still have concern on the performance. Practically, we need some kind of cross-thread synchronization on every read / write operations on the byte buffers.&lt;/p&gt;

&lt;p&gt;I can try to provide a patch with the safety net. I think we can make a decision after measuring the performance differences with the patch.&lt;/p&gt;</comment>
                            <comment id="17278469" author="ykt836" created="Thu, 4 Feb 2021 01:51:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&#160; Will it affect all interfaces of MemorySegment or it only affects the ByteBuffer which is wrapped on MemorySegment through wrap()?&lt;/p&gt;</comment>
                            <comment id="17278470" author="xintongsong" created="Thu, 4 Feb 2021 01:57:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ykt836&quot; class=&quot;user-hover&quot; rel=&quot;ykt836&quot;&gt;ykt836&lt;/a&gt;, I&apos;m afraid it also affects `MemorySegment` interfaces.&lt;/p&gt;</comment>
                            <comment id="17278479" author="ykt836" created="Thu, 4 Feb 2021 02:17:30 +0000"  >&lt;p&gt;ï¿½&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&#160;Then I think the result will be even worse.&#160;&lt;/p&gt;</comment>
                            <comment id="17279483" author="xintongsong" created="Fri, 5 Feb 2021 09:04:20 +0000"  >&lt;p&gt;For the record, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ykt836&quot; class=&quot;user-hover&quot; rel=&quot;ykt836&quot;&gt;ykt836&lt;/a&gt; and I had a offline discussion, and we decided on the following action items.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Check whether there&apos;s in-proper cleared threads/references that keep the segments from being GC-ed, by generating a heap dump on hitting the managed memory budget.&lt;/li&gt;
	&lt;li&gt;Accessing to a ByteBuffer wrapped from an unsafe memory segment should be forbidden after the segment is freed.&lt;/li&gt;
	&lt;li&gt;If the synchronization (whether segment has been freed) is too heavy, we should at least activate it with a configuration options for the CI tests.&lt;/li&gt;
	&lt;li&gt;Further optimizations may be considered later.
	&lt;ul&gt;
		&lt;li&gt;Migrating more ByteBuffer accesses to direct segment accesses.&lt;/li&gt;
		&lt;li&gt;Removing GC-based memory free if we&apos;re sure about no reference leaking.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17280756" author="ym" created="Mon, 8 Feb 2021 05:22:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ykt836&quot; class=&quot;user-hover&quot; rel=&quot;ykt836&quot;&gt;ykt836&lt;/a&gt; mentioned it is better to include this ticket in 1.12.2; do we have a rough estimation of how long this will take?&lt;/p&gt;</comment>
                            <comment id="17280778" author="xintongsong" created="Mon, 8 Feb 2021 06:15:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ym&quot; class=&quot;user-hover&quot; rel=&quot;ym&quot;&gt;ym&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I don&apos;t have a good estimation atm. I should be able to open a PR by tomorrow. However, we need to do some memory safety and performance evaluations for the changes. Anything discovered during the evaluation may increase the time needed.&lt;/p&gt;

&lt;p&gt;I would not block 1.12.2 on this ticket. However, if including this ticket only delays the release for a few days, it might worth to include it. We should have a better ETA very soon.&lt;/p&gt;</comment>
                            <comment id="17280927" author="xintongsong" created="Mon, 8 Feb 2021 10:27:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ykt836&quot; class=&quot;user-hover&quot; rel=&quot;ykt836&quot;&gt;ykt836&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I&apos;m afraid implementing our own &lt;tt&gt;ByteBuffer&lt;/tt&gt; is a dead end. &lt;tt&gt;ByteBuffer&lt;/tt&gt; is an abstract class, not an interface. It has only package-visibility constructors and many final methods. I don&apos;t find a good way to extend the class with our own implementation, even with reflection. Any suggestions on that?&lt;/p&gt;

&lt;p&gt;Shall we try the other approach, that do not allow wrapping unsafe buffers from the segment, and migrate existing wrappings to direct operations on the segment?&lt;/p&gt;</comment>
                            <comment id="17281026" author="till.rohrmann" created="Mon, 8 Feb 2021 12:58:14 +0000"  >&lt;p&gt;Sounds as the next best option here.&lt;/p&gt;</comment>
                            <comment id="17281172" author="till.rohrmann" created="Mon, 8 Feb 2021 16:20:15 +0000"  >&lt;p&gt;What we could also try in order to see whether the problem disappears is to increase the number of &lt;tt&gt;UnsafeMemoryBudget.MAX_SLEEPS&lt;/tt&gt;. Increasing this value should increase the overall waiting time.&lt;/p&gt;
</comment>
                            <comment id="17284779" author="xintongsong" created="Mon, 15 Feb 2021 15:24:20 +0000"  >&lt;p&gt;Fixed via&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;master (1.13): 75fc592187a3a84163e262c6b1ba2a286cec4be4&lt;/li&gt;
	&lt;li&gt;release-1.12: 1f8be1fd7b2b37a124e4d2b8080d08e259bdf095&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17316227" author="zhou_yb" created="Wed, 7 Apr 2021 11:13:12 +0000"  >&lt;p&gt;the problem is still exist on flink1.12.2,what should I do?&lt;/p&gt;</comment>
                            <comment id="17316250" author="xintongsong" created="Wed, 7 Apr 2021 11:37:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhou_yb&quot; class=&quot;user-hover&quot; rel=&quot;zhou_yb&quot;&gt;zhou_yb&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Could you share some more information about the problem you encountered? It would be helpful if you can provide error stack, or complete jobmanager/taskmanager logs which are even better.&lt;/p&gt;</comment>
                            <comment id="17316264" author="zhou_yb" created="Wed, 7 Apr 2021 11:54:26 +0000"  >&lt;p&gt;&#160;here is script (the data set amount is small ) :&lt;/p&gt;


&lt;p&gt;&#160;/space/airflow/dags/chloe # /space/flink/bin/flink run -m yarn-cluster -yjm 26096 -ytm 46789 -ynm collocation --pyFiles /space/airflow/dags/ -py /space/airflow/dags/chloe/material_collocation_summary.py --date=2021-04-01 --env=pro&lt;/p&gt;
&lt;blockquote&gt;

&lt;p&gt;File &quot;/space/airflow/dags/chloe/material_collocation_summary.py&quot;, line 181, in &amp;lt;module&amp;gt;&lt;br/&gt;
 main(date)&lt;br/&gt;
 File &quot;/space/airflow/dags/chloe/material_collocation_summary.py&quot;, line 129, in main&lt;br/&gt;
 result.execute().print()&lt;br/&gt;
 File &quot;/space/flink/opt/python/pyflink.zip/pyflink/table/table_result.py&quot;, line 219, in print&lt;br/&gt;
 File &quot;/space/flink/opt/python/py4j-0.10.8.1-src.zip/py4j/java_gateway.py&quot;, line 1286, in _&lt;em&gt;call&lt;/em&gt;_&lt;br/&gt;
 File &quot;/space/flink/opt/python/pyflink.zip/pyflink/util/exceptions.py&quot;, line 147, in deco&lt;br/&gt;
 File &quot;/space/flink/opt/python/py4j-0.10.8.1-src.zip/py4j/protocol.py&quot;, line 328, in get_return_value&lt;br/&gt;
py4j.protocol.Py4JJavaError: An error occurred while calling o1428.print.&lt;br/&gt;
: java.lang.RuntimeException: Failed to fetch next result&lt;br/&gt;
 at org.apache.flink.streaming.api.operators.collect.CollectResultIterator.nextResultFromFetcher(CollectResultIterator.java:109)&lt;br/&gt;
 at org.apache.flink.streaming.api.operators.collect.CollectResultIterator.hasNext(CollectResultIterator.java:80)&lt;br/&gt;
 at org.apache.flink.table.planner.sinks.SelectTableSinkBase$RowIteratorWrapper.hasNext(SelectTableSinkBase.java:117)&lt;br/&gt;
 at org.apache.flink.table.api.internal.TableResultImpl$CloseableRowIteratorWrapper.hasNext(TableResultImpl.java:350)&lt;br/&gt;
 at org.apache.flink.table.utils.PrintUtils.printAsTableauForm(PrintUtils.java:149)&lt;br/&gt;
 at org.apache.flink.table.api.internal.TableResultImpl.print(TableResultImpl.java:154)&lt;br/&gt;
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
 at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
 at org.apache.flink.api.python.shaded.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)&lt;br/&gt;
 at org.apache.flink.api.python.shaded.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)&lt;br/&gt;
 at org.apache.flink.api.python.shaded.py4j.Gateway.invoke(Gateway.java:282)&lt;br/&gt;
 at org.apache.flink.api.python.shaded.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)&lt;br/&gt;
 at org.apache.flink.api.python.shaded.py4j.commands.CallCommand.execute(CallCommand.java:79)&lt;br/&gt;
 at org.apache.flink.api.python.shaded.py4j.GatewayConnection.run(GatewayConnection.java:238)&lt;br/&gt;
 at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
Caused by: java.io.IOException: Failed to fetch job execution result&lt;br/&gt;
 at org.apache.flink.streaming.api.operators.collect.CollectResultFetcher.getAccumulatorResults(CollectResultFetcher.java:169)&lt;br/&gt;
 at org.apache.flink.streaming.api.operators.collect.CollectResultFetcher.next(CollectResultFetcher.java:118)&lt;br/&gt;
 at org.apache.flink.streaming.api.operators.collect.CollectResultIterator.nextResultFromFetcher(CollectResultIterator.java:106)&lt;br/&gt;
 ... 16 more&lt;br/&gt;
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: ef1a60be8f725a192a72b12cbcc2769c)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1915)&lt;br/&gt;
 at org.apache.flink.streaming.api.operators.collect.CollectResultFetcher.getAccumulatorResults(CollectResultFetcher.java:167)&lt;br/&gt;
 ... 18 more&lt;br/&gt;
Caused by: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: ef1a60be8f725a192a72b12cbcc2769c)&lt;br/&gt;
 at org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$null$6(ClusterClientJobClientAdapter.java:125)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:602)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)&lt;br/&gt;
 at org.apache.flink.client.program.rest.RestClusterClient.lambda$pollResourceAsync$22(RestClusterClient.java:665)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1962)&lt;br/&gt;
 at org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$9(FutureUtils.java:394)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:760)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:736)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture.postFire(CompletableFuture.java:561)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:929)&lt;br/&gt;
 at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:442)&lt;br/&gt;
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;br/&gt;
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;br/&gt;
 ... 1 more&lt;br/&gt;
Caused by: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.&lt;br/&gt;
 at org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:144)&lt;br/&gt;
 at org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$null$6(ClusterClientJobClientAdapter.java:123)&lt;br/&gt;
 ... 19 more&lt;br/&gt;
Caused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy&lt;br/&gt;
 at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:118)&lt;br/&gt;
 at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:80)&lt;br/&gt;
 at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:233)&lt;br/&gt;
 at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:224)&lt;br/&gt;
 at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:215)&lt;br/&gt;
 at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:669)&lt;br/&gt;
 at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:89)&lt;br/&gt;
 at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:447)&lt;br/&gt;
 at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source)&lt;br/&gt;
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
 at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
 at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305)&lt;br/&gt;
 at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212)&lt;br/&gt;
 at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77)&lt;br/&gt;
 at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158)&lt;br/&gt;
 at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)&lt;br/&gt;
 at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)&lt;br/&gt;
 at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)&lt;br/&gt;
 at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)&lt;br/&gt;
 at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)&lt;br/&gt;
 at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)&lt;br/&gt;
 at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)&lt;br/&gt;
 at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)&lt;br/&gt;
 at akka.actor.Actor.aroundReceive(Actor.scala:517)&lt;br/&gt;
 at akka.actor.Actor.aroundReceive$(Actor.scala:515)&lt;br/&gt;
 at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)&lt;br/&gt;
 at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)&lt;br/&gt;
 at akka.actor.ActorCell.invoke(ActorCell.scala:561)&lt;br/&gt;
 at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)&lt;br/&gt;
 at akka.dispatch.Mailbox.run(Mailbox.scala:225)&lt;br/&gt;
 at akka.dispatch.Mailbox.exec(Mailbox.scala:235)&lt;br/&gt;
 at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)&lt;br/&gt;
 at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)&lt;br/&gt;
 at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)&lt;br/&gt;
 at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)&lt;br/&gt;
Caused by: java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages&lt;br/&gt;
 at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:84)&lt;br/&gt;
 at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254)&lt;br/&gt;
 at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313)&lt;br/&gt;
 at org.apache.flink.table.runtime.hashtable.LongHashPartition.&amp;lt;init&amp;gt;(LongHashPartition.java:166)&lt;br/&gt;
 at org.apache.flink.table.runtime.hashtable.LongHashPartition.&amp;lt;init&amp;gt;(LongHashPartition.java:136)&lt;br/&gt;
 at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276)&lt;br/&gt;
 at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.&amp;lt;init&amp;gt;(LongHybridHashTable.java:89)&lt;br/&gt;
 at LongHashJoinOperator$893$LongHashTable$877.&amp;lt;init&amp;gt;(Unknown Source)&lt;br/&gt;
 at LongHashJoinOperator$893.open(Unknown Source)&lt;br/&gt;
 at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428)&lt;br/&gt;
 at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543)&lt;br/&gt;
 at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)&lt;br/&gt;
 at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533)&lt;br/&gt;
 at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573)&lt;br/&gt;
 at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755)&lt;br/&gt;
 at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570)&lt;br/&gt;
 at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages&lt;br/&gt;
 at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235)&lt;br/&gt;
 at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82)&lt;br/&gt;
 ... 16 more&lt;br/&gt;
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 0 bytes are remaining. This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher if running on an old Java version.&lt;br/&gt;
 at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:170)&lt;br/&gt;
 at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:84)&lt;br/&gt;
 at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:232)&lt;br/&gt;
 ... 17 more&lt;/p&gt;

&lt;p&gt;org.apache.flink.client.program.ProgramAbortException&lt;br/&gt;
 at org.apache.flink.client.python.PythonDriver.main(PythonDriver.java:124)&lt;br/&gt;
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
 at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
 at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:349)&lt;br/&gt;
 at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:219)&lt;br/&gt;
 at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:114)&lt;br/&gt;
 at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:812)&lt;br/&gt;
 at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:246)&lt;br/&gt;
 at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:1054)&lt;br/&gt;
 at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:1132)&lt;br/&gt;
 at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
 at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1876)&lt;br/&gt;
 at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)&lt;br/&gt;
 at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1132)&lt;br/&gt;
Exception in thread &quot;Thread-9&quot; java.lang.IllegalStateException: Trying to access closed classloader. Please check if you store classloaders directly or indirectly in static fields. If the stacktrace suggests that the leak occurs in a third party library and cannot be fixed immediately, you can disable this check with the configuration &apos;classloader.check-leaked-classloader&apos;.&lt;br/&gt;
 at org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders$SafetyNetWrapperClassLoader.ensureInner(FlinkUserCodeClassLoaders.java:164)&lt;br/&gt;
 at org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders$SafetyNetWrapperClassLoader.getResource(FlinkUserCodeClassLoaders.java:183)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.getResource(Configuration.java:2803)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3059)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3018)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2991)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2871)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.get(Configuration.java:1223)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1835)&lt;br/&gt;
 at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1812)&lt;br/&gt;
 at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)&lt;br/&gt;
 at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)&lt;br/&gt;
 at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)&lt;br/&gt;
 at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17316311" author="xintongsong" created="Wed, 7 Apr 2021 12:51:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhou_yb&quot; class=&quot;user-hover&quot; rel=&quot;zhou_yb&quot;&gt;zhou_yb&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;This indeed looks similar.&lt;/p&gt;

&lt;p&gt;Is it possible for you to share the complete jobmanager and taskmanager logs? And does the problem happen at the very beginning of the task execution, or it happens when upstream tasks are finished and new tasks are executed?.&lt;/p&gt;</comment>
                            <comment id="17316842" author="zhou_yb" created="Thu, 8 Apr 2021 03:25:42 +0000"  >&lt;p&gt;&#160;logs in attachment,it a long text:&#160;&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/13023530/13023530_exception&quot; title=&quot;exception attached to FLINK-20663&quot;&gt;exception&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="17316920" author="xintongsong" created="Thu, 8 Apr 2021 07:25:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhou_yb&quot; class=&quot;user-hover&quot; rel=&quot;zhou_yb&quot;&gt;zhou_yb&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Findings from the JM logs:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The TM where the failure happen is newly started, registered at 19:14:30, with plenty of managed memory (1.7G).&lt;/li&gt;
	&lt;li&gt;In the first stage, 3 source tasks are deployed onto the TM (19:14:30), and successfully finished (19:14:51)&lt;/li&gt;
	&lt;li&gt;In the second stage, 3 hash join tasks are deployed onto the (19:14:52), and soon failed (19:14:55) due to not being able to allocate managed memory.&lt;/li&gt;
	&lt;li&gt;From the task name ( &lt;tt&gt;Source: HiveSource-chloe.chloe_bus_hive_log -&amp;gt; Calc(select=&lt;span class=&quot;error&quot;&gt;&amp;#91;dataobj&amp;#93;&lt;/span&gt;, where=&lt;span class=&quot;error&quot;&gt;&amp;#91;(bustype = 12)&amp;#93;&lt;/span&gt;) -&amp;gt; (BatchExecPythonCalc, BatchExecPythonCalc&lt;/tt&gt; ), it seems the first stage tasks do not use memory segments. They should only use managed memory for the python process.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think this is a different problem. The previous problem reported in this ticket was caused due to memory segment not being GC-ed timely. In your case, the first stage tasks do not use memory segments. &lt;/p&gt;

&lt;p&gt;With the provided JM lobs, I cannot explain how this happened. Checking the codes, memory for python operators should have been released by the time the first stage tasks finish.&lt;/p&gt;

&lt;p&gt;Would you be able to provide the complete task manager logs? And one more question, can the problem be reproduced, steady or occasionally?&lt;/p&gt;</comment>
                            <comment id="17316952" author="zhou_yb" created="Thu, 8 Apr 2021 08:27:57 +0000"  >&lt;p&gt;the problem is &#160;steady. taskmanager log :&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/13023542/13023542_taskmanager.log&quot; title=&quot;taskmanager.log attached to FLINK-20663&quot;&gt;taskmanager.log&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="17316993" author="till.rohrmann" created="Thu, 8 Apr 2021 08:54:34 +0000"  >&lt;p&gt;If the problem is reproducible could you maybe share the complete job with some example data which reproduces the problem &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhou_yb&quot; class=&quot;user-hover&quot; rel=&quot;zhou_yb&quot;&gt;zhou_yb&lt;/a&gt;? That way it will be a lot easier to figure the problem out.&lt;/p&gt;</comment>
                            <comment id="17317579" author="xintongsong" created="Fri, 9 Apr 2021 02:03:24 +0000"  >&lt;p&gt;I haven&apos;t find anything useful from the task manager logs.&lt;/p&gt;

&lt;p&gt;+1 on &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=trohrmann&quot; class=&quot;user-hover&quot; rel=&quot;trohrmann&quot;&gt;trohrmann&lt;/a&gt;&apos;s advice. It would be helpful if we can reproduce the problem locally.&lt;/p&gt;</comment>
                            <comment id="17317585" author="zhou_yb" created="Fri, 9 Apr 2021 02:26:13 +0000"  >&lt;p&gt;here is my code script:&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/13023587/13023587_summary.py&quot; title=&quot;summary.py attached to FLINK-20663&quot;&gt;summary.py&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;when I do sceond union all operator ,the exception occured. the code is correctly on flink1.11. when the code executed faild on flink1.12.1, I change the grammar that pyflink1.12.1 supported.&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;so you will see the code cant run on flink1.11. but if you change the code grammar that pyflink1.11 supported ,the code can executed correctly on flink1.11&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 result = result1.union_all(result2)
 result = result.union_all(result3)
 result = result.union_all(result4)
 result.execute().print()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17317644" author="zhou_yb" created="Fri, 9 Apr 2021 04:33:13 +0000"  >&lt;p&gt;I have another script have same problems,but I just change little sql grammar .the code executed correctly, I had pasted some different codes,not complete codes&#160;&lt;/p&gt;

&lt;p&gt;Is the planner bug?&#160;&lt;/p&gt;

&lt;p&gt;first code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
sql = &lt;span class=&quot;code-quote&quot;&gt;&quot;select ds, bustype,dataobj from chloe_bus_hive_log where ds=&lt;span class=&quot;code-quote&quot;&gt;&apos;%s&apos;&lt;/span&gt; and bustype=11 &quot;&lt;/span&gt; % date
bus_result1 = st_env.sql_query(sql)
sql = &lt;span class=&quot;code-quote&quot;&gt;&quot;select ds, bustype,dataobj from chloe_bus_hive_log where ds=&lt;span class=&quot;code-quote&quot;&gt;&apos;%s&apos;&lt;/span&gt; and bustype=4 &quot;&lt;/span&gt; % date 
bus_result2 = st_env.sql_query(sql)


&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;changed code executed correctly :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

sql = &lt;span class=&quot;code-quote&quot;&gt;&quot;select ds, bustype,dataobj from chloe_bus_hive_log where ds=&lt;span class=&quot;code-quote&quot;&gt;&apos;%s&apos;&lt;/span&gt; and (bustype=11 or bustype=4) &quot;&lt;/span&gt; % date
bus_result = st_env.sql_query(sql)

type1_result = bus_result.where(&lt;span class=&quot;code-quote&quot;&gt;&quot;bustype==11&quot;&lt;/span&gt;)
type2_result = bus_result.where(&lt;span class=&quot;code-quote&quot;&gt;&quot;bustype==4&quot;&lt;/span&gt;)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17317657" author="xintongsong" created="Fri, 9 Apr 2021 05:15:35 +0000"  >&lt;p&gt;I&apos;m not sure about this being a planner bug.&lt;/p&gt;

&lt;p&gt;My gut feeling this is some runtime/operator bug that happens to be triggered by certain task execution pattern. Changing of the sql query also changes the compiled execution plan, thus the bug is not triggered with the new plan.&lt;/p&gt;

&lt;p&gt;It seems we cannot easily reproduce your problem. We cannot execute the scripts locally, due to missing the &quot;chloe&quot; packages. And even we have the packages, I assume we cannot access the data sources anyway.&lt;/p&gt;

&lt;p&gt;Would it be possible for you to run the scripts with a debug version of Flink? I can provide you a github branch based on 1.12.1, with some additional logs that help us understand whats going on with the memory. You would need to checkout the branch, manually build and install the package. Would that work for you?&lt;/p&gt;</comment>
                            <comment id="17317666" author="zhou_yb" created="Fri, 9 Apr 2021 05:31:25 +0000"  >&lt;p&gt;ok,but Im not sure when I will do it done. I need some spare time to do it&#160;&lt;/p&gt;</comment>
                            <comment id="17317706" author="xintongsong" created="Fri, 9 Apr 2021 06:36:43 +0000"  >&lt;p&gt;I think I&apos;ve found out the problem. I&apos;m afraid this is a pyflink bug, which causes the python worker not terminated and the memory not released.&lt;/p&gt;

&lt;p&gt;Python UDFs are executed in python VM processes. A python VM is only started when there&apos;s python UDFs to execute, and is expected terminated when the UDFs finish, releasing the managed memory for other executions. If the VM is not terminated, new coming tasks will not be able to use the memory. That&apos;s the error we met.&lt;/p&gt;

&lt;p&gt;When there&apos;re multiple python UDFs within the same slot, they share the same VM. Consider the python VM as a resource, when it is first requested the resource is created (starting the VM), and a second request will get the same resource without creating a new one. The resource is disposed (terminating the VM) only when it is released as many times as it is requested.&lt;/p&gt;

&lt;p&gt;The bug is that, this reference counting logic is implemented twice, in &lt;tt&gt;SharedResource.release()&lt;/tt&gt; and &lt;tt&gt;BeamPythonFunctionRunner.close&lt;/tt&gt;. Consequently, when there&apos;s multiple python UDFs in the slot, &lt;tt&gt;BeamPythonFunctionRunner&lt;/tt&gt; requests &lt;tt&gt;SharedResource&lt;/tt&gt; many times but only release once, while &lt;tt&gt;SharedResource&lt;/tt&gt; expects to be released as many times as requested.&lt;/p&gt;

&lt;p&gt;This bug can be triggered when 1) there are multiple python UDFs in the same slot, and 2) another operator tries to allocate non-python managed memory afterwards. If there&apos;s only 1) without 2), there are still python process leaks, which might easily get overlooked.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhou_yb&quot; class=&quot;user-hover&quot; rel=&quot;zhou_yb&quot;&gt;zhou_yb&lt;/a&gt;, the above bug matches observations from your job.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;There are 2 python UDFs in the same slot. That can be seen from the operator name &lt;tt&gt;(BatchExecPythonCalc, BatchExecPythonCalc)&lt;/tt&gt;, and that the log &quot;Obtained shared Python process ...&quot; are printed as many times as twice of the slots.&lt;/li&gt;
	&lt;li&gt;The error happens on the same TM after the python UDFs are executed.&lt;/li&gt;
	&lt;li&gt;Changing of the SQL codes probably have changed the number of underlying python UDFs, thus no longer triggers the problem.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dianfu&quot; class=&quot;user-hover&quot; rel=&quot;dianfu&quot;&gt;dianfu&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hxbks2ks&quot; class=&quot;user-hover&quot; rel=&quot;hxbks2ks&quot;&gt;hxbks2ks&lt;/a&gt;, could you confirm this issue? And before the bug is fixed, is there any way to help the user workaround the problem? E.g., any way to prevent multiple python UDFs in the same slot?&lt;/p&gt;</comment>
                            <comment id="17317721" author="zhou_yb" created="Fri, 9 Apr 2021 06:53:19 +0000"  >&lt;p&gt;Im glad to you found the problem&#65292;expected to fix it .&lt;/p&gt;</comment>
                            <comment id="17317726" author="xintongsong" created="Fri, 9 Apr 2021 07:00:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhou_yb&quot; class=&quot;user-hover&quot; rel=&quot;zhou_yb&quot;&gt;zhou_yb&lt;/a&gt;, &lt;br/&gt;
Thanks for reporting this issue and helping us locating the bug. This is a very valuable finding.&lt;br/&gt;
FYI, a new ticket (&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-22172&quot; title=&quot;Fix the bug of shared resource among Python Operators of the same slot is not released&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-22172&quot;&gt;&lt;del&gt;FLINK-22172&lt;/del&gt;&lt;/a&gt;) has been opened to track this bug.&lt;/p&gt;</comment>
                            <comment id="17317785" author="hxbks2ks" created="Fri, 9 Apr 2021 08:42:05 +0000"  >&lt;p&gt;Thanks a lot for the analysis. I agree with @Xintong&apos;s analysis. I&apos;m fixing it in &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-22172&quot; title=&quot;Fix the bug of shared resource among Python Operators of the same slot is not released&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-22172&quot;&gt;&lt;del&gt;FLINK-22172&lt;/del&gt;&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Regarding to the work around, just as @Xintong said, this issue only happens if there are multiple Python operators in the same slot, so one work around in my mind is to split the python operators into different slot sharing group, e.g. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
t_env # StreamTableEnvironment
t = # Table
t1 = t.select(pyFunc1(col(&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;)))
ds = t_env.to_append_stream(t1, type_info=...).map(lambda x: x).slot_sharing_group(&lt;span class=&quot;code-quote&quot;&gt;&quot;another2&quot;&lt;/span&gt;) # &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; slot sharing group is &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;
t = t_env.from_data_stream(ds, col(&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;))
t.select(pyFunc2(&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17317791" author="zhou_yb" created="Fri, 9 Apr 2021 08:53:26 +0000"  >&lt;p&gt;each udf calling split to different slot? the progress is : table &amp;gt; dataStream/dataSet &amp;gt; newTable?&lt;/p&gt;</comment>
                            <comment id="17317865" author="hxbks2ks" created="Fri, 9 Apr 2021 10:29:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhou_yb&quot; class=&quot;user-hover&quot; rel=&quot;zhou_yb&quot;&gt;zhou_yb&lt;/a&gt; If some udfs can be chained together, they will be executed in the same Python Operator. In this situation, we don&apos;t need to split them. So what needs to be split are multiple Python Operators in a slot, and then separate them into different slot sharing group. the progress is : table -&amp;gt; datastream.map.slot_sharing_group -&amp;gt; table&lt;/p&gt;</comment>
                            <comment id="17317930" author="zhou_yb" created="Fri, 9 Apr 2021 11:43:47 +0000"  >&lt;p&gt;how to&#160; know&#160;multiple Python Operators in a slot.&#160;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13255135">FLINK-13985</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13281453">FLINK-15758</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13023530" name="exception" size="561306" author="zhou_yb" created="Thu, 8 Apr 2021 03:25:18 +0000"/>
                            <attachment id="13023587" name="summary.py" size="9605" author="zhou_yb" created="Fri, 9 Apr 2021 02:17:02 +0000"/>
                            <attachment id="13023542" name="taskmanager.log" size="450970" author="zhou_yb" created="Thu, 8 Apr 2021 08:27:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 31 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0lmnk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>