<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:49:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-19151] Flink does not normalize container resource with correct configurations when Yarn FairScheduler is used </title>
                <link>https://issues.apache.org/jira/browse/FLINK-19151</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;h3&gt;&lt;a name=&quot;Problem&quot;&gt;&lt;/a&gt;Problem&lt;/h3&gt;

&lt;p&gt;It&apos;s a Yarn protocol that the requested container resource will be normalized for allocation. That means, the allocated container may have different resource (larger than or equal to) compared to what is requested.&lt;/p&gt;

&lt;p&gt;Currently, Flink matches the allocated containers to the original requests by reading the Yarn configurations and calculate how the requested resources should be normalized.&lt;/p&gt;

&lt;p&gt;What has been overlooked is that, Yarn FairScheduler (and its subclass SLSFairScheduler) has overridden the normalization behavior. To be specific,&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;By default, Yarn normalize container resources to integer multiple of &quot;yarn.scheduler.minimum-allocation-&lt;span class=&quot;error&quot;&gt;&amp;#91;mb|vcores&amp;#93;&lt;/span&gt;&quot;&lt;/li&gt;
	&lt;li&gt;FairScheduler normalize container resources to integer multiple of &quot;yarn.resource-types.&lt;span class=&quot;error&quot;&gt;&amp;#91;memory-mb|vcores&amp;#93;&lt;/span&gt;.increment-allocation&quot; (or the deprecated keys &quot;yarn.scheduler.increment-allocation-&lt;span class=&quot;error&quot;&gt;&amp;#91;mb|vcores&amp;#93;&lt;/span&gt;&quot;), while making sure the resource is no less than &quot;yarn.scheduler.minimum-allocation-&lt;span class=&quot;error&quot;&gt;&amp;#91;mb|vcores&amp;#93;&lt;/span&gt;&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;&lt;a name=&quot;Proposalforshorttermsolution&quot;&gt;&lt;/a&gt;Proposal for short term solution&lt;/h3&gt;

&lt;p&gt;To fix this problem, a quick and easy way is to also read Yarn configuration and learn which scheduler is used, and perform normalization calculations accordingly. This should be good enough to cover behaviors of all the schedulers that Yarn currently provides. The limitation is that, Flink will not be able to deal with custom Yarn schedulers which override the normalization behaviors.&lt;/p&gt;
&lt;h3&gt;&lt;a name=&quot;Proposalforlongtermsolution&quot;&gt;&lt;/a&gt;Proposal for long term solution&lt;/h3&gt;

&lt;p&gt;For long term, it would be good to use Yarn ContainerRequest#allocationRequestId to match the allocated containers with the original requests, so that Flink no longer needs to understand how Yarn normalize container resources.&#160;&lt;/p&gt;

&lt;p&gt;Yarn ContainerRequest#allocationRequestId is introduced in Hadoop 2.9, while ATM Flink claims to be compatible with Hadoop 2.4+. Therefore, this solution would not work at the moment.&lt;/p&gt;

&lt;p&gt;Another idea is to support various Hadoop versions with different container matching logics. We can abstract the container matching logics into a dedicating component, and provide different implementations for it. This will allow Flink to take advantages of the new versions (e.g., work well with custom schedulers), while stay compatible with the old versions without those advantages.&lt;/p&gt;

&lt;p&gt;Given that we need the resource based matching anyway for the old Hadoop versions, and the cost for maintaining two sets of matching logics, I tend to think this approach as a back-up option to be worked on when we indeed see a need for it.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13326262">FLINK-19151</key>
            <summary>Flink does not normalize container resource with correct configurations when Yarn FairScheduler is used </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="csbliss">jinhai</assignee>
                                    <reporter username="xtsong">Xintong Song</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 7 Sep 2020 08:08:26 +0000</created>
                <updated>Mon, 21 Sep 2020 10:00:33 +0000</updated>
                            <resolved>Thu, 10 Sep 2020 11:12:50 +0000</resolved>
                                    <version>1.11.2</version>
                                    <fixVersion>1.11.3</fixVersion>
                    <fixVersion>1.12.0</fixVersion>
                                    <component>Deployment / YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="17191623" author="csbliss" created="Mon, 7 Sep 2020 10:23:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Can we add two fields to the class WorkerSpecContainerResourceAdapter: unitMemMB and unitVcore.&lt;br/&gt;
Calculate the unit value in the WorkerSpecContainerResourceAdapter constructor according to different yarn scheduler, such as FairScheduler or other yarn scheduler&lt;/p&gt;</comment>
                            <comment id="17191633" author="xintongsong" created="Mon, 7 Sep 2020 10:50:19 +0000"  >&lt;p&gt;+1 on adding unit memory/vcore in&#160;WorkerSpecContainerResourceAdapter and deciding the unit resources according to the Yarn scheduler.&lt;/p&gt;

&lt;p&gt;I would suggest to decide the unit resources outside `WorkerSpecContainerResourceAdapter`. The adapter does not need to be aware of the Yarn scheduler differences. It should also make the adapter easy to test.&lt;/p&gt;</comment>
                            <comment id="17191637" author="csbliss" created="Mon, 7 Sep 2020 10:55:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&#160;Yes, we can set the unit resources in the constructor of YarnResourceManager&lt;/p&gt;</comment>
                            <comment id="17191911" author="csbliss" created="Tue, 8 Sep 2020 02:32:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt; Can i have this issue?&lt;/p&gt;</comment>
                            <comment id="17191912" author="xintongsong" created="Tue, 8 Sep 2020 02:38:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csbliss&quot; class=&quot;user-hover&quot; rel=&quot;csbliss&quot;&gt;csbliss&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sure. Thanks for the volunteering. I have assigned you.&lt;/p&gt;

&lt;p&gt;Please make sure you read the community &lt;a href=&quot;https://flink.apache.org/contributing/contribute-code.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;contribution&lt;/a&gt; and &lt;a href=&quot;https://flink.apache.org/contributing/code-style-and-quality-preamble.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;code style&lt;/a&gt; guidelines in advance and go ahead.&lt;/p&gt;</comment>
                            <comment id="17191917" author="fly_in_gis" created="Tue, 8 Sep 2020 03:01:34 +0000"  >&lt;p&gt;I prefer the long term solution and +1 for the different implementations based on hadoop versions. Currently, many hadoop versions are going to EOL, including&#160;&lt;span class=&quot;error&quot;&gt;&amp;#91;2.0.x - 2.9.x&amp;#93;&lt;/span&gt;,&#160;&lt;span class=&quot;error&quot;&gt;&amp;#91;3.0.x&amp;#93;&lt;/span&gt;. And the community strongly suggests to upgrade to hadoop-3.1. It should be stable enough.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/HADOOP/EOL+(End-of-life)+Release+Branches&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/HADOOP/EOL+(End-of-life)+Release+Branches&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17191956" author="xintongsong" created="Tue, 8 Sep 2020 05:06:50 +0000"  >&lt;p&gt;Thanks for the input, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fly_in_gis&quot; class=&quot;user-hover&quot; rel=&quot;fly_in_gis&quot;&gt;fly_in_gis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I think how do we support various hadoop versions w.r.t. the API and feature differences is a big topic, which probably deserve a separate discussion thread. &lt;/p&gt;

&lt;p&gt;In addition to the container allocation request id, currently in Flink there are also other usages of Yarn APIs/features that are not supported by all hadoop versions. E.g., getting previous attempt containers and scheduler resource types from register application response, requesting containers with external resources (a.t.m. GPU), submitting application with specific tags and node labels, e.t.c. I think it would be better to take all these issues into consideration, and try to come up with some general principles how we handle such version diversities.&lt;/p&gt;

&lt;p&gt;Such discussion could take some time, at mean time it might be good to fix the problem with the proposed short-term solution, which should not require much efforts.&lt;/p&gt;

&lt;p&gt;WDYT?&lt;/p&gt;</comment>
                            <comment id="17191985" author="fly_in_gis" created="Tue, 8 Sep 2020 06:54:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xintongsong&quot; class=&quot;user-hover&quot; rel=&quot;xintongsong&quot;&gt;xintongsong&lt;/a&gt;&#160;Thanks for the explanation. I agree with you that we could start with the short-term solution. Since it do not need too much efforts and could fix the issues.&#160;&lt;/p&gt;</comment>
                            <comment id="17193547" author="xintongsong" created="Thu, 10 Sep 2020 11:12:50 +0000"  >&lt;p&gt;Fixed via&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;master: 00bf41f33a10b59850f0ee4fe31c0271484d6d4c&lt;/li&gt;
	&lt;li&gt;release-1.11: bfff6b15ec7dd3a4415f6a5a9d8535ea7960e474&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13326068">FLINK-19141</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13328526">FLINK-19324</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 9 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0idoo:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>