<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:27:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-5701] FlinkKafkaProducer should check asyncException on checkpoints</title>
                <link>https://issues.apache.org/jira/browse/FLINK-5701</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Reported in ML: &lt;a href=&quot;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Fink-KafkaProducer-Data-Loss-td11413.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Fink-KafkaProducer-Data-Loss-td11413.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The problem:&lt;/p&gt;

&lt;p&gt;The producer holds a &lt;tt&gt;pendingRecords&lt;/tt&gt; value that is incremented on each invoke() and decremented on each callback, used to check if the producer needs to sync on pending callbacks on checkpoints.&lt;br/&gt;
On each checkpoint, we should only consider the checkpoint succeeded iff after flushing the &lt;tt&gt;pendingRecords == 0&lt;/tt&gt; and &lt;tt&gt;asyncException == null&lt;/tt&gt; (currently, we&#8217;re only checking &lt;tt&gt;pendingRecords&lt;/tt&gt;).&lt;/p&gt;

&lt;p&gt;A quick fix for this is to check and rethrow async exceptions in the &lt;tt&gt;snapshotState&lt;/tt&gt; method both before and after flushing and &lt;tt&gt;pendingRecords&lt;/tt&gt; becomes 0.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13040042">FLINK-5701</key>
            <summary>FlinkKafkaProducer should check asyncException on checkpoints</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tzulitai">Tzu-Li (Gordon) Tai</assignee>
                                    <reporter username="tzulitai">Tzu-Li (Gordon) Tai</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 Feb 2017 05:46:56 +0000</created>
                <updated>Thu, 16 Mar 2017 04:43:50 +0000</updated>
                            <resolved>Thu, 16 Mar 2017 04:43:50 +0000</resolved>
                                                    <fixVersion>1.1.5</fixVersion>
                    <fixVersion>1.2.1</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>Connectors / Common</component>
                    <component>Connectors / Kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="15854349" author="githubbot" created="Mon, 6 Feb 2017 16:55:14 +0000"  >&lt;p&gt;GitHub user tzulitai opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5701&quot; title=&quot;FlinkKafkaProducer should check asyncException on checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5701&quot;&gt;&lt;del&gt;FLINK-5701&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; FlinkKafkaProducer should check asyncException on checkpoints&lt;/p&gt;

&lt;p&gt;    Prior to this change, at-least-once is violated for the FlinkKafkaProducer because we were not failing checkpoints if there were async exceptions from the Kafka producer.&lt;/p&gt;

&lt;p&gt;    With this PR, on `snapshotState()`, we fail if there previously were async exceptions. We also fail if the flushed records on checkpoint resulted in exceptions.&lt;/p&gt;

&lt;p&gt;    This PR also improves the tests in `FlinkKafkaProducerBaseTest` to use one-shot latches instead of sleeping for more stable tests. It also removes the test `testAtLeastOnceProducerFailsIfFlushingDisabled()`. My reasoning is that essentially, you &lt;em&gt;might&lt;/em&gt; still have at-least-once even if flushing is disabled (i.e. always no pending records to flush on checkpoint), so I don&apos;t see the necessity in having that test. I&apos;m open to discussing the removal of that test and adding it back if others think it&apos;s necessary.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/tzulitai/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/tzulitai/flink&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5701&quot; title=&quot;FlinkKafkaProducer should check asyncException on checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5701&quot;&gt;&lt;del&gt;FLINK-5701&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3278&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit c3eb0a905b86c6265af91c4bda7d2c9da2dc6ce2&lt;br/&gt;
Author: Tzu-Li (Gordon) Tai &amp;lt;tzulitai@apache.org&amp;gt;&lt;br/&gt;
Date:   2017-02-06T16:37:13Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5701&quot; title=&quot;FlinkKafkaProducer should check asyncException on checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5701&quot;&gt;&lt;del&gt;FLINK-5701&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; FlinkKafkaProducer should check asyncException on checkpoints&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15854380" author="githubbot" created="Mon, 6 Feb 2017 17:12:44 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I don&apos;t think that you have at least once guarantees if you disable flushing. Assume the following: You have the input `event1, checkpoint barrier, event2`. Now you write `event1` to Kafka but it is not yet committed. Now you process the checkpoint barrier and complete the checkpoint without waiting for `event1` to be written. Now writing `event1` to Kafka fails for some reason and triggers a recovery. Then you will start at `event2` without having ever written `event1` to Kafka.&lt;/p&gt;</comment>
                            <comment id="15854409" author="githubbot" created="Mon, 6 Feb 2017 17:24:38 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann &lt;br/&gt;
    Yes, in the condition that you described, then at-least-once doesn&apos;t hold. I said &lt;em&gt;might&lt;/em&gt; mainly considering there is chance that for every checkpoint barrier, the previous events (i.e. `event1` in your example) has been committed. But yes, essentially this indeterminate behaviour means that it is not at-least-once, so I&apos;m incorrect in saying that it &lt;em&gt;might&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;    I was trying to point out that this indeterminate behaviour made it hard to have a stable test for `testAtLeastOnceProducerFailsIfFlushingDisabled()` without relying on sleeping, which ultimately leads to flaky tests.&lt;/p&gt;</comment>
                            <comment id="15855991" author="githubbot" created="Tue, 7 Feb 2017 13:36:31 +0000"  >&lt;p&gt;Github user tillrohrmann commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Ah now I understand what the problem of `testAtLeastOnceProdcuerFailsIfFlushingDisabled` was. Can&apos;t we mock the `KafkaProducer` to control when the record&apos;s callbacks are triggered? That way we have full control over the execution and can write a proper test.&lt;/p&gt;</comment>
                            <comment id="15856085" author="githubbot" created="Tue, 7 Feb 2017 14:29:03 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann thanks for the comment. I&apos;ll try again and see if I can come with up a proper test for `testAtLeastOnceProdcuerFailsIfFlushingDisabled()`.&lt;/p&gt;</comment>
                            <comment id="15857494" author="githubbot" created="Wed, 8 Feb 2017 06:35:13 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Instead of directly re-adding `testAtLeastOnceProducerFailsIfFlushingDisabled `, I instead added a test `testDoesNotWaitForPendingRecordsIfFlushingDisabled` to simply assure that the snapshot method returns even if there are pending records.&lt;/p&gt;

&lt;p&gt;    The purpose of the `testDoesNotWaitForPendingRecordsIfFlushingDisabled` test is to assure that the actual `testAtLeastOnceProducer` test is valid.&lt;br/&gt;
    I think this was what the original `testAtLeastOnceProducerFailsIfFlushingDisabled` was actually meant for anyway.&lt;/p&gt;

&lt;p&gt;    @tillrohrmann please let me know if this makes sense to you &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15857766" author="githubbot" created="Wed, 8 Feb 2017 10:12:16 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100030887&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100030887&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Can&apos;t we simply give this instance a mock `KafkaProducer`? Then we could easily check via `verify` whether the `send` method has been called.&lt;/p&gt;</comment>
                            <comment id="15857767" author="githubbot" created="Wed, 8 Feb 2017 10:12:16 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100029980&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100029980&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, inputLatch, 100, new AtomicBoolean(false));&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;Callback&amp;gt; pending = producer.getProducerInstance().getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));
    +		}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why processing `100` elements? Wouldn&apos;t `1` be enough?&lt;/p&gt;</comment>
                            <comment id="15857768" author="githubbot" created="Wed, 8 Feb 2017 10:12:16 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100030073&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100030073&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, inputLatch, 100, new AtomicBoolean(false));&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;Callback&amp;gt; pending = producer.getProducerInstance().getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		inputLatch.await();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    There is no concurrency in this test. Thus no need to synchronize on anything. The moment you reach this point, `inputLatch` will be triggered.&lt;/p&gt;</comment>
                            <comment id="15857769" author="githubbot" created="Wed, 8 Feb 2017 10:12:16 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100030377&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100030377&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, inputLatch, 100, new AtomicBoolean(false));&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;Callback&amp;gt; pending = producer.getProducerInstance().getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		inputLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure that all callbacks have not been completed&lt;br/&gt;
    +		Assert.assertEquals(100, pending.size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// use a separate thread to continuously monitor whether snapshotting has returned&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() {&lt;br/&gt;
    +				try &lt;/p&gt;
{
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					runnableError.f0 = e;
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Why this additional `Thread`? I think calling directly `testHarness.snapshot` is perfectly fine. Whether you block on this call or on the `Thread.join` does not make a difference.&lt;/p&gt;</comment>
                            <comment id="15857810" author="githubbot" created="Wed, 8 Feb 2017 10:34:32 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100035474&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100035474&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, inputLatch, 100, new AtomicBoolean(false));&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;Callback&amp;gt; pending = producer.getProducerInstance().getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));
    +		}
&lt;p&gt;    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    1 is enough, will change this.&lt;/p&gt;</comment>
                            <comment id="15857811" author="githubbot" created="Wed, 8 Feb 2017 10:35:27 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100035659&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100035659&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, inputLatch, 100, new AtomicBoolean(false));&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;Callback&amp;gt; pending = producer.getProducerInstance().getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		inputLatch.await();&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Correct, I&apos;ll change this. The other tests might actually not need also, I&apos;ll check them as well.&lt;/p&gt;</comment>
                            <comment id="15857814" author="githubbot" created="Wed, 8 Feb 2017 10:37:33 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100036011&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100036011&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, inputLatch, 100, new AtomicBoolean(false));&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		List&amp;lt;Callback&amp;gt; pending = producer.getProducerInstance().getPending();&lt;br/&gt;
    +&lt;br/&gt;
    +		for (int i = 0; i &amp;lt; 100; i++) &lt;/p&gt;
{
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));
    +		}
&lt;p&gt;    +&lt;br/&gt;
    +		inputLatch.await();&lt;br/&gt;
    +&lt;br/&gt;
    +		// make sure that all callbacks have not been completed&lt;br/&gt;
    +		Assert.assertEquals(100, pending.size());&lt;br/&gt;
    +&lt;br/&gt;
    +		// use a separate thread to continuously monitor whether snapshotting has returned&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() {&lt;br/&gt;
    +				try &lt;/p&gt;
{
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					runnableError.f0 = e;
    +				}
&lt;p&gt;    +			}&lt;br/&gt;
    +		});&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    You&apos;re right, not really sure what I was thinking at the time :/ Will change this!&lt;/p&gt;</comment>
                            <comment id="15857816" author="githubbot" created="Wed, 8 Feb 2017 10:40:51 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100036593&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100036593&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    That makes sense. I was just reusing the &lt;tt&gt;MockProducer&lt;/tt&gt; implementation in this class, which is needed in other tests to be able to provide success / failure fake callback completions. In this test we don&apos;t need to do that, so a simple &lt;tt&gt;mock(KafkaProducer.class)&lt;/tt&gt; should do.&lt;/p&gt;</comment>
                            <comment id="15857831" author="githubbot" created="Wed, 8 Feb 2017 10:55:58 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the detailed review @tillrohrmann, I&apos;ll follow-up and address your comments.&lt;/p&gt;

&lt;p&gt;    Regarding removing the `setFlushOnCheckpoint`:&lt;br/&gt;
    I think it was added at first to provide flexibility for users who know what they are doing, and making sure that the producer will be able to work in all environments (see comments in #2108).&lt;/p&gt;

&lt;p&gt;    However, recently I&apos;ve also gathered opinions (from you and others) about the settings over complicating at-least-once guarantees for the producer, and I have the feeling we can remove it starting from the next release.&lt;/p&gt;

&lt;p&gt;    There is &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5728&quot; title=&quot;FlinkKafkaProducer should flush on checkpoint by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5728&quot;&gt;&lt;del&gt;FLINK-5728&lt;/del&gt;&lt;/a&gt; to enable flushing by default (currently the default is no flushing). I&apos;ll incorporate your opinion on this to that JIRA, and decide there if we only want to disable if by default or remove it completely.&lt;/p&gt;
</comment>
                            <comment id="15858135" author="githubbot" created="Wed, 8 Feb 2017 15:43:47 +0000"  >&lt;p&gt;Github user rmetzger commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    I think we should allow users to disable the wait on flush, because it can substantially delay the confirmation of a checkpoint.&lt;br/&gt;
    If a user favors fast checkpoints over complete data in Kafka (for example when a particular producer instance is used mostly for debugging purposes only), we should allow them to do that. The overhead for us making this configurable is very low, but the benefit for some users might be huge.&lt;/p&gt;</comment>
                            <comment id="15860859" author="githubbot" created="Fri, 10 Feb 2017 07:18:34 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100482362&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100482362&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -293,6 +293,61 @@ public void run() &lt;/p&gt;
{
     		testHarness.close();
     	}

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;br/&gt;
    +		final OneShotLatch inputLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Turns out that we must have an extension of `KafkaProducer` provided to `FlinkKafkaProducerBase`. The reason is that the producer base requires implementing an abstract `flush` method, which doesn&apos;t exist on the `KafkaProducer`&apos;s interface. So it&apos;ll be more straightforward to extend `KafkaProducer` and implement a `flush` method ourselves, and let `FlinkKafkaProducerBase` call that.&lt;/p&gt;</comment>
                            <comment id="15860987" author="githubbot" created="Fri, 10 Feb 2017 09:38:02 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann I&apos;ve hopefully addressed your comments. Could you please have a look?&lt;/p&gt;

&lt;p&gt;    The major change was to refactor the `DummyFlinkKafkaProducer` so that a simple mock `KafkaProducer` can be provided for tests where a simple `verify(mockProducer).send(...)` is sufficient. The refactored version also has the advantage that it makes sure the `Callback` implementation in the connector is correct (correctly decrements `pendingRecords` value).&lt;/p&gt;

&lt;p&gt;    Note: the only thing I could not really improve is the `testAtLeastOnceProducer` test. Like before, the refactored version is still essentially continuously checking whether the snapshot method has returned early. The test is definitely stable, just that I don&apos;t think there is a better approach for it.&lt;/p&gt;</comment>
                            <comment id="15862840" author="githubbot" created="Sun, 12 Feb 2017 15:52:20 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100696016&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100696016&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Maybe you could override the `DummyFlinkKafkaProducer#flush` method to insert some latches to see when you enter and when the method is done. Then you could wait on the first latch and check with the latter whether the method has completed.&lt;/p&gt;</comment>
                            <comment id="15862839" author="githubbot" created="Sun, 12 Feb 2017 15:52:20 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100695842&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100695842&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Here you can use a `CheckedThread` instead.&lt;/p&gt;</comment>
                            <comment id="15862841" author="githubbot" created="Sun, 12 Feb 2017 15:52:20 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100695926&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100695926&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    The same could be done via `Thread.join(3, Seconds)`.&lt;/p&gt;</comment>
                            <comment id="15862842" author="githubbot" created="Sun, 12 Feb 2017 15:52:20 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100695937&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100695937&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try &lt;/p&gt;
{
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);
    +		}
&lt;p&gt; catch (TimeoutException expected) &lt;/p&gt;
{
    +			//
     		}&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(2, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(1, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertEquals(0, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		snapshotReturnedLatch.await();&lt;br/&gt;
    +		snapshotThread.join();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I think the latch is redundant.&lt;/p&gt;</comment>
                            <comment id="15862843" author="githubbot" created="Sun, 12 Feb 2017 15:52:20 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100695748&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100695748&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try &lt;/p&gt;
{
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);
    +		}
&lt;p&gt; catch (TimeoutException expected) &lt;/p&gt;
{
    +			//
     		}&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(2, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(1, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertEquals(0, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		snapshotReturnedLatch.await();&lt;br/&gt;
    +		snapshotThread.join();&lt;br/&gt;
    +&lt;br/&gt;
     		if (runnableError.f0 != null) 
{
     			throw runnableError.f0;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.close();&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// ------------------------------------------------------------------------&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;/li&gt;
	&lt;li&gt;private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private transient MockProducer prod;&lt;/li&gt;
	&lt;li&gt;private AtomicBoolean snapshottingFinished;&lt;br/&gt;
    +		testHarness.open();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner, AtomicBoolean snapshottingFinished) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = snapshottingFinished;
    -		}
&lt;p&gt;    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg&quot;));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// constructor variant for test irrelated to snapshotting&lt;/li&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = new AtomicBoolean(true);
    -		}
&lt;p&gt;    +		// make sure that all callbacks have not been completed&lt;br/&gt;
    +		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected &amp;lt;K, V&amp;gt; KafkaProducer&amp;lt;K, V&amp;gt; getKafkaProducer(Properties props) 
{
    -			this.prod = new MockProducer();
    -			return this.prod;
    -		}
&lt;p&gt;    +		// should return even if there are pending records&lt;br/&gt;
    +		testHarness.snapshot(123L, 123L);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void snapshotState(FunctionSnapshotContext ctx) throws Exception 
{
    -			// call the actual snapshot state
    -			super.snapshotState(ctx);
    -			// notify test that snapshotting has been done
    -			snapshottingFinished.set(true);
    -		}
&lt;p&gt;    +		testHarness.close();&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected void flush() 
{
    -			this.prod.flush();
    -		}
&lt;p&gt;    +	// ------------------------------------------------------------------------&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public MockProducer getProducerInstance() 
{
    -			return this.prod;
    -		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    +	private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		&lt;br/&gt;
    +		private final static String DUMMY_TOPIC = &quot;dummy-topic&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class MockProducer&amp;lt;K, V&amp;gt; extends KafkaProducer&amp;lt;K, V&amp;gt; {&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pendingCallbacks = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		private final KafkaProducer mockProducer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Not serializable --&amp;gt; `transient`&lt;/p&gt;</comment>
                            <comment id="15862844" author="githubbot" created="Sun, 12 Feb 2017 15:52:20 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100695754&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100695754&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try &lt;/p&gt;
{
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);
    +		}
&lt;p&gt; catch (TimeoutException expected) &lt;/p&gt;
{
    +			//
     		}&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(2, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(1, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertEquals(0, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		snapshotReturnedLatch.await();&lt;br/&gt;
    +		snapshotThread.join();&lt;br/&gt;
    +&lt;br/&gt;
     		if (runnableError.f0 != null) 
{
     			throw runnableError.f0;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.close();&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// ------------------------------------------------------------------------&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;/li&gt;
	&lt;li&gt;private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private transient MockProducer prod;&lt;/li&gt;
	&lt;li&gt;private AtomicBoolean snapshottingFinished;&lt;br/&gt;
    +		testHarness.open();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner, AtomicBoolean snapshottingFinished) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = snapshottingFinished;
    -		}
&lt;p&gt;    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg&quot;));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// constructor variant for test irrelated to snapshotting&lt;/li&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = new AtomicBoolean(true);
    -		}
&lt;p&gt;    +		// make sure that all callbacks have not been completed&lt;br/&gt;
    +		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected &amp;lt;K, V&amp;gt; KafkaProducer&amp;lt;K, V&amp;gt; getKafkaProducer(Properties props) 
{
    -			this.prod = new MockProducer();
    -			return this.prod;
    -		}
&lt;p&gt;    +		// should return even if there are pending records&lt;br/&gt;
    +		testHarness.snapshot(123L, 123L);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void snapshotState(FunctionSnapshotContext ctx) throws Exception 
{
    -			// call the actual snapshot state
    -			super.snapshotState(ctx);
    -			// notify test that snapshotting has been done
    -			snapshottingFinished.set(true);
    -		}
&lt;p&gt;    +		testHarness.close();&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected void flush() 
{
    -			this.prod.flush();
    -		}
&lt;p&gt;    +	// ------------------------------------------------------------------------&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public MockProducer getProducerInstance() 
{
    -			return this.prod;
    -		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    +	private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		&lt;br/&gt;
    +		private final static String DUMMY_TOPIC = &quot;dummy-topic&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class MockProducer&amp;lt;K, V&amp;gt; extends KafkaProducer&amp;lt;K, V&amp;gt; {&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pendingCallbacks = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		private final KafkaProducer mockProducer;&lt;br/&gt;
    +		private final List&amp;lt;Callback&amp;gt; pendingCallbacks = new ArrayList&amp;lt;&amp;gt;();
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    `Callback` is not serializable.&lt;/p&gt;</comment>
                            <comment id="15862845" author="githubbot" created="Sun, 12 Feb 2017 15:52:20 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r100695724&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r100695724&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try &lt;/p&gt;
{
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);
    +		}
&lt;p&gt; catch (TimeoutException expected) &lt;/p&gt;
{
    +			//
     		}&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(2, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(1, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertEquals(0, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		snapshotReturnedLatch.await();&lt;br/&gt;
    +		snapshotThread.join();&lt;br/&gt;
    +&lt;br/&gt;
     		if (runnableError.f0 != null) 
{
     			throw runnableError.f0;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.close();&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// ------------------------------------------------------------------------&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;/li&gt;
	&lt;li&gt;private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private transient MockProducer prod;&lt;/li&gt;
	&lt;li&gt;private AtomicBoolean snapshottingFinished;&lt;br/&gt;
    +		testHarness.open();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner, AtomicBoolean snapshottingFinished) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = snapshottingFinished;
    -		}
&lt;p&gt;    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg&quot;));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// constructor variant for test irrelated to snapshotting&lt;/li&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = new AtomicBoolean(true);
    -		}
&lt;p&gt;    +		// make sure that all callbacks have not been completed&lt;br/&gt;
    +		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected &amp;lt;K, V&amp;gt; KafkaProducer&amp;lt;K, V&amp;gt; getKafkaProducer(Properties props) 
{
    -			this.prod = new MockProducer();
    -			return this.prod;
    -		}
&lt;p&gt;    +		// should return even if there are pending records&lt;br/&gt;
    +		testHarness.snapshot(123L, 123L);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void snapshotState(FunctionSnapshotContext ctx) throws Exception 
{
    -			// call the actual snapshot state
    -			super.snapshotState(ctx);
    -			// notify test that snapshotting has been done
    -			snapshottingFinished.set(true);
    -		}
&lt;p&gt;    +		testHarness.close();&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected void flush() 
{
    -			this.prod.flush();
    -		}
&lt;p&gt;    +	// ------------------------------------------------------------------------&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public MockProducer getProducerInstance() 
{
    -			return this.prod;
    -		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    +	private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		&lt;br/&gt;
    +		private final static String DUMMY_TOPIC = &quot;dummy-topic&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class MockProducer&amp;lt;K, V&amp;gt; extends KafkaProducer&amp;lt;K, V&amp;gt; {&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pendingCallbacks = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		private final KafkaProducer mockProducer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Raw usage of Kafka producer&lt;/p&gt;</comment>
                            <comment id="15867807" author="githubbot" created="Wed, 15 Feb 2017 13:13:45 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r101273261&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r101273261&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Thanks for this tip! Will change.&lt;/p&gt;</comment>
                            <comment id="15867809" author="githubbot" created="Wed, 15 Feb 2017 13:14:49 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r101273458&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r101273458&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try {&lt;br/&gt;
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I&apos;ve removed the latch completely. You&apos;re right, the latch was unnecessary.&lt;/p&gt;</comment>
                            <comment id="15867827" author="githubbot" created="Wed, 15 Feb 2017 13:24:29 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r101275048&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r101275048&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,195 +87,296 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +		&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;/p&gt;

&lt;p&gt;     		DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), mockPartitioner, mockProducer);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		KafkaProducer mockProducer = mock(KafkaProducer.class);    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null, mockProducer);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; asyncError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
     			@Override&lt;br/&gt;
     			public void run() {&lt;br/&gt;
     				try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    +					// this should block at first, since there are still two pending records that needs to be flushed
    +					testHarness.snapshot(123L, 123L);
    +				}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +					asyncError.f0 = e;
     				}
&lt;p&gt;     			}&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;};&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    +		snapshotThread.join();
    +
    +		// the snapshot should have failed with the async exception
    +		Assert.assertTrue(asyncError.f0 != null &amp;amp;&amp;amp; asyncError.f0.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +	}
&lt;p&gt;    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;br/&gt;
    +		final OneShotLatch snapshotReturnedLatch = new OneShotLatch();&lt;br/&gt;
    +&lt;br/&gt;
    +		Thread snapshotThread = new Thread(new Runnable() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void run() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +				try {
    +					// this should block until all records are flushed
    +					testHarness.snapshot(123L, 123L);
    +				} catch (Throwable e) {
    +					runnableError.f0 = e;
    +				} finally {
    +					snapshotReturnedLatch.trigger();
    +				}    +			}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;    +		});&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked&lt;br/&gt;
    +		try &lt;/p&gt;
{
    +			snapshotReturnedLatch.await(3, TimeUnit.SECONDS);
    +		}
&lt;p&gt; catch (TimeoutException expected) &lt;/p&gt;
{
    +			//
     		}&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(2, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertTrue(&quot;Snapshot returned before all records were flushed&quot;, !snapshotReturnedLatch.isTriggered());&lt;br/&gt;
    +		Assert.assertEquals(1, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;br/&gt;
    +		Assert.assertEquals(0, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		snapshotReturnedLatch.await();&lt;br/&gt;
    +		snapshotThread.join();&lt;br/&gt;
    +&lt;br/&gt;
     		if (runnableError.f0 != null) 
{
     			throw runnableError.f0;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.close();&lt;br/&gt;
     	}&lt;/p&gt;

&lt;p&gt;    +	/**&lt;br/&gt;
    +	 * This test is meant to assure that testAtLeastOnceProducer is valid by testing that if flushing is disabled,&lt;br/&gt;
    +	 * the snapshot method does indeed finishes without waiting for pending records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testDoesNotWaitForPendingRecordsIfFlushingDisabled() throws Throwable {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// ------------------------------------------------------------------------&lt;br/&gt;
    +		KafkaProducer mockProducer = mock(KafkaProducer.class);&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null, mockProducer);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(false);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;/li&gt;
	&lt;li&gt;private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private transient MockProducer prod;&lt;/li&gt;
	&lt;li&gt;private AtomicBoolean snapshottingFinished;&lt;br/&gt;
    +		testHarness.open();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner, AtomicBoolean snapshottingFinished) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = snapshottingFinished;
    -		}
&lt;p&gt;    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg&quot;));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// constructor variant for test irrelated to snapshotting&lt;/li&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;public DummyFlinkKafkaProducer(Properties producerConfig, KafkaPartitioner partitioner) 
{
    -			super(&quot;dummy-topic&quot;, (KeyedSerializationSchema&amp;lt; T &amp;gt;) mock(KeyedSerializationSchema.class), producerConfig, partitioner);
    -			this.snapshottingFinished = new AtomicBoolean(true);
    -		}
&lt;p&gt;    +		// make sure that all callbacks have not been completed&lt;br/&gt;
    +		verify(mockProducer, times(1)).send(any(ProducerRecord.class), any(Callback.class));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected &amp;lt;K, V&amp;gt; KafkaProducer&amp;lt;K, V&amp;gt; getKafkaProducer(Properties props) 
{
    -			this.prod = new MockProducer();
    -			return this.prod;
    -		}
&lt;p&gt;    +		// should return even if there are pending records&lt;br/&gt;
    +		testHarness.snapshot(123L, 123L);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void snapshotState(FunctionSnapshotContext ctx) throws Exception 
{
    -			// call the actual snapshot state
    -			super.snapshotState(ctx);
    -			// notify test that snapshotting has been done
    -			snapshottingFinished.set(true);
    -		}
&lt;p&gt;    +		testHarness.close();&lt;br/&gt;
    +	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;protected void flush() 
{
    -			this.prod.flush();
    -		}
&lt;p&gt;    +	// ------------------------------------------------------------------------&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public MockProducer getProducerInstance() 
{
    -			return this.prod;
    -		}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
    +	private static class DummyFlinkKafkaProducer&amp;lt;T&amp;gt; extends FlinkKafkaProducerBase&amp;lt;T&amp;gt; {&lt;br/&gt;
    +		private static final long serialVersionUID = 1L;&lt;br/&gt;
    +		&lt;br/&gt;
    +		private final static String DUMMY_TOPIC = &quot;dummy-topic&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class MockProducer&amp;lt;K, V&amp;gt; extends KafkaProducer&amp;lt;K, V&amp;gt; {&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pendingCallbacks = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
    +		private final KafkaProducer mockProducer;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Will change to `transient`.&lt;/p&gt;

&lt;p&gt;    Curious, though: is this just for documentation purposes for readers of the code?&lt;/p&gt;

&lt;p&gt;    Otherwise, we need the `mockProducer` throughout the whole life cycle of the object (I tried instantiating a mocked `KafkaProducer` in `open()` like what we would normally do for the non-serializable fields, but it won&apos;t work because of how the `testPartitionerOpenedWithDeterminatePartitionList` needs to mock more method calls before calling `open()`). Also in the tests we&apos;re not serializing the instances anyway.&lt;/p&gt;</comment>
                            <comment id="15867860" author="githubbot" created="Wed, 15 Feb 2017 13:54:31 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    @tillrohrmann thanks for your second-pass review, the tips you mentioned were helpful. I&apos;ve incoporated all of your comments except:&lt;/p&gt;

&lt;p&gt;    &amp;gt; Maybe you could override the DummyFlinkKafkaProducer#flush method to insert some latches to see when you enter and when the method is done. Then you could wait on the first latch and check with the latter whether the method has completed.&lt;/p&gt;

&lt;p&gt;    I think this is over-complicating things. I don&apos;t think it makes sense to add ways to explicitly wait for the `flush` method to complete - it&apos;s called in the `snapshotState` method, so isn&apos;t it identical to waiting for the snapshot thread to complete?&lt;/p&gt;

&lt;p&gt;    Instead, I override the `snapshotState` method and added a flag inside the to make sure that when the base `snapshotState` implementation returns, it returned after it finished calling `flush`. Whether or not `flush` blocks correctly is out-of-scope of these tests, because `flush` is actually an abstract method for Kafka version-specific concrete subclasses to implement.&lt;/p&gt;</comment>
                            <comment id="15874235" author="githubbot" created="Mon, 20 Feb 2017 09:08:30 +0000"  >&lt;p&gt;Github user tillrohrmann commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r101971157&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r101971157&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,201 +85,321 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    -&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;br/&gt;
     			FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +		final KafkaProducer mockProducer = producer.getMockKafkaProducer();&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;br/&gt;
    +&lt;br/&gt;
     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +
    +			// test succeeded
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +
    +			// test succeeded
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final KafkaProducer&amp;lt;?, ?&amp;gt; mockProducer = producer.getMockKafkaProducer();&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +		CheckedThread snapshotThread = new CheckedThread() {&lt;br/&gt;
     			@Override&lt;/li&gt;
	&lt;li&gt;public void run() {&lt;/li&gt;
	&lt;li&gt;try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    -				}
&lt;p&gt;    +			public void go() throws Exception &lt;/p&gt;
{
    +				// this should block at first, since there are still two pending records that needs to be flushed
    +				testHarness.snapshot(123L, 123L);
     			}
&lt;p&gt;     		};&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;/li&gt;
	&lt;li&gt;if (runnableError.f0 != null) {&lt;/li&gt;
	&lt;li&gt;throw runnableError.f0;&lt;br/&gt;
    +		try 
{
    +			snapshotThread.sync();
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the snapshot should have failed with the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +
    +			// test succeeded
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +		Assert.fail();&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final KafkaProducer&amp;lt;?, ?&amp;gt; mockProducer = producer.getMockKafkaProducer();&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		CheckedThread snapshotThread = new CheckedThread() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void go() throws Exception &lt;/p&gt;
{
    +				// this should block until all records are flushed;
    +				// if the snapshot implementation returns before pending records are flushed,
    +				testHarness.snapshot(123L, 123L);
    +			}
&lt;p&gt;    +		};&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked;&lt;br/&gt;
    +		// after some arbitrary time, the snapshot should still be blocked&lt;br/&gt;
    +		snapshotThread.join(3000);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Blocking for 3 seconds is not good. It&apos;s basically a `sleep` what you&apos;re doing here. Better to wait on a latch which is triggered when you enter the flush method, for example.&lt;/p&gt;</comment>
                            <comment id="15874242" author="githubbot" created="Mon, 20 Feb 2017 09:17:33 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278#discussion_r101973453&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278#discussion_r101973453&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBaseTest.java &amp;#8212;&lt;br/&gt;
    @@ -88,201 +85,321 @@ public void testKeyValueDeserializersSetIfMissing() throws Exception {&lt;br/&gt;
     	@Test&lt;br/&gt;
     	public void testPartitionerOpenedWithDeterminatePartitionList() throws Exception {&lt;br/&gt;
     		KafkaPartitioner mockPartitioner = mock(KafkaPartitioner.class);&lt;br/&gt;
    +&lt;br/&gt;
     		RuntimeContext mockRuntimeContext = mock(RuntimeContext.class);&lt;br/&gt;
     		when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);&lt;br/&gt;
     		when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);&lt;br/&gt;
    -&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;br/&gt;
    +		&lt;br/&gt;
    +		// out-of-order list of 4 partitions&lt;br/&gt;
    +		List&amp;lt;PartitionInfo&amp;gt; mockPartitionsList = new ArrayList&amp;lt;&amp;gt;(4);&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));&lt;br/&gt;
    +		mockPartitionsList.add(new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));&lt;br/&gt;
    +&lt;br/&gt;
    +		final DummyFlinkKafkaProducer producer = new DummyFlinkKafkaProducer(&lt;br/&gt;
     			FakeStandardProducerConfig.get(), mockPartitioner);&lt;br/&gt;
     		producer.setRuntimeContext(mockRuntimeContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +		final KafkaProducer mockProducer = producer.getMockKafkaProducer();&lt;br/&gt;
    +		when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);&lt;br/&gt;
    +		when(mockProducer.metrics()).thenReturn(null);&lt;br/&gt;
    +&lt;br/&gt;
     		producer.open(new Configuration());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// the internal mock KafkaProducer will return an out-of-order list of 4 partitions,&lt;/li&gt;
	&lt;li&gt;// which should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
    +		// the out-of-order partitions list should be sorted before provided to the custom partitioner&apos;s open() method&lt;br/&gt;
     		int[] correctPartitionList = 
{0, 1, 2, 3}
&lt;p&gt;;&lt;br/&gt;
     		verify(mockPartitioner).open(0, 1, correctPartitionList);&lt;br/&gt;
     	}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Test ensuring that the producer is not dropping buffered records.;&lt;/li&gt;
	&lt;li&gt;* we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 * Test ensuring that if an invoke call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducer() throws Throwable {&lt;/li&gt;
	&lt;li&gt;runAtLeastOnceTest(true);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnInvoke() throws Throwable 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(    +			FakeStandardProducerConfig.get(), null);    +    +		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));    +    +		testHarness.open();    +    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&amp;quot;msg-1&amp;quot;));    +    +		// let the message request return an async exception    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&amp;quot;artificial async exception&amp;quot;));    +    +		try {
    +			testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));
    +		} catch (Exception e) {
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +
    +			// test succeeded
    +			return;
    +		}    +    +		Assert.fail();     	}&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     	/**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Ensures that the at least once producing test fails if the flushing is disabled&lt;br/&gt;
    +	 * Test ensuring that if a snapshot call happens right after an async exception is caught, it should be rethrown&lt;br/&gt;
     	 */&lt;/li&gt;
	&lt;li&gt;@Test(expected = AssertionError.class, timeout=5000)&lt;/li&gt;
	&lt;li&gt;public void testAtLeastOnceProducerFailsIfFlushingDisabled() throws Throwable 
{
    -		runAtLeastOnceTest(false);
    -	}
&lt;p&gt;    -&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private void runAtLeastOnceTest(boolean flushOnCheckpoint) throws Throwable {&lt;/li&gt;
	&lt;li&gt;final AtomicBoolean snapshottingFinished = new AtomicBoolean(false);&lt;br/&gt;
    +	@Test&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {&lt;br/&gt;
     		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;FakeStandardProducerConfig.get(), null, snapshottingFinished);&lt;/li&gt;
	&lt;li&gt;producer.setFlushOnCheckpoint(flushOnCheckpoint);&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink(producer));&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     		testHarness.open();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; 100; i++) {&lt;/li&gt;
	&lt;li&gt;testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-&quot; + i));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		// let the message request return an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, new Exception(&quot;artificial async exception&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		try 
{
    +			testHarness.snapshot(123L, 123L);
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the next invoke should rethrow the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async exception&quot;));
    +
    +			// test succeeded
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// start a thread confirming all pending records&lt;/li&gt;
	&lt;li&gt;final Tuple1&amp;lt;Throwable&amp;gt; runnableError = new Tuple1&amp;lt;&amp;gt;(null);&lt;/li&gt;
	&lt;li&gt;final Thread threadA = Thread.currentThread();&lt;br/&gt;
    +		Assert.fail();&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that if an async exception is caught for one of the flushed requests on checkpoint,&lt;br/&gt;
    +	 * it should be rethrown; we set a timeout because the test will not finish if the logic is broken.&lt;br/&gt;
    +	 *&lt;br/&gt;
    +	 * Note that this test does not test the snapshot method is blocked correctly when there are pending recorrds.&lt;br/&gt;
    +	 * The test for that is covered in testAtLeastOnceProducer.&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	@Test(timeout=5000)&lt;br/&gt;
    +	public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final KafkaProducer&amp;lt;?, ?&amp;gt; mockProducer = producer.getMockKafkaProducer();&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +&lt;br/&gt;
    +		// only let the first callback succeed for now&lt;br/&gt;
    +		producer.getPendingCallbacks().get(0).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runnable confirmer = new Runnable() {&lt;br/&gt;
    +		CheckedThread snapshotThread = new CheckedThread() {&lt;br/&gt;
     			@Override&lt;/li&gt;
	&lt;li&gt;public void run() {&lt;/li&gt;
	&lt;li&gt;try {&lt;/li&gt;
	&lt;li&gt;MockProducer mp = producer.getProducerInstance();&lt;/li&gt;
	&lt;li&gt;List&amp;lt;Callback&amp;gt; pending = mp.getPending();&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// we need to find out if the snapshot() method blocks forever&lt;/li&gt;
	&lt;li&gt;// this is not possible. If snapshot() is running, it will&lt;/li&gt;
	&lt;li&gt;// start removing elements from the pending list.&lt;/li&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -						threadA.wait(500L);
    -					}&lt;/li&gt;
	&lt;li&gt;// we now check that no records have been confirmed yet&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(100, pending.size());&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Snapshot method returned before all records were confirmed&quot;,&lt;/li&gt;
	&lt;li&gt;snapshottingFinished.get());&lt;br/&gt;
    -&lt;/li&gt;
	&lt;li&gt;// now confirm all checkpoints&lt;/li&gt;
	&lt;li&gt;for (Callback c: pending) 
{
    -						c.onCompletion(null, null);
    -					}&lt;/li&gt;
	&lt;li&gt;pending.clear();&lt;/li&gt;
	&lt;li&gt;} catch(Throwable t) 
{
    -					runnableError.f0 = t;
    -				}
&lt;p&gt;    +			public void go() throws Exception &lt;/p&gt;
{
    +				// this should block at first, since there are still two pending records that needs to be flushed
    +				testHarness.snapshot(123L, 123L);
     			}
&lt;p&gt;     		};&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;Thread threadB = new Thread(confirmer);&lt;/li&gt;
	&lt;li&gt;threadB.start();&lt;br/&gt;
    +		snapshotThread.start();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// this should block:&lt;/li&gt;
	&lt;li&gt;testHarness.snapshot(0, 0);&lt;br/&gt;
    +		// let the 2nd message fail with an async exception&lt;br/&gt;
    +		producer.getPendingCallbacks().get(1).onCompletion(null, new Exception(&quot;artificial async failure for 2nd message&quot;));&lt;br/&gt;
    +		producer.getPendingCallbacks().get(2).onCompletion(null, null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;synchronized (threadA) 
{
    -			threadA.notifyAll(); // just in case, to let the test fail faster
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertEquals(0, producer.getProducerInstance().getPending().size());&lt;/li&gt;
	&lt;li&gt;Deadline deadline = FiniteDuration.apply(5, &quot;s&quot;).fromNow();&lt;/li&gt;
	&lt;li&gt;while (deadline.hasTimeLeft() &amp;amp;&amp;amp; threadB.isAlive()) 
{
    -			threadB.join(500);
    -		}&lt;/li&gt;
	&lt;li&gt;Assert.assertFalse(&quot;Thread A is expected to be finished at this point. If not, the test is prone to fail&quot;, threadB.isAlive());&lt;/li&gt;
	&lt;li&gt;if (runnableError.f0 != null) {&lt;/li&gt;
	&lt;li&gt;throw runnableError.f0;&lt;br/&gt;
    +		try 
{
    +			snapshotThread.sync();
    +		}
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
    +			// the snapshot should have failed with the async exception
    +			Assert.assertTrue(e.getCause().getMessage().contains(&quot;artificial async failure for 2nd message&quot;));
    +
    +			// test succeeded
    +			return;
     		}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    +		Assert.fail();&lt;br/&gt;
    +	}&lt;br/&gt;
    +&lt;br/&gt;
    +	/**&lt;br/&gt;
    +	 * Test ensuring that the producer is not dropping buffered records;&lt;br/&gt;
    +	 * we set a timeout because the test will not finish if the logic is broken&lt;br/&gt;
    +	 */&lt;br/&gt;
    +	@SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
    +	@Test(timeout=10000)&lt;br/&gt;
    +	public void testAtLeastOnceProducer() throws Throwable {&lt;br/&gt;
    +		final DummyFlinkKafkaProducer&amp;lt;String&amp;gt; producer = new DummyFlinkKafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
    +			FakeStandardProducerConfig.get(), null);&lt;br/&gt;
    +		producer.setFlushOnCheckpoint(true);&lt;br/&gt;
    +&lt;br/&gt;
    +		final KafkaProducer&amp;lt;?, ?&amp;gt; mockProducer = producer.getMockKafkaProducer();&lt;br/&gt;
    +&lt;br/&gt;
    +		final OneInputStreamOperatorTestHarness&amp;lt;String, Object&amp;gt; testHarness =&lt;br/&gt;
    +			new OneInputStreamOperatorTestHarness&amp;lt;&amp;gt;(new StreamSink&amp;lt;&amp;gt;(producer));&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.open();&lt;br/&gt;
    +&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-1&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-2&quot;));&lt;br/&gt;
    +		testHarness.processElement(new StreamRecord&amp;lt;&amp;gt;(&quot;msg-3&quot;));&lt;br/&gt;
    +&lt;br/&gt;
    +		verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));&lt;br/&gt;
    +		Assert.assertEquals(3, producer.getPendingSize());&lt;br/&gt;
    +&lt;br/&gt;
    +		// start a thread to perform checkpointing&lt;br/&gt;
    +		CheckedThread snapshotThread = new CheckedThread() {&lt;br/&gt;
    +			@Override&lt;br/&gt;
    +			public void go() throws Exception &lt;/p&gt;
{
    +				// this should block until all records are flushed;
    +				// if the snapshot implementation returns before pending records are flushed,
    +				testHarness.snapshot(123L, 123L);
    +			}
&lt;p&gt;    +		};&lt;br/&gt;
    +		snapshotThread.start();&lt;br/&gt;
    +&lt;br/&gt;
    +		// being extra safe that the snapshot is correctly blocked;&lt;br/&gt;
    +		// after some arbitrary time, the snapshot should still be blocked&lt;br/&gt;
    +		snapshotThread.join(3000);&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Now I see what you mean, and the purpose of the latch you were previously proposing. Thanks for the comment. I will address this and proceed to merge the PR later today.&lt;/p&gt;
</comment>
                            <comment id="15877497" author="githubbot" created="Wed, 22 Feb 2017 05:22:10 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Addressed waiting for flushing to start with a latch instead of sleeping.&lt;br/&gt;
    Will merge this to `master` and `release-1.2` once Travis turns green (running also locally due to the timeouts).&lt;/p&gt;</comment>
                            <comment id="15878746" author="githubbot" created="Wed, 22 Feb 2017 17:15:14 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Tests have passed, failed ones are Travis timeouts. Merging this now ...&lt;/p&gt;</comment>
                            <comment id="15878770" author="githubbot" created="Wed, 22 Feb 2017 17:21:55 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3278&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15878777" author="tzulitai" created="Wed, 22 Feb 2017 17:24:58 +0000"  >&lt;p&gt;Resolved for &lt;tt&gt;master&lt;/tt&gt; via &lt;a href=&quot;http://git-wip-us.apache.org/repos/asf/flink/commit/646490c&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://git-wip-us.apache.org/repos/asf/flink/commit/646490c&lt;/a&gt;&lt;br/&gt;
Resolved for &lt;tt&gt;release-1.2&lt;/tt&gt; via &lt;a href=&quot;http://git-wip-us.apache.org/repos/asf/flink/commit/576cc89&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://git-wip-us.apache.org/repos/asf/flink/commit/576cc89&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15926437" author="githubbot" created="Wed, 15 Mar 2017 16:09:59 +0000"  >&lt;p&gt;GitHub user tzulitai opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5701&quot; title=&quot;FlinkKafkaProducer should check asyncException on checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5701&quot;&gt;&lt;del&gt;FLINK-5701&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; FlinkKafkaProducer should check asyncException on checkpoints&lt;/p&gt;

&lt;p&gt;    This is a backport of &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5701&quot; title=&quot;FlinkKafkaProducer should check asyncException on checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5701&quot;&gt;&lt;del&gt;FLINK-5701&lt;/del&gt;&lt;/a&gt; for `release-1.1`.&lt;/p&gt;

&lt;p&gt;    The added tests are identical to #3278, with only minor changes to fit with the state of the producer in the `release-1.1` branch.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/tzulitai/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/tzulitai/flink&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5701&quot; title=&quot;FlinkKafkaProducer should check asyncException on checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5701&quot;&gt;&lt;del&gt;FLINK-5701&lt;/del&gt;&lt;/a&gt;-1.1&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3549&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit e4d9a14dc45200c00806377cdd34f551870213ef&lt;br/&gt;
Author: Tzu-Li (Gordon) Tai &amp;lt;tzulitai@apache.org&amp;gt;&lt;br/&gt;
Date:   2017-03-15T16:05:51Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-5701&quot; title=&quot;FlinkKafkaProducer should check asyncException on checkpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-5701&quot;&gt;&lt;del&gt;FLINK-5701&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; FlinkKafkaProducer should check asyncException on checkpoints&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15926441" author="tzulitai" created="Wed, 15 Mar 2017 16:11:41 +0000"  >&lt;p&gt;Re-opening this, because it needs to be backported for 1.1.5.&lt;/p&gt;</comment>
                            <comment id="15926550" author="githubbot" created="Wed, 15 Mar 2017 16:52:42 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549#discussion_r106221016&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549#discussion_r106221016&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -240,6 +240,7 @@ public void open(Configuration configuration) {&lt;br/&gt;
     		}&lt;/p&gt;

&lt;p&gt;     		if (flushOnCheckpoint &amp;amp;&amp;amp; !((StreamingRuntimeContext)this.getRuntimeContext()).isCheckpointingEnabled()) {&lt;br/&gt;
    +			System.out.println(((StreamingRuntimeContext)this.getRuntimeContext()).isCheckpointingEnabled());&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This looks like a debug message&lt;/p&gt;</comment>
                            <comment id="15926551" author="githubbot" created="Wed, 15 Mar 2017 16:53:39 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549#discussion_r106221305&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549#discussion_r106221305&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -374,4 +380,11 @@ public static Properties getPropertiesFromBrokerList(String brokerList) &lt;/p&gt;
{
     		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
     		return props;
     	}
&lt;p&gt;    +&lt;br/&gt;
    +	// this is exposed for testing purposes&lt;br/&gt;
    +	protected long numPendingRecords() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    There is the `@VisibleForTesting` annotation for that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15926552" author="githubbot" created="Wed, 15 Mar 2017 16:54:25 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549#discussion_r106221523&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549#discussion_r106221523&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -240,6 +240,7 @@ public void open(Configuration configuration) {&lt;br/&gt;
     		}&lt;/p&gt;

&lt;p&gt;     		if (flushOnCheckpoint &amp;amp;&amp;amp; !((StreamingRuntimeContext)this.getRuntimeContext()).isCheckpointingEnabled()) {&lt;br/&gt;
    +			System.out.println(((StreamingRuntimeContext)this.getRuntimeContext()).isCheckpointingEnabled());&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes indeed, will remove.&lt;/p&gt;</comment>
                            <comment id="15926556" author="githubbot" created="Wed, 15 Mar 2017 16:55:26 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549#discussion_r106221830&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549#discussion_r106221830&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -374,4 +380,11 @@ public static Properties getPropertiesFromBrokerList(String brokerList) &lt;/p&gt;
{
     		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
     		return props;
     	}
&lt;p&gt;    +&lt;br/&gt;
    +	// this is exposed for testing purposes&lt;br/&gt;
    +	protected long numPendingRecords() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Damn .. This is Flink 1.1&lt;/p&gt;</comment>
                            <comment id="15926558" author="githubbot" created="Wed, 15 Mar 2017 16:55:54 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549#discussion_r106221979&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549#discussion_r106221979&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -374,4 +380,11 @@ public static Properties getPropertiesFromBrokerList(String brokerList) &lt;/p&gt;
{
     		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
     		return props;
     	}
&lt;p&gt;    +&lt;br/&gt;
    +	// this is exposed for testing purposes&lt;br/&gt;
    +	protected long numPendingRecords() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I don&apos;t think its available in `release-1.1`, is it? I might be mistakened, though ..&lt;/p&gt;</comment>
                            <comment id="15926563" author="githubbot" created="Wed, 15 Mar 2017 16:56:10 +0000"  >&lt;p&gt;Github user tzulitai commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549#discussion_r106222066&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549#discussion_r106222066&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -374,4 +380,11 @@ public static Properties getPropertiesFromBrokerList(String brokerList) &lt;/p&gt;
{
     		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
     		return props;
     	}
&lt;p&gt;    +&lt;br/&gt;
    +	// this is exposed for testing purposes&lt;br/&gt;
    +	protected long numPendingRecords() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    yup :-D&lt;/p&gt;</comment>
                            <comment id="15926564" author="githubbot" created="Wed, 15 Mar 2017 16:56:16 +0000"  >&lt;p&gt;Github user rmetzger commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549#discussion_r106222093&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549#discussion_r106222093&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-streaming-connectors/flink-connector-kafka-base/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java &amp;#8212;&lt;br/&gt;
    @@ -374,4 +380,11 @@ public static Properties getPropertiesFromBrokerList(String brokerList) &lt;/p&gt;
{
     		props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
     		return props;
     	}
&lt;p&gt;    +&lt;br/&gt;
    +	// this is exposed for testing purposes&lt;br/&gt;
    +	protected long numPendingRecords() {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    No, you are right &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15926566" author="githubbot" created="Wed, 15 Mar 2017 16:56:32 +0000"  >&lt;p&gt;Github user rmetzger commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Backport is +1 to merge, once the sysout has been removed.&lt;/p&gt;</comment>
                            <comment id="15927441" author="githubbot" created="Thu, 16 Mar 2017 03:57:22 +0000"  >&lt;p&gt;Github user tzulitai commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Thanks for the review!&lt;br/&gt;
    Travis is green (local branch), with only test timeouts: &lt;a href=&quot;https://travis-ci.org/tzulitai/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://travis-ci.org/tzulitai/flink&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Merging this ..&lt;/p&gt;</comment>
                            <comment id="15927479" author="githubbot" created="Thu, 16 Mar 2017 04:43:09 +0000"  >&lt;p&gt;Github user tzulitai closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3549&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3549&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15927482" author="tzulitai" created="Thu, 16 Mar 2017 04:43:50 +0000"  >&lt;p&gt;Additionally fixed for 1.1.5 with &lt;a href=&quot;http://git-wip-us.apache.org/repos/asf/flink/commit/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://git-wip-us.apache.org/repos/asf/flink/commit/&lt;/a&gt; 6662cc6.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 35 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i39kbr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>