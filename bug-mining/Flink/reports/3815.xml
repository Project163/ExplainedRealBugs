<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:44:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-16550] HadoopS3* tests fail with NullPointerException exceptions</title>
                <link>https://issues.apache.org/jira/browse/FLINK-16550</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;Logs: &lt;a href=&quot;https://travis-ci.org/github/apache/flink/jobs/660975486?utm_medium=notification&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://travis-ci.org/github/apache/flink/jobs/660975486?utm_medium=notification&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;All subsequent builds failed as well. It is likely that this commit / &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-16014&quot; title=&quot;S3 plugin ClassNotFoundException SAXParser&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-16014&quot;&gt;&lt;del&gt;FLINK-16014&lt;/del&gt;&lt;/a&gt; introduced the issue, as these tests depend on S3 credentials to be available.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
09:38:48.022 [INFO] -------------------------------------------------------
09:38:48.025 [INFO]  T E S T S
09:38:48.026 [INFO] -------------------------------------------------------
09:38:48.657 [INFO] Running org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase
09:38:48.669 [INFO] Running org.apache.flink.fs.s3hadoop.HadoopS3FileSystemITCase
09:38:54.541 [ERROR] Tests run: 3, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 5.88 s &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase
09:38:54.542 [ERROR] testResumeAfterCommit(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase)  Time elapsed: 3.592 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.Exception: Unexpected exception, expected&amp;lt;java.io.IOException&amp;gt; but was&amp;lt;java.lang.NullPointerException&amp;gt;
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase.testResumeAfterCommit(HadoopS3RecoverableWriterExceptionITCase.java:162)

09:38:54.542 [ERROR] testResumeWithWrongOffset(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase)  Time elapsed: 0.24 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.Exception: Unexpected exception, expected&amp;lt;java.io.IOException&amp;gt; but was&amp;lt;java.lang.NullPointerException&amp;gt;
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase.testResumeWithWrongOffset(HadoopS3RecoverableWriterExceptionITCase.java:182)

09:38:54.542 [ERROR] testExceptionWritingAfterCloseForCommit(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase)  Time elapsed: 0.448 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.Exception: Unexpected exception, expected&amp;lt;java.io.IOException&amp;gt; but was&amp;lt;java.lang.NullPointerException&amp;gt;
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterExceptionITCase.testExceptionWritingAfterCloseForCommit(HadoopS3RecoverableWriterExceptionITCase.java:144)

09:38:55.173 [INFO] Running org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase
09:38:58.737 [ERROR] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 10.066 s &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.flink.fs.s3hadoop.HadoopS3FileSystemITCase
09:38:58.737 [ERROR] testDirectoryListing(org.apache.flink.fs.s3hadoop.HadoopS3FileSystemITCase)  Time elapsed: 3.448 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.io.FileNotFoundException: No such file or directory: s3:&lt;span class=&quot;code-comment&quot;&gt;//[secure]/temp/tests-f37db36e-c116-4c58-a16b-8ca241baae4b/testdir
&lt;/span&gt;
09:38:59.447 [INFO] Running org.apache.flink.fs.s3hadoop.HadoopS3FileSystemBehaviorITCase
09:39:01.791 [ERROR] Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 6.611 s &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase
09:39:01.797 [ERROR] testCloseWithNoData(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 2.394 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testCloseWithNoData(HadoopS3RecoverableWriterITCase.java:186)

09:39:01.798 [ERROR] testCommitAfterPersist(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.191 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testCommitAfterPersist(HadoopS3RecoverableWriterITCase.java:208)

09:39:01.799 [ERROR] testRecoverWithEmptyState(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.235 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersist(HadoopS3RecoverableWriterITCase.java:384)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersistWithSmallData(HadoopS3RecoverableWriterITCase.java:352)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testRecoverWithEmptyState(HadoopS3RecoverableWriterITCase.java:302)

09:39:01.799 [ERROR] testRecoverFromIntermWithoutAdditionalState(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.181 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersist(HadoopS3RecoverableWriterITCase.java:384)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersistWithSmallData(HadoopS3RecoverableWriterITCase.java:352)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testRecoverFromIntermWithoutAdditionalState(HadoopS3RecoverableWriterITCase.java:316)

09:39:01.799 [ERROR] testCallingDeleteObjectTwiceDoesNotThroughException(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.181 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testCallingDeleteObjectTwiceDoesNotThroughException(HadoopS3RecoverableWriterITCase.java:245)

09:39:01.801 [ERROR] testCommitAfterNormalClose(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.174 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testCommitAfterNormalClose(HadoopS3RecoverableWriterITCase.java:196)

09:39:01.802 [ERROR] testRecoverWithStateWithMultiPart(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.338 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersist(HadoopS3RecoverableWriterITCase.java:384)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersistWithMultiPartUploads(HadoopS3RecoverableWriterITCase.java:364)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testRecoverWithStateWithMultiPart(HadoopS3RecoverableWriterITCase.java:330)

09:39:01.803 [ERROR] testRecoverFromIntermWithoutAdditionalStateWithMultiPart(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.486 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersist(HadoopS3RecoverableWriterITCase.java:384)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersistWithMultiPartUploads(HadoopS3RecoverableWriterITCase.java:364)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testRecoverFromIntermWithoutAdditionalStateWithMultiPart(HadoopS3RecoverableWriterITCase.java:337)

09:39:01.810 [ERROR] testRecoverWithState(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.199 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersist(HadoopS3RecoverableWriterITCase.java:384)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersistWithSmallData(HadoopS3RecoverableWriterITCase.java:352)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testRecoverWithState(HadoopS3RecoverableWriterITCase.java:309)

09:39:01.810 [ERROR] testCleanupRecoverableState(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.202 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.Exception: Unexpected exception, expected&amp;lt;java.io.FileNotFoundException&amp;gt; but was&amp;lt;java.lang.NullPointerException&amp;gt;
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testCleanupRecoverableState(HadoopS3RecoverableWriterITCase.java:223)

09:39:01.810 [ERROR] testCommitAfterRecovery(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.26 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testCommitAfterRecovery(HadoopS3RecoverableWriterITCase.java:270)

09:39:01.810 [ERROR] testRecoverAfterMultiplePersistsState(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.165 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersist(HadoopS3RecoverableWriterITCase.java:384)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersistWithSmallData(HadoopS3RecoverableWriterITCase.java:352)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testRecoverAfterMultiplePersistsState(HadoopS3RecoverableWriterITCase.java:323)

09:39:01.810 [ERROR] testRecoverAfterMultiplePersistsStateWithMultiPart(org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase)  Time elapsed: 0.735 s  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NullPointerException
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersist(HadoopS3RecoverableWriterITCase.java:384)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testResumeAfterMultiplePersistWithMultiPartUploads(HadoopS3RecoverableWriterITCase.java:364)
	at org.apache.flink.fs.s3hadoop.HadoopS3RecoverableWriterITCase.testRecoverAfterMultiplePersistsStateWithMultiPart(HadoopS3RecoverableWriterITCase.java:344)

09:39:14.711 [WARNING] Tests run: 8, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 15.262 s - in org.apache.flink.fs.s3hadoop.HadoopS3FileSystemBehaviorITCase
09:39:15.047 [INFO] 
09:39:15.047 [INFO] Results:
09:39:15.047 [INFO] 
09:39:15.047 [ERROR] Errors: 
09:39:15.047 [ERROR]   HadoopS3FileSystemITCase&amp;gt;AbstractHadoopFileSystemITTest.testDirectoryListing:127 &#194;&#187; FileNotFound
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterExceptionITCase.testExceptionWritingAfterCloseForCommit &#194;&#187; 
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterExceptionITCase.testResumeAfterCommit &#194;&#187;  Unexpected e...
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterExceptionITCase.testResumeWithWrongOffset &#194;&#187;  Unexpect...
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testCallingDeleteObjectTwiceDoesNotThroughException:245 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testCleanupRecoverableState &#194;&#187;  Unexpected exce...
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testCloseWithNoData:186 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testCommitAfterNormalClose:196 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testCommitAfterPersist:208 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testCommitAfterRecovery:270 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testRecoverAfterMultiplePersistsState:323-&amp;gt;testResumeAfterMultiplePersistWithSmallData:352-&amp;gt;testResumeAfterMultiplePersist:384 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testRecoverAfterMultiplePersistsStateWithMultiPart:344-&amp;gt;testResumeAfterMultiplePersistWithMultiPartUploads:364-&amp;gt;testResumeAfterMultiplePersist:384 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testRecoverFromIntermWithoutAdditionalState:316-&amp;gt;testResumeAfterMultiplePersistWithSmallData:352-&amp;gt;testResumeAfterMultiplePersist:384 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testRecoverFromIntermWithoutAdditionalStateWithMultiPart:337-&amp;gt;testResumeAfterMultiplePersistWithMultiPartUploads:364-&amp;gt;testResumeAfterMultiplePersist:384 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testRecoverWithEmptyState:302-&amp;gt;testResumeAfterMultiplePersistWithSmallData:352-&amp;gt;testResumeAfterMultiplePersist:384 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testRecoverWithState:309-&amp;gt;testResumeAfterMultiplePersistWithSmallData:352-&amp;gt;testResumeAfterMultiplePersist:384 &#194;&#187; NullPointer
09:39:15.047 [ERROR]   HadoopS3RecoverableWriterITCase.testRecoverWithStateWithMultiPart:330-&amp;gt;testResumeAfterMultiplePersistWithMultiPartUploads:364-&amp;gt;testResumeAfterMultiplePersist:384 &#194;&#187; NullPointer
09:39:15.047 [INFO] 
09:39:15.047 [ERROR] Tests run: 26, Failures: 0, Errors: 17, Skipped: 2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13291096">FLINK-16550</key>
            <summary>HadoopS3* tests fail with NullPointerException exceptions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="arvid">Arvid Heise</assignee>
                                    <reporter username="rmetzger">Robert Metzger</reporter>
                        <labels>
                            <label>pull-request-available</label>
                            <label>test-stability</label>
                    </labels>
                <created>Wed, 11 Mar 2020 14:33:00 +0000</created>
                <updated>Tue, 22 Jun 2021 14:04:37 +0000</updated>
                            <resolved>Thu, 12 Mar 2020 12:45:43 +0000</resolved>
                                    <version>1.11.0</version>
                                    <fixVersion>1.10.1</fixVersion>
                    <fixVersion>1.11.0</fixVersion>
                                    <component>FileSystems</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1200">20m</timespent>
                                <comments>
                            <comment id="17057370" author="zentol" created="Wed, 11 Mar 2020 20:48:34 +0000"  >&lt;p&gt;ping &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=AHeise&quot; class=&quot;user-hover&quot; rel=&quot;AHeise&quot;&gt;AHeise&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17057449" author="nicok" created="Wed, 11 Mar 2020 22:30:21 +0000"  >&lt;p&gt;This actually also showed up in an end-to-end Flink cluster setup where I couldn&apos;t download my savepoint from s3 anymore and this showed up on job submission:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 The program finished with the following exception:

org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: java.util.concurrent.ExecutionException: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
        at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:335)
        at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:205)
        at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:138)
        at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:664)
        at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:213)
        at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:895)
        at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:968)
        at org.apache.flink.runtime.security.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:30)
        at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:968)
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
        at org.apache.flink.util.ExceptionUtils.rethrow(ExceptionUtils.java:199)
        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1741)
        at org.apache.flink.streaming.api.environment.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:94)
        at org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:63)
        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1620)
        at org.apache.flink.streaming.examples.windowing.TopSpeedWindowing.main(TopSpeedWindowing.java:96)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:321)
        ... 8 more
Caused by: java.util.concurrent.ExecutionException: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
        at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357)
        at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1908)
        at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1736)
        ... 17 more
Caused by: org.apache.flink.runtime.client.JobSubmissionException: Failed to submit JobGraph.
        at org.apache.flink.client.program.&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;.RestClusterClient.lambda$submitJob$7(RestClusterClient.java:359)
        at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:884)
        at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:866)
        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
        at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990)
        at org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$8(FutureUtils.java:274)
        at java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)
        at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)
        at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)
        at java.util.concurrent.CompletableFuture.postFire(CompletableFuture.java:575)
        at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:943)
        at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:456)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: org.apache.flink.runtime.&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;.util.RestClientException: [Internal server error., &amp;lt;Exception on server side:
org.apache.flink.runtime.client.JobSubmissionException: Failed to submit job.
        at org.apache.flink.runtime.dispatcher.Dispatcher.lambda$internalSubmitJob$3(Dispatcher.java:336)
        at java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:836)
        at java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:811)
        at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:456)
        at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
        at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
        at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: org.apache.flink.runtime.client.JobExecutionException: Could not set up JobManager
        at org.apache.flink.util.function.CheckedSupplier.lambda$unchecked$0(CheckedSupplier.java:36)
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
        ... 6 more
Caused by: org.apache.flink.runtime.client.JobExecutionException: Could not set up JobManager
        at org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl.&amp;lt;init&amp;gt;(JobManagerRunnerImpl.java:152)
        at org.apache.flink.runtime.dispatcher.DefaultJobManagerRunnerFactory.createJobManagerRunner(DefaultJobManagerRunnerFactory.java:84)
        at org.apache.flink.runtime.dispatcher.Dispatcher.lambda$createJobManagerRunner$6(Dispatcher.java:379)
        at org.apache.flink.util.function.CheckedSupplier.lambda$unchecked$0(CheckedSupplier.java:34)
        ... 7 more
Caused by: java.io.FileNotFoundException: Cannot find checkpoint or savepoint file/directory &lt;span class=&quot;code-quote&quot;&gt;&apos;&amp;lt;path&amp;gt;&apos;&lt;/span&gt; on file system &lt;span class=&quot;code-quote&quot;&gt;&apos;s3&apos;&lt;/span&gt;.
        at org.apache.flink.runtime.state.filesystem.AbstractFsCheckpointStorage.resolveCheckpointPointer(AbstractFsCheckpointStorage.java:243)
        at org.apache.flink.runtime.state.filesystem.AbstractFsCheckpointStorage.resolveCheckpoint(AbstractFsCheckpointStorage.java:110)
        at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.restoreSavepoint(CheckpointCoordinator.java:1152)
        at org.apache.flink.runtime.scheduler.SchedulerBase.tryRestoreExecutionGraphFromSavepoint(SchedulerBase.java:307)
        at org.apache.flink.runtime.scheduler.SchedulerBase.createAndRestoreExecutionGraph(SchedulerBase.java:240)
        at org.apache.flink.runtime.scheduler.SchedulerBase.&amp;lt;init&amp;gt;(SchedulerBase.java:216)
        at org.apache.flink.runtime.scheduler.DefaultScheduler.&amp;lt;init&amp;gt;(DefaultScheduler.java:120)
        at org.apache.flink.runtime.scheduler.DefaultSchedulerFactory.createInstance(DefaultSchedulerFactory.java:105)
        at org.apache.flink.runtime.jobmaster.JobMaster.createScheduler(JobMaster.java:278)
        at org.apache.flink.runtime.jobmaster.JobMaster.&amp;lt;init&amp;gt;(JobMaster.java:266)
        at org.apache.flink.runtime.jobmaster.factories.DefaultJobMasterServiceFactory.createJobMasterService(DefaultJobMasterServiceFactory.java:98)
        at org.apache.flink.runtime.jobmaster.factories.DefaultJobMasterServiceFactory.createJobMasterService(DefaultJobMasterServiceFactory.java:40)
        at org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl.&amp;lt;init&amp;gt;(JobManagerRunnerImpl.java:146)
        ... 10 more

End of exception on server side&amp;gt;]
        at org.apache.flink.runtime.&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;.RestClient.parseResponse(RestClient.java:390)
        at org.apache.flink.runtime.&lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt;.RestClient.lambda$submitRequest$3(RestClient.java:374)
        at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:966)
        at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:940)
        ... 4 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The proposed patch fixes that scenario as well.&lt;/p&gt;</comment>
                            <comment id="17057451" author="rmetzger" created="Wed, 11 Mar 2020 22:42:56 +0000"  >&lt;p&gt;Thanks for providing a patch Arvid. I assigned you to the ticket.&lt;/p&gt;</comment>
                            <comment id="17057891" author="rmetzger" created="Thu, 12 Mar 2020 12:45:43 +0000"  >&lt;p&gt;Resolved in 62abfa97a497f03d8701f4acdbdd9217f0d33a06&lt;/p&gt;</comment>
                            <comment id="17058036" author="arvid" created="Thu, 12 Mar 2020 16:00:31 +0000"  >&lt;p&gt;Should also be backported to 1.10.&lt;/p&gt;</comment>
                            <comment id="17058038" author="rmetzger" created="Thu, 12 Mar 2020 16:01:47 +0000"  >&lt;p&gt;Done in 15a149ebc4042c5f623c88c1afddb826bc4d09e7&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="13291245">FLINK-16564</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13284766">FLINK-16014</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 35 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0cfao:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>