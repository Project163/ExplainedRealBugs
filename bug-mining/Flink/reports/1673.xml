<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 20:28:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[FLINK-6491] Add QueryConfig to specify state retention time for streaming queries</title>
                <link>https://issues.apache.org/jira/browse/FLINK-6491</link>
                <project id="12315522" key="FLINK">Flink</project>
                    <description>&lt;p&gt;By now we have a couple of streaming operators (group-windows, over-windows, non-windowed aggregations) that require operator state. Since state is not automatically cleaned-up by Flink, we need to add a mechanism to configure a state retention time. &lt;/p&gt;

&lt;p&gt;If configured, a query will retain state for a specified period of state inactivity. If state is not accessed within this period of time, it will be cleared. I propose to add two parameters for this, a min and a max retention time. The min retention time specifies the earliest time and the max retention time the latest time when state is cleared. The reasoning for having two parameters is that we can avoid to register many timers if we have more freedom when to discard state.&lt;/p&gt;

&lt;p&gt;This issue also introduces a QueryConfig object which can be passed to a streaming query, when it is emitted to a TableSink or converted to a DataStream (append or retraction).&lt;/p&gt;</description>
                <environment></environment>
        <key id="13070055">FLINK-6491</key>
            <summary>Add QueryConfig to specify state retention time for streaming queries</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="10">Implemented</resolution>
                                        <assignee username="sunjincheng121">sunjincheng</assignee>
                                    <reporter username="fhueske">Fabian Hueske</reporter>
                        <labels>
                    </labels>
                <created>Mon, 8 May 2017 16:40:05 +0000</created>
                <updated>Fri, 12 May 2017 06:52:23 +0000</updated>
                            <resolved>Fri, 12 May 2017 06:52:23 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>1.3.0</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>Table SQL / API</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16004626" author="githubbot" created="Wed, 10 May 2017 12:46:08 +0000"  >&lt;p&gt;GitHub user sunjincheng121 opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6491&quot; title=&quot;Add QueryConfig to specify state retention time for streaming queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6491&quot;&gt;&lt;del&gt;FLINK-6491&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;talbe&amp;#93;&lt;/span&gt;Add QueryConfig to specify state retention time for streaming queries&lt;/p&gt;

&lt;p&gt;    In this PR we have the changes as follows:&lt;br/&gt;
    1. Add QueryConfig and state clean up for non-windowed aggregates.&lt;br/&gt;
    2. Add QueryConfig and state clean up for over-windowed aggregates.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; General&lt;/li&gt;
	&lt;li&gt;The pull request references the related JIRA issue (&quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6491&quot; title=&quot;Add QueryConfig to specify state retention time for streaming queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6491&quot;&gt;&lt;del&gt;FLINK-6491&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;talbe&amp;#93;&lt;/span&gt;Add QueryConfig to specify state retention time for streaming queries&quot;)&lt;/li&gt;
	&lt;li&gt;The pull request addresses only one issue&lt;/li&gt;
	&lt;li&gt;Each commit in the PR has a meaningful commit message (including the JIRA id)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Documentation&lt;/li&gt;
	&lt;li&gt;Documentation has been added for new functionality&lt;/li&gt;
	&lt;li&gt;Old documentation affected by the pull request has been updated&lt;/li&gt;
	&lt;li&gt;JavaDoc for public methods has been added&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; Tests &amp;amp; Build&lt;/li&gt;
	&lt;li&gt;Functionality added by the pull request is covered by tests&lt;/li&gt;
	&lt;li&gt;`mvn clean verify` has been executed successfully locally or a Travis build has passed&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/sunjincheng121/flink&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/sunjincheng121/flink&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6491&quot; title=&quot;Add QueryConfig to specify state retention time for streaming queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6491&quot;&gt;&lt;del&gt;FLINK-6491&lt;/del&gt;&lt;/a&gt;-PR&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3863&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 2d168a924d5a607343579793b64f621aa15419bd&lt;br/&gt;
Author: Fabian Hueske &amp;lt;fhueske@apache.org&amp;gt;&lt;br/&gt;
Date:   2017-05-08T16:41:37Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6491&quot; title=&quot;Add QueryConfig to specify state retention time for streaming queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6491&quot;&gt;&lt;del&gt;FLINK-6491&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; Add QueryConfig and state clean up for non-windowed aggregates.&lt;/p&gt;

&lt;p&gt;commit f8b2ef3d27ef73142679ab50882a46c895074947&lt;br/&gt;
Author: sunjincheng121 &amp;lt;sunjincheng121@gmail.com&amp;gt;&lt;br/&gt;
Date:   2017-05-09T06:36:42Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-6491&quot; title=&quot;Add QueryConfig to specify state retention time for streaming queries&quot; class=&quot;issue-link&quot; data-issue-key=&quot;FLINK-6491&quot;&gt;&lt;del&gt;FLINK-6491&lt;/del&gt;&lt;/a&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt; Add QueryConfig and state clean up for over-windowed aggregates.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16004893" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115734636&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115734636&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamGroupAggregate.scala &amp;#8212;&lt;br/&gt;
    @@ -100,9 +104,18 @@ class DataStreamGroupAggregate(&lt;br/&gt;
             inputSchema.logicalType, groupings, getRowType, namedAggregates, Nil))&lt;br/&gt;
       }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;override def translateToPlan(tableEnv: StreamTableEnvironment): DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;CRow&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
    +  override def translateToPlan(&lt;br/&gt;
    +      tableEnv: StreamTableEnvironment,&lt;br/&gt;
    +      qConfig: StreamQueryConfig): DataStream&lt;span class=&quot;error&quot;&gt;&amp;#91;CRow&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
    +&lt;br/&gt;
    +    if (qConfig.getMinIdleStateRetentionTime &amp;lt; 0 || qConfig.getMaxIdleStateRetentionTime &amp;lt; 0) {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    we should also check that this is not a global aggregate and only emit a warning if the aggregate is partitioned.&lt;/p&gt;</comment>
                            <comment id="16004894" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115731631&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115731631&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/StreamTableEnvironment.scala &amp;#8212;&lt;br/&gt;
    @@ -81,6 +81,8 @@ abstract class StreamTableEnvironment(&lt;br/&gt;
       // the naming pattern for internally registered tables.&lt;br/&gt;
       private val internalNamePattern = &quot;^&lt;em&gt;DataStreamTable&lt;/em&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;+$&quot;.r&lt;/p&gt;

&lt;p&gt;    +  def qConf: StreamQueryConfig = new StreamQueryConfig&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    rename to `queryConfig`?&lt;/p&gt;</comment>
                            <comment id="16004895" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115731151&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115731151&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/BatchTableEnvironment.scala &amp;#8212;&lt;br/&gt;
    @@ -113,9 +113,20 @@ abstract class BatchTableEnvironment(&lt;br/&gt;
         *&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@param table The [&lt;span class=&quot;error&quot;&gt;&amp;#91;Table&amp;#93;&lt;/span&gt;] to write.&lt;/li&gt;
	&lt;li&gt;@param sink The [&lt;span class=&quot;error&quot;&gt;&amp;#91;TableSink&amp;#93;&lt;/span&gt;] to write the [&lt;span class=&quot;error&quot;&gt;&amp;#91;Table&amp;#93;&lt;/span&gt;] to.&lt;br/&gt;
    +    * @param qConfig The configuration for the query to generate.&lt;/li&gt;
	&lt;li&gt;@tparam T The expected type of the [&lt;span class=&quot;error&quot;&gt;&amp;#91;DataSet&amp;#93;&lt;/span&gt;] which represents the [&lt;span class=&quot;error&quot;&gt;&amp;#91;Table&amp;#93;&lt;/span&gt;].&lt;br/&gt;
         */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;override private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def writeToSink&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;(table: Table, sink: TableSink&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
    +  override private&lt;span class=&quot;error&quot;&gt;&amp;#91;flink&amp;#93;&lt;/span&gt; def writeToSink&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;(&lt;br/&gt;
    +      table: Table,&lt;br/&gt;
    +      sink: TableSink&lt;span class=&quot;error&quot;&gt;&amp;#91;T&amp;#93;&lt;/span&gt;,&lt;br/&gt;
    +      qConfig: QueryConfig): Unit = {&lt;br/&gt;
    +&lt;br/&gt;
    +    // We do not pass the configuration on, because there is nothing to configure for batch queries.&lt;br/&gt;
    +    val bQConfig = qConfig match {
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    can change this to &lt;br/&gt;
    ```&lt;br/&gt;
    qConfig match &lt;/p&gt;
{
      case _: BatchQueryConfig =&amp;gt;
      case _ =&amp;gt;
        throw new TableException(&quot;BatchQueryConfig required to configure batch query.&quot;)
    }
&lt;p&gt;    ```&lt;/p&gt;</comment>
                            <comment id="16004896" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115779043&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115779043&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/harness/OverWindowHarnessTest.scala &amp;#8212;&lt;br/&gt;
    @@ -220,15 +74,19 @@ class OverWindowHarnessTest extends HarnessTestBase{&lt;br/&gt;
         testHarness.processElement(new StreamRecord(&lt;br/&gt;
           CRow(Row.of(2: JInt, 0L: JLong, 0: JInt, &quot;bbb&quot;, 30L: JLong), true), 1))&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;testHarness.setProcessingTime(2)&lt;br/&gt;
    +    // trigger cleanup timer and register cleanup timer with 6001&lt;br/&gt;
    +    testHarness.setProcessingTime(3001)&lt;br/&gt;
         testHarness.processElement(new StreamRecord(&lt;br/&gt;
           CRow(Row.of(1: JInt, 11L: JLong, 1: JInt, &quot;aaa&quot;, 7L: JLong), true), 2))&lt;br/&gt;
         testHarness.processElement(new StreamRecord(&lt;br/&gt;
           CRow(Row.of(1: JInt, 11L: JLong, 1: JInt, &quot;aaa&quot;, 8L: JLong), true), 2))&lt;br/&gt;
         testHarness.processElement(new StreamRecord(&lt;br/&gt;
           CRow(Row.of(1: JInt, 11L: JLong, 1: JInt, &quot;aaa&quot;, 9L: JLong), true), 2))&lt;br/&gt;
    +&lt;br/&gt;
    +    // using historical data and register cleanup timer with 9000
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    what do you mean by historical data?&lt;/p&gt;</comment>
                            <comment id="16004897" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115734490&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115734490&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala &amp;#8212;&lt;br/&gt;
    @@ -239,6 +248,7 @@ class DataStreamOverAggregate(&lt;br/&gt;
       }&lt;/p&gt;

&lt;p&gt;       def createBoundedAndCurrentRowOverWindow(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    we should add a warning similar to `DataStreamGroupAggregate` if the windows are partitioned. The non-partitioned case can be cleaned up as well, but is not so critical.&lt;/p&gt;</comment>
                            <comment id="16004898" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115747425&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115747425&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/harness/HarnessTestBase.scala &amp;#8212;&lt;br/&gt;
    @@ -19,15 +19,299 @@ package org.apache.flink.table.runtime.harness&lt;/p&gt;

&lt;p&gt;     import java.util.&lt;/p&gt;
{Comparator, Queue =&amp;gt; JQueue}

&lt;p&gt;    +import org.apache.flink.api.common.time.Time&lt;br/&gt;
    +import org.apache.flink.api.common.typeinfo.BasicTypeInfo.&lt;/p&gt;
{INT_TYPE_INFO, LONG_TYPE_INFO, STRING_TYPE_INFO}
&lt;p&gt;     import org.apache.flink.api.common.typeinfo.TypeInformation&lt;br/&gt;
     import org.apache.flink.api.java.functions.KeySelector&lt;br/&gt;
    +import org.apache.flink.api.java.typeutils.RowTypeInfo&lt;br/&gt;
     import org.apache.flink.streaming.api.operators.OneInputStreamOperator&lt;br/&gt;
     import org.apache.flink.streaming.api.watermark.Watermark&lt;br/&gt;
     import org.apache.flink.streaming.runtime.streamrecord.StreamRecord&lt;br/&gt;
     import org.apache.flink.streaming.util.&lt;/p&gt;
{KeyedOneInputStreamOperatorTestHarness, TestHarnessUtil}
&lt;p&gt;    -import org.apache.flink.table.runtime.types.CRow&lt;br/&gt;
    +import org.apache.flink.table.api.StreamQueryConfig&lt;br/&gt;
    +import org.apache.flink.table.codegen.GeneratedAggregationsFunction&lt;br/&gt;
    +import org.apache.flink.table.functions.AggregateFunction&lt;br/&gt;
    +import org.apache.flink.table.functions.aggfunctions.&lt;/p&gt;
{LongMaxWithRetractAggFunction, LongMinWithRetractAggFunction, IntSumWithRetractAggFunction}
&lt;p&gt;    +import org.apache.flink.table.runtime.aggregate.AggregateUtil&lt;br/&gt;
    +import org.apache.flink.table.runtime.types.&lt;/p&gt;
{CRow, CRowTypeInfo}

&lt;p&gt;     class HarnessTestBase {&lt;br/&gt;
    +&lt;br/&gt;
    +  protected var qConfig =&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I would not make this part of the test base. &lt;br/&gt;
    IMO, the tests are easier to read if we do not have to check the harness for all implementations.&lt;/p&gt;</comment>
                            <comment id="16004899" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115739260&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115739260&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/ProcessFunctionWithCleanupState.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,99 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.table.runtime.aggregate&lt;br/&gt;
    +&lt;br/&gt;
    +import java.lang.&lt;/p&gt;
{Long =&amp;gt; JLong}
&lt;p&gt;    +&lt;br/&gt;
    +import org.apache.flink.api.common.state.&lt;/p&gt;
{ValueState, ValueStateDescriptor}
&lt;p&gt;    +import org.apache.flink.api.common.state.State&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.ProcessFunction&lt;br/&gt;
    +import org.apache.flink.table.api.&lt;/p&gt;
{StreamQueryConfig, Types}
&lt;p&gt;    +&lt;br/&gt;
    +abstract class ProcessFunctionWithCleanupState&lt;span class=&quot;error&quot;&gt;&amp;#91;IN,OUT&amp;#93;&lt;/span&gt;(qConfig: StreamQueryConfig)&lt;br/&gt;
    +  extends ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;{&lt;br/&gt;
    +&lt;br/&gt;
    +  protected val minRetentionTime = qConfig.getMinIdleStateRetentionTime&lt;br/&gt;
    +  protected val maxRetentionTime = qConfig.getMaxIdleStateRetentionTime&lt;br/&gt;
    +  protected val stateCleaningEnabled = minRetentionTime &amp;gt; 1 &amp;amp;&amp;amp; maxRetentionTime &amp;gt; 1&lt;br/&gt;
    +  // interval in which clean-up timers are registered&lt;br/&gt;
    +  protected val cleanupTimerInterval = maxRetentionTime - minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +  // holds the latest registered cleanup timer&lt;br/&gt;
    +  private var cleanupTimeState: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;JLong&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def initCleanupTimeState(stateName: String) {&lt;br/&gt;
    +    if (stateCleaningEnabled) &lt;/p&gt;
{
    +      val inputCntDescriptor: ValueStateDescriptor[JLong] =
    +        new ValueStateDescriptor[JLong](stateName, Types.LONG)
    +      cleanupTimeState = getRuntimeContext.getState(inputCntDescriptor)
    +    }
&lt;p&gt;    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def registerProcessingCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) &lt;/p&gt;
{
    +        // we need to register a new timer
    +        val cleanupTime = earliestCleanup + cleanupTimerInterval
    +        // register timer and remember clean-up time
    +        ctx.timerService().registerProcessingTimeTimer(cleanupTime)
    +        cleanupTimeState.update(cleanupTime)
    +      }
&lt;p&gt;    +    }&lt;br/&gt;
    +  }&lt;br/&gt;
    +  protected def registerEventCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) &lt;/p&gt;
{
    +        // we need to register a new timer
    +        val cleanupTime = earliestCleanup + cleanupTimerInterval
    +        // register timer and remember clean-up time
    +        ctx.timerService().registerEventTimeTimer(cleanupTime)
    +        cleanupTimeState.update(cleanupTime)
    +      }
&lt;p&gt;    +    }&lt;br/&gt;
    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def cleanupStateOnTimer(timestamp: Long, states: State*): Boolean = {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    we need to add the `OnTimerContext` as a parameter as well to check if this is a processing time timer call.&lt;/p&gt;</comment>
                            <comment id="16004900" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115775350&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115775350&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/ProcessFunctionWithCleanupState.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,99 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.table.runtime.aggregate&lt;br/&gt;
    +&lt;br/&gt;
    +import java.lang.&lt;/p&gt;
{Long =&amp;gt; JLong}
&lt;p&gt;    +&lt;br/&gt;
    +import org.apache.flink.api.common.state.&lt;/p&gt;
{ValueState, ValueStateDescriptor}
&lt;p&gt;    +import org.apache.flink.api.common.state.State&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.ProcessFunction&lt;br/&gt;
    +import org.apache.flink.table.api.&lt;/p&gt;
{StreamQueryConfig, Types}
&lt;p&gt;    +&lt;br/&gt;
    +abstract class ProcessFunctionWithCleanupState&lt;span class=&quot;error&quot;&gt;&amp;#91;IN,OUT&amp;#93;&lt;/span&gt;(qConfig: StreamQueryConfig)&lt;br/&gt;
    +  extends ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;{&lt;br/&gt;
    +&lt;br/&gt;
    +  protected val minRetentionTime = qConfig.getMinIdleStateRetentionTime&lt;br/&gt;
    +  protected val maxRetentionTime = qConfig.getMaxIdleStateRetentionTime&lt;br/&gt;
    +  protected val stateCleaningEnabled = minRetentionTime &amp;gt; 1 &amp;amp;&amp;amp; maxRetentionTime &amp;gt; 1&lt;br/&gt;
    +  // interval in which clean-up timers are registered&lt;br/&gt;
    +  protected val cleanupTimerInterval = maxRetentionTime - minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +  // holds the latest registered cleanup timer&lt;br/&gt;
    +  private var cleanupTimeState: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;JLong&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def initCleanupTimeState(stateName: String) {&lt;br/&gt;
    +    if (stateCleaningEnabled) &lt;/p&gt;
{
    +      val inputCntDescriptor: ValueStateDescriptor[JLong] =
    +        new ValueStateDescriptor[JLong](stateName, Types.LONG)
    +      cleanupTimeState = getRuntimeContext.getState(inputCntDescriptor)
    +    }
&lt;p&gt;    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def registerProcessingCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) &lt;/p&gt;
{
    +        // we need to register a new timer
    +        val cleanupTime = earliestCleanup + cleanupTimerInterval
    +        // register timer and remember clean-up time
    +        ctx.timerService().registerProcessingTimeTimer(cleanupTime)
    +        cleanupTimeState.update(cleanupTime)
    +      }
&lt;p&gt;    +    }&lt;br/&gt;
    +  }&lt;br/&gt;
    +  protected def registerEventCleanupTimer(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I&apos;m not sure if we should define state cleanup on event time. &lt;br/&gt;
    If we have an event-time window followed by a non-windowed aggregate, we would use event-time and processing time for cleaning up. Event-time is also harder to reason about than processing time. &lt;br/&gt;
    The RocksDB TTL is probably also defined in terms of wall clock time.&lt;/p&gt;

&lt;p&gt;    So I would propose to drop this method and always use processing time for cleanup timers.&lt;br/&gt;
    What do you think @sunjincheng121?&lt;/p&gt;</comment>
                            <comment id="16004901" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115734432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115734432&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala &amp;#8212;&lt;br/&gt;
    @@ -182,6 +189,7 @@ class DataStreamOverAggregate(&lt;br/&gt;
       }&lt;/p&gt;

&lt;p&gt;       def createUnboundedAndCurrentRowOverWindow(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    we should add a warning similar to `DataStreamGroupAggregate` if the windows are partitioned. The non-partitioned case can be cleaned up as well, but is not so critical.&lt;/p&gt;</comment>
                            <comment id="16004903" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115739685&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115739685&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/RowTimeBoundedRowsOver.scala &amp;#8212;&lt;br/&gt;
    @@ -43,8 +44,9 @@ class RowTimeBoundedRowsOver(&lt;br/&gt;
         genAggregations: GeneratedAggregationsFunction,&lt;br/&gt;
         aggregationStateType: RowTypeInfo,&lt;br/&gt;
         inputRowType: CRowTypeInfo,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;precedingOffset: Long)&lt;/li&gt;
	&lt;li&gt;extends ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;CRow, CRow&amp;#93;&lt;/span&gt;&lt;br/&gt;
    +    precedingOffset: Long,&lt;br/&gt;
    +    qConfig: StreamQueryConfig)&lt;br/&gt;
    +extends ProcessFunctionWithCleanupState&lt;span class=&quot;error&quot;&gt;&amp;#91;CRow, CRow&amp;#93;&lt;/span&gt;(qConfig)
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    indent +2&lt;/p&gt;</comment>
                            <comment id="16004902" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115750947&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115750947&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala &amp;#8212;&lt;br/&gt;
    @@ -182,6 +189,7 @@ class DataStreamOverAggregate(&lt;br/&gt;
       }&lt;/p&gt;

&lt;p&gt;       def createUnboundedAndCurrentRowOverWindow(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Also we should check for processing time over range windows that `minIdleStateRetentionTime` &amp;gt; preceding interval. Otherwise, we cannot compute this correctly.&lt;/p&gt;</comment>
                            <comment id="16004904" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115778205&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115778205&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/ProcessFunctionWithCleanupState.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,99 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.table.runtime.aggregate&lt;br/&gt;
    +&lt;br/&gt;
    +import java.lang.&lt;/p&gt;
{Long =&amp;gt; JLong}
&lt;p&gt;    +&lt;br/&gt;
    +import org.apache.flink.api.common.state.&lt;/p&gt;
{ValueState, ValueStateDescriptor}
&lt;p&gt;    +import org.apache.flink.api.common.state.State&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.ProcessFunction&lt;br/&gt;
    +import org.apache.flink.table.api.&lt;/p&gt;
{StreamQueryConfig, Types}
&lt;p&gt;    +&lt;br/&gt;
    +abstract class ProcessFunctionWithCleanupState&lt;span class=&quot;error&quot;&gt;&amp;#91;IN,OUT&amp;#93;&lt;/span&gt;(qConfig: StreamQueryConfig)&lt;br/&gt;
    +  extends ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;{&lt;br/&gt;
    +&lt;br/&gt;
    +  protected val minRetentionTime = qConfig.getMinIdleStateRetentionTime&lt;br/&gt;
    +  protected val maxRetentionTime = qConfig.getMaxIdleStateRetentionTime&lt;br/&gt;
    +  protected val stateCleaningEnabled = minRetentionTime &amp;gt; 1 &amp;amp;&amp;amp; maxRetentionTime &amp;gt; 1&lt;br/&gt;
    +  // interval in which clean-up timers are registered&lt;br/&gt;
    +  protected val cleanupTimerInterval = maxRetentionTime - minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +  // holds the latest registered cleanup timer&lt;br/&gt;
    +  private var cleanupTimeState: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;JLong&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def initCleanupTimeState(stateName: String) {&lt;br/&gt;
    +    if (stateCleaningEnabled) &lt;/p&gt;
{
    +      val inputCntDescriptor: ValueStateDescriptor[JLong] =
    +        new ValueStateDescriptor[JLong](stateName, Types.LONG)
    +      cleanupTimeState = getRuntimeContext.getState(inputCntDescriptor)
    +    }
&lt;p&gt;    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def registerProcessingCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    It would also be good to extend one of the test cases to cover the corner cases of the clean up logic (1 ms before min retention time, 1 ms before max retention time, 1 ms after min retention, 1 ms after max retention).&lt;/p&gt;</comment>
                            <comment id="16004905" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115739101&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115739101&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/ProcessFunctionWithCleanupState.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,99 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.table.runtime.aggregate&lt;br/&gt;
    +&lt;br/&gt;
    +import java.lang.&lt;/p&gt;
{Long =&amp;gt; JLong}
&lt;p&gt;    +&lt;br/&gt;
    +import org.apache.flink.api.common.state.&lt;/p&gt;
{ValueState, ValueStateDescriptor}
&lt;p&gt;    +import org.apache.flink.api.common.state.State&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.ProcessFunction&lt;br/&gt;
    +import org.apache.flink.table.api.&lt;/p&gt;
{StreamQueryConfig, Types}
&lt;p&gt;    +&lt;br/&gt;
    +abstract class ProcessFunctionWithCleanupState&lt;span class=&quot;error&quot;&gt;&amp;#91;IN,OUT&amp;#93;&lt;/span&gt;(qConfig: StreamQueryConfig)&lt;br/&gt;
    +  extends ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;{&lt;br/&gt;
    +&lt;br/&gt;
    +  protected val minRetentionTime = qConfig.getMinIdleStateRetentionTime&lt;br/&gt;
    +  protected val maxRetentionTime = qConfig.getMaxIdleStateRetentionTime&lt;br/&gt;
    +  protected val stateCleaningEnabled = minRetentionTime &amp;gt; 1 &amp;amp;&amp;amp; maxRetentionTime &amp;gt; 1&lt;br/&gt;
    +  // interval in which clean-up timers are registered&lt;br/&gt;
    +  protected val cleanupTimerInterval = maxRetentionTime - minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +  // holds the latest registered cleanup timer&lt;br/&gt;
    +  private var cleanupTimeState: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;JLong&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def initCleanupTimeState(stateName: String) {&lt;br/&gt;
    +    if (stateCleaningEnabled) &lt;/p&gt;
{
    +      val inputCntDescriptor: ValueStateDescriptor[JLong] =
    +        new ValueStateDescriptor[JLong](stateName, Types.LONG)
    +      cleanupTimeState = getRuntimeContext.getState(inputCntDescriptor)
    +    }
&lt;p&gt;    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def registerProcessingCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) &lt;/p&gt;
{
    +        // we need to register a new timer
    +        val cleanupTime = earliestCleanup + cleanupTimerInterval
    +        // register timer and remember clean-up time
    +        ctx.timerService().registerProcessingTimeTimer(cleanupTime)
    +        cleanupTimeState.update(cleanupTime)
    +      }
&lt;p&gt;    +    }&lt;br/&gt;
    +  }&lt;br/&gt;
    +  protected def registerEventCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) &lt;/p&gt;
{
    +        // we need to register a new timer
    +        val cleanupTime = earliestCleanup + cleanupTimerInterval
    +        // register timer and remember clean-up time
    +        ctx.timerService().registerEventTimeTimer(cleanupTime)
    +        cleanupTimeState.update(cleanupTime)
    +      }
&lt;p&gt;    +    }&lt;br/&gt;
    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def cleanupStateOnTimer(timestamp: Long, states: State*): Boolean = {&lt;br/&gt;
    +    var result: Boolean = false&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +      val cleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +      if (null != cleanupTime &amp;amp;&amp;amp; timestamp == cleanupTime) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    We need to extend the condition to &lt;br/&gt;
    ```&lt;br/&gt;
    (null != cleanupTime &amp;amp;&amp;amp; timestamp == cleanupTime &amp;amp;&amp;amp; ctx.timeDomain == TimeDomain.PROCESSING_TIME)&lt;br/&gt;
    ```&lt;br/&gt;
    to ensure that this is actually a processing time timer. &lt;br/&gt;
    Otherwise, event-time operators might clean the space if we process records with timestamps which are a bit in the future.&lt;/p&gt;</comment>
                            <comment id="16004906" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115776739&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115776739&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/ProcessFunctionWithCleanupState.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,99 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.table.runtime.aggregate&lt;br/&gt;
    +&lt;br/&gt;
    +import java.lang.&lt;/p&gt;
{Long =&amp;gt; JLong}
&lt;p&gt;    +&lt;br/&gt;
    +import org.apache.flink.api.common.state.&lt;/p&gt;
{ValueState, ValueStateDescriptor}
&lt;p&gt;    +import org.apache.flink.api.common.state.State&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.ProcessFunction&lt;br/&gt;
    +import org.apache.flink.table.api.&lt;/p&gt;
{StreamQueryConfig, Types}
&lt;p&gt;    +&lt;br/&gt;
    +abstract class ProcessFunctionWithCleanupState&lt;span class=&quot;error&quot;&gt;&amp;#91;IN,OUT&amp;#93;&lt;/span&gt;(qConfig: StreamQueryConfig)&lt;br/&gt;
    +  extends ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;{&lt;br/&gt;
    +&lt;br/&gt;
    +  protected val minRetentionTime = qConfig.getMinIdleStateRetentionTime&lt;br/&gt;
    +  protected val maxRetentionTime = qConfig.getMaxIdleStateRetentionTime&lt;br/&gt;
    +  protected val stateCleaningEnabled = minRetentionTime &amp;gt; 1 &amp;amp;&amp;amp; maxRetentionTime &amp;gt; 1&lt;br/&gt;
    +  // interval in which clean-up timers are registered&lt;br/&gt;
    +  protected val cleanupTimerInterval = maxRetentionTime - minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +  // holds the latest registered cleanup timer&lt;br/&gt;
    +  private var cleanupTimeState: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;JLong&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def initCleanupTimeState(stateName: String) {&lt;br/&gt;
    +    if (stateCleaningEnabled) &lt;/p&gt;
{
    +      val inputCntDescriptor: ValueStateDescriptor[JLong] =
    +        new ValueStateDescriptor[JLong](stateName, Types.LONG)
    +      cleanupTimeState = getRuntimeContext.getState(inputCntDescriptor)
    +    }
&lt;p&gt;    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def registerProcessingCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) {&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    This condition is wrong and would lead to state being discarded before the min retention time. It should be `(lastCleanupTime == null || earliestCleanup &amp;gt; lastCleanupTime)`. &lt;/p&gt;

&lt;p&gt;    With this condition, the timer logic works as follows:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;If the earliest time at which the state may be cleaned (`earliestCleanup`) is later than the last registered timer (`lastCleanupTime`), we need to register a new (later) timer.&lt;/li&gt;
	&lt;li&gt;The new timer is registered for current time + max retention interval, such that all records that arrive from now on until `currentTime + cleanupTimerInterval` can reuse this timer.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Please double check the logic @sunjincheng121.&lt;/p&gt;</comment>
                            <comment id="16004907" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115750977&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115750977&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala &amp;#8212;&lt;br/&gt;
    @@ -239,6 +248,7 @@ class DataStreamOverAggregate(&lt;br/&gt;
       }&lt;/p&gt;

&lt;p&gt;       def createBoundedAndCurrentRowOverWindow(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Also we should check for processing time over range windows that `minIdleStateRetentionTime` &amp;gt; preceding interval. Otherwise, we cannot compute this correctly.&lt;/p&gt;</comment>
                            <comment id="16004908" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115735538&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115735538&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/GroupAggProcessFunction.scala &amp;#8212;&lt;br/&gt;
    @@ -54,6 +55,7 @@ class GroupAggProcessFunction(&lt;br/&gt;
       private var state: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;Row&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
       // counts the number of added and retracted input records&lt;br/&gt;
       private var cntState: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;JLong&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
    +  // holds the latest registered cleanup timer&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    remove comment&lt;/p&gt;</comment>
                            <comment id="16004909" author="githubbot" created="Wed, 10 May 2017 15:55:33 +0000"  >&lt;p&gt;Github user fhueske commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115778815&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115778815&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/harness/OverWindowHarnessTest.scala &amp;#8212;&lt;br/&gt;
    @@ -265,7 +123,7 @@ class OverWindowHarnessTest extends HarnessTestBase{&lt;br/&gt;
             Row.of(2: JInt, 0L: JLong, 0: JInt, &quot;bbb&quot;, 30L: JLong, 20L: JLong, 30L: JLong), true), 1))&lt;br/&gt;
         expectedOutput.add(new StreamRecord(&lt;br/&gt;
           CRow(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Row.of(1: JInt, 11L: JLong, 1: JInt, &quot;aaa&quot;, 7L: JLong, 6L: JLong, 7L: JLong), true), 2))&lt;br/&gt;
    +        Row.of(1: JInt, 11L: JLong, 1: JInt, &quot;aaa&quot;, 7L: JLong, 7L: JLong, 7L: JLong), true), 2))
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;End diff &amp;#8211;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    The state for this record may not have been deleted before. The last input for that key is on time `1100` and the min retention time is `2000ms`, so the state should be kept at least until `3100` but was already discarded at `3001` (this is the bug that I pointed out earlier).&lt;/p&gt;</comment>
                            <comment id="16005751" author="githubbot" created="Thu, 11 May 2017 01:15:15 +0000"  >&lt;p&gt;Github user sunjincheng121 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115888057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115888057&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/StreamTableEnvironment.scala &amp;#8212;&lt;br/&gt;
    @@ -81,6 +81,8 @@ abstract class StreamTableEnvironment(&lt;br/&gt;
       // the naming pattern for internally registered tables.&lt;br/&gt;
       private val internalNamePattern = &quot;^&lt;em&gt;DataStreamTable&lt;/em&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;0-9&amp;#93;&lt;/span&gt;+$&quot;.r&lt;/p&gt;

&lt;p&gt;    +  def qConf: StreamQueryConfig = new StreamQueryConfig&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    Yes,I want change all `qConfig` and `qConf` to `queryConfig`.&lt;/p&gt;</comment>
                            <comment id="16005913" author="githubbot" created="Thu, 11 May 2017 05:37:09 +0000"  >&lt;p&gt;Github user sunjincheng121 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115907975&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115907975&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/ProcessFunctionWithCleanupState.scala &amp;#8212;&lt;br/&gt;
    @@ -0,0 +1,99 @@&lt;br/&gt;
    +/*&lt;br/&gt;
    + * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
    + * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
    + * distributed with this work for additional information&lt;br/&gt;
    + * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
    + * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
    + * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
    + * with the License.  You may obtain a copy of the License at&lt;br/&gt;
    + *&lt;br/&gt;
    + *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
    + *&lt;br/&gt;
    + * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
    + * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
    + * See the License for the specific language governing permissions and&lt;br/&gt;
    + * limitations under the License.&lt;br/&gt;
    + */&lt;br/&gt;
    +package org.apache.flink.table.runtime.aggregate&lt;br/&gt;
    +&lt;br/&gt;
    +import java.lang.&lt;/p&gt;
{Long =&amp;gt; JLong}
&lt;p&gt;    +&lt;br/&gt;
    +import org.apache.flink.api.common.state.&lt;/p&gt;
{ValueState, ValueStateDescriptor}
&lt;p&gt;    +import org.apache.flink.api.common.state.State&lt;br/&gt;
    +import org.apache.flink.streaming.api.functions.ProcessFunction&lt;br/&gt;
    +import org.apache.flink.table.api.&lt;/p&gt;
{StreamQueryConfig, Types}
&lt;p&gt;    +&lt;br/&gt;
    +abstract class ProcessFunctionWithCleanupState&lt;span class=&quot;error&quot;&gt;&amp;#91;IN,OUT&amp;#93;&lt;/span&gt;(qConfig: StreamQueryConfig)&lt;br/&gt;
    +  extends ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;{&lt;br/&gt;
    +&lt;br/&gt;
    +  protected val minRetentionTime = qConfig.getMinIdleStateRetentionTime&lt;br/&gt;
    +  protected val maxRetentionTime = qConfig.getMaxIdleStateRetentionTime&lt;br/&gt;
    +  protected val stateCleaningEnabled = minRetentionTime &amp;gt; 1 &amp;amp;&amp;amp; maxRetentionTime &amp;gt; 1&lt;br/&gt;
    +  // interval in which clean-up timers are registered&lt;br/&gt;
    +  protected val cleanupTimerInterval = maxRetentionTime - minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +  // holds the latest registered cleanup timer&lt;br/&gt;
    +  private var cleanupTimeState: ValueState&lt;span class=&quot;error&quot;&gt;&amp;#91;JLong&amp;#93;&lt;/span&gt; = _&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def initCleanupTimeState(stateName: String) {&lt;br/&gt;
    +    if (stateCleaningEnabled) &lt;/p&gt;
{
    +      val inputCntDescriptor: ValueStateDescriptor[JLong] =
    +        new ValueStateDescriptor[JLong](stateName, Types.LONG)
    +      cleanupTimeState = getRuntimeContext.getState(inputCntDescriptor)
    +    }
&lt;p&gt;    +  }&lt;br/&gt;
    +&lt;br/&gt;
    +  protected def registerProcessingCleanupTimer(&lt;br/&gt;
    +    ctx: ProcessFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;IN, OUT&amp;#93;&lt;/span&gt;#Context,&lt;br/&gt;
    +    currentTime: Long): Unit = {&lt;br/&gt;
    +    if (stateCleaningEnabled) {&lt;br/&gt;
    +&lt;br/&gt;
    +      val earliestCleanup = currentTime + minRetentionTime&lt;br/&gt;
    +&lt;br/&gt;
    +      // last registered timer&lt;br/&gt;
    +      val lastCleanupTime = cleanupTimeState.value()&lt;br/&gt;
    +&lt;br/&gt;
    +      if (lastCleanupTime == null || earliestCleanup &amp;gt;= lastCleanupTime + cleanupTimerInterval) &lt;/p&gt;
{
    +        // we need to register a new timer
    +        val cleanupTime = earliestCleanup + cleanupTimerInterval
    +        // register timer and remember clean-up time
    +        ctx.timerService().registerProcessingTimeTimer(cleanupTime)
    +        cleanupTimeState.update(cleanupTime)
    +      }
&lt;p&gt;    +    }&lt;br/&gt;
    +  }&lt;br/&gt;
    +  protected def registerEventCleanupTimer(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    The reason of I add this method is In A `row-time` OVER (TimeDomain.EVENT_TIME), we always get `0` when we call `ctx.timerService.currentProcessingTime`.&lt;/p&gt;</comment>
                            <comment id="16005922" author="githubbot" created="Thu, 11 May 2017 05:46:47 +0000"  >&lt;p&gt;Github user sunjincheng121 commented on a diff in the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863#discussion_r115908788&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863#discussion_r115908788&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &amp;#8212; Diff: flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala &amp;#8212;&lt;br/&gt;
    @@ -239,6 +248,7 @@ class DataStreamOverAggregate(&lt;br/&gt;
       }&lt;/p&gt;

&lt;p&gt;       def createBoundedAndCurrentRowOverWindow(&lt;br/&gt;
    &amp;#8212; End diff &amp;#8211;&lt;/p&gt;

&lt;p&gt;    I do not think we need add this check. Because both `row-base` and `time-base` will be able to meet the incorrect result due to state cleanup. an importation thing we need to do is let use know the function of the `cleanup config`. &lt;/p&gt;</comment>
                            <comment id="16005933" author="githubbot" created="Thu, 11 May 2017 05:52:39 +0000"  >&lt;p&gt;Github user sunjincheng121 commented on the issue:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hi @fhueske thanks a lot for your reviewing. I had update the PR. with following changes:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Uniform hump name, change all `qConfig` and `qConf` to `queryConfig`.&lt;/li&gt;
	&lt;li&gt;Add warn log into `DataStreamOverAggregate`.&lt;/li&gt;
	&lt;li&gt;Fix cleanup logic&lt;/li&gt;
	&lt;li&gt;Extend test cases that cover the corner cases of the clean up logic.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    But there are two things I have not do, that is:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;`check for processing time over range windows that minIdleStateRetentionTime &amp;gt; preceding interval.`&lt;br/&gt;
       I do not think we need add this check. Because both row-base and time-base will be able to meet the incorrect result due to state cleanup. an importation thing we need to do is let use know the function of the cleanup config.&lt;/li&gt;
	&lt;li&gt;`remove the registerEventCleanupTimer method`&lt;br/&gt;
    The reason of I add this method is In A row-time OVER (TimeDomain.EVENT_TIME), we always get 0 when we call ctx.timerService.currentProcessingTime.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    What do you think?&lt;br/&gt;
    Thanks,&lt;br/&gt;
    SunJincheng&lt;/p&gt;</comment>
                            <comment id="16007686" author="githubbot" created="Fri, 12 May 2017 06:12:15 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/flink/pull/3863&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/flink/pull/3863&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16007712" author="fhueske" created="Fri, 12 May 2017 06:52:23 +0000"  >&lt;p&gt;Implemented for 1.3 with f0868c5d77d1ace9989a7ee56b24368d63bff138&lt;br/&gt;
Implemented for 1.4 with 2480887180d881c30d228a73c746f94abbcbbb64&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="13068394">FLINK-6428</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 27 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3en93:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>