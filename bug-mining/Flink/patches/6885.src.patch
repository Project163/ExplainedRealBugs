diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecNodeBase.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecNodeBase.java
index f765bcbd720..3669e7d482d 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecNodeBase.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecNodeBase.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.table.planner.plan.nodes.exec;
 
+import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.api.dag.Transformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.ReadableConfig;
@@ -276,4 +277,10 @@ public abstract class ExecNodeBase<T> implements ExecNode<T> {
     public void resetTransformation() {
         this.transformation = null;
     }
+
+    @VisibleForTesting
+    @JsonIgnore
+    public Transformation<T> getTransformation() {
+        return this.transformation;
+    }
 }
diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/batch/BatchExecMultipleInput.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/batch/BatchExecMultipleInput.java
index 8ab69e34d18..93b5bf84937 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/batch/BatchExecMultipleInput.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/batch/BatchExecMultipleInput.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.table.planner.plan.nodes.exec.batch;
 
+import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.api.dag.Transformation;
 import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.streaming.api.operators.ChainingStrategy;
@@ -32,6 +33,7 @@ import org.apache.flink.table.planner.plan.nodes.exec.ExecNodeContext;
 import org.apache.flink.table.planner.plan.nodes.exec.InputProperty;
 import org.apache.flink.table.planner.plan.nodes.exec.SingleTransformationTranslator;
 import org.apache.flink.table.planner.plan.nodes.exec.utils.ExecNodeUtil;
+import org.apache.flink.table.planner.plan.nodes.exec.visitor.AbstractExecNodeExactlyOnceVisitor;
 import org.apache.flink.table.runtime.operators.multipleinput.BatchMultipleInputStreamOperatorFactory;
 import org.apache.flink.table.runtime.operators.multipleinput.TableOperatorWrapperGenerator;
 import org.apache.flink.table.runtime.operators.multipleinput.input.InputSpec;
@@ -149,7 +151,29 @@ public class BatchExecMultipleInput extends ExecNodeBase<RowData>
         return multipleInputTransform;
     }
 
+    @Override
+    public void resetTransformation() {
+        super.resetTransformation();
+        // For BatchExecMultipleInput, we also need to reset transformation for
+        // rootNode in BatchExecMultipleInput.
+        AbstractExecNodeExactlyOnceVisitor visitor =
+                new AbstractExecNodeExactlyOnceVisitor() {
+
+                    @Override
+                    protected void visitNode(ExecNode<?> node) {
+                        ((ExecNodeBase<?>) node).resetTransformation();
+                        visitInputs(node);
+                    }
+                };
+        rootNode.accept(visitor);
+    }
+
     public List<ExecEdge> getOriginalEdges() {
         return originalEdges;
     }
+
+    @VisibleForTesting
+    public ExecNode<?> getRootNode() {
+        return rootNode;
+    }
 }
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/processor/MultipleInputNodeCreationProcessorTest.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/processor/MultipleInputNodeCreationProcessorTest.java
index 08679fd4a07..213982425ce 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/processor/MultipleInputNodeCreationProcessorTest.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/processor/MultipleInputNodeCreationProcessorTest.java
@@ -22,27 +22,22 @@ import org.apache.flink.api.common.eventtime.WatermarkStrategy;
 import org.apache.flink.api.connector.source.Boundedness;
 import org.apache.flink.api.connector.source.mocks.MockSource;
 import org.apache.flink.streaming.api.datastream.DataStreamSource;
-import org.apache.flink.table.api.Table;
 import org.apache.flink.table.api.TableConfig;
 import org.apache.flink.table.api.TableEnvironment;
 import org.apache.flink.table.expressions.ApiExpressionUtils;
 import org.apache.flink.table.expressions.Expression;
 import org.apache.flink.table.planner.plan.nodes.exec.ExecNode;
 import org.apache.flink.table.planner.plan.nodes.exec.ExecNodeGraph;
-import org.apache.flink.table.planner.plan.nodes.exec.ExecNodeGraphGenerator;
-import org.apache.flink.table.planner.plan.nodes.physical.FlinkPhysicalRel;
 import org.apache.flink.table.planner.utils.BatchTableTestUtil;
 import org.apache.flink.table.planner.utils.StreamTableTestUtil;
 import org.apache.flink.table.planner.utils.TableTestBase;
 import org.apache.flink.table.planner.utils.TableTestUtil;
 import org.apache.flink.util.FileUtils;
 
-import org.apache.calcite.rel.RelNode;
 import org.junit.Test;
 
 import java.io.File;
 import java.io.IOException;
-import java.util.Collections;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -101,12 +96,7 @@ public class MultipleInputNodeCreationProcessorTest extends TableTestBase {
 
     private void assertChainableSource(String name, TableTestUtil util, boolean expected) {
         String sql = "SELECT * FROM " + name;
-        Table table = util.tableEnv().sqlQuery(sql);
-        RelNode relNode = TableTestUtil.toRelNode(table);
-        FlinkPhysicalRel optimizedRel = (FlinkPhysicalRel) util.getPlanner().optimize(relNode);
-        ExecNodeGraphGenerator generator = new ExecNodeGraphGenerator();
-        ExecNodeGraph execGraph =
-                generator.generate(Collections.singletonList(optimizedRel), false);
+        ExecNodeGraph execGraph = TableTestUtil.toExecNodeGraph(util.tableEnv(), sql);
         ExecNode<?> execNode = execGraph.getRootNodes().get(0);
         while (!execNode.getInputEdges().isEmpty()) {
             execNode = execNode.getInputEdges().get(0).getSource();
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/processor/ResetTransformationProcessorTest.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/processor/ResetTransformationProcessorTest.java
new file mode 100644
index 00000000000..0a5a00d3bf9
--- /dev/null
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/processor/ResetTransformationProcessorTest.java
@@ -0,0 +1,143 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.planner.plan.nodes.exec.processor;
+
+import org.apache.flink.table.api.TableConfig;
+import org.apache.flink.table.api.TableEnvironment;
+import org.apache.flink.table.planner.plan.nodes.exec.ExecNode;
+import org.apache.flink.table.planner.plan.nodes.exec.ExecNodeBase;
+import org.apache.flink.table.planner.plan.nodes.exec.ExecNodeGraph;
+import org.apache.flink.table.planner.plan.nodes.exec.batch.BatchExecMultipleInput;
+import org.apache.flink.table.planner.plan.nodes.exec.visitor.AbstractExecNodeExactlyOnceVisitor;
+import org.apache.flink.table.planner.utils.BatchTableTestUtil;
+import org.apache.flink.table.planner.utils.TableTestBase;
+import org.apache.flink.table.planner.utils.TableTestUtil;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+
+/** Tests for {@link ResetTransformationProcessor}. */
+public class ResetTransformationProcessorTest extends TableTestBase {
+
+    private BatchTableTestUtil util;
+    private TableEnvironment tEnv;
+
+    @Before
+    public void begin() {
+        util = batchTestUtil(TableConfig.getDefault());
+        tEnv = util.tableEnv();
+
+        tEnv.executeSql(
+                "CREATE TABLE Source1 (\n"
+                        + "  a BIGINT,\n"
+                        + "  b BIGINT,\n"
+                        + "  c VARCHAR,\n"
+                        + "  d BIGINT\n"
+                        + ") WITH (\n"
+                        + " 'connector' = 'values',\n"
+                        + " 'bounded' = 'true'\n"
+                        + ")");
+
+        tEnv.executeSql(
+                "CREATE TABLE Source2 (\n"
+                        + "  a BIGINT,\n"
+                        + "  b BIGINT,\n"
+                        + "  c VARCHAR,\n"
+                        + "  d BIGINT\n"
+                        + ") WITH (\n"
+                        + " 'connector' = 'values',\n"
+                        + " 'bounded' = 'true'\n"
+                        + ")");
+    }
+
+    @Test
+    public void testResetTransformation() {
+        String query = "SELECT * FROM Source1 WHERE a > 100";
+        ExecNodeGraph execNodeGraph = TableTestUtil.toExecNodeGraph(tEnv, query);
+        execNodeGraph.getRootNodes().forEach(node -> node.translateToPlan(util.getPlanner()));
+        assertAllTransformationsIsNotNull(execNodeGraph);
+
+        ResetTransformationProcessor resetTransformationProcessor =
+                new ResetTransformationProcessor();
+        resetTransformationProcessor.process(
+                execNodeGraph, new ProcessorContext(util.getPlanner()));
+        assertAllTransformationsIsNull(execNodeGraph);
+    }
+
+    @Test
+    public void testResetTransformationWithExecMultipleInputInExecGraph() {
+        String query =
+                "SELECT Source1.a FROM Source1, Source2 "
+                        + "WHERE Source1.a = Source2.a AND Source2.a = (SELECT Source2.a FROM Source2 WHERE b > 100)";
+        ExecNodeGraph execNodeGraph = TableTestUtil.toExecNodeGraph(tEnv, query);
+
+        MultipleInputNodeCreationProcessor multipleInputNodeCreationProcessor =
+                new MultipleInputNodeCreationProcessor(false);
+        multipleInputNodeCreationProcessor.process(
+                execNodeGraph, new ProcessorContext(util.getPlanner()));
+        execNodeGraph.getRootNodes().forEach(node -> node.translateToPlan(util.getPlanner()));
+        assertAllTransformationsIsNotNull(execNodeGraph);
+
+        // If execNodeGraph include batchExecMultipleInput node. The ResetTransformationProcessor
+        // need to both set the transformation in each execNode and the transformation in
+        // batchExecMultipleInput.rootNode to null.
+        ResetTransformationProcessor resetTransformationProcessor =
+                new ResetTransformationProcessor();
+        resetTransformationProcessor.process(
+                execNodeGraph, new ProcessorContext(util.getPlanner()));
+        assertAllTransformationsIsNull(execNodeGraph);
+    }
+
+    private void assertAllTransformationsIsNotNull(ExecNodeGraph execNodeGraph) {
+        AbstractExecNodeExactlyOnceVisitor visitor =
+                new AbstractExecNodeExactlyOnceVisitor() {
+                    @Override
+                    protected void visitNode(ExecNode<?> node) {
+                        assertNotNull(((ExecNodeBase<?>) node).getTransformation());
+                        visitInputs(node);
+                        if (node instanceof BatchExecMultipleInput) {
+                            ExecNode<?> rootNode = ((BatchExecMultipleInput) node).getRootNode();
+                            assertNotNull(((ExecNodeBase<?>) node).getTransformation());
+                            visitInputs(rootNode);
+                        }
+                    }
+                };
+        execNodeGraph.getRootNodes().forEach(r -> r.accept(visitor));
+    }
+
+    private void assertAllTransformationsIsNull(ExecNodeGraph execNodeGraph) {
+        AbstractExecNodeExactlyOnceVisitor visitor =
+                new AbstractExecNodeExactlyOnceVisitor() {
+                    @Override
+                    protected void visitNode(ExecNode<?> node) {
+                        assertNull(((ExecNodeBase<?>) node).getTransformation());
+                        visitInputs(node);
+                        if (node instanceof BatchExecMultipleInput) {
+                            ExecNode<?> rootNode = ((BatchExecMultipleInput) node).getRootNode();
+                            assertNull(((ExecNodeBase<?>) node).getTransformation());
+                            visitInputs(rootNode);
+                        }
+                    }
+                };
+        execNodeGraph.getRootNodes().forEach(r -> r.accept(visitor));
+    }
+}
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/utils/TableTestBase.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/utils/TableTestBase.scala
index 30c6dd5b8f5..bca3fd2c37c 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/utils/TableTestBase.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/utils/TableTestBase.scala
@@ -47,8 +47,9 @@ import org.apache.flink.table.planner.delegation.PlannerBase
 import org.apache.flink.table.planner.functions.sql.FlinkSqlOperatorTable
 import org.apache.flink.table.planner.operations.{InternalDataStreamQueryOperation, PlannerQueryOperation, RichTableSourceQueryOperation}
 import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner
-import org.apache.flink.table.planner.plan.nodes.exec.ExecNodeContext
+import org.apache.flink.table.planner.plan.nodes.exec.{ExecNodeContext, ExecNodeGraph, ExecNodeGraphGenerator}
 import org.apache.flink.table.planner.plan.nodes.exec.utils.ExecNodePlanDumper
+import org.apache.flink.table.planner.plan.nodes.physical.FlinkPhysicalRel
 import org.apache.flink.table.planner.plan.optimize.program._
 import org.apache.flink.table.planner.plan.stats.FlinkStatistic
 import org.apache.flink.table.planner.plan.utils.FlinkRelOptUtil
@@ -83,6 +84,7 @@ import java.io.{File, IOException}
 import java.net.URL
 import java.nio.file.{Files, Paths}
 import java.time.Duration
+import java.util.Collections
 
 /** Test base for testing Table API / SQL plans. */
 abstract class TableTestBase {
@@ -1655,6 +1657,15 @@ object TableTestUtil {
     planner.translateToRel(modifyOperation)
   }
 
+  /** Convert a sql query to a ExecNodeGraph. */
+  def toExecNodeGraph(tEnv: TableEnvironment, sqlQuery: String): ExecNodeGraph = {
+    val planner = tEnv.asInstanceOf[TableEnvironmentImpl].getPlanner.asInstanceOf[PlannerBase]
+    val optimizedRel =
+      planner.optimize(toRelNode(tEnv.sqlQuery(sqlQuery))).asInstanceOf[FlinkPhysicalRel]
+    val generator = new ExecNodeGraphGenerator
+    generator.generate(Collections.singletonList(optimizedRel), false)
+  }
+
   def createTemporaryView[T](
       tEnv: TableEnvironment,
       name: String,
