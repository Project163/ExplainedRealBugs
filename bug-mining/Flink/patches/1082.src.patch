diff --git a/flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java b/flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java
index 80dbcfef83e..192843107ef 100644
--- a/flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java
+++ b/flink-streaming-connectors/flink-connector-cassandra/src/main/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSink.java
@@ -31,7 +31,6 @@ import org.apache.flink.api.java.tuple.Tuple;
 import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;
 import org.apache.flink.streaming.runtime.operators.CheckpointCommitter;
 import org.apache.flink.streaming.runtime.operators.GenericWriteAheadSink;
-import org.apache.flink.types.IntValue;
 
 import java.util.UUID;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -97,7 +96,7 @@ public class CassandraTupleWriteAheadSink<IN extends Tuple> extends GenericWrite
 
 	@Override
 	protected boolean sendValues(Iterable<IN> values, long timestamp) throws Exception {
-		final IntValue updatesCount = new IntValue(0);
+		final AtomicInteger updatesCount = new AtomicInteger(0);
 		final AtomicInteger updatesConfirmed = new AtomicInteger(0);
 
 		final AtomicReference<Throwable> exception = new AtomicReference<>();
@@ -106,8 +105,8 @@ public class CassandraTupleWriteAheadSink<IN extends Tuple> extends GenericWrite
 			@Override
 			public void onSuccess(ResultSet resultSet) {
 				updatesConfirmed.incrementAndGet();
-				if (updatesCount.getValue() > 0) { // only set if all updates have been sent
-					if (updatesCount.getValue() == updatesConfirmed.get()) {
+				if (updatesCount.get() > 0) { // only set if all updates have been sent
+					if (updatesCount.get() == updatesConfirmed.get()) {
 						synchronized (updatesConfirmed) {
 							updatesConfirmed.notifyAll();
 						}
@@ -142,18 +141,19 @@ public class CassandraTupleWriteAheadSink<IN extends Tuple> extends GenericWrite
 				Futures.addCallback(result, callback);
 			}
 		}
-		updatesCount.setValue(updatesSent);
+		updatesCount.set(updatesSent);
 
 		synchronized (updatesConfirmed) {
-			while (updatesSent != updatesConfirmed.get()) {
-				if (exception.get() != null) { // verify that no query failed until now
-					LOG.warn("Sending a value failed.", exception.get());
-					break;
-				}
+			while (exception.get() == null && updatesSent != updatesConfirmed.get()) {
 				updatesConfirmed.wait();
 			}
 		}
-		boolean success = updatesSent == updatesConfirmed.get();
-		return success;
+
+		if (exception.get() != null) {
+			LOG.warn("Sending a value failed.", exception.get());
+			return false;
+		} else {
+			return true;
+		}
 	}
 }
diff --git a/flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraConnectorUnitTest.java b/flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSinkTest.java
similarity index 59%
rename from flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraConnectorUnitTest.java
rename to flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSinkTest.java
index e7d9df992e8..847d1a049e5 100644
--- a/flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraConnectorUnitTest.java
+++ b/flink-streaming-connectors/flink-connector-cassandra/src/test/java/org/apache/flink/streaming/connectors/cassandra/CassandraTupleWriteAheadSinkTest.java
@@ -25,39 +25,33 @@ import com.datastax.driver.core.Session;
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.java.tuple.Tuple0;
 import org.apache.flink.api.java.typeutils.TupleTypeInfo;
-import org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter;
 import org.apache.flink.streaming.runtime.operators.CheckpointCommitter;
 import org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness;
-import org.apache.flink.util.IterableIterator;
-import org.junit.Assert;
 import org.junit.Test;
-import org.junit.runner.RunWith;
 import org.mockito.Matchers;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
-import org.powermock.core.classloader.annotations.PowerMockIgnore;
-import org.powermock.core.classloader.annotations.PrepareForTest;
-import org.powermock.modules.junit4.PowerMockRunner;
 
-import java.util.Iterator;
+import java.util.Collections;
 import java.util.concurrent.Executor;
 import java.util.concurrent.atomic.AtomicReference;
 
+import static org.junit.Assert.assertFalse;
 import static org.mockito.Matchers.any;
 import static org.mockito.Matchers.anyString;
 import static org.powermock.api.mockito.PowerMockito.doAnswer;
 import static org.powermock.api.mockito.PowerMockito.mock;
 import static org.powermock.api.mockito.PowerMockito.when;
 
-@RunWith(PowerMockRunner.class)
-@PrepareForTest({ResultPartitionWriter.class, CassandraTupleWriteAheadSink.class})
-@PowerMockIgnore({"javax.management.*", "com.sun.jndi.*"})
-public class CassandraConnectorUnitTest {
-	@Test
+public class CassandraTupleWriteAheadSinkTest {
+
+	@Test(timeout=20000)
 	public void testAckLoopExitOnException() throws Exception {
-		final AtomicReference<Runnable> callback = new AtomicReference<>();
+		final AtomicReference<Runnable> runnableFuture = new AtomicReference<>();
 
 		final ClusterBuilder clusterBuilder = new ClusterBuilder() {
+			private static final long serialVersionUID = 4624400760492936756L;
+
 			@Override
 			protected Cluster buildCluster(Cluster.Builder builder) {
 				try {
@@ -73,7 +67,10 @@ public class CassandraConnectorUnitTest {
 					doAnswer(new Answer<Void>() {
 						@Override
 						public Void answer(InvocationOnMock invocationOnMock) throws Throwable {
-							callback.set((((Runnable) invocationOnMock.getArguments()[0])));
+							synchronized (runnableFuture) {
+								runnableFuture.set((((Runnable) invocationOnMock.getArguments()[0])));
+								runnableFuture.notifyAll();
+							}
 							return null;
 						}
 					}).when(future).addListener(any(Runnable.class), any(Executor.class));
@@ -91,68 +88,40 @@ public class CassandraConnectorUnitTest {
 			}
 		};
 
-		final IterableIterator<Tuple0> iter = new IterableIterator<Tuple0>() {
-			private boolean exhausted = false;
-
-			@Override
-			public boolean hasNext() {
-				return !exhausted;
-			}
-
-			@Override
-			public Tuple0 next() {
-				exhausted = true;
-				return new Tuple0();
-			}
-
-			@Override
-			public void remove() {
-			}
-
+		// Our asynchronous executor thread
+		new Thread(new Runnable() {
 			@Override
-			public Iterator<Tuple0> iterator() {
-				return this;
-			}
-		};
-
-		final AtomicReference<Boolean> exceptionCaught = new AtomicReference<>();
-
-		Thread t = new Thread() {
 			public void run() {
-				try {
-					CheckpointCommitter cc = mock(CheckpointCommitter.class);
-					final CassandraTupleWriteAheadSink<Tuple0> sink = new CassandraTupleWriteAheadSink<>(
-						"abc",
-						TupleTypeInfo.of(Tuple0.class).createSerializer(new ExecutionConfig()),
-						clusterBuilder,
-						cc
-					);
-
-					OneInputStreamOperatorTestHarness<Tuple0, Tuple0> harness = new OneInputStreamOperatorTestHarness(sink);
-					harness.getEnvironment().getTaskConfiguration().setBoolean("checkpointing", true);
-
-					harness.setup();
-					sink.open();
-					boolean result = sink.sendValues(iter, 0L);
-					sink.close();
-					exceptionCaught.set(result == false);
-				} catch (Exception e) {
-					throw new RuntimeException(e);
+				synchronized (runnableFuture) {
+					while (runnableFuture.get() == null) {
+						try {
+							runnableFuture.wait();
+						} catch (InterruptedException e) {
+							// ignore interrupts
+						}
+					}
 				}
+				runnableFuture.get().run();
 			}
-		};
-		t.start();
+		}).start();
+
+		CheckpointCommitter cc = mock(CheckpointCommitter.class);
+		final CassandraTupleWriteAheadSink<Tuple0> sink = new CassandraTupleWriteAheadSink<>(
+			"abc",
+			TupleTypeInfo.of(Tuple0.class).createSerializer(new ExecutionConfig()),
+			clusterBuilder,
+			cc
+		);
 
-		int count = 0;
-		while (t.getState() != Thread.State.WAITING && count < 100) { // 10 second timeout 10 * 10 * 100ms
-			Thread.sleep(100);
-			count++;
-		}
+		OneInputStreamOperatorTestHarness<Tuple0, Tuple0> harness = new OneInputStreamOperatorTestHarness(sink);
+		harness.getEnvironment().getTaskConfiguration().setBoolean("checkpointing", true);
 
-		callback.get().run();
+		harness.setup();
+		sink.open();
 
-		t.join();
+		// we should leave the loop and return false since we've seen an exception
+		assertFalse(sink.sendValues(Collections.singleton(new Tuple0()), 0L));
 
-		Assert.assertTrue(exceptionCaught.get());
+		sink.close();
 	}
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java
index b6cc39944c5..5545717b244 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/GenericWriteAheadSink.java
@@ -190,6 +190,9 @@ public abstract class GenericWriteAheadSink<IN> extends AbstractStreamOperator<I
 	 * used since the last completed checkpoint.
 	 **/
 	public static class ExactlyOnceState implements StateHandle<Serializable> {
+
+		private static final long serialVersionUID = -3571063495273460743L;
+
 		protected TreeMap<Long, Tuple2<Long, StateHandle<DataInputView>>> pendingHandles;
 
 		public ExactlyOnceState() {
