diff --git a/flink-examples/flink-examples-streaming/pom.xml b/flink-examples/flink-examples-streaming/pom.xml
index 76325f18ea5..e225742ae62 100644
--- a/flink-examples/flink-examples-streaming/pom.xml
+++ b/flink-examples/flink-examples-streaming/pom.xml
@@ -253,7 +253,6 @@ under the License.
 								<include>org/apache/flink/streaming/examples/wordcount/WordCount$*.class</include>
 								<include>org/apache/flink/streaming/examples/wordcount/util/WordCountData.class</include>
 								<include>org/apache/flink/streaming/examples/wordcount/util/CLI.class</include>
-								<include>org/apache/flink/streaming/examples/utils/ParameterTool.class</include>
 								<include>META-INF/LICENSE</include>
 								<include>META-INF/NOTICE</include>
 							</includes>
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/async/AsyncIOExample.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/async/AsyncIOExample.java
index b8e19212df1..5f2574f11d5 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/async/AsyncIOExample.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/async/AsyncIOExample.java
@@ -20,6 +20,7 @@ package org.apache.flink.streaming.examples.async;
 import org.apache.flink.api.common.eventtime.WatermarkStrategy;
 import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.api.connector.source.util.ratelimit.RateLimiterStrategy;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.connector.datagen.source.DataGeneratorSource;
 import org.apache.flink.streaming.api.datastream.AsyncDataStream;
@@ -28,7 +29,6 @@ import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.async.AsyncFunction;
 import org.apache.flink.streaming.api.functions.async.ResultFuture;
 import org.apache.flink.streaming.api.functions.async.RichAsyncFunction;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 
 import java.util.Collections;
 import java.util.concurrent.TimeUnit;
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/gpu/MatrixVectorMul.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/gpu/MatrixVectorMul.java
index e1d8a3962dc..e0d1181d8c7 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/gpu/MatrixVectorMul.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/gpu/MatrixVectorMul.java
@@ -23,6 +23,7 @@ import org.apache.flink.api.common.externalresource.ExternalResourceInfo;
 import org.apache.flink.api.common.functions.RichMapFunction;
 import org.apache.flink.api.common.serialization.SimpleStringEncoder;
 import org.apache.flink.api.common.typeinfo.Types;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.connector.datagen.source.DataGeneratorSource;
 import org.apache.flink.connector.datagen.source.GeneratorFunction;
@@ -30,7 +31,6 @@ import org.apache.flink.connector.file.sink.FileSink;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 import org.apache.flink.util.Preconditions;
 
 import jcuda.Pointer;
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/iteration/IterateExample.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/iteration/IterateExample.java
index f89290786d2..d72933b7366 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/iteration/IterateExample.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/iteration/IterateExample.java
@@ -24,6 +24,7 @@ import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.api.connector.source.util.ratelimit.RateLimiterStrategy;
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.api.java.tuple.Tuple5;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.configuration.MemorySize;
 import org.apache.flink.connector.datagen.source.DataGeneratorSource;
 import org.apache.flink.connector.datagen.source.GeneratorFunction;
@@ -37,7 +38,6 @@ import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.ProcessFunction;
 import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 import org.apache.flink.util.Collector;
 import org.apache.flink.util.OutputTag;
 
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/join/WindowJoin.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/join/WindowJoin.java
index eb0cb543e08..ef33a58ddcb 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/join/WindowJoin.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/join/WindowJoin.java
@@ -27,13 +27,13 @@ import org.apache.flink.api.common.functions.JoinFunction;
 import org.apache.flink.api.java.functions.KeySelector;
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.api.java.tuple.Tuple3;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
 import org.apache.flink.streaming.api.windowing.time.Time;
 import org.apache.flink.streaming.examples.join.WindowJoinSampleData.GradeSource;
 import org.apache.flink.streaming.examples.join.WindowJoinSampleData.SalarySource;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 
 /**
  * Example illustrating a windowed stream join between two data streams.
@@ -63,6 +63,9 @@ public class WindowJoin {
         // obtain execution environment, run this example in "ingestion time"
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
 
+        // make parameters available in the web interface
+        env.getConfig().setGlobalJobParameters(params);
+
         // create the data sources for both grades and salaries
         DataStream<Tuple2<String, Integer>> grades =
                 GradeSource.getSource(env, rate)
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/sideoutput/SideOutputExample.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/sideoutput/SideOutputExample.java
index 3796c768570..7439a33566c 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/sideoutput/SideOutputExample.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/sideoutput/SideOutputExample.java
@@ -26,6 +26,7 @@ import org.apache.flink.api.common.eventtime.WatermarkStrategy;
 import org.apache.flink.api.common.serialization.SimpleStringEncoder;
 import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.api.java.tuple.Tuple2;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.configuration.MemorySize;
 import org.apache.flink.connector.file.sink.FileSink;
 import org.apache.flink.connector.file.src.FileSource;
@@ -39,7 +40,6 @@ import org.apache.flink.streaming.api.functions.ProcessFunction;
 import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy;
 import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
 import org.apache.flink.streaming.api.windowing.time.Time;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 import org.apache.flink.streaming.examples.wordcount.util.WordCountData;
 import org.apache.flink.util.Collector;
 import org.apache.flink.util.OutputTag;
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/socket/SocketWindowWordCount.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/socket/SocketWindowWordCount.java
index 1734154e3ba..76fb37f321f 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/socket/SocketWindowWordCount.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/socket/SocketWindowWordCount.java
@@ -20,11 +20,11 @@ package org.apache.flink.streaming.examples.socket;
 
 import org.apache.flink.api.common.functions.FlatMapFunction;
 import org.apache.flink.api.common.typeinfo.Types;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows;
 import org.apache.flink.streaming.api.windowing.time.Time;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 
 /**
  * Implements a streaming windowed version of the "WordCount" program.
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/KafkaEventsGeneratorJob.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/KafkaEventsGeneratorJob.java
index 7ac5f2dd316..776fcfd9b8c 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/KafkaEventsGeneratorJob.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/KafkaEventsGeneratorJob.java
@@ -21,6 +21,7 @@ package org.apache.flink.streaming.examples.statemachine;
 import org.apache.flink.api.common.eventtime.WatermarkStrategy;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.connector.source.util.ratelimit.RateLimiterStrategy;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.connector.datagen.source.DataGeneratorSource;
 import org.apache.flink.connector.datagen.source.GeneratorFunction;
 import org.apache.flink.connector.kafka.sink.KafkaRecordSerializationSchema;
@@ -29,7 +30,6 @@ import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.examples.statemachine.event.Event;
 import org.apache.flink.streaming.examples.statemachine.generator.EventsGeneratorFunction;
 import org.apache.flink.streaming.examples.statemachine.kafka.EventDeSerializationSchema;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 
 /**
  * Job to generate input events that are written to Kafka, for the {@link StateMachineExample} job.
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/StateMachineExample.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/StateMachineExample.java
index 448f4c600bf..1f43021a6b7 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/StateMachineExample.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/StateMachineExample.java
@@ -25,6 +25,7 @@ import org.apache.flink.api.common.state.ValueState;
 import org.apache.flink.api.common.state.ValueStateDescriptor;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.connector.source.util.ratelimit.RateLimiterStrategy;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.MemorySize;
 import org.apache.flink.connector.datagen.source.DataGeneratorSource;
@@ -44,7 +45,6 @@ import org.apache.flink.streaming.examples.statemachine.event.Alert;
 import org.apache.flink.streaming.examples.statemachine.event.Event;
 import org.apache.flink.streaming.examples.statemachine.generator.EventsGeneratorFunction;
 import org.apache.flink.streaming.examples.statemachine.kafka.EventDeSerializationSchema;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 import org.apache.flink.util.Collector;
 
 import java.time.Duration;
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/utils/ParameterTool.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/utils/ParameterTool.java
deleted file mode 100644
index 99f85f5e2a0..00000000000
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/utils/ParameterTool.java
+++ /dev/null
@@ -1,227 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.streaming.examples.utils;
-
-import org.apache.flink.api.common.ExecutionConfig;
-import org.apache.flink.api.java.Utils;
-import org.apache.flink.util.CollectionUtil;
-import org.apache.flink.util.Preconditions;
-
-import org.apache.commons.lang3.math.NumberUtils;
-
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Objects;
-import java.util.stream.Collectors;
-
-/**
- * This class provides simple utility methods for parsing program arguments into a map. The key of
- * map is the argument key. The value of map is the list of argument values of the same argument
- * key.
- *
- * <p><strong>Example arguments:</strong> --key1 value1 --key2 value2 -key3 value3 --multi
- * multiValue1 --multi multiValue2
- */
-public class ParameterTool extends ExecutionConfig.GlobalJobParameters {
-    private static final long serialVersionUID = 1L;
-
-    private static final String NO_VALUE_KEY = "__NO_VALUE_KEY";
-
-    /**
-     * Returns {@link ParameterTool} for the given program arguments.
-     *
-     * @param args Input array arguments
-     * @return A {@link ParameterTool}
-     */
-    public static ParameterTool fromArgs(String[] args) {
-        final Map<String, Collection<String>> map =
-                CollectionUtil.newHashMapWithExpectedSize(args.length / 2);
-
-        int i = 0;
-        while (i < args.length) {
-            final String key = Utils.getKeyFromArgs(args, i);
-
-            i += 1; // try to find the value
-
-            map.putIfAbsent(key, new ArrayList<>());
-            if (i >= args.length) {
-                map.get(key).add(NO_VALUE_KEY);
-            } else if (NumberUtils.isCreatable(args[i])) {
-                map.get(key).add(args[i]);
-                i += 1;
-            } else if (args[i].startsWith("--") || args[i].startsWith("-")) {
-                // the argument cannot be a negative number because we checked earlier
-                // -> the next argument is a parameter name
-                map.get(key).add(NO_VALUE_KEY);
-            } else {
-                map.get(key).add(args[i]);
-                i += 1;
-            }
-        }
-        return new ParameterTool(map);
-    }
-
-    private final Map<String, Collection<String>> data;
-
-    private ParameterTool(Map<String, Collection<String>> data) {
-        this.data = Collections.unmodifiableMap(new HashMap<>(data));
-    }
-
-    // ------------------ Get data from the util ----------------
-
-    /** Returns the String value for the given key. The value should only have one item. */
-    public String get(String key) {
-        if (!data.containsKey(key)) {
-            return null;
-        }
-        Preconditions.checkState(
-                data.get(key).size() == 1, "Key %s should has only one value.", key);
-        return (String) data.get(key).toArray()[0];
-    }
-
-    /**
-     * Returns the String value for the given key. If the key does not exist it will return the
-     * given default value.
-     */
-    public String get(String key, String defaultValue) {
-        String value = get(key);
-        if (value == null) {
-            return defaultValue;
-        } else {
-            return value;
-        }
-    }
-
-    /**
-     * Returns the Long value for the given key. If the key does not exists it will return the
-     * default value given. The method fails if the value is not a Long.
-     */
-    public long getLong(String key, long defaultValue) {
-        String value = get(key);
-        if (value == null) {
-            return defaultValue;
-        } else {
-            return Long.parseLong(value);
-        }
-    }
-
-    /**
-     * Returns the Boolean value for the given key. If the key does not exists it will return the
-     * default value given. The method returns whether the string of the value is "true" ignoring
-     * cases.
-     */
-    public boolean getBoolean(String key, boolean defaultValue) {
-        String value = get(key);
-        if (value == null) {
-            return defaultValue;
-        } else {
-            return Boolean.parseBoolean(value);
-        }
-    }
-
-    /**
-     * Returns the Double value for the given key. If the key does not exists it will return the
-     * default value given. The method fails if the value is not a Double.
-     */
-    public double getDouble(String key, double defaultValue) {
-        String value = get(key);
-        if (value == null) {
-            return defaultValue;
-        } else {
-            return Double.parseDouble(value);
-        }
-    }
-
-    /**
-     * Returns the Integer value for the given key. If the key does not exists it will return the
-     * default value given. The method fails if the value is not an Integer.
-     */
-    public int getInt(String key, int defaultValue) {
-        String value = get(key);
-        if (value == null) {
-            return defaultValue;
-        }
-        return Integer.parseInt(value);
-    }
-
-    /**
-     * Returns the Integer value for the given key. The method fails if the key does not exist or
-     * the value is not an Integer.
-     */
-    public int getInt(String key) {
-        String value = get(key);
-        if (value == null) {
-            throw new RuntimeException("No data for required key '" + key + "'");
-        }
-        return Integer.parseInt(value);
-    }
-
-    /** Check if value is set. */
-    public boolean has(String value) {
-        return data.containsKey(value);
-    }
-
-    /**
-     * Returns the Collection of String values for the given key. If the key does not exist it will
-     * throw a {@link RuntimeException}.
-     */
-    public Collection<String> getMultiParameterRequired(String key) {
-        Collection<String> value = data.getOrDefault(key, null);
-        if (value == null) {
-            throw new RuntimeException("No data for required key '" + key + "'");
-        }
-        return value;
-    }
-
-    @Override
-    public Map<String, String> toMap() {
-        return data.entrySet().stream()
-                .collect(
-                        Collectors.toMap(
-                                Map.Entry::getKey,
-                                e -> {
-                                    if (e.getValue().size() > 0) {
-                                        return (String)
-                                                e.getValue().toArray()[e.getValue().size() - 1];
-                                    } else {
-                                        return NO_VALUE_KEY;
-                                    }
-                                }));
-    }
-
-    @Override
-    public boolean equals(Object o) {
-        if (this == o) {
-            return true;
-        }
-        if (o == null || getClass() != o.getClass()) {
-            return false;
-        }
-        ParameterTool that = (ParameterTool) o;
-        return Objects.equals(data, that.data);
-    }
-
-    @Override
-    public int hashCode() {
-        return Objects.hash(data);
-    }
-}
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/windowing/SessionWindowing.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/windowing/SessionWindowing.java
index 2924e746bfd..34b3dd7d285 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/windowing/SessionWindowing.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/windowing/SessionWindowing.java
@@ -22,6 +22,7 @@ import org.apache.flink.api.common.serialization.SimpleStringEncoder;
 import org.apache.flink.api.common.typeinfo.TypeHint;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.java.tuple.Tuple3;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.configuration.MemorySize;
 import org.apache.flink.connector.datagen.source.DataGeneratorSource;
 import org.apache.flink.connector.datagen.source.GeneratorFunction;
@@ -32,7 +33,6 @@ import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy;
 import org.apache.flink.streaming.api.windowing.assigners.EventTimeSessionWindows;
 import org.apache.flink.streaming.api.windowing.time.Time;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 
 import java.time.Duration;
 import java.util.ArrayList;
diff --git a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/wordcount/util/CLI.java b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/wordcount/util/CLI.java
index b160fe7ec5b..ddf11113e20 100644
--- a/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/wordcount/util/CLI.java
+++ b/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/wordcount/util/CLI.java
@@ -19,9 +19,9 @@ package org.apache.flink.streaming.examples.wordcount.util;
 
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.RuntimeExecutionMode;
+import org.apache.flink.api.java.utils.MultipleParameterTool;
 import org.apache.flink.configuration.ExecutionOptions;
 import org.apache.flink.core.fs.Path;
-import org.apache.flink.streaming.examples.utils.ParameterTool;
 import org.apache.flink.util.TimeUtils;
 
 import java.time.Duration;
@@ -43,7 +43,7 @@ public class CLI extends ExecutionConfig.GlobalJobParameters {
     public static final String EXECUTION_MODE = "execution-mode";
 
     public static CLI fromArgs(String[] args) throws Exception {
-        ParameterTool params = ParameterTool.fromArgs(args);
+        MultipleParameterTool params = MultipleParameterTool.fromArgs(args);
         Path[] inputs = null;
         if (params.has(INPUT_KEY)) {
             inputs =
@@ -79,14 +79,14 @@ public class CLI extends ExecutionConfig.GlobalJobParameters {
     private final Path output;
     private final Duration discoveryInterval;
     private final RuntimeExecutionMode executionMode;
-    private final ParameterTool params;
+    private final MultipleParameterTool params;
 
     private CLI(
             Path[] inputs,
             Path output,
             Duration discoveryInterval,
             RuntimeExecutionMode executionMode,
-            ParameterTool params) {
+            MultipleParameterTool params) {
         this.inputs = inputs;
         this.output = output;
         this.discoveryInterval = discoveryInterval;
@@ -112,7 +112,7 @@ public class CLI extends ExecutionConfig.GlobalJobParameters {
 
     public OptionalInt getInt(String key) {
         if (params.has(key)) {
-            return OptionalInt.of(Integer.parseInt(params.get(key)));
+            return OptionalInt.of(params.getInt(key));
         }
 
         return OptionalInt.empty();
diff --git a/flink-examples/flink-examples-table/src/main/java/org/apache/flink/table/examples/java/connectors/ChangelogSocketExample.java b/flink-examples/flink-examples-table/src/main/java/org/apache/flink/table/examples/java/connectors/ChangelogSocketExample.java
index 40e8f8d574f..b0f894a1a8b 100644
--- a/flink-examples/flink-examples-table/src/main/java/org/apache/flink/table/examples/java/connectors/ChangelogSocketExample.java
+++ b/flink-examples/flink-examples-table/src/main/java/org/apache/flink/table/examples/java/connectors/ChangelogSocketExample.java
@@ -19,19 +19,13 @@
 package org.apache.flink.table.examples.java.connectors;
 
 import org.apache.flink.api.connector.source.Source;
-import org.apache.flink.api.java.Utils;
+import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.table.api.Table;
 import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;
 import org.apache.flink.table.connector.format.DecodingFormat;
 import org.apache.flink.table.connector.source.DynamicTableSource;
 import org.apache.flink.table.factories.FactoryUtil;
-import org.apache.flink.util.CollectionUtil;
-
-import org.apache.commons.lang3.math.NumberUtils;
-
-import java.util.Arrays;
-import java.util.Map;
 
 /**
  * Example for implementing a custom {@link DynamicTableSource} and a {@link DecodingFormat}.
@@ -72,9 +66,9 @@ import java.util.Map;
 public final class ChangelogSocketExample {
 
     public static void main(String[] args) throws Exception {
-        Map<String, String> params = parseArgs(args);
-        final String hostname = params.getOrDefault("hostname", "localhost");
-        final String port = params.getOrDefault("port", "9999");
+        final ParameterTool params = ParameterTool.fromArgs(args);
+        final String hostname = params.get("hostname", "localhost");
+        final String port = params.get("port", "9999");
 
         final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
         env.setParallelism(1); // source only supports parallelism of 1
@@ -105,33 +99,4 @@ public final class ChangelogSocketExample {
 
         env.execute();
     }
-
-    private static Map<String, String> parseArgs(String[] args) {
-        final Map<String, String> map = CollectionUtil.newHashMapWithExpectedSize(args.length / 2);
-        int i = 0;
-        while (i < args.length) {
-            final String key = Utils.getKeyFromArgs(args, i);
-            if (key.isEmpty()) {
-                throw new IllegalArgumentException(
-                        "The input " + Arrays.toString(args) + " contains an empty argument");
-            }
-
-            i += 1; // try to find the value
-
-            if (i >= args.length) {
-                map.put(key, "__NO_VALUE_KEY");
-            } else if (NumberUtils.isCreatable(args[i])) {
-                map.put(key, args[i]);
-                i += 1;
-            } else if (args[i].startsWith("--") || args[i].startsWith("-")) {
-                // the argument cannot be a negative number because we checked earlier
-                // -> the next argument is a parameter name
-                map.put(key, "__NO_VALUE_KEY");
-            } else {
-                map.put(key, args[i]);
-                i += 1;
-            }
-        }
-        return map;
-    }
 }
diff --git a/flink-java/src/main/java/org/apache/flink/api/java/utils/AbstractParameterTool.java b/flink-java/src/main/java/org/apache/flink/api/java/utils/AbstractParameterTool.java
index 9d4ac9c8db8..27cd36b5818 100644
--- a/flink-java/src/main/java/org/apache/flink/api/java/utils/AbstractParameterTool.java
+++ b/flink-java/src/main/java/org/apache/flink/api/java/utils/AbstractParameterTool.java
@@ -30,14 +30,7 @@ import java.util.Set;
 /**
  * This class provides common utility methods of {@link ParameterTool} and {@link
  * MultipleParameterTool}.
- *
- * @deprecated All Flink DataSet APIs are deprecated since Flink 1.18 and will be removed in a
- *     future Flink major version. You can still build your application in DataSet, but you should
- *     move to either the DataStream and/or Table API.
- * @see <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=158866741">
- *     FLIP-131: Consolidate the user-facing Dataflow SDKs/APIs (and deprecate the DataSet API</a>
  */
-@Deprecated
 @Public
 public abstract class AbstractParameterTool extends ExecutionConfig.GlobalJobParameters
         implements Serializable, Cloneable {
diff --git a/flink-java/src/main/java/org/apache/flink/api/java/utils/MultipleParameterTool.java b/flink-java/src/main/java/org/apache/flink/api/java/utils/MultipleParameterTool.java
index c7085be0906..eb0f256032f 100644
--- a/flink-java/src/main/java/org/apache/flink/api/java/utils/MultipleParameterTool.java
+++ b/flink-java/src/main/java/org/apache/flink/api/java/utils/MultipleParameterTool.java
@@ -43,14 +43,7 @@ import java.util.stream.Collectors;
  * multiValue1 --multi multiValue2. If {@link MultipleParameterTool} object is used for
  * GlobalJobParameters, the last one of multiple values will be used. Navigate to {@link #toMap()}
  * for more information.
- *
- * @deprecated All Flink DataSet APIs are deprecated since Flink 1.18 and will be removed in a
- *     future Flink major version. You can still build your application in DataSet, but you should
- *     move to either the DataStream and/or Table API.
- * @see <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=158866741">
- *     FLIP-131: Consolidate the user-facing Dataflow SDKs/APIs (and deprecate the DataSet API</a>
  */
-@Deprecated
 @PublicEvolving
 public class MultipleParameterTool extends AbstractParameterTool {
     private static final long serialVersionUID = 1L;
diff --git a/flink-java/src/main/java/org/apache/flink/api/java/utils/ParameterTool.java b/flink-java/src/main/java/org/apache/flink/api/java/utils/ParameterTool.java
index fd3954eb80b..63064e3b242 100644
--- a/flink-java/src/main/java/org/apache/flink/api/java/utils/ParameterTool.java
+++ b/flink-java/src/main/java/org/apache/flink/api/java/utils/ParameterTool.java
@@ -46,14 +46,7 @@ import java.util.concurrent.ConcurrentHashMap;
 /**
  * This class provides simple utility methods for reading and parsing program arguments from
  * different sources. Only single value parameter could be supported in args.
- *
- * @deprecated All Flink DataSet APIs are deprecated since Flink 1.18 and will be removed in a
- *     future Flink major version. You can still build your application in DataSet, but you should
- *     move to either the DataStream and/or Table API.
- * @see <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=158866741">
- *     FLIP-131: Consolidate the user-facing Dataflow SDKs/APIs (and deprecate the DataSet API</a>
  */
-@Deprecated
 @Public
 public class ParameterTool extends AbstractParameterTool {
     private static final long serialVersionUID = 1L;
