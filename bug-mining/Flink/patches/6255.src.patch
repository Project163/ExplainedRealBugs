diff --git a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSAuthenticationException.java b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSAuthenticationException.java
new file mode 100644
index 00000000000..cf0d0517801
--- /dev/null
+++ b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSAuthenticationException.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.aws.util;
+
+import org.apache.flink.annotation.Internal;
+
+/**
+ * A {@link IllegalStateException} wrapper indicating the exception was thrown from AWS credentials.
+ */
+@Internal
+public class AWSAuthenticationException extends IllegalStateException {
+
+    public AWSAuthenticationException(final String message) {
+        super(message);
+    }
+
+    public AWSAuthenticationException(final String message, final Throwable cause) {
+        super(message, cause);
+    }
+}
diff --git a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialRetryableExceptionClassifiers.java b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialRetryableExceptionClassifiers.java
new file mode 100644
index 00000000000..6172c86123e
--- /dev/null
+++ b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialRetryableExceptionClassifiers.java
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.aws.util;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
+
+import software.amazon.awssdk.core.exception.SdkClientException;
+import software.amazon.awssdk.services.sts.model.StsException;
+
+/** Class containing set of {@link RetryableExceptionClassifier} for AWS credenetial failures. */
+@Internal
+public class AWSCredentialRetryableExceptionClassifiers {
+    public static RetryableExceptionClassifier getInvalidCredentialsExceptionClassifier() {
+        return RetryableExceptionClassifier.withRootCauseOfType(
+                StsException.class,
+                err ->
+                        new AWSAuthenticationException(
+                                "Encountered non-recoverable exception relating to the provided credentials.",
+                                err));
+    }
+
+    public static RetryableExceptionClassifier getSdkClientMisconfiguredExceptionClassifier() {
+        return RetryableExceptionClassifier.withRootCauseOfType(
+                SdkClientException.class,
+                err ->
+                        new AWSAuthenticationException(
+                                "Encountered non-recoverable exception relating to mis-configured client",
+                                err));
+    }
+}
diff --git a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java
index dfc78d8162a..0c8dfc8d505 100644
--- a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java
+++ b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java
@@ -49,6 +49,8 @@ import java.util.Map;
 import java.util.Optional;
 import java.util.Properties;
 
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.CredentialProvider.WEB_IDENTITY_TOKEN;
+
 /** Some general utilities specific to Amazon Web Service. */
 @Internal
 public class AWSGeneralUtil {
@@ -86,7 +88,15 @@ public class AWSGeneralUtil {
                 return CredentialProvider.AUTO;
             }
         } else {
-            return CredentialProvider.valueOf(configProps.getProperty(configPrefix));
+            try {
+                return CredentialProvider.valueOf(configProps.getProperty(configPrefix));
+            } catch (IllegalArgumentException e) {
+                throw new IllegalArgumentException(
+                        String.format(
+                                "Invalid AWS Credential Provider type %s.",
+                                configProps.getProperty(configPrefix)),
+                        e);
+            }
         }
     }
 
@@ -315,20 +325,8 @@ public class AWSGeneralUtil {
      */
     public static void validateAwsConfiguration(Properties config) {
         if (config.containsKey(AWSConfigConstants.AWS_CREDENTIALS_PROVIDER)) {
-            // value specified for AWSConfigConstants.AWS_CREDENTIALS_PROVIDER needs to be
-            // recognizable
-            try {
-                getCredentialsProvider(config);
-            } catch (IllegalArgumentException e) {
-                StringBuilder sb = new StringBuilder();
-                for (CredentialProvider type : CredentialProvider.values()) {
-                    sb.append(type.toString()).append(", ");
-                }
-                throw new IllegalArgumentException(
-                        "Invalid AWS Credential Provider Type set in config. Valid values are: "
-                                + sb.toString());
-            }
 
+            validateCredentialProvider(config);
             // if BASIC type is used, also check that the Access Key ID and Secret Key is supplied
             CredentialProvider credentialsProviderType =
                     getCredentialProviderType(config, AWSConfigConstants.AWS_CREDENTIALS_PROVIDER);
@@ -374,4 +372,36 @@ public class AWSGeneralUtil {
             throw exception;
         }
     }
+
+
+    public static void validateWebIdentityTokenFileCredentialsProvider(Properties config) {
+        validateCredentialProvider(config);
+        try {
+            CredentialProvider credentialProviderType =
+                    getCredentialProviderType(config, AWSConfigConstants.AWS_CREDENTIALS_PROVIDER);
+            if (credentialProviderType.equals(WEB_IDENTITY_TOKEN)) {
+                getCredentialsProvider(config).resolveCredentials();
+            }
+        } catch (Throwable e) {
+            throw new AWSAuthenticationException(
+                    String.format("Failed to create client using %s provider", WEB_IDENTITY_TOKEN),
+                    e);
+        }
+    }
+
+    private static void validateCredentialProvider(Properties config) {
+        // value specified for AWSConfigConstants.AWS_CREDENTIALS_PROVIDER needs to be
+        // recognizable
+        try {
+            getCredentialsProvider(config);
+        } catch (IllegalArgumentException e) {
+            StringBuilder sb = new StringBuilder();
+            for (CredentialProvider type : CredentialProvider.values()) {
+                sb.append(type.toString()).append(", ");
+            }
+            throw new IllegalArgumentException(
+                    "Invalid AWS Credential Provider Type set in config. Valid values are: "
+                            + sb.toString());
+        }
+    }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsException.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsException.java
index 59b49ef030d..3ab30e1ef09 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsException.java
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsException.java
@@ -37,15 +37,15 @@ class KinesisDataStreamsException extends RuntimeException {
      */
     static class KinesisDataStreamsFailFastException extends KinesisDataStreamsException {
 
+        private static final String ERROR_MESSAGE =
+                "Encountered an exception while persisting records, not retrying due to {failOnError} being set.";
+
         public KinesisDataStreamsFailFastException() {
-            super(
-                    "Encountered an exception while persisting records, not retrying due to {failOnError} being set.");
+            super(ERROR_MESSAGE);
         }
 
         public KinesisDataStreamsFailFastException(final Throwable cause) {
-            super(
-                    "Encountered an exception while persisting records, not retrying due to {failOnError} being set.",
-                    cause);
+            super(ERROR_MESSAGE, cause);
         }
     }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
index 88359faf8a4..58f3001838e 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
@@ -20,13 +20,12 @@ package org.apache.flink.connector.kinesis.sink;
 import org.apache.flink.api.connector.sink2.Sink;
 import org.apache.flink.connector.aws.util.AWSAsyncSinkUtil;
 import org.apache.flink.connector.aws.util.AWSGeneralUtil;
+import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
 import org.apache.flink.connector.base.sink.writer.AsyncSinkWriter;
 import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.metrics.Counter;
 import org.apache.flink.metrics.groups.SinkWriterMetricGroup;
-import org.apache.flink.util.ExceptionUtils;
-import org.apache.flink.util.FlinkException;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -44,9 +43,13 @@ import java.util.Collections;
 import java.util.List;
 import java.util.Properties;
 import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.CompletionException;
 import java.util.function.Consumer;
 
+import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
+import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getGeneralExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getInterruptedExceptionClassifier;
+
 /**
  * Sink writer created by {@link KinesisDataStreamsSink} to write to Kinesis Data Streams. More
  * details on the operation of this sink writer may be found in the doc for {@link
@@ -60,6 +63,31 @@ import java.util.function.Consumer;
 class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRecordsRequestEntry> {
     private static final Logger LOG = LoggerFactory.getLogger(KinesisDataStreamsSinkWriter.class);
 
+    private static final RetryableExceptionClassifier RESOURCE_NOT_FOUND_STRATEGY =
+            RetryableExceptionClassifier.withRootCauseOfType(
+                    ResourceNotFoundException.class,
+                    err ->
+                            new KinesisDataStreamsException(
+                                    "Encountered non-recoverable exception relating to not being able to find the specified resources",
+                                    err));
+
+    private static final RetryableExceptionClassifier NON_RECOVERABLE_EXCEPTION_STRATEGY =
+            RetryableExceptionClassifier.withRootCauseOfType(
+                    Error.class,
+                    err ->
+                            new KinesisDataStreamsException(
+                                    "Encountered non-recoverable exception in the Kinesis Data Streams Sink",
+                                    err));
+
+    private static final RetryableExceptionClassifier KINESIS_RETRY_VALIDATION_STRATEGY =
+            RetryableExceptionClassifier.createChain(
+                    getGeneralExceptionClassifier(),
+                    getInterruptedExceptionClassifier(),
+                    getInvalidCredentialsExceptionClassifier(),
+                    RESOURCE_NOT_FOUND_STRATEGY,
+                    getSdkClientMisconfiguredExceptionClassifier(),
+                    NON_RECOVERABLE_EXCEPTION_STRATEGY);
+
     /* A counter for the total number of records that have encountered an error during put */
     private final Counter numRecordsOutErrorsCounter;
 
@@ -136,8 +164,9 @@ class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRe
         this.kinesisClient = buildClient(kinesisClientProperties, this.httpClient);
     }
 
-    private KinesisAsyncClient buildClient(
-            Properties kinesisClientProperties, SdkAsyncHttpClient httpClient) {
+    private KinesisAsyncClient buildClient(Properties kinesisClientProperties, SdkAsyncHttpClient httpClient) {
+        AWSGeneralUtil.validateAwsConfiguration(kinesisClientProperties);
+        AWSGeneralUtil.validateWebIdentityTokenFileCredentialsProvider(kinesisClientProperties);
         return AWSAsyncSinkUtil.createAwsAsyncClient(
                 kinesisClientProperties,
                 httpClient,
@@ -218,35 +247,8 @@ class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRe
     }
 
     private boolean isRetryable(Throwable err) {
-        if (err instanceof CompletionException
-                && isInterruptingSignalException(ExceptionUtils.stripCompletionException(err))) {
-            getFatalExceptionCons().accept(new FlinkException("Running job was cancelled"));
-            return false;
-        }
-        if (err instanceof CompletionException
-                && ExceptionUtils.stripCompletionException(err)
-                        instanceof ResourceNotFoundException) {
-            getFatalExceptionCons()
-                    .accept(
-                            new KinesisDataStreamsException(
-                                    "Encountered non-recoverable exception relating to not being able to find the specified resources",
-                                    err));
-            return false;
-        }
-        if (err instanceof CompletionException
-                && ExceptionUtils.stripCompletionException(err) instanceof StsException) {
-            getFatalExceptionCons()
-                    .accept(
-                            new KinesisDataStreamsException(
-                                    "Encountered non-recoverable exception relating to the provided credentials.",
-                                    err));
-            return false;
-        }
-        if (err instanceof Error) {
-            getFatalExceptionCons()
-                    .accept(
-                            new KinesisDataStreamsException(
-                                    "Encountered non-recoverable exception.", err));
+
+        if (!KINESIS_RETRY_VALIDATION_STRATEGY.shouldSuppress(err, getFatalExceptionCons())) {
             return false;
         }
         if (failOnError) {
@@ -259,11 +261,4 @@ class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRe
 
         return true;
     }
-
-    private boolean isInterruptingSignalException(Throwable err) {
-        return err != null
-                && (err instanceof InterruptedException
-                        || (err instanceof IllegalStateException
-                                && err.getCause() instanceof InterruptedException));
-    }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java
index fddff2934d7..cad256f225b 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java
@@ -20,6 +20,7 @@ package org.apache.flink.connector.kinesis.sink;
 import org.apache.flink.api.common.serialization.SerializationSchema;
 import org.apache.flink.api.common.serialization.SimpleStringSchema;
 import org.apache.flink.api.common.time.Deadline;
+import org.apache.flink.connector.aws.config.AWSConfigConstants;
 import org.apache.flink.connector.aws.util.AWSGeneralUtil;
 import org.apache.flink.connectors.kinesis.testutils.KinesaliteContainer;
 import org.apache.flink.runtime.client.JobExecutionException;
@@ -54,6 +55,7 @@ import java.util.Properties;
 
 import static java.util.concurrent.TimeUnit.SECONDS;
 import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_ACCESS_KEY_ID;
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_CREDENTIALS_PROVIDER;
 import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_ENDPOINT;
 import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_REGION;
 import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_SECRET_ACCESS_KEY;
@@ -159,6 +161,21 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         testJobFatalFailureTerminatesCorrectlyWithFailOnErrorFlagSetTo(false, "test-stream-name-6");
     }
 
+    private void testJobFatalFailureTerminatesCorrectlyWithFailOnErrorFlagSetTo(
+            boolean failOnError, String streamName) {
+        Assertions.assertThatExceptionOfType(JobExecutionException.class)
+                .isThrownBy(
+                        () ->
+                                new Scenario()
+                                        .withKinesaliteStreamName(streamName)
+                                        .withSinkConnectionStreamName("non-existent-stream")
+                                        .withFailOnError(failOnError)
+                                        .runScenario())
+                .havingCause()
+                .havingCause()
+                .withMessageContaining("Encountered non-recoverable exception");
+    }
+
     @Test
     public void veryLargeMessagesFailGracefullyWithBrokenElementConverter() {
         Assertions.assertThatExceptionOfType(JobExecutionException.class)
@@ -179,6 +196,227 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
                         "Encountered an exception while persisting records, not retrying due to {failOnError} being set.");
     }
 
+    @Test
+    public void badRegionShouldResultInFailureWhenInFailOnErrorIsOn() {
+        badRegionShouldResultInFailureWhenInFailOnErrorIs(true);
+    }
+
+    @Test
+    public void badRegionShouldResultInFailureWhenInFailOnErrorIsOff() {
+        badRegionShouldResultInFailureWhenInFailOnErrorIs(false);
+    }
+
+    private void badRegionShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
+        Properties properties = getDefaultProperties();
+        properties.setProperty(AWS_REGION, "some-bad-region");
+        String streamName = "do-not-create-new-stream";
+        assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
+                streamName, failOnError, properties, "Invalid AWS region set in config");
+    }
+
+    @Test
+    public void missingRegionShouldResultInFailureWhenInFailOnErrorIsOn() {
+        missingRegionShouldResultInFailureWhenInFailOnErrorIs(true);
+    }
+
+    @Test
+    public void missingRegionShouldResultInFailureWhenInFailOnErrorIsOff() {
+        missingRegionShouldResultInFailureWhenInFailOnErrorIs(false);
+    }
+
+    private void missingRegionShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
+        Properties properties = getDefaultProperties();
+        properties.remove(AWS_REGION);
+        String streamName = "do-not-create-new-stream";
+        assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
+                streamName, failOnError, properties, "region must not be null.");
+    }
+
+    @Test
+    public void noURIEndpointShouldResultInFailureWhenInFailOnErrorIsOn() {
+        noURIEndpointShouldResultInFailureWhenInFailOnErrorIs(true);
+    }
+
+    @Test
+    public void noURIEndpointShouldResultInFailureWhenInFailOnErrorIsOff() {
+        noURIEndpointShouldResultInFailureWhenInFailOnErrorIs(false);
+    }
+
+    private void noURIEndpointShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
+        Properties properties = getDefaultProperties();
+        properties.setProperty(AWS_ENDPOINT, "bad-endpoint-no-uri");
+        String streamName = "do-not-create-new-stream";
+        assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
+                streamName,
+                failOnError,
+                properties,
+                "The URI scheme of endpointOverride must not be null.");
+    }
+
+    @Test
+    public void badEndpointShouldResultInFailureWhenInFailOnErrorIsOn() {
+        badEndpointShouldResultInFailureWhenInFailOnErrorIs(true);
+    }
+
+    @Test
+    public void badEndpointShouldResultInFailureWhenInFailOnErrorIsOff() {
+        badEndpointShouldResultInFailureWhenInFailOnErrorIs(false);
+    }
+
+    private void badEndpointShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
+        Properties properties = getDefaultProperties();
+        properties.setProperty(AWS_ENDPOINT, "https://bad-endpoint-with-uri");
+        String streamName = "do-not-create-new-stream";
+        assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
+                streamName,
+                failOnError,
+                properties,
+                "Encountered non-recoverable exception relating to mis-configured client");
+    }
+
+    @Test
+    public void envVarWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOn() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                true,
+                AWSConfigConstants.CredentialProvider.ENV_VAR.toString(),
+                "Encountered non-recoverable exception relating to mis-configured client");
+    }
+
+    @Test
+    public void envVarWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOff() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                false,
+                AWSConfigConstants.CredentialProvider.ENV_VAR.toString(),
+                "Encountered non-recoverable exception relating to mis-configured client");
+    }
+
+    @Test
+    public void sysPropWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOn() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                true,
+                AWSConfigConstants.CredentialProvider.SYS_PROP.toString(),
+                "Encountered non-recoverable exception relating to mis-configured client");
+    }
+
+    @Test
+    public void sysPropWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOff() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                false,
+                AWSConfigConstants.CredentialProvider.SYS_PROP.toString(),
+                "Encountered non-recoverable exception relating to mis-configured client");
+    }
+
+    @Test
+    public void basicWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOn() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                true,
+                AWSConfigConstants.CredentialProvider.BASIC.toString(),
+                "Please set values for AWS Access Key ID ('"
+                        + AWSConfigConstants.AWS_ACCESS_KEY_ID
+                        + "') "
+                        + "and Secret Key ('"
+                        + AWSConfigConstants.AWS_SECRET_ACCESS_KEY
+                        + "') when using the BASIC AWS credential provider type.");
+    }
+
+    @Test
+    public void basicWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOff() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                false,
+                AWSConfigConstants.CredentialProvider.BASIC.toString(),
+                "Please set values for AWS Access Key ID ('"
+                        + AWSConfigConstants.AWS_ACCESS_KEY_ID
+                        + "') "
+                        + "and Secret Key ('"
+                        + AWSConfigConstants.AWS_SECRET_ACCESS_KEY
+                        + "') when using the BASIC AWS credential provider type.");
+    }
+
+    @Test
+    public void webIdentityTokenWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOn() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                true,
+                AWSConfigConstants.CredentialProvider.WEB_IDENTITY_TOKEN.toString(),
+                "Failed to create client using WEB_IDENTITY_TOKEN provider");
+    }
+
+    @Test
+    public void webIdentityTokenWithNoCredentialsShouldResultInFailureWhenInFailOnErrorIsOff() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                false,
+                AWSConfigConstants.CredentialProvider.WEB_IDENTITY_TOKEN.toString(),
+                "Failed to create client using WEB_IDENTITY_TOKEN provider");
+    }
+
+    @Test
+    public void wrongCredentialProviderNameShouldResultInFailureWhenInFailOnErrorIsOn() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                true, "WRONG", "Invalid AWS Credential Provider Type");
+    }
+
+    @Test
+    public void wrongCredentialProviderNameShouldResultInFailureWhenInFailOnErrorIsOff() {
+        noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+                false, "WRONG", "Invalid AWS Credential Provider Type");
+    }
+
+    private void credentialsProvidedThroughProfilePathShouldResultInFailure(
+            boolean failOnError,
+            String credentialsProvider,
+            String credentialsProfileLocation,
+            String expectedMessage) {
+        Properties properties =
+                getDefaultPropertiesWithoutCredentialsSetAndCredentialProvider(credentialsProvider);
+        properties.put(
+                AWSConfigConstants.profilePath(AWS_CREDENTIALS_PROVIDER),
+                credentialsProfileLocation);
+        assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
+                "do-not-create-new-stream", failOnError, properties, expectedMessage);
+    }
+
+    private void noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
+            boolean failOnError, String credentialsProvider, String expectedMessage) {
+        assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
+                "do-not-create-new-stream",
+                failOnError,
+                getDefaultPropertiesWithoutCredentialsSetAndCredentialProvider(credentialsProvider),
+                expectedMessage);
+    }
+
+    private void assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
+            String streamName, boolean failOnError, Properties properties, String expectedMessage) {
+        Assertions.assertThatExceptionOfType(JobExecutionException.class)
+                .isThrownBy(
+                        () ->
+                                new Scenario()
+                                        .withKinesaliteStreamName(streamName)
+                                        .withSinkConnectionStreamName(streamName)
+                                        .withFailOnError(failOnError)
+                                        .withProperties(properties)
+                                        .runScenario())
+                .havingCause()
+                .havingCause()
+                .withMessageContaining(expectedMessage);
+    }
+
+    private Properties getDefaultPropertiesWithoutCredentialsSetAndCredentialProvider(
+            String credentialsProvider) {
+        Properties properties = getDefaultProperties();
+        properties.setProperty(AWS_CREDENTIALS_PROVIDER, credentialsProvider);
+        properties.remove(AWS_SECRET_ACCESS_KEY);
+        properties.remove(AWS_ACCESS_KEY_ID);
+        return properties;
+    }
+
+    private Properties getDefaultProperties() {
+        Properties properties = new Properties();
+        properties.setProperty(AWS_ENDPOINT, KINESALITE.getHostEndpointUrl());
+        properties.setProperty(AWS_ACCESS_KEY_ID, KINESALITE.getAccessKey());
+        properties.setProperty(AWS_SECRET_ACCESS_KEY, KINESALITE.getSecretKey());
+        properties.setProperty(AWS_REGION, KINESALITE.getRegion().toString());
+        return properties;
+    }
+
     private class Scenario {
         private int numberOfElementsToSend = 50;
         private int sizeOfMessageBytes = 25;
@@ -193,9 +431,12 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
                 KinesisDataStreamsSinkITCase.this.serializationSchema;
         private PartitionKeyGenerator<String> partitionKeyGenerator =
                 KinesisDataStreamsSinkITCase.this.partitionKeyGenerator;
+        private Properties properties = KinesisDataStreamsSinkITCase.this.getDefaultProperties();
 
         public void runScenario() throws Exception {
             prepareStream(kinesaliteStreamName);
+            properties.setProperty(TRUST_ALL_CERTIFICATES, "true");
+            properties.setProperty(HTTP_PROTOCOL_VERSION, "HTTP1_1");
 
             DataStream<String> stream =
                     env.addSource(
@@ -205,14 +446,6 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
                                             (long) numberOfElementsToSend))
                             .returns(String.class);
 
-            Properties prop = new Properties();
-            prop.setProperty(AWS_ENDPOINT, KINESALITE.getHostEndpointUrl());
-            prop.setProperty(AWS_ACCESS_KEY_ID, KINESALITE.getAccessKey());
-            prop.setProperty(AWS_SECRET_ACCESS_KEY, KINESALITE.getSecretKey());
-            prop.setProperty(AWS_REGION, KINESALITE.getRegion().toString());
-            prop.setProperty(TRUST_ALL_CERTIFICATES, "true");
-            prop.setProperty(HTTP_PROTOCOL_VERSION, "HTTP1_1");
-
             KinesisDataStreamsSink<String> kdsSink =
                     KinesisDataStreamsSink.<String>builder()
                             .setSerializationSchema(serializationSchema)
@@ -223,7 +456,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
                             .setFailOnError(failOnError)
                             .setMaxBufferedRequests(1000)
                             .setStreamName(sinkConnectionStreamName)
-                            .setKinesisClientProperties(prop)
+                            .setKinesisClientProperties(properties)
                             .setFailOnError(true)
                             .build();
 
@@ -310,7 +543,15 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
             return this;
         }
 
+        public Scenario withProperties(Properties properties) {
+            this.properties = properties;
+            return this;
+        }
+
         private void prepareStream(String streamName) throws Exception {
+            if (streamName.equals("do-not-create-new-stream")) {
+                return;
+            }
             final RateLimiter rateLimiter =
                     RateLimiterBuilder.newBuilder()
                             .withRate(1, SECONDS)
@@ -349,19 +590,4 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
             }
         }
     }
-
-    private void testJobFatalFailureTerminatesCorrectlyWithFailOnErrorFlagSetTo(
-            boolean failOnError, String streamName) {
-        Assertions.assertThatExceptionOfType(JobExecutionException.class)
-                .isThrownBy(
-                        () ->
-                                new Scenario()
-                                        .withKinesaliteStreamName(streamName)
-                                        .withSinkConnectionStreamName("non-existent-stream")
-                                        .withFailOnError(failOnError)
-                                        .runScenario())
-                .havingCause()
-                .havingCause()
-                .withMessageContaining("Encountered non-recoverable exception");
-    }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseException.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseException.java
index ff6918c29bb..e76c10b117f 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseException.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseException.java
@@ -40,15 +40,15 @@ class KinesisFirehoseException extends RuntimeException {
      */
     static class KinesisFirehoseFailFastException extends KinesisFirehoseException {
 
+        private static final String ERROR_MESSAGE =
+                "Encountered an exception while persisting records, not retrying due to {failOnError} being set.";
+
         public KinesisFirehoseFailFastException() {
-            super(
-                    "Encountered an exception while persisting records, not retrying due to {failOnError} being set.");
+            super(ERROR_MESSAGE);
         }
 
         public KinesisFirehoseFailFastException(final Throwable cause) {
-            super(
-                    "Encountered an exception while persisting records, not retrying due to {failOnError} being set.",
-                    cause);
+            super(ERROR_MESSAGE, cause);
         }
     }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
index 89d37d34aa1..770404b6fff 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
@@ -21,6 +21,8 @@ import org.apache.flink.annotation.Internal;
 import org.apache.flink.api.connector.sink2.Sink;
 import org.apache.flink.connector.aws.util.AWSAsyncSinkUtil;
 import org.apache.flink.connector.aws.util.AWSGeneralUtil;
+import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
+import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
 import org.apache.flink.connector.base.sink.writer.AsyncSinkWriter;
 import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
@@ -43,9 +45,18 @@ import java.util.Collections;
 import java.util.List;
 import java.util.Properties;
 import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.CompletionException;
 import java.util.function.Consumer;
 
+import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
+import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getGeneralExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getInterruptedExceptionClassifier;
+
+import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
+import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getGeneralExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getInterruptedExceptionClassifier;
+
 /**
  * Sink writer created by {@link KinesisFirehoseSink} to write to Kinesis Data Firehose. More
  * details on the operation of this sink writer may be found in the doc for {@link
@@ -75,6 +86,31 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
                 KinesisFirehoseConfigConstants.FIREHOSE_CLIENT_USER_AGENT_PREFIX);
     }
 
+    private static final RetryableExceptionClassifier RESOURCE_NOT_FOUND_STRATEGY =
+            RetryableExceptionClassifier.withRootCauseOfType(
+                    ResourceNotFoundException.class,
+                    err ->
+                            new KinesisFirehoseException(
+                                    "Encountered non-recoverable exception relating to not being able to find the specified resources",
+                                    err));
+
+    private static final RetryableExceptionClassifier NON_RECOVERABLE_EXCEPTION_STRATEGY =
+            RetryableExceptionClassifier.withRootCauseOfType(
+                    Error.class,
+                    err ->
+                            new KinesisFirehoseException(
+                                    "Encountered non-recoverable exception in the Kinesis Data Firehose Sink",
+                                    err));
+
+    private static final RetryableExceptionClassifier FIREHOSE_RETRY_VALIDATION_STRATEGY =
+            RetryableExceptionClassifier.createChain(
+                    getGeneralExceptionClassifier(),
+                    getInterruptedExceptionClassifier(),
+                    getInvalidCredentialsExceptionClassifier(),
+                    RESOURCE_NOT_FOUND_STRATEGY,
+                    getSdkClientMisconfiguredExceptionClassifier(),
+                    NON_RECOVERABLE_EXCEPTION_STRATEGY);
+
     /* A counter for the total number of records that have encountered an error during put */
     private final Counter numRecordsOutErrorsCounter;
 
@@ -151,6 +187,20 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
         this.firehoseClient = createFirehoseClient(firehoseClientProperties, httpClient);
     }
 
+    private FirehoseAsyncClient buildClient(Properties firehoseClientProperties) {
+        AWSGeneralUtil.validateAwsConfiguration(firehoseClientProperties);
+        AWSGeneralUtil.validateWebIdentityTokenFileCredentialsProvider(firehoseClientProperties);
+        final SdkAsyncHttpClient httpClient =
+                AWSGeneralUtil.createAsyncHttpClient(firehoseClientProperties);
+
+        return AWSAsyncSinkUtil.createAwsAsyncClient(
+                firehoseClientProperties,
+                httpClient,
+                FirehoseAsyncClient.builder(),
+                KinesisFirehoseConfigConstants.BASE_FIREHOSE_USER_AGENT_PREFIX_FORMAT,
+                KinesisFirehoseConfigConstants.FIREHOSE_CLIENT_USER_AGENT_PREFIX);
+    }
+
     @Override
     protected void submitRequestEntries(
             List<Record> requestEntries, Consumer<List<Record>> requestResult) {
@@ -230,12 +280,7 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
     }
 
     private boolean isRetryable(Throwable err) {
-        if (err instanceof CompletionException
-                && err.getCause() instanceof ResourceNotFoundException) {
-            getFatalExceptionCons()
-                    .accept(
-                            new KinesisFirehoseException(
-                                    "Encountered non-recoverable exception", err));
+        if (!FIREHOSE_RETRY_VALIDATION_STRATEGY.shouldSuppress(err, getFatalExceptionCons())) {
             return false;
         }
         if (failOnError) {
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java
index 80678b44c9f..de1c943f1b9 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java
@@ -18,15 +18,17 @@
 package org.apache.flink.connector.firehose.sink;
 
 import org.apache.flink.api.common.serialization.SimpleStringSchema;
-import org.apache.flink.connector.aws.testutils.AWSServicesTestUtils;
+import org.apache.flink.connector.aws.config.AWSConfigConstants;
 import org.apache.flink.connector.aws.testutils.LocalstackContainer;
-import org.apache.flink.connector.aws.util.AWSGeneralUtil;
+import org.apache.flink.runtime.client.JobExecutionException;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.util.DockerImageVersions;
 
+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonProcessingException;
 import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;
 
+import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.ClassRule;
@@ -35,7 +37,6 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.testcontainers.utility.DockerImageName;
 import software.amazon.awssdk.core.SdkSystemSetting;
-import software.amazon.awssdk.http.async.SdkAsyncHttpClient;
 import software.amazon.awssdk.services.firehose.FirehoseAsyncClient;
 import software.amazon.awssdk.services.iam.IamAsyncClient;
 import software.amazon.awssdk.services.s3.S3AsyncClient;
@@ -44,12 +45,16 @@ import software.amazon.awssdk.utils.ImmutableMap;
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Properties;
 
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_CREDENTIALS_PROVIDER;
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_REGION;
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.TRUST_ALL_CERTIFICATES;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createBucket;
-import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createConfig;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createIAMRole;
-import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createIamClient;
-import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createS3Client;
+import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.getConfig;
+import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.getIamClient;
+import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.getS3Client;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.listBucketObjects;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.readObjectsFromS3Bucket;
 import static org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils.createDeliveryStream;
@@ -65,8 +70,9 @@ public class KinesisFirehoseSinkITCase {
     private static final String BUCKET_NAME = "s3-firehose";
     private static final String STREAM_NAME = "s3-stream";
     private static final int NUMBER_OF_ELEMENTS = 92;
+    private StreamExecutionEnvironment env;
+    private static final ObjectMapper MAPPER = new ObjectMapper();
 
-    private SdkAsyncHttpClient httpClient;
     private S3AsyncClient s3AsyncClient;
     private FirehoseAsyncClient firehoseAsyncClient;
     private IamAsyncClient iamAsyncClient;
@@ -78,21 +84,19 @@ public class KinesisFirehoseSinkITCase {
     @Before
     public void setup() throws Exception {
         System.setProperty(SdkSystemSetting.CBOR_ENABLED.property(), "false");
-        httpClient = AWSServicesTestUtils.createHttpClient(mockFirehoseContainer.getEndpoint());
-        s3AsyncClient = createS3Client(mockFirehoseContainer.getEndpoint(), httpClient);
-        firehoseAsyncClient = getFirehoseClient(mockFirehoseContainer.getEndpoint(), httpClient);
-        iamAsyncClient = createIamClient(mockFirehoseContainer.getEndpoint(), httpClient);
+        s3AsyncClient = getS3Client(mockFirehoseContainer.getEndpoint());
+        firehoseAsyncClient = getFirehoseClient(mockFirehoseContainer.getEndpoint());
+        iamAsyncClient = getIamClient(mockFirehoseContainer.getEndpoint());
+        env = StreamExecutionEnvironment.getExecutionEnvironment();
     }
 
     @After
     public void teardown() {
         System.clearProperty(SdkSystemSetting.CBOR_ENABLED.property());
-        AWSGeneralUtil.closeResources(
-                httpClient, s3AsyncClient, firehoseAsyncClient, iamAsyncClient);
     }
 
     @Test
-    public void eachElementArrivingAtSinkWillBeWrittenToFirehoseAtLeastOnce() throws Exception {
+    public void firehoseSinkWritesCorrectDataToMockAWSServices() throws Exception {
         LOG.info("1 - Creating the bucket for Firehose to deliver into...");
         createBucket(s3AsyncClient, BUCKET_NAME);
         LOG.info("2 - Creating the IAM Role for Firehose to write into the s3 bucket...");
@@ -100,39 +104,89 @@ public class KinesisFirehoseSinkITCase {
         LOG.info("3 - Creating the Firehose delivery stream...");
         createDeliveryStream(STREAM_NAME, BUCKET_NAME, ROLE_ARN, firehoseAsyncClient);
 
-        ObjectMapper mapper = new ObjectMapper();
-        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-
-        DataStream<String> generator =
-                env.fromSequence(1, NUMBER_OF_ELEMENTS)
-                        .map(Object::toString)
-                        .returns(String.class)
-                        .map(data -> mapper.writeValueAsString(ImmutableMap.of("data", data)));
-        List<String> expectedElements = new ArrayList<>();
-        for (int i = 1; i < NUMBER_OF_ELEMENTS; i++) {
-            expectedElements.add(
-                    mapper.writeValueAsString(ImmutableMap.of("data", String.valueOf(i))));
-        }
-
         KinesisFirehoseSink<String> kdsSink =
                 KinesisFirehoseSink.<String>builder()
                         .setSerializationSchema(new SimpleStringSchema())
                         .setDeliveryStreamName(STREAM_NAME)
                         .setMaxBatchSize(1)
-                        .setFirehoseClientProperties(
-                                createConfig(mockFirehoseContainer.getEndpoint()))
+                        .setFirehoseClientProperties(getConfig(mockFirehoseContainer.getEndpoint()))
                         .build();
 
-        generator.sinkTo(kdsSink);
+        getSampleDataGenerator().sinkTo(kdsSink);
         env.execute("Integration Test");
 
-        List<S3Object> objects = listBucketObjects(s3AsyncClient, BUCKET_NAME);
+        List<S3Object> objects =
+                listBucketObjects(getS3Client(mockFirehoseContainer.getEndpoint()), BUCKET_NAME);
+        assertThat(objects.size()).isEqualTo(NUMBER_OF_ELEMENTS);
         assertThat(
                         readObjectsFromS3Bucket(
                                 s3AsyncClient,
                                 objects,
                                 BUCKET_NAME,
                                 response -> new String(response.asByteArrayUnsafe())))
-                .containsAll(expectedElements);
+                .containsAll(getSampleDataGenerated());
+    }
+
+    @Test
+    public void firehoseSinkFailsWhenAccessKeyIdIsNotProvided() {
+        Properties properties = getConfig(mockFirehoseContainer.getEndpoint());
+        properties.setProperty(
+                AWS_CREDENTIALS_PROVIDER, AWSConfigConstants.CredentialProvider.BASIC.toString());
+        properties.remove(AWSConfigConstants.accessKeyId(AWS_CREDENTIALS_PROVIDER));
+        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+                properties, "Please set values for AWS Access Key ID");
+    }
+
+    @Test
+    public void firehoseSinkFailsWhenRegionIsNotProvided() {
+        Properties properties = getConfig(mockFirehoseContainer.getEndpoint());
+        properties.remove(AWS_REGION);
+        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+                properties, "region must not be null.");
+    }
+
+    @Test
+    public void firehoseSinkFailsWhenUnableToConnectToRemoteService() {
+        Properties properties = getConfig(mockFirehoseContainer.getEndpoint());
+        properties.remove(TRUST_ALL_CERTIFICATES);
+        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+                properties,
+                "Encountered non-recoverable exception relating to mis-configured client");
+    }
+
+    private void firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+            Properties properties, String errorMessage) {
+        KinesisFirehoseSink<String> kdsSink =
+                KinesisFirehoseSink.<String>builder()
+                        .setSerializationSchema(new SimpleStringSchema())
+                        .setDeliveryStreamName("non-existent-stream")
+                        .setMaxBatchSize(1)
+                        .setFirehoseClientProperties(properties)
+                        .build();
+
+        getSampleDataGenerator().sinkTo(kdsSink);
+
+        Assertions.assertThatExceptionOfType(JobExecutionException.class)
+                .isThrownBy(() -> env.execute("Integration Test"))
+                .havingCause()
+                .havingCause()
+                .withMessageContaining(errorMessage);
+    }
+
+    private DataStream<String> getSampleDataGenerator() {
+        ObjectMapper mapper = new ObjectMapper();
+        return env.fromSequence(1, NUMBER_OF_ELEMENTS)
+                .map(Object::toString)
+                .returns(String.class)
+                .map(data -> mapper.writeValueAsString(ImmutableMap.of("data", data)));
+    }
+
+    private List<String> getSampleDataGenerated() throws JsonProcessingException {
+        List<String> expectedElements = new ArrayList<>();
+        for (int i = 1; i <= NUMBER_OF_ELEMENTS; i++) {
+            expectedElements.add(
+                    MAPPER.writeValueAsString(ImmutableMap.of("data", String.valueOf(i))));
+        }
+        return expectedElements;
     }
 }
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifier.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifier.java
new file mode 100644
index 00000000000..71aa5dfdd0c
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifier.java
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.util;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.util.ExceptionUtils;
+
+import java.util.HashSet;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.function.Function;
+import java.util.function.Predicate;
+
+/** Classifier class for retryable exceptions on request submission failure. */
+@Internal
+public class RetryableExceptionClassifier {
+    private final Function<Throwable, Exception> throwableMapper;
+    private final Predicate<Throwable> validator;
+    private RetryableExceptionClassifier chainedClassifier;
+
+    public RetryableExceptionClassifier(
+            Predicate<Throwable> validator, Function<Throwable, Exception> throwableMapper) {
+        this.throwableMapper = throwableMapper;
+        this.validator = validator;
+        this.chainedClassifier = null;
+    }
+
+    public boolean shouldSuppress(Throwable err, Consumer<Exception> throwableConsumer) {
+        if (validator.test(err)) {
+            throwableConsumer.accept(throwableMapper.apply(err));
+            return false;
+        }
+
+        if (chainedClassifier != null) {
+            return chainedClassifier.shouldSuppress(err, throwableConsumer);
+        } else {
+            return true;
+        }
+    }
+
+    public static RetryableExceptionClassifier withRootCauseOfType(
+            Class<? extends Throwable> type, Function<Throwable, Exception> mapper) {
+        return new RetryableExceptionClassifier(
+                err -> ExceptionUtils.findThrowable(err, type).isPresent(), mapper);
+    }
+
+    public static RetryableExceptionClassifier createChain(
+            RetryableExceptionClassifier... classifiers) {
+        Set<RetryableExceptionClassifier> importedClassifiers = new HashSet<>();
+
+        RetryableExceptionClassifier taleClassifier = classifiers[0];
+        importedClassifiers.add(taleClassifier);
+
+        for (int i = 1; i < classifiers.length; ++i) {
+            if (importedClassifiers.contains(classifiers[i])) {
+                throw new IllegalArgumentException(
+                        "Wrong classifier chain; Circular chain of classifiers detected.");
+            }
+
+            taleClassifier.chainedClassifier = classifiers[i];
+            taleClassifier = classifiers[i];
+            importedClassifiers.add(taleClassifier);
+        }
+
+        return classifiers[0];
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkRetryableExceptionClassifiers.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkRetryableExceptionClassifiers.java
new file mode 100644
index 00000000000..b8933769590
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkRetryableExceptionClassifiers.java
@@ -0,0 +1,38 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
+import org.apache.flink.util.FlinkException;
+
+/** Common retry exception classifiers needed for common errors. */
+@Internal
+public class AsyncSinkRetryableExceptionClassifiers {
+    public static RetryableExceptionClassifier getInterruptedExceptionClassifier() {
+        return RetryableExceptionClassifier.withRootCauseOfType(
+                InterruptedException.class, err -> new FlinkException("Thread was interrupted"));
+    }
+
+    public static RetryableExceptionClassifier getGeneralExceptionClassifier() {
+        return RetryableExceptionClassifier.withRootCauseOfType(
+                Error.class,
+                err -> new RuntimeException("Encountered non-recoverable exception", err));
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifierTest.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifierTest.java
new file mode 100644
index 00000000000..a17bf637c0d
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifierTest.java
@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.util;
+
+import org.apache.flink.util.ExceptionUtils;
+
+import org.junit.jupiter.api.Test;
+
+import java.util.concurrent.atomic.AtomicReference;
+
+import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
+import static org.assertj.core.api.AssertionsForClassTypes.assertThat;
+
+/** Tests the RetryableExceptionClassifier of the Async Sink Writer. */
+public class RetryableExceptionClassifierTest {
+
+    private static Integer nullReference;
+
+    private static final RetryableExceptionClassifier ARITHMETIC_EXCEPTION_STRATEGY =
+            new RetryableExceptionClassifier(
+                    err -> ExceptionUtils.findThrowable(err, ArithmeticException.class).isPresent(),
+                    err ->
+                            new RuntimeException(
+                                    "Buffer manipulation calculations resulted in a calculation exception",
+                                    err));
+
+    private static final RetryableExceptionClassifier NULL_POINTER_EXCEPTION_STRATEGY =
+            new RetryableExceptionClassifier(
+                    err ->
+                            ExceptionUtils.findThrowable(err, NullPointerException.class)
+                                    .isPresent(),
+                    err ->
+                            new RuntimeException(
+                                    "Buffer manipulation calculations resulted in a reference exception",
+                                    err));
+
+    @Test
+    public void exceptionsAreWrappedInTheContainingExceptionWhenAMatchIsFound() {
+        AtomicReference<Exception> caughtExceptionReference = new AtomicReference<>();
+
+        ARITHMETIC_EXCEPTION_STRATEGY.shouldSuppress(
+                new ArithmeticException("Base arithmetic exception"),
+                caughtExceptionReference::set);
+
+        assertThatCaughtExceptionIsWrappedArithmeticDivByZeroException(
+                caughtExceptionReference.get());
+    }
+
+    @Test
+    public void noExceptionIsThrownIfTheExceptionDoesNotMatchTheOneExpected() {
+        AtomicReference<Exception> caughtException = new AtomicReference<>();
+        try {
+            System.out.print(nullReference.toString());
+        } catch (Exception e) {
+            ARITHMETIC_EXCEPTION_STRATEGY.shouldSuppress(e, caughtException::set);
+        }
+        assertThat(caughtException.get()).isNull();
+    }
+
+    @Test
+    public void chainedRetryStrategiesAcceptExceptionsOnTheFirstItemOfChain() {
+        RetryableExceptionClassifier retryableExceptionClassifier =
+                RetryableExceptionClassifier.createChain(
+                        ARITHMETIC_EXCEPTION_STRATEGY, NULL_POINTER_EXCEPTION_STRATEGY);
+        AtomicReference<Exception> caughtExceptionReference = new AtomicReference<>();
+
+        retryableExceptionClassifier.shouldSuppress(
+                new ArithmeticException("Base arithmetic exception"),
+                caughtExceptionReference::set);
+
+        assertThatCaughtExceptionIsWrappedArithmeticDivByZeroException(
+                caughtExceptionReference.get());
+    }
+
+    @Test
+    public void chainedRetryStrategiesAcceptExceptionsOnTheLastItemOfChain() {
+        RetryableExceptionClassifier retryableExceptionClassifier =
+                RetryableExceptionClassifier.createChain(
+                        ARITHMETIC_EXCEPTION_STRATEGY, NULL_POINTER_EXCEPTION_STRATEGY);
+        AtomicReference<Exception> caughtException = new AtomicReference<>();
+
+        retryableExceptionClassifier.shouldSuppress(
+                new NullPointerException("Base NullPointerException"), caughtException::set);
+
+        assertThat(caughtException.get())
+                .isInstanceOf(RuntimeException.class)
+                .hasMessage("Buffer manipulation calculations resulted in a reference exception")
+                .getCause()
+                .isInstanceOf(NullPointerException.class)
+                .hasMessage("Base NullPointerException");
+    }
+
+    @Test
+    public void circularChainStrategyThrowsException() {
+        assertThatExceptionOfType(IllegalArgumentException.class)
+                .isThrownBy(
+                        () ->
+                                RetryableExceptionClassifier.createChain(
+                                        ARITHMETIC_EXCEPTION_STRATEGY,
+                                        NULL_POINTER_EXCEPTION_STRATEGY,
+                                        ARITHMETIC_EXCEPTION_STRATEGY))
+                .withMessageContaining(
+                        "Wrong classifier chain; Circular chain of classifiers detected");
+    }
+
+    private void assertThatCaughtExceptionIsWrappedArithmeticDivByZeroException(
+            Exception caughtException) {
+        assertThat(caughtException)
+                .isInstanceOf(RuntimeException.class)
+                .hasMessage("Buffer manipulation calculations resulted in a calculation exception")
+                .getCause()
+                .isInstanceOf(ArithmeticException.class)
+                .hasMessage("Base arithmetic exception");
+    }
+}
