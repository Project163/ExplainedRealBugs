diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java
index 0b17a06a90f..1e04d01f8a6 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.runtime.scheduler.strategy;
 
+import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.runtime.execution.ExecutionState;
 import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;
 import org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID;
@@ -93,31 +94,41 @@ public class PipelinedRegionSchedulingStrategy implements SchedulingStrategy {
     }
 
     private void initCrossRegionConsumedPartitionGroups() {
-        Set<ConsumedPartitionGroup> visitedPartitionGroups =
-                Collections.newSetFromMap(new IdentityHashMap<>());
+        final Map<ConsumedPartitionGroup, Set<SchedulingPipelinedRegion>>
+                producerRegionsByConsumedPartitionGroup = new IdentityHashMap<>();
+
+        for (SchedulingPipelinedRegion pipelinedRegion :
+                schedulingTopology.getAllPipelinedRegions()) {
+            for (ConsumedPartitionGroup consumedPartitionGroup :
+                    pipelinedRegion.getAllBlockingConsumedPartitionGroups()) {
+                producerRegionsByConsumedPartitionGroup.computeIfAbsent(
+                        consumedPartitionGroup, this::getProducerRegionsForConsumedPartitionGroup);
+            }
+        }
 
         for (SchedulingPipelinedRegion pipelinedRegion :
                 schedulingTopology.getAllPipelinedRegions()) {
             for (ConsumedPartitionGroup consumedPartitionGroup :
                     pipelinedRegion.getAllBlockingConsumedPartitionGroups()) {
-                if (!visitedPartitionGroups.contains(consumedPartitionGroup)) {
-                    visitedPartitionGroups.add(consumedPartitionGroup);
-
-                    SchedulingPipelinedRegion producerRegion = null;
-                    for (IntermediateResultPartitionID partitionId : consumedPartitionGroup) {
-                        SchedulingPipelinedRegion region = getProducerRegion(partitionId);
-                        if (producerRegion == null) {
-                            producerRegion = region;
-                        } else if (producerRegion != region) {
-                            crossRegionConsumedPartitionGroups.add(consumedPartitionGroup);
-                            break;
-                        }
-                    }
+                final Set<SchedulingPipelinedRegion> producerRegions =
+                        producerRegionsByConsumedPartitionGroup.get(consumedPartitionGroup);
+                if (producerRegions.size() > 1 && producerRegions.contains(pipelinedRegion)) {
+                    crossRegionConsumedPartitionGroups.add(consumedPartitionGroup);
                 }
             }
         }
     }
 
+    private Set<SchedulingPipelinedRegion> getProducerRegionsForConsumedPartitionGroup(
+            ConsumedPartitionGroup consumedPartitionGroup) {
+        final Set<SchedulingPipelinedRegion> producerRegions =
+                Collections.newSetFromMap(new IdentityHashMap<>());
+        for (IntermediateResultPartitionID partitionId : consumedPartitionGroup) {
+            producerRegions.add(getProducerRegion(partitionId));
+        }
+        return producerRegions;
+    }
+
     private SchedulingPipelinedRegion getProducerRegion(IntermediateResultPartitionID partitionId) {
         return schedulingTopology.getPipelinedRegionOfVertex(
                 schedulingTopology.getResultPartition(partitionId).getProducer().getId());
@@ -312,6 +323,11 @@ public class PipelinedRegionSchedulingStrategy implements SchedulingStrategy {
                 schedulingTopology.getResultPartition(partitionId).getProducer().getId());
     }
 
+    @VisibleForTesting
+    Set<ConsumedPartitionGroup> getCrossRegionConsumedPartitionGroups() {
+        return Collections.unmodifiableSet(crossRegionConsumedPartitionGroups);
+    }
+
     /** The factory for creating {@link PipelinedRegionSchedulingStrategy}. */
     public static class Factory implements SchedulingStrategyFactory {
         @Override
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java
index 31cccacb781..a4336a53eab 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java
@@ -210,6 +210,68 @@ public class PipelinedRegionSchedulingStrategyTest extends TestLogger {
         assertLatestScheduledVerticesAreEqualTo(expectedScheduledVertices);
     }
 
+    @Test
+    public void testComputingCrossRegionConsumedPartitionGroupsCorrectly() throws Exception {
+        final JobVertex v1 = createJobVertex("v1", 4);
+        final JobVertex v2 = createJobVertex("v2", 3);
+        final JobVertex v3 = createJobVertex("v3", 2);
+
+        v2.connectNewDataSetAsInput(
+                v1, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);
+        v3.connectNewDataSetAsInput(
+                v2, DistributionPattern.POINTWISE, ResultPartitionType.BLOCKING);
+        v3.connectNewDataSetAsInput(
+                v1, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);
+
+        final List<JobVertex> ordered = new ArrayList<>(Arrays.asList(v1, v2, v3));
+        final JobGraph jobGraph =
+                JobGraphBuilder.newBatchJobGraphBuilder().addJobVertices(ordered).build();
+        final ExecutionGraph executionGraph =
+                TestingDefaultExecutionGraphBuilder.newBuilder().setJobGraph(jobGraph).build();
+
+        final SchedulingTopology schedulingTopology = executionGraph.getSchedulingTopology();
+
+        final PipelinedRegionSchedulingStrategy schedulingStrategy =
+                new PipelinedRegionSchedulingStrategy(
+                        testingSchedulerOperation, schedulingTopology);
+
+        final Set<ConsumedPartitionGroup> crossRegionConsumedPartitionGroups =
+                schedulingStrategy.getCrossRegionConsumedPartitionGroups();
+
+        assertEquals(1, crossRegionConsumedPartitionGroups.size());
+
+        final ConsumedPartitionGroup expected =
+                executionGraph
+                        .getJobVertex(v3.getID())
+                        .getTaskVertices()[1]
+                        .getAllConsumedPartitionGroups()
+                        .get(0);
+
+        assertTrue(crossRegionConsumedPartitionGroups.contains(expected));
+    }
+
+    @Test
+    public void testNoCrossRegionConsumedPartitionGroupsWithAllToAllBlockingEdge() {
+        final TestingSchedulingTopology topology = new TestingSchedulingTopology();
+
+        final List<TestingSchedulingExecutionVertex> producer =
+                topology.addExecutionVertices().withParallelism(4).finish();
+        final List<TestingSchedulingExecutionVertex> consumer =
+                topology.addExecutionVertices().withParallelism(4).finish();
+
+        topology.connectAllToAll(producer, consumer)
+                .withResultPartitionType(ResultPartitionType.BLOCKING)
+                .finish();
+
+        final PipelinedRegionSchedulingStrategy schedulingStrategy =
+                new PipelinedRegionSchedulingStrategy(testingSchedulerOperation, topology);
+
+        final Set<ConsumedPartitionGroup> crossRegionConsumedPartitionGroups =
+                schedulingStrategy.getCrossRegionConsumedPartitionGroups();
+
+        assertEquals(0, crossRegionConsumedPartitionGroups.size());
+    }
+
     @Test
     public void testSchedulingTopologyWithCrossRegionConsumedPartitionGroups() throws Exception {
         final JobVertex v1 = createJobVertex("v1", 4);
