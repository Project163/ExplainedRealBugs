diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java
index d8a2baa2610..3177bd5f9f4 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/channel/RecoveredChannelStateHandler.java
@@ -26,7 +26,6 @@ import org.apache.flink.runtime.io.network.buffer.Buffer;
 import org.apache.flink.runtime.io.network.buffer.BufferBuilder;
 import org.apache.flink.runtime.io.network.buffer.BufferConsumer;
 import org.apache.flink.runtime.io.network.partition.CheckpointedResultPartition;
-import org.apache.flink.runtime.io.network.partition.CheckpointedResultSubpartition;
 import org.apache.flink.runtime.io.network.partition.consumer.InputChannel;
 import org.apache.flink.runtime.io.network.partition.consumer.InputGate;
 import org.apache.flink.runtime.io.network.partition.consumer.RecoveredInputChannel;
@@ -162,8 +161,8 @@ class ResultSubpartitionRecoveredStateHandler
 
     private final InflightDataRescalingDescriptor channelMapping;
 
-    private final Map<ResultSubpartitionInfo, List<CheckpointedResultSubpartition>>
-            rescaledChannels = new HashMap<>();
+    private final Map<ResultSubpartitionInfo, List<ResultSubpartitionInfo>> rescaledChannels =
+            new HashMap<>();
     private final Map<Integer, RescaleMappings> oldToNewMappings = new HashMap<>();
 
     ResultSubpartitionRecoveredStateHandler(
@@ -179,8 +178,9 @@ class ResultSubpartitionRecoveredStateHandler
     public BufferWithContext<BufferBuilder> getBuffer(ResultSubpartitionInfo subpartitionInfo)
             throws IOException, InterruptedException {
         // request the buffer from any mapped subpartition as they all will receive the same buffer
-        final List<CheckpointedResultSubpartition> channels = getMappedChannels(subpartitionInfo);
-        BufferBuilder bufferBuilder = channels.get(0).requestBufferBuilderBlocking();
+        BufferBuilder bufferBuilder =
+                getCheckpointedResultPartition(subpartitionInfo.getPartitionIdx())
+                        .requestBufferBuilderBlocking();
         return new BufferWithContext<>(wrap(bufferBuilder), bufferBuilder);
     }
 
@@ -190,51 +190,60 @@ class ResultSubpartitionRecoveredStateHandler
             int oldSubtaskIndex,
             BufferWithContext<BufferBuilder> bufferWithContext)
             throws IOException {
-        try (BufferBuilder bufferBuilder = bufferWithContext.context) {
-            try (BufferConsumer bufferConsumer =
-                    bufferBuilder.createBufferConsumerFromBeginning()) {
-                bufferBuilder.finish();
-                if (bufferConsumer.isDataAvailable()) {
-                    final List<CheckpointedResultSubpartition> channels =
-                            getMappedChannels(subpartitionInfo);
-                    for (final CheckpointedResultSubpartition channel : channels) {
-                        // channel selector is created from the downstream's point of view: the
-                        // subtask of downstream = subpartition index of recovered buffer
-                        final SubtaskConnectionDescriptor channelSelector =
-                                new SubtaskConnectionDescriptor(
-                                        subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);
-                        channel.addRecovered(
-                                EventSerializer.toBufferConsumer(channelSelector, false));
-                        channel.addRecovered(bufferConsumer.copy());
-                    }
-                }
+        try (BufferBuilder bufferBuilder = bufferWithContext.context;
+                BufferConsumer bufferConsumer = bufferBuilder.createBufferConsumerFromBeginning()) {
+            bufferBuilder.finish();
+            if (!bufferConsumer.isDataAvailable()) {
+                return;
+            }
+            final List<ResultSubpartitionInfo> mappedSubpartitions =
+                    getMappedSubpartitions(subpartitionInfo);
+            CheckpointedResultPartition checkpointedResultPartition =
+                    getCheckpointedResultPartition(subpartitionInfo.getPartitionIdx());
+            for (final ResultSubpartitionInfo mappedSubpartition : mappedSubpartitions) {
+                // channel selector is created from the downstream's point of view: the
+                // subtask of downstream = subpartition index of recovered buffer
+                final SubtaskConnectionDescriptor channelSelector =
+                        new SubtaskConnectionDescriptor(
+                                subpartitionInfo.getSubPartitionIdx(), oldSubtaskIndex);
+                checkpointedResultPartition.addRecovered(
+                        mappedSubpartition.getSubPartitionIdx(),
+                        EventSerializer.toBufferConsumer(channelSelector, false));
+                checkpointedResultPartition.addRecovered(
+                        mappedSubpartition.getSubPartitionIdx(), bufferConsumer.copy());
             }
         }
     }
 
-    private CheckpointedResultSubpartition getSubpartition(
-            int partitionIndex, int subPartitionIdx) {
+    private ResultSubpartitionInfo getSubpartitionInfo(int partitionIndex, int subPartitionIdx) {
+        CheckpointedResultPartition writer = getCheckpointedResultPartition(partitionIndex);
+        return writer.getCheckpointedSubpartitionInfo(subPartitionIdx);
+    }
+
+    private CheckpointedResultPartition getCheckpointedResultPartition(int partitionIndex) {
         ResultPartitionWriter writer = writers[partitionIndex];
         if (!(writer instanceof CheckpointedResultPartition)) {
             throw new IllegalStateException(
                     "Cannot restore state to a non-checkpointable partition type: " + writer);
         }
-        return ((CheckpointedResultPartition) writer).getCheckpointedSubpartition(subPartitionIdx);
+        return (CheckpointedResultPartition) writer;
     }
 
-    private List<CheckpointedResultSubpartition> getMappedChannels(
+    private List<ResultSubpartitionInfo> getMappedSubpartitions(
             ResultSubpartitionInfo subpartitionInfo) {
         return rescaledChannels.computeIfAbsent(subpartitionInfo, this::calculateMapping);
     }
 
-    private List<CheckpointedResultSubpartition> calculateMapping(ResultSubpartitionInfo info) {
+    private List<ResultSubpartitionInfo> calculateMapping(ResultSubpartitionInfo info) {
         final RescaleMappings oldToNewMapping =
                 oldToNewMappings.computeIfAbsent(
                         info.getPartitionIdx(),
                         idx -> channelMapping.getChannelMapping(idx).invert());
-        final List<CheckpointedResultSubpartition> subpartitions =
+        final List<ResultSubpartitionInfo> subpartitions =
                 Arrays.stream(oldToNewMapping.getMappedIndexes(info.getSubPartitionIdx()))
-                        .mapToObj(newIndexes -> getSubpartition(info.getPartitionIdx(), newIndexes))
+                        .mapToObj(
+                                newIndexes ->
+                                        getSubpartitionInfo(info.getPartitionIdx(), newIndexes))
                         .collect(Collectors.toList());
         if (subpartitions.isEmpty()) {
             throw new IllegalStateException(
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java
index b9d8d5105a2..b59893b0ea8 100755
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java
@@ -179,15 +179,17 @@ final class BoundedBlockingSubpartition extends ResultSubpartition {
     }
 
     @Override
-    public void finish() throws IOException {
+    public int finish() throws IOException {
         checkState(!isReleased, "data partition already released");
         checkState(!isFinished, "data partition already finished");
 
         isFinished = true;
         flushCurrentBuffer();
-        writeAndCloseBufferConsumer(
-                EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE, false));
+        BufferConsumer eventBufferConsumer =
+                EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE, false);
+        writeAndCloseBufferConsumer(eventBufferConsumer);
         data.finishWrite();
+        return eventBufferConsumer.getWrittenBytes();
     }
 
     @Override
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/CheckpointedResultPartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/CheckpointedResultPartition.java
index caf008b29e7..7f5c6b09510 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/CheckpointedResultPartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/CheckpointedResultPartition.java
@@ -18,6 +18,10 @@
 
 package org.apache.flink.runtime.io.network.partition;
 
+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;
+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;
+import org.apache.flink.runtime.io.network.buffer.BufferConsumer;
+
 import java.io.IOException;
 
 /**
@@ -26,8 +30,13 @@ import java.io.IOException;
  */
 public interface CheckpointedResultPartition {
 
-    /** Gets the checkpointed subpartition with the given subpartitionIndex. */
-    CheckpointedResultSubpartition getCheckpointedSubpartition(int subpartitionIndex);
+    /** Gets the checkpointed subpartition info with the given subpartitionIndex. */
+    ResultSubpartitionInfo getCheckpointedSubpartitionInfo(int subpartitionIndex);
 
     void finishReadRecoveredState(boolean notifyAndBlockOnCompletion) throws IOException;
+
+    BufferBuilder requestBufferBuilderBlocking()
+            throws IOException, RuntimeException, InterruptedException;
+
+    void addRecovered(int subpartitionIndex, BufferConsumer bufferConsumer) throws IOException;
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/CheckpointedResultSubpartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/CheckpointedResultSubpartition.java
deleted file mode 100644
index a8700b33a8a..00000000000
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/CheckpointedResultSubpartition.java
+++ /dev/null
@@ -1,41 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.runtime.io.network.partition;
-
-import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;
-import org.apache.flink.runtime.io.network.buffer.BufferBuilder;
-import org.apache.flink.runtime.io.network.buffer.BufferConsumer;
-
-import java.io.IOException;
-
-/**
- * Interface for subpartitions that are checkpointed, meaning they store data as part of unaligned
- * checkpoints.
- */
-public interface CheckpointedResultSubpartition {
-
-    ResultSubpartitionInfo getSubpartitionInfo();
-
-    BufferBuilder requestBufferBuilderBlocking()
-            throws IOException, RuntimeException, InterruptedException;
-
-    void addRecovered(BufferConsumer bufferConsumer) throws IOException;
-
-    void finishReadRecoveredState(boolean notifyAndBlockOnCompletion) throws IOException;
-}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedApproximateSubpartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedApproximateSubpartition.java
index 8fbf5883ae2..460b6a9d58d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedApproximateSubpartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedApproximateSubpartition.java
@@ -27,8 +27,6 @@ import org.slf4j.LoggerFactory;
 
 import javax.annotation.concurrent.GuardedBy;
 
-import java.io.IOException;
-
 import static org.apache.flink.util.Preconditions.checkState;
 
 /**
@@ -104,9 +102,8 @@ public class PipelinedApproximateSubpartition extends PipelinedSubpartition {
     }
 
     @Override
-    public void finishReadRecoveredState(boolean notifyAndBlockOnCompletion) throws IOException {
-        // The Approximate Local Recovery can not work with unaligned checkpoint for now, so no need
-        // to recover channel state
+    public boolean isSupportChannelStateRecover() {
+        return false;
     }
 
     /** for testing only. */
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedResultPartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedResultPartition.java
index 0654f57cecc..12de80e29e4 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedResultPartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedResultPartition.java
@@ -19,10 +19,16 @@
 package org.apache.flink.runtime.io.network.partition;
 
 import org.apache.flink.runtime.checkpoint.channel.ChannelStateWriter;
+import org.apache.flink.runtime.checkpoint.channel.ResultSubpartitionInfo;
 import org.apache.flink.runtime.io.network.api.EndOfData;
 import org.apache.flink.runtime.io.network.api.StopMode;
+import org.apache.flink.runtime.io.network.api.serialization.EventSerializer;
+import org.apache.flink.runtime.io.network.buffer.BufferBuilder;
 import org.apache.flink.runtime.io.network.buffer.BufferCompressor;
+import org.apache.flink.runtime.io.network.buffer.BufferConsumer;
 import org.apache.flink.runtime.io.network.buffer.BufferPool;
+import org.apache.flink.runtime.io.network.logger.NetworkActionsLogger;
+import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;
 import org.apache.flink.util.function.SupplierWithException;
 
 import javax.annotation.Nullable;
@@ -179,8 +185,8 @@ public class PipelinedResultPartition extends BufferWritingResultPartition
     }
 
     @Override
-    public CheckpointedResultSubpartition getCheckpointedSubpartition(int subpartitionIndex) {
-        return (CheckpointedResultSubpartition) subpartitions[subpartitionIndex];
+    public ResultSubpartitionInfo getCheckpointedSubpartitionInfo(int subpartitionIndex) {
+        return subpartitions[subpartitionIndex].getSubpartitionInfo();
     }
 
     @Override
@@ -252,9 +258,38 @@ public class PipelinedResultPartition extends BufferWritingResultPartition
 
     @Override
     public void finishReadRecoveredState(boolean notifyAndBlockOnCompletion) throws IOException {
-        for (ResultSubpartition subpartition : subpartitions) {
-            ((CheckpointedResultSubpartition) subpartition)
-                    .finishReadRecoveredState(notifyAndBlockOnCompletion);
+        if (!notifyAndBlockOnCompletion) {
+            return;
+        }
+        try (BufferConsumer eventBufferConsumer =
+                EventSerializer.toBufferConsumer(EndOfChannelStateEvent.INSTANCE, false)) {
+            for (ResultSubpartition resultSubpartition : subpartitions) {
+                PipelinedSubpartition subpartition = (PipelinedSubpartition) resultSubpartition;
+                if (subpartition.isSupportChannelStateRecover()) {
+                    subpartition.add(eventBufferConsumer.copy(), 0);
+                }
+            }
+        }
+    }
+
+    @Override
+    public BufferBuilder requestBufferBuilderBlocking()
+            throws IOException, RuntimeException, InterruptedException {
+        return getBufferPool().requestBufferBuilderBlocking();
+    }
+
+    @Override
+    public void addRecovered(int subpartitionIndex, BufferConsumer bufferConsumer)
+            throws IOException {
+        ResultSubpartition subpartition = subpartitions[subpartitionIndex];
+        NetworkActionsLogger.traceRecover(
+                "PipelinedSubpartition#addRecovered",
+                bufferConsumer,
+                getOwningTaskName(),
+                subpartition.subpartitionInfo);
+        if (subpartition.add(bufferConsumer, Integer.MIN_VALUE)
+                == ResultSubpartition.ADD_BUFFER_ERROR_CODE) {
+            throw new IOException("Buffer consumer couldn't be added to ResultSubpartition");
         }
     }
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java
index 8050853aa5c..b20e099b783 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java
@@ -26,11 +26,9 @@ import org.apache.flink.runtime.io.network.api.CheckpointBarrier;
 import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;
 import org.apache.flink.runtime.io.network.api.serialization.EventSerializer;
 import org.apache.flink.runtime.io.network.buffer.Buffer;
-import org.apache.flink.runtime.io.network.buffer.BufferBuilder;
 import org.apache.flink.runtime.io.network.buffer.BufferConsumer;
 import org.apache.flink.runtime.io.network.buffer.BufferConsumerWithPartialRecordLength;
 import org.apache.flink.runtime.io.network.logger.NetworkActionsLogger;
-import org.apache.flink.runtime.io.network.partition.consumer.EndOfChannelStateEvent;
 
 import org.apache.flink.shaded.guava31.com.google.common.collect.Iterators;
 
@@ -69,8 +67,7 @@ import static org.apache.flink.util.Preconditions.checkState;
  * PipelinedSubpartitionView#notifyDataAvailable() notification} for any {@link BufferConsumer}
  * present in the queue.
  */
-public class PipelinedSubpartition extends ResultSubpartition
-        implements CheckpointedResultSubpartition, ChannelStateHolder {
+public class PipelinedSubpartition extends ResultSubpartition implements ChannelStateHolder {
 
     private static final Logger LOG = LoggerFactory.getLogger(PipelinedSubpartition.class);
 
@@ -158,29 +155,17 @@ public class PipelinedSubpartition extends ResultSubpartition
         return add(bufferConsumer, partialRecordLength, false);
     }
 
-    @Override
-    public void addRecovered(BufferConsumer bufferConsumer) throws IOException {
-        NetworkActionsLogger.traceRecover(
-                "PipelinedSubpartition#addRecovered",
-                bufferConsumer,
-                parent.getOwningTaskName(),
-                subpartitionInfo);
-        if (add(bufferConsumer, Integer.MIN_VALUE) == ADD_BUFFER_ERROR_CODE) {
-            throw new IOException("Buffer consumer couldn't be added to ResultSubpartition");
-        }
+    public boolean isSupportChannelStateRecover() {
+        return true;
     }
 
     @Override
-    public void finishReadRecoveredState(boolean notifyAndBlockOnCompletion) throws IOException {
-        if (notifyAndBlockOnCompletion) {
-            add(EventSerializer.toBufferConsumer(EndOfChannelStateEvent.INSTANCE, false), 0, false);
-        }
-    }
-
-    @Override
-    public void finish() throws IOException {
-        add(EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE, false), 0, true);
+    public int finish() throws IOException {
+        BufferConsumer eventBufferConsumer =
+                EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE, false);
+        add(eventBufferConsumer, 0, true);
         LOG.debug("{}: Finished {}.", parent.getOwningTaskName(), this);
+        return eventBufferConsumer.getWrittenBytes();
     }
 
     private int add(BufferConsumer bufferConsumer, int partialRecordLength, boolean finish) {
@@ -800,11 +785,6 @@ public class PipelinedSubpartition extends ResultSubpartition
         return Math.max(0, numBuffers - 1);
     }
 
-    @Override
-    public BufferBuilder requestBufferBuilderBlocking() throws InterruptedException {
-        return parent.getBufferPool().requestBufferBuilderBlocking();
-    }
-
     Buffer buildSliceBuffer(BufferConsumerWithPartialRecordLength buffer) {
         return buffer.build();
     }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultSubpartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultSubpartition.java
index 03fee8d303a..712552debe7 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultSubpartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/ResultSubpartition.java
@@ -97,7 +97,12 @@ public abstract class ResultSubpartition {
 
     public abstract void flush();
 
-    public abstract void finish() throws IOException;
+    /**
+     * Writing of data is finished.
+     *
+     * @return the size of data written for this subpartition inside of finish.
+     */
+    public abstract int finish() throws IOException;
 
     public abstract void release() throws IOException;
 
