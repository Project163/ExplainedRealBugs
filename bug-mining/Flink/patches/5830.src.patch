diff --git a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/FlinkKafkaInternalProducer.java b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/FlinkKafkaInternalProducer.java
index c04f73e01e6..4856222dd02 100644
--- a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/FlinkKafkaInternalProducer.java
+++ b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/FlinkKafkaInternalProducer.java
@@ -101,8 +101,16 @@ class FlinkKafkaInternalProducer<K, V> extends KafkaProducer<K, V> {
     @Override
     public void close() {
         closed = true;
-        flush();
-        super.close(Duration.ZERO);
+        if (inTransaction) {
+            // This is state is most likely reached in case of a failure.
+            // If this producer is still in transaction, it should be committing.
+            // However, at this point, we cannot decide that and we shouldn't prolong cancellation.
+            // So hard kill this producer with all resources.
+            super.close(Duration.ZERO);
+        } else {
+            // If this is outside of a transaction, we should be able to cleanly shutdown.
+            super.close(Duration.ofHours(1));
+        }
     }
 
     @Override
diff --git a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaWriter.java b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaWriter.java
index 8be56f88d19..b13a51f92e8 100644
--- a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaWriter.java
+++ b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaWriter.java
@@ -38,6 +38,7 @@ import org.apache.kafka.clients.producer.Producer;
 import org.apache.kafka.clients.producer.ProducerRecord;
 import org.apache.kafka.common.Metric;
 import org.apache.kafka.common.MetricName;
+import org.apache.kafka.common.errors.ProducerFencedException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -54,6 +55,7 @@ import java.util.Properties;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.function.Consumer;
 
+import static org.apache.flink.util.IOUtils.closeAll;
 import static org.apache.flink.util.Preconditions.checkNotNull;
 import static org.apache.flink.util.Preconditions.checkState;
 
@@ -206,14 +208,26 @@ class KafkaWriter<IN> implements SinkWriter<IN, KafkaCommittable, KafkaWriterSta
 
     @Override
     public void close() throws Exception {
+        closed = true;
+        closeAll(
+                this::abortCurrentProducer,
+                closer,
+                producerPool::clear,
+                () -> {
+                    checkState(currentProducer.isClosed());
+                    currentProducer = null;
+                });
+    }
+
+    private void abortCurrentProducer() {
         if (currentProducer.isInTransaction()) {
-            currentProducer.abortTransaction();
+            try {
+                currentProducer.abortTransaction();
+            } catch (ProducerFencedException e) {
+                LOG.debug(
+                        "Producer {} fenced while aborting", currentProducer.getTransactionalId());
+            }
         }
-        closed = true;
-        closer.close();
-        producerPool.clear();
-        checkState(currentProducer.isClosed());
-        currentProducer = null;
     }
 
     @VisibleForTesting
