diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/udf/RangeBoundaryBuilder.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/udf/RangeBoundaryBuilder.java
index cd163d335e8..09bd42d3d41 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/udf/RangeBoundaryBuilder.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/udf/RangeBoundaryBuilder.java
@@ -60,13 +60,15 @@ public class RangeBoundaryBuilder<T> extends RichMapPartitionFunction<T, Object[
 
 		int boundarySize = parallelism - 1;
 		Object[][] boundaries = new Object[boundarySize][];
-		double avgRange = sampledData.size() / (double) parallelism;
-		int numKey = comparator.getFlatComparators().length;
-		for (int i = 1; i < parallelism; i++) {
-			T record = sampledData.get((int) (i * avgRange));
-			Object[] keys = new Object[numKey];
-			comparator.extractKeys(record, keys, 0);
-			boundaries[i-1] = keys;
+		if (sampledData.size() > 0) {
+			double avgRange = sampledData.size() / (double) parallelism;
+			int numKey = comparator.getFlatComparators().length;
+			for (int i = 1; i < parallelism; i++) {
+				T record = sampledData.get((int) (i * avgRange));
+				Object[] keys = new Object[numKey];
+				comparator.extractKeys(record, keys, 0);
+				boundaries[i-1] = keys;
+			}
 		}
 
 		out.collect(boundaries);
diff --git a/flink-tests/src/test/scala/org/apache/flink/api/scala/operators/PartitionITCase.scala b/flink-tests/src/test/scala/org/apache/flink/api/scala/operators/PartitionITCase.scala
index ca8bcd99966..df13cd43125 100644
--- a/flink-tests/src/test/scala/org/apache/flink/api/scala/operators/PartitionITCase.scala
+++ b/flink-tests/src/test/scala/org/apache/flink/api/scala/operators/PartitionITCase.scala
@@ -49,6 +49,38 @@ class PartitionITCase(mode: TestExecutionMode) extends MultipleProgramsTestBase(
     TestBaseUtils.compareResultsByLinesInMemory(expected, resultPath)
   }
 
+  @Test
+  def testEmptyHashPartition(): Unit = {
+    /*
+     * Test hash partition by tuple field
+     */
+    val env = ExecutionEnvironment.getExecutionEnvironment
+    val ds = env.fromCollection(Seq[Tuple1[String]]())
+
+    val unique = ds.partitionByHash(0)
+
+    unique.writeAsText(resultPath, WriteMode.OVERWRITE)
+    env.execute()
+
+    expected = ""
+  }
+
+  @Test
+  def testEmptyRangePartition(): Unit = {
+    /*
+     * Test hash partition by tuple field
+     */
+    val env = ExecutionEnvironment.getExecutionEnvironment
+    val ds = env.fromCollection(Seq[Tuple1[String]]())
+
+    val unique = ds.partitionByRange(0)
+
+    unique.writeAsText(resultPath, WriteMode.OVERWRITE)
+    env.execute()
+
+    expected = ""
+  }
+
   @Test
   def testHashPartitionByTupleField(): Unit = {
     /*
