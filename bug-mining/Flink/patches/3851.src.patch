diff --git a/flink-end-to-end-tests/run-nightly-tests.sh b/flink-end-to-end-tests/run-nightly-tests.sh
index a8957407475..d6a691f44d4 100755
--- a/flink-end-to-end-tests/run-nightly-tests.sh
+++ b/flink-end-to-end-tests/run-nightly-tests.sh
@@ -113,6 +113,8 @@ if [[ ${PROFILE} != *"jdk11"* ]]; then
 	run_test "Run Kubernetes test" "$END_TO_END_DIR/test-scripts/test_kubernetes_embedded_job.sh"
 	run_test "Run kubernetes session test" "$END_TO_END_DIR/test-scripts/test_kubernetes_session.sh"
 
+	run_test "Running Flink over NAT end-to-end test" "$END_TO_END_DIR/test-scripts/test_nat.sh" "skip_check_exceptions"
+
 	if [[ $PROFILE == *"include-hadoop"* ]]; then
 		run_test "Run Mesos WordCount test" "$END_TO_END_DIR/test-scripts/test_mesos_wordcount.sh"
 		run_test "Run Mesos multiple submission test" "$END_TO_END_DIR/test-scripts/test_mesos_multiple_submissions.sh"
diff --git a/flink-end-to-end-tests/test-scripts/container-scripts/docker-compose.nat.yml b/flink-end-to-end-tests/test-scripts/container-scripts/docker-compose.nat.yml
new file mode 100644
index 00000000000..943291c26df
--- /dev/null
+++ b/flink-end-to-end-tests/test-scripts/container-scripts/docker-compose.nat.yml
@@ -0,0 +1,90 @@
+################################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one
+#  or more contributor license agreements.  See the NOTICE file
+#  distributed with this work for additional information
+#  regarding copyright ownership.  The ASF licenses this file
+#  to you under the Apache License, Version 2.0 (the
+#  "License"); you may not use this file except in compliance
+#  with the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+# limitations under the License.
+################################################################################
+
+# Docker compose file for a Flink job cluster deployment with NAT network.
+#
+# All the network traffics are intended to go through the Docker host. NAT port mapping is simulated by publishing
+# internal container ports to different external Docker host ports. A container's external hostname is simulated
+# resolvable to all other containers except itself, by adding extra hosts to other containers that maps the hostname to
+# the IP address of the Docker host. 
+#
+# Parameters:
+# * FLINK_DOCKER_IMAGE_NAME - Image name to use for the deployment (default: flink-job:latest)
+# * FLINK_JOB - Name of the Flink job to execute (default: none)
+# * FLINK_JOB_ARGUMENTS - Additional arguments which will be passed to the job cluster (default: none)
+#
+# * INPUT_VOLUME - Volume to be mounted for input.
+# * OUTPUT_VOLUME - Volume to be mounted for output.
+# * INPUT_PATH - Path inside container for the input.
+# * OUTPUT_PATH - Path outside container for the input.
+#
+# * HOST_IP - IP address of the Docker host. This will be used for resolving JM/TM external addresses.
+# * JM_EX_HOSTNAME - External hostname for JM.
+# * TM_1_EX_HOSTNAME - External hostname for TM 1.
+# * TM_2_EX_HOSTNAME - External hostname for TM 2.
+#
+# * JM_RPC_EX_PORT - External RPC port for JM.
+# * JM_RPC_IN_PORT - Internal RPC port for JM.
+# * TM_1_RPC_EX_PORT - External RPC port for TM 1.
+# * TM_2_RPC_EX_PORT - External RPC port for TM 2.
+# * TM_RPC_IN_PORT - Internal RPC port for both TMs.
+#
+# * TM_1_DATA_EX_PORT - External data port for TM 1.
+# * TM_2_DATA_EX_PORT - External data port for TM 2.
+# * TM_DATA_IN_PORT - Internal data port for both TMs.
+
+version: "2.2"
+services:
+  job-cluster:
+    image: ${FLINK_DOCKER_IMAGE_NAME:-flink-job}
+    ports:
+      - "8081:8081"
+      - ${JM_RPC_EX_PORT}:${JM_RPC_IN_PORT}
+    volumes:
+      - ${INPUT_VOLUME}:${INPUT_PATH}
+      - ${OUTPUT_VOLUME}:${OUTPUT_PATH}
+    command: job-cluster --job-classname ${FLINK_JOB} -Dparallelism.default=2 -Djobmanager.rpc.address=${JM_EX_HOSTNAME} -Djobmanager.bind-host=0.0.0.0 -Djobmanager.rpc.port=${JM_RPC_EX_PORT} -Djobmanager.rpc.bind-port=${JM_RPC_IN_PORT} ${FLINK_JOB_ARGUMENTS}
+    extra_hosts:
+      - ${TM_1_EX_HOSTNAME}:${HOST_IP}
+      - ${TM_2_EX_HOSTNAME}:${HOST_IP}
+
+  taskmanager1:
+    image: ${FLINK_DOCKER_IMAGE_NAME:-flink-job}
+    ports:
+      - ${TM_1_RPC_EX_PORT}:${TM_RPC_IN_PORT}
+      - ${TM_1_DATA_EX_PORT}:${TM_DATA_IN_PORT}
+    volumes:
+      - ${INPUT_VOLUME}:${INPUT_PATH}
+      - ${OUTPUT_VOLUME}:${OUTPUT_PATH}
+    command: task-manager -Djobmanager.rpc.address=${JM_EX_HOSTNAME} -Djobmanager.rpc.port=${JM_RPC_EX_PORT} -Dtaskmanager.host=${TM_1_EX_HOSTNAME} -Dtaskmanager.bind-host=0.0.0.0 -Dtaskmanager.rpc.port=${TM_1_RPC_EX_PORT} -Dtaskmanager.rpc.bind-port=${TM_RPC_IN_PORT} -Dtaskmanager.data.port=${TM_1_DATA_EX_PORT} -Dtaskmanager.data.bind-port=${TM_DATA_IN_PORT}
+    extra_hosts:
+      - ${JM_EX_HOSTNAME}:${HOST_IP}
+      - ${TM_2_EX_HOSTNAME}:${HOST_IP}
+
+  taskmanager2:
+    image: ${FLINK_DOCKER_IMAGE_NAME:-flink-job}
+    ports:
+      - ${TM_2_RPC_EX_PORT}:${TM_RPC_IN_PORT}
+      - ${TM_2_DATA_EX_PORT}:${TM_DATA_IN_PORT}
+    volumes:
+      - ${INPUT_VOLUME}:${INPUT_PATH}
+      - ${OUTPUT_VOLUME}:${OUTPUT_PATH}
+    command: task-manager -Djobmanager.rpc.address=${JM_EX_HOSTNAME} -Djobmanager.rpc.port=${JM_RPC_EX_PORT} -Dtaskmanager.host=${TM_2_EX_HOSTNAME} -Dtaskmanager.bind-host=0.0.0.0 -Dtaskmanager.rpc.port=${TM_2_RPC_EX_PORT} -Dtaskmanager.rpc.bind-port=${TM_RPC_IN_PORT} -Dtaskmanager.data.port=${TM_2_DATA_EX_PORT} -Dtaskmanager.data.bind-port=${TM_DATA_IN_PORT}
+    extra_hosts:
+      - ${JM_EX_HOSTNAME}:${HOST_IP}
+      - ${TM_1_EX_HOSTNAME}:${HOST_IP}
diff --git a/flink-end-to-end-tests/test-scripts/test_nat.sh b/flink-end-to-end-tests/test-scripts/test_nat.sh
new file mode 100755
index 00000000000..ace023f8090
--- /dev/null
+++ b/flink-end-to-end-tests/test-scripts/test_nat.sh
@@ -0,0 +1,77 @@
+#!/usr/bin/env bash
+################################################################################
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+################################################################################
+
+source "$(dirname "$0")"/common.sh
+source "$(dirname "$0")"/common_docker.sh
+
+DOCKER_MODULE_DIR=${END_TO_END_DIR}/../flink-container/docker
+DOCKER_SCRIPTS=${END_TO_END_DIR}/test-scripts/container-scripts
+DOCKER_IMAGE_BUILD_RETRIES=3
+BUILD_BACKOFF_TIME=5
+
+export FLINK_JOB=org.apache.flink.examples.java.wordcount.WordCount
+export FLINK_DOCKER_IMAGE_NAME=test_nat
+export INPUT_VOLUME=${END_TO_END_DIR}/test-scripts/test-data
+export OUTPUT_VOLUME=${TEST_DATA_DIR}/out
+export INPUT_PATH=/data/test/input
+export OUTPUT_PATH=/data/test/output
+
+export HOST_IP=$(get_node_ip | awk '{print $1}')
+export JM_EX_HOSTNAME=jm.flink.test
+export TM_1_EX_HOSTNAME=tm1.flink.test
+export TM_2_EX_HOSTNAME=tm2.flink.test
+
+export JM_RPC_EX_PORT=10000
+export JM_RPC_IN_PORT=10000
+
+export TM_1_RPC_EX_PORT=10001
+export TM_2_RPC_EX_PORT=10002
+export TM_RPC_IN_PORT=10000
+
+export TM_1_DATA_EX_PORT=11001
+export TM_2_DATA_EX_PORT=11002
+export TM_DATA_IN_PORT=11000
+
+RESULT_HASH="72a690412be8928ba239c2da967328a5"
+INPUT_ARGS="--input ${INPUT_PATH}/words"
+OUTPUT_PREFIX="docker_wc_out"
+
+export FLINK_JOB_ARGUMENTS="${INPUT_ARGS} --output ${OUTPUT_PATH}/${OUTPUT_PREFIX}"
+
+build_image() {
+    build_image_with_jar ${FLINK_DIR}/examples/batch/WordCount.jar ${FLINK_DOCKER_IMAGE_NAME}
+}
+
+# user inside the container must be able to create files, this is a workaround in-container permissions
+mkdir -p $OUTPUT_VOLUME
+chmod 777 $OUTPUT_VOLUME
+
+pushd "$DOCKER_MODULE_DIR"
+if ! retry_times $DOCKER_IMAGE_BUILD_RETRIES ${BUILD_BACKOFF_TIME} build_image; then
+    echo "Failed to build docker image. Aborting..."
+    exit 1
+fi
+popd
+
+docker-compose -f ${DOCKER_SCRIPTS}/docker-compose.nat.yml up --abort-on-container-exit --exit-code-from job-cluster &> /dev/null
+docker-compose -f ${DOCKER_SCRIPTS}/docker-compose.nat.yml logs job-cluster > ${FLINK_DIR}/log/jobmanager.log
+docker-compose -f ${DOCKER_SCRIPTS}/docker-compose.nat.yml logs taskmanager1 > ${FLINK_DIR}/log/taskmanager1.log
+docker-compose -f ${DOCKER_SCRIPTS}/docker-compose.nat.yml logs taskmanager2 > ${FLINK_DIR}/log/taskmanager2.log
+
+check_result_hash "WordCount" ${OUTPUT_VOLUME}/${OUTPUT_PREFIX}/ "${RESULT_HASH}"
diff --git a/tools/travis/splits/split_container.sh b/tools/travis/splits/split_container.sh
index 4d2ba156fb6..d57917245d0 100755
--- a/tools/travis/splits/split_container.sh
+++ b/tools/travis/splits/split_container.sh
@@ -53,6 +53,7 @@ if [[ "${HADOOP_INTEGRATION}" = "with-hadoop" ]]; then
     run_test "Run Mesos WordCount test" "$END_TO_END_DIR/test-scripts/test_mesos_wordcount.sh"
     run_test "Run Mesos multiple submission test" "$END_TO_END_DIR/test-scripts/test_mesos_multiple_submissions.sh"
 fi
+run_test "Running Flink over NAT end-to-end test" "$END_TO_END_DIR/test-scripts/test_nat.sh" "skip_check_exceptions"
 
 printf "\n[PASS] All tests passed\n"
 exit 0
