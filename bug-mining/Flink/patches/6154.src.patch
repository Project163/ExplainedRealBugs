diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AbstractAvroBulkFormat.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AbstractAvroBulkFormat.java
index 1221a04b185..2f0a7834b77 100644
--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AbstractAvroBulkFormat.java
+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AbstractAvroBulkFormat.java
@@ -39,6 +39,7 @@ import javax.annotation.Nullable;
 
 import java.io.IOException;
 import java.util.Iterator;
+import java.util.function.Function;
 
 /** Provides a {@link BulkFormat} for Avro records. */
 @Internal
@@ -55,14 +56,12 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
 
     @Override
     public AvroReader createReader(Configuration config, SplitT split) throws IOException {
-        open(split);
-        return createReader(split);
+        return createReader(split, createReusedAvroRecord(), createConverter());
     }
 
     @Override
     public AvroReader restoreReader(Configuration config, SplitT split) throws IOException {
-        open(split);
-        return createReader(split);
+        return createReader(split, createReusedAvroRecord(), createConverter());
     }
 
     @Override
@@ -70,7 +69,8 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
         return true;
     }
 
-    private AvroReader createReader(SplitT split) throws IOException {
+    private AvroReader createReader(SplitT split, A reuse, Function<A, T> converter)
+            throws IOException {
         long end = split.offset() + split.length();
         if (split.getReaderPosition().isPresent()) {
             CheckpointedPosition position = split.getReaderPosition().get();
@@ -79,21 +79,22 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
                     split.offset(),
                     end,
                     position.getOffset(),
-                    position.getRecordsAfterOffset());
+                    position.getRecordsAfterOffset(),
+                    reuse,
+                    converter);
         } else {
-            return new AvroReader(split.path(), split.offset(), end, -1, 0);
+            return new AvroReader(split.path(), split.offset(), end, -1, 0, reuse, converter);
         }
     }
 
-    protected void open(SplitT split) {}
-
-    protected abstract T convert(A record);
-
     protected abstract A createReusedAvroRecord();
 
+    protected abstract Function<A, T> createConverter();
+
     private class AvroReader implements BulkFormat.Reader<T> {
 
         private final DataFileReader<A> reader;
+        private final Function<A, T> converter;
 
         private final long end;
         private final Pool<A> pool;
@@ -101,10 +102,15 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
         private long currentBlockStart;
         private long currentRecordsToSkip;
 
-        private AvroReader(Path path, long offset, long end, long blockStart, long recordsToSkip)
+        private AvroReader(
+                Path path,
+                long offset,
+                long end,
+                long blockStart,
+                long recordsToSkip,
+                A reuse,
+                Function<A, T> converter)
                 throws IOException {
-            A reuse = createReusedAvroRecord();
-
             this.reader = createReaderFromPath(path);
             if (blockStart >= 0) {
                 reader.seek(blockStart);
@@ -114,6 +120,7 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
             for (int i = 0; i < recordsToSkip; i++) {
                 reader.next(reuse);
             }
+            this.converter = converter;
 
             this.end = end;
             this.pool = new Pool<>(1);
@@ -152,7 +159,10 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
             currentBlockStart = reader.previousSync();
             Iterator<T> iterator =
                     new AvroBlockIterator(
-                            reader.getBlockCount() - currentRecordsToSkip, reader, reuse);
+                            reader.getBlockCount() - currentRecordsToSkip,
+                            reader,
+                            reuse,
+                            converter);
             long recordsToSkip = currentRecordsToSkip;
             currentRecordsToSkip = 0;
             return new IteratorResultIterator<>(
@@ -179,11 +189,17 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
         private long numRecordsRemaining;
         private final DataFileReader<A> reader;
         private final A reuse;
+        private final Function<A, T> converter;
 
-        private AvroBlockIterator(long numRecordsRemaining, DataFileReader<A> reader, A reuse) {
+        private AvroBlockIterator(
+                long numRecordsRemaining,
+                DataFileReader<A> reader,
+                A reuse,
+                Function<A, T> converter) {
             this.numRecordsRemaining = numRecordsRemaining;
             this.reader = reader;
             this.reuse = reuse;
+            this.converter = converter;
         }
 
         @Override
@@ -197,7 +213,7 @@ public abstract class AbstractAvroBulkFormat<A, T, SplitT extends FileSourceSpli
                 numRecordsRemaining--;
                 // reader.next merely deserialize bytes in memory to java objects
                 // and will not read from file
-                return convert(reader.next(reuse));
+                return converter.apply(reader.next(reuse));
             } catch (IOException e) {
                 throw new RuntimeException(
                         "Encountered exception when reading from avro format file", e);
diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroFileFormatFactory.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroFileFormatFactory.java
index e188405ed49..6025be498e8 100644
--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroFileFormatFactory.java
+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroFileFormatFactory.java
@@ -52,6 +52,7 @@ import java.io.IOException;
 import java.io.OutputStream;
 import java.util.HashSet;
 import java.util.Set;
+import java.util.function.Function;
 
 import static org.apache.flink.formats.avro.AvroFormatOptions.AVRO_OUTPUT_CODEC;
 
@@ -129,9 +130,6 @@ public class AvroFileFormatFactory implements BulkReaderFormatFactory, BulkWrite
         private final RowType producedRowType;
         private final TypeInformation<RowData> producedTypeInfo;
 
-        private transient AvroToRowDataConverters.AvroToRowDataConverter converter;
-        private transient GenericRecord reusedAvroRecord;
-
         public AvroGenericRecordBulkFormat(
                 DynamicTableSource.Context context, RowType producedRowType) {
             super(AvroSchemaConverter.convertToSchema(producedRowType));
@@ -140,19 +138,15 @@ public class AvroFileFormatFactory implements BulkReaderFormatFactory, BulkWrite
         }
 
         @Override
-        protected void open(FileSourceSplit split) {
-            converter = AvroToRowDataConverters.createRowConverter(producedRowType);
-            reusedAvroRecord = new GenericData.Record(readerSchema);
-        }
-
-        @Override
-        protected RowData convert(GenericRecord record) {
-            return record == null ? null : (GenericRowData) converter.convert(record);
+        protected GenericRecord createReusedAvroRecord() {
+            return new GenericData.Record(readerSchema);
         }
 
         @Override
-        protected GenericRecord createReusedAvroRecord() {
-            return reusedAvroRecord;
+        protected Function<GenericRecord, RowData> createConverter() {
+            AvroToRowDataConverters.AvroToRowDataConverter converter =
+                    AvroToRowDataConverters.createRowConverter(producedRowType);
+            return record -> record == null ? null : (GenericRowData) converter.convert(record);
         }
 
         @Override
diff --git a/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroBulkFormatTestUtils.java b/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroBulkFormatTestUtils.java
index a688ff7332e..caebbc42d64 100644
--- a/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroBulkFormatTestUtils.java
+++ b/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroBulkFormatTestUtils.java
@@ -30,6 +30,8 @@ import org.apache.flink.table.types.logical.RowType;
 import org.apache.avro.generic.GenericData;
 import org.apache.avro.generic.GenericRecord;
 
+import java.util.function.Function;
+
 /** Testing utils for tests related to {@link AbstractAvroBulkFormat}. */
 public class AvroBulkFormatTestUtils {
 
@@ -45,27 +47,20 @@ public class AvroBulkFormatTestUtils {
     public static class TestingAvroBulkFormat
             extends AbstractAvroBulkFormat<GenericRecord, RowData, FileSourceSplit> {
 
-        private transient GenericRecord reusedAvroRecord;
-        private transient AvroToRowDataConverters.AvroToRowDataConverter converter;
-
         protected TestingAvroBulkFormat() {
             super(AvroSchemaConverter.convertToSchema(ROW_TYPE));
         }
 
         @Override
-        protected void open(FileSourceSplit split) {
-            reusedAvroRecord = new GenericData.Record(readerSchema);
-            converter = AvroToRowDataConverters.createRowConverter(ROW_TYPE);
-        }
-
-        @Override
-        protected RowData convert(GenericRecord record) {
-            return record == null ? null : (RowData) converter.convert(record);
+        protected GenericRecord createReusedAvroRecord() {
+            return new GenericData.Record(readerSchema);
         }
 
         @Override
-        protected GenericRecord createReusedAvroRecord() {
-            return reusedAvroRecord;
+        protected Function<GenericRecord, RowData> createConverter() {
+            AvroToRowDataConverters.AvroToRowDataConverter converter =
+                    AvroToRowDataConverters.createRowConverter(ROW_TYPE);
+            return record -> record == null ? null : (RowData) converter.convert(record);
         }
 
         @Override
