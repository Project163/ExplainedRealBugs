diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarFunctionCallGen.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarFunctionCallGen.scala
index 3ef085f5c5a..3957fceba55 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarFunctionCallGen.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarFunctionCallGen.scala
@@ -47,14 +47,6 @@ class ScalarFunctionCallGen(scalarFunction: ScalarFunction) extends CallGenerato
       operands: Seq[GeneratedExpression],
       returnType: LogicalType): GeneratedExpression = {
     val operandTypes = operands.map(_.resultType).toArray
-    val arguments = operands.map {
-      case expr if expr.literal =>
-        getConverterForDataType(fromLogicalTypeToDataType(expr.resultType))
-            .asInstanceOf[DataFormatConverters.DataFormatConverter[Any, Any]]
-            .toExternal(expr.literalValue.get)
-            .asInstanceOf[AnyRef]
-      case _ => null
-    }.toArray
     // determine function method and result class
     val resultClass = getResultTypeClassOfScalarFunction(scalarFunction, operandTypes)
 
@@ -71,7 +63,7 @@ class ScalarFunctionCallGen(scalarFunction: ScalarFunction) extends CallGenerato
     val resultTerm = ctx.addReusableLocalVariable(resultTypeTerm, "result")
     val evalResult = s"$functionReference.eval(${parameters.map(_.resultTerm).mkString(", ")})"
     val resultExternalType = UserDefinedFunctionUtils.getResultTypeOfScalarFunction(
-      scalarFunction, arguments, operandTypes)
+      scalarFunction, operandTypes)
     val setResult = {
       if (resultClass.isPrimitive && isInternalClass(resultExternalType)) {
         s"$resultTerm = $evalResult;"
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/expressions/call.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/expressions/call.scala
index f4caf9e6ecb..0d10647b761 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/expressions/call.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/expressions/call.scala
@@ -179,7 +179,6 @@ case class PlannerScalarFunctionCall(
   override private[flink] def resultType =
     fromDataTypeToTypeInfo(getResultTypeOfScalarFunction(
       scalarFunction,
-      Array(),
       signature))
 
   override private[flink] def validateInput(): ValidationResult = {
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/ScalarSqlFunction.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/ScalarSqlFunction.scala
index c98e2daf5ad..34314c6a623 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/ScalarSqlFunction.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/ScalarSqlFunction.scala
@@ -80,20 +80,8 @@ object ScalarSqlFunction {
       */
     new SqlReturnTypeInference {
       override def inferReturnType(opBinding: SqlOperatorBinding): RelDataType = {
-        val sqlTypes = opBinding.collectOperandTypes().asScala.toArray
         val parameters = getOperandType(opBinding).toArray
-
-        val arguments = sqlTypes.indices.map(i =>
-          if (opBinding.isOperandNull(i, false)) {
-            null
-          } else if (opBinding.isOperandLiteral(i, false)) {
-            opBinding.getOperandLiteralValue(
-              i, getDefaultExternalClassForType(parameters(i))).asInstanceOf[AnyRef]
-          } else {
-            null
-          }
-        ).toArray
-        val resultType = getResultTypeOfScalarFunction(scalarFunction, arguments, parameters)
+        val resultType = getResultTypeOfScalarFunction(scalarFunction, parameters)
         typeFactory.createFieldTypeFromLogicalType(
           fromDataTypeToLogicalType(resultType))
       }
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/UserDefinedFunctionUtils.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/UserDefinedFunctionUtils.scala
index c5779ff5e0d..da902bb4193 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/UserDefinedFunctionUtils.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/functions/utils/UserDefinedFunctionUtils.scala
@@ -615,7 +615,6 @@ object UserDefinedFunctionUtils {
 
   def getResultTypeOfScalarFunction(
       function: ScalarFunction,
-      arguments: Array[AnyRef],
       argTypes: Array[LogicalType]): DataType = {
     val userDefinedTypeInfo = function.getResultType(getEvalMethodSignature(function, argTypes))
     if (userDefinedTypeInfo != null) {
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala
index 0f65507c70e..2e9e6eab4e9 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala
@@ -25,25 +25,17 @@ import org.apache.flink.table.api.{DataTypes, Types, ValidationException}
 import org.apache.flink.table.functions.ScalarFunction
 import org.apache.flink.table.planner.expressions.utils.{ExpressionTestBase, _}
 import org.apache.flink.table.planner.runtime.utils.JavaUserDefinedScalarFunctions._
+import org.apache.flink.table.planner.runtime.utils.UserDefinedFunctionTestUtils.{DateFunction, DateTimeFunction, LocalDateFunction, LocalTimeFunction, TimeFunction, TimestampFunction}
 import org.apache.flink.table.planner.utils.DateTimeTestUtil
 import org.apache.flink.types.Row
+
 import org.junit.Test
+
 import java.lang.{Boolean => JBoolean}
 import java.time.ZoneId
 
 class UserDefinedScalarFunctionTest extends ExpressionTestBase {
 
-  @Test
-  def test(): Unit = {
-    val JavaFunc1 = new JavaFunc1()
-
-    testAllApis(
-      JavaFunc1(nullOf(DataTypes.TIME), 15, nullOf(DataTypes.TIMESTAMP(3))),
-      "JavaFunc1(Null(SQL_TIME), 15, Null(SQL_TIMESTAMP))",
-      "JavaFunc1(NULL, 15, NULL)",
-      "null and 15 and null")
-  }
-
   @Test
   def testParameters(): Unit = {
     testAllApis(
@@ -154,6 +146,13 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
       "Func0(Null(INT))",
       "Func0(NULL)",
       "-1")
+
+    val JavaFunc1 = new JavaFunc1()
+    testAllApis(
+      JavaFunc1(nullOf(DataTypes.TIME), 15, nullOf(DataTypes.TIMESTAMP(3))),
+      "JavaFunc1(Null(SQL_TIME), 15, Null(SQL_TIMESTAMP))",
+      "JavaFunc1(NULL, 15, NULL)",
+      "null and 15 and null")
   }
 
   @Test
@@ -257,6 +256,16 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
       "1990-10-14 12:10:10.000")
   }
 
+  @Test
+  def testLiteralTemporalParameters(): Unit = {
+    testSqlApi("DateFunction(DATE '2020-03-27')", "2020-03-27")
+    testSqlApi("LocalDateFunction(DATE '2020-03-27')", "2020-03-27")
+    testSqlApi("TimeFunction(TIME '18:30:55')", "18:30:55")
+    testSqlApi("LocalTimeFunction(TIME '18:30:55')", "18:30:55")
+    testSqlApi("DateTimeFunction(TIMESTAMP '2020-03-27 18:30:55')", "2020-03-27T18:30:55")
+    testSqlApi("TimestampFunction(TIMESTAMP '2020-03-27 18:30:55')", "2020-03-27 18:30:55.0")
+  }
+
   @Test
   def testTimePointsOnPrimitivesInShanghai(): Unit = {
     config.setLocalTimeZone(ZoneId.of("Asia/Shanghai"))
@@ -565,7 +574,13 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
     "JavaFunc4" -> new JavaFunc4,
     "RichFunc0" -> new RichFunc0,
     "RichFunc1" -> new RichFunc1,
-    "RichFunc2" -> new RichFunc2
+    "RichFunc2" -> new RichFunc2,
+    "DateFunction" -> DateFunction,
+    "LocalDateFunction" -> LocalDateFunction,
+    "TimeFunction" -> TimeFunction,
+    "LocalTimeFunction" -> LocalTimeFunction,
+    "DateTimeFunction" -> DateTimeFunction,
+    "TimestampFunction" -> TimestampFunction
   )
 }
 
