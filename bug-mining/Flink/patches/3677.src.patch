diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/CollectStreamTableSink.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/CollectStreamTableSink.java
index d86af582664..00f0cbed9f7 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/CollectStreamTableSink.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/CollectStreamTableSink.java
@@ -43,7 +43,11 @@ public class CollectStreamTableSink implements RetractStreamTableSink<Row> {
 	private final TypeSerializer<Tuple2<Boolean, Row>> serializer;
 	private final TableSchema tableSchema;
 
-	public CollectStreamTableSink(InetAddress targetAddress, int targetPort, TypeSerializer<Tuple2<Boolean, Row>> serializer, TableSchema tableSchema) {
+	public CollectStreamTableSink(
+			InetAddress targetAddress,
+			int targetPort,
+			TypeSerializer<Tuple2<Boolean, Row>> serializer,
+			TableSchema tableSchema) {
 		this.targetAddress = targetAddress;
 		this.targetPort = targetPort;
 		this.serializer = serializer;
@@ -51,13 +55,20 @@ public class CollectStreamTableSink implements RetractStreamTableSink<Row> {
 	}
 
 	@Override
-	public TableSchema getTableSchema() {
-		return tableSchema;
+	public CollectStreamTableSink configure(String[] fieldNames, TypeInformation<?>[] fieldTypes) {
+		return new CollectStreamTableSink(targetAddress, targetPort, serializer, tableSchema);
 	}
 
+	// Retract stream sinks work only with the old type system.
 	@Override
-	public CollectStreamTableSink configure(String[] fieldNames, TypeInformation<?>[] fieldTypes) {
-		return new CollectStreamTableSink(targetAddress, targetPort, serializer, tableSchema);
+	public String[] getFieldNames() {
+		return tableSchema.getFieldNames();
+	}
+
+	// Retract stream sinks work only with the old type system.
+	@Override
+	public TypeInformation<?>[] getFieldTypes() {
+		return tableSchema.getFieldTypes();
 	}
 
 	@Override
diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ResultStore.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ResultStore.java
index 61b8289f513..2cea4aa7973 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ResultStore.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ResultStore.java
@@ -19,7 +19,6 @@
 package org.apache.flink.table.client.gateway.local;
 
 import org.apache.flink.api.common.ExecutionConfig;
-import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.JobManagerOptions;
 import org.apache.flink.runtime.net.ConnectionUtils;
@@ -63,8 +62,6 @@ public class ResultStore {
 			ExecutionConfig config,
 			ClassLoader classLoader) {
 
-		final RowTypeInfo outputType = new RowTypeInfo(schema.getFieldTypes(), schema.getFieldNames());
-
 		if (env.getExecution().inStreamingMode()) {
 			// determine gateway address (and port if possible)
 			final InetAddress gatewayAddress = getGatewayAddress(env.getDeployment());
@@ -72,7 +69,6 @@ public class ResultStore {
 
 			if (env.getExecution().isChangelogMode()) {
 				return new ChangelogCollectStreamResult<>(
-						outputType,
 						schema,
 						config,
 						gatewayAddress,
@@ -80,7 +76,6 @@ public class ResultStore {
 						classLoader);
 			} else {
 				return new MaterializedCollectStreamResult<>(
-						outputType,
 						schema,
 						config,
 						gatewayAddress,
@@ -94,7 +89,7 @@ public class ResultStore {
 			if (!env.getExecution().isTableMode()) {
 				throw new SqlExecutionException("Results of batch queries can only be served in table mode.");
 			}
-			return new MaterializedCollectBatchResult<>(schema, outputType, config, classLoader);
+			return new MaterializedCollectBatchResult<>(schema, config, classLoader);
 		}
 	}
 
diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/ChangelogCollectStreamResult.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/ChangelogCollectStreamResult.java
index eedc6f6c980..7fec1730e5a 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/ChangelogCollectStreamResult.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/ChangelogCollectStreamResult.java
@@ -20,7 +20,6 @@ package org.apache.flink.table.client.gateway.local.result;
 
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.java.tuple.Tuple2;
-import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.table.api.TableSchema;
 import org.apache.flink.table.client.gateway.TypedResult;
 import org.apache.flink.types.Row;
@@ -40,13 +39,12 @@ public class ChangelogCollectStreamResult<C> extends CollectStreamResult<C> impl
 	private static final int CHANGE_RECORD_BUFFER_SIZE = 5_000;
 
 	public ChangelogCollectStreamResult(
-			RowTypeInfo outputType,
 			TableSchema tableSchema,
 			ExecutionConfig config,
 			InetAddress gatewayAddress,
 			int gatewayPort,
 			ClassLoader classLoader) {
-		super(outputType, tableSchema, config, gatewayAddress, gatewayPort, classLoader);
+		super(tableSchema, config, gatewayAddress, gatewayPort, classLoader);
 
 		// prepare for changelog
 		changeRecordBuffer = new ArrayList<>();
diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/CollectStreamResult.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/CollectStreamResult.java
index fb7c4b1f574..04aef6be64c 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/CollectStreamResult.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/CollectStreamResult.java
@@ -24,7 +24,6 @@ import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.api.java.tuple.Tuple2;
-import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.DataStreamUtils;
 import org.apache.flink.streaming.experimental.SocketStreamIterator;
@@ -51,7 +50,6 @@ import static org.apache.flink.util.Preconditions.checkNotNull;
  */
 public abstract class CollectStreamResult<C> extends BasicResult<C> implements DynamicResult<C> {
 
-	private final TypeInformation<Row> outputType;
 	private final SocketStreamIterator<Tuple2<Boolean, Row>> iterator;
 	private final CollectStreamTableSink collectTableSink;
 	private final ResultRetrievalThread retrievalThread;
@@ -62,18 +60,15 @@ public abstract class CollectStreamResult<C> extends BasicResult<C> implements D
 	protected AtomicReference<SqlExecutionException> executionException = new AtomicReference<>();
 
 	public CollectStreamResult(
-			RowTypeInfo outputType,
 			TableSchema tableSchema,
 			ExecutionConfig config,
 			InetAddress gatewayAddress,
 			int gatewayPort,
 			ClassLoader classLoader) {
-		this.outputType = outputType;
-
 		resultLock = new Object();
 
 		// create socket stream iterator
-		final TypeInformation<Tuple2<Boolean, Row>> socketType = Types.TUPLE(Types.BOOLEAN, outputType);
+		final TypeInformation<Tuple2<Boolean, Row>> socketType = Types.TUPLE(Types.BOOLEAN, tableSchema.toRowType());
 		final TypeSerializer<Tuple2<Boolean, Row>> serializer = socketType.createSerializer(config);
 		try {
 			// pass gateway port and address such that iterator knows where to bind to
@@ -90,11 +85,6 @@ public abstract class CollectStreamResult<C> extends BasicResult<C> implements D
 		this.classLoader = checkNotNull(classLoader);
 	}
 
-	@Override
-	public TypeInformation<Row> getOutputType() {
-		return outputType;
-	}
-
 	@Override
 	public void startRetrieval(ProgramDeployer deployer) {
 		// start listener thread
diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/DynamicResult.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/DynamicResult.java
index 9aeec97bc16..22e0c8c7b91 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/DynamicResult.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/DynamicResult.java
@@ -18,10 +18,8 @@
 
 package org.apache.flink.table.client.gateway.local.result;
 
-import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.table.client.gateway.local.ProgramDeployer;
 import org.apache.flink.table.sinks.TableSink;
-import org.apache.flink.types.Row;
 
 /**
  * A result of a dynamic table program.
@@ -38,11 +36,6 @@ public interface DynamicResult<C> extends Result<C> {
 	 */
 	boolean isMaterialized();
 
-	/**
-	 * Returns the output type as defined by the query.
-	 */
-	TypeInformation<Row> getOutputType();
-
 	/**
 	 * Starts the table program using the given deployer and monitors it's execution.
 	 */
diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectBatchResult.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectBatchResult.java
index e944acd8168..c2d9fd866e5 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectBatchResult.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectBatchResult.java
@@ -21,8 +21,7 @@ package org.apache.flink.table.client.gateway.local.result;
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.JobExecutionResult;
 import org.apache.flink.api.common.accumulators.SerializedListAccumulator;
-import org.apache.flink.api.common.typeinfo.TypeInformation;
-import org.apache.flink.api.java.typeutils.RowTypeInfo;
+import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.table.api.TableSchema;
 import org.apache.flink.table.client.gateway.SqlExecutionException;
 import org.apache.flink.table.client.gateway.TypedResult;
@@ -45,7 +44,6 @@ import static org.apache.flink.util.Preconditions.checkNotNull;
  */
 public class MaterializedCollectBatchResult<C> extends BasicResult<C> implements MaterializedResult<C> {
 
-	private final TypeInformation<Row> outputType;
 	private final String accumulatorName;
 	private final CollectBatchTableSink tableSink;
 	private final Object resultLock;
@@ -60,13 +58,12 @@ public class MaterializedCollectBatchResult<C> extends BasicResult<C> implements
 
 	public MaterializedCollectBatchResult(
 			TableSchema tableSchema,
-			RowTypeInfo outputType,
 			ExecutionConfig config,
 			ClassLoader classLoader) {
-		this.outputType = outputType;
 
 		accumulatorName = new AbstractID().toString();
-		tableSink = new CollectBatchTableSink(accumulatorName, outputType.createSerializer(config), tableSchema);
+		TypeSerializer<Row> serializer = tableSchema.toRowType().createSerializer(config);
+		tableSink = new CollectBatchTableSink(accumulatorName, serializer, tableSchema);
 		resultLock = new Object();
 		this.classLoader = checkNotNull(classLoader);
 
@@ -78,11 +75,6 @@ public class MaterializedCollectBatchResult<C> extends BasicResult<C> implements
 		return true;
 	}
 
-	@Override
-	public TypeInformation<Row> getOutputType() {
-		return outputType;
-	}
-
 	@Override
 	public void startRetrieval(ProgramDeployer deployer) {
 		deployer
diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResult.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResult.java
index d695af2c8aa..40dd676fd1c 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResult.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResult.java
@@ -21,7 +21,6 @@ package org.apache.flink.table.client.gateway.local.result;
 import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.java.tuple.Tuple2;
-import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.table.api.TableSchema;
 import org.apache.flink.table.client.gateway.SqlExecutionException;
 import org.apache.flink.table.client.gateway.TypedResult;
@@ -91,7 +90,6 @@ public class MaterializedCollectStreamResult<C> extends CollectStreamResult<C> i
 
 	@VisibleForTesting
 	public MaterializedCollectStreamResult(
-			RowTypeInfo outputType,
 			TableSchema tableSchema,
 			ExecutionConfig config,
 			InetAddress gatewayAddress,
@@ -99,7 +97,7 @@ public class MaterializedCollectStreamResult<C> extends CollectStreamResult<C> i
 			int maxRowCount,
 			int overcommitThreshold,
 			ClassLoader classLoader) {
-		super(outputType, tableSchema, config, gatewayAddress, gatewayPort, classLoader);
+		super(tableSchema, config, gatewayAddress, gatewayPort, classLoader);
 
 		if (maxRowCount <= 0) {
 			this.maxRowCount = Integer.MAX_VALUE;
@@ -120,7 +118,6 @@ public class MaterializedCollectStreamResult<C> extends CollectStreamResult<C> i
 	}
 
 	public MaterializedCollectStreamResult(
-			RowTypeInfo outputType,
 			TableSchema tableSchema,
 			ExecutionConfig config,
 			InetAddress gatewayAddress,
@@ -129,7 +126,6 @@ public class MaterializedCollectStreamResult<C> extends CollectStreamResult<C> i
 			ClassLoader classLoader) {
 
 		this(
-			outputType,
 			tableSchema,
 			config,
 			gatewayAddress,
diff --git a/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/LocalExecutorITCase.java b/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/LocalExecutorITCase.java
index ac9094e03b2..c136f506ddb 100644
--- a/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/LocalExecutorITCase.java
+++ b/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/LocalExecutorITCase.java
@@ -429,7 +429,7 @@ public class LocalExecutorITCase extends TestLogger {
 			// start job and retrieval
 			final ResultDescriptor desc = executor.executeQuery(
 				sessionId,
-				"SELECT scalarUDF(IntegerField1), StringField1 FROM TableNumber1");
+				"SELECT scalarUDF(IntegerField1), StringField1, 'ABC' FROM TableNumber1");
 
 			assertFalse(desc.isMaterialized());
 
@@ -437,12 +437,12 @@ public class LocalExecutorITCase extends TestLogger {
 				retrieveChangelogResult(executor, sessionId, desc.getResultId());
 
 			final List<String> expectedResults = new ArrayList<>();
-			expectedResults.add("(true,47,Hello World)");
-			expectedResults.add("(true,27,Hello World)");
-			expectedResults.add("(true,37,Hello World)");
-			expectedResults.add("(true,37,Hello World)");
-			expectedResults.add("(true,47,Hello World)");
-			expectedResults.add("(true,57,Hello World!!!!)");
+			expectedResults.add("(true,47,Hello World,ABC)");
+			expectedResults.add("(true,27,Hello World,ABC)");
+			expectedResults.add("(true,37,Hello World,ABC)");
+			expectedResults.add("(true,37,Hello World,ABC)");
+			expectedResults.add("(true,47,Hello World,ABC)");
+			expectedResults.add("(true,57,Hello World!!!!,ABC)");
 
 			TestBaseUtils.compareResultCollections(expectedResults, actualResults, Comparator.naturalOrder());
 		} finally {
@@ -507,15 +507,15 @@ public class LocalExecutorITCase extends TestLogger {
 		replaceVars.put("$VAR_UPDATE_MODE", "update-mode: append");
 		replaceVars.put("$VAR_MAX_ROWS", "100");
 
-		final String query = "SELECT scalarUDF(IntegerField1), StringField1 FROM TableNumber1";
+		final String query = "SELECT scalarUDF(IntegerField1), StringField1, 'ABC' FROM TableNumber1";
 
 		final List<String> expectedResults = new ArrayList<>();
-		expectedResults.add("47,Hello World");
-		expectedResults.add("27,Hello World");
-		expectedResults.add("37,Hello World");
-		expectedResults.add("37,Hello World");
-		expectedResults.add("47,Hello World");
-		expectedResults.add("57,Hello World!!!!");
+		expectedResults.add("47,Hello World,ABC");
+		expectedResults.add("27,Hello World,ABC");
+		expectedResults.add("37,Hello World,ABC");
+		expectedResults.add("37,Hello World,ABC");
+		expectedResults.add("47,Hello World,ABC");
+		expectedResults.add("57,Hello World!!!!,ABC");
 
 		executeStreamQueryTable(replaceVars, query, expectedResults);
 	}
@@ -596,19 +596,19 @@ public class LocalExecutorITCase extends TestLogger {
 		assertEquals("test-session", sessionId);
 
 		try {
-			final ResultDescriptor desc = executor.executeQuery(sessionId, "SELECT * FROM TestView1");
+			final ResultDescriptor desc = executor.executeQuery(sessionId, "SELECT *, 'ABC' FROM TestView1");
 
 			assertTrue(desc.isMaterialized());
 
 			final List<String> actualResults = retrieveTableResult(executor, sessionId, desc.getResultId());
 
 			final List<String> expectedResults = new ArrayList<>();
-			expectedResults.add("47");
-			expectedResults.add("27");
-			expectedResults.add("37");
-			expectedResults.add("37");
-			expectedResults.add("47");
-			expectedResults.add("57");
+			expectedResults.add("47,ABC");
+			expectedResults.add("27,ABC");
+			expectedResults.add("37,ABC");
+			expectedResults.add("37,ABC");
+			expectedResults.add("47,ABC");
+			expectedResults.add("57,ABC");
 
 			TestBaseUtils.compareResultCollections(expectedResults, actualResults, Comparator.naturalOrder());
 		} finally {
diff --git a/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResultTest.java b/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResultTest.java
index 8fdbe58ca1b..0abd0d5d509 100644
--- a/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResultTest.java
+++ b/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/result/MaterializedCollectStreamResultTest.java
@@ -19,9 +19,7 @@
 package org.apache.flink.table.client.gateway.local.result;
 
 import org.apache.flink.api.common.ExecutionConfig;
-import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.api.java.tuple.Tuple2;
-import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.table.api.DataTypes;
 import org.apache.flink.table.api.TableSchema;
 import org.apache.flink.table.client.gateway.TypedResult;
@@ -45,14 +43,12 @@ public class MaterializedCollectStreamResultTest {
 
 	@Test
 	public void testSnapshot() throws UnknownHostException {
-		final RowTypeInfo type = new RowTypeInfo(Types.STRING, Types.LONG);
 		TableSchema tableSchema = TableSchema.builder().fields(
 				new String[]{"f0", "f1"}, new DataType[]{DataTypes.STRING(), DataTypes.BIGINT()}).build();
 
 		TestMaterializedCollectStreamResult<?> result = null;
 		try {
 			result = new TestMaterializedCollectStreamResult<>(
-				type,
 				tableSchema,
 				new ExecutionConfig(),
 				InetAddress.getLocalHost(),
@@ -96,14 +92,12 @@ public class MaterializedCollectStreamResultTest {
 
 	@Test
 	public void testLimitedSnapshot() throws UnknownHostException {
-		final RowTypeInfo type = new RowTypeInfo(Types.STRING, Types.LONG);
 		TableSchema tableSchema = TableSchema.builder().fields(
 				new String[]{"f0", "f1"}, new DataType[]{DataTypes.STRING(), DataTypes.BIGINT()}).build();
 
 		TestMaterializedCollectStreamResult<?> result = null;
 		try {
 			result = new TestMaterializedCollectStreamResult<>(
-				type,
 				tableSchema,
 				new ExecutionConfig(),
 				InetAddress.getLocalHost(),
@@ -154,7 +148,6 @@ public class MaterializedCollectStreamResultTest {
 		public boolean isRetrieving;
 
 		public TestMaterializedCollectStreamResult(
-				RowTypeInfo outputType,
 				TableSchema tableSchema,
 				ExecutionConfig config,
 				InetAddress gatewayAddress,
@@ -163,7 +156,6 @@ public class MaterializedCollectStreamResultTest {
 				int overcommitThreshold) {
 
 			super(
-				outputType,
 				tableSchema,
 				config,
 				gatewayAddress,
@@ -174,7 +166,6 @@ public class MaterializedCollectStreamResultTest {
 		}
 
 		public TestMaterializedCollectStreamResult(
-				RowTypeInfo outputType,
 				TableSchema tableSchema,
 				ExecutionConfig config,
 				InetAddress gatewayAddress,
@@ -182,7 +173,6 @@ public class MaterializedCollectStreamResultTest {
 				int maxRowCount) {
 
 			super(
-				outputType,
 				tableSchema,
 				config,
 				gatewayAddress,
