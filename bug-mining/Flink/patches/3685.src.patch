diff --git a/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaTableTestBase.java b/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaTableTestBase.java
index c6558ac0b5c..5ff57587b11 100644
--- a/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaTableTestBase.java
+++ b/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaTableTestBase.java
@@ -160,8 +160,8 @@ public abstract class KafkaTableTestBase extends KafkaTestBase {
 		}
 
 		List<String> expected = Arrays.asList(
-			"2019-12-12 00:00:05,2019-12-12 00:00:04.004,3,50.00",
-			"2019-12-12 00:00:10,2019-12-12 00:00:06.006,2,5.33");
+			"2019-12-12 00:00:05.000,2019-12-12 00:00:04.004,3,50.00",
+			"2019-12-12 00:00:10.000,2019-12-12 00:00:06.006,2,5.33");
 
 		assertEquals(expected, TestingSinkFunction.rows);
 
diff --git a/flink-end-to-end-tests/flink-end-to-end-tests-common-kafka/src/test/java/org/apache/flink/tests/util/kafka/SQLClientKafkaITCase.java b/flink-end-to-end-tests/flink-end-to-end-tests-common-kafka/src/test/java/org/apache/flink/tests/util/kafka/SQLClientKafkaITCase.java
index ce7ea99fe55..8de1de696b1 100644
--- a/flink-end-to-end-tests/flink-end-to-end-tests-common-kafka/src/test/java/org/apache/flink/tests/util/kafka/SQLClientKafkaITCase.java
+++ b/flink-end-to-end-tests/flink-end-to-end-tests-common-kafka/src/test/java/org/apache/flink/tests/util/kafka/SQLClientKafkaITCase.java
@@ -42,7 +42,6 @@ import org.junit.runners.Parameterized;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.io.ByteArrayInputStream;
 import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.IOException;
@@ -50,14 +49,11 @@ import java.net.URL;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.StandardOpenOption;
-import java.security.MessageDigest;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Map;
 
-import static org.apache.flink.util.StringUtils.byteToHexString;
-
 /**
  * End-to-end test for the kafka SQL connectors.
  */
@@ -222,14 +218,12 @@ public class SQLClientKafkaITCase extends TestLogger {
 				String lines = new String(bytes, Charsets.UTF_8);
 				if (lines.split("\n").length == 4) {
 					success = true;
-					// Check the MD5SUM of the result file.
-					// Expected results:
-					//
-					// 2018-03-12 08:00:00.000,Alice,This was a warning.,2,Success constant folding.
-					// 2018-03-12 09:00:00.000,Bob,This was another warning.,1,Success constant folding.
-					// 2018-03-12 09:00:00.000,Steve,This was another info.,2,Success constant folding.
-					// 2018-03-12 09:00:00.000,Alice,This was a info.,1,Success constant folding.
-					Assert.assertEquals("MD5 checksum mismatch", "9b06d1f8c8b8dd4ce3341786897c8993", getMd5Sum(bytes));
+					String expected =
+						"2018-03-12 08:00:00.000,Alice,This was a warning.,2,Success constant folding.\n" +
+						"2018-03-12 09:00:00.000,Bob,This was another warning.,1,Success constant folding.\n" +
+						"2018-03-12 09:00:00.000,Steve,This was another info.,2,Success constant folding.\n" +
+						"2018-03-12 09:00:00.000,Alice,This was a info.,1,Success constant folding.\n";
+					Assert.assertEquals(expected, lines);
 					break;
 				}
 			} else {
@@ -239,15 +233,4 @@ public class SQLClientKafkaITCase extends TestLogger {
 		}
 		Assert.assertTrue("Timeout(" + (maxRetries * duration) + " sec) to read the correct CSV results.", success);
 	}
-
-	private static String getMd5Sum(byte[] bytes) throws Exception {
-		MessageDigest md = MessageDigest.getInstance("MD5");
-		try (ByteArrayInputStream is = new ByteArrayInputStream(bytes)) {
-			byte[] buf = new byte[1024];
-			for (int len = 0; (len = is.read(buf)) > 0; ) {
-				md.update(buf, 0, len);
-			}
-		}
-		return byteToHexString(md.digest());
-	}
 }
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala
index fcf2b6707a0..a6e4b5f9086 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala
@@ -218,12 +218,12 @@ object BuiltInMethods {
   val TIMESTAMP_TO_STRING = Types.lookupMethod(
     classOf[SqlDateTimeUtils],
     "timestampToString",
-    classOf[SqlTimestamp])
+    classOf[SqlTimestamp], classOf[Int])
 
   val TIMESTAMP_TO_STRING_TIME_ZONE = Types.lookupMethod(
     classOf[SqlDateTimeUtils],
     "timestampToString",
-    classOf[SqlTimestamp], classOf[TimeZone])
+    classOf[SqlTimestamp], classOf[TimeZone], classOf[Int])
 
   val TIMESTAMP_TO_TIMESTAMP_WITH_LOCAL_ZONE = Types.lookupMethod(
     classOf[SqlDateTimeUtils],
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala
index e1651645859..5cfcc3cb1b6 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala
@@ -2325,11 +2325,13 @@ object ScalarOperatorGens {
       case TIMESTAMP_WITHOUT_TIME_ZONE => // including rowtime indicator
         // The interpreted string conforms to the definition of timestamp literal
         // SQL 2011 Part 2 Section 6.13 General Rules 11) d)
-        s"${qualifyMethod(BuiltInMethods.TIMESTAMP_TO_STRING)}($operandTerm)"
+        val precision = fromType.asInstanceOf[TimestampType].getPrecision
+        s"${qualifyMethod(BuiltInMethods.TIMESTAMP_TO_STRING)}($operandTerm, $precision)"
       case TIMESTAMP_WITH_LOCAL_TIME_ZONE =>
         val method = qualifyMethod(BuiltInMethods.TIMESTAMP_TO_STRING_TIME_ZONE)
         val zone = ctx.addReusableTimeZone()
-        s"$method($operandTerm, $zone)"
+        val precision = fromType.asInstanceOf[LocalZonedTimestampType].getPrecision
+        s"$method($operandTerm, $zone, $precision)"
     }
 
 }
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ArrayTypeTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ArrayTypeTest.scala
index 614f782574e..2574a66d483 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ArrayTypeTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ArrayTypeTest.scala
@@ -90,9 +90,13 @@ class ArrayTypeTest extends ArrayTypeTestBase {
       "ARRAY[TIME '14:15:16', TIME '17:18:19']",
       "[14:15:16, 17:18:19]")
 
-    testAllApis(
+    // There is no timestamp literal function in Java String Table API,
+    // toTimestamp is casting string to TIMESTAMP(3) which is not the same to timestamp literal.
+    testTableApi(
       Array(localDateTime("1985-04-11 14:15:16"), localDateTime("2018-07-26 17:18:19")),
-      "array('1985-04-11 14:15:16'.toTimestamp, '2018-07-26 17:18:19'.toTimestamp)",
+      "[1985-04-11 14:15:16, 2018-07-26 17:18:19]")
+
+    testSqlApi(
       "ARRAY[TIMESTAMP '1985-04-11 14:15:16', TIMESTAMP '2018-07-26 17:18:19']",
       "[1985-04-11 14:15:16, 2018-07-26 17:18:19]")
 
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/DecimalTypeTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/DecimalTypeTest.scala
index 0e4bbdfe98a..84b94b6c7e7 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/DecimalTypeTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/DecimalTypeTest.scala
@@ -189,6 +189,12 @@ class DecimalTypeTest extends ExpressionTestBase {
       BigDecimal("123456789.123456789123456789").cast(DataTypes.DOUBLE),
       "(123456789.123456789123456789p).cast(DOUBLE)",
       "1.2345678912345679E8")
+
+    // testing padding behaviour
+    testSqlApi(
+      "CAST(CAST(f67 AS DECIMAL(10, 5)) AS VARCHAR)",
+      "1.00000"
+    )
   }
 
   @Test
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/MapTypeTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/MapTypeTest.scala
index aad557243a6..b68d8a8b34f 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/MapTypeTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/MapTypeTest.scala
@@ -85,13 +85,15 @@ class MapTypeTest extends MapTypeTestBase {
       "MAP[DATE '1985-04-11', TIME '14:15:16', DATE '2018-07-26', TIME '17:18:19']",
       "{1985-04-11=14:15:16, 2018-07-26=17:18:19}")
 
-    testAllApis(
+    // There is no timestamp literal function in Java String Table API,
+    // toTimestamp is casting string to TIMESTAMP(3) which is not the same to timestamp literal.
+    testTableApi(
       map(valueLiteral(gLocalTime("14:15:16")), valueLiteral(localDateTime("1985-04-11 14:15:16")),
         valueLiteral(gLocalTime("17:18:19")), valueLiteral(localDateTime("2018-07-26 17:18:19"))),
-      "map('14:15:16'.toTime, '1985-04-11 14:15:16'.toTimestamp, " +
-          "'17:18:19'.toTime, '2018-07-26 17:18:19'.toTimestamp)",
+      "{14:15:16=1985-04-11 14:15:16, 17:18:19=2018-07-26 17:18:19}")
+    testSqlApi(
       "MAP[TIME '14:15:16', TIMESTAMP '1985-04-11 14:15:16', " +
-          "TIME '17:18:19', TIMESTAMP '2018-07-26 17:18:19']",
+        "TIME '17:18:19', TIMESTAMP '2018-07-26 17:18:19']",
       "{14:15:16=1985-04-11 14:15:16, 17:18:19=2018-07-26 17:18:19}")
 
     testAllApis(
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/RowTypeTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/RowTypeTest.scala
index 35d38d57641..8ae8b2f2286 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/RowTypeTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/RowTypeTest.scala
@@ -38,7 +38,7 @@ class RowTypeTest extends RowTypeTestBase {
       "(1,foo,true)")
 
     // special literal
-    testAllApis(
+    testTableApi(
       row(
         localDate("1985-04-11"),
         gLocalTime("14:15:16"),
@@ -47,12 +47,7 @@ class RowTypeTest extends RowTypeTestBase {
         array(1, 2, 3),
         map("foo", "bar"),
         row(1, true)),
-      "row('1985-04-11'.toDate, '14:15:16'.toTime, '1985-04-11 14:15:16'.toTimestamp, " +
-          "0.1p, Array(1, 2, 3), Map('foo', 'bar'), row(1, true))",
-      "ROW(DATE '1985-04-11', TIME '14:15:16', TIMESTAMP '1985-04-11 14:15:16', " +
-          "CAST(0.1 AS DECIMAL(2, 1)), ARRAY[1, 2, 3], MAP['foo', 'bar'], row(1, true))",
       "(1985-04-11,14:15:16,1985-04-11 14:15:16,0.1,[1, 2, 3],{foo=bar},(1,true))")
-
     testSqlApi(
       "ROW(DATE '1985-04-11', TIME '14:15:16', TIMESTAMP '1985-04-11 14:15:16', " +
           "CAST(0.1 AS DECIMAL(2, 1)), ARRAY[1, 2, 3], MAP['foo', 'bar'], row(1, true))",
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ScalarFunctionsTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ScalarFunctionsTest.scala
index f38a6d2f4e9..a3f4f78e52a 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ScalarFunctionsTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/ScalarFunctionsTest.scala
@@ -3018,37 +3018,37 @@ class ScalarFunctionsTest extends ScalarTypesTestBase {
       'f18.floor(TimeIntervalUnit.YEAR),
       "f18.floor(YEAR)",
       "FLOOR(f18 TO YEAR)",
-      "1996-01-01 00:00:00")
+      "1996-01-01 00:00:00.000")
 
     testAllApis(
       'f18.floor(TimeIntervalUnit.MONTH),
       "f18.floor(MONTH)",
       "FLOOR(f18 TO MONTH)",
-      "1996-11-01 00:00:00")
+      "1996-11-01 00:00:00.000")
 
     testAllApis(
       'f18.floor(TimeIntervalUnit.DAY),
       "f18.floor(DAY)",
       "FLOOR(f18 TO DAY)",
-      "1996-11-10 00:00:00")
+      "1996-11-10 00:00:00.000")
 
     testAllApis(
       'f18.floor(TimeIntervalUnit.HOUR),
       "f18.floor(HOUR)",
       "FLOOR(f18 TO HOUR)",
-      "1996-11-10 06:00:00")
+      "1996-11-10 06:00:00.000")
 
     testAllApis(
       'f18.floor(TimeIntervalUnit.MINUTE),
       "f18.floor(MINUTE)",
       "FLOOR(f18 TO MINUTE)",
-      "1996-11-10 06:55:00")
+      "1996-11-10 06:55:00.000")
 
     testAllApis(
       'f18.floor(TimeIntervalUnit.SECOND),
       "f18.floor(SECOND)",
       "FLOOR(f18 TO SECOND)",
-      "1996-11-10 06:55:44")
+      "1996-11-10 06:55:44.000")
 
     testAllApis(
       'f17.floor(TimeIntervalUnit.HOUR),
@@ -3084,37 +3084,37 @@ class ScalarFunctionsTest extends ScalarTypesTestBase {
       'f18.ceil(TimeIntervalUnit.YEAR),
       "f18.ceil(YEAR)",
       "CEIL(f18 TO YEAR)",
-      "1997-01-01 00:00:00")
+      "1997-01-01 00:00:00.000")
 
     testAllApis(
       'f18.ceil(TimeIntervalUnit.MONTH),
       "f18.ceil(MONTH)",
       "CEIL(f18 TO MONTH)",
-      "1996-12-01 00:00:00")
+      "1996-12-01 00:00:00.000")
 
     testAllApis(
       'f18.ceil(TimeIntervalUnit.DAY),
       "f18.ceil(DAY)",
       "CEIL(f18 TO DAY)",
-      "1996-11-11 00:00:00")
+      "1996-11-11 00:00:00.000")
 
     testAllApis(
       'f18.ceil(TimeIntervalUnit.HOUR),
       "f18.ceil(HOUR)",
       "CEIL(f18 TO HOUR)",
-      "1996-11-10 07:00:00")
+      "1996-11-10 07:00:00.000")
 
     testAllApis(
       'f18.ceil(TimeIntervalUnit.MINUTE),
       "f18.ceil(MINUTE)",
       "CEIL(f18 TO MINUTE)",
-      "1996-11-10 06:56:00")
+      "1996-11-10 06:56:00.000")
 
     testAllApis(
       'f18.ceil(TimeIntervalUnit.SECOND),
       "f18.ceil(SECOND)",
       "CEIL(f18 TO SECOND)",
-      "1996-11-10 06:55:45")
+      "1996-11-10 06:55:45.000")
 
     testAllApis(
       'f17.ceil(TimeIntervalUnit.HOUR),
@@ -3538,25 +3538,38 @@ class ScalarFunctionsTest extends ScalarTypesTestBase {
       "timestampadd(DAY, 1, date '2016-06-15')",
       "2016-06-16")
 
-    testAllApis("2016-06-15".toTimestamp - 1.hour,
+    // There is no timestamp literal function in Java String Table API,
+    // toTimestamp is casting string to TIMESTAMP(3) which is not the same to timestamp literal.
+    testTableApi("2016-06-15".toTimestamp - 1.hour,
       "'2016-06-15'.toTimestamp - 1.hour",
+      "2016-06-14 23:00:00.000")
+    testSqlApi(
       "timestampadd(HOUR, -1, date '2016-06-15')",
-      "2016-06-14 23:00:00")
+      "2016-06-14 23:00:00.000000")
 
-    testAllApis("2016-06-15".toTimestamp + 1.minute,
+    // There is no timestamp literal function in Java String Table API,
+    // toTimestamp is casting string to TIMESTAMP(3) which is not the same to timestamp literal.
+    testTableApi("2016-06-15".toTimestamp + 1.minute,
       "'2016-06-15'.toTimestamp + 1.minute",
-      "timestampadd(MINUTE, 1, date '2016-06-15')",
-      "2016-06-15 00:01:00")
+      "2016-06-15 00:01:00.000")
+    testSqlApi("timestampadd(MINUTE, 1, date '2016-06-15')",
+      "2016-06-15 00:01:00.000000")
 
-    testAllApis("2016-06-15".toTimestamp - 1.second,
+    // There is no timestamp literal function in Java String Table API,
+    // toTimestamp is casting string to TIMESTAMP(3) which is not the same to timestamp literal.
+    testTableApi("2016-06-15".toTimestamp - 1.second,
       "'2016-06-15'.toTimestamp - 1.second",
-      "timestampadd(SQL_TSI_SECOND, -1, date '2016-06-15')",
-      "2016-06-14 23:59:59")
+      "2016-06-14 23:59:59.000")
+    testSqlApi("timestampadd(SQL_TSI_SECOND, -1, date '2016-06-15')",
+      "2016-06-14 23:59:59.000000")
 
-    testAllApis("2016-06-15".toTimestamp + 1.second,
+    // There is no timestamp literal function in Java String Table API,
+    // toTimestamp is casting string to TIMESTAMP(3) which is not the same to timestamp literal.
+    testTableApi("2016-06-15".toTimestamp + 1.second,
       "'2016-06-15'.toTimestamp + 1.second",
-      "timestampadd(SECOND, 1, date '2016-06-15')",
-      "2016-06-15 00:00:01")
+      "2016-06-15 00:00:01.000")
+    testSqlApi("timestampadd(SECOND, 1, date '2016-06-15')",
+      "2016-06-15 00:00:01.000000")
 
     testAllApis(nullOf(Types.SQL_TIMESTAMP) + 1.second,
       "nullOf(SQL_TIMESTAMP) + 1.second",
@@ -3615,9 +3628,9 @@ class ScalarFunctionsTest extends ScalarTypesTestBase {
   @Test
   def testToTimestamp(): Unit = {
     testSqlApi("to_timestamp('abc')", "null")
-    testSqlApi("to_timestamp('2017-09-15 00:00:00')", "2017-09-15 00:00:00")
-    testSqlApi("to_timestamp('20170915000000', 'yyyyMMddHHmmss')", "2017-09-15 00:00:00")
-    testSqlApi("to_timestamp('2017-09-15', 'yyyy-MM-dd')", "2017-09-15 00:00:00")
+    testSqlApi("to_timestamp('2017-09-15 00:00:00')", "2017-09-15 00:00:00.000")
+    testSqlApi("to_timestamp('20170915000000', 'yyyyMMddHHmmss')", "2017-09-15 00:00:00.000")
+    testSqlApi("to_timestamp('2017-09-15', 'yyyy-MM-dd')", "2017-09-15 00:00:00.000")
     // test with null input
     testSqlApi("to_timestamp(cast(null as varchar))", "null")
   }
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/TemporalTypesTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/TemporalTypesTest.scala
index 871c3965cf3..42eb09702bd 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/TemporalTypesTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/TemporalTypesTest.scala
@@ -83,14 +83,13 @@ class TemporalTypesTest extends ExpressionTestBase {
 
     testTableApi(
       localDateTime2Literal(localDateTime("2040-09-11 00:00:00.000")),
-      "'2040-09-11 00:00:00.000'.toTimestamp",
       "2040-09-11 00:00:00")
 
     testAllApis(
       "1500-04-30 12:00:00".cast(DataTypes.TIMESTAMP(3)),
       "'1500-04-30 12:00:00'.cast(SQL_TIMESTAMP)",
       "CAST('1500-04-30 12:00:00' AS TIMESTAMP(3))",
-      "1500-04-30 12:00:00")
+      "1500-04-30 12:00:00.000")
 
     testSqlApi(
       "TIMESTAMP '1500-04-30 12:00:00.123456789'",
@@ -209,14 +208,14 @@ class TemporalTypesTest extends ExpressionTestBase {
     testAllApis(
       'f0.cast(DataTypes.TIMESTAMP(3)),
       "f0.cast(SQL_TIMESTAMP)",
-      "CAST(f0 AS TIMESTAMP)",
-      "1990-10-14 00:00:00")
+      "CAST(f0 AS TIMESTAMP(3))",
+      "1990-10-14 00:00:00.000")
 
     testAllApis(
       'f1.cast(DataTypes.TIMESTAMP(3)),
       "f1.cast(SQL_TIMESTAMP)",
-      "CAST(f1 AS TIMESTAMP)",
-      "1970-01-01 10:20:45")
+      "CAST(f1 AS TIMESTAMP(3))",
+      "1970-01-01 10:20:45.000")
 
     testAllApis(
       'f2.cast(DataTypes.DATE),
@@ -259,12 +258,12 @@ class TemporalTypesTest extends ExpressionTestBase {
     testTableApi(
       'f15.cast(DataTypes.TIMESTAMP(3)),
       "f15.cast(SQL_TIMESTAMP)",
-      "2016-06-27 07:23:33")
+      "2016-06-27 07:23:33.000")
 
     testTableApi(
       'f15.toTimestamp,
       "f15.toTimestamp",
-      "2016-06-27 07:23:33")
+      "2016-06-27 07:23:33.000")
 
     testTableApi(
       'f8.cast(DataTypes.TIMESTAMP(3)).cast(DataTypes.BIGINT()),
@@ -273,7 +272,7 @@ class TemporalTypesTest extends ExpressionTestBase {
 
     testSqlApi(
       "CAST(CAST('123' as DECIMAL(5, 2)) AS TIMESTAMP)",
-      "1970-01-01 00:02:03")
+      "1970-01-01 00:02:03.000000")
 
     testSqlApi(
       "CAST(TIMESTAMP '1970-01-01 00:02:03' AS DECIMAL(5, 2))",
@@ -281,7 +280,7 @@ class TemporalTypesTest extends ExpressionTestBase {
 
     testSqlApi(
       "CAST(CAST('123' AS FLOAT) AS TIMESTAMP)",
-      "1970-01-01 00:02:03")
+      "1970-01-01 00:02:03.000000")
 
     testSqlApi(
       "CAST(TIMESTAMP '1970-01-01 00:02:03' AS FLOAT)",
@@ -289,7 +288,7 @@ class TemporalTypesTest extends ExpressionTestBase {
 
     testSqlApi(
       "CAST(CAST('123' AS DOUBLE) AS TIMESTAMP)",
-      "1970-01-01 00:02:03")
+      "1970-01-01 00:02:03.000000")
 
     testSqlApi(
       "CAST(TIMESTAMP '1970-01-01 00:02:03' AS DOUBLE)",
@@ -309,11 +308,11 @@ class TemporalTypesTest extends ExpressionTestBase {
 
     testSqlApi(
       "CAST(f0 AS TIMESTAMP(3) WITH LOCAL TIME ZONE)",
-      "1990-10-14 00:00:00")
+      "1990-10-14 00:00:00.000")
 
     testSqlApi(
       "CAST(f1 AS TIMESTAMP(3) WITH LOCAL TIME ZONE)",
-      "1970-01-01 10:20:45")
+      "1970-01-01 10:20:45.000")
 
     testSqlApi(
       s"CAST(${timestampTz("2018-03-14 01:02:03")} AS TIME)",
@@ -782,21 +781,33 @@ class TemporalTypesTest extends ExpressionTestBase {
     //testSqlApi("CEIL(TIMESTAMP '2018-03-20 06:10:31' TO HOUR)", "2018-03-20 07:00:00.000")
   }
 
-  private def timestampTz(str: String) = {
-    s"CAST(TIMESTAMP '$str' AS TIMESTAMP WITH LOCAL TIME ZONE)"
+  private def timestampTz(str: String): String = {
+    val precision = extractPrecision(str)
+    timestampTz(str, precision)
   }
 
-  private def timestampTz(str: String, precision: Int) = {
+  private def timestampTz(str: String, precision: Int): String = {
     s"CAST(TIMESTAMP '$str' AS TIMESTAMP($precision) WITH LOCAL TIME ZONE)"
   }
 
+  // According to SQL standard, the length of second fraction is
+  // the precision of the Timestamp literal
+  private def extractPrecision(str: String): Int = {
+    val dot = str.indexOf('.')
+    if (dot == -1) {
+      0
+    } else {
+      str.length - dot - 1
+    }
+  }
+
 
   @Test
   def testTemporalShanghai(): Unit = {
     config.setLocalTimeZone(ZoneId.of("Asia/Shanghai"))
 
     testSqlApi(timestampTz("2018-03-14 19:01:02.123"), "2018-03-14 19:01:02.123")
-    testSqlApi(timestampTz("2018-03-14 19:00:00.010"), "2018-03-14 19:00:00.01")
+    testSqlApi(timestampTz("2018-03-14 19:00:00.010"), "2018-03-14 19:00:00.010")
 
     testSqlApi(
       timestampTz("2018-03-14 19:00:00.010") + " > " + "f25",
@@ -875,11 +886,11 @@ class TemporalTypesTest extends ExpressionTestBase {
       "true")
     testSqlApi(
       "CEIL(f17 TO HOUR)",
-      "1990-10-14 08:00:00"
+      "1990-10-14 08:00:00.000"
     )
     testSqlApi(
       "FLOOR(f17 TO DAY)",
-      "1990-10-14 00:00:00"
+      "1990-10-14 00:00:00.000"
     )
 
     // TIMESTAMP_ADD
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala
index d04e7313dd6..0f65507c70e 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/UserDefinedScalarFunctionTest.scala
@@ -248,13 +248,13 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
       Func10('f6),
       "Func10(f6)",
       "Func10(f6)",
-      "1990-10-14 12:10:10")
+      "1990-10-14 12:10:10.000")
 
     testAllApis(
       Func26('f6),
       "Func26(f6)",
       "Func26(f6)",
-      "1990-10-14 12:10:10")
+      "1990-10-14 12:10:10.000")
   }
 
   @Test
@@ -265,20 +265,20 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
       Func27('f17),
       "Func27(f17)",
       "Func27(f17)",
-      "1990-10-14 12:10:10")
+      "1990-10-14 12:10:10.000")
 
     // Func28 needs a Long parameter, pass a Instant
     testAllApis(
       Func28('f17),
       "Func28(f17)",
       "Func28(f17)",
-      "1990-10-14 12:10:10")
+      "1990-10-14 12:10:10.000")
 
     testAllApis(
       Func30('f17),
       "Func30(f17)",
       "Func30(f17)",
-      "1990-10-14 12:10:10"
+      "1990-10-14 12:10:10.000"
     )
 
     // Func29 declares return a Instant, but returns a Long actually
@@ -287,7 +287,7 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
       Func29('f18),
       "Func29(f18)",
       "Func29(f18)",
-      "1970-01-01 08:00:00")
+      "1970-01-01 08:00:00.000")
   }
 
   @Test
@@ -298,14 +298,14 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
       Func27('f17),
       "Func27(f17)",
       "Func27(f17)",
-      "1990-10-14 12:10:10")
+      "1990-10-14 12:10:10.000")
 
     // Func28 needs a Long parameter, pass a Instant
     testAllApis(
       Func28('f17),
       "Func28(f17)",
       "Func28(f17)",
-      "1990-10-14 12:10:10")
+      "1990-10-14 12:10:10.000")
 
     // Func29 declares return a Instant, but returns a Long actually
     // the framework helps convert Long to Instant
@@ -313,7 +313,7 @@ class UserDefinedScalarFunctionTest extends ExpressionTestBase {
       Func29('f18),
       "Func29(f18)",
       "Func29(f18)",
-      "1969-12-31 16:00:00")
+      "1969-12-31 16:00:00.000")
   }
 
 
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/CalcITCase.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/CalcITCase.scala
index afcb621657d..d1b8907012c 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/CalcITCase.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/CalcITCase.scala
@@ -343,7 +343,7 @@ class CalcITCase extends BatchTestBase {
     tEnv.getConfig.setLocalTimeZone(pairs)
     checkResult(
       "SELECT CAST(a AS VARCHAR), b, CAST(b AS VARCHAR) FROM T",
-      Seq(row("1969-07-20 16:17:39", "1969-07-20T20:17:39Z", "1969-07-20 21:17:39"))
+      Seq(row("1969-07-20 16:17:39.000", "1969-07-20T20:17:39Z", "1969-07-20 21:17:39.000"))
     )
   }
 
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/TableScanITCase.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/TableScanITCase.scala
index b1521019320..9a42a17c750 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/TableScanITCase.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/TableScanITCase.scala
@@ -134,7 +134,7 @@ class TableScanITCase extends StreamingTestBase {
     result.addSink(sink)
     env.execute()
 
-    val expected = Seq("1970-01-01 00:00:00.01,4")
+    val expected = Seq("1970-01-01 00:00:00.010,4")
     assertEquals(expected.sorted, sink.getAppendResults.sorted)
   }
 
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/functions/SqlDateTimeUtils.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/functions/SqlDateTimeUtils.java
index c9c6cf2e6f5..a64ff98812b 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/functions/SqlDateTimeUtils.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/functions/SqlDateTimeUtils.java
@@ -1391,11 +1391,11 @@ public class SqlDateTimeUtils {
 		return r;
 	}
 
-	public static String timestampToString(SqlTimestamp ts) {
+	public static String timestampToString(SqlTimestamp ts, int precision) {
 		LocalDateTime ldt = ts.toLocalDateTime();
 
 		String fraction = pad(9, (long) ldt.getNano());
-		while (fraction.endsWith("0")) {
+		while (fraction.length() > precision && fraction.endsWith("0")) {
 			fraction = fraction.substring(0, fraction.length() - 1);
 		}
 
@@ -1411,8 +1411,8 @@ public class SqlDateTimeUtils {
 		return ymdhms.toString();
 	}
 
-	public static String timestampToString(SqlTimestamp ts, TimeZone tz) {
-		return timestampToString(timestampWithLocalZoneToTimestamp(ts, tz));
+	public static String timestampToString(SqlTimestamp ts, TimeZone tz, int precision) {
+		return timestampToString(timestampWithLocalZoneToTimestamp(ts, tz), precision);
 	}
 
 	private static String pad(int length, long v) {
