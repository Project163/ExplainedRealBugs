diff --git a/flink-core/src/test/java/org/apache/flink/core/fs/AbstractRecoverableWriterTest.java b/flink-core/src/test/java/org/apache/flink/core/fs/AbstractRecoverableWriterTest.java
index 949b67f594d..7cefb7e5bf8 100644
--- a/flink-core/src/test/java/org/apache/flink/core/fs/AbstractRecoverableWriterTest.java
+++ b/flink-core/src/test/java/org/apache/flink/core/fs/AbstractRecoverableWriterTest.java
@@ -25,6 +25,8 @@ import org.apache.flink.util.StringUtils;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
@@ -42,6 +44,8 @@ import static org.assertj.core.api.Assertions.assertThatThrownBy;
  */
 public abstract class AbstractRecoverableWriterTest {
 
+    private static final Logger LOG = LoggerFactory.getLogger(AbstractRecoverableWriterTest.class);
+
     private static final Random RND = new Random();
 
     private static final String testData1 = "THIS IS A TEST 1.";
@@ -196,16 +200,29 @@ public abstract class AbstractRecoverableWriterTest {
         final Map<String, RecoverableWriter.ResumeRecoverable> recoverables = new HashMap<>(4);
         RecoverableFsDataOutputStream stream = null;
         try {
-            stream = initWriter.open(path);
-            recoverables.put(INIT_EMPTY_PERSIST, stream.persist());
-
-            stream.write(testData1.getBytes(StandardCharsets.UTF_8));
-
-            recoverables.put(INTERM_WITH_STATE_PERSIST, stream.persist());
-            recoverables.put(INTERM_WITH_NO_ADDITIONAL_STATE_PERSIST, stream.persist());
-
-            // and write some more data
-            stream.write(testData2.getBytes(StandardCharsets.UTF_8));
+            // This is just to provide diagnostics to locate the root cause:
+            // https://issues.apache.org/jira/browse/FLINK-37703
+            // After the fix, this logic should be reverted.
+            int times = 0;
+            try {
+                times++;
+                stream = initWriter.open(path);
+                recoverables.put(INIT_EMPTY_PERSIST, stream.persist());
+
+                times++;
+                stream.write(testData1.getBytes(StandardCharsets.UTF_8));
+
+                recoverables.put(INTERM_WITH_STATE_PERSIST, stream.persist());
+                recoverables.put(INTERM_WITH_NO_ADDITIONAL_STATE_PERSIST, stream.persist());
+
+                // and write some more data
+                times++;
+                stream.write(testData2.getBytes(StandardCharsets.UTF_8));
+
+            } catch (IOException e) {
+                LOG.warn("{} execution failed, err message{}: ", times, e.getMessage());
+                throw e;
+            }
 
             recoverables.put(FINAL_WITH_EXTRA_STATE, stream.persist());
         } finally {
@@ -236,9 +253,13 @@ public abstract class AbstractRecoverableWriterTest {
                 assertThat(fileContents.getKey().getName()).startsWith(".part-0.inprogress.");
                 assertThat(fileContents.getValue()).isEqualTo(expectedPostRecoveryContents);
             }
-
-            recoveredStream.write(testData3.getBytes(StandardCharsets.UTF_8));
-            recoveredStream.closeForCommit().commit();
+            try {
+                recoveredStream.write(testData3.getBytes(StandardCharsets.UTF_8));
+                recoveredStream.closeForCommit().commit();
+            } catch (IOException e) {
+                LOG.warn("Final write failed: {}", e.getMessage());
+                throw e;
+            }
 
             files = getFileContentByPath(testDir);
             assertThat(files).hasSize(1);
diff --git a/flink-filesystems/flink-hadoop-fs/src/test/resources/log4j2-test.properties b/flink-filesystems/flink-hadoop-fs/src/test/resources/log4j2-test.properties
index 835c2ec9a3d..cc0425b120f 100644
--- a/flink-filesystems/flink-hadoop-fs/src/test/resources/log4j2-test.properties
+++ b/flink-filesystems/flink-hadoop-fs/src/test/resources/log4j2-test.properties
@@ -18,7 +18,11 @@
 
 # Set root logger level to OFF to not flood build logs
 # set manually to INFO for debugging purposes
-rootLogger.level = OFF
+# ----------------------
+# This is just for locate  the root cause:
+# https://issues.apache.org/jira/browse/FLINK-37703
+# After the fix, this logic should be reverted.
+rootLogger.level = WARN
 rootLogger.appenderRef.test.ref = TestLogger
 
 appender.testlogger.name = TestLogger
@@ -26,3 +30,7 @@ appender.testlogger.type = CONSOLE
 appender.testlogger.target = SYSTEM_ERR
 appender.testlogger.layout.type = PatternLayout
 appender.testlogger.layout.pattern = %-4r [%t] %-5p %c %x - %m%n
+
+logger.DataStreamer.name = org.apache.hadoop.hdfs.DataStreamer
+logger.DataStreamer.level = DEBUG
+
