diff --git a/flink-core/src/main/java/org/apache/flink/api/common/cache/DistributedCache.java b/flink-core/src/main/java/org/apache/flink/api/common/cache/DistributedCache.java
index af8c716b1f1..a4261d01211 100644
--- a/flink-core/src/main/java/org/apache/flink/api/common/cache/DistributedCache.java
+++ b/flink-core/src/main/java/org/apache/flink/api/common/cache/DistributedCache.java
@@ -21,11 +21,13 @@ package org.apache.flink.api.common.cache;
 
 
 import java.io.File;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Set;
-import java.util.concurrent.FutureTask;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Future;
 
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.fs.Path;
@@ -37,6 +39,7 @@ import org.apache.flink.core.fs.Path;
 public class DistributedCache {
 	
 	public static class DistributedCacheEntry {
+		
 		public String filePath;
 		public Boolean isExecutable;
 		
@@ -45,19 +48,45 @@ public class DistributedCache {
 			this.isExecutable=isExecutable;
 		}
 	}
-
-	final static String CACHE_FILE_NUM = "DISTRIBUTED_CACHE_FILE_NUM";
-
-	final static String CACHE_FILE_NAME = "DISTRIBUTED_CACHE_FILE_NAME_";
-
-	final static String CACHE_FILE_PATH = "DISTRIBUTED_CACHE_FILE_PATH_";
 	
-	final static String CACHE_FILE_EXE = "DISTRIBUTED_CACHE_FILE_EXE_";
+	// ------------------------------------------------------------------------
 
-	public final static String TMP_PREFIX = "tmp_";
+	private final Map<String, Future<Path>> cacheCopyTasks;
 
-	private Map<String, FutureTask<Path>> cacheCopyTasks = new HashMap<String, FutureTask<Path>>();
+	public DistributedCache(Map<String, Future<Path>> cacheCopyTasks) {
+		this.cacheCopyTasks = cacheCopyTasks;
+	}
+
+	// ------------------------------------------------------------------------
 
+	public File getFile(String name) {
+		if (name == null) {
+			throw new NullPointerException("name must not be null");
+		}
+		
+		Future<Path> future = cacheCopyTasks.get(name);
+		if (future == null) {
+			throw new IllegalArgumentException("File with name '" + name + "' is not available." +
+					" Did you forget to register the file?");
+		}
+		
+		try {
+			Path tmp = future.get();
+			return new File(tmp.toString());
+		}
+		catch (ExecutionException e) {
+			throw new RuntimeException("An error occurred while copying the file.", e.getCause());
+		}
+		catch (Exception e) {
+			throw new RuntimeException("Error while getting the file registered under '" + name +
+					"' from the distributed cache", e);
+		}
+	}
+	
+	// ------------------------------------------------------------------------
+	//  Utilities to read/write cache files from/to the configuration
+	// ------------------------------------------------------------------------
+	
 	public static void writeFileInfoToConfig(String name, DistributedCacheEntry e, Configuration conf) {
 		int num = conf.getInteger(CACHE_FILE_NUM,0) + 1;
 		conf.setInteger(CACHE_FILE_NUM, num);
@@ -67,29 +96,26 @@ public class DistributedCache {
 	}
 
 	public static Set<Entry<String, DistributedCacheEntry>> readFileInfoFromConfig(Configuration conf) {
-		Map<String, DistributedCacheEntry> cacheFiles = new HashMap<String, DistributedCacheEntry>();
 		int num = conf.getInteger(CACHE_FILE_NUM, 0);
+		if (num == 0) {
+			return Collections.emptySet();
+		}
+
+		Map<String, DistributedCacheEntry> cacheFiles = new HashMap<String, DistributedCacheEntry>();
 		for (int i = 1; i <= num; i++) {
-			String name = conf.getString(CACHE_FILE_NAME + i, "");
-			String filePath = conf.getString(CACHE_FILE_PATH + i, "");
+			String name = conf.getString(CACHE_FILE_NAME + i, null);
+			String filePath = conf.getString(CACHE_FILE_PATH + i, null);
 			Boolean isExecutable = conf.getBoolean(CACHE_FILE_EXE + i, false);
 			cacheFiles.put(name, new DistributedCacheEntry(filePath, isExecutable));
 		}
 		return cacheFiles.entrySet();
 	}
 
-	public void setCopyTasks(Map<String, FutureTask<Path>> cpTasks) {
-			this.cacheCopyTasks = cpTasks;
-	}
+	private static final String CACHE_FILE_NUM = "DISTRIBUTED_CACHE_FILE_NUM";
 
-	public File getFile(String name) {
-		Path tmp = null;
-		//The FutureTask.get() method will block until the file is ready.
-		try {
-			tmp = cacheCopyTasks.get(name).get();
-		} catch (Exception  e) {
-			throw new RuntimeException("Error while getting file from distributed cache", e);
-		}
-		return new File(tmp.toString());
-	}
+	private static final String CACHE_FILE_NAME = "DISTRIBUTED_CACHE_FILE_NAME_";
+
+	private static final String CACHE_FILE_PATH = "DISTRIBUTED_CACHE_FILE_PATH_";
+
+	private static final String CACHE_FILE_EXE = "DISTRIBUTED_CACHE_FILE_EXE_";
 }
diff --git a/flink-core/src/main/java/org/apache/flink/api/common/functions/util/AbstractRuntimeUDFContext.java b/flink-core/src/main/java/org/apache/flink/api/common/functions/util/AbstractRuntimeUDFContext.java
index ff531c73dd4..735fe8ea9c6 100644
--- a/flink-core/src/main/java/org/apache/flink/api/common/functions/util/AbstractRuntimeUDFContext.java
+++ b/flink-core/src/main/java/org/apache/flink/api/common/functions/util/AbstractRuntimeUDFContext.java
@@ -19,9 +19,10 @@
 package org.apache.flink.api.common.functions.util;
 
 import java.io.Serializable;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.concurrent.FutureTask;
+import java.util.concurrent.Future;
 
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.accumulators.Accumulator;
@@ -51,20 +52,30 @@ public abstract class AbstractRuntimeUDFContext implements RuntimeContext {
 
 	private final HashMap<String, Accumulator<?, ?>> accumulators = new HashMap<String, Accumulator<?, ?>>();
 	
-	private final DistributedCache distributedCache = new DistributedCache();
+	private final DistributedCache distributedCache;
 	
 	
-	public AbstractRuntimeUDFContext(String name, int numParallelSubtasks, int subtaskIndex, ClassLoader userCodeClassLoader, ExecutionConfig executionConfig) {
+	public AbstractRuntimeUDFContext(String name,
+										int numParallelSubtasks, int subtaskIndex,
+										ClassLoader userCodeClassLoader,
+										ExecutionConfig executionConfig)
+	{
+		this(name, numParallelSubtasks, subtaskIndex, userCodeClassLoader, executionConfig,
+				Collections.<String, Future<Path>>emptyMap());
+	}
+	
+	public AbstractRuntimeUDFContext(String name,
+										int numParallelSubtasks, int subtaskIndex,
+										ClassLoader userCodeClassLoader,
+										ExecutionConfig executionConfig,
+										Map<String, Future<Path>> cpTasks)
+	{
 		this.name = name;
 		this.numParallelSubtasks = numParallelSubtasks;
 		this.subtaskIndex = subtaskIndex;
 		this.userCodeClassLoader = userCodeClassLoader;
 		this.executionConfig = executionConfig;
-	}
-	
-	public AbstractRuntimeUDFContext(String name, int numParallelSubtasks, int subtaskIndex, ClassLoader userCodeClassLoader, ExecutionConfig executionConfig, Map<String, FutureTask<Path>> cpTasks) {
-		this(name, numParallelSubtasks, subtaskIndex, userCodeClassLoader, executionConfig);
-		this.distributedCache.setCopyTasks(cpTasks);
+		this.distributedCache = new DistributedCache(cpTasks);
 	}
 
 	@Override
diff --git a/flink-core/src/main/java/org/apache/flink/api/common/functions/util/RuntimeUDFContext.java b/flink-core/src/main/java/org/apache/flink/api/common/functions/util/RuntimeUDFContext.java
index b9c98cd051c..d116d00bc05 100644
--- a/flink-core/src/main/java/org/apache/flink/api/common/functions/util/RuntimeUDFContext.java
+++ b/flink-core/src/main/java/org/apache/flink/api/common/functions/util/RuntimeUDFContext.java
@@ -21,7 +21,7 @@ package org.apache.flink.api.common.functions.util;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.FutureTask;
+import java.util.concurrent.Future;
 
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.functions.BroadcastVariableInitializer;
@@ -42,7 +42,7 @@ public class RuntimeUDFContext extends AbstractRuntimeUDFContext {
 		super(name, numParallelSubtasks, subtaskIndex, userCodeClassLoader, executionConfig);
 	}
 	
-	public RuntimeUDFContext(String name, int numParallelSubtasks, int subtaskIndex, ClassLoader userCodeClassLoader, ExecutionConfig executionConfig, Map<String, FutureTask<Path>> cpTasks) {
+	public RuntimeUDFContext(String name, int numParallelSubtasks, int subtaskIndex, ClassLoader userCodeClassLoader, ExecutionConfig executionConfig, Map<String, Future<Path>> cpTasks) {
 		super(name, numParallelSubtasks, subtaskIndex, userCodeClassLoader, executionConfig, cpTasks);
 	}
 	
diff --git a/flink-core/src/main/java/org/apache/flink/core/fs/FileSystem.java b/flink-core/src/main/java/org/apache/flink/core/fs/FileSystem.java
index 0e38d8a7ac0..8b4cdba09b2 100644
--- a/flink-core/src/main/java/org/apache/flink/core/fs/FileSystem.java
+++ b/flink-core/src/main/java/org/apache/flink/core/fs/FileSystem.java
@@ -168,17 +168,15 @@ public abstract class FileSystem {
 	 * @throws IOException
 	 *         thrown if a reference to the file system instance could not be obtained
 	 */
-	public static FileSystem getLocalFileSystem() throws IOException {
-
-		URI localUri;
-
+	public static FileSystem getLocalFileSystem() {
+		// this should really never fail.
 		try {
-			localUri = OperatingSystem.isWindows() ?  new URI("file:/") : new URI("file:///");
-		} catch (URISyntaxException e) {
-			throw new IOException("Cannot create URI for local file system");
+			URI localUri = OperatingSystem.isWindows() ? new URI("file:/") : new URI("file:///");
+			return get(localUri);
+		}
+		catch (Exception e) {
+			throw new RuntimeException("Cannot create URI for local file system");
 		}
-
-		return get(localUri);
 	}
 
 	/**
@@ -193,7 +191,7 @@ public abstract class FileSystem {
 	 *         thrown if a reference to the file system instance could not be obtained
 	 */
 	public static FileSystem get(URI uri) throws IOException {
-		FileSystem fs = null;
+		FileSystem fs;
 
 		synchronized (SYNCHRONIZATION_OBJECT) {
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/Environment.java b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/Environment.java
index 1bd4f7b5b7e..7ab3bc90e67 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/Environment.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/Environment.java
@@ -18,58 +18,62 @@
 
 package org.apache.flink.runtime.execution;
 
-import akka.actor.ActorRef;
 import org.apache.flink.api.common.accumulators.Accumulator;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.runtime.broadcast.BroadcastVariableManager;
+import org.apache.flink.runtime.executiongraph.ExecutionAttemptID;
 import org.apache.flink.runtime.io.disk.iomanager.IOManager;
 import org.apache.flink.runtime.io.network.api.writer.ResultPartitionWriter;
 import org.apache.flink.runtime.io.network.partition.consumer.InputGate;
-import org.apache.flink.runtime.jobgraph.JobGraph;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.runtime.jobgraph.JobVertexID;
 import org.apache.flink.runtime.jobgraph.tasks.InputSplitProvider;
 import org.apache.flink.runtime.memorymanager.MemoryManager;
 
 import java.util.Map;
-import java.util.concurrent.FutureTask;
+import java.util.concurrent.Future;
 
 /**
- * The user code of every task runs inside an <code>Environment</code> object.
- * The environment provides important services to the task. It keeps track of
- * setting up the communication channels and provides access to input splits,
- * memory manager, etc.
+ * The Environment gives the code executed in a task access to the task's properties
+ * (such as name, parallelism), the configurations, the data stream readers and writers,
+ * as well as the various components that are provided by the TaskManager, such as
+ * memory manager, I/O manager, ...
  */
 public interface Environment {
 
 	/**
-	 * Returns the ID of the job from the original job graph. It is used by the library cache manager to find the
-	 * required
-	 * libraries for executing the assigned Nephele task.
+	 * Returns the ID of the job that the task belongs to.
 	 *
 	 * @return the ID of the job from the original job graph
 	 */
 	JobID getJobID();
 
 	/**
-	 * Gets the ID of the jobVertex that this task corresponds to.
+	 * Gets the ID of the JobVertex for which this task executes a parallel subtask.
 	 *
 	 * @return The JobVertexID of this task.
 	 */
 	JobVertexID getJobVertexId();
 
 	/**
-	 * Returns the task configuration object which was attached to the original JobVertex.
+	 * Gets the ID of the task execution attempt.
 	 *
-	 * @return the task configuration object which was attached to the original JobVertex.
+	 * @return The ID of the task execution attempt.
+	 */
+	ExecutionAttemptID getExecutionId();
+
+	/**
+	 * Returns the task-wide configuration object, originally attache to the job vertex.
+	 *
+	 * @return The task-wide configuration
 	 */
 	Configuration getTaskConfiguration();
 
 	/**
-	 * Returns the job configuration object which was attached to the original {@link JobGraph}.
+	 * Returns the job-wide configuration object that was attached to the JobGraph.
 	 *
-	 * @return the job configuration object which was attached to the original {@link JobGraph}
+	 * @return The job-wide configuration
 	 */
 	Configuration getJobConfiguration();
 
@@ -132,7 +136,7 @@ public interface Environment {
 	 */
 	ClassLoader getUserClassLoader();
 
-	Map<String, FutureTask<Path>> getCopyTask();
+	Map<String, Future<Path>> getDistributedCacheEntries();
 
 	BroadcastVariableManager getBroadcastVariableManager();
 
@@ -155,13 +159,4 @@ public interface Environment {
 
 	InputGate[] getAllInputGates();
 
-
-	/**
-	 * Returns the proxy object for the accumulator protocol.
-	 */
-	// THIS DOES NOT BELONG HERE, THIS TOTALLY BREAKS COMPONENTIZATION.
-	// THE EXECUTED TASKS HAVE BEEN KEPT INDEPENDENT OF ANY RPC OR ACTOR
-	// COMMUNICATION !!!
-	ActorRef getJobManager();
-
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/filecache/FileCache.java b/flink-runtime/src/main/java/org/apache/flink/runtime/filecache/FileCache.java
index 3449100ad32..fa5ad853842 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/filecache/FileCache.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/filecache/FileCache.java
@@ -22,99 +22,219 @@ import java.io.File;
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
+import java.util.UUID;
 import java.util.concurrent.Callable;
 import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
 import java.util.concurrent.FutureTask;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
 
-import org.apache.flink.api.common.cache.DistributedCache;
+import org.apache.commons.io.FileUtils;
 import org.apache.flink.api.common.cache.DistributedCache.DistributedCacheEntry;
+import org.apache.flink.api.java.tuple.Tuple4;
 import org.apache.flink.configuration.ConfigConstants;
-import org.apache.flink.configuration.GlobalConfiguration;
+import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.fs.FSDataInputStream;
 import org.apache.flink.core.fs.FSDataOutputStream;
 import org.apache.flink.core.fs.FileStatus;
 import org.apache.flink.core.fs.FileSystem;
 import org.apache.flink.core.fs.Path;
-import org.apache.flink.core.fs.local.LocalFileSystem;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.runtime.util.ExecutorThreadFactory;
 import org.apache.flink.runtime.util.IOUtils;
+
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
- * The FileCache is used to create the local files for the registered cache files when a task is deployed. 
+ * The FileCache is used to create the local files for the registered cache files when a task is deployed.
  * The files will be removed when the task is unregistered after a 5 second delay.
  * A given file x will be placed in "<system-tmp-dir>/tmp_<jobID>/".
  */
 public class FileCache {
 
-	private static final Logger LOG = LoggerFactory.getLogger(FileCache.class);
-	
-	private static final Object lock = new Object();
-	
+	static final Logger LOG = LoggerFactory.getLogger(FileCache.class);
 	
-	private LocalFileSystem lfs = new LocalFileSystem();
+	/** cache-wide lock to ensure consistency. copies are not done under this lock */
+	private final Object lock = new Object();
+
+	private final Map<JobID, Map<String, Tuple4<Integer, File, Path, Future<Path>>>> entries;
+
+	private final ScheduledExecutorService executorService;
+
+	private final File[] storageDirectories;
 
-	private Map<JobID, Map<String, Integer>> jobCounts = new HashMap<JobID, Map<String, Integer>>();
+	private final Thread shutdownHook;
 
-	private final ScheduledExecutorService executorService = Executors.newScheduledThreadPool(10, ExecutorThreadFactory.INSTANCE);
+	private int nextDirectory;
+
+	// ------------------------------------------------------------------------
+
+	public FileCache(Configuration config) throws IOException {
+		
+		String tempDirs = config.getString(ConfigConstants.TASK_MANAGER_TMP_DIR_KEY,
+				ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH);
+
+		String[] directories = tempDirs.split(",|" + File.pathSeparator);
+		String cacheDirName = "flink-dist-cache-" + UUID.randomUUID().toString();
+		storageDirectories = new File[directories.length];
+
+		for (int i = 0; i < directories.length; i++) {
+			storageDirectories[i] = new File(directories[i], cacheDirName);
+			String path = storageDirectories[i].getAbsolutePath();
+
+			if (storageDirectories[i].mkdirs()) {
+				LOG.info("User file cache uses directory " + path);
+			} else {
+				LOG.error("User file cache cannot create directory " + path);
+				// delete all other directories we created so far
+				for (int k = 0; k < i; k++) {
+					if (!storageDirectories[k].delete()) {
+						LOG.warn("User file cache cannot remove prior directory " +
+								storageDirectories[k].getAbsolutePath());
+					}
+				}
+				throw new IOException("File cache cannot create temp storage directory: " + path);
+			}
+		}
+
+		this.shutdownHook = createShutdownHook(this, LOG);
+
+		this.entries = new HashMap<JobID, Map<String, Tuple4<Integer, File, Path, Future<Path>>>>();
+		this.executorService = Executors.newScheduledThreadPool(10, ExecutorThreadFactory.INSTANCE);
+	}
+
+	/**
+	 * Shuts down the file cache by cancelling all
+	 */
+	public void shutdown() {
+		synchronized (lock) {
+			// first shutdown the thread pool
+			ScheduledExecutorService es = this.executorService;
+			if (es != null) {
+				es.shutdown();
+				try {
+					es.awaitTermination(5000L, TimeUnit.MILLISECONDS);
+				}
+				catch (InterruptedException e) {
+					// may happen
+				}
+			}
+			
+			entries.clear();
+			
+			// clean up the all storage directories
+			for (File dir : storageDirectories) {
+				try {
+					FileUtils.deleteDirectory(dir);
+				}
+				catch (IOException e) {
+					LOG.error("File cache could not properly clean up storage directory.");
+				}
+			}
+
+			// Remove shutdown hook to prevent resource leaks, unless this is invoked by the
+			// shutdown hook itself
+			if (shutdownHook != null && shutdownHook != Thread.currentThread()) {
+				try {
+					Runtime.getRuntime().removeShutdownHook(shutdownHook);
+				}
+				catch (IllegalStateException e) {
+					// race, JVM is in shutdown already, we can safely ignore this
+				}
+				catch (Throwable t) {
+					LOG.warn("Exception while unregistering file cache's cleanup shutdown hook.");
+				}
+			}
+		}
+	}
+
+	// ------------------------------------------------------------------------
 
 	/**
 	 * If the file doesn't exists locally, it will copy the file to the temp directory.
-	 * @param name file identifier
-	 * @param entry entry containing all relevant information
-	 * @param jobID
-	 * @return copy task
+	 *
+	 * @param name  The name under which the file is registered.
+	 * @param entry The cache entry descriptor (path, executable flag)
+	 * @param jobID The ID of the job for which the file is copied.
+	 * @return The handle to the task that copies the file.
 	 */
-	public FutureTask<Path> createTmpFile(String name, DistributedCacheEntry entry, JobID jobID) {
+	public Future<Path> createTmpFile(String name, DistributedCacheEntry entry, JobID jobID) {
 		synchronized (lock) {
-			if (!jobCounts.containsKey(jobID)) {
-				jobCounts.put(jobID, new HashMap<String, Integer>());
+			Map<String, Tuple4<Integer, File, Path, Future<Path>>> jobEntries = entries.get(jobID);
+			if (jobEntries == null) {
+				jobEntries = new HashMap<String, Tuple4<Integer, File, Path, Future<Path>>>();
+				entries.put(jobID, jobEntries);
 			}
-			Map<String, Integer> count = jobCounts.get(jobID);
-			if (count.containsKey(name)) {
-				count.put(name, count.get(name) + 1);
-			} else {
-				count.put(name, 1);
+
+			// tuple is (ref-count, parent-temp-dir, cached-file-path, copy-process)
+			Tuple4<Integer, File, Path, Future<Path>> fileEntry = jobEntries.get(name);
+			if (fileEntry != null) {
+				// file is already in the cache. return a future that
+				// immediately returns the file
+				fileEntry.f0 = fileEntry.f0 + 1;
+				
+				// return the future. may be that the copy is still in progress
+				return fileEntry.f3;
+			}
+			else {
+				// need to copy the file
+
+				// create the target path
+				File tempDirToUse = new File(storageDirectories[nextDirectory++], jobID.toString());
+				if (nextDirectory >= storageDirectories.length) {
+					nextDirectory = 0;
+				}
+
+				String sourceFile = entry.filePath;
+				int posOfSep = sourceFile.lastIndexOf("/");
+				if (posOfSep > 0) {
+					sourceFile = sourceFile.substring(posOfSep + 1);
+				}
+
+				Path target = new Path(tempDirToUse.getAbsolutePath() + "/" + sourceFile);
+
+				// kick off the copying
+				CopyProcess cp = new CopyProcess(entry, target);
+				FutureTask<Path> copyTask = new FutureTask<Path>(cp);
+				executorService.submit(copyTask);
+				
+				// store our entry
+				jobEntries.put(name, new Tuple4<Integer, File, Path, Future<Path>>(1, tempDirToUse, target, copyTask));
+				
+				return copyTask;
 			}
 		}
-		CopyProcess cp = new CopyProcess(entry, jobID);
-		FutureTask<Path> copyTask = new FutureTask<Path>(cp);
-		executorService.submit(copyTask);
-		return copyTask;
 	}
 
 	/**
 	 * Deletes the local file after a 5 second delay.
-	 * @param name file identifier
-	 * @param entry entry containing all relevant information
-	 * @param jobID
+	 *
+	 * @param name  The name under which the file is registered.
+	 * @param jobID The ID of the job for which the file is copied.
 	 */
-	public void deleteTmpFile(String name, DistributedCacheEntry entry, JobID jobID) {
-		DeleteProcess dp = new DeleteProcess(name, entry, jobID);
+	public void deleteTmpFile(String name, JobID jobID) {
+		DeleteProcess dp = new DeleteProcess(lock, entries, name, jobID);
 		executorService.schedule(dp, 5000L, TimeUnit.MILLISECONDS);
 	}
-
-	public Path getTempDir(JobID jobID, String childPath) {
-		return new Path(GlobalConfiguration.getString(ConfigConstants.TASK_MANAGER_TMP_DIR_KEY,
-			ConfigConstants.DEFAULT_TASK_MANAGER_TMP_PATH), DistributedCache.TMP_PREFIX + jobID.toString() + "/" + childPath);
-	}
-
-	public void shutdown() {
-		ScheduledExecutorService es = this.executorService;
-		if (es != null) {
-			es.shutdown();
-			try {
-				es.awaitTermination(5000L, TimeUnit.MILLISECONDS);
-			} catch (InterruptedException e) {
-				throw new RuntimeException("Error shutting down the file cache", e);
-			}
+	
+	
+	boolean holdsStillReference(String name, JobID jobId) {
+		Map<String, Tuple4<Integer, File, Path, Future<Path>>> jobEntries = entries.get(jobId);
+		if (jobEntries != null) {
+			Tuple4<Integer, File, Path, Future<Path>> entry = jobEntries.get(name);
+			return entry != null && entry.f0 > 0;
+		}
+		else {
+			return false;
 		}
 	}
 
+	// ------------------------------------------------------------------------
+	//  Utilities
+	// ------------------------------------------------------------------------
+
 	public static void copy(Path sourcePath, Path targetPath, boolean executable) throws IOException {
 		FileSystem sFS = sourcePath.getFileSystem();
 		FileSystem tFS = targetPath.getFileSystem();
@@ -137,80 +257,144 @@ public class FileCache {
 					FSDataOutputStream lfsOutput = tFS.create(targetPath, false);
 					FSDataInputStream fsInput = sFS.open(sourcePath);
 					IOUtils.copyBytes(fsInput, lfsOutput);
+					//noinspection ResultOfMethodCallIgnored
 					new File(targetPath.toString()).setExecutable(executable);
-				} catch (IOException ioe) {
+				}
+				catch (IOException ioe) {
 					LOG.error("could not copy file to local file cache.", ioe);
 				}
 			}
 		}
 	}
 
+	private static Thread createShutdownHook(final FileCache cache, final Logger logger) {
+
+		Thread shutdownHook = new Thread(new Runnable() {
+			@Override
+			public void run() {
+				try {
+					cache.shutdown();
+				}
+				catch (Throwable t) {
+					logger.error("Error during shutdown of file cache via JVM shutdown hook: " + t.getMessage(), t);
+				}
+			}
+		});
+
+		try {
+			// Add JVM shutdown hook to call shutdown of service
+			Runtime.getRuntime().addShutdownHook(shutdownHook);
+			return shutdownHook;
+		}
+		catch (IllegalStateException e) {
+			// JVM is already shutting down. no need to do our work
+			return null;
+		}
+		catch (Throwable t) {
+			logger.error("Cannot register shutdown hook that cleanly terminates the file cache service.");
+			return null;
+		}
+	}
+
+	// ------------------------------------------------------------------------
+	//  background processes
+	// ------------------------------------------------------------------------
+
 	/**
 	 * Asynchronous file copy process
 	 */
-	private class CopyProcess implements Callable<Path> {
-		
-		private JobID jobID;
-		private String filePath;
-		private Boolean executable;
+	private static class CopyProcess implements Callable<Path> {
+
+		private final Path filePath;
+		private final Path cachedPath;
+		private boolean executable;
 
-		public CopyProcess(DistributedCacheEntry e, JobID jobID) {
-			this.filePath = e.filePath;
+		public CopyProcess(DistributedCacheEntry e, Path cachedPath) {
+			this.filePath = new Path(e.filePath);
 			this.executable = e.isExecutable;
-			this.jobID = jobID;
+			this.cachedPath = cachedPath;
 		}
+
 		@Override
-		public Path call()  {
-			Path tmp = getTempDir(jobID, filePath.substring(filePath.lastIndexOf("/") + 1));
-			try {
-				synchronized (lock) {
-					copy(new Path(filePath), tmp, this.executable);
-				}
-			} catch (IOException e) {
-				LOG.error("Could not copy file to local file cache.", e);
-			}
-			return tmp;
+		public Path call() throws IOException {
+			// let exceptions propagate. we can retrieve them later from
+			// the future and report them upon access to the result
+			copy(filePath, cachedPath, this.executable);
+			return cachedPath;
 		}
 	}
 
 	/**
 	 * If no task is using this file after 5 seconds, clear it.
 	 */
-	private class DeleteProcess implements Runnable {
-		
-		private String name;
-		private JobID jobID;
-		private String filePath;
+	private static class DeleteProcess implements Runnable {
+
+		private final Object lock;
+		private final Map<JobID, Map<String, Tuple4<Integer, File, Path, Future<Path>>>> entries;
+
+		private final String name;
+		private final JobID jobID;
 
-		public DeleteProcess(String name, DistributedCacheEntry e, JobID jobID) {
+		public DeleteProcess(Object lock, Map<JobID, Map<String, Tuple4<Integer, File, Path, Future<Path>>>> entries,
+								String name, JobID jobID)
+		{
+			this.lock = lock;
+			this.entries = entries;
 			this.name = name;
 			this.jobID = jobID;
-			this.filePath = e.filePath;
 		}
+
 		@Override
 		public void run() {
-			Path tmp = getTempDir(jobID, filePath.substring(filePath.lastIndexOf("/") + 1));
 			try {
 				synchronized (lock) {
-					Map<String, Integer> count = jobCounts.get(jobID);
-					if (count.containsKey(name)) {
-						count.put(name, count.get(name) - 1);
-						if (count.get(name) == 0) {
-							if (lfs.exists(tmp)) {
-								lfs.delete(tmp, true);
+					Map<String, Tuple4<Integer, File, Path, Future<Path>>> jobEntries = entries.get(jobID);
+					
+					if (jobEntries != null) {
+						Tuple4<Integer, File, Path, Future<Path>> entry = jobEntries.get(name);
+						
+						if (entry != null) {
+							int count = entry.f0;
+							if (count > 1) {
+								// multiple references still
+								entry.f0 = count - 1;
 							}
-							count.remove(name);
-							if (count.isEmpty()) { //delete job directory
-								tmp = getTempDir(jobID, "");
-								if (lfs.exists(tmp)) {
-									lfs.delete(tmp, true);
+							else {
+								// we remove the last reference
+								jobEntries.remove(name);
+								if (jobEntries.isEmpty()) {
+									entries.remove(jobID);
+								}
+								
+								// abort the copy
+								entry.f3.cancel(true);
+
+								// remove the file
+								File file = new File(entry.f2.toString());
+								if (file.exists()) {
+									if (file.isDirectory()) {
+										FileUtils.deleteDirectory(file);
+									}
+									else if (!file.delete()) {
+										LOG.error("Could not delete locally cached file " + file.getAbsolutePath());
+									}
+								}
+								
+								// remove the job wide temp directory, if it is now empty
+								File parent = entry.f1;
+								if (parent.isDirectory()) {
+									String[] children = parent.list();
+									if (children == null || children.length == 0) {
+										//noinspection ResultOfMethodCallIgnored
+										parent.delete();
+									}
 								}
-								jobCounts.remove(jobID);
 							}
 						}
 					}
 				}
-			} catch (IOException e) {
+			}
+			catch (IOException e) {
 				LOG.error("Could not delete file from local file cache.", e);
 			}
 		}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/chaining/ChainedDriver.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/chaining/ChainedDriver.java
index c84d888c8ae..b4cfa273c47 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/chaining/ChainedDriver.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/chaining/ChainedDriver.java
@@ -62,7 +62,8 @@ public abstract class ChainedDriver<IT, OT> implements Collector<IT> {
 		} else {
 			Environment env = parent.getEnvironment();
 			this.udfContext = new DistributedRuntimeUDFContext(taskName, env.getNumberOfSubtasks(),
-					env.getIndexInSubtaskGroup(), userCodeClassLoader, parent.getExecutionConfig(), env.getCopyTask());
+					env.getIndexInSubtaskGroup(), userCodeClassLoader, parent.getExecutionConfig(),
+					env.getDistributedCacheEntries());
 		}
 
 		this.executionConfig = executionConfig;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/util/DistributedRuntimeUDFContext.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/util/DistributedRuntimeUDFContext.java
index e84106638f1..f4cd35482f1 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/util/DistributedRuntimeUDFContext.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/util/DistributedRuntimeUDFContext.java
@@ -21,7 +21,7 @@ package org.apache.flink.runtime.operators.util;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.FutureTask;
+import java.util.concurrent.Future;
 
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.functions.BroadcastVariableInitializer;
@@ -45,7 +45,7 @@ public class DistributedRuntimeUDFContext extends AbstractRuntimeUDFContext {
 		super(name, numParallelSubtasks, subtaskIndex, userCodeClassLoader, executionConfig);
 	}
 	
-	public DistributedRuntimeUDFContext(String name, int numParallelSubtasks, int subtaskIndex, ClassLoader userCodeClassLoader, ExecutionConfig executionConfig, Map<String, FutureTask<Path>> cpTasks) {
+	public DistributedRuntimeUDFContext(String name, int numParallelSubtasks, int subtaskIndex, ClassLoader userCodeClassLoader, ExecutionConfig executionConfig, Map<String, Future<Path>> cpTasks) {
 		super(name, numParallelSubtasks, subtaskIndex, userCodeClassLoader, executionConfig, cpTasks);
 	}
 	
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/filecache/FileCacheDeleteValidationTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/filecache/FileCacheDeleteValidationTest.java
index 8623f754724..c369674b46b 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/filecache/FileCacheDeleteValidationTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/filecache/FileCacheDeleteValidationTest.java
@@ -16,17 +16,16 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.runtime.filecache;
 
 import java.io.File;
-import java.io.IOException;
-
-import org.junit.Assert;
+import java.util.concurrent.Future;
 
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.core.fs.Path;
 import org.apache.flink.api.common.cache.DistributedCache.DistributedCacheEntry;
-import org.apache.flink.core.fs.local.LocalFileSystem;
 import org.apache.flink.api.common.JobID;
+
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -34,16 +33,16 @@ import org.junit.Test;
 import com.google.common.base.Charsets;
 import com.google.common.io.Files;
 
+import static org.junit.Assert.fail;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.assertFalse;
+
 /**
  * Test delete process of {@link FileCache}. The local cache file should not be deleted why another task comes in 5 seconds.
  */
 public class FileCacheDeleteValidationTest {
-	FileCache fileCache = new FileCache();
-	LocalFileSystem lfs = new LocalFileSystem();
-	File f;
 
-
-	String testFileContent = "Goethe - Faust: Der Tragoedie erster Teil\n" + "Prolog im Himmel.\n"
+	private static final String testFileContent = "Goethe - Faust: Der Tragoedie erster Teil\n" + "Prolog im Himmel.\n"
 		+ "Der Herr. Die himmlischen Heerscharen. Nachher Mephistopheles. Die drei\n" + "Erzengel treten vor.\n"
 		+ "RAPHAEL: Die Sonne toent, nach alter Weise, In Brudersphaeren Wettgesang,\n"
 		+ "Und ihre vorgeschriebne Reise Vollendet sie mit Donnergang. Ihr Anblick\n"
@@ -58,60 +57,83 @@ public class FileCacheDeleteValidationTest {
 		+ "Da flammt ein blitzendes Verheeren Dem Pfade vor des Donnerschlags. Doch\n"
 		+ "deine Boten, Herr, verehren Das sanfte Wandeln deines Tags.\n";
 
+	private FileCache fileCache;
+	private File f;
+	
 	@Before
-	public void createTmpCacheFile() {
+	public void setup() {
+		try {
+			fileCache = new FileCache(new Configuration());
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail("Cannot create FileCache: " + e.getMessage());
+		}
+		
 		f = new File(System.getProperty("java.io.tmpdir"), "cacheFile");
 		try {
 			Files.write(testFileContent, f, Charsets.UTF_8);
-		} catch (IOException e) {
-			throw new RuntimeException("Error initializing the test", e);
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail("Error initializing the test: " + e.getMessage());
 		}
 	}
 
-	@Test
-	public void testFileReuseForNextTask() {
-		JobID jobID = new JobID();
-		String filePath = f.toURI().toString();
-		fileCache.createTmpFile("test_file", new DistributedCacheEntry(filePath, false), jobID);
-		try {
-			Thread.sleep(1000);
-		} catch (InterruptedException e) {
-			throw new RuntimeException("Interrupted error", e);
-		}
-		fileCache.deleteTmpFile("test_file", new DistributedCacheEntry(filePath, false), jobID);
-		try {
-			Thread.sleep(1000);
-		} catch (InterruptedException e) {
-			throw new RuntimeException("Interrupted error", e);
-		}
-		//new task comes after 1 second
+	@After
+	public void shutdown() {
 		try {
-			Assert.assertTrue("Local cache file should not be deleted when another task comes in 5 seconds!", lfs.exists(fileCache.getTempDir(jobID, "cacheFile")));
-		} catch (IOException e) {
-			throw new RuntimeException("Interrupted error", e);
+			fileCache.shutdown();
 		}
-		fileCache.createTmpFile("test_file", new DistributedCacheEntry(filePath, false), jobID);
-		try {
-			Thread.sleep(1000);
-		} catch (InterruptedException e) {
-			throw new RuntimeException("Interrupted error", e);
+		catch (Exception e) {
+			e.printStackTrace();
+			fail("FileCache shutdown failed: " + e.getMessage());
 		}
-		fileCache.deleteTmpFile("test_file", new DistributedCacheEntry(filePath, false), jobID);
+	}
+
+	@Test
+	public void testFileReuseForNextTask() {
 		try {
-			Thread.sleep(7000);
-		} catch (InterruptedException e) {
-			throw new RuntimeException("Interrupted error", e);
+			final JobID jobID = new JobID();
+			final String fileName = "test_file";
+			
+			final String filePath = f.toURI().toString();
+			
+			// copy / create the file
+			Future<Path> copyResult = fileCache.createTmpFile(fileName, new DistributedCacheEntry(filePath, false), jobID);
+			copyResult.get();
+			
+			// get another reference to the file
+			Future<Path> copyResult2 = fileCache.createTmpFile(fileName, new DistributedCacheEntry(filePath, false), jobID);
+			
+			// this should be available immediately
+			assertTrue(copyResult2.isDone());
+			
+			// delete the file
+			fileCache.deleteTmpFile(fileName, jobID);
+			// file should not yet be deleted
+			assertTrue(fileCache.holdsStillReference(fileName, jobID));
+
+			// delete the second reference
+			fileCache.deleteTmpFile(fileName, jobID);
+			// file should still not be deleted, but remain for a bit
+			assertTrue(fileCache.holdsStillReference(fileName, jobID));
+			
+			fileCache.createTmpFile(fileName, new DistributedCacheEntry(filePath, false), jobID);
+			fileCache.deleteTmpFile(fileName, jobID);
+			
+			// after a while, the file should disappear
+			long deadline = System.currentTimeMillis() + 20000;
+			do {
+				Thread.sleep(5500);
+			}
+			while (fileCache.holdsStillReference(fileName, jobID) && System.currentTimeMillis() < deadline);
+
+			assertFalse(fileCache.holdsStillReference(fileName, jobID));
 		}
-		//no task comes in 7 seconds
-		try {
-			Assert.assertTrue("Local cache file should be deleted when no task comes in 5 seconds!", !lfs.exists(fileCache.getTempDir(jobID, "cacheFile")));
-		} catch (IOException e) {
-			throw new RuntimeException("Interrupted error", e);
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
 		}
 	}
-
-	@After
-	public void shutdown() {
-		fileCache.shutdown();
-	}
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java
index 319a37c626d..16cd66e6eea 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/MockEnvironment.java
@@ -16,16 +16,15 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.runtime.operators.testutils;
 
-import akka.actor.ActorRef;
 import org.apache.flink.api.common.accumulators.Accumulator;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.core.memory.MemorySegment;
 import org.apache.flink.runtime.broadcast.BroadcastVariableManager;
 import org.apache.flink.runtime.execution.Environment;
+import org.apache.flink.runtime.executiongraph.ExecutionAttemptID;
 import org.apache.flink.runtime.io.disk.iomanager.IOManager;
 import org.apache.flink.runtime.io.disk.iomanager.IOManagerAsync;
 import org.apache.flink.runtime.io.network.partition.consumer.IteratorWrappingTestSingleInputGate;
@@ -46,10 +45,11 @@ import org.apache.flink.util.MutableObjectIterator;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 
+import java.util.Collections;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.FutureTask;
+import java.util.concurrent.Future;
 
 import static org.junit.Assert.fail;
 import static org.mockito.Matchers.any;
@@ -210,19 +210,14 @@ public class MockEnvironment implements Environment {
 		return null;
 	}
 
-	@Override
-	public ActorRef getJobManager() {
-		throw new UnsupportedOperationException("getAccumulatorProtocolProxy() is not supported by MockEnvironment");
-	}
-
 	@Override
 	public ClassLoader getUserClassLoader() {
 		return getClass().getClassLoader();
 	}
 
 	@Override
-	public Map<String, FutureTask<Path>> getCopyTask() {
-		return null;
+	public Map<String, Future<Path>> getDistributedCacheEntries() {
+		return Collections.emptyMap();
 	}
 
 	@Override
@@ -252,6 +247,11 @@ public class MockEnvironment implements Environment {
 		return new JobVertexID(new byte[16]);
 	}
 
+	@Override
+	public ExecutionAttemptID getExecutionId() {
+		return new ExecutionAttemptID(0L, 0L);
+	}
+
 	@Override
 	public BroadcastVariableManager getBroadcastVariableManager() {
 		return this.bcVarManager;
diff --git a/flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamingRuntimeContext.java b/flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamingRuntimeContext.java
index eaf8a1d67f0..8ae2ced84b6 100644
--- a/flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamingRuntimeContext.java
+++ b/flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamingRuntimeContext.java
@@ -42,7 +42,7 @@ public class StreamingRuntimeContext extends RuntimeUDFContext {
 	public StreamingRuntimeContext(String name, Environment env, ClassLoader userCodeClassLoader,
 			ExecutionConfig executionConfig, Map<String, OperatorState<?>> operatorStates) {
 		super(name, env.getNumberOfSubtasks(), env.getIndexInSubtaskGroup(), userCodeClassLoader,
-				executionConfig, env.getCopyTask());
+				executionConfig, env.getDistributedCacheEntries());
 		this.env = env;
 		this.operatorStates = operatorStates;
 	}
