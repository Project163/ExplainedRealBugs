diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetAggregate.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetAggregate.scala
index c917061e7c3..6e421304c43 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetAggregate.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetAggregate.scala
@@ -62,6 +62,14 @@ class DataSetAggregate(
       grouping)
   }
 
+  override def toString: String = {
+    s"Aggregate(${ if (!grouping.isEmpty) {
+      s"groupBy: ($groupingToString), "
+    } else {
+      ""
+    }}}select:($aggregationToString))"
+  }
+
   override def explainTerms(pw: RelWriter): RelWriter = {
     super.explainTerms(pw)
       .itemIf("groupBy",groupingToString, !grouping.isEmpty)
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetCalc.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetCalc.scala
index d26c1cd48ec..5fd3e862eb4 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetCalc.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetCalc.scala
@@ -61,6 +61,14 @@ class DataSetCalc(
       ruleDescription)
   }
 
+  override def toString: String = {
+    s"Calc(${if (calcProgram.getCondition != null) {
+      s"where: ($conditionToString), "
+    } else {
+      ""
+    }}select: ($selectionToString))"
+  }
+
   override def explainTerms(pw: RelWriter): RelWriter = {
     super.explainTerms(pw)
       .item("select", selectionToString)
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetJoin.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetJoin.scala
index 38a70fb1249..de5489749ff 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetJoin.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetJoin.scala
@@ -18,24 +18,27 @@
 
 package org.apache.flink.api.table.plan.nodes.dataset
 
-import org.apache.calcite.plan.{RelOptCost, RelOptPlanner, RelTraitSet, RelOptCluster}
+import org.apache.calcite.plan._
 import org.apache.calcite.rel.`type`.RelDataType
 import org.apache.calcite.rel.core.JoinInfo
+import org.apache.calcite.rel.logical.LogicalJoin
 import org.apache.calcite.rel.metadata.RelMetadataQuery
 import org.apache.calcite.rel.{RelWriter, BiRel, RelNode}
+import org.apache.calcite.sql.fun.SqlStdOperatorTable
 import org.apache.calcite.util.mapping.IntPair
 import org.apache.flink.api.common.operators.base.JoinOperatorBase.JoinHint
 import org.apache.flink.api.common.typeinfo.TypeInformation
 import org.apache.flink.api.java.DataSet
 import org.apache.flink.api.java.operators.join.JoinType
 import org.apache.flink.api.table.codegen.CodeGenerator
+import org.apache.flink.api.table.plan.PlanGenException
 import org.apache.flink.api.table.runtime.FlatJoinRunner
 import org.apache.flink.api.table.typeutils.TypeConverter
 import org.apache.flink.api.table.{TableException, TableConfig}
 import org.apache.flink.api.common.functions.FlatJoinFunction
 import TypeConverter.determineReturnType
 import scala.collection.mutable.ArrayBuffer
-import org.apache.calcite.rex.RexNode
+import org.apache.calcite.rex.{RexInputRef, RexCall, RexNode}
 
 import scala.collection.JavaConverters._
 import scala.collection.JavaConversions._
@@ -59,6 +62,8 @@ class DataSetJoin(
   extends BiRel(cluster, traitSet, left, right)
   with DataSetRel {
 
+  val translatable = canBeTranslated
+
   override def deriveRowType() = rowType
 
   override def copy(traitSet: RelTraitSet, inputs: java.util.List[RelNode]): RelNode = {
@@ -77,6 +82,10 @@ class DataSetJoin(
       ruleDescription)
   }
 
+  override def toString: String = {
+    s"Join(where: ($joinConditionToString), join: ($joinSelectionToString))"
+  }
+
   override def explainTerms(pw: RelWriter): RelWriter = {
     super.explainTerms(pw)
       .item("where", joinConditionToString)
@@ -85,22 +94,25 @@ class DataSetJoin(
 
   override def computeSelfCost (planner: RelOptPlanner): RelOptCost = {
 
-    val children = this.getInputs
-
-    children.foldLeft(planner.getCostFactory.makeCost(0, 0, 0)) { (cost, child) =>
-      val rowCnt = RelMetadataQuery.getRowCount(child)
-      val rowSize = this.estimateRowSize(child.getRowType)
-      cost.plus(planner.getCostFactory.makeCost(rowCnt, rowCnt, rowCnt * rowSize))
+    if (!translatable) {
+      // join cannot be translated. Make huge costs
+      planner.getCostFactory.makeHugeCost()
+    } else {
+      // join can be translated. Compute cost estimate
+      val children = this.getInputs
+      children.foldLeft(planner.getCostFactory.makeCost(0, 0, 0)) { (cost, child) =>
+        val rowCnt = RelMetadataQuery.getRowCount(child)
+        val rowSize = this.estimateRowSize(child.getRowType)
+        cost.plus(planner.getCostFactory.makeCost(rowCnt, rowCnt, rowCnt * rowSize))
+      }
     }
+
   }
 
   override def translateToPlan(
       config: TableConfig,
       expectedType: Option[TypeInformation[Any]]): DataSet[Any] = {
 
-    val leftDataSet = left.asInstanceOf[DataSetRel].translateToPlan(config)
-    val rightDataSet = right.asInstanceOf[DataSetRel].translateToPlan(config)
-
     val returnType = determineReturnType(
       getRowType,
       expectedType,
@@ -112,16 +124,41 @@ class DataSetJoin(
     val rightKeys = ArrayBuffer.empty[Int]
     if (keyPairs.isEmpty) {
       // if no equality keys => not supported
-      throw new TableException("Joins should have at least one equality condition")
+      throw new TableException(
+        "Joins should have at least one equality condition.\n" +
+          s"\tLeft: ${left.toString},\n" +
+          s"\tRight: ${right.toString},\n" +
+          s"\tCondition: ($joinConditionToString)"
+      )
     }
     else {
-      // at least one equality expression => generate a join function
+      // at least one equality expression
+      val leftFields = left.getRowType.getFieldList
+      val rightFields = right.getRowType.getFieldList
+
       keyPairs.foreach(pair => {
-        leftKeys.add(pair.source)
-        rightKeys.add(pair.target)
+        val leftKeyType = leftFields.get(pair.source).getType.getSqlTypeName
+        val rightKeyType = rightFields.get(pair.target).getType.getSqlTypeName
+
+        // check if keys are compatible
+        if (leftKeyType == rightKeyType) {
+          // add key pair
+          leftKeys.add(pair.source)
+          rightKeys.add(pair.target)
+        } else {
+          throw new TableException(
+            "Equality join predicate on incompatible types.\n" +
+              s"\tLeft: ${left.toString},\n" +
+              s"\tRight: ${right.toString},\n" +
+              s"\tCondition: ($joinConditionToString)"
+          )
+        }
       })
     }
 
+    val leftDataSet = left.asInstanceOf[DataSetRel].translateToPlan(config)
+    val rightDataSet = right.asInstanceOf[DataSetRel].translateToPlan(config)
+
     val generator = new CodeGenerator(config, leftDataSet.getType, Some(rightDataSet.getType))
     val conversion = generator.generateConverterResultExpression(
       returnType,
@@ -163,6 +200,48 @@ class DataSetJoin(
       .`with`(joinFun).name(joinOpName).asInstanceOf[DataSet[Any]]
   }
 
+  private def canBeTranslated: Boolean = {
+
+    val equiCondition =
+      joinInfo.getEquiCondition(left, right, cluster.getRexBuilder)
+
+    // joins require at least one equi-condition
+    if (equiCondition.isAlwaysTrue) {
+      false
+    }
+    else {
+      // check that all equality predicates refer to field refs only (not computed expressions)
+      //   Note: Calcite treats equality predicates on expressions as non-equi predicates
+      joinCondition match {
+
+        // conjunction of join predicates
+        case c: RexCall if c.getOperator.equals(SqlStdOperatorTable.AND) =>
+
+          c.getOperands.asScala
+            // look at equality predicates only
+            .filter { o =>
+            o.isInstanceOf[RexCall] &&
+              o.asInstanceOf[RexCall].getOperator.equals(SqlStdOperatorTable.EQUALS)
+          }
+            // check that both children are field references
+            .map { o =>
+            o.asInstanceOf[RexCall].getOperands.get(0).isInstanceOf[RexInputRef] &&
+              o.asInstanceOf[RexCall].getOperands.get(1).isInstanceOf[RexInputRef]
+          }
+            // any equality predicate that does not refer to a field reference?
+            .reduce( (a, b) => a && b)
+
+        // single equi-join predicate
+        case c: RexCall if c.getOperator.equals(SqlStdOperatorTable.EQUALS) =>
+          c.getOperands.get(0).isInstanceOf[RexInputRef] &&
+            c.getOperands.get(1).isInstanceOf[RexInputRef]
+        case _ =>
+          false
+      }
+    }
+
+  }
+
   private def joinSelectionToString: String = {
     rowType.getFieldNames.asScala.toList.mkString(", ")
   }
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetSource.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetSource.scala
index 4e20ab938d1..6f94251d93f 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetSource.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetSource.scala
@@ -63,6 +63,10 @@ class DataSetSource(
     )
   }
 
+  override def toString: String = {
+    s"Source(from: (${rowType.getFieldNames.asScala.toList.mkString(", ")}))"
+  }
+
   override def computeSelfCost (planner: RelOptPlanner): RelOptCost = {
 
     val rowCnt = RelMetadataQuery.getRowCount(this)
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetUnion.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetUnion.scala
index 8f22285cc22..e4e0a145c13 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetUnion.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/nodes/dataset/DataSetUnion.scala
@@ -54,6 +54,10 @@ class DataSetUnion(
     )
   }
 
+  override def toString: String = {
+    "Union(union: (${rowType.getFieldNames.asScala.toList.mkString(\", \")}))"
+  }
+
   override def explainTerms(pw: RelWriter): RelWriter = {
     super.explainTerms(pw).item("union", unionSelectionToString)
   }
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/rules/dataSet/DataSetJoinRule.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/rules/dataSet/DataSetJoinRule.scala
index 5dee709c703..01b803c0847 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/rules/dataSet/DataSetJoinRule.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/api/table/plan/rules/dataSet/DataSetJoinRule.scala
@@ -37,54 +37,6 @@ class DataSetJoinRule
       "FlinkJoinRule")
   {
 
-    override def matches(call: RelOptRuleCall): Boolean = {
-
-      val join = call.rel(0).asInstanceOf[LogicalJoin]
-      val children = join.getInputs
-      val rexBuilder = call.builder().getRexBuilder
-
-      val joinInfo = join.analyzeCondition()
-      val joinCondition = join.getCondition
-      val equiCondition =
-        joinInfo.getEquiCondition(children.get(0), children.get(1), rexBuilder)
-
-      // joins require at least one equi-condition
-      if (equiCondition.isAlwaysTrue) {
-        false
-      }
-      else {
-        // check that all equality predicates refer to field refs only (not computed expressions)
-        //   Note: Calcite treats equality predicates on expressions as non-equi predicates
-        joinCondition match {
-
-          // conjunction of join predicates
-          case c: RexCall if c.getOperator.equals(SqlStdOperatorTable.AND) =>
-
-            c.getOperands.asScala
-              // look at equality predicates only
-              .filter { o =>
-                o.isInstanceOf[RexCall] &&
-                o.asInstanceOf[RexCall].getOperator.equals(SqlStdOperatorTable.EQUALS)
-              }
-              // check that both children are field references
-              .map { o =>
-                o.asInstanceOf[RexCall].getOperands.get(0).isInstanceOf[RexInputRef] &&
-                o.asInstanceOf[RexCall].getOperands.get(1).isInstanceOf[RexInputRef]
-              }
-              // any equality predicate that does not refer to a field reference?
-              .reduce( (a, b) => a && b)
-
-          // single equi-join predicate
-          case c: RexCall if c.getOperator.equals(SqlStdOperatorTable.EQUALS) =>
-            c.getOperands.get(0).isInstanceOf[RexInputRef] &&
-              c.getOperands.get(1).isInstanceOf[RexInputRef]
-          case _ =>
-            false
-        }
-      }
-
-    }
-
     def convert(rel: RelNode): RelNode = {
 
       val join: LogicalJoin = rel.asInstanceOf[LogicalJoin]
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/JoinITCase.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/JoinITCase.scala
index 4583bd46ac3..0f4a9645afa 100644
--- a/flink-libraries/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/JoinITCase.scala
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/JoinITCase.scala
@@ -18,7 +18,7 @@
 
 package org.apache.flink.api.scala.table.test
 
-import org.apache.flink.api.table.Row
+import org.apache.flink.api.table.{TableException, Row}
 import org.apache.flink.api.scala._
 import org.apache.flink.api.scala.table._
 import org.apache.flink.api.scala.util.CollectionDataSets
@@ -101,7 +101,7 @@ class JoinITCase(mode: TestExecutionMode) extends MultipleProgramsTestBase(mode)
       .select('c, 'g)
   }
 
-  @Test(expected = classOf[InvalidProgramException])
+  @Test(expected = classOf[TableException])
   def testJoinWithNonMatchingKeyTypes(): Unit = {
     val env: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment
     val ds1 = CollectionDataSets.getSmall3TupleDataSet(env).as('a, 'b, 'c)
@@ -125,6 +125,30 @@ class JoinITCase(mode: TestExecutionMode) extends MultipleProgramsTestBase(mode)
       .select('c, 'g)
   }
 
+  @Test(expected = classOf[IllegalArgumentException])
+  def testNoEqualityJoinPredicate1(): Unit = {
+    val env: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment
+    val ds1 = CollectionDataSets.getSmall3TupleDataSet(env).as('a, 'b, 'c)
+    val ds2 = CollectionDataSets.get5TupleDataSet(env).as('d, 'e, 'f, 'g, 'c)
+
+    ds1.join(ds2)
+      // must fail. No equality join predicate
+      .where('d === 'f)
+      .select('c, 'g)
+  }
+
+  @Test(expected = classOf[IllegalArgumentException])
+  def testNoEqualityJoinPredicate2(): Unit = {
+    val env: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment
+    val ds1 = CollectionDataSets.getSmall3TupleDataSet(env).as('a, 'b, 'c)
+    val ds2 = CollectionDataSets.get5TupleDataSet(env).as('d, 'e, 'f, 'g, 'c)
+
+    ds1.join(ds2)
+      // must fail. No equality join predicate
+      .where('a < 'd)
+      .select('c, 'g)
+  }
+
   @Test
   def testJoinWithAggregation(): Unit = {
     val env: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment
