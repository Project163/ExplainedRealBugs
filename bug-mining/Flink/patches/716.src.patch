diff --git a/flink-streaming-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer.java b/flink-streaming-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer.java
index e42faef30c5..2d1d91a61a7 100644
--- a/flink-streaming-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer.java
+++ b/flink-streaming-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaConsumer.java
@@ -306,6 +306,11 @@ public class FlinkKafkaConsumer<T> extends RichParallelSourceFunction<T>
 		// Connect to a broker to get the partitions
 		List<PartitionInfo> partitionInfos = getPartitionsForTopic(topic, props);
 
+		if (partitionInfos.size() == 0) {
+			throw new RuntimeException("Unable to retrieve any partitions for topic " + topic + "." +
+					"Please check previous log entries");
+		}
+
 		// get initial partitions list. The order of the partitions is important for consistent 
 		// partition id assignment in restart cases.
 		this.partitions = new int[partitionInfos.size()];
@@ -424,7 +429,11 @@ public class FlinkKafkaConsumer<T> extends RichParallelSourceFunction<T>
 			} finally {
 				if (offsetCommitter != null) {
 					offsetCommitter.close();
-					offsetCommitter.join();
+					try {
+						offsetCommitter.join();
+					} catch(InterruptedException ie) {
+						// ignore interrupt
+					}
 				}
 			}
 		}
diff --git a/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java b/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java
index 48f4c5037aa..2116c015880 100644
--- a/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java
+++ b/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java
@@ -123,6 +123,35 @@ public abstract class KafkaConsumerTestBase extends KafkaTestBase {
 	//  select which tests to run.
 	// ------------------------------------------------------------------------
 
+
+	/**
+	 * Test that ensures the KafkaConsumer is properly failing if the topic doesnt exist
+	 * and a wrong broker was specified
+	 *
+	 * @throws Exception
+	 */
+	public void runFailOnNoBrokerTest() throws Exception {
+		try {
+			Properties properties = new Properties();
+
+			StreamExecutionEnvironment see = StreamExecutionEnvironment.createRemoteEnvironment("localhost", flinkPort);
+			see.getConfig().disableSysoutLogging();
+			see.setNumberOfExecutionRetries(0);
+			see.setParallelism(1);
+
+			// use wrong ports for the consumers
+			properties.setProperty("bootstrap.servers", "localhost:80");
+			properties.setProperty("zookeeper.connect", "localhost:80");
+			properties.setProperty("group.id", "test");
+			FlinkKafkaConsumer<String> source = getConsumer("doesntexist", new SimpleStringSchema(), properties);
+			DataStream<String> stream = see.addSource(source);
+			stream.print();
+			see.execute("No broker test");
+		} catch(RuntimeException re){
+			Assert.assertTrue("Wrong RuntimeException thrown",
+					re.getMessage().contains("Unable to retrieve any partitions for topic"));
+		}
+	}
 	/**
 	 * Test that validates that checkpointing and checkpoint notification works properly
 	 */
diff --git a/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaITCase.java b/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaITCase.java
index 3ca7c5ce47f..5f2cdbca719 100644
--- a/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaITCase.java
+++ b/flink-streaming-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaITCase.java
@@ -40,6 +40,11 @@ public class KafkaITCase extends KafkaConsumerTestBase {
 		runCheckpointingTest();
 	}
 
+	@Test()
+	public void testFailOnNoBroker() throws Exception {
+		runFailOnNoBrokerTest();
+	}
+
 	@Test
 	public void testOffsetInZookeeper() throws Exception {
 		runOffsetInZookeeperValidationTest();
