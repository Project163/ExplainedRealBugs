diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/optimize/StreamCommonSubGraphBasedOptimizer.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/optimize/StreamCommonSubGraphBasedOptimizer.scala
index f67cc48f86b..279cd34760a 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/optimize/StreamCommonSubGraphBasedOptimizer.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/optimize/StreamCommonSubGraphBasedOptimizer.scala
@@ -177,7 +177,7 @@ class StreamCommonSubGraphBasedOptimizer(planner: StreamPlanner)
 
       def getMiniBatchInterval: MiniBatchInterval = miniBatchInterval
 
-      override def needFinalTimeIndicatorConversion: Boolean = true
+      override def needFinalTimeIndicatorConversion: Boolean = isSinkBlock
     })
   }
 
diff --git a/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.xml b/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.xml
index 39d6c48835a..0a921bea7b2 100644
--- a/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.xml
+++ b/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.xml
@@ -344,6 +344,37 @@ Calc(select=[w$end AS rowtime, long, EXPR$2])
 +- GroupWindowAggregate(groupBy=[long], window=[TumblingGroupWindow('w$, rowtime, 100)], properties=[w$start, w$end, w$rowtime, w$proctime], select=[long, SUM(int) AS EXPR$2, start('w$) AS w$start, end('w$) AS w$end, rowtime('w$) AS w$rowtime, proctime('w$) AS w$proctime])
    +- Exchange(distribution=[hash[long]])
       +- DataStreamScan(table=[[default_catalog, default_database, MyTable1]], fields=[rowtime, long, int])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testKeepProcessTimeAttrAfterSubGraphOptimize">
+    <Resource name="planBefore">
+      <![CDATA[
+LogicalLegacySink(name=[`default_catalog`.`default_database`.`appendSink1`], fields=[long, sum])
++- LogicalProject(long=[$1], sum=[CAST($2):BIGINT])
+   +- LogicalAggregate(group=[{0, 1}], EXPR$1=[SUM($2)])
+      +- LogicalProject($f0=[$TUMBLE($2, 10000:INTERVAL SECOND)], long=[$0], int=[$1])
+         +- LogicalTableScan(table=[[default_catalog, default_database, MyTable2]])
+
+LogicalLegacySink(name=[`default_catalog`.`default_database`.`appendSink2`], fields=[long, sum])
++- LogicalProject(long=[$1], sum=[CAST($2):BIGINT])
+   +- LogicalAggregate(group=[{0, 1}], EXPR$1=[SUM($2)])
+      +- LogicalProject($f0=[$TUMBLE($2, 10000:INTERVAL SECOND)], long=[$0], int=[$1])
+         +- LogicalTableScan(table=[[default_catalog, default_database, MyTable2]])
+]]>
+    </Resource>
+    <Resource name="planAfter">
+      <![CDATA[
+Calc(select=[long, CAST(EXPR$1) AS sum], reuse_id=[1])
++- GroupWindowAggregate(groupBy=[long], window=[TumblingGroupWindow('w$, proctime, 10000)], select=[long, SUM(int) AS EXPR$1])
+   +- Exchange(distribution=[hash[long]])
+      +- DataStreamScan(table=[[default_catalog, default_database, MyTable2]], fields=[long, int, proctime])
+
+LegacySink(name=[`default_catalog`.`default_database`.`appendSink1`], fields=[long, sum])
++- Reused(reference_id=[1])
+
+LegacySink(name=[`default_catalog`.`default_database`.`appendSink2`], fields=[long, sum])
++- Reused(reference_id=[1])
 ]]>
     </Resource>
   </TestCase>
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.scala
index c8f740f17c2..c3683ac2a69 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/RelTimeIndicatorConverterTest.scala
@@ -20,10 +20,12 @@ package org.apache.flink.table.planner.plan.stream.sql
 
 import org.apache.flink.api.scala._
 import org.apache.flink.table.api._
+import org.apache.flink.table.api.internal.TableEnvironmentInternal
 import org.apache.flink.table.data.TimestampData
 import org.apache.flink.table.functions.TableFunction
 import org.apache.flink.table.planner.plan.stream.sql.RelTimeIndicatorConverterTest.TableFunc
 import org.apache.flink.table.planner.utils.TableTestBase
+import org.apache.flink.table.types.logical.BigIntType
 
 import org.junit.Test
 
@@ -163,6 +165,37 @@ class RelTimeIndicatorConverterTest extends TableTestBase {
     util.verifyPlan(result)
   }
 
+  @Test
+  def testKeepProcessTimeAttrAfterSubGraphOptimize(): Unit = {
+    val stmtSet = util.tableEnv.createStatementSet()
+    val sql =
+      """
+        |SELECT
+        |    long,
+        |    SUM(`int`)
+        |FROM MyTable2
+        |    GROUP BY TUMBLE(proctime, INTERVAL '10' SECOND), long
+      """.stripMargin
+
+    val table = util.tableEnv.sqlQuery(sql)
+
+    val appendSink1 = util.createAppendTableSink(
+      Array("long", "sum"),
+      Array(new BigIntType(), new BigIntType()))
+    util.tableEnv.asInstanceOf[TableEnvironmentInternal].registerTableSinkInternal(
+      "appendSink1", appendSink1)
+    stmtSet.addInsert("appendSink1", table)
+
+    val appendSink2 = util.createAppendTableSink(
+      Array("long", "sum"),
+      Array(new BigIntType(), new BigIntType()))
+    util.tableEnv.asInstanceOf[TableEnvironmentInternal].registerTableSinkInternal(
+      "appendSink2", appendSink2)
+    stmtSet.addInsert("appendSink2", table)
+
+    util.verifyPlan(stmtSet)
+  }
+
   // TODO add temporal table join case
 }
 
