diff --git a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSAuthenticationException.java b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSAuthenticationException.java
index cf0d0517801..e5527b39b04 100644
--- a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSAuthenticationException.java
+++ b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSAuthenticationException.java
@@ -21,10 +21,12 @@ package org.apache.flink.connector.aws.util;
 import org.apache.flink.annotation.Internal;
 
 /**
- * A {@link IllegalStateException} wrapper indicating the exception was thrown from AWS credentials.
+ * Exception thrown on failure of authentication of Aws Credentials, this includes missing
+ * configuration, illegal access and unreachable endpoints. All {@code AWSAuthenticationException}
+ * should be non-retryable.
  */
 @Internal
-public class AWSAuthenticationException extends IllegalStateException {
+public class AWSAuthenticationException extends RuntimeException {
 
     public AWSAuthenticationException(final String message) {
         super(message);
diff --git a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialRetryableExceptionClassifiers.java b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialFatalExceptionClassifiers.java
similarity index 61%
rename from flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialRetryableExceptionClassifiers.java
rename to flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialFatalExceptionClassifiers.java
index 6172c86123e..713e11de284 100644
--- a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialRetryableExceptionClassifiers.java
+++ b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSCredentialFatalExceptionClassifiers.java
@@ -19,16 +19,16 @@
 package org.apache.flink.connector.aws.util;
 
 import org.apache.flink.annotation.Internal;
-import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
+import org.apache.flink.connector.base.sink.throwable.FatalExceptionClassifier;
 
 import software.amazon.awssdk.core.exception.SdkClientException;
 import software.amazon.awssdk.services.sts.model.StsException;
 
-/** Class containing set of {@link RetryableExceptionClassifier} for AWS credenetial failures. */
+/** Class containing set of {@link FatalExceptionClassifier} for AWS credential failures. */
 @Internal
-public class AWSCredentialRetryableExceptionClassifiers {
-    public static RetryableExceptionClassifier getInvalidCredentialsExceptionClassifier() {
-        return RetryableExceptionClassifier.withRootCauseOfType(
+public class AWSCredentialFatalExceptionClassifiers {
+    public static FatalExceptionClassifier getInvalidCredentialsExceptionClassifier() {
+        return FatalExceptionClassifier.withRootCauseOfType(
                 StsException.class,
                 err ->
                         new AWSAuthenticationException(
@@ -36,12 +36,8 @@ public class AWSCredentialRetryableExceptionClassifiers {
                                 err));
     }
 
-    public static RetryableExceptionClassifier getSdkClientMisconfiguredExceptionClassifier() {
-        return RetryableExceptionClassifier.withRootCauseOfType(
-                SdkClientException.class,
-                err ->
-                        new AWSAuthenticationException(
-                                "Encountered non-recoverable exception relating to mis-configured client",
-                                err));
+    public static FatalExceptionClassifier getSdkClientMisconfiguredExceptionClassifier() {
+        return FatalExceptionClassifier.withRootCauseOfType(
+                SdkClientException.class, err -> (Exception) err);
     }
 }
diff --git a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java
index 0c8dfc8d505..d70b438aa4f 100644
--- a/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java
+++ b/flink-connectors/flink-connector-aws-base/src/main/java/org/apache/flink/connector/aws/util/AWSGeneralUtil.java
@@ -49,8 +49,6 @@ import java.util.Map;
 import java.util.Optional;
 import java.util.Properties;
 
-import static org.apache.flink.connector.aws.config.AWSConfigConstants.CredentialProvider.WEB_IDENTITY_TOKEN;
-
 /** Some general utilities specific to Amazon Web Service. */
 @Internal
 public class AWSGeneralUtil {
@@ -93,7 +91,7 @@ public class AWSGeneralUtil {
             } catch (IllegalArgumentException e) {
                 throw new IllegalArgumentException(
                         String.format(
-                                "Invalid AWS Credential Provider type %s.",
+                                "Invalid AWS Credential Provider Type %s.",
                                 configProps.getProperty(configPrefix)),
                         e);
             }
@@ -373,20 +371,9 @@ public class AWSGeneralUtil {
         }
     }
 
-
-    public static void validateWebIdentityTokenFileCredentialsProvider(Properties config) {
-        validateCredentialProvider(config);
-        try {
-            CredentialProvider credentialProviderType =
-                    getCredentialProviderType(config, AWSConfigConstants.AWS_CREDENTIALS_PROVIDER);
-            if (credentialProviderType.equals(WEB_IDENTITY_TOKEN)) {
-                getCredentialsProvider(config).resolveCredentials();
-            }
-        } catch (Throwable e) {
-            throw new AWSAuthenticationException(
-                    String.format("Failed to create client using %s provider", WEB_IDENTITY_TOKEN),
-                    e);
-        }
+    public static void validateAwsCredentials(Properties config) {
+        validateAwsConfiguration(config);
+        getCredentialsProvider(config).resolveCredentials();
     }
 
     private static void validateCredentialProvider(Properties config) {
diff --git a/flink-connectors/flink-connector-aws-base/src/test/java/org/apache/flink/connector/aws/util/AWSGeneralUtilTest.java b/flink-connectors/flink-connector-aws-base/src/test/java/org/apache/flink/connector/aws/util/AWSGeneralUtilTest.java
index 7caf213d2cd..1edab3529ff 100644
--- a/flink-connectors/flink-connector-aws-base/src/test/java/org/apache/flink/connector/aws/util/AWSGeneralUtilTest.java
+++ b/flink-connectors/flink-connector-aws-base/src/test/java/org/apache/flink/connector/aws/util/AWSGeneralUtilTest.java
@@ -30,6 +30,7 @@ import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsPro
 import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;
 import software.amazon.awssdk.auth.credentials.SystemPropertyCredentialsProvider;
 import software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider;
+import software.amazon.awssdk.core.exception.SdkClientException;
 import software.amazon.awssdk.http.Protocol;
 import software.amazon.awssdk.http.SdkHttpConfigurationOption;
 import software.amazon.awssdk.http.async.SdkAsyncHttpClient;
@@ -742,6 +743,50 @@ public class AWSGeneralUtilTest {
         AWSGeneralUtil.validateAwsConfiguration(testConfig);
     }
 
+    @Test
+    public void testMissingWebIdentityTokenFileInCredentials() {
+        exception.expect(IllegalStateException.class);
+        exception.expectMessage(
+                "Either the environment variable AWS_WEB_IDENTITY_TOKEN_FILE or the javaproperty aws.webIdentityTokenFile must be set");
+        Properties properties = TestUtil.getStandardProperties();
+        properties.setProperty(AWS_CREDENTIALS_PROVIDER, "WEB_IDENTITY_TOKEN");
+
+        AWSGeneralUtil.validateAwsCredentials(properties);
+    }
+
+    @Test
+    public void testMissingEnvironmentVariableCredentials() {
+        exception.expect(SdkClientException.class);
+        exception.expectMessage("Access key must be specified either via environment variable");
+        Properties properties = TestUtil.getStandardProperties();
+        properties.setProperty(AWS_CREDENTIALS_PROVIDER, "ENV_VAR");
+
+        AWSGeneralUtil.validateAwsCredentials(properties);
+    }
+
+    @Test
+    public void testFailedSystemPropertiesCredentialsValidationsOnMissingAccessKey() {
+        exception.expect(SdkClientException.class);
+        exception.expectMessage(
+                "Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)");
+        Properties properties = TestUtil.getStandardProperties();
+        properties.setProperty(AWS_CREDENTIALS_PROVIDER, "SYS_PROP");
+
+        AWSGeneralUtil.validateAwsCredentials(properties);
+    }
+
+    @Test
+    public void testFailedSystemPropertiesCredentialsValidationsOnMissingSecretKey() {
+        System.setProperty("aws.accessKeyId", "accesKeyId");
+        exception.expect(SdkClientException.class);
+        exception.expectMessage(
+                "Secret key must be specified either via environment variable (AWS_SECRET_ACCESS_KEY) or system property (aws.secretAccessKey)");
+        Properties properties = TestUtil.getStandardProperties();
+        properties.setProperty(AWS_CREDENTIALS_PROVIDER, "SYS_PROP");
+
+        AWSGeneralUtil.validateAwsCredentials(properties);
+    }
+
     private WebIdentityTokenFileCredentialsProvider.Builder
             mockWebIdentityTokenFileCredentialsProviderBuilder() {
         WebIdentityTokenFileCredentialsProvider.Builder builder =
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
index 58f3001838e..c0450416779 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
@@ -20,7 +20,7 @@ package org.apache.flink.connector.kinesis.sink;
 import org.apache.flink.api.connector.sink2.Sink;
 import org.apache.flink.connector.aws.util.AWSAsyncSinkUtil;
 import org.apache.flink.connector.aws.util.AWSGeneralUtil;
-import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
+import org.apache.flink.connector.base.sink.throwable.FatalExceptionClassifier;
 import org.apache.flink.connector.base.sink.writer.AsyncSinkWriter;
 import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
@@ -45,10 +45,9 @@ import java.util.Properties;
 import java.util.concurrent.CompletableFuture;
 import java.util.function.Consumer;
 
-import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
-import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
-import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getGeneralExceptionClassifier;
-import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getInterruptedExceptionClassifier;
+import static org.apache.flink.connector.aws.util.AWSCredentialFatalExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
+import static org.apache.flink.connector.aws.util.AWSCredentialFatalExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkFatalExceptionClassifiers.getInterruptedExceptionClassifier;
 
 /**
  * Sink writer created by {@link KinesisDataStreamsSink} to write to Kinesis Data Streams. More
@@ -63,30 +62,20 @@ import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExce
 class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRecordsRequestEntry> {
     private static final Logger LOG = LoggerFactory.getLogger(KinesisDataStreamsSinkWriter.class);
 
-    private static final RetryableExceptionClassifier RESOURCE_NOT_FOUND_STRATEGY =
-            RetryableExceptionClassifier.withRootCauseOfType(
+    private static final FatalExceptionClassifier RESOURCE_NOT_FOUND_EXCEPTION_CLASSIFIER =
+            FatalExceptionClassifier.withRootCauseOfType(
                     ResourceNotFoundException.class,
                     err ->
                             new KinesisDataStreamsException(
                                     "Encountered non-recoverable exception relating to not being able to find the specified resources",
                                     err));
 
-    private static final RetryableExceptionClassifier NON_RECOVERABLE_EXCEPTION_STRATEGY =
-            RetryableExceptionClassifier.withRootCauseOfType(
-                    Error.class,
-                    err ->
-                            new KinesisDataStreamsException(
-                                    "Encountered non-recoverable exception in the Kinesis Data Streams Sink",
-                                    err));
-
-    private static final RetryableExceptionClassifier KINESIS_RETRY_VALIDATION_STRATEGY =
-            RetryableExceptionClassifier.createChain(
-                    getGeneralExceptionClassifier(),
+    private static final FatalExceptionClassifier KINESIS_FATAL_EXCEPTION_CLASSIFIER =
+            FatalExceptionClassifier.createChain(
                     getInterruptedExceptionClassifier(),
                     getInvalidCredentialsExceptionClassifier(),
-                    RESOURCE_NOT_FOUND_STRATEGY,
-                    getSdkClientMisconfiguredExceptionClassifier(),
-                    NON_RECOVERABLE_EXCEPTION_STRATEGY);
+                    RESOURCE_NOT_FOUND_EXCEPTION_CLASSIFIER,
+                    getSdkClientMisconfiguredExceptionClassifier());
 
     /* A counter for the total number of records that have encountered an error during put */
     private final Counter numRecordsOutErrorsCounter;
@@ -164,9 +153,10 @@ class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRe
         this.kinesisClient = buildClient(kinesisClientProperties, this.httpClient);
     }
 
-    private KinesisAsyncClient buildClient(Properties kinesisClientProperties, SdkAsyncHttpClient httpClient) {
-        AWSGeneralUtil.validateAwsConfiguration(kinesisClientProperties);
-        AWSGeneralUtil.validateWebIdentityTokenFileCredentialsProvider(kinesisClientProperties);
+    private KinesisAsyncClient buildClient(
+            Properties kinesisClientProperties, SdkAsyncHttpClient httpClient) {
+        AWSGeneralUtil.validateAwsCredentials(kinesisClientProperties);
+
         return AWSAsyncSinkUtil.createAwsAsyncClient(
                 kinesisClientProperties,
                 httpClient,
@@ -248,7 +238,7 @@ class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRe
 
     private boolean isRetryable(Throwable err) {
 
-        if (!KINESIS_RETRY_VALIDATION_STRATEGY.shouldSuppress(err, getFatalExceptionCons())) {
+        if (!KINESIS_FATAL_EXCEPTION_CLASSIFIER.isFatal(err, getFatalExceptionCons())) {
             return false;
         }
         if (failOnError) {
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java
index cad256f225b..3e23e871fdd 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkITCase.java
@@ -209,9 +209,9 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
     private void badRegionShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
         Properties properties = getDefaultProperties();
         properties.setProperty(AWS_REGION, "some-bad-region");
-        String streamName = "do-not-create-new-stream";
+
         assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
-                streamName, failOnError, properties, "Invalid AWS region set in config");
+                failOnError, properties, "Invalid AWS region");
     }
 
     @Test
@@ -227,9 +227,8 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
     private void missingRegionShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
         Properties properties = getDefaultProperties();
         properties.remove(AWS_REGION);
-        String streamName = "do-not-create-new-stream";
         assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
-                streamName, failOnError, properties, "region must not be null.");
+                failOnError, properties, "region must not be null.");
     }
 
     @Test
@@ -245,12 +244,8 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
     private void noURIEndpointShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
         Properties properties = getDefaultProperties();
         properties.setProperty(AWS_ENDPOINT, "bad-endpoint-no-uri");
-        String streamName = "do-not-create-new-stream";
         assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
-                streamName,
-                failOnError,
-                properties,
-                "The URI scheme of endpointOverride must not be null.");
+                failOnError, properties, "The URI scheme of endpointOverride must not be null.");
     }
 
     @Test
@@ -266,12 +261,10 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
     private void badEndpointShouldResultInFailureWhenInFailOnErrorIs(boolean failOnError) {
         Properties properties = getDefaultProperties();
         properties.setProperty(AWS_ENDPOINT, "https://bad-endpoint-with-uri");
-        String streamName = "do-not-create-new-stream";
         assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
-                streamName,
                 failOnError,
                 properties,
-                "Encountered non-recoverable exception relating to mis-configured client");
+                "UnknownHostException when attempting to interact with a service.");
     }
 
     @Test
@@ -279,7 +272,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 true,
                 AWSConfigConstants.CredentialProvider.ENV_VAR.toString(),
-                "Encountered non-recoverable exception relating to mis-configured client");
+                "Access key must be specified either via environment variable");
     }
 
     @Test
@@ -287,7 +280,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 false,
                 AWSConfigConstants.CredentialProvider.ENV_VAR.toString(),
-                "Encountered non-recoverable exception relating to mis-configured client");
+                "Access key must be specified either via environment variable");
     }
 
     @Test
@@ -295,7 +288,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 true,
                 AWSConfigConstants.CredentialProvider.SYS_PROP.toString(),
-                "Encountered non-recoverable exception relating to mis-configured client");
+                "Unable to load credentials from system settings");
     }
 
     @Test
@@ -303,7 +296,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 false,
                 AWSConfigConstants.CredentialProvider.SYS_PROP.toString(),
-                "Encountered non-recoverable exception relating to mis-configured client");
+                "Unable to load credentials from system settings");
     }
 
     @Test
@@ -311,12 +304,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 true,
                 AWSConfigConstants.CredentialProvider.BASIC.toString(),
-                "Please set values for AWS Access Key ID ('"
-                        + AWSConfigConstants.AWS_ACCESS_KEY_ID
-                        + "') "
-                        + "and Secret Key ('"
-                        + AWSConfigConstants.AWS_SECRET_ACCESS_KEY
-                        + "') when using the BASIC AWS credential provider type.");
+                "Please set values for AWS Access Key ID ('aws.credentials.provider.basic.accesskeyid') and Secret Key ('aws.credentials.provider.basic.secretkey') when using the BASIC AWS credential provider type.");
     }
 
     @Test
@@ -324,12 +312,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 false,
                 AWSConfigConstants.CredentialProvider.BASIC.toString(),
-                "Please set values for AWS Access Key ID ('"
-                        + AWSConfigConstants.AWS_ACCESS_KEY_ID
-                        + "') "
-                        + "and Secret Key ('"
-                        + AWSConfigConstants.AWS_SECRET_ACCESS_KEY
-                        + "') when using the BASIC AWS credential provider type.");
+                "Please set values for AWS Access Key ID ('aws.credentials.provider.basic.accesskeyid') and Secret Key ('aws.credentials.provider.basic.secretkey') when using the BASIC AWS credential provider type.");
     }
 
     @Test
@@ -337,7 +320,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 true,
                 AWSConfigConstants.CredentialProvider.WEB_IDENTITY_TOKEN.toString(),
-                "Failed to create client using WEB_IDENTITY_TOKEN provider");
+                "Either the environment variable AWS_WEB_IDENTITY_TOKEN_FILE or the javaproperty aws.webIdentityTokenFile must be set");
     }
 
     @Test
@@ -345,7 +328,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
                 false,
                 AWSConfigConstants.CredentialProvider.WEB_IDENTITY_TOKEN.toString(),
-                "Failed to create client using WEB_IDENTITY_TOKEN provider");
+                "Either the environment variable AWS_WEB_IDENTITY_TOKEN_FILE or the javaproperty aws.webIdentityTokenFile must be set");
     }
 
     @Test
@@ -371,26 +354,24 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
                 AWSConfigConstants.profilePath(AWS_CREDENTIALS_PROVIDER),
                 credentialsProfileLocation);
         assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
-                "do-not-create-new-stream", failOnError, properties, expectedMessage);
+                failOnError, properties, expectedMessage);
     }
 
     private void noCredentialsProvidedAndCredentialsProviderSpecifiedShouldResultInFailure(
             boolean failOnError, String credentialsProvider, String expectedMessage) {
         assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
-                "do-not-create-new-stream",
                 failOnError,
                 getDefaultPropertiesWithoutCredentialsSetAndCredentialProvider(credentialsProvider),
                 expectedMessage);
     }
 
     private void assertRunWithPropertiesAndStreamShouldFailWithExceptionOfType(
-            String streamName, boolean failOnError, Properties properties, String expectedMessage) {
+            boolean failOnError, Properties properties, String expectedMessage) {
         Assertions.assertThatExceptionOfType(JobExecutionException.class)
                 .isThrownBy(
                         () ->
                                 new Scenario()
-                                        .withKinesaliteStreamName(streamName)
-                                        .withSinkConnectionStreamName(streamName)
+                                        .withSinkConnectionStreamName("default-stream-name")
                                         .withFailOnError(failOnError)
                                         .withProperties(properties)
                                         .runScenario())
@@ -425,7 +406,7 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         private int maxBatchSize = 50;
         private int expectedElements = 50;
         private boolean failOnError = false;
-        private String kinesaliteStreamName;
+        private String kinesaliteStreamName = null;
         private String sinkConnectionStreamName;
         private SerializationSchema<String> serializationSchema =
                 KinesisDataStreamsSinkITCase.this.serializationSchema;
@@ -434,7 +415,10 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         private Properties properties = KinesisDataStreamsSinkITCase.this.getDefaultProperties();
 
         public void runScenario() throws Exception {
-            prepareStream(kinesaliteStreamName);
+            if (kinesaliteStreamName != null) {
+                prepareStream(kinesaliteStreamName);
+            }
+
             properties.setProperty(TRUST_ALL_CERTIFICATES, "true");
             properties.setProperty(HTTP_PROTOCOL_VERSION, "HTTP1_1");
 
@@ -549,9 +533,6 @@ public class KinesisDataStreamsSinkITCase extends TestLogger {
         }
 
         private void prepareStream(String streamName) throws Exception {
-            if (streamName.equals("do-not-create-new-stream")) {
-                return;
-            }
             final RateLimiter rateLimiter =
                     RateLimiterBuilder.newBuilder()
                             .withRate(1, SECONDS)
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
index 770404b6fff..46e93c01ea2 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
@@ -21,8 +21,7 @@ import org.apache.flink.annotation.Internal;
 import org.apache.flink.api.connector.sink2.Sink;
 import org.apache.flink.connector.aws.util.AWSAsyncSinkUtil;
 import org.apache.flink.connector.aws.util.AWSGeneralUtil;
-import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
-import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
+import org.apache.flink.connector.base.sink.throwable.FatalExceptionClassifier;
 import org.apache.flink.connector.base.sink.writer.AsyncSinkWriter;
 import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
@@ -47,15 +46,9 @@ import java.util.Properties;
 import java.util.concurrent.CompletableFuture;
 import java.util.function.Consumer;
 
-import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
-import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
-import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getGeneralExceptionClassifier;
-import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getInterruptedExceptionClassifier;
-
-import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
-import static org.apache.flink.connector.aws.util.AWSCredentialRetryableExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
-import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getGeneralExceptionClassifier;
-import static org.apache.flink.connector.base.sink.writer.AsyncSinkRetryableExceptionClassifiers.getInterruptedExceptionClassifier;
+import static org.apache.flink.connector.aws.util.AWSCredentialFatalExceptionClassifiers.getInvalidCredentialsExceptionClassifier;
+import static org.apache.flink.connector.aws.util.AWSCredentialFatalExceptionClassifiers.getSdkClientMisconfiguredExceptionClassifier;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkFatalExceptionClassifiers.getInterruptedExceptionClassifier;
 
 /**
  * Sink writer created by {@link KinesisFirehoseSink} to write to Kinesis Data Firehose. More
@@ -78,6 +71,7 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
 
     private static FirehoseAsyncClient createFirehoseClient(
             Properties firehoseClientProperties, SdkAsyncHttpClient httpClient) {
+        AWSGeneralUtil.validateAwsCredentials(firehoseClientProperties);
         return AWSAsyncSinkUtil.createAwsAsyncClient(
                 firehoseClientProperties,
                 httpClient,
@@ -86,30 +80,20 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
                 KinesisFirehoseConfigConstants.FIREHOSE_CLIENT_USER_AGENT_PREFIX);
     }
 
-    private static final RetryableExceptionClassifier RESOURCE_NOT_FOUND_STRATEGY =
-            RetryableExceptionClassifier.withRootCauseOfType(
+    private static final FatalExceptionClassifier RESOURCE_NOT_FOUND_EXCEPTION_CLASSIFIER =
+            FatalExceptionClassifier.withRootCauseOfType(
                     ResourceNotFoundException.class,
                     err ->
                             new KinesisFirehoseException(
                                     "Encountered non-recoverable exception relating to not being able to find the specified resources",
                                     err));
 
-    private static final RetryableExceptionClassifier NON_RECOVERABLE_EXCEPTION_STRATEGY =
-            RetryableExceptionClassifier.withRootCauseOfType(
-                    Error.class,
-                    err ->
-                            new KinesisFirehoseException(
-                                    "Encountered non-recoverable exception in the Kinesis Data Firehose Sink",
-                                    err));
-
-    private static final RetryableExceptionClassifier FIREHOSE_RETRY_VALIDATION_STRATEGY =
-            RetryableExceptionClassifier.createChain(
-                    getGeneralExceptionClassifier(),
+    private static final FatalExceptionClassifier FIREHOSE_FATAL_EXCEPTION_CLASSIFIER =
+            FatalExceptionClassifier.createChain(
                     getInterruptedExceptionClassifier(),
                     getInvalidCredentialsExceptionClassifier(),
-                    RESOURCE_NOT_FOUND_STRATEGY,
-                    getSdkClientMisconfiguredExceptionClassifier(),
-                    NON_RECOVERABLE_EXCEPTION_STRATEGY);
+                    RESOURCE_NOT_FOUND_EXCEPTION_CLASSIFIER,
+                    getSdkClientMisconfiguredExceptionClassifier());
 
     /* A counter for the total number of records that have encountered an error during put */
     private final Counter numRecordsOutErrorsCounter;
@@ -187,20 +171,6 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
         this.firehoseClient = createFirehoseClient(firehoseClientProperties, httpClient);
     }
 
-    private FirehoseAsyncClient buildClient(Properties firehoseClientProperties) {
-        AWSGeneralUtil.validateAwsConfiguration(firehoseClientProperties);
-        AWSGeneralUtil.validateWebIdentityTokenFileCredentialsProvider(firehoseClientProperties);
-        final SdkAsyncHttpClient httpClient =
-                AWSGeneralUtil.createAsyncHttpClient(firehoseClientProperties);
-
-        return AWSAsyncSinkUtil.createAwsAsyncClient(
-                firehoseClientProperties,
-                httpClient,
-                FirehoseAsyncClient.builder(),
-                KinesisFirehoseConfigConstants.BASE_FIREHOSE_USER_AGENT_PREFIX_FORMAT,
-                KinesisFirehoseConfigConstants.FIREHOSE_CLIENT_USER_AGENT_PREFIX);
-    }
-
     @Override
     protected void submitRequestEntries(
             List<Record> requestEntries, Consumer<List<Record>> requestResult) {
@@ -280,7 +250,7 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
     }
 
     private boolean isRetryable(Throwable err) {
-        if (!FIREHOSE_RETRY_VALIDATION_STRATEGY.shouldSuppress(err, getFatalExceptionCons())) {
+        if (!FIREHOSE_FATAL_EXCEPTION_CLASSIFIER.isFatal(err, getFatalExceptionCons())) {
             return false;
         }
         if (failOnError) {
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java
index de1c943f1b9..602d6546106 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkITCase.java
@@ -18,17 +18,12 @@
 package org.apache.flink.connector.firehose.sink;
 
 import org.apache.flink.api.common.serialization.SimpleStringSchema;
-import org.apache.flink.connector.aws.config.AWSConfigConstants;
+import org.apache.flink.connector.aws.testutils.AWSServicesTestUtils;
 import org.apache.flink.connector.aws.testutils.LocalstackContainer;
-import org.apache.flink.runtime.client.JobExecutionException;
-import org.apache.flink.streaming.api.datastream.DataStream;
+import org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.util.DockerImageVersions;
 
-import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonProcessingException;
-import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;
-
-import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.ClassRule;
@@ -37,28 +32,23 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.testcontainers.utility.DockerImageName;
 import software.amazon.awssdk.core.SdkSystemSetting;
+import software.amazon.awssdk.http.async.SdkAsyncHttpClient;
 import software.amazon.awssdk.services.firehose.FirehoseAsyncClient;
 import software.amazon.awssdk.services.iam.IamAsyncClient;
 import software.amazon.awssdk.services.s3.S3AsyncClient;
 import software.amazon.awssdk.services.s3.model.S3Object;
-import software.amazon.awssdk.utils.ImmutableMap;
 
-import java.util.ArrayList;
 import java.util.List;
-import java.util.Properties;
 
-import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_CREDENTIALS_PROVIDER;
-import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_REGION;
-import static org.apache.flink.connector.aws.config.AWSConfigConstants.TRUST_ALL_CERTIFICATES;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createBucket;
+import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createConfig;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createIAMRole;
-import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.getConfig;
-import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.getIamClient;
-import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.getS3Client;
+import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createIamClient;
+import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createS3Client;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.listBucketObjects;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.readObjectsFromS3Bucket;
 import static org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils.createDeliveryStream;
-import static org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils.getFirehoseClient;
+import static org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils.createFirehoseClient;
 import static org.assertj.core.api.Assertions.assertThat;
 
 /** Integration test suite for the {@code KinesisFirehoseSink} using a localstack container. */
@@ -71,8 +61,8 @@ public class KinesisFirehoseSinkITCase {
     private static final String STREAM_NAME = "s3-stream";
     private static final int NUMBER_OF_ELEMENTS = 92;
     private StreamExecutionEnvironment env;
-    private static final ObjectMapper MAPPER = new ObjectMapper();
 
+    private SdkAsyncHttpClient httpClient;
     private S3AsyncClient s3AsyncClient;
     private FirehoseAsyncClient firehoseAsyncClient;
     private IamAsyncClient iamAsyncClient;
@@ -84,9 +74,10 @@ public class KinesisFirehoseSinkITCase {
     @Before
     public void setup() throws Exception {
         System.setProperty(SdkSystemSetting.CBOR_ENABLED.property(), "false");
-        s3AsyncClient = getS3Client(mockFirehoseContainer.getEndpoint());
-        firehoseAsyncClient = getFirehoseClient(mockFirehoseContainer.getEndpoint());
-        iamAsyncClient = getIamClient(mockFirehoseContainer.getEndpoint());
+        httpClient = AWSServicesTestUtils.createHttpClient(mockFirehoseContainer.getEndpoint());
+        s3AsyncClient = createS3Client(mockFirehoseContainer.getEndpoint(), httpClient);
+        firehoseAsyncClient = createFirehoseClient(mockFirehoseContainer.getEndpoint(), httpClient);
+        iamAsyncClient = createIamClient(mockFirehoseContainer.getEndpoint(), httpClient);
         env = StreamExecutionEnvironment.getExecutionEnvironment();
     }
 
@@ -109,14 +100,17 @@ public class KinesisFirehoseSinkITCase {
                         .setSerializationSchema(new SimpleStringSchema())
                         .setDeliveryStreamName(STREAM_NAME)
                         .setMaxBatchSize(1)
-                        .setFirehoseClientProperties(getConfig(mockFirehoseContainer.getEndpoint()))
+                        .setFirehoseClientProperties(
+                                createConfig(mockFirehoseContainer.getEndpoint()))
                         .build();
 
-        getSampleDataGenerator().sinkTo(kdsSink);
+        KinesisFirehoseTestUtils.getSampleDataGenerator(env, NUMBER_OF_ELEMENTS).sinkTo(kdsSink);
         env.execute("Integration Test");
 
         List<S3Object> objects =
-                listBucketObjects(getS3Client(mockFirehoseContainer.getEndpoint()), BUCKET_NAME);
+                listBucketObjects(
+                        createS3Client(mockFirehoseContainer.getEndpoint(), httpClient),
+                        BUCKET_NAME);
         assertThat(objects.size()).isEqualTo(NUMBER_OF_ELEMENTS);
         assertThat(
                         readObjectsFromS3Bucket(
@@ -124,69 +118,6 @@ public class KinesisFirehoseSinkITCase {
                                 objects,
                                 BUCKET_NAME,
                                 response -> new String(response.asByteArrayUnsafe())))
-                .containsAll(getSampleDataGenerated());
-    }
-
-    @Test
-    public void firehoseSinkFailsWhenAccessKeyIdIsNotProvided() {
-        Properties properties = getConfig(mockFirehoseContainer.getEndpoint());
-        properties.setProperty(
-                AWS_CREDENTIALS_PROVIDER, AWSConfigConstants.CredentialProvider.BASIC.toString());
-        properties.remove(AWSConfigConstants.accessKeyId(AWS_CREDENTIALS_PROVIDER));
-        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
-                properties, "Please set values for AWS Access Key ID");
-    }
-
-    @Test
-    public void firehoseSinkFailsWhenRegionIsNotProvided() {
-        Properties properties = getConfig(mockFirehoseContainer.getEndpoint());
-        properties.remove(AWS_REGION);
-        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
-                properties, "region must not be null.");
-    }
-
-    @Test
-    public void firehoseSinkFailsWhenUnableToConnectToRemoteService() {
-        Properties properties = getConfig(mockFirehoseContainer.getEndpoint());
-        properties.remove(TRUST_ALL_CERTIFICATES);
-        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
-                properties,
-                "Encountered non-recoverable exception relating to mis-configured client");
-    }
-
-    private void firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
-            Properties properties, String errorMessage) {
-        KinesisFirehoseSink<String> kdsSink =
-                KinesisFirehoseSink.<String>builder()
-                        .setSerializationSchema(new SimpleStringSchema())
-                        .setDeliveryStreamName("non-existent-stream")
-                        .setMaxBatchSize(1)
-                        .setFirehoseClientProperties(properties)
-                        .build();
-
-        getSampleDataGenerator().sinkTo(kdsSink);
-
-        Assertions.assertThatExceptionOfType(JobExecutionException.class)
-                .isThrownBy(() -> env.execute("Integration Test"))
-                .havingCause()
-                .havingCause()
-                .withMessageContaining(errorMessage);
-    }
-
-    private DataStream<String> getSampleDataGenerator() {
-        ObjectMapper mapper = new ObjectMapper();
-        return env.fromSequence(1, NUMBER_OF_ELEMENTS)
-                .map(Object::toString)
-                .returns(String.class)
-                .map(data -> mapper.writeValueAsString(ImmutableMap.of("data", data)));
-    }
-
-    private List<String> getSampleDataGenerated() throws JsonProcessingException {
-        List<String> expectedElements = new ArrayList<>();
-        for (int i = 1; i <= NUMBER_OF_ELEMENTS; i++) {
-            expectedElements.add(
-                    MAPPER.writeValueAsString(ImmutableMap.of("data", String.valueOf(i))));
-        }
-        return expectedElements;
+                .containsAll(KinesisFirehoseTestUtils.getSampleData(NUMBER_OF_ELEMENTS));
     }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkTest.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkTest.java
index 164ec398605..e91cb395fef 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkTest.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkTest.java
@@ -18,7 +18,11 @@
 package org.apache.flink.connector.firehose.sink;
 
 import org.apache.flink.api.common.serialization.SimpleStringSchema;
+import org.apache.flink.connector.aws.config.AWSConfigConstants;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
+import org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils;
+import org.apache.flink.runtime.client.JobExecutionException;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 
 import org.assertj.core.api.Assertions;
 import org.junit.Test;
@@ -26,6 +30,11 @@ import software.amazon.awssdk.services.firehose.model.Record;
 
 import java.util.Properties;
 
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_CREDENTIALS_PROVIDER;
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_REGION;
+import static org.apache.flink.connector.aws.config.AWSConfigConstants.TRUST_ALL_CERTIFICATES;
+import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.createConfig;
+
 /** Covers construction, defaults and sanity checking of {@link KinesisFirehoseSink}. */
 public class KinesisFirehoseSinkTest {
 
@@ -73,4 +82,51 @@ public class KinesisFirehoseSinkTest {
                 .withMessageContaining(
                         "The delivery stream name must be set when initializing the KDF Sink.");
     }
+
+    @Test
+    public void firehoseSinkFailsWhenAccessKeyIdIsNotProvided() {
+        Properties properties = createConfig("https://non-exisitent-location");
+        properties.setProperty(
+                AWS_CREDENTIALS_PROVIDER, AWSConfigConstants.CredentialProvider.BASIC.toString());
+        properties.remove(AWSConfigConstants.accessKeyId(AWS_CREDENTIALS_PROVIDER));
+        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+                properties, "Please set values for AWS Access Key ID");
+    }
+
+    @Test
+    public void firehoseSinkFailsWhenRegionIsNotProvided() {
+        Properties properties = createConfig("https://non-exisitent-location");
+        properties.remove(AWS_REGION);
+        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+                properties, "region must not be null.");
+    }
+
+    @Test
+    public void firehoseSinkFailsWhenUnableToConnectToRemoteService() {
+        Properties properties = createConfig("https://non-exisitent-location");
+        properties.remove(TRUST_ALL_CERTIFICATES);
+        firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+                properties,
+                "Received an UnknownHostException when attempting to interact with a service.");
+    }
+
+    private void firehoseSinkFailsWithAppropriateMessageWhenInitialConditionsAreMisconfigured(
+            Properties properties, String errorMessage) {
+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        KinesisFirehoseSink<String> kdsSink =
+                KinesisFirehoseSink.<String>builder()
+                        .setSerializationSchema(new SimpleStringSchema())
+                        .setDeliveryStreamName("non-existent-stream")
+                        .setMaxBatchSize(1)
+                        .setFirehoseClientProperties(properties)
+                        .build();
+
+        KinesisFirehoseTestUtils.getSampleDataGenerator(env, 10).sinkTo(kdsSink);
+
+        Assertions.assertThatExceptionOfType(JobExecutionException.class)
+                .isThrownBy(() -> env.execute("Integration Test"))
+                .havingCause()
+                .havingCause()
+                .withMessageContaining(errorMessage);
+    }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java
index d8dc5d40f7d..0366d0f64e9 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java
@@ -19,21 +19,19 @@ package org.apache.flink.connector.firehose.sink;
 
 import org.apache.flink.api.common.serialization.SimpleStringSchema;
 import org.apache.flink.api.connector.sink2.SinkWriter;
-import org.apache.flink.connector.aws.config.AWSConfigConstants;
+import org.apache.flink.connector.aws.testutils.AWSServicesTestUtils;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.connector.base.sink.writer.TestSinkInitContext;
 
 import org.junit.Before;
 import org.junit.Test;
 import software.amazon.awssdk.core.SdkBytes;
-import software.amazon.awssdk.regions.Region;
 import software.amazon.awssdk.services.firehose.model.Record;
 
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
 import java.util.Properties;
 
-import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_ENDPOINT;
 import static org.assertj.core.api.Assertions.assertThat;
 
 /** Covers construction, defaults and sanity checking of {@link KinesisFirehoseSinkWriter}. */
@@ -49,8 +47,7 @@ public class KinesisFirehoseSinkWriterTest {
     @Before
     public void setup() {
         TestSinkInitContext sinkInitContext = new TestSinkInitContext();
-        Properties sinkProperties = new Properties();
-        sinkProperties.put(AWSConfigConstants.AWS_REGION, "eu-west-1");
+        Properties sinkProperties = AWSServicesTestUtils.createConfig("https://fake_aws_endpoint");
         sinkWriter =
                 new KinesisFirehoseSinkWriter<>(
                         ELEMENT_CONVERTER_PLACEHOLDER,
@@ -77,9 +74,7 @@ public class KinesisFirehoseSinkWriterTest {
     @Test
     public void getNumRecordsOutErrorsCounterRecordsCorrectNumberOfFailures()
             throws IOException, InterruptedException {
-        Properties prop = new Properties();
-        prop.setProperty(AWSConfigConstants.AWS_REGION, Region.EU_WEST_1.toString());
-        prop.setProperty(AWS_ENDPOINT, "https://fake_aws_endpoint");
+        Properties prop = AWSServicesTestUtils.createConfig("https://fake_aws_endpoint");
         TestSinkInitContext ctx = new TestSinkInitContext();
         KinesisFirehoseSink<String> kinesisFirehoseSink =
                 new KinesisFirehoseSink<>(
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/testutils/KinesisFirehoseTestUtils.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/testutils/KinesisFirehoseTestUtils.java
index 4496662195c..d6b3964e38c 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/testutils/KinesisFirehoseTestUtils.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/testutils/KinesisFirehoseTestUtils.java
@@ -19,6 +19,11 @@ package org.apache.flink.connector.firehose.sink.testutils;
 
 import org.apache.flink.connector.aws.util.AWSAsyncSinkUtil;
 import org.apache.flink.connector.firehose.sink.KinesisFirehoseConfigConstants;
+import org.apache.flink.streaming.api.datastream.DataStream;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+
+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonProcessingException;
+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;
 
 import software.amazon.awssdk.http.async.SdkAsyncHttpClient;
 import software.amazon.awssdk.services.firehose.FirehoseAsyncClient;
@@ -26,9 +31,12 @@ import software.amazon.awssdk.services.firehose.model.CreateDeliveryStreamReques
 import software.amazon.awssdk.services.firehose.model.CreateDeliveryStreamResponse;
 import software.amazon.awssdk.services.firehose.model.DeliveryStreamType;
 import software.amazon.awssdk.services.firehose.model.ExtendedS3DestinationConfiguration;
+import software.amazon.awssdk.utils.ImmutableMap;
 
 import java.net.URI;
 import java.net.URISyntaxException;
+import java.util.ArrayList;
+import java.util.List;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
@@ -39,7 +47,9 @@ import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.crea
  */
 public class KinesisFirehoseTestUtils {
 
-    public static FirehoseAsyncClient getFirehoseClient(
+    private static final ObjectMapper MAPPER = new ObjectMapper();
+
+    public static FirehoseAsyncClient createFirehoseClient(
             String endpoint, SdkAsyncHttpClient httpClient) throws URISyntaxException {
         return AWSAsyncSinkUtil.createAwsAsyncClient(
                 createConfig(endpoint),
@@ -73,4 +83,22 @@ public class KinesisFirehoseTestUtils {
                 firehoseAsyncClient.createDeliveryStream(request);
         deliveryStream.get();
     }
+
+    public static DataStream<String> getSampleDataGenerator(
+            StreamExecutionEnvironment env, int endValue) {
+        ObjectMapper mapper = new ObjectMapper();
+        return env.fromSequence(1, endValue)
+                .map(Object::toString)
+                .returns(String.class)
+                .map(data -> mapper.writeValueAsString(ImmutableMap.of("data", data)));
+    }
+
+    public static List<String> getSampleData(int endValue) throws JsonProcessingException {
+        List<String> expectedElements = new ArrayList<>();
+        for (int i = 1; i <= endValue; i++) {
+            expectedElements.add(
+                    MAPPER.writeValueAsString(ImmutableMap.of("data", String.valueOf(i))));
+        }
+        return expectedElements;
+    }
 }
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifier.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/throwable/FatalExceptionClassifier.java
similarity index 68%
rename from flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifier.java
rename to flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/throwable/FatalExceptionClassifier.java
index 71aa5dfdd0c..a1c4ae401c9 100644
--- a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifier.java
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/throwable/FatalExceptionClassifier.java
@@ -16,7 +16,7 @@
  * limitations under the License.
  */
 
-package org.apache.flink.connector.base.sink.util;
+package org.apache.flink.connector.base.sink.throwable;
 
 import org.apache.flink.annotation.Internal;
 import org.apache.flink.util.ExceptionUtils;
@@ -29,43 +29,46 @@ import java.util.function.Predicate;
 
 /** Classifier class for retryable exceptions on request submission failure. */
 @Internal
-public class RetryableExceptionClassifier {
+public class FatalExceptionClassifier {
     private final Function<Throwable, Exception> throwableMapper;
     private final Predicate<Throwable> validator;
-    private RetryableExceptionClassifier chainedClassifier;
+    private FatalExceptionClassifier chainedClassifier;
 
-    public RetryableExceptionClassifier(
+    public FatalExceptionClassifier(
             Predicate<Throwable> validator, Function<Throwable, Exception> throwableMapper) {
         this.throwableMapper = throwableMapper;
         this.validator = validator;
         this.chainedClassifier = null;
     }
 
-    public boolean shouldSuppress(Throwable err, Consumer<Exception> throwableConsumer) {
+    public boolean isFatal(Throwable err, Consumer<Exception> throwableConsumer) {
         if (validator.test(err)) {
             throwableConsumer.accept(throwableMapper.apply(err));
             return false;
         }
 
         if (chainedClassifier != null) {
-            return chainedClassifier.shouldSuppress(err, throwableConsumer);
+            return chainedClassifier.isFatal(err, throwableConsumer);
         } else {
             return true;
         }
     }
 
-    public static RetryableExceptionClassifier withRootCauseOfType(
+    public static FatalExceptionClassifier withRootCauseOfType(
             Class<? extends Throwable> type, Function<Throwable, Exception> mapper) {
-        return new RetryableExceptionClassifier(
+        return new FatalExceptionClassifier(
                 err -> ExceptionUtils.findThrowable(err, type).isPresent(), mapper);
     }
 
-    public static RetryableExceptionClassifier createChain(
-            RetryableExceptionClassifier... classifiers) {
-        Set<RetryableExceptionClassifier> importedClassifiers = new HashSet<>();
+    public static FatalExceptionClassifier createChain(FatalExceptionClassifier... classifiers) {
+        Set<FatalExceptionClassifier> importedClassifiers = new HashSet<>();
 
-        RetryableExceptionClassifier taleClassifier = classifiers[0];
-        importedClassifiers.add(taleClassifier);
+        if (classifiers.length == 0) {
+            throw new IllegalArgumentException("Cannot create empty classifier chain.");
+        }
+
+        FatalExceptionClassifier tailClassifier = classifiers[0];
+        importedClassifiers.add(tailClassifier);
 
         for (int i = 1; i < classifiers.length; ++i) {
             if (importedClassifiers.contains(classifiers[i])) {
@@ -73,9 +76,9 @@ public class RetryableExceptionClassifier {
                         "Wrong classifier chain; Circular chain of classifiers detected.");
             }
 
-            taleClassifier.chainedClassifier = classifiers[i];
-            taleClassifier = classifiers[i];
-            importedClassifiers.add(taleClassifier);
+            tailClassifier.chainedClassifier = classifiers[i];
+            tailClassifier = classifiers[i];
+            importedClassifiers.add(tailClassifier);
         }
 
         return classifiers[0];
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkRetryableExceptionClassifiers.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkFatalExceptionClassifiers.java
similarity index 62%
rename from flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkRetryableExceptionClassifiers.java
rename to flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkFatalExceptionClassifiers.java
index b8933769590..8cb01ae1255 100644
--- a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkRetryableExceptionClassifiers.java
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkFatalExceptionClassifiers.java
@@ -19,20 +19,15 @@
 package org.apache.flink.connector.base.sink.writer;
 
 import org.apache.flink.annotation.Internal;
-import org.apache.flink.connector.base.sink.util.RetryableExceptionClassifier;
+import org.apache.flink.connector.base.sink.throwable.FatalExceptionClassifier;
 import org.apache.flink.util.FlinkException;
 
 /** Common retry exception classifiers needed for common errors. */
 @Internal
-public class AsyncSinkRetryableExceptionClassifiers {
-    public static RetryableExceptionClassifier getInterruptedExceptionClassifier() {
-        return RetryableExceptionClassifier.withRootCauseOfType(
-                InterruptedException.class, err -> new FlinkException("Thread was interrupted"));
-    }
-
-    public static RetryableExceptionClassifier getGeneralExceptionClassifier() {
-        return RetryableExceptionClassifier.withRootCauseOfType(
-                Error.class,
-                err -> new RuntimeException("Encountered non-recoverable exception", err));
+public class AsyncSinkFatalExceptionClassifiers {
+    public static FatalExceptionClassifier getInterruptedExceptionClassifier() {
+        return FatalExceptionClassifier.withRootCauseOfType(
+                InterruptedException.class,
+                err -> new FlinkException("Thread was interrupted", err));
     }
 }
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifierTest.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/throwable/FatalExceptionClassifierTest.java
similarity index 75%
rename from flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifierTest.java
rename to flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/throwable/FatalExceptionClassifierTest.java
index a17bf637c0d..60a856882c8 100644
--- a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/util/RetryableExceptionClassifierTest.java
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/throwable/FatalExceptionClassifierTest.java
@@ -16,7 +16,7 @@
  * limitations under the License.
  */
 
-package org.apache.flink.connector.base.sink.util;
+package org.apache.flink.connector.base.sink.throwable;
 
 import org.apache.flink.util.ExceptionUtils;
 
@@ -27,21 +27,21 @@ import java.util.concurrent.atomic.AtomicReference;
 import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
 import static org.assertj.core.api.AssertionsForClassTypes.assertThat;
 
-/** Tests the RetryableExceptionClassifier of the Async Sink Writer. */
-public class RetryableExceptionClassifierTest {
+/** Tests the FatalExceptionClassifier of the Async Sink Writer. */
+public class FatalExceptionClassifierTest {
 
     private static Integer nullReference;
 
-    private static final RetryableExceptionClassifier ARITHMETIC_EXCEPTION_STRATEGY =
-            new RetryableExceptionClassifier(
+    private static final FatalExceptionClassifier ARITHMETIC_EXCEPTION_STRATEGY =
+            new FatalExceptionClassifier(
                     err -> ExceptionUtils.findThrowable(err, ArithmeticException.class).isPresent(),
                     err ->
                             new RuntimeException(
                                     "Buffer manipulation calculations resulted in a calculation exception",
                                     err));
 
-    private static final RetryableExceptionClassifier NULL_POINTER_EXCEPTION_STRATEGY =
-            new RetryableExceptionClassifier(
+    private static final FatalExceptionClassifier NULL_POINTER_EXCEPTION_STRATEGY =
+            new FatalExceptionClassifier(
                     err ->
                             ExceptionUtils.findThrowable(err, NullPointerException.class)
                                     .isPresent(),
@@ -54,7 +54,7 @@ public class RetryableExceptionClassifierTest {
     public void exceptionsAreWrappedInTheContainingExceptionWhenAMatchIsFound() {
         AtomicReference<Exception> caughtExceptionReference = new AtomicReference<>();
 
-        ARITHMETIC_EXCEPTION_STRATEGY.shouldSuppress(
+        ARITHMETIC_EXCEPTION_STRATEGY.isFatal(
                 new ArithmeticException("Base arithmetic exception"),
                 caughtExceptionReference::set);
 
@@ -68,19 +68,19 @@ public class RetryableExceptionClassifierTest {
         try {
             System.out.print(nullReference.toString());
         } catch (Exception e) {
-            ARITHMETIC_EXCEPTION_STRATEGY.shouldSuppress(e, caughtException::set);
+            ARITHMETIC_EXCEPTION_STRATEGY.isFatal(e, caughtException::set);
         }
         assertThat(caughtException.get()).isNull();
     }
 
     @Test
-    public void chainedRetryStrategiesAcceptExceptionsOnTheFirstItemOfChain() {
-        RetryableExceptionClassifier retryableExceptionClassifier =
-                RetryableExceptionClassifier.createChain(
+    public void chainedFatalExceptionClassifierAcceptExceptionsOnTheFirstItemOfChain() {
+        FatalExceptionClassifier fatalExceptionClassifier =
+                FatalExceptionClassifier.createChain(
                         ARITHMETIC_EXCEPTION_STRATEGY, NULL_POINTER_EXCEPTION_STRATEGY);
         AtomicReference<Exception> caughtExceptionReference = new AtomicReference<>();
 
-        retryableExceptionClassifier.shouldSuppress(
+        fatalExceptionClassifier.isFatal(
                 new ArithmeticException("Base arithmetic exception"),
                 caughtExceptionReference::set);
 
@@ -89,13 +89,13 @@ public class RetryableExceptionClassifierTest {
     }
 
     @Test
-    public void chainedRetryStrategiesAcceptExceptionsOnTheLastItemOfChain() {
-        RetryableExceptionClassifier retryableExceptionClassifier =
-                RetryableExceptionClassifier.createChain(
+    public void chainedFatalExceptionClassifierAcceptExceptionsOnTheLastItemOfChain() {
+        FatalExceptionClassifier fatalExceptionClassifier =
+                FatalExceptionClassifier.createChain(
                         ARITHMETIC_EXCEPTION_STRATEGY, NULL_POINTER_EXCEPTION_STRATEGY);
         AtomicReference<Exception> caughtException = new AtomicReference<>();
 
-        retryableExceptionClassifier.shouldSuppress(
+        fatalExceptionClassifier.isFatal(
                 new NullPointerException("Base NullPointerException"), caughtException::set);
 
         assertThat(caughtException.get())
@@ -107,11 +107,11 @@ public class RetryableExceptionClassifierTest {
     }
 
     @Test
-    public void circularChainStrategyThrowsException() {
+    public void circularChainedFatalExceptionClassifierThrowsException() {
         assertThatExceptionOfType(IllegalArgumentException.class)
                 .isThrownBy(
                         () ->
-                                RetryableExceptionClassifier.createChain(
+                                FatalExceptionClassifier.createChain(
                                         ARITHMETIC_EXCEPTION_STRATEGY,
                                         NULL_POINTER_EXCEPTION_STRATEGY,
                                         ARITHMETIC_EXCEPTION_STRATEGY))
@@ -119,6 +119,13 @@ public class RetryableExceptionClassifierTest {
                         "Wrong classifier chain; Circular chain of classifiers detected");
     }
 
+    @Test
+    public void emptyChainedFatalExceptionClassifierThrowsException() {
+        assertThatExceptionOfType(IllegalArgumentException.class)
+                .isThrownBy(FatalExceptionClassifier::createChain)
+                .withMessageContaining("Cannot create empty classifier chain.");
+    }
+
     private void assertThatCaughtExceptionIsWrappedArithmeticDivByZeroException(
             Exception caughtException) {
         assertThat(caughtException)
diff --git a/flink-end-to-end-tests/flink-end-to-end-tests-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/table/test/KinesisFirehoseTableITTest.java b/flink-end-to-end-tests/flink-end-to-end-tests-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/table/test/KinesisFirehoseTableITTest.java
index 576c1509228..ff256b15f3b 100644
--- a/flink-end-to-end-tests/flink-end-to-end-tests-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/table/test/KinesisFirehoseTableITTest.java
+++ b/flink-end-to-end-tests/flink-end-to-end-tests-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/table/test/KinesisFirehoseTableITTest.java
@@ -66,7 +66,7 @@ import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.crea
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.listBucketObjects;
 import static org.apache.flink.connector.aws.testutils.AWSServicesTestUtils.readObjectsFromS3Bucket;
 import static org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils.createDeliveryStream;
-import static org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils.getFirehoseClient;
+import static org.apache.flink.connector.firehose.sink.testutils.KinesisFirehoseTestUtils.createFirehoseClient;
 
 /** End to End test for Kinesis Firehose Table sink API. */
 public class KinesisFirehoseTableITTest extends TestLogger {
@@ -114,7 +114,7 @@ public class KinesisFirehoseTableITTest extends TestLogger {
         httpClient = createHttpClient(mockFirehoseContainer.getEndpoint());
 
         s3AsyncClient = createS3Client(mockFirehoseContainer.getEndpoint(), httpClient);
-        firehoseAsyncClient = getFirehoseClient(mockFirehoseContainer.getEndpoint(), httpClient);
+        firehoseAsyncClient = createFirehoseClient(mockFirehoseContainer.getEndpoint(), httpClient);
         iamAsyncClient = createIamClient(mockFirehoseContainer.getEndpoint(), httpClient);
 
         LOG.info("1 - Creating the bucket for Firehose to deliver into...");
