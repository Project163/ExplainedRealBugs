diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala
index be984736df4..96d05d1c081 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/stream/StreamExecDeduplicate.scala
@@ -101,6 +101,7 @@ class StreamExecDeduplicate(
     val tableConfig = planner.getTableConfig
     val isMiniBatchEnabled = tableConfig.getConfiguration.getBoolean(
       ExecutionConfigOptions.TABLE_EXEC_MINIBATCH_ENABLED)
+    val minRetentionTime = tableConfig.getMinIdleStateRetentionTime
     val operator = if (isMiniBatchEnabled) {
       val exeConfig = planner.getExecEnv.getConfig
       val rowSerializer = rowTypeInfo.createSerializer(exeConfig)
@@ -108,25 +109,25 @@ class StreamExecDeduplicate(
         new MiniBatchDeduplicateKeepLastRowFunction(
           rowTypeInfo,
           generateUpdateBefore,
-          rowSerializer)
+          rowSerializer,
+          minRetentionTime)
       } else {
-        new MiniBatchDeduplicateKeepFirstRowFunction(rowSerializer)
+        new MiniBatchDeduplicateKeepFirstRowFunction(
+          rowSerializer,
+          minRetentionTime)
       }
       val trigger = AggregateUtil.createMiniBatchTrigger(tableConfig)
       new KeyedMapBundleOperator(
         processFunction,
         trigger)
     } else {
-      val minRetentionTime = tableConfig.getMinIdleStateRetentionTime
-      val maxRetentionTime = tableConfig.getMaxIdleStateRetentionTime
       val processFunction = if (keepLastRow) {
         new DeduplicateKeepLastRowFunction(
           minRetentionTime,
-          maxRetentionTime,
           rowTypeInfo,
           generateUpdateBefore)
       } else {
-        new DeduplicateKeepFirstRowFunction(minRetentionTime, maxRetentionTime)
+        new DeduplicateKeepFirstRowFunction(minRetentionTime)
       }
       new KeyedProcessOperator[BaseRow, BaseRow, BaseRow](processFunction)
     }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunction.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunction.java
index 820defa0082..b969e189569 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunction.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunction.java
@@ -18,51 +18,47 @@
 
 package org.apache.flink.table.runtime.operators.deduplicate;
 
+import org.apache.flink.api.common.state.StateTtlConfig;
 import org.apache.flink.api.common.state.ValueState;
 import org.apache.flink.api.common.state.ValueStateDescriptor;
 import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
 import org.apache.flink.table.dataformat.BaseRow;
-import org.apache.flink.table.runtime.functions.KeyedProcessFunctionWithCleanupState;
 import org.apache.flink.util.Collector;
 
 import static org.apache.flink.table.runtime.operators.deduplicate.DeduplicateFunctionHelper.processFirstRow;
+import static org.apache.flink.table.runtime.util.StateTtlConfigUtil.createTtlConfig;
 
 /**
  * This function is used to deduplicate on keys and keeps only first row.
  */
 public class DeduplicateKeepFirstRowFunction
-		extends KeyedProcessFunctionWithCleanupState<BaseRow, BaseRow, BaseRow> {
+		extends KeyedProcessFunction<BaseRow, BaseRow, BaseRow> {
 
 	private static final long serialVersionUID = 5865777137707602549L;
 
+	private final long minRetentionTime;
 	// state stores a boolean flag to indicate whether key appears before.
 	private ValueState<Boolean> state;
 
-	public DeduplicateKeepFirstRowFunction(long minRetentionTime, long maxRetentionTime) {
-		super(minRetentionTime, maxRetentionTime);
+	public DeduplicateKeepFirstRowFunction(long minRetentionTime) {
+		this.minRetentionTime = minRetentionTime;
 	}
 
 	@Override
 	public void open(Configuration configure) throws Exception {
 		super.open(configure);
-		initCleanupTimeState("DeduplicateFunctionKeepFirstRow");
 		ValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>("existsState", Types.BOOLEAN);
+		StateTtlConfig ttlConfig = createTtlConfig(minRetentionTime);
+		if (ttlConfig.isEnabled()) {
+			stateDesc.enableTimeToLive(ttlConfig);
+		}
 		state = getRuntimeContext().getState(stateDesc);
 	}
 
 	@Override
 	public void processElement(BaseRow input, Context ctx, Collector<BaseRow> out) throws Exception {
-		long currentTime = ctx.timerService().currentProcessingTime();
-		// register state-cleanup timer
-		registerProcessingCleanupTimer(ctx, currentTime);
 		processFirstRow(input, state, out);
 	}
-
-	@Override
-	public void onTimer(long timestamp, OnTimerContext ctx, Collector<BaseRow> out) throws Exception {
-		if (stateCleaningEnabled) {
-			cleanupState(state);
-		}
-	}
 }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunction.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunction.java
index 373ea4cebe6..17ced13825e 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunction.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunction.java
@@ -18,35 +18,37 @@
 
 package org.apache.flink.table.runtime.operators.deduplicate;
 
+import org.apache.flink.api.common.state.StateTtlConfig;
 import org.apache.flink.api.common.state.ValueState;
 import org.apache.flink.api.common.state.ValueStateDescriptor;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
 import org.apache.flink.table.dataformat.BaseRow;
-import org.apache.flink.table.runtime.functions.KeyedProcessFunctionWithCleanupState;
 import org.apache.flink.table.runtime.typeutils.BaseRowTypeInfo;
 import org.apache.flink.util.Collector;
 
 import static org.apache.flink.table.runtime.operators.deduplicate.DeduplicateFunctionHelper.processLastRow;
+import static org.apache.flink.table.runtime.util.StateTtlConfigUtil.createTtlConfig;
 
 /**
  * This function is used to deduplicate on keys and keeps only last row.
  */
 public class DeduplicateKeepLastRowFunction
-		extends KeyedProcessFunctionWithCleanupState<BaseRow, BaseRow, BaseRow> {
+		extends KeyedProcessFunction<BaseRow, BaseRow, BaseRow> {
 
 	private static final long serialVersionUID = -291348892087180350L;
 	private final BaseRowTypeInfo rowTypeInfo;
 	private final boolean generateUpdateBefore;
 
+	private final long minRetentionTime;
 	// state stores complete row.
 	private ValueState<BaseRow> state;
 
 	public DeduplicateKeepLastRowFunction(
 			long minRetentionTime,
-			long maxRetentionTime,
 			BaseRowTypeInfo rowTypeInfo,
 			boolean generateUpdateBefore) {
-		super(minRetentionTime, maxRetentionTime);
+		this.minRetentionTime = minRetentionTime;
 		this.rowTypeInfo = rowTypeInfo;
 		this.generateUpdateBefore = generateUpdateBefore;
 	}
@@ -56,26 +58,18 @@ public class DeduplicateKeepLastRowFunction
 		super.open(configure);
 		if (generateUpdateBefore) {
 			// state stores complete row if need generate retraction, otherwise do not need a state
-			initCleanupTimeState("DeduplicateFunctionKeepLastRow");
 			ValueStateDescriptor<BaseRow> stateDesc = new ValueStateDescriptor<>("preRowState", rowTypeInfo);
+			StateTtlConfig ttlConfig = createTtlConfig(minRetentionTime);
+			if (ttlConfig.isEnabled()) {
+				stateDesc.enableTimeToLive(ttlConfig);
+			}
 			state = getRuntimeContext().getState(stateDesc);
 		}
 	}
 
 	@Override
 	public void processElement(BaseRow input, Context ctx, Collector<BaseRow> out) throws Exception {
-		if (generateUpdateBefore) {
-			long currentTime = ctx.timerService().currentProcessingTime();
-			// register state-cleanup timer
-			registerProcessingCleanupTimer(ctx, currentTime);
-		}
 		processLastRow(input, generateUpdateBefore, state, out);
 	}
 
-	@Override
-	public void onTimer(long timestamp, OnTimerContext ctx, Collector<BaseRow> out) throws Exception {
-		if (stateCleaningEnabled) {
-			cleanupState(state);
-		}
-	}
 }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java
index 443142c7f92..27b2cd30449 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunction.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.table.runtime.operators.deduplicate;
 
+import org.apache.flink.api.common.state.StateTtlConfig;
 import org.apache.flink.api.common.state.ValueState;
 import org.apache.flink.api.common.state.ValueStateDescriptor;
 import org.apache.flink.api.common.typeinfo.Types;
@@ -32,6 +33,7 @@ import javax.annotation.Nullable;
 import java.util.Map;
 
 import static org.apache.flink.table.runtime.operators.deduplicate.DeduplicateFunctionHelper.processFirstRow;
+import static org.apache.flink.table.runtime.util.StateTtlConfigUtil.createTtlConfig;
 
 /**
  * This function is used to get the first row for every key partition in miniBatch mode.
@@ -42,11 +44,14 @@ public class MiniBatchDeduplicateKeepFirstRowFunction
 	private static final long serialVersionUID = -7994602893547654994L;
 
 	private final TypeSerializer<BaseRow> typeSerializer;
-
+	private final long minRetentionTime;
 	// state stores a boolean flag to indicate whether key appears before.
 	private ValueState<Boolean> state;
 
-	public MiniBatchDeduplicateKeepFirstRowFunction(TypeSerializer<BaseRow> typeSerializer) {
+	public MiniBatchDeduplicateKeepFirstRowFunction(
+			TypeSerializer<BaseRow> typeSerializer,
+			long minRetentionTime) {
+		this.minRetentionTime = minRetentionTime;
 		this.typeSerializer = typeSerializer;
 	}
 
@@ -54,6 +59,10 @@ public class MiniBatchDeduplicateKeepFirstRowFunction
 	public void open(ExecutionContext ctx) throws Exception {
 		super.open(ctx);
 		ValueStateDescriptor<Boolean> stateDesc = new ValueStateDescriptor<>("existsState", Types.BOOLEAN);
+		StateTtlConfig ttlConfig = createTtlConfig(minRetentionTime);
+		if (ttlConfig.isEnabled()) {
+			stateDesc.enableTimeToLive(ttlConfig);
+		}
 		state = ctx.getRuntimeContext().getState(stateDesc);
 	}
 
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunction.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunction.java
index b8dfbfcb1c6..f81a2031d9e 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunction.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunction.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.table.runtime.operators.deduplicate;
 
+import org.apache.flink.api.common.state.StateTtlConfig;
 import org.apache.flink.api.common.state.ValueState;
 import org.apache.flink.api.common.state.ValueStateDescriptor;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
@@ -32,6 +33,7 @@ import javax.annotation.Nullable;
 import java.util.Map;
 
 import static org.apache.flink.table.runtime.operators.deduplicate.DeduplicateFunctionHelper.processLastRow;
+import static org.apache.flink.table.runtime.util.StateTtlConfigUtil.createTtlConfig;
 
 /**
  * This function is used to get the last row for every key partition in miniBatch mode.
@@ -44,14 +46,16 @@ public class MiniBatchDeduplicateKeepLastRowFunction
 	private final BaseRowTypeInfo rowTypeInfo;
 	private final boolean generateUpdateBefore;
 	private final TypeSerializer<BaseRow> typeSerializer;
-
+	private final long minRetentionTime;
 	// state stores complete row.
 	private ValueState<BaseRow> state;
 
 	public MiniBatchDeduplicateKeepLastRowFunction(
 			BaseRowTypeInfo rowTypeInfo,
 			boolean generateUpdateBefore,
-			TypeSerializer<BaseRow> typeSerializer) {
+			TypeSerializer<BaseRow> typeSerializer,
+			long minRetentionTime) {
+		this.minRetentionTime = minRetentionTime;
 		this.rowTypeInfo = rowTypeInfo;
 		this.generateUpdateBefore = generateUpdateBefore;
 		this.typeSerializer = typeSerializer;
@@ -61,6 +65,10 @@ public class MiniBatchDeduplicateKeepLastRowFunction
 	public void open(ExecutionContext ctx) throws Exception {
 		super.open(ctx);
 		ValueStateDescriptor<BaseRow> stateDesc = new ValueStateDescriptor<>("preRowState", rowTypeInfo);
+		StateTtlConfig ttlConfig = createTtlConfig(minRetentionTime);
+		if (ttlConfig.isEnabled()) {
+			stateDesc.enableTimeToLive(ttlConfig);
+		}
 		state = ctx.getRuntimeContext().getState(stateDesc);
 	}
 
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/AbstractStreamingJoinOperator.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/AbstractStreamingJoinOperator.java
index ead4b5bf18b..191d12856d6 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/AbstractStreamingJoinOperator.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/AbstractStreamingJoinOperator.java
@@ -76,7 +76,6 @@ public abstract class AbstractStreamingJoinOperator extends AbstractStreamOperat
 	private final boolean filterAllNulls;
 
 	protected final long minRetentionTime;
-	protected final boolean stateCleaningEnabled;
 
 	protected transient JoinConditionWithNullFilters joinCondition;
 	protected transient TimestampedCollector<BaseRow> collector;
@@ -95,7 +94,6 @@ public abstract class AbstractStreamingJoinOperator extends AbstractStreamOperat
 		this.leftInputSideSpec = leftInputSideSpec;
 		this.rightInputSideSpec = rightInputSideSpec;
 		this.minRetentionTime = minRetentionTime;
-		this.stateCleaningEnabled = minRetentionTime > 1;
 		this.nullFilterKeys = NullAwareJoinHelper.getNullFilterKeys(filterNullKeys);
 		this.nullSafe = nullFilterKeys.length == 0;
 		this.filterAllNulls = nullFilterKeys.length == filterNullKeys.length;
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingJoinOperator.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingJoinOperator.java
index 94630291e3d..0a1e16e5f67 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingJoinOperator.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingJoinOperator.java
@@ -82,16 +82,14 @@ public class StreamingJoinOperator extends AbstractStreamingJoinOperator {
 				"left-records",
 				leftInputSideSpec,
 				leftType,
-				minRetentionTime,
-				stateCleaningEnabled);
+				minRetentionTime);
 		} else {
 			this.leftRecordStateView = JoinRecordStateViews.create(
 				getRuntimeContext(),
 				"left-records",
 				leftInputSideSpec,
 				leftType,
-				minRetentionTime,
-				stateCleaningEnabled);
+				minRetentionTime);
 		}
 
 		if (rightIsOuter) {
@@ -100,16 +98,14 @@ public class StreamingJoinOperator extends AbstractStreamingJoinOperator {
 				"right-records",
 				rightInputSideSpec,
 				rightType,
-				minRetentionTime,
-				stateCleaningEnabled);
+				minRetentionTime);
 		} else {
 			this.rightRecordStateView = JoinRecordStateViews.create(
 				getRuntimeContext(),
 				"right-records",
 				rightInputSideSpec,
 				rightType,
-				minRetentionTime,
-				stateCleaningEnabled);
+				minRetentionTime);
 		}
 	}
 
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingSemiAntiJoinOperator.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingSemiAntiJoinOperator.java
index fc4587643e8..52edaed6f59 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingSemiAntiJoinOperator.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/StreamingSemiAntiJoinOperator.java
@@ -66,16 +66,14 @@ public class StreamingSemiAntiJoinOperator extends AbstractStreamingJoinOperator
 			LEFT_RECORDS_STATE_NAME,
 			leftInputSideSpec,
 			leftType,
-			minRetentionTime,
-			stateCleaningEnabled);
+			minRetentionTime);
 
 		this.rightRecordStateView = JoinRecordStateViews.create(
 			getRuntimeContext(),
 			RIGHT_RECORDS_STATE_NAME,
 			rightInputSideSpec,
 			rightType,
-			minRetentionTime,
-			stateCleaningEnabled);
+			minRetentionTime);
 	}
 
 	/**
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/JoinRecordStateViews.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/JoinRecordStateViews.java
index c2201f2fd4e..cfacbad4ffe 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/JoinRecordStateViews.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/JoinRecordStateViews.java
@@ -24,7 +24,6 @@ import org.apache.flink.api.common.state.MapStateDescriptor;
 import org.apache.flink.api.common.state.StateTtlConfig;
 import org.apache.flink.api.common.state.ValueState;
 import org.apache.flink.api.common.state.ValueStateDescriptor;
-import org.apache.flink.api.common.time.Time;
 import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.api.java.functions.KeySelector;
 import org.apache.flink.table.dataformat.BaseRow;
@@ -36,7 +35,7 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static org.apache.flink.util.Preconditions.checkArgument;
+import static org.apache.flink.table.runtime.util.StateTtlConfigUtil.createTtlConfig;
 import static org.apache.flink.util.Preconditions.checkNotNull;
 
 /**
@@ -52,9 +51,8 @@ public final class JoinRecordStateViews {
 			String stateName,
 			JoinInputSideSpec inputSideSpec,
 			BaseRowTypeInfo recordType,
-			long retentionTime,
-			boolean stateCleaningEnabled) {
-		StateTtlConfig ttlConfig = createTtlConfig(retentionTime, stateCleaningEnabled);
+			long retentionTime) {
+		StateTtlConfig ttlConfig = createTtlConfig(retentionTime);
 		if (inputSideSpec.hasUniqueKey()) {
 			if (inputSideSpec.joinKeyContainsUniqueKey()) {
 				return new JoinKeyContainsUniqueKey(ctx, stateName, recordType, ttlConfig);
@@ -72,18 +70,6 @@ public final class JoinRecordStateViews {
 		}
 	}
 
-	static StateTtlConfig createTtlConfig(long retentionTime, boolean stateCleaningEnabled) {
-		if (stateCleaningEnabled) {
-			checkArgument(retentionTime > 0);
-			return StateTtlConfig
-				.newBuilder(Time.milliseconds(retentionTime))
-				.setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
-				.setStateVisibility(StateTtlConfig.StateVisibility.ReturnExpiredIfNotCleanedUp)
-				.build();
-		} else {
-			return StateTtlConfig.DISABLED;
-		}
-	}
 
 	// ------------------------------------------------------------------------------------
 
@@ -100,7 +86,7 @@ public final class JoinRecordStateViews {
 			ValueStateDescriptor<BaseRow> recordStateDesc = new ValueStateDescriptor<>(
 				stateName,
 				recordType);
-			if (!ttlConfig.equals(StateTtlConfig.DISABLED)) {
+			if (ttlConfig.isEnabled()) {
 				recordStateDesc.enableTimeToLive(ttlConfig);
 			}
 			this.recordState = ctx.getState(recordStateDesc);
@@ -148,7 +134,7 @@ public final class JoinRecordStateViews {
 				stateName,
 				uniqueKeyType,
 				recordType);
-			if (!ttlConfig.equals(StateTtlConfig.DISABLED)) {
+			if (ttlConfig.isEnabled()) {
 				recordStateDesc.enableTimeToLive(ttlConfig);
 			}
 			this.recordState = ctx.getMapState(recordStateDesc);
@@ -186,7 +172,7 @@ public final class JoinRecordStateViews {
 				stateName,
 				recordType,
 				Types.INT);
-			if (!ttlConfig.equals(StateTtlConfig.DISABLED)) {
+			if (ttlConfig.isEnabled()) {
 				recordStateDesc.enableTimeToLive(ttlConfig);
 			}
 			this.recordState = ctx.getMapState(recordStateDesc);
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/OuterJoinRecordStateViews.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/OuterJoinRecordStateViews.java
index 2a146aecb81..34e2f05c8de 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/OuterJoinRecordStateViews.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/join/stream/state/OuterJoinRecordStateViews.java
@@ -37,7 +37,7 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static org.apache.flink.table.runtime.operators.join.stream.state.JoinRecordStateViews.createTtlConfig;
+import static org.apache.flink.table.runtime.util.StateTtlConfigUtil.createTtlConfig;
 import static org.apache.flink.util.Preconditions.checkNotNull;
 
 /**
@@ -53,9 +53,8 @@ public final class OuterJoinRecordStateViews {
 			String stateName,
 			JoinInputSideSpec inputSideSpec,
 			BaseRowTypeInfo recordType,
-			long retentionTime,
-			boolean stateCleaningEnabled) {
-		StateTtlConfig ttlConfig = createTtlConfig(retentionTime, stateCleaningEnabled);
+			long retentionTime) {
+		StateTtlConfig ttlConfig = createTtlConfig(retentionTime);
 		if (inputSideSpec.hasUniqueKey()) {
 			if (inputSideSpec.joinKeyContainsUniqueKey()) {
 				return new OuterJoinRecordStateViews.JoinKeyContainsUniqueKey(ctx, stateName, recordType, ttlConfig);
@@ -86,7 +85,7 @@ public final class OuterJoinRecordStateViews {
 			ValueStateDescriptor<Tuple2<BaseRow, Integer>> recordStateDesc = new ValueStateDescriptor<>(
 				stateName,
 				valueTypeInfo);
-			if (!ttlConfig.equals(StateTtlConfig.DISABLED)) {
+			if (ttlConfig.isEnabled()) {
 				recordStateDesc.enableTimeToLive(ttlConfig);
 			}
 			this.recordState = ctx.getState(recordStateDesc);
@@ -157,7 +156,7 @@ public final class OuterJoinRecordStateViews {
 				stateName,
 				uniqueKeyType,
 				valueTypeInfo);
-			if (!ttlConfig.equals(StateTtlConfig.DISABLED)) {
+			if (ttlConfig.isEnabled()) {
 				recordStateDesc.enableTimeToLive(ttlConfig);
 			}
 			this.recordState = ctx.getMapState(recordStateDesc);
@@ -213,7 +212,7 @@ public final class OuterJoinRecordStateViews {
 				stateName,
 				recordType,
 				tupleTypeInfo);
-			if (!ttlConfig.equals(StateTtlConfig.DISABLED)) {
+			if (ttlConfig.isEnabled()) {
 				recordStateDesc.enableTimeToLive(ttlConfig);
 			}
 			this.recordState = ctx.getMapState(recordStateDesc);
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java
new file mode 100644
index 00000000000..ea48a99a59d
--- /dev/null
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/util/StateTtlConfigUtil.java
@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.runtime.util;
+
+import org.apache.flink.api.common.state.StateTtlConfig;
+import org.apache.flink.api.common.time.Time;
+
+/**
+ * Utility to create a {@link StateTtlConfig} object.
+ * */
+public class StateTtlConfigUtil {
+
+	/**
+	 * Creates a {@link StateTtlConfig} depends on retentionTime parameter.
+	 * @param retentionTime State ttl time which unit is MILLISECONDS.
+	 */
+	public static StateTtlConfig createTtlConfig(long retentionTime) {
+		if (retentionTime > 0) {
+			return StateTtlConfig
+				.newBuilder(Time.milliseconds(retentionTime))
+				.setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
+				.setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
+				.build();
+		} else {
+			return StateTtlConfig.DISABLED;
+		}
+	}
+}
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateFunctionTestBase.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateFunctionTestBase.java
index 1964ba4db8d..f7d4afe93b8 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateFunctionTestBase.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateFunctionTestBase.java
@@ -33,8 +33,6 @@ import org.apache.flink.table.types.logical.VarCharType;
 abstract class DeduplicateFunctionTestBase {
 
 	Time minTime = Time.milliseconds(10);
-	Time maxTime = Time.milliseconds(20);
-
 	BaseRowTypeInfo inputRowType = new BaseRowTypeInfo(new VarCharType(VarCharType.MAX_LENGTH), new BigIntType(),
 			new IntType());
 
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunctionTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunctionTest.java
index 0c0f1c7eb84..91f9cc2b234 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunctionTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepFirstRowFunctionTest.java
@@ -44,8 +44,7 @@ public class DeduplicateKeepFirstRowFunctionTest extends DeduplicateFunctionTest
 
 	@Test
 	public void test() throws Exception {
-		DeduplicateKeepFirstRowFunction func = new DeduplicateKeepFirstRowFunction(minTime.toMilliseconds(),
-				maxTime.toMilliseconds());
+		DeduplicateKeepFirstRowFunction func = new DeduplicateKeepFirstRowFunction(minTime.toMilliseconds());
 		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
 		testHarness.open();
 		testHarness.processElement(record("book", 1L, 12));
@@ -60,4 +59,28 @@ public class DeduplicateKeepFirstRowFunctionTest extends DeduplicateFunctionTest
 		assertor.assertOutputEqualsSorted("output wrong.", expectedOutput, testHarness.getOutput());
 	}
 
+	@Test
+	public void testWithStateTtl() throws Exception {
+		DeduplicateKeepFirstRowFunction func = new DeduplicateKeepFirstRowFunction(minTime.toMilliseconds());
+		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
+		testHarness.open();
+		testHarness.processElement(record("book", 1L, 12));
+		testHarness.processElement(record("book", 2L, 11));
+		testHarness.processElement(record("book", 1L, 13));
+
+		testHarness.setStateTtlProcessingTime(30);
+		testHarness.processElement(record("book", 1L, 17));
+		testHarness.processElement(record("book", 2L, 18));
+		testHarness.processElement(record("book", 1L, 19));
+
+		// Keep FirstRow in deduplicate will not send retraction
+		List<Object> expectedOutput = new ArrayList<>();
+		expectedOutput.add(record("book", 1L, 12));
+		expectedOutput.add(record("book", 2L, 11));
+		//(1L,12),(2L,11) has retired, so output (1L,17) and (2L,18)
+		expectedOutput.add(record("book", 1L, 17));
+		expectedOutput.add(record("book", 2L, 18));
+		assertor.assertOutputEqualsSorted("output wrong.", expectedOutput, testHarness.getOutput());
+		testHarness.close();
+	}
 }
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunctionTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunctionTest.java
index 5d8e5eb7da6..369f40345ae 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunctionTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/DeduplicateKeepLastRowFunctionTest.java
@@ -39,7 +39,6 @@ public class DeduplicateKeepLastRowFunctionTest extends DeduplicateFunctionTestB
 	private DeduplicateKeepLastRowFunction createFunction(boolean generateUpdateBefore) {
 		return new DeduplicateKeepLastRowFunction(
 			minTime.toMilliseconds(),
-			maxTime.toMilliseconds(),
 			inputRowType,
 			generateUpdateBefore);
 	}
@@ -86,4 +85,33 @@ public class DeduplicateKeepLastRowFunctionTest extends DeduplicateFunctionTestB
 		expectedOutput.add(record("book", 2L, 11));
 		assertor.assertOutputEqualsSorted("output wrong.", expectedOutput, testHarness.getOutput());
 	}
+
+	@Test
+	public void testWithGenerateUpdateBeforeAndStateTtl() throws Exception {
+		DeduplicateKeepLastRowFunction func = createFunction(true);
+		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
+		testHarness.open();
+		testHarness.processElement(record("book", 1L, 12));
+		testHarness.processElement(record("book", 2L, 11));
+		testHarness.processElement(record("book", 1L, 13));
+
+		testHarness.setStateTtlProcessingTime(30);
+		testHarness.processElement(record("book", 1L, 17));
+		testHarness.processElement(record("book", 2L, 18));
+		testHarness.processElement(record("book", 1L, 19));
+
+		// Keep LastRow in deduplicate may send retraction
+		List<Object> expectedOutput = new ArrayList<>();
+		expectedOutput.add(record("book", 1L, 12));
+		expectedOutput.add(retractRecord("book", 1L, 12));
+		expectedOutput.add(record("book", 1L, 13));
+		expectedOutput.add(record("book", 2L, 11));
+		// because (2L,11), (1L,13) retired, so there is no retract message send to downstream
+		expectedOutput.add(record("book", 1L, 17));
+		expectedOutput.add(retractRecord("book", 1L, 17));
+		expectedOutput.add(record("book", 1L, 19));
+		expectedOutput.add(record("book", 2L, 18));
+		assertor.assertOutputEqualsSorted("output wrong.", expectedOutput, testHarness.getOutput());
+		testHarness.close();
+	}
 }
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java
index 6c9b9c7c44e..5f5cb9a4d1d 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepFirstRowFunctionTest.java
@@ -52,7 +52,7 @@ public class MiniBatchDeduplicateKeepFirstRowFunctionTest extends DeduplicateFun
 
 	@Test
 	public void testKeepFirstRowWithGenerateUpdateBefore() throws Exception {
-		MiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer);
+		MiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());
 		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
 		testHarness.open();
 		testHarness.processElement(record("book", 1L, 12));
@@ -71,4 +71,31 @@ public class MiniBatchDeduplicateKeepFirstRowFunctionTest extends DeduplicateFun
 		testHarness.close();
 	}
 
+	@Test
+	public void testKeepFirstRowWithStateTtl() throws Exception {
+		MiniBatchDeduplicateKeepFirstRowFunction func = new MiniBatchDeduplicateKeepFirstRowFunction(typeSerializer, minTime.toMilliseconds());
+		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
+		testHarness.setup();
+		testHarness.open();
+		testHarness.processElement(record("book", 1L, 12));
+		testHarness.processElement(record("book", 2L, 11));
+		// output is empty because bundle not trigger yet.
+		Assert.assertTrue(testHarness.getOutput().isEmpty());
+		testHarness.processElement(record("book", 1L, 13));
+
+		testHarness.setStateTtlProcessingTime(30);
+		testHarness.processElement(record("book", 1L, 17));
+		testHarness.processElement(record("book", 2L, 18));
+		testHarness.processElement(record("book", 1L, 19));
+
+		// Keep FirstRow in deduplicate
+		List<Object> expectedOutput = new ArrayList<>();
+		expectedOutput.add(record("book", 1L, 12));
+		expectedOutput.add(record("book", 2L, 11));
+		//(1L,12),(2L,11) has retired, so output (1L,17) and (2L,18)
+		expectedOutput.add(record("book", 1L, 17));
+		expectedOutput.add(record("book", 2L, 18));
+		assertor.assertOutputEqualsSorted("output wrong.", expectedOutput, testHarness.getOutput());
+		testHarness.close();
+	}
 }
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java
index ff2868d2788..a05c88dae8d 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/MiniBatchDeduplicateKeepLastRowFunctionTest.java
@@ -43,8 +43,8 @@ public class MiniBatchDeduplicateKeepLastRowFunctionTest extends DeduplicateFunc
 
 	private TypeSerializer<BaseRow> typeSerializer = inputRowType.createSerializer(new ExecutionConfig());
 
-	private MiniBatchDeduplicateKeepLastRowFunction createFunction(boolean generateUpdateBefore) {
-		return new MiniBatchDeduplicateKeepLastRowFunction(inputRowType, generateUpdateBefore, typeSerializer);
+	private MiniBatchDeduplicateKeepLastRowFunction createFunction(boolean generateUpdateBefore, long minRetentionTime) {
+		return new MiniBatchDeduplicateKeepLastRowFunction(inputRowType, generateUpdateBefore, typeSerializer, minRetentionTime);
 	}
 
 	private OneInputStreamOperatorTestHarness<BaseRow, BaseRow> createTestHarness(
@@ -57,7 +57,7 @@ public class MiniBatchDeduplicateKeepLastRowFunctionTest extends DeduplicateFunc
 
 	@Test
 	public void testWithoutGenerateUpdateBefore() throws Exception {
-		MiniBatchDeduplicateKeepLastRowFunction func = createFunction(false);
+		MiniBatchDeduplicateKeepLastRowFunction func = createFunction(false, minTime.toMilliseconds());
 		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
 		testHarness.open();
 		testHarness.processElement(record("book", 1L, 10));
@@ -85,7 +85,7 @@ public class MiniBatchDeduplicateKeepLastRowFunctionTest extends DeduplicateFunc
 
 	@Test
 	public void testWithGenerateUpdateBefore() throws Exception {
-		MiniBatchDeduplicateKeepLastRowFunction func = createFunction(true);
+		MiniBatchDeduplicateKeepLastRowFunction func = createFunction(true, minTime.toMilliseconds());
 		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
 		testHarness.open();
 		testHarness.processElement(record("book", 1L, 10));
@@ -113,4 +113,31 @@ public class MiniBatchDeduplicateKeepLastRowFunctionTest extends DeduplicateFunc
 		testHarness.close();
 		assertor.assertOutputEqualsSorted("output wrong.", expectedOutput, testHarness.getOutput());
 	}
+
+	@Test
+	public void testWithGenerateUpdateBeforeAndStateTtl() throws Exception {
+		MiniBatchDeduplicateKeepLastRowFunction func = createFunction(true, minTime.toMilliseconds());
+		OneInputStreamOperatorTestHarness<BaseRow, BaseRow> testHarness = createTestHarness(func);
+		testHarness.setup();
+		testHarness.open();
+
+		testHarness.processElement(record("book", 1L, 10));
+		testHarness.processElement(record("book", 2L, 11));
+		// output is empty because bundle not trigger yet.
+		Assert.assertTrue(testHarness.getOutput().isEmpty());
+		testHarness.processElement(record("book", 1L, 13));
+
+		testHarness.setStateTtlProcessingTime(30);
+		testHarness.processElement(record("book", 1L, 17));
+		testHarness.processElement(record("book", 2L, 18));
+		testHarness.processElement(record("book", 1L, 19));
+
+		List<Object> expectedOutput = new ArrayList<>();
+		expectedOutput.add(record("book", 2L, 11));
+		expectedOutput.add(record("book", 1L, 13));
+		// because (2L,11), (1L,13) retired, so there is no retract message send to downstream
+		expectedOutput.add(record("book", 1L, 19));
+		expectedOutput.add(record("book", 2L, 18));
+		assertor.assertOutputEqualsSorted("output wrong.", expectedOutput, testHarness.getOutput());
+	}
 }
