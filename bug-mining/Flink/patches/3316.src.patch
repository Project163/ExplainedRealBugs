diff --git a/flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/KeyedStream.scala b/flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/KeyedStream.scala
index f85e1b538e2..4c50bd01cff 100644
--- a/flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/KeyedStream.scala
+++ b/flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala/KeyedStream.scala
@@ -25,8 +25,8 @@ import org.apache.flink.api.common.typeinfo.TypeInformation
 import org.apache.flink.api.common.typeutils.TypeSerializer
 import org.apache.flink.streaming.api.datastream.{QueryableStateStream, DataStream => JavaStream, KeyedStream => KeyedJavaStream, WindowedStream => WindowedJavaStream}
 import org.apache.flink.streaming.api.functions.aggregation.AggregationFunction.AggregationType
-import org.apache.flink.streaming.api.functions.aggregation.{ComparableAggregator, SumAggregator}
 import org.apache.flink.streaming.api.functions.co.ProcessJoinFunction
+import org.apache.flink.streaming.api.functions.aggregation.{AggregationFunction, ComparableAggregator, SumAggregator}
 import org.apache.flink.streaming.api.functions.query.{QueryableAppendingStateOperator, QueryableValueStateOperator}
 import org.apache.flink.streaming.api.functions.{KeyedProcessFunction, ProcessFunction}
 import org.apache.flink.streaming.api.operators.StreamGroupedReduce
@@ -488,13 +488,19 @@ class KeyedStream[T, K](javaStream: KeyedJavaStream[T, K]) extends DataStream[T]
     aggregate(AggregationType.MAXBY, field)
     
   private def aggregate(aggregationType: AggregationType, field: String): DataStream[T] = {
-    val position = fieldNames2Indices(javaStream.getType(), Array(field))(0)
-    aggregate(aggregationType, position)
+    val aggregationFunc = aggregationType match {
+      case AggregationType.SUM =>
+        new SumAggregator(field, javaStream.getType, javaStream.getExecutionConfig)
+      case _ =>
+        new ComparableAggregator(field, javaStream.getType, aggregationType, true,
+          javaStream.getExecutionConfig)
+    }
+
+    aggregate(aggregationFunc)
   }
 
   private def aggregate(aggregationType: AggregationType, position: Int): DataStream[T] = {
-
-    val reducer = aggregationType match {
+    val aggregationFunc = aggregationType match {
       case AggregationType.SUM =>
         new SumAggregator(position, javaStream.getType, javaStream.getExecutionConfig)
       case _ =>
@@ -502,10 +508,14 @@ class KeyedStream[T, K](javaStream: KeyedJavaStream[T, K]) extends DataStream[T]
           javaStream.getExecutionConfig)
     }
 
-    val invokable =  new StreamGroupedReduce[T](reducer,
-      getType().createSerializer(getExecutionConfig))
-     
-    new DataStream[T](javaStream.transform("aggregation", javaStream.getType(),invokable))
+    aggregate(aggregationFunc)
+  }
+
+  private def aggregate(aggregationFunc: AggregationFunction[T]): DataStream[T] = {
+    val invokable =
+      new StreamGroupedReduce[T](aggregationFunc, dataType.createSerializer(executionConfig))
+
+    new DataStream[T](javaStream.transform("aggregation", javaStream.getType(), invokable))
       .asInstanceOf[DataStream[T]]
   }
 
diff --git a/flink-streaming-scala/src/test/scala/org/apache/flink/streaming/api/scala/StreamingOperatorsITCase.scala b/flink-streaming-scala/src/test/scala/org/apache/flink/streaming/api/scala/StreamingOperatorsITCase.scala
index 334633ab613..0219e0714af 100644
--- a/flink-streaming-scala/src/test/scala/org/apache/flink/streaming/api/scala/StreamingOperatorsITCase.scala
+++ b/flink-streaming-scala/src/test/scala/org/apache/flink/streaming/api/scala/StreamingOperatorsITCase.scala
@@ -31,8 +31,10 @@ class StreamingOperatorsITCase extends AbstractTestBase {
 
   var resultPath1: String = _
   var resultPath2: String = _
+  var resultPath3: String = _
   var expected1: String = _
   var expected2: String = _
+  var expected3: String = _
 
   val _tempFolder = new TemporaryFolder()
 
@@ -44,14 +46,17 @@ class StreamingOperatorsITCase extends AbstractTestBase {
     val temp = tempFolder
     resultPath1 = temp.newFile.toURI.toString
     resultPath2 = temp.newFile.toURI.toString
+    resultPath3 = temp.newFile.toURI.toString
     expected1 = ""
     expected2 = ""
+    expected3 = ""
   }
 
   @After
   def after(): Unit = {
     TestBaseUtils.compareResultsByLinesInMemory(expected1, resultPath1)
     TestBaseUtils.compareResultsByLinesInMemory(expected2, resultPath2)
+    TestBaseUtils.compareResultsByLinesInMemory(expected3, resultPath3)
   }
 
   /** Tests the streaming fold operation. For this purpose a stream of Tuple[Int, Int] is created.
@@ -122,4 +127,38 @@ class StreamingOperatorsITCase extends AbstractTestBase {
 
     env.execute()
   }
+
+  @Test
+  def testKeyedAggregation(): Unit = {
+    val env = StreamExecutionEnvironment.getExecutionEnvironment
+
+    env.setParallelism(1)
+    env.getConfig.setMaxParallelism(1)
+
+    val inp = env.fromElements(
+      StreamingOperatorsITCase.Outer(1, StreamingOperatorsITCase.Inner(3, "alma"), true),
+      StreamingOperatorsITCase.Outer(1, StreamingOperatorsITCase.Inner(6, "alma"), true),
+      StreamingOperatorsITCase.Outer(2, StreamingOperatorsITCase.Inner(7, "alma"), true),
+      StreamingOperatorsITCase.Outer(2, StreamingOperatorsITCase.Inner(8, "alma"), true)
+    )
+
+    inp
+      .keyBy("a")
+      .sum("i.c")
+        .writeAsText(resultPath3, FileSystem.WriteMode.OVERWRITE)
+
+    expected3 =
+      "Outer(1,Inner(3,alma),true)\n" +
+      "Outer(1,Inner(9,alma),true)\n" +
+      "Outer(2,Inner(15,alma),true)\n" +
+      "Outer(2,Inner(7,alma),true)"
+
+    env.execute()
+  }
 }
+
+object StreamingOperatorsITCase {
+  case class Inner(c: Short, d: String)
+  case class Outer(a: Int, i: StreamingOperatorsITCase.Inner, b: Boolean)
+}
+
