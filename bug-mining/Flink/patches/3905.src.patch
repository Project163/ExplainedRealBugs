diff --git a/docs/_includes/generated/rocks_db_configuration.html b/docs/_includes/generated/rocks_db_configuration.html
index 3ce04c75d2d..1648ab3725e 100644
--- a/docs/_includes/generated/rocks_db_configuration.html
+++ b/docs/_includes/generated/rocks_db_configuration.html
@@ -58,8 +58,8 @@
         </tr>
         <tr>
             <td><h5>state.backend.rocksdb.timer-service.factory</h5></td>
-            <td style="word-wrap: break-word;">"ROCKSDB"</td>
-            <td>String</td>
+            <td style="word-wrap: break-word;">ROCKSDB</td>
+            <td><p>Enum</p>Possible values: [HEAP, ROCKSDB]</td>
             <td>This determines the factory for timer service state implementation. Options are either HEAP (heap-based, default) or ROCKSDB for an implementation based on RocksDB .</td>
         </tr>
     </tbody>
diff --git a/docs/_includes/generated/state_backend_rocksdb_section.html b/docs/_includes/generated/state_backend_rocksdb_section.html
index 974c5c12abe..a5c9e78e956 100644
--- a/docs/_includes/generated/state_backend_rocksdb_section.html
+++ b/docs/_includes/generated/state_backend_rocksdb_section.html
@@ -34,8 +34,8 @@
         </tr>
         <tr>
             <td><h5>state.backend.rocksdb.timer-service.factory</h5></td>
-            <td style="word-wrap: break-word;">"ROCKSDB"</td>
-            <td>String</td>
+            <td style="word-wrap: break-word;">ROCKSDB</td>
+            <td><p>Enum</p>Possible values: [HEAP, ROCKSDB]</td>
             <td>This determines the factory for timer service state implementation. Options are either HEAP (heap-based, default) or ROCKSDB for an implementation based on RocksDB .</td>
         </tr>
     </tbody>
diff --git a/flink-core/src/main/java/org/apache/flink/configuration/ReadableConfigToConfigurationAdapter.java b/flink-core/src/main/java/org/apache/flink/configuration/ReadableConfigToConfigurationAdapter.java
deleted file mode 100644
index c2e9292f680..00000000000
--- a/flink-core/src/main/java/org/apache/flink/configuration/ReadableConfigToConfigurationAdapter.java
+++ /dev/null
@@ -1,328 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.configuration;
-
-import org.apache.flink.annotation.Internal;
-import org.apache.flink.core.memory.DataInputView;
-import org.apache.flink.core.memory.DataOutputView;
-
-import java.io.IOException;
-import java.util.Map;
-import java.util.Optional;
-import java.util.Properties;
-import java.util.Set;
-
-import static org.apache.flink.util.Preconditions.checkNotNull;
-
-/**
- * A simple adapter between {@link ReadableConfig} and {@link Configuration}.
- * It is used to bridge some of the old public interfaces that work with {@link Configuration} even though they
- * should actually work with {@link ReadableConfig}.
- */
-@Internal
-public class ReadableConfigToConfigurationAdapter extends Configuration {
-	private final ReadableConfig backingConfig;
-
-	public ReadableConfigToConfigurationAdapter(ReadableConfig backingConfig) {
-		this.backingConfig = checkNotNull(backingConfig);
-	}
-
-	@Override
-	public String getString(ConfigOption<String> configOption) {
-		return backingConfig.get(configOption);
-	}
-
-	@Override
-	public String getString(ConfigOption<String> configOption, String overrideDefault) {
-		return backingConfig.getOptional(configOption).orElse(overrideDefault);
-	}
-
-	@Override
-	public int getInteger(ConfigOption<Integer> configOption) {
-		return backingConfig.get(configOption);
-	}
-
-	@Override
-	public int getInteger(ConfigOption<Integer> configOption, int overrideDefault) {
-		return backingConfig.getOptional(configOption).orElse(overrideDefault);
-	}
-
-	@Override
-	public long getLong(ConfigOption<Long> configOption) {
-		return backingConfig.get(configOption);
-	}
-
-	@Override
-	public long getLong(ConfigOption<Long> configOption, long overrideDefault) {
-		return backingConfig.getOptional(configOption).orElse(overrideDefault);
-	}
-
-	@Override
-	public boolean getBoolean(ConfigOption<Boolean> configOption) {
-		return backingConfig.get(configOption);
-	}
-
-	@Override
-	public boolean getBoolean(ConfigOption<Boolean> configOption, boolean overrideDefault) {
-		return backingConfig.getOptional(configOption).orElse(overrideDefault);
-	}
-
-	@Override
-	public float getFloat(ConfigOption<Float> configOption) {
-		return backingConfig.get(configOption);
-	}
-
-	@Override
-	public float getFloat(ConfigOption<Float> configOption, float overrideDefault) {
-		return backingConfig.getOptional(configOption).orElse(overrideDefault);
-	}
-
-	@Override
-	public double getDouble(ConfigOption<Double> configOption) {
-		return backingConfig.get(configOption);
-	}
-
-	@Override
-	public double getDouble(ConfigOption<Double> configOption, double overrideDefault) {
-		return backingConfig.getOptional(configOption).orElse(overrideDefault);
-	}
-
-	@Override
-	public <T> T get(ConfigOption<T> option) {
-		return backingConfig.get(option);
-	}
-
-	@Override
-	public <T> Optional<T> getOptional(ConfigOption<T> option) {
-		return backingConfig.getOptional(option);
-	}
-
-	@Override
-	public boolean contains(ConfigOption<?> configOption) {
-		return this.backingConfig.getOptional(configOption).isPresent();
-	}
-
-	@Override
-	public int hashCode() {
-		return backingConfig.hashCode();
-	}
-
-	@Override
-	public boolean equals(Object obj) {
-		return backingConfig.equals(obj);
-	}
-
-	@Override
-	public String toString() {
-		return backingConfig.toString();
-	}
-
-	/*
-		Modifying methods
-	*/
-
-	@Override
-	public void setClass(String key, Class<?> klazz) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setString(String key, String value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setString(ConfigOption<String> key, String value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setInteger(String key, int value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setInteger(ConfigOption<Integer> key, int value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setLong(String key, long value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setLong(ConfigOption<Long> key, long value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setBoolean(String key, boolean value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setBoolean(ConfigOption<Boolean> key, boolean value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setFloat(String key, float value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setFloat(ConfigOption<Float> key, float value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setDouble(String key, double value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setDouble(ConfigOption<Double> key, double value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void setBytes(String key, byte[] bytes) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void addAllToProperties(Properties props) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void addAll(Configuration other) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public void addAll(Configuration other, String prefix) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public <T> Configuration set(ConfigOption<T> option, T value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	<T> void setValueInternal(String key, T value) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	@Override
-	public <T> boolean removeConfig(ConfigOption<T> configOption) {
-		throw new UnsupportedOperationException("The configuration is read only");
-	}
-
-	/*
-	 * Other unsupported options.
-	 */
-
-	@Override
-	public byte[] getBytes(String key, byte[] defaultValue) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public String getValue(ConfigOption<?> configOption) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public <T extends Enum<T>> T getEnum(
-		Class<T> enumClass,
-		ConfigOption<String> configOption) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public Configuration clone() {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public boolean containsKey(String key) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public double getDouble(String key, double defaultValue) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public <T> Class<T> getClass(
-		String key,
-		Class<? extends T> defaultValue,
-		ClassLoader classLoader) throws ClassNotFoundException {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public String getString(String key, String defaultValue) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public int getInteger(String key, int defaultValue) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public long getLong(String key, long defaultValue) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public boolean getBoolean(String key, boolean defaultValue) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public float getFloat(String key, float defaultValue) {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public Set<String> keySet() {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public Map<String, String> toMap() {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public void read(DataInputView in) throws IOException {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-
-	@Override
-	public void write(DataOutputView out) throws IOException {
-		throw new UnsupportedOperationException("The adapter does not support this method");
-	}
-}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/ConfigurableStateBackend.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/ConfigurableStateBackend.java
index dd484678729..a5d003ce58f 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/ConfigurableStateBackend.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/ConfigurableStateBackend.java
@@ -19,8 +19,8 @@
 package org.apache.flink.runtime.state;
 
 import org.apache.flink.annotation.Internal;
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
+import org.apache.flink.configuration.ReadableConfig;
 
 /**
  * An interface for state backends that pick up additional parameters from a configuration.
@@ -44,5 +44,5 @@ public interface ConfigurableStateBackend {
 	 *
 	 * @throws IllegalConfigurationException Thrown if the configuration contained invalid entries.
 	 */
-	StateBackend configure(Configuration config, ClassLoader classLoader) throws IllegalConfigurationException;
+	StateBackend configure(ReadableConfig config, ClassLoader classLoader) throws IllegalConfigurationException;
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendFactory.java
index c9d7ef4b7f1..5b0bd339a9e 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendFactory.java
@@ -19,8 +19,8 @@
 package org.apache.flink.runtime.state;
 
 import org.apache.flink.annotation.PublicEvolving;
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
+import org.apache.flink.configuration.ReadableConfig;
 
 import java.io.IOException;
 
@@ -48,5 +48,5 @@ public interface StateBackendFactory<T extends StateBackend> {
 	 * @throws IOException
 	 *             If the state backend initialization failed due to an I/O exception
 	 */
-	T createFromConfig(Configuration config, ClassLoader classLoader) throws IllegalConfigurationException, IOException;
+	T createFromConfig(ReadableConfig config, ClassLoader classLoader) throws IllegalConfigurationException, IOException;
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendLoader.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendLoader.java
index 7ab572e6c1c..4f551d7686b 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendLoader.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/StateBackendLoader.java
@@ -21,6 +21,7 @@ package org.apache.flink.runtime.state;
 import org.apache.flink.configuration.CheckpointingOptions;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.runtime.state.filesystem.FsStateBackend;
 import org.apache.flink.runtime.state.filesystem.FsStateBackendFactory;
@@ -65,7 +66,7 @@ public class StateBackendLoader {
 	 * <p>The state backends can be specified either via their shortcut name, or via the class name
 	 * of a {@link StateBackendFactory}. If a StateBackendFactory class name is specified, the factory
 	 * is instantiated (via its zero-argument constructor) and its
-	 * {@link StateBackendFactory#createFromConfig(Configuration, ClassLoader)} method is called.
+	 * {@link StateBackendFactory#createFromConfig(ReadableConfig, ClassLoader)} method is called.
 	 *
 	 * <p>Recognized shortcut names are '{@value StateBackendLoader#MEMORY_STATE_BACKEND_NAME}',
 	 * '{@value StateBackendLoader#FS_STATE_BACKEND_NAME}', and
@@ -87,14 +88,14 @@ public class StateBackendLoader {
 	 *             May be thrown by the StateBackendFactory when instantiating the state backend
 	 */
 	public static StateBackend loadStateBackendFromConfig(
-			Configuration config,
+			ReadableConfig config,
 			ClassLoader classLoader,
 			@Nullable Logger logger) throws IllegalConfigurationException, DynamicCodeLoadingException, IOException {
 
 		checkNotNull(config, "config");
 		checkNotNull(classLoader, "classLoader");
 
-		final String backendName = config.getString(CheckpointingOptions.STATE_BACKEND);
+		final String backendName = config.get(CheckpointingOptions.STATE_BACKEND);
 		if (backendName == null) {
 			return null;
 		}
@@ -162,10 +163,10 @@ public class StateBackendLoader {
 	 * default state backend (the {@link MemoryStateBackend}). 
 	 *
 	 * <p>If an application-defined state backend is found, and the state backend is a
-	 * {@link ConfigurableStateBackend}, this methods calls {@link ConfigurableStateBackend#configure(Configuration, ClassLoader)}
+	 * {@link ConfigurableStateBackend}, this methods calls {@link ConfigurableStateBackend#configure(ReadableConfig, ClassLoader)}
 	 * on the state backend.
 	 *
-	 * <p>Refer to {@link #loadStateBackendFromConfig(Configuration, ClassLoader, Logger)} for details on
+	 * <p>Refer to {@link #loadStateBackendFromConfig(ReadableConfig, ClassLoader, Logger)} for details on
 	 * how the state backend is loaded from the configuration.
 	 *
 	 * @param config The configuration to load the state backend from
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/AbstractFileStateBackend.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/AbstractFileStateBackend.java
index 0929504b2b0..2bbeedebccf 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/AbstractFileStateBackend.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/AbstractFileStateBackend.java
@@ -21,8 +21,8 @@ package org.apache.flink.runtime.state.filesystem;
 import org.apache.flink.annotation.PublicEvolving;
 import org.apache.flink.configuration.CheckpointingOptions;
 import org.apache.flink.configuration.ConfigOption;
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.runtime.state.AbstractStateBackend;
 import org.apache.flink.runtime.state.CompletedCheckpointStorageLocation;
@@ -126,7 +126,7 @@ public abstract class AbstractFileStateBackend extends AbstractStateBackend {
 	protected AbstractFileStateBackend(
 			@Nullable Path baseCheckpointPath,
 			@Nullable Path baseSavepointPath,
-			Configuration configuration) {
+			ReadableConfig configuration) {
 
 		this(parameterOrConfigured(baseCheckpointPath, configuration, CheckpointingOptions.CHECKPOINTS_DIRECTORY),
 				parameterOrConfigured(baseSavepointPath, configuration, CheckpointingOptions.SAVEPOINT_DIRECTORY));
@@ -199,12 +199,12 @@ public abstract class AbstractFileStateBackend extends AbstractStateBackend {
 	}
 
 	@Nullable
-	private static Path parameterOrConfigured(@Nullable Path path, Configuration config, ConfigOption<String> option) {
+	private static Path parameterOrConfigured(@Nullable Path path, ReadableConfig config, ConfigOption<String> option) {
 		if (path != null) {
 			return path;
 		}
 		else {
-			String configValue = config.getString(option);
+			String configValue = config.get(option);
 			try {
 				return configValue == null ? null : new Path(configValue);
 			}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackend.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackend.java
index 472b23a9015..e45fb20c44c 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackend.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackend.java
@@ -22,7 +22,7 @@ import org.apache.flink.annotation.PublicEvolving;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.configuration.CheckpointingOptions;
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.CloseableRegistry;
 import org.apache.flink.core.fs.FileSystem;
 import org.apache.flink.core.fs.Path;
@@ -93,7 +93,7 @@ import static org.apache.flink.util.Preconditions.checkNotNull;
  * parameters from the Flink configuration. For example, if the backend if configured in the application
  * without a default savepoint directory, it will pick up a default savepoint directory specified in the
  * Flink configuration of the running job/cluster. That behavior is implemented via the
- * {@link #configure(Configuration, ClassLoader)} method.
+ * {@link #configure(ReadableConfig, ClassLoader)} method.
  */
 @PublicEvolving
 public class FsStateBackend extends AbstractFileStateBackend implements ConfigurableStateBackend {
@@ -355,17 +355,17 @@ public class FsStateBackend extends AbstractFileStateBackend implements Configur
 	 * @param original The state backend to re-configure
 	 * @param configuration The configuration
 	 */
-	private FsStateBackend(FsStateBackend original, Configuration configuration, ClassLoader classLoader) {
+	private FsStateBackend(FsStateBackend original, ReadableConfig configuration, ClassLoader classLoader) {
 		super(original.getCheckpointPath(), original.getSavepointPath(), configuration);
 
 		// if asynchronous snapshots were configured, use that setting,
 		// else check the configuration
 		this.asynchronousSnapshots = original.asynchronousSnapshots.resolveUndefined(
-				configuration.getBoolean(CheckpointingOptions.ASYNC_SNAPSHOTS));
+				configuration.get(CheckpointingOptions.ASYNC_SNAPSHOTS));
 
 		final int sizeThreshold = original.fileStateThreshold >= 0 ?
 				original.fileStateThreshold :
-				configuration.getInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD);
+				configuration.get(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD);
 
 		if (sizeThreshold >= 0 && sizeThreshold <= MAX_FILE_STATE_THRESHOLD) {
 			this.fileStateThreshold = sizeThreshold;
@@ -383,7 +383,7 @@ public class FsStateBackend extends AbstractFileStateBackend implements Configur
 
 		final int bufferSize = original.writeBufferSize >= 0 ?
 			original.writeBufferSize :
-			configuration.getInteger(CheckpointingOptions.FS_WRITE_BUFFER_SIZE);
+			configuration.get(CheckpointingOptions.FS_WRITE_BUFFER_SIZE);
 
 		this.writeBufferSize = Math.max(bufferSize, this.fileStateThreshold);
 	}
@@ -471,7 +471,7 @@ public class FsStateBackend extends AbstractFileStateBackend implements Configur
 	 * @return The re-configured variant of the state backend
 	 */
 	@Override
-	public FsStateBackend configure(Configuration config, ClassLoader classLoader) {
+	public FsStateBackend configure(ReadableConfig config, ClassLoader classLoader) {
 		return new FsStateBackend(this, config, classLoader);
 	}
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackendFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackendFactory.java
index e0db5de8eb5..828070a9fb2 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackendFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsStateBackendFactory.java
@@ -20,8 +20,8 @@ package org.apache.flink.runtime.state.filesystem;
 
 import org.apache.flink.annotation.PublicEvolving;
 import org.apache.flink.configuration.CheckpointingOptions;
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.runtime.state.StateBackendFactory;
 
 /**
@@ -31,10 +31,10 @@ import org.apache.flink.runtime.state.StateBackendFactory;
 public class FsStateBackendFactory implements StateBackendFactory<FsStateBackend> {
 
 	@Override
-	public FsStateBackend createFromConfig(Configuration config, ClassLoader classLoader) throws IllegalConfigurationException {
+	public FsStateBackend createFromConfig(ReadableConfig config, ClassLoader classLoader) throws IllegalConfigurationException {
 		// we need to explicitly read the checkpoint directory here, because that
 		// is a required constructor parameter
-		final String checkpointDir = config.getString(CheckpointingOptions.CHECKPOINTS_DIRECTORY);
+		final String checkpointDir = config.get(CheckpointingOptions.CHECKPOINTS_DIRECTORY);
 		if (checkpointDir == null) {
 			throw new IllegalConfigurationException(
 					"Cannot create the file system state backend: The configuration does not specify the " +
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackend.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackend.java
index c0fbb9ae759..3a6b875a2b9 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackend.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackend.java
@@ -22,7 +22,7 @@ import org.apache.flink.annotation.PublicEvolving;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.configuration.CheckpointingOptions;
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.CloseableRegistry;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.metrics.MetricGroup;
@@ -100,7 +100,7 @@ import static org.apache.flink.util.Preconditions.checkArgument;
  * parameters from the Flink configuration. For example, if the backend if configured in the application
  * without a default savepoint directory, it will pick up a default savepoint directory specified in the
  * Flink configuration of the running job/cluster. That behavior is implemented via the
- * {@link #configure(Configuration, ClassLoader)} method.
+ * {@link #configure(ReadableConfig, ClassLoader)} method.
  */
 @PublicEvolving
 public class MemoryStateBackend extends AbstractFileStateBackend implements ConfigurableStateBackend {
@@ -234,7 +234,7 @@ public class MemoryStateBackend extends AbstractFileStateBackend implements Conf
 	 * @param configuration The configuration
 	 * @param classLoader The class loader
 	 */
-	private MemoryStateBackend(MemoryStateBackend original, Configuration configuration, ClassLoader classLoader) {
+	private MemoryStateBackend(MemoryStateBackend original, ReadableConfig configuration, ClassLoader classLoader) {
 		super(original.getCheckpointPath(), original.getSavepointPath(), configuration);
 
 		this.maxStateSize = original.maxStateSize;
@@ -242,7 +242,7 @@ public class MemoryStateBackend extends AbstractFileStateBackend implements Conf
 		// if asynchronous snapshots were configured, use that setting,
 		// else check the configuration
 		this.asynchronousSnapshots = original.asynchronousSnapshots.resolveUndefined(
-				configuration.getBoolean(CheckpointingOptions.ASYNC_SNAPSHOTS));
+				configuration.get(CheckpointingOptions.ASYNC_SNAPSHOTS));
 	}
 
 	// ------------------------------------------------------------------------
@@ -282,7 +282,7 @@ public class MemoryStateBackend extends AbstractFileStateBackend implements Conf
 	 * @return The re-configured variant of the state backend
 	 */
 	@Override
-	public MemoryStateBackend configure(Configuration config, ClassLoader classLoader) {
+	public MemoryStateBackend configure(ReadableConfig config, ClassLoader classLoader) {
 		return new MemoryStateBackend(this, config, classLoader);
 	}
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackendFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackendFactory.java
index 149063fba06..39625c506c5 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackendFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/state/memory/MemoryStateBackendFactory.java
@@ -19,7 +19,7 @@
 package org.apache.flink.runtime.state.memory;
 
 import org.apache.flink.annotation.PublicEvolving;
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.runtime.state.StateBackendFactory;
 
 /**
@@ -29,7 +29,7 @@ import org.apache.flink.runtime.state.StateBackendFactory;
 public class MemoryStateBackendFactory implements StateBackendFactory<MemoryStateBackend> {
 
 	@Override
-	public MemoryStateBackend createFromConfig(Configuration config, ClassLoader classLoader) {
+	public MemoryStateBackend createFromConfig(ReadableConfig config, ClassLoader classLoader) {
 		return new MemoryStateBackend().configure(config, classLoader);
 	}
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/state/StateBackendLoadingTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/state/StateBackendLoadingTest.java
index 3567049f995..877a51da215 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/state/StateBackendLoadingTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/state/StateBackendLoadingTest.java
@@ -21,6 +21,7 @@ package org.apache.flink.runtime.state;
 import org.apache.flink.configuration.CheckpointingOptions;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.HighAvailabilityOptions;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.FileSystem;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.runtime.state.filesystem.FsStateBackend;
@@ -427,7 +428,7 @@ public class StateBackendLoadingTest {
 	static final class FailingFactory implements StateBackendFactory<StateBackend> {
 
 		@Override
-		public StateBackend createFromConfig(Configuration config, ClassLoader classLoader) throws IOException {
+		public StateBackend createFromConfig(ReadableConfig config, ClassLoader classLoader) throws IOException {
 			throw new IOException("fail!");
 		}
 	}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/state/testutils/BackendForTestStream.java b/flink-runtime/src/test/java/org/apache/flink/runtime/state/testutils/BackendForTestStream.java
index c8697f8c015..4a6330d6f31 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/state/testutils/BackendForTestStream.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/state/testutils/BackendForTestStream.java
@@ -19,7 +19,7 @@
 package org.apache.flink.runtime.state.testutils;
 
 import org.apache.flink.api.common.JobID;
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.runtime.state.CheckpointStorage;
 import org.apache.flink.runtime.state.CheckpointStorageLocation;
 import org.apache.flink.runtime.state.CheckpointStorageLocationReference;
@@ -56,7 +56,7 @@ public class BackendForTestStream extends MemoryStateBackend {
 
 	// make no reconfiguration!
 	@Override
-	public MemoryStateBackend configure(Configuration config, ClassLoader classLoader) {
+	public MemoryStateBackend configure(ReadableConfig config, ClassLoader classLoader) {
 		return this;
 	}
 
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableOptionsFactory.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableOptionsFactory.java
index 343eda8ace3..9256e5911eb 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableOptionsFactory.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableOptionsFactory.java
@@ -18,7 +18,7 @@
 
 package org.apache.flink.contrib.streaming.state;
 
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 
 /**
  * @deprecated Replaced by {@link ConfigurableRocksDBOptionsFactory}.
@@ -35,5 +35,5 @@ public interface ConfigurableOptionsFactory extends OptionsFactory {
 	 * @param configuration The configuration to pick the values from.
 	 * @return A reconfigured options factory.
 	 */
-	OptionsFactory configure(Configuration configuration);
+	OptionsFactory configure(ReadableConfig configuration);
 }
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableRocksDBOptionsFactory.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableRocksDBOptionsFactory.java
index ac7b882a867..3a7e5497320 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableRocksDBOptionsFactory.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ConfigurableRocksDBOptionsFactory.java
@@ -18,7 +18,7 @@
 
 package org.apache.flink.contrib.streaming.state;
 
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 
 /**
  * An interface for options factory that pick up additional parameters from a configuration.
@@ -35,5 +35,5 @@ public interface ConfigurableRocksDBOptionsFactory extends RocksDBOptionsFactory
 	 * @param configuration The configuration to pick the values from.
 	 * @return A reconfigured options factory.
 	 */
-	RocksDBOptionsFactory configure(Configuration configuration);
+	RocksDBOptionsFactory configure(ReadableConfig configuration);
 }
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/DefaultConfigurableOptionsFactory.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/DefaultConfigurableOptionsFactory.java
index aaa9e83217d..88c8fada5c2 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/DefaultConfigurableOptionsFactory.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/DefaultConfigurableOptionsFactory.java
@@ -19,8 +19,8 @@
 package org.apache.flink.contrib.streaming.state;
 
 import org.apache.flink.configuration.ConfigOption;
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.MemorySize;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.util.Preconditions;
 
 import org.rocksdb.BlockBasedTableConfig;
@@ -333,7 +333,7 @@ public class DefaultConfigurableOptionsFactory implements ConfigurableRocksDBOpt
 	));
 
 	/**
-	 * Creates a {@link DefaultConfigurableOptionsFactory} instance from a {@link Configuration}.
+	 * Creates a {@link DefaultConfigurableOptionsFactory} instance from a {@link ReadableConfig}.
 	 *
 	 * <p>If no options within {@link RocksDBConfigurableOptions} has ever been configured,
 	 * the created OptionsFactory would not override anything defined in {@link PredefinedOptions}.
@@ -342,7 +342,7 @@ public class DefaultConfigurableOptionsFactory implements ConfigurableRocksDBOpt
 	 * @return A ConfigurableOptionsFactory created from the given configuration
 	 */
 	@Override
-	public DefaultConfigurableOptionsFactory configure(Configuration configuration) {
+	public DefaultConfigurableOptionsFactory configure(ReadableConfig configuration) {
 		for (ConfigOption<?> option : CANDIDATE_CONFIGS) {
 			Optional<?> newValue = configuration.getOptional(option);
 
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMemoryConfiguration.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMemoryConfiguration.java
index 40f20faa67c..96bc247c491 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMemoryConfiguration.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMemoryConfiguration.java
@@ -18,8 +18,8 @@
 
 package org.apache.flink.contrib.streaming.state;
 
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.MemorySize;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.util.Preconditions;
 
 import javax.annotation.Nullable;
@@ -183,13 +183,13 @@ public final class RocksDBMemoryConfiguration implements Serializable {
 	 */
 	public static RocksDBMemoryConfiguration fromOtherAndConfiguration(
 			RocksDBMemoryConfiguration other,
-			Configuration config) {
+			ReadableConfig config) {
 
 		final RocksDBMemoryConfiguration newConfig = new RocksDBMemoryConfiguration();
 
 		newConfig.useManagedMemory = other.useManagedMemory != null
 				? other.useManagedMemory
-				: config.getBoolean(RocksDBOptions.USE_MANAGED_MEMORY);
+				: config.get(RocksDBOptions.USE_MANAGED_MEMORY);
 
 		newConfig.fixedMemoryPerSlot = other.fixedMemoryPerSlot != null
 				? other.fixedMemoryPerSlot
@@ -197,11 +197,11 @@ public final class RocksDBMemoryConfiguration implements Serializable {
 
 		newConfig.writeBufferRatio = other.writeBufferRatio != null
 				? other.writeBufferRatio
-				: config.getDouble(RocksDBOptions.WRITE_BUFFER_RATIO);
+				: config.get(RocksDBOptions.WRITE_BUFFER_RATIO);
 
 		newConfig.highPriorityPoolRatio = other.highPriorityPoolRatio != null
 			? other.highPriorityPoolRatio
-			: config.getDouble(RocksDBOptions.HIGH_PRIORITY_POOL_RATIO);
+			: config.get(RocksDBOptions.HIGH_PRIORITY_POOL_RATIO);
 
 		return newConfig;
 	}
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBNativeMetricOptions.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBNativeMetricOptions.java
index bbdb145f1aa..0a56c7e38c3 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBNativeMetricOptions.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBNativeMetricOptions.java
@@ -20,7 +20,7 @@ package org.apache.flink.contrib.streaming.state;
 
 import org.apache.flink.configuration.ConfigOption;
 import org.apache.flink.configuration.ConfigOptions;
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 
 import java.io.Serializable;
 import java.util.Collection;
@@ -186,109 +186,109 @@ public class RocksDBNativeMetricOptions implements Serializable {
 	 * Creates a {@link RocksDBNativeMetricOptions} based on an
 	 * external configuration.
 	 */
-	public static RocksDBNativeMetricOptions fromConfig(Configuration config) {
+	public static RocksDBNativeMetricOptions fromConfig(ReadableConfig config) {
 		RocksDBNativeMetricOptions options = new RocksDBNativeMetricOptions();
-		if (config.getBoolean(MONITOR_NUM_IMMUTABLE_MEM_TABLES)) {
+		if (config.get(MONITOR_NUM_IMMUTABLE_MEM_TABLES)) {
 			options.enableNumImmutableMemTable();
 		}
 
-		if (config.getBoolean(MONITOR_MEM_TABLE_FLUSH_PENDING)) {
+		if (config.get(MONITOR_MEM_TABLE_FLUSH_PENDING)) {
 			options.enableMemTableFlushPending();
 		}
 
-		if (config.getBoolean(TRACK_COMPACTION_PENDING)) {
+		if (config.get(TRACK_COMPACTION_PENDING)) {
 			options.enableCompactionPending();
 		}
 
-		if (config.getBoolean(MONITOR_BACKGROUND_ERRORS)) {
+		if (config.get(MONITOR_BACKGROUND_ERRORS)) {
 			options.enableBackgroundErrors();
 		}
 
-		if (config.getBoolean(MONITOR_CUR_SIZE_ACTIVE_MEM_TABLE)) {
+		if (config.get(MONITOR_CUR_SIZE_ACTIVE_MEM_TABLE)) {
 			options.enableCurSizeActiveMemTable();
 		}
 
-		if (config.getBoolean(MONITOR_CUR_SIZE_ALL_MEM_TABLE)) {
+		if (config.get(MONITOR_CUR_SIZE_ALL_MEM_TABLE)) {
 			options.enableCurSizeAllMemTables();
 		}
 
-		if (config.getBoolean(MONITOR_SIZE_ALL_MEM_TABLES)) {
+		if (config.get(MONITOR_SIZE_ALL_MEM_TABLES)) {
 			options.enableSizeAllMemTables();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_ENTRIES_ACTIVE_MEM_TABLE)) {
+		if (config.get(MONITOR_NUM_ENTRIES_ACTIVE_MEM_TABLE)) {
 			options.enableNumEntriesActiveMemTable();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_ENTRIES_IMM_MEM_TABLES)) {
+		if (config.get(MONITOR_NUM_ENTRIES_IMM_MEM_TABLES)) {
 			options.enableNumEntriesImmMemTables();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_DELETES_ACTIVE_MEM_TABLE)) {
+		if (config.get(MONITOR_NUM_DELETES_ACTIVE_MEM_TABLE)) {
 			options.enableNumDeletesActiveMemTable();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_DELETES_IMM_MEM_TABLE)) {
+		if (config.get(MONITOR_NUM_DELETES_IMM_MEM_TABLE)) {
 			options.enableNumDeletesImmMemTables();
 		}
 
-		if (config.getBoolean(ESTIMATE_NUM_KEYS)) {
+		if (config.get(ESTIMATE_NUM_KEYS)) {
 			options.enableEstimateNumKeys();
 		}
 
-		if (config.getBoolean(ESTIMATE_TABLE_READERS_MEM)) {
+		if (config.get(ESTIMATE_TABLE_READERS_MEM)) {
 			options.enableEstimateTableReadersMem();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_SNAPSHOTS)) {
+		if (config.get(MONITOR_NUM_SNAPSHOTS)) {
 			options.enableNumSnapshots();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_LIVE_VERSIONS)) {
+		if (config.get(MONITOR_NUM_LIVE_VERSIONS)) {
 			options.enableNumLiveVersions();
 		}
 
-		if (config.getBoolean(ESTIMATE_LIVE_DATA_SIZE)) {
+		if (config.get(ESTIMATE_LIVE_DATA_SIZE)) {
 			options.enableEstimateLiveDataSize();
 		}
 
-		if (config.getBoolean(MONITOR_TOTAL_SST_FILES_SIZE)) {
+		if (config.get(MONITOR_TOTAL_SST_FILES_SIZE)) {
 			options.enableTotalSstFilesSize();
 		}
 
-		if (config.getBoolean(ESTIMATE_PENDING_COMPACTION_BYTES)) {
+		if (config.get(ESTIMATE_PENDING_COMPACTION_BYTES)) {
 			options.enableEstimatePendingCompactionBytes();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_RUNNING_COMPACTIONS)) {
+		if (config.get(MONITOR_NUM_RUNNING_COMPACTIONS)) {
 			options.enableNumRunningCompactions();
 		}
 
-		if (config.getBoolean(MONITOR_NUM_RUNNING_FLUSHES)) {
+		if (config.get(MONITOR_NUM_RUNNING_FLUSHES)) {
 			options.enableNumRunningFlushes();
 		}
 
-		if (config.getBoolean(MONITOR_ACTUAL_DELAYED_WRITE_RATE)) {
+		if (config.get(MONITOR_ACTUAL_DELAYED_WRITE_RATE)) {
 			options.enableActualDelayedWriteRate();
 		}
 
-		if (config.getBoolean(IS_WRITE_STOPPED)) {
+		if (config.get(IS_WRITE_STOPPED)) {
 			options.enableIsWriteStopped();
 		}
 
-		if (config.getBoolean(BLOCK_CACHE_CAPACITY)) {
+		if (config.get(BLOCK_CACHE_CAPACITY)) {
 			options.enableBlockCacheCapacity();
 		}
 
-		if (config.getBoolean(BLOCK_CACHE_USAGE)) {
+		if (config.get(BLOCK_CACHE_USAGE)) {
 			options.enableBlockCacheUsage();
 		}
 
-		if (config.getBoolean(BLOCK_CACHE_PINNED_USAGE)) {
+		if (config.get(BLOCK_CACHE_PINNED_USAGE)) {
 			options.enableBlockCachePinnedUsage();
 		}
 
-		options.setColumnFamilyAsVariable(config.getBoolean(COLUMN_FAMILY_AS_VARIABLE));
+		options.setColumnFamilyAsVariable(config.get(COLUMN_FAMILY_AS_VARIABLE));
 
 		return options;
 	}
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java
index 932d0366069..5a5470efb5c 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java
@@ -22,6 +22,7 @@ import org.apache.flink.annotation.docs.Documentation;
 import org.apache.flink.configuration.ConfigOption;
 import org.apache.flink.configuration.ConfigOptions;
 import org.apache.flink.configuration.MemorySize;
+import org.apache.flink.contrib.streaming.state.RocksDBStateBackend.PriorityQueueStateType;
 
 import static org.apache.flink.contrib.streaming.state.PredefinedOptions.DEFAULT;
 import static org.apache.flink.contrib.streaming.state.PredefinedOptions.FLASH_SSD_OPTIMIZED;
@@ -47,9 +48,10 @@ public class RocksDBOptions {
 	 * Choice of timer service implementation.
 	 */
 	@Documentation.Section(Documentation.Sections.STATE_BACKEND_ROCKSDB)
-	public static final ConfigOption<String> TIMER_SERVICE_FACTORY = ConfigOptions
+	public static final ConfigOption<PriorityQueueStateType> TIMER_SERVICE_FACTORY = ConfigOptions
 		.key("state.backend.rocksdb.timer-service.factory")
-		.defaultValue(ROCKSDB.name())
+		.enumType(PriorityQueueStateType.class)
+		.defaultValue(ROCKSDB)
 		.withDescription(String.format("This determines the factory for timer service state implementation. Options " +
 			"are either %s (heap-based, default) or %s for an implementation based on RocksDB .",
 			HEAP.name(), ROCKSDB.name()));
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryAdapter.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryAdapter.java
index 36e8c3f5978..862832f7631 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryAdapter.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryAdapter.java
@@ -18,7 +18,7 @@
 
 package org.apache.flink.contrib.streaming.state;
 
-import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 
 import org.rocksdb.ColumnFamilyOptions;
 import org.rocksdb.DBOptions;
@@ -57,7 +57,7 @@ final class RocksDBOptionsFactoryAdapter implements ConfigurableRocksDBOptionsFa
 	}
 
 	@Override
-	public RocksDBOptionsFactory configure(Configuration configuration) {
+	public RocksDBOptionsFactory configure(ReadableConfig configuration) {
 		if (optionsFactory instanceof ConfigurableOptionsFactory) {
 			final OptionsFactory reconfigured = ((ConfigurableOptionsFactory) optionsFactory).configure(configuration);
 			return reconfigured == optionsFactory ? this : new RocksDBOptionsFactoryAdapter(reconfigured);
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackend.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackend.java
index 873f57d6978..add3cf1c14c 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackend.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackend.java
@@ -22,8 +22,8 @@ import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.configuration.CheckpointingOptions;
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.CloseableRegistry;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.metrics.MetricGroup;
@@ -304,7 +304,7 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 	 * @param config The configuration.
 	 * @param classLoader The class loader.
 	 */
-	private RocksDBStateBackend(RocksDBStateBackend original, Configuration config, ClassLoader classLoader) {
+	private RocksDBStateBackend(RocksDBStateBackend original, ReadableConfig config, ClassLoader classLoader) {
 		// reconfigure the state backend backing the streams
 		final StateBackend originalStreamBackend = original.checkpointStreamBackend;
 		this.checkpointStreamBackend = originalStreamBackend instanceof ConfigurableStateBackend ?
@@ -313,10 +313,10 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 
 		// configure incremental checkpoints
 		this.enableIncrementalCheckpointing = original.enableIncrementalCheckpointing.resolveUndefined(
-			config.getBoolean(CheckpointingOptions.INCREMENTAL_CHECKPOINTS));
+			config.get(CheckpointingOptions.INCREMENTAL_CHECKPOINTS));
 
 		if (original.numberOfTransferThreads == UNDEFINED_NUMBER_OF_TRANSFER_THREADS) {
-			this.numberOfTransferThreads = config.getInteger(CHECKPOINT_TRANSFER_THREAD_NUM);
+			this.numberOfTransferThreads = config.get(CHECKPOINT_TRANSFER_THREAD_NUM);
 		} else {
 			this.numberOfTransferThreads = original.numberOfTransferThreads;
 		}
@@ -327,13 +327,13 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 			this.writeBatchSize = original.writeBatchSize;
 		}
 		this.enableTtlCompactionFilter = original.enableTtlCompactionFilter
-			.resolveUndefined(config.getBoolean(TTL_COMPACT_FILTER_ENABLED));
+			.resolveUndefined(config.get(TTL_COMPACT_FILTER_ENABLED));
 
 		this.memoryConfiguration = RocksDBMemoryConfiguration.fromOtherAndConfiguration(original.memoryConfiguration, config);
 		this.memoryConfiguration.validate();
 
 		if (null == original.priorityQueueStateType) {
-			this.priorityQueueStateType = config.getEnum(PriorityQueueStateType.class, TIMER_SERVICE_FACTORY);
+			this.priorityQueueStateType = config.get(TIMER_SERVICE_FACTORY);
 		} else {
 			this.priorityQueueStateType = original.priorityQueueStateType;
 		}
@@ -343,7 +343,7 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 			this.localRocksDbDirectories = original.localRocksDbDirectories;
 		}
 		else {
-			final String rocksdbLocalPaths = config.getString(RocksDBOptions.LOCAL_DIRECTORIES);
+			final String rocksdbLocalPaths = config.get(RocksDBOptions.LOCAL_DIRECTORIES);
 			if (rocksdbLocalPaths != null) {
 				String[] directories = rocksdbLocalPaths.split(",|" + File.pathSeparator);
 
@@ -362,14 +362,14 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 
 		// configure RocksDB predefined options
 		this.predefinedOptions = original.predefinedOptions == null ?
-			PredefinedOptions.valueOf(config.getString(RocksDBOptions.PREDEFINED_OPTIONS)) : original.predefinedOptions;
+			PredefinedOptions.valueOf(config.get(RocksDBOptions.PREDEFINED_OPTIONS)) : original.predefinedOptions;
 		LOG.info("Using predefined options: {}.", predefinedOptions.name());
 
 		// configure RocksDB options factory
 		try {
 			rocksDbOptionsFactory = configureOptionsFactory(
 				original.rocksDbOptionsFactory,
-				config.getString(RocksDBOptions.OPTIONS_FACTORY),
+				config.get(RocksDBOptions.OPTIONS_FACTORY),
 				config,
 				classLoader);
 		} catch (DynamicCodeLoadingException e) {
@@ -390,7 +390,7 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 	 * @return The re-configured variant of the state backend
 	 */
 	@Override
-	public RocksDBStateBackend configure(Configuration config, ClassLoader classLoader) {
+	public RocksDBStateBackend configure(ReadableConfig config, ClassLoader classLoader) {
 		return new RocksDBStateBackend(this, config, classLoader);
 	}
 
@@ -568,7 +568,7 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 	private RocksDBOptionsFactory configureOptionsFactory(
 			@Nullable RocksDBOptionsFactory originalOptionsFactory,
 			String factoryClassName,
-			Configuration config,
+			ReadableConfig config,
 			ClassLoader classLoader) throws DynamicCodeLoadingException {
 
 		if (originalOptionsFactory != null) {
@@ -775,8 +775,7 @@ public class RocksDBStateBackend extends AbstractStateBackend implements Configu
 	 * @return The type of the priority queue state.
 	 */
 	public PriorityQueueStateType getPriorityQueueStateType() {
-		return priorityQueueStateType == null ?
-			PriorityQueueStateType.valueOf(TIMER_SERVICE_FACTORY.defaultValue()) : priorityQueueStateType;
+		return priorityQueueStateType == null ? TIMER_SERVICE_FACTORY.defaultValue() : priorityQueueStateType;
 	}
 
 	/**
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendFactory.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendFactory.java
index 7f3872fe142..8d12ef0ceb3 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendFactory.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendFactory.java
@@ -19,8 +19,8 @@
 package org.apache.flink.contrib.streaming.state;
 
 import org.apache.flink.configuration.CheckpointingOptions;
-import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.runtime.state.StateBackendFactory;
 
 import java.io.IOException;
@@ -32,12 +32,12 @@ import java.io.IOException;
 public class RocksDBStateBackendFactory implements StateBackendFactory<RocksDBStateBackend> {
 
 	@Override
-	public RocksDBStateBackend createFromConfig(Configuration config, ClassLoader classLoader)
+	public RocksDBStateBackend createFromConfig(ReadableConfig config, ClassLoader classLoader)
 			throws IllegalConfigurationException, IOException {
 
 		// we need to explicitly read the checkpoint directory here, because that
 		// is a required constructor parameter
-		final String checkpointDirURI = config.getString(CheckpointingOptions.CHECKPOINTS_DIRECTORY);
+		final String checkpointDirURI = config.get(CheckpointingOptions.CHECKPOINTS_DIRECTORY);
 		if (checkpointDirURI == null) {
 			throw new IllegalConfigurationException(
 				"Cannot create the RocksDB state backend: The configuration does not specify the " +
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBAsyncSnapshotTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBAsyncSnapshotTest.java
index 25a7bce5088..6ebc9d2fca0 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBAsyncSnapshotTest.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBAsyncSnapshotTest.java
@@ -257,7 +257,7 @@ public class RocksDBAsyncSnapshotTest extends TestLogger {
 
 		File dbDir = temporaryFolder.newFolder();
 
-		final RocksDBStateBackend.PriorityQueueStateType timerServicePriorityQueueType = RocksDBStateBackend.PriorityQueueStateType.valueOf(RocksDBOptions.TIMER_SERVICE_FACTORY.defaultValue());
+		final RocksDBStateBackend.PriorityQueueStateType timerServicePriorityQueueType = RocksDBOptions.TIMER_SERVICE_FACTORY.defaultValue();
 
 		final int skipStreams;
 
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryCompatibilityTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryCompatibilityTest.java
index f96bed3419f..8c77ac249ff 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryCompatibilityTest.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBOptionsFactoryCompatibilityTest.java
@@ -19,6 +19,7 @@
 package org.apache.flink.contrib.streaming.state;
 
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 
 import org.junit.Test;
 import org.rocksdb.ColumnFamilyOptions;
@@ -70,7 +71,7 @@ public class RocksDBOptionsFactoryCompatibilityTest {
 		boolean wasConfigured;
 
 		@Override
-		public OptionsFactory configure(Configuration configuration) {
+		public OptionsFactory configure(ReadableConfig configuration) {
 			wasConfigured = true;
 			return this;
 		}
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendConfigTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendConfigTest.java
index 2167a000d1a..d3eb6dbc28d 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendConfigTest.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendConfigTest.java
@@ -21,8 +21,10 @@ package org.apache.flink.contrib.streaming.state;
 import org.apache.flink.api.common.typeutils.base.IntSerializer;
 import org.apache.flink.configuration.CheckpointingOptions;
 import org.apache.flink.configuration.ConfigOption;
+import org.apache.flink.configuration.ConfigOptions;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.CoreOptions;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.CloseableRegistry;
 import org.apache.flink.core.fs.FileSystem;
 import org.apache.flink.core.fs.Path;
@@ -153,7 +155,7 @@ public class RocksDBStateBackendConfigTest {
 
 		// Fix the default
 		Assert.assertEquals(
-			RocksDBStateBackend.PriorityQueueStateType.ROCKSDB.toString(),
+			RocksDBStateBackend.PriorityQueueStateType.ROCKSDB,
 			RocksDBOptions.TIMER_SERVICE_FACTORY.defaultValue());
 
 		RocksDBStateBackend rocksDbBackend = new RocksDBStateBackend(tempFolder.newFolder().toURI().toString());
@@ -163,9 +165,7 @@ public class RocksDBStateBackendConfigTest {
 		keyedBackend.dispose();
 
 		Configuration conf = new Configuration();
-		conf.setString(
-			RocksDBOptions.TIMER_SERVICE_FACTORY,
-			RocksDBStateBackend.PriorityQueueStateType.HEAP.toString());
+		conf.set(RocksDBOptions.TIMER_SERVICE_FACTORY, RocksDBStateBackend.PriorityQueueStateType.HEAP);
 
 		rocksDbBackend = rocksDbBackend.configure(conf, Thread.currentThread().getContextClassLoader());
 		keyedBackend = createKeyedStateBackend(rocksDbBackend, env);
@@ -190,7 +190,7 @@ public class RocksDBStateBackendConfigTest {
 		// priorityQueueStateType in the cluster config
 		final Configuration configFromConfFile = new Configuration();
 		configFromConfFile.setString(
-			RocksDBOptions.TIMER_SERVICE_FACTORY,
+			RocksDBOptions.TIMER_SERVICE_FACTORY.key(),
 			RocksDBStateBackend.PriorityQueueStateType.ROCKSDB.toString());
 
 		// configure final backend from job and cluster config
@@ -547,7 +547,7 @@ public class RocksDBStateBackendConfigTest {
 		// verify that user-defined options factory could be configured via flink-conf.yaml
 		Configuration config = new Configuration();
 		config.setString(RocksDBOptions.OPTIONS_FACTORY.key(), TestOptionsFactory.class.getName());
-		config.setInteger(TestOptionsFactory.BACKGROUND_JOBS_OPTION, 4);
+		config.setString(TestOptionsFactory.BACKGROUND_JOBS_OPTION.key(), "4");
 
 		rocksDbBackend = rocksDbBackend.configure(config, getClass().getClassLoader());
 
@@ -776,10 +776,12 @@ public class RocksDBStateBackendConfigTest {
 	 * An implementation of options factory for testing.
 	 */
 	public static class TestOptionsFactory implements ConfigurableRocksDBOptionsFactory {
-		public static final String BACKGROUND_JOBS_OPTION = "my.custom.rocksdb.backgroundJobs";
+		public static final ConfigOption<Integer> BACKGROUND_JOBS_OPTION =
+			ConfigOptions.key("my.custom.rocksdb.backgroundJobs")
+				.intType()
+				.defaultValue(2);
 
-		private static final int DEFAULT_BACKGROUND_JOBS = 2;
-		private int backgroundJobs = DEFAULT_BACKGROUND_JOBS;
+		private int backgroundJobs = BACKGROUND_JOBS_OPTION.defaultValue();
 
 		@Override
 		public DBOptions createDBOptions(DBOptions currentOptions, Collection<AutoCloseable> handlesToClose) {
@@ -792,8 +794,8 @@ public class RocksDBStateBackendConfigTest {
 		}
 
 		@Override
-		public RocksDBOptionsFactory configure(Configuration configuration) {
-			this.backgroundJobs = configuration.getInteger(BACKGROUND_JOBS_OPTION, DEFAULT_BACKGROUND_JOBS);
+		public RocksDBOptionsFactory configure(ReadableConfig configuration) {
+			this.backgroundJobs = configuration.get(BACKGROUND_JOBS_OPTION);
 			return this;
 		}
 	}
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendMigrationTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendMigrationTest.java
index 4d58a644444..056e46ff1a5 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendMigrationTest.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendMigrationTest.java
@@ -53,9 +53,7 @@ public class RocksDBStateBackendMigrationTest extends StateBackendMigrationTestB
 		RocksDBStateBackend backend = new RocksDBStateBackend(new FsStateBackend(checkpointPath), enableIncrementalCheckpointing);
 
 		Configuration configuration = new Configuration();
-		configuration.setString(
-			RocksDBOptions.TIMER_SERVICE_FACTORY,
-			RocksDBStateBackend.PriorityQueueStateType.ROCKSDB.toString());
+		configuration.set(RocksDBOptions.TIMER_SERVICE_FACTORY, RocksDBStateBackend.PriorityQueueStateType.ROCKSDB);
 		backend = backend.configure(configuration, Thread.currentThread().getContextClassLoader());
 		backend.setDbStoragePath(dbPath);
 		return backend;
diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendTest.java
index b31e190e9ea..10cb6e71e60 100644
--- a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendTest.java
+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackendTest.java
@@ -133,9 +133,7 @@ public class RocksDBStateBackendTest extends StateBackendTestBase<RocksDBStateBa
 		String checkpointPath = tempFolder.newFolder().toURI().toString();
 		RocksDBStateBackend backend = new RocksDBStateBackend(new FsStateBackend(checkpointPath), enableIncrementalCheckpointing);
 		Configuration configuration = new Configuration();
-		configuration.setString(
-			RocksDBOptions.TIMER_SERVICE_FACTORY,
-			RocksDBStateBackend.PriorityQueueStateType.ROCKSDB.toString());
+		configuration.set(RocksDBOptions.TIMER_SERVICE_FACTORY, RocksDBStateBackend.PriorityQueueStateType.ROCKSDB);
 		backend = backend.configure(configuration, Thread.currentThread().getContextClassLoader());
 		backend.setDbStoragePath(dbPath);
 		return backend;
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java
index 77cef243048..705ae8ff8b4 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java
@@ -47,7 +47,6 @@ import org.apache.flink.configuration.DeploymentOptions;
 import org.apache.flink.configuration.ExecutionOptions;
 import org.apache.flink.configuration.PipelineOptions;
 import org.apache.flink.configuration.ReadableConfig;
-import org.apache.flink.configuration.ReadableConfigToConfigurationAdapter;
 import org.apache.flink.configuration.RestOptions;
 import org.apache.flink.core.execution.DefaultExecutorServiceLoader;
 import org.apache.flink.core.execution.DetachedJobExecutionResult;
@@ -790,7 +789,7 @@ public class StreamExecutionEnvironment {
 	private StateBackend loadStateBackend(ReadableConfig configuration, ClassLoader classLoader) {
 		try {
 			return StateBackendLoader.loadStateBackendFromConfig(
-				new ReadableConfigToConfigurationAdapter(configuration),
+				configuration,
 				classLoader,
 				null);
 		} catch (DynamicCodeLoadingException | IOException e) {
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java
index 29c22ba9714..3fa9508ab68 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/StreamTaskTest.java
@@ -23,6 +23,7 @@ import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.api.common.typeutils.base.StringSerializer;
 import org.apache.flink.configuration.CheckpointingOptions;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.FSDataInputStream;
 import org.apache.flink.core.testutils.OneShotLatch;
 import org.apache.flink.runtime.checkpoint.CheckpointMetaData;
@@ -1249,11 +1250,11 @@ public class StreamTaskTest extends TestLogger {
 		private static final long serialVersionUID = 1L;
 
 		@Override
-		public AbstractStateBackend createFromConfig(Configuration config, ClassLoader classLoader) {
+		public AbstractStateBackend createFromConfig(ReadableConfig config, ClassLoader classLoader) {
 			return new TestSpyWrapperStateBackend(createInnerBackend(config));
 		}
 
-		protected AbstractStateBackend createInnerBackend(Configuration config) {
+		protected AbstractStateBackend createInnerBackend(ReadableConfig config) {
 			return new MemoryStateBackend();
 		}
 	}
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/TaskCheckpointingBehaviourTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/TaskCheckpointingBehaviourTest.java
index bdf3a52346a..8d0c424a59b 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/TaskCheckpointingBehaviourTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/tasks/TaskCheckpointingBehaviourTest.java
@@ -22,6 +22,7 @@ import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.api.common.functions.FilterFunction;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.core.fs.CloseableRegistry;
 import org.apache.flink.core.testutils.OneShotLatch;
 import org.apache.flink.runtime.blob.BlobCacheService;
@@ -316,7 +317,7 @@ public class TaskCheckpointingBehaviourTest extends TestLogger {
 		}
 
 		@Override
-		public SyncFailureInducingStateBackend configure(Configuration config, ClassLoader classLoader) {
+		public SyncFailureInducingStateBackend configure(ReadableConfig configuration, ClassLoader classLoader) {
 			// retain this instance, no re-configuration!
 			return this;
 		}
@@ -368,7 +369,7 @@ public class TaskCheckpointingBehaviourTest extends TestLogger {
 		}
 
 		@Override
-		public AsyncFailureInducingStateBackend configure(Configuration config, ClassLoader classLoader) {
+		public AsyncFailureInducingStateBackend configure(ReadableConfig config, ClassLoader classLoader) {
 			// retain this instance, no re-configuration!
 			return this;
 		}
diff --git a/flink-tests/src/test/java/org/apache/flink/test/checkpointing/EventTimeWindowCheckpointingITCase.java b/flink-tests/src/test/java/org/apache/flink/test/checkpointing/EventTimeWindowCheckpointingITCase.java
index 9a41ef6c0b5..81e23c94e6f 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/checkpointing/EventTimeWindowCheckpointingITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/checkpointing/EventTimeWindowCheckpointingITCase.java
@@ -178,9 +178,7 @@ public class EventTimeWindowCheckpointingITCase extends TestLogger {
 			}
 			case ROCKSDB_INCREMENTAL:
 				// Test RocksDB based timer service as well
-				config.setString(
-					RocksDBOptions.TIMER_SERVICE_FACTORY,
-					RocksDBStateBackend.PriorityQueueStateType.ROCKSDB.toString());
+				config.set(RocksDBOptions.TIMER_SERVICE_FACTORY, RocksDBStateBackend.PriorityQueueStateType.ROCKSDB);
 				setupRocksDB(config, 16, true);
 				break;
 			case ROCKSDB_INCREMENTAL_ZK: {
