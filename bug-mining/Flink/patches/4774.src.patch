diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java
index 0a6409796b7..7cdc84dd794 100644
--- a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java
@@ -26,19 +26,21 @@ import kafka.server.KafkaServer;
 import org.apache.kafka.clients.consumer.ConsumerRecord;
 import org.apache.kafka.clients.consumer.ConsumerRecords;
 import org.apache.kafka.clients.consumer.KafkaConsumer;
+import org.apache.kafka.clients.producer.Callback;
 import org.apache.kafka.clients.producer.Producer;
 import org.apache.kafka.clients.producer.ProducerRecord;
+import org.apache.kafka.clients.producer.RecordMetadata;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
-import java.io.IOException;
 import java.time.Duration;
 import java.util.Collections;
 import java.util.Properties;
 import java.util.UUID;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNull;
 
 /**
  * Tests for our own {@link FlinkKafkaInternalProducer}.
@@ -47,6 +49,7 @@ import static org.junit.Assert.assertEquals;
 public class FlinkKafkaInternalProducerITCase extends KafkaTestBase {
 	protected String transactionalId;
 	protected Properties extraProperties;
+	private volatile Exception exceptionInCallback;
 
 	@BeforeClass
 	public static void prepare() throws Exception {
@@ -78,31 +81,33 @@ public class FlinkKafkaInternalProducerITCase extends KafkaTestBase {
 	}
 
 	@Test(timeout = 30000L)
-	public void testHappyPath() throws IOException {
+	public void testHappyPath() throws Exception {
 		String topicName = "flink-kafka-producer-happy-path";
 
 		Producer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);
 		try {
 			kafkaProducer.initTransactions();
 			kafkaProducer.beginTransaction();
-			kafkaProducer.send(new ProducerRecord<>(topicName, "42", "42"));
+			kafkaProducer.send(new ProducerRecord<>(topicName, "42", "42"), new ErrorCheckingCallback());
 			kafkaProducer.commitTransaction();
 		} finally {
 			kafkaProducer.close(Duration.ofSeconds(5));
 		}
+		assertNull("The message should have been successfully sent", exceptionInCallback);
 		assertRecord(topicName, "42", "42");
 		deleteTestTopic(topicName);
 	}
 
 	@Test(timeout = 30000L)
-	public void testResumeTransaction() throws IOException {
+	public void testResumeTransaction() throws Exception {
 		String topicName = "flink-kafka-producer-resume-transaction";
 		FlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);
 		try {
 			kafkaProducer.initTransactions();
 			kafkaProducer.beginTransaction();
-			kafkaProducer.send(new ProducerRecord<>(topicName, "42", "42"));
+			kafkaProducer.send(new ProducerRecord<>(topicName, "42", "42"), new ErrorCheckingCallback());
 			kafkaProducer.flush();
+			assertNull("The message should have been successfully sent", exceptionInCallback);
 			long producerId = kafkaProducer.getProducerId();
 			short epoch = kafkaProducer.getEpoch();
 
@@ -205,15 +210,19 @@ public class FlinkKafkaInternalProducerITCase extends KafkaTestBase {
 		FlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);
 		kafkaProducer.initTransactions();
 		kafkaProducer.beginTransaction();
-		kafkaProducer.send(new ProducerRecord<>(topicName, "42", "42"));
+		kafkaProducer.send(new ProducerRecord<>(topicName, "42", "42"), new ErrorCheckingCallback());
 		kafkaProducer.close(Duration.ofSeconds(5));
+		assertNull("The message should have been successfully sent", exceptionInCallback);
 		return kafkaProducer;
 	}
 
 	private void assertRecord(String topicName, String expectedKey, String expectedValue) {
 		try (KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(extraProperties)) {
 			kafkaConsumer.subscribe(Collections.singletonList(topicName));
-			ConsumerRecords<String, String> records = kafkaConsumer.poll(10000);
+			ConsumerRecords<String, String> records = ConsumerRecords.empty();
+			while (records.isEmpty()) {
+				records = kafkaConsumer.poll(10000);
+			}
 
 			ConsumerRecord<String, String> record = Iterables.getOnlyElement(records);
 			assertEquals(expectedKey, record.key());
@@ -244,4 +253,11 @@ public class FlinkKafkaInternalProducerITCase extends KafkaTestBase {
 			toRestart.startup();
 		}
 	}
+
+	private class ErrorCheckingCallback implements Callback {
+		@Override
+		public void onCompletion(RecordMetadata metadata, Exception exception) {
+			exceptionInCallback = exception;
+		}
+	}
 }
