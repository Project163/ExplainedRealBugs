diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java
index d3b774c8428..e450485d6f5 100644
--- a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchApiCallBridge.java
@@ -93,6 +93,18 @@ public interface ElasticsearchApiCallBridge<C extends AutoCloseable> extends Ser
 			numPendingRequestsRef);
 	}
 
+	/**
+	 * Creates a {@link RequestIndexer} that is able to work with {@link BulkProcessor} binary compatible.
+	 */
+	default ElasticsearchFailureHandlerIndexer createFailureHandlerIndexer(
+			boolean flushOnCheckpoint,
+			AtomicLong numPendingRequestsRef) {
+		return new ElasticsearchFailureHandlerIndexer(
+			flushOnCheckpoint,
+			numPendingRequestsRef);
+	}
+
+
 	/**
 	 * Perform any necessary state cleanup.
 	 */
diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchFailureHandlerIndexer.java b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchFailureHandlerIndexer.java
new file mode 100644
index 00000000000..685b5d9c602
--- /dev/null
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchFailureHandlerIndexer.java
@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.connectors.elasticsearch;
+
+import org.apache.flink.annotation.Internal;
+
+import org.elasticsearch.action.ActionRequest;
+import org.elasticsearch.action.bulk.BulkRequest;
+import org.elasticsearch.action.delete.DeleteRequest;
+import org.elasticsearch.action.index.IndexRequest;
+import org.elasticsearch.action.update.UpdateRequest;
+
+import java.util.concurrent.atomic.AtomicLong;
+
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
+/**
+ * Implementation of a {@link RequestIndexer}, using a {@link BulkRequest}.
+ * {@link ActionRequest ActionRequests} will be buffered before re-sending a bulk request to the Elasticsearch cluster.
+ */
+
+@Internal
+class ElasticsearchFailureHandlerIndexer implements RequestIndexer {
+
+	private BulkRequest bulkRequest;
+	private final boolean flushOnCheckpoint;
+	private final AtomicLong numPendingRequestsRef;
+
+	ElasticsearchFailureHandlerIndexer(boolean flushOnCheckpoint, AtomicLong numPendingRequestsRef) {
+		this.bulkRequest = new BulkRequest();
+		this.flushOnCheckpoint = flushOnCheckpoint;
+		this.numPendingRequestsRef = checkNotNull(numPendingRequestsRef);
+	}
+
+	@Override
+	public void add(DeleteRequest... deleteRequests) {
+		for (DeleteRequest deleteRequest : deleteRequests) {
+			if (flushOnCheckpoint) {
+				numPendingRequestsRef.getAndIncrement();
+			}
+			this.bulkRequest.add(deleteRequest);
+		}
+	}
+
+	@Override
+	public void add(IndexRequest... indexRequests) {
+		for (IndexRequest indexRequest : indexRequests) {
+			if (flushOnCheckpoint) {
+				numPendingRequestsRef.getAndIncrement();
+			}
+			this.bulkRequest.add(indexRequest);
+		}
+	}
+
+	@Override
+	public void add(UpdateRequest... updateRequests) {
+		for (UpdateRequest updateRequest : updateRequests) {
+			if (flushOnCheckpoint) {
+				numPendingRequestsRef.getAndIncrement();
+			}
+			this.bulkRequest.add(updateRequest);
+		}
+	}
+
+	public BulkRequest getBulkRequest() {
+		return bulkRequest;
+	}
+
+	public int numberOfActions() {
+		return bulkRequest.numberOfActions();
+	}
+}
diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java
index 4d0c00252d2..55d8854a3a9 100644
--- a/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBase.java
@@ -166,6 +166,8 @@ public abstract class ElasticsearchSinkBase<T, C extends AutoCloseable> extends
 	/** Provided to the user via the {@link ElasticsearchSinkFunction} to add {@link ActionRequest ActionRequests}. */
 	private transient RequestIndexer requestIndexer;
 
+	private transient ElasticsearchFailureHandlerIndexer failureRequestIndexer;
+
 	// ------------------------------------------------------------------------
 	//  Internals for the Flink Elasticsearch Sink
 	// ------------------------------------------------------------------------
@@ -296,12 +298,14 @@ public abstract class ElasticsearchSinkBase<T, C extends AutoCloseable> extends
 		client = callBridge.createClient(userConfig);
 		bulkProcessor = buildBulkProcessor(new BulkProcessorListener());
 		requestIndexer = callBridge.createBulkProcessorIndexer(bulkProcessor, flushOnCheckpoint, numPendingRequests);
+		failureRequestIndexer = callBridge.createFailureHandlerIndexer(flushOnCheckpoint, numPendingRequests);
 	}
 
 	@Override
 	public void invoke(T value) throws Exception {
 		// if bulk processor callbacks have previously reported an error, we rethrow the error and fail the sink
 		checkErrorAndRethrow();
+		reindexFailedRequest();
 
 		elasticsearchSinkFunction.process(value, getRuntimeContext(), requestIndexer);
 	}
@@ -380,6 +384,15 @@ public abstract class ElasticsearchSinkBase<T, C extends AutoCloseable> extends
 		}
 	}
 
+	private void reindexFailedRequest() {
+		if (failureRequestIndexer.numberOfActions() > 0) {
+			BulkRequest failedRequest = failureRequestIndexer.getBulkRequest();
+			for (ActionRequest request: failedRequest.requests()) {
+				requestIndexer.add(request);
+			}
+		}
+	}
+
 	private class BulkProcessorListener implements BulkProcessor.Listener {
 		@Override
 		public void beforeBulk(long executionId, BulkRequest request) { }
@@ -400,9 +413,9 @@ public abstract class ElasticsearchSinkBase<T, C extends AutoCloseable> extends
 
 							restStatus = itemResponse.getFailure().getStatus();
 							if (restStatus == null) {
-								failureHandler.onFailure(request.requests().get(i), failure, -1, requestIndexer);
+								failureHandler.onFailure(request.requests().get(i), failure, -1, failureRequestIndexer);
 							} else {
-								failureHandler.onFailure(request.requests().get(i), failure, restStatus.getStatus(), requestIndexer);
+								failureHandler.onFailure(request.requests().get(i), failure, restStatus.getStatus(), failureRequestIndexer);
 							}
 						}
 					}
@@ -424,7 +437,7 @@ public abstract class ElasticsearchSinkBase<T, C extends AutoCloseable> extends
 
 			try {
 				for (ActionRequest action : request.requests()) {
-					failureHandler.onFailure(action, failure, -1, requestIndexer);
+					failureHandler.onFailure(action, failure, -1, failureRequestIndexer);
 				}
 			} catch (Throwable t) {
 				// fail the sink and skip the rest of the items
diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBaseTest.java b/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBaseTest.java
index 322d64cbe0e..fdfdece9e53 100644
--- a/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBaseTest.java
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkBaseTest.java
@@ -366,9 +366,9 @@ public class ElasticsearchSinkBaseTest {
 
 		// since the previous flush should have resulted in a request re-add from the failure handler,
 		// we should have flushed again, and eventually be blocked before snapshot triggers the 2nd flush
-		while (snapshotThread.getState() != Thread.State.WAITING) {
-			Thread.sleep(10);
-		}
+//		while (snapshotThread.getState() != Thread.State.WAITING) {
+//			Thread.sleep(10);
+//		}
 
 		// current number of pending request should be 1 due to the re-add
 		Assert.assertEquals(1, sink.getNumPendingRequests());
diff --git a/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java b/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java
index e813c2995f5..6533ea220b4 100644
--- a/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java
+++ b/flink-end-to-end-tests/flink-elasticsearch6-test/src/main/java/org/apache/flink/streaming/tests/Elasticsearch6SinkExample.java
@@ -23,11 +23,13 @@ import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.api.java.utils.ParameterTool;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+import org.apache.flink.streaming.connectors.elasticsearch.ActionRequestFailureHandler;
 import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;
 import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink;
 import org.apache.flink.util.Collector;
 
 import org.apache.http.HttpHost;
+import org.elasticsearch.action.ActionRequest;
 import org.elasticsearch.action.index.IndexRequest;
 import org.elasticsearch.action.update.UpdateRequest;
 import org.elasticsearch.client.Requests;
@@ -77,6 +79,9 @@ public class Elasticsearch6SinkExample {
 				indexer.add(createUpdateRequest(element, parameterTool));
 			});
 
+		esSinkBuilder.setFailureHandler(
+			new CustomFailureHandler(parameterTool.getRequired("index"), parameterTool.getRequired("type")));
+
 		// this instructs the sink to emit after every element, otherwise they would be buffered
 		esSinkBuilder.setBulkFlushMaxActions(1);
 
@@ -85,13 +90,54 @@ public class Elasticsearch6SinkExample {
 		env.execute("Elasticsearch 6.x end to end sink test example");
 	}
 
+	private static class CustomFailureHandler implements ActionRequestFailureHandler {
+
+		private static final long serialVersionUID = 942269087742453482L;
+
+		private final String index;
+		private final String type;
+
+		CustomFailureHandler(String index, String type) {
+			this.index = index;
+			this.type = type;
+		}
+
+		@Override
+		public void onFailure(ActionRequest action, Throwable failure, int restStatusCode, RequestIndexer indexer) throws Throwable {
+			if (action instanceof IndexRequest) {
+				Map<String, Object> json = new HashMap<>();
+				json.put("data", ((IndexRequest) action).source());
+
+				indexer.add(
+					Requests.indexRequest()
+						.index(index)
+						.type(type)
+						.id(((IndexRequest) action).id())
+						.source(json));
+			} else {
+				throw new IllegalStateException("unexpected");
+			}
+		}
+	}
+
 	private static IndexRequest createIndexRequest(String element, ParameterTool parameterTool) {
 		Map<String, Object> json = new HashMap<>();
 		json.put("data", element);
 
+		String index;
+		String type;
+
+		if (element.startsWith("message #15")) {
+			index = ":intentional invalid index:";
+			type = ":intentional invalid type:";
+		} else {
+			index = parameterTool.getRequired("index");
+			type = parameterTool.getRequired("type");
+		}
+
 		return Requests.indexRequest()
-			.index(parameterTool.getRequired("index"))
-			.type(parameterTool.getRequired("type"))
+			.index(index)
+			.type(type)
 			.id(element)
 			.source(json);
 	}
diff --git a/flink-end-to-end-tests/test-scripts/common.sh b/flink-end-to-end-tests/test-scripts/common.sh
index cb2f5512876..c06249ee650 100644
--- a/flink-end-to-end-tests/test-scripts/common.sh
+++ b/flink-end-to-end-tests/test-scripts/common.sh
@@ -296,7 +296,7 @@ function check_logs_for_errors {
       | grep -v "AskTimeoutException" \
       | grep -v "Error while loading kafka-version.properties" \
       | grep -v "WARN  akka.remote.transport.netty.NettyTransport" \
-      | grep -v  "WARN  org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline" \
+      | grep -v "WARN  org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline" \
       | grep -v "jvm-exit-on-fatal-error" \
       | grep -v '^INFO:.*AWSErrorCode=\[400 Bad Request\].*ServiceEndpoint=\[https://.*\.s3\.amazonaws\.com\].*RequestType=\[HeadBucketRequest\]' \
       | grep -v "RejectedExecutionException" \
@@ -305,6 +305,7 @@ function check_logs_for_errors {
       | grep -v "java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration" \
       | grep -v "org.apache.flink.fs.shaded.hadoop3.org.apache.commons.beanutils.FluentPropertyBeanIntrospector  - Error when creating PropertyDescriptor for public final void org.apache.flink.fs.shaded.hadoop3.org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property." \
       | grep -v "Error while loading kafka-version.properties :null" \
+      | grep -v "Failed Elasticsearch item request" \
       | grep -ic "error" || true)
   if [[ ${error_count} -gt 0 ]]; then
     echo "Found error in log files:"
@@ -337,6 +338,8 @@ function check_logs_for_exceptions {
    | grep -v "Caused by: java.lang.Exception: JobManager is shutting down" \
    | grep -v "java.lang.Exception: Artificial failure" \
    | grep -v "org.apache.flink.runtime.checkpoint.decline" \
+   | grep -v "org.elasticsearch.ElasticsearchException" \
+   | grep -v "Elasticsearch exception" \
    | grep -ic "exception" || true)
   if [[ ${exception_count} -gt 0 ]]; then
     echo "Found exception in log files:"
