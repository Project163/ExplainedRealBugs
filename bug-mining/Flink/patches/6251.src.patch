diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AIMDRateLimitingStrategy.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AIMDRateLimitingStrategy.java
new file mode 100644
index 00000000000..dc6819c5827
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AIMDRateLimitingStrategy.java
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.util.Preconditions;
+
+/**
+ * Additive Increase/Multiplicative Decrease implementation of throttling Strategy This
+ * implementation is not thread safe.
+ *
+ * <p>This Strategy is used by the writer to implement rate limiting on request thoroughput to match
+ * throttled destinations.
+ */
+@Internal
+public final class AIMDRateLimitingStrategy {
+    private final int increaseRate;
+    private final double decreaseFactor;
+    private final int rateThreshold;
+
+    private int inFlightMessages;
+
+    /**
+     * @param increaseRate Linear increase value of rate limit on each acknowledgement.
+     * @param decreaseFactor Exponential decrease factor of rate limit on each failure.
+     * @param rateThreshold Threshold for maximum value of rate limit, this can be enforced due to
+     *     writer or destination specific limits.
+     * @param initialRate Initial rate limit to start with.
+     */
+    public AIMDRateLimitingStrategy(
+            int increaseRate, double decreaseFactor, int rateThreshold, int initialRate) {
+        Preconditions.checkArgument(
+                decreaseFactor < 1.0 && decreaseFactor > 0.0,
+                "Decrease factor must be between 0.0 and 1.0.");
+        Preconditions.checkArgument(increaseRate > 0, "Increase rate must be positive integer.");
+        Preconditions.checkArgument(
+                rateThreshold >= initialRate, "Initial rate must not exceed threshold.");
+
+        this.increaseRate = increaseRate;
+        this.decreaseFactor = decreaseFactor;
+        this.rateThreshold = rateThreshold;
+        this.inFlightMessages = initialRate;
+    }
+
+    public int getRateLimit() {
+        return inFlightMessages;
+    }
+
+    public void scaleUp() {
+        inFlightMessages = (Math.min(inFlightMessages + increaseRate, rateThreshold));
+    }
+
+    public void scaleDown() {
+        inFlightMessages = Math.max(1, (int) Math.round(inFlightMessages * decreaseFactor));
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java
index 6d34690c578..bb9da6d4a57 100644
--- a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java
@@ -53,6 +53,9 @@ import java.util.function.Consumer;
 public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable>
         implements StatefulSink.StatefulSinkWriter<InputT, BufferedRequestState<RequestEntryT>> {
 
+    private static final int INFLIGHT_MESSAGES_LIMIT_INCREASE_RATE = 10;
+    private static final double INFLIGHT_MESSAGES_LIMIT_DECREASE_FACTOR = 0.5;
+
     private final MailboxExecutor mailboxExecutor;
     private final ProcessingTimeService timeService;
 
@@ -71,6 +74,19 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
     /* Counter for number of records this sink has attempted to send to the destination. */
     private final Counter numRecordsOutCounter;
 
+    /**
+     * Rate limiting strategy {@code inflightMessages} at any given time, {@code
+     * rateLimitingStrategy.getRateLimit()} is used to adjust the sink's throughput not to exceed
+     * destination's throttle rate.
+     *
+     * <p>throttled requests should update limit by calling {@code rateLimitingStrategy.scaleDown()}
+     * and successful requests should update by calling {@code rateLimitingStrategy.scaleUp()}
+     *
+     * <p>Failure of throttled request decreases limit resulting in yielding on fewer number of
+     * messages.
+     */
+    private final AIMDRateLimitingStrategy rateLimitingStrategy;
+
     private final int maxBatchSize;
     private final int maxInFlightRequests;
     private final int maxBufferedRequests;
@@ -118,6 +134,16 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
      */
     private int inFlightRequestsCount;
 
+    /**
+     * Tracks number of messages (request entries) in the inflight requests. This variable is used
+     * to control rate of outbound messages flow as {@code inFlightMessages} should not exceed
+     * {@code rateLimitingStrategy}.
+     *
+     * <p>{@code inFlightMessages} should also be consistent with {@code inFlightRequestsCount}
+     * where {@code inFlightMessages} should never exceed {@code inFlightRequestsCount} at any time.
+     */
+    private int inFlightMessages;
+
     /**
      * Tracks the cumulative size of all elements in {@code bufferedRequestEntries} to facilitate
      * the criterion for flushing after {@code maxBatchSizeInBytes} is reached.
@@ -259,6 +285,14 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
         this.inFlightRequestsCount = 0;
         this.bufferedRequestEntriesTotalSizeInBytes = 0;
 
+        this.inFlightMessages = 0;
+        this.rateLimitingStrategy =
+                new AIMDRateLimitingStrategy(
+                        INFLIGHT_MESSAGES_LIMIT_INCREASE_RATE,
+                        INFLIGHT_MESSAGES_LIMIT_DECREASE_FACTOR,
+                        maxBatchSize * maxInFlightRequests,
+                        maxBatchSize * maxInFlightRequests);
+
         this.metrics = context.metricGroup();
         this.metrics.setCurrentSendTimeGauge(() -> this.ackTime - this.lastSendTimestamp);
         this.numBytesOutCounter = this.metrics.getIOMetricGroup().getNumBytesOutCounter();
@@ -299,7 +333,7 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
     }
 
     private void flushIfAble() {
-        while (bufferedRequestEntries.size() >= maxBatchSize
+        while (bufferedRequestEntries.size() >= getNextBatchSizeLimit()
                 || bufferedRequestEntriesTotalSizeInBytes >= maxBatchSizeInBytes) {
             flush();
         }
@@ -312,11 +346,13 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
      * <p>The method blocks if too many async requests are in flight.
      */
     private void flush() {
-        while (inFlightRequestsCount >= maxInFlightRequests) {
+        while (inFlightRequestsCount >= maxInFlightRequests
+                || inFlightMessages >= rateLimitingStrategy.getRateLimit()) {
             mailboxExecutor.tryYield();
         }
 
         List<RequestEntryT> batch = createNextAvailableBatch();
+        int batchSize = batch.size();
 
         if (batch.size() == 0) {
             return;
@@ -326,11 +362,16 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
         Consumer<List<RequestEntryT>> requestResult =
                 failedRequestEntries ->
                         mailboxExecutor.execute(
-                                () -> completeRequest(failedRequestEntries, timestampOfRequest),
+                                () ->
+                                        completeRequest(
+                                                failedRequestEntries,
+                                                batchSize,
+                                                timestampOfRequest),
                                 "Mark in-flight request as completed and requeue %d request entries",
                                 failedRequestEntries.size());
 
         inFlightRequestsCount++;
+        inFlightMessages += batchSize;
         submitRequestEntries(batch, requestResult);
     }
 
@@ -339,7 +380,7 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
      * {@code maxBatchSizeInBytes}. Also adds these to the metrics counters.
      */
     private List<RequestEntryT> createNextAvailableBatch() {
-        int batchSize = Math.min(maxBatchSize, bufferedRequestEntries.size());
+        int batchSize = Math.min(getNextBatchSizeLimit(), bufferedRequestEntries.size());
         List<RequestEntryT> batch = new ArrayList<>(batchSize);
 
         int batchSizeBytes = 0;
@@ -366,10 +407,16 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
      *
      * @param failedRequestEntries requestEntries that need to be retried
      */
-    private void completeRequest(List<RequestEntryT> failedRequestEntries, long requestStartTime) {
+    private void completeRequest(
+            List<RequestEntryT> failedRequestEntries, int batchSize, long requestStartTime) {
         lastSendTimestamp = requestStartTime;
         ackTime = System.currentTimeMillis();
+
         inFlightRequestsCount--;
+        inFlightMessages -= batchSize;
+
+        updateInFlightMessagesLimit(failedRequestEntries.size() == 0);
+
         ListIterator<RequestEntryT> iterator =
                 failedRequestEntries.listIterator(failedRequestEntries.size());
         while (iterator.hasPrevious()) {
@@ -377,6 +424,14 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
         }
     }
 
+    private void updateInFlightMessagesLimit(boolean isSuccessfulRequest) {
+        if (isSuccessfulRequest) {
+            rateLimitingStrategy.scaleUp();
+        } else {
+            rateLimitingStrategy.scaleDown();
+        }
+    }
+
     private void addEntryToBuffer(RequestEntryT entry, boolean insertAtHead) {
         if (bufferedRequestEntries.isEmpty() && !existsActiveTimerCallback) {
             registerCallback();
@@ -454,6 +509,10 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
     @Override
     public void close() {}
 
+    private int getNextBatchSizeLimit() {
+        return Math.min(maxBatchSize, rateLimitingStrategy.getRateLimit());
+    }
+
     protected Consumer<Exception> getFatalExceptionCons() {
         return fatalExceptionCons;
     }
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AIMDRateLimitingStrategyTest.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AIMDRateLimitingStrategyTest.java
new file mode 100644
index 00000000000..272a9d6084a
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AIMDRateLimitingStrategyTest.java
@@ -0,0 +1,113 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import org.junit.Test;
+
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
+
+/** Unit tests for {@link AIMDRateLimitingStrategy}. */
+public class AIMDRateLimitingStrategyTest {
+    private static final int INITIAL_RATE = 32;
+    private static final int INCREASE_RATE = 10;
+    private static final int THRESHOLD = 100;
+    private static final double DECREASE_RATE = 0.5;
+
+    @Test
+    public void testInitialRateIsSetByConstructor() {
+        AIMDRateLimitingStrategy rateLimitingStrategy =
+                new AIMDRateLimitingStrategy(INCREASE_RATE, DECREASE_RATE, THRESHOLD, INITIAL_RATE);
+        assertThat(rateLimitingStrategy.getRateLimit()).isEqualTo(INITIAL_RATE);
+    }
+
+    @Test
+    public void testAcknowledgedRequestsIncreaseLinearly() {
+        AIMDRateLimitingStrategy rateLimitingStrategy =
+                new AIMDRateLimitingStrategy(INCREASE_RATE, DECREASE_RATE, THRESHOLD, INITIAL_RATE);
+
+        int numberOfAcks = 5;
+        updateStrategyWithAcks(rateLimitingStrategy, numberOfAcks);
+
+        assertThat(rateLimitingStrategy.getRateLimit())
+                .isEqualTo(INITIAL_RATE + numberOfAcks * INCREASE_RATE);
+    }
+
+    @Test
+    public void testFailedRequestsDecreaseExponentially() {
+        AIMDRateLimitingStrategy rateLimitingStrategy =
+                new AIMDRateLimitingStrategy(INCREASE_RATE, DECREASE_RATE, THRESHOLD, INITIAL_RATE);
+        int numberOfFailures = 5;
+        int rate = rateLimitingStrategy.getRateLimit();
+
+        for (int i = 1; i < numberOfFailures; i++) {
+            rateLimitingStrategy.scaleDown();
+
+            assertThat(rateLimitingStrategy.getRateLimit())
+                    .isEqualTo(decreaseRateWithFactor(rate, DECREASE_RATE));
+
+            rate = decreaseRateWithFactor(rate, DECREASE_RATE);
+        }
+    }
+
+    @Test
+    public void testIncreaseRateNeverExceedsThreshold() {
+        AIMDRateLimitingStrategy rateLimitingStrategy =
+                new AIMDRateLimitingStrategy(INCREASE_RATE, DECREASE_RATE, THRESHOLD, INITIAL_RATE);
+
+        int numberOfAcks = THRESHOLD / INCREASE_RATE + 1;
+        updateStrategyWithAcks(rateLimitingStrategy, numberOfAcks);
+
+        assertThat(rateLimitingStrategy.getRateLimit()).isEqualTo(THRESHOLD);
+    }
+
+    @Test
+    public void testFailureOnInitialBiggerThanThreshold() {
+        assertThatExceptionOfType(IllegalArgumentException.class)
+                .isThrownBy(() -> new AIMDRateLimitingStrategy(10, 0.5, 10, 11))
+                .withMessageContaining("Initial rate must not exceed threshold");
+    }
+
+    @Test
+    public void testFailureOnInvalidDecreaseFactor() {
+        double badDecreaseFactor = 1.5;
+        assertThatExceptionOfType(IllegalArgumentException.class)
+                .isThrownBy(() -> new AIMDRateLimitingStrategy(10, badDecreaseFactor, 100, 11))
+                .withMessageContaining("Decrease factor must be between 0.0 and 1.0");
+    }
+
+    @Test
+    public void testFailureOnInvalidIncreaseRate() {
+        int badIncreaseRate = -15;
+        assertThatExceptionOfType(IllegalArgumentException.class)
+                .isThrownBy(() -> new AIMDRateLimitingStrategy(badIncreaseRate, 0.5, 100, 11))
+                .withMessageContaining("Increase rate must be positive integer.");
+    }
+
+    private void updateStrategyWithAcks(
+            AIMDRateLimitingStrategy rateLimitingStrategy, int numberOfAcks) {
+        for (int i = 0; i < numberOfAcks; i++) {
+            rateLimitingStrategy.scaleUp();
+        }
+    }
+
+    private int decreaseRateWithFactor(int rate, double factor) {
+        return Math.max((int) Math.round(rate * factor), 1);
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java
index 904743dc74b..bbb649d57a5 100644
--- a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java
@@ -249,36 +249,50 @@ public class AsyncSinkWriterTest {
         /*
          * Writing 955 to the sink increases the buffer to size 3 containing [75, 95, 955]. This
          * triggers the outstanding in flight request with the failed 965 to be run, and 965 is
-         * placed at the front of the queue. The first {@code maxBatchSize = 3} elements are
-         * persisted, with 965 succeeding this (second) time. 955 remains in the buffer.
+         * placed at the front of the queue. The failure throttles down {@code maxBatchSize} to 1.
+         * buffer now should be [965, 75, 95, 955]
+         * A new batch containing 965 is then sent, success causes {@code maxBatchSize} to go up
+         * to 3 again.
+         * next batch is then created of all requests, 75 and 95 are also persisted.
+         * 955 is in flight after failure.
          */
         writeXToSinkAssertDestinationIsInStateYAndBufferHasZ(
-                sink, "955", Arrays.asList(25, 55, 965, 75, 95), Arrays.asList(955));
+                sink, "955", Arrays.asList(25, 55, 965, 75, 95), Arrays.asList());
 
         writeXToSinkAssertDestinationIsInStateYAndBufferHasZ(
-                sink, "550", Arrays.asList(25, 55, 965, 75, 95), Arrays.asList(955, 550));
+                sink, "550", Arrays.asList(25, 55, 965, 75, 95), Arrays.asList(550));
 
         /*
-         * [955, 550, 45] are attempted to be persisted
+         * [550, 45] are attempted to be persisted
          */
         writeXToSinkAssertDestinationIsInStateYAndBufferHasZ(
-                sink, "45", Arrays.asList(25, 55, 965, 75, 95, 45), Arrays.asList());
+                sink, "45", Arrays.asList(25, 55, 965, 75, 95), Arrays.asList(550, 45));
 
+        /*
+         * [550,45,35] triggers inflight request to be added, buffer should be [955,550,45,35]
+         * batch size is reduced to 1.
+         * Next request would contain only [995] which is persisted,
+         * success causes batch size to rise again to 3. next batch is now [550,45,35].
+         * All are persisted and batch size is 3.
+         */
         writeXToSinkAssertDestinationIsInStateYAndBufferHasZ(
-                sink, "35", Arrays.asList(25, 55, 965, 75, 95, 45), Arrays.asList(35));
+                sink, "35", Arrays.asList(25, 55, 965, 75, 95, 955, 550, 45, 35), Arrays.asList());
 
-        /* [35, 535] should be in the bufferedRequestEntries
-         * [955, 550] should be in the inFlightRequest, ready to be added
-         * [25, 55, 965, 75, 95, 45] should be downstream already
+        /* ] should be in the bufferedRequestEntries
+         * [ 550] should be in the inFlightRequest, ready to be added
+         * [25, 55, 965, 75, 95, 995, 45, 35] should be downstream already
          */
         writeXToSinkAssertDestinationIsInStateYAndBufferHasZ(
-                sink, "535", Arrays.asList(25, 55, 965, 75, 95, 45), Arrays.asList(35, 535));
+                sink,
+                "535",
+                Arrays.asList(25, 55, 965, 75, 95, 955, 550, 45, 35),
+                Arrays.asList(535));
 
         // Checkpoint occurs
         sink.flush(true);
 
         // Everything is saved
-        assertEquals(Arrays.asList(25, 55, 965, 75, 95, 45, 955, 550, 35, 535), res);
+        assertEquals(Arrays.asList(25, 55, 965, 75, 95, 955, 550, 45, 35, 535), res);
         assertEquals(0, getWriterState(sink).getStateSize());
     }
 
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterThrottlingTest.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterThrottlingTest.java
new file mode 100644
index 00000000000..639cafe6d05
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterThrottlingTest.java
@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import org.apache.flink.api.common.operators.ProcessingTimeService;
+import org.apache.flink.api.connector.sink2.Sink;
+import org.apache.flink.api.java.tuple.Tuple2;
+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;
+
+import org.assertj.core.api.Assertions;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.util.ArrayDeque;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Queue;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+import java.util.stream.LongStream;
+
+/** Test class for rate limiting functionalities of {@link AsyncSinkWriter}. */
+public class AsyncSinkWriterThrottlingTest {
+
+    @Test
+    public void testSinkThroughputShouldThrottleToHalfBatchSize() throws Exception {
+        int maxBatchSize = 32;
+        int maxInFlightRequest = 10;
+        int numberOfBatchesToSend = 1000;
+        Queue<String> testRequests = getTestRequestsBuffer();
+
+        TestSinkInitContext context = new TestSinkInitContext();
+        TestProcessingTimeService tpts = context.getTestProcessingTimeService();
+
+        ThrottlingWriter writer =
+                new ThrottlingWriter(
+                        (elem, ctx) -> Long.valueOf(elem),
+                        context,
+                        maxBatchSize,
+                        maxInFlightRequest);
+
+        long currentTime = 0L;
+        tpts.setCurrentTime(currentTime);
+
+        // numberOfBatchesToSend should be high enough to overcome initial transient state
+        for (int i = 0; i < numberOfBatchesToSend; i++) {
+            removeBatchAndSend(writer, testRequests, maxBatchSize);
+            tpts.setCurrentTime(currentTime + 50);
+            currentTime += 50L;
+        }
+
+        /**
+         * Throttling limit should be maxBatchSize/2 , worst case margin on throttling (maxBatchSize
+         * / 2 + 1)->(maxBatchSize/4) or when scaling up (maxBatchSize/2) -> (maxBatchSize/2 + 10).
+         */
+        Assertions.assertThat(writer.getInflightMessagesLimit())
+                .isGreaterThanOrEqualTo(maxBatchSize / 4);
+        Assertions.assertThat(writer.getInflightMessagesLimit())
+                .isLessThanOrEqualTo(maxBatchSize / 2 + 10);
+    }
+
+    private Queue<String> getTestRequestsBuffer() {
+        return LongStream.range(1, 1000_000L)
+                .mapToObj(Long::toString)
+                .collect(Collectors.toCollection(ArrayDeque::new));
+    }
+
+    private void removeBatchAndSend(ThrottlingWriter writer, Queue<String> buffer, int batchSize)
+            throws IOException, InterruptedException {
+        for (int i = 0; i < Math.min(batchSize, buffer.size()); ++i) {
+            writer.write(buffer.remove());
+        }
+    }
+
+    private static class ThrottlingWriter extends AsyncSinkWriter<String, Long> {
+
+        private final ProcessingTimeService timeService;
+        private final int maxBatchSize;
+        private final Queue<Tuple2<Long, Integer>> requestsData;
+        private long sizeOfLast100ms;
+        private int inflightMessagesLimit;
+
+        public ThrottlingWriter(
+                ElementConverter<String, Long> elementConverter,
+                Sink.InitContext context,
+                int maxBatchSize,
+                int maxInFlightRequests) {
+            super(
+                    elementConverter,
+                    context,
+                    maxBatchSize,
+                    maxInFlightRequests,
+                    10_000,
+                    10_000,
+                    100,
+                    1000);
+            this.maxBatchSize = maxBatchSize;
+            this.timeService = context.getProcessingTimeService();
+            this.requestsData = new ArrayDeque<>();
+            this.inflightMessagesLimit = maxBatchSize;
+            this.sizeOfLast100ms = 0;
+        }
+
+        public void write(String element) throws IOException, InterruptedException {
+            super.write(element, null);
+        }
+
+        public int getInflightMessagesLimit() {
+            return inflightMessagesLimit;
+        }
+
+        @Override
+        protected void submitRequestEntries(
+                List<Long> requestEntries, Consumer<List<Long>> requestResult) {
+            long currentProcessingTime = timeService.getCurrentProcessingTime();
+            inflightMessagesLimit = requestEntries.size();
+
+            addRequestDataToQueue(requestEntries.size(), currentProcessingTime);
+
+            if (sizeOfLast100ms > maxBatchSize && requestEntries.size() > 1) {
+                requestResult.accept(requestEntries);
+            } else {
+                requestResult.accept(new ArrayList<>());
+            }
+        }
+
+        @Override
+        protected long getSizeInBytes(Long requestEntry) {
+            return 8;
+        }
+
+        private void addRequestDataToQueue(int size, long time) {
+            requestsData.add(Tuple2.of(time, size));
+
+            sizeOfLast100ms += size;
+            while (!requestsData.isEmpty() && requestsData.peek().f0 < time - 100L) {
+                sizeOfLast100ms -= requestsData.remove().f1;
+            }
+        }
+    }
+}
