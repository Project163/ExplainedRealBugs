diff --git a/docs/dev/table/functions/udfs.md b/docs/dev/table/functions/udfs.md
index 805f3379ec5..01598777a0b 100644
--- a/docs/dev/table/functions/udfs.md
+++ b/docs/dev/table/functions/udfs.md
@@ -547,6 +547,25 @@ public static class LiteralFunction extends ScalarFunction {
 
 </div>
 
+### Determinism
+
+Every user-defined function class can declare whether it produces deterministic results or not by overriding
+the `isDeterministic()` method. If the function is not purely functional (like `random()`, `date()`, or `now()`),
+the method must return `false`. By default, `isDeterministic()` returns `true`.
+
+Furthermore, the `isDeterministic()` method might also influence the runtime behavior. A runtime
+implementation might be called at two different stages:
+
+**During planning (i.e. pre-flight phase)**: If a function is called with constant expressions
+or constant expressions can be derived from the given statement, a function is pre-evaluated
+for constant expression reduction and might not be executed on the cluster anymore. Unless
+`isDeterministic()` is used to disable constant expression reduction in this case. For example,
+the following calls to `ABS` are executed during planning: `SELECT ABS(-1) FROM t` and
+`SELECT ABS(field) FROM t WHERE field = -1`; whereas `SELECT ABS(field) FROM t` is not.
+
+**During runtime (i.e. cluster execution)**: If a function is called with non-constant expressions
+or `isDeterministic()` returns `false`.
+
 ### Runtime Integration
 
 Sometimes it might be necessary for a user-defined function to get global runtime information or do some setup/clean-up work before the actual work. User-defined functions provide `open()` and `close()` methods that can be overridden and provide similar functionality as the methods in `RichFunction` of DataStream API.
@@ -557,11 +576,15 @@ The `open()` method provides a `FunctionContext` that contains information about
 
 The following information can be obtained by calling the corresponding methods of `FunctionContext`:
 
-| Method                                | Description                                            |
-| :------------------------------------ | :----------------------------------------------------- |
-| `getMetricGroup()`                    | Metric group for this parallel subtask.                |
-| `getCachedFile(name)`                 | Local temporary file copy of a distributed cache file. |
-| `getJobParameter(name, defaultValue)` | Global job parameter value associated with given key.  |
+| Method                                   | Description                                                             |
+| :--------------------------------------- | :---------------------------------------------------------------------- |
+| `getMetricGroup()`                       | Metric group for this parallel subtask.                                 |
+| `getCachedFile(name)`                    | Local temporary file copy of a distributed cache file.                  |
+| `getJobParameter(name, defaultValue)`    | Global job parameter value associated with given key.                   |
+| `getExternalResourceInfos(resourceName)` | Returns a set of external resource infos associated with the given key. |
+
+**Note**: Depending on the context in which the function is executed, not all methods from above might be available. For example,
+during constant expression reduction adding a metric is a no-op operation.
 
 The following example snippet shows how to use `FunctionContext` in a scalar function for accessing a global job parameter:
 
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/ConstantFunctionContext.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/ConstantFunctionContext.java
new file mode 100644
index 00000000000..4efe9173c5d
--- /dev/null
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/ConstantFunctionContext.java
@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.functions;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.api.common.externalresource.ExternalResourceInfo;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.PipelineOptions;
+import org.apache.flink.metrics.MetricGroup;
+import org.apache.flink.metrics.groups.UnregisteredMetricsGroup;
+import org.apache.flink.table.api.TableException;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.File;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+
+/**
+ * A {@link FunctionContext} for constant expression reduction. It is used when a function is called
+ * with constant expressions or constant expressions can be derived from the given statement.
+ *
+ * <p>Since constant expression reduction happens during planning, methods that reference Flink's runtime
+ * context are not available.
+ *
+ * @see FunctionDefinition#isDeterministic()
+ */
+@Internal
+public final class ConstantFunctionContext extends FunctionContext {
+
+	private static final Logger LOG = LoggerFactory.getLogger(ConstantFunctionContext.class);
+
+	private static final UnregisteredMetricsGroup metricsGroup = new UnregisteredMetricsGroup();
+
+	private final Map<String, String> jobParameters;
+
+	public ConstantFunctionContext(Configuration configuration) {
+		super(null);
+		this.jobParameters = configuration.getOptional(PipelineOptions.GLOBAL_JOB_PARAMETERS)
+			.map(HashMap::new)
+			.orElseGet(HashMap::new);
+	}
+
+	@Override
+	public MetricGroup getMetricGroup() {
+		LOG.warn(
+			"Calls to FunctionContext.getMetricGroup will have no effect during constant expression reduction.");
+		return metricsGroup;
+	}
+
+	@Override
+	public File getCachedFile(String name) {
+		throw new TableException(
+			"Calls to FunctionContext.getCachedFile are not available during constant expression reduction.");
+	}
+
+	@Override
+	public String getJobParameter(String key, String defaultValue) {
+		return jobParameters.getOrDefault(key, defaultValue);
+	}
+
+	@Override
+	public Set<ExternalResourceInfo> getExternalResourceInfos(String resourceName) {
+		throw new TableException(
+			"Calls to FunctionContext.getExternalResourceInfos are not available during constant expression reduction.");
+	}
+}
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionContext.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionContext.java
index 18a2dbcbbbb..1f101cf1eca 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionContext.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionContext.java
@@ -77,11 +77,10 @@ public class FunctionContext {
 	 */
 	public String getJobParameter(String key, String defaultValue) {
 		final GlobalJobParameters conf = context.getExecutionConfig().getGlobalJobParameters();
-		if (conf != null && conf.toMap().containsKey(key)) {
-			return conf.toMap().get(key);
-		} else {
-			return defaultValue;
+		if (conf != null) {
+			return conf.toMap().getOrDefault(key, defaultValue);
 		}
+		return defaultValue;
 	}
 
 	/**
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionDefinition.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionDefinition.java
index 44f1c9da86a..e933c5fb8e2 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionDefinition.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/FunctionDefinition.java
@@ -68,8 +68,12 @@ public interface FunctionDefinition {
 	 *
 	 * <p>It returns <code>true</code> if and only if a call to this function is guaranteed to
 	 * always return the same result given the same parameters. <code>true</code> is
-	 * assumed by default. If the function is not pure functional like <code>random(), date(), now(), ...</code>
+	 * assumed by default. If the function is not purely functional like <code>random(), date(), now(), ...</code>
 	 * this method must return <code>false</code>.
+	 *
+	 * <p>Furthermore, return <code>false</code> if the planner should always execute this function
+	 * on the cluster side. In other words: the planner should not perform constant expression reduction
+	 * during planning for constant calls to this function.
 	 */
 	default boolean isDeterministic() {
 		return true;
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/UserDefinedFunction.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/UserDefinedFunction.java
index 48be28dd00d..4c4a9ca2f85 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/UserDefinedFunction.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/UserDefinedFunction.java
@@ -32,7 +32,19 @@ import java.io.Serializable;
  * Base class for all user-defined functions.
  *
  * <p>User-defined functions combine the logical definition of a function for validation and planning
- * and contain a corresponding runtime implementation.
+ * (see {@link FunctionDefinition}) and contain a corresponding runtime implementation.
+ *
+ * <p>A runtime implementation might be called at two different stages:
+ * <ul>
+ *     <li>During planning (i.e. pre-flight phase): If a function is called with constant expressions
+ *     or constant expressions can be derived from the given statement, a function is pre-evaluated
+ *     for constant expression reduction and might not be executed on the cluster anymore. Use
+ *     {@link #isDeterministic()} to disable constant expression reduction in this case. For example,
+ *     the following calls to {@code ABS} are executed during planning:
+ *     {@code SELECT ABS(-1) FROM t} and {@code SELECT ABS(field) FROM t WHERE field = -1}.
+ *     <li>During runtime (i.e. cluster execution): If a function is called with non-constant expressions
+ *     or {@link #isDeterministic()} returns false.
+ * </ul>
  *
  * @see ScalarFunction
  * @see TableFunction
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/ExpressionReducer.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/ExpressionReducer.scala
index bf445684679..166011f1361 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/ExpressionReducer.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/ExpressionReducer.scala
@@ -19,15 +19,14 @@
 package org.apache.flink.table.planner.codegen
 
 import org.apache.flink.api.common.functions.{MapFunction, RichMapFunction}
-import org.apache.flink.configuration.Configuration
-import org.apache.flink.metrics.MetricGroup
 import org.apache.flink.table.api.{TableConfig, TableException}
 import org.apache.flink.table.data.binary.{BinaryStringData, BinaryStringDataUtil}
 import org.apache.flink.table.data.{DecimalData, GenericRowData, TimestampData}
-import org.apache.flink.table.functions.{FunctionContext, UserDefinedFunction}
+import org.apache.flink.table.functions.{ConstantFunctionContext, FunctionContext, UserDefinedFunction}
 import org.apache.flink.table.planner.calcite.FlinkTypeFactory
 import org.apache.flink.table.planner.codegen.FunctionCodeGenerator.generateFunction
 import org.apache.flink.table.planner.plan.utils.PythonUtil.containsPythonCall
+import org.apache.flink.table.planner.utils.Logging
 import org.apache.flink.table.types.DataType
 import org.apache.flink.table.types.logical.RowType
 import org.apache.flink.table.util.TimestampStringUtils.fromLocalDateTime
@@ -36,8 +35,6 @@ import org.apache.calcite.avatica.util.ByteString
 import org.apache.calcite.rex.{RexBuilder, RexExecutor, RexNode}
 import org.apache.calcite.sql.`type`.SqlTypeName
 
-import java.io.File
-
 import scala.collection.JavaConverters._
 import scala.collection.mutable.ListBuffer
 
@@ -51,7 +48,8 @@ import scala.collection.mutable.ListBuffer
 class ExpressionReducer(
     config: TableConfig,
     allowChangeNullability: Boolean = false)
-  extends RexExecutor {
+  extends RexExecutor
+  with Logging {
 
   private val EMPTY_ROW_TYPE = RowType.of()
   private val EMPTY_ROW = new GenericRowData(0)
@@ -119,6 +117,16 @@ class ExpressionReducer(
       richMapFunction.open(parameters)
       // execute
       richMapFunction.map(EMPTY_ROW)
+    } catch { case t: Throwable =>
+      // maybe a function accesses some cluster specific context information
+      // skip the expression reduction and try it again during runtime
+      LOG.warn(
+        "Unable to perform constant expression reduction. " +
+          "An exception occurred during the evaluation. " +
+          "One or more expressions will be executed unreduced.",
+        t)
+      reducedValues.addAll(constExprs)
+      return
     } finally {
       richMapFunction.close()
     }
@@ -238,35 +246,6 @@ class ExpressionReducer(
   }
 }
 
-/**
-  * A [[ConstantFunctionContext]] allows to obtain user-defined configuration information set
-  * in [[TableConfig]].
-  *
-  * @param parameters User-defined configuration set in [[TableConfig]].
-  */
-class ConstantFunctionContext(parameters: Configuration) extends FunctionContext(null) {
-
-  override def getMetricGroup: MetricGroup = {
-    throw new UnsupportedOperationException("getMetricGroup is not supported when optimizing")
-  }
-
-  override def getCachedFile(name: String): File = {
-    throw new UnsupportedOperationException("getCachedFile is not supported when optimizing")
-  }
-
-  /**
-    * Gets the user-defined configuration value associated with the given key as a string.
-    *
-    * @param key          key pointing to the associated value
-    * @param defaultValue default value which is returned in case user-defined configuration
-    *                     value is null or there is no value associated with the given key
-    * @return (default) value associated with the given key
-    */
-  override def getJobParameter(key: String, defaultValue: String): String = {
-    parameters.getString(key, defaultValue)
-  }
-}
-
 /**
   * Constant expression code generator context.
   */
diff --git a/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.xml b/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.xml
index ced14c1a2ca..844ecaa832d 100644
--- a/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.xml
+++ b/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.xml
@@ -16,6 +16,24 @@ See the License for the specific language governing permissions and
 limitations under the License.
 -->
 <Root>
+  <TestCase name="testExpressionReductionWithPythonUDF">
+    <Resource name="sql">
+      <![CDATA[SELECT PyUdf(), MyUdf(1) FROM MyTable]]>
+    </Resource>
+    <Resource name="planBefore">
+      <![CDATA[
+LogicalProject(EXPR$0=[PyUdf()], EXPR$1=[MyUdf(1)])
++- LogicalTableScan(table=[[default_catalog, default_database, MyTable, source: [TestTableSource(a, b, c)]]])
+]]>
+    </Resource>
+    <Resource name="planAfter">
+      <![CDATA[
+Calc(select=[f0 AS EXPR$0, CAST(2) AS EXPR$1])
++- PythonCalc(select=[PyUdf() AS f0])
+   +- LegacyTableSourceScan(table=[[default_catalog, default_database, MyTable, source: [TestTableSource(a, b, c)]]], fields=[a, b, c])
+]]>
+    </Resource>
+  </TestCase>
   <TestCase name="testExpressionReductionWithUDF">
     <Resource name="sql">
       <![CDATA[SELECT MyUdf(1) FROM MyTable]]>
@@ -50,21 +68,20 @@ Calc(select=[11 AS EXPR$0])
 ]]>
     </Resource>
   </TestCase>
-  <TestCase name="testExpressionReductionWithPythonUDF">
+  <TestCase name="testExpressionReductionWithRichUDFAndInvalidOpen">
     <Resource name="sql">
-      <![CDATA[SELECT PyUdf(), MyUdf(1) FROM MyTable]]>
+      <![CDATA[SELECT myUdf(1 + 1) FROM MyTable]]>
     </Resource>
     <Resource name="planBefore">
       <![CDATA[
-LogicalProject(EXPR$0=[PyUdf()], EXPR$1=[MyUdf(1)])
+LogicalProject(EXPR$0=[myUdf(+(1, 1))])
 +- LogicalTableScan(table=[[default_catalog, default_database, MyTable, source: [TestTableSource(a, b, c)]]])
 ]]>
     </Resource>
     <Resource name="planAfter">
       <![CDATA[
-Calc(select=[f0 AS EXPR$0, CAST(2) AS EXPR$1])
-+- PythonCalc(select=[PyUdf() AS f0])
-   +- LegacyTableSourceScan(table=[[default_catalog, default_database, MyTable, source: [TestTableSource(a, b, c)]]], fields=[a, b, c])
+Calc(select=[myUdf(+(1, 1)) AS EXPR$0])
++- LegacyTableSourceScan(table=[[default_catalog, default_database, MyTable, source: [TestTableSource(a, b, c)]]], fields=[a, b, c])
 ]]>
     </Resource>
   </TestCase>
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/utils/userDefinedScalarFunctions.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/utils/userDefinedScalarFunctions.scala
index 319c6315cbe..8db4284482f 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/utils/userDefinedScalarFunctions.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/expressions/utils/userDefinedScalarFunctions.scala
@@ -211,6 +211,9 @@ class RichFunc1 extends ScalarFunction {
 
   override def open(context: FunctionContext): Unit = {
     added = context.getJobParameter("int.value", "0").toInt
+    if (context.getJobParameter("fail-for-cached-file", "false").toBoolean) {
+      context.getCachedFile("FAIL")
+    }
   }
 
   def eval(index: Int): Int = {
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.scala
index 58c92a3c5c8..435fa29ea3b 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/rules/logical/ExpressionReductionRulesTest.scala
@@ -44,10 +44,19 @@ class ExpressionReductionRulesTest extends TableTestBase {
   @Test
   def testExpressionReductionWithRichUDF(): Unit = {
     util.addFunction("MyUdf", new RichFunc1)
-    util.getTableEnv.getConfig.getConfiguration.setString("int.value", "10")
+    util.getTableEnv.getConfig.addJobParameter("int.value", "10")
     util.verifyPlan("SELECT myUdf(1) FROM MyTable")
   }
 
+  @Test
+  def testExpressionReductionWithRichUDFAndInvalidOpen(): Unit = {
+    util.addFunction("MyUdf", new RichFunc1)
+    // FunctionContext.getCachedFile will fail during expression reduction
+    // it will be executed during runtime though
+    util.getTableEnv.getConfig.addJobParameter("fail-for-cached-file", "true")
+    util.verifyPlan("SELECT myUdf(1 + 1) FROM MyTable")
+  }
+
   @Test
   def testExpressionReductionWithPythonUDF(): Unit = {
     util.addFunction("PyUdf", DeterministicPythonFunc)
