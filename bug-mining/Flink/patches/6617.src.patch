diff --git a/flink-python/pyflink/datastream/formats/tests/test_csv.py b/flink-python/pyflink/datastream/formats/tests/test_csv.py
index d1c62f618e2..bbcefcb058a 100644
--- a/flink-python/pyflink/datastream/formats/tests/test_csv.py
+++ b/flink-python/pyflink/datastream/formats/tests/test_csv.py
@@ -17,9 +17,12 @@
 ################################################################################
 import glob
 import os
+import sys
 import tempfile
 from typing import Tuple, List
 
+import pytest
+
 from pyflink.common import WatermarkStrategy, Types
 from pyflink.datastream import MapFunction
 from pyflink.datastream.connectors.file_system import FileSource, FileSink
@@ -29,12 +32,13 @@ from pyflink.datastream.tests.test_util import DataStreamTestSinkFunction
 from pyflink.java_gateway import get_gateway
 from pyflink.table import DataTypes
 from pyflink.testing.test_case_utils import PyFlinkStreamingTestCase, PyFlinkTestCase
+from pyflink.util.java_utils import get_j_env_configuration
 
 
-class FileSourceCsvReaderFormatTests(PyFlinkStreamingTestCase):
+class FileSourceCsvReaderFormatTests(object):
 
     def setUp(self):
-        super().setUp()
+        super(FileSourceCsvReaderFormatTests, self).setUp()
         self.test_sink = DataStreamTestSinkFunction()
         self.csv_file_name = tempfile.mktemp(suffix='.csv', dir=self.tempdir)
 
@@ -105,6 +109,20 @@ class FileSourceCsvReaderFormatTests(PyFlinkStreamingTestCase):
             .add_sink(self.test_sink)
 
 
+class ProcessFileSourceCsvReaderFormatTests(FileSourceCsvReaderFormatTests,
+                                            PyFlinkStreamingTestCase):
+    pass
+
+
+@pytest.mark.skipif(sys.version_info < (3, 7), reason="requires python3.7")
+class EmbeddedFileSourceCsvReaderFormatTests(FileSourceCsvReaderFormatTests,
+                                             PyFlinkStreamingTestCase):
+    def setUp(self):
+        super(EmbeddedFileSourceCsvReaderFormatTests, self).setUp()
+        config = get_j_env_configuration(self.env._j_stream_execution_environment)
+        config.setString("python.execution-mode", "thread")
+
+
 class FileSinkCsvBulkWriterTests(PyFlinkStreamingTestCase):
 
     def setUp(self):
@@ -288,9 +306,9 @@ def _create_csv_array_column_schema_and_lines() -> Tuple[CsvSchema, List[str]]:
 
 def _check_csv_array_column_results(test, results):
     row = results[0]
-    test.assertListEqual(row['number_array'], [1, 2, 3])
-    test.assertListEqual(row['boolean_array'], [True, False])
-    test.assertListEqual(row['string_array'], ['a', 'b', 'c'])
+    test.assertListEqual(list(row['number_array']), [1, 2, 3])
+    test.assertListEqual(list(row['boolean_array']), [True, False])
+    test.assertListEqual(list(row['string_array']), ['a', 'b', 'c'])
 
 
 def _create_csv_allow_comments_schema_and_lines() -> Tuple[CsvSchema, List[str]]:
diff --git a/flink-python/src/main/java/org/apache/flink/streaming/api/utils/PythonTypeUtils.java b/flink-python/src/main/java/org/apache/flink/streaming/api/utils/PythonTypeUtils.java
index b717d64b606..35d3303654a 100644
--- a/flink-python/src/main/java/org/apache/flink/streaming/api/utils/PythonTypeUtils.java
+++ b/flink-python/src/main/java/org/apache/flink/streaming/api/utils/PythonTypeUtils.java
@@ -66,6 +66,8 @@ import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;
 import org.apache.flink.core.memory.DataInputViewStreamWrapper;
 import org.apache.flink.fnexecution.v1.FlinkFnApi;
 import org.apache.flink.streaming.api.typeinfo.python.PickledByteArrayTypeInfo;
+import org.apache.flink.table.data.RowData;
+import org.apache.flink.table.data.util.DataFormatConverters;
 import org.apache.flink.table.runtime.typeutils.ExternalTypeInfo;
 import org.apache.flink.table.runtime.typeutils.InternalTypeInfo;
 import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;
@@ -74,9 +76,16 @@ import org.apache.flink.table.runtime.typeutils.serializers.python.StringSeriali
 import org.apache.flink.table.runtime.typeutils.serializers.python.TimeSerializer;
 import org.apache.flink.table.runtime.typeutils.serializers.python.TimestampSerializer;
 import org.apache.flink.table.types.logical.ArrayType;
+import org.apache.flink.table.types.logical.FloatType;
+import org.apache.flink.table.types.logical.IntType;
+import org.apache.flink.table.types.logical.LogicalType;
 import org.apache.flink.table.types.logical.MapType;
 import org.apache.flink.table.types.logical.RowType;
+import org.apache.flink.table.types.logical.SmallIntType;
+import org.apache.flink.table.types.logical.TinyIntType;
+import org.apache.flink.table.types.logical.utils.LogicalTypeDefaultVisitor;
 import org.apache.flink.table.types.utils.LegacyTypeInfoDataTypeConverter;
+import org.apache.flink.table.types.utils.TypeConversions;
 import org.apache.flink.table.typeutils.TimeIntervalTypeInfo;
 import org.apache.flink.types.Row;
 import org.apache.flink.types.RowKind;
@@ -1019,6 +1028,72 @@ public class PythonTypeUtils {
             }
             return reuseExternalRow;
         }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) {
+                return true;
+            }
+
+            if (o == null || getClass() != o.getClass()) {
+                return false;
+            }
+
+            final RowDataConverter other = (RowDataConverter) o;
+            if (other.fieldDataConverters.length != this.fieldDataConverters.length) {
+                return false;
+            }
+
+            for (int i = 0; i < other.fieldDataConverters.length; i++) {
+                if (!other.fieldDataConverters[i].equals(this.fieldDataConverters[i])) {
+                    return false;
+                }
+            }
+
+            return true;
+        }
+    }
+
+    /**
+     * RowData Data will be converted to the Object Array [RowKind(as Long Object), Field Values(as
+     * Object Array)].
+     */
+    public static final class RowDataDataConverter extends DataConverter<RowData, Object[]> {
+
+        private final RowDataConverter dataConverter;
+
+        private final DataFormatConverters.DataFormatConverter<RowData, Row> dataFormatConverter;
+
+        RowDataDataConverter(
+                RowDataConverter dataConverter,
+                DataFormatConverters.DataFormatConverter<RowData, Row> dataFormatConverter) {
+            this.dataConverter = dataConverter;
+            this.dataFormatConverter = dataFormatConverter;
+        }
+
+        @Override
+        public RowData toInternal(Object[] value) {
+            return dataFormatConverter.toInternal(dataConverter.toInternal(value));
+        }
+
+        @Override
+        public Object[] toExternal(RowData value) {
+            return dataConverter.toExternal(dataFormatConverter.toExternal(value));
+        }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) {
+                return true;
+            }
+
+            if (o == null || getClass() != o.getClass()) {
+                return false;
+            }
+
+            final RowDataDataConverter other = (RowDataDataConverter) o;
+            return this.dataConverter.equals(other.dataConverter);
+        }
     }
 
     /** Tuple Data will be converted to the Object Array. */
@@ -1059,6 +1134,29 @@ public class PythonTypeUtils {
             }
             return reuseExternalTuple;
         }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) {
+                return true;
+            }
+
+            if (o == null || getClass() != o.getClass()) {
+                return false;
+            }
+
+            final TupleDataConverter other = (TupleDataConverter) o;
+            if (other.fieldDataConverters.length != this.fieldDataConverters.length) {
+                return false;
+            }
+
+            for (int i = 0; i < other.fieldDataConverters.length; i++) {
+                if (!other.fieldDataConverters[i].equals(this.fieldDataConverters[i])) {
+                    return false;
+                }
+            }
+            return true;
+        }
     }
 
     /**
@@ -1106,6 +1204,20 @@ public class PythonTypeUtils {
 
             return array;
         }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) {
+                return true;
+            }
+
+            if (o == null || getClass() != o.getClass()) {
+                return false;
+            }
+
+            final ArrayDataConverter other = (ArrayDataConverter) o;
+            return this.elementConverter.equals(other.elementConverter);
+        }
     }
 
     /**
@@ -1149,6 +1261,20 @@ public class PythonTypeUtils {
             }
             return list;
         }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) {
+                return true;
+            }
+
+            if (o == null || getClass() != o.getClass()) {
+                return false;
+            }
+
+            final ListDataConverter other = (ListDataConverter) o;
+            return this.elementConverter.equals(other.elementConverter);
+        }
     }
 
     /**
@@ -1199,6 +1325,21 @@ public class PythonTypeUtils {
             }
             return map;
         }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) {
+                return true;
+            }
+
+            if (o == null || getClass() != o.getClass()) {
+                return false;
+            }
+
+            final MapDataConverter other = (MapDataConverter) o;
+            return this.keyConverter.equals(other.keyConverter)
+                    && this.valueConverter.equals(other.valueConverter);
+        }
     }
 
     /** Get DataConverter according to the given typeInformation. */
@@ -1282,6 +1423,13 @@ public class PythonTypeUtils {
                                             ((MapTypeInfo) typeInformation).getValueTypeInfo()));
                 }
 
+                if (typeInformation instanceof InternalTypeInfo) {
+
+                    return ((InternalTypeInfo<IN>) typeInformation)
+                            .toLogicalType()
+                            .accept(LogicalTypeToDataConverter.INSTANCE);
+                }
+
                 if (typeInformation instanceof ExternalTypeInfo) {
                     return (DataConverter<IN, OUT>)
                             TypeInfoToDataConverter.typeInfoDataConverter(
@@ -1294,6 +1442,66 @@ public class PythonTypeUtils {
         }
     }
 
+    private static class LogicalTypeToDataConverter
+            extends LogicalTypeDefaultVisitor<DataConverter> {
+
+        public static final LogicalTypeToDataConverter INSTANCE = new LogicalTypeToDataConverter();
+
+        @Override
+        public DataConverter visit(IntType intType) {
+            return IntDataConverter.INSTANCE;
+        }
+
+        @Override
+        public DataConverter visit(TinyIntType tinyIntType) {
+            return ByteDataConverter.INSTANCE;
+        }
+
+        @Override
+        public DataConverter visit(SmallIntType smallIntType) {
+            return ShortDataConverter.INSTANCE;
+        }
+
+        @Override
+        public DataConverter visit(FloatType floatType) {
+            return FloatDataConverter.INSTANCE;
+        }
+
+        @Override
+        public DataConverter visit(ArrayType arrayType) {
+            LogicalType elementType = arrayType.getElementType();
+            return new ArrayDataConverter<>(
+                    elementType.getDefaultConversion(), elementType.accept(this));
+        }
+
+        @Override
+        public DataConverter visit(MapType mapType) {
+            return new MapDataConverter(
+                    mapType.getKeyType().accept(this), mapType.getValueType().accept(this));
+        }
+
+        @SuppressWarnings("unchecked")
+        @Override
+        public DataConverter visit(RowType rowType) {
+            final DataConverter[] fieldTypeDataConverters =
+                    rowType.getFields().stream()
+                            .map(f -> f.getType().accept(this))
+                            .toArray(DataConverter[]::new);
+
+            DataFormatConverters.DataFormatConverter dataFormatConverter =
+                    DataFormatConverters.getConverterForDataType(
+                            TypeConversions.fromLogicalToDataType(rowType));
+
+            return new RowDataDataConverter(
+                    new RowDataConverter(fieldTypeDataConverters), dataFormatConverter);
+        }
+
+        @Override
+        protected DataConverter defaultMethod(LogicalType logicalType) {
+            return IdentityDataConverter.INSTANCE;
+        }
+    }
+
     /**
      * Wrap the unpickled python data with an InputFormat. It will be passed to
      * StreamExecutionEnvironment.creatInput() to create an InputFormat later.
diff --git a/flink-python/src/test/java/org/apache/flink/streaming/api/utils/PythonTypeUtilsTest.java b/flink-python/src/test/java/org/apache/flink/streaming/api/utils/PythonTypeUtilsTest.java
index fce1ead8fd6..a45e4b6e3bf 100644
--- a/flink-python/src/test/java/org/apache/flink/streaming/api/utils/PythonTypeUtilsTest.java
+++ b/flink-python/src/test/java/org/apache/flink/streaming/api/utils/PythonTypeUtilsTest.java
@@ -41,11 +41,16 @@ import org.apache.flink.api.java.typeutils.runtime.RowSerializer;
 import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;
 import org.apache.flink.fnexecution.v1.FlinkFnApi;
 import org.apache.flink.streaming.api.typeinfo.python.PickledByteArrayTypeInfo;
+import org.apache.flink.table.api.DataTypes;
+import org.apache.flink.table.data.util.DataFormatConverters;
+import org.apache.flink.table.runtime.typeutils.InternalTypeInfo;
 import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;
 import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;
 import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;
 import org.apache.flink.table.runtime.typeutils.serializers.python.TimeSerializer;
 import org.apache.flink.table.runtime.typeutils.serializers.python.TimestampSerializer;
+import org.apache.flink.table.types.logical.RowType;
+import org.apache.flink.table.types.utils.TypeConversions;
 import org.apache.flink.types.Row;
 
 import org.junit.jupiter.api.Test;
@@ -229,4 +234,62 @@ class PythonTypeUtilsTest {
                                 tupleTypeInfo.getTypeClass(),
                                 new TypeSerializer[] {IntSerializer.INSTANCE}));
     }
+
+    @SuppressWarnings("unchecked")
+    @Test
+    void testInternalTypeInfoToDataConverter() {
+        RowType rowDataType =
+                (RowType)
+                        DataTypes.ROW(
+                                        DataTypes.BOOLEAN(),
+                                        DataTypes.TINYINT(),
+                                        DataTypes.SMALLINT(),
+                                        DataTypes.INT(),
+                                        DataTypes.BIGINT(),
+                                        DataTypes.FLOAT(),
+                                        DataTypes.DOUBLE(),
+                                        DataTypes.BINARY(10),
+                                        DataTypes.VARCHAR(100),
+                                        DataTypes.CHAR(100),
+                                        DataTypes.VARCHAR(1000),
+                                        DataTypes.DATE(),
+                                        DataTypes.TIME(),
+                                        DataTypes.ARRAY(DataTypes.STRING()),
+                                        DataTypes.MAP(DataTypes.BIGINT(), DataTypes.BYTES()))
+                                .getLogicalType();
+        PythonTypeUtils.DataConverter dataConverter =
+                PythonTypeUtils.TypeInfoToDataConverter.typeInfoDataConverter(
+                        InternalTypeInfo.of(rowDataType));
+
+        PythonTypeUtils.RowDataConverter rowDataConverter =
+                new PythonTypeUtils.RowDataConverter(
+                        new PythonTypeUtils.DataConverter[] {
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.ByteDataConverter.INSTANCE,
+                            PythonTypeUtils.ShortDataConverter.INSTANCE,
+                            PythonTypeUtils.IntDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.FloatDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                            new PythonTypeUtils.ArrayDataConverter<>(
+                                    String.class, PythonTypeUtils.IdentityDataConverter.INSTANCE),
+                            new PythonTypeUtils.MapDataConverter(
+                                    PythonTypeUtils.IdentityDataConverter.INSTANCE,
+                                    PythonTypeUtils.IdentityDataConverter.INSTANCE)
+                        });
+
+        PythonTypeUtils.RowDataDataConverter expectedDataConverter =
+                new PythonTypeUtils.RowDataDataConverter(
+                        rowDataConverter,
+                        DataFormatConverters.getConverterForDataType(
+                                TypeConversions.fromLogicalToDataType(rowDataType)));
+
+        assertThat(dataConverter).isEqualTo(expectedDataConverter);
+    }
 }
