diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java
index 4f348546c74..1d760d0653e 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java
@@ -73,6 +73,50 @@ public class TableEnvHiveConnectorITCase {
 
     @ClassRule public static TemporaryFolder tempFolder = new TemporaryFolder();
 
+    @Test
+    public void testOverwriteWithEmptySource() throws Exception {
+        TableEnvironment tableEnv = getTableEnvWithHiveCatalog();
+        tableEnv.executeSql("create database db1");
+        try {
+            tableEnv.useDatabase("db1");
+            tableEnv.executeSql("create table src (x int,p int)");
+            // non-partitioned table
+            tableEnv.executeSql("create table dest (x int)");
+            HiveTestUtils.createTextTableInserter(hiveCatalog, "db1", "dest")
+                    .addRow(new Object[] {1})
+                    .addRow(new Object[] {2})
+                    .commit();
+            tableEnv.executeSql("insert overwrite table dest select x from src").await();
+            List<Row> results =
+                    CollectionUtil.iteratorToList(
+                            tableEnv.executeSql("select * from dest").collect());
+            assertEquals(0, results.size());
+            // dynamic partitioned table
+            tableEnv.executeSql("create table destp (x int) partitioned by (p int)");
+            HiveTestUtils.createTextTableInserter(hiveCatalog, "db1", "destp")
+                    .addRow(new Object[] {1})
+                    .commit("p=1");
+            HiveTestUtils.createTextTableInserter(hiveCatalog, "db1", "destp")
+                    .addRow(new Object[] {2})
+                    .commit("p=2");
+            tableEnv.executeSql("insert overwrite table destp partition (p) select * from src")
+                    .await();
+            results =
+                    CollectionUtil.iteratorToList(
+                            tableEnv.executeSql("select * from destp order by x").collect());
+            assertEquals("[+I[1, 1], +I[2, 2]]", results.toString());
+            // static partitioned table
+            tableEnv.executeSql("insert overwrite table destp partition(p=1) select x from src")
+                    .await();
+            results =
+                    CollectionUtil.iteratorToList(
+                            tableEnv.executeSql("select * from destp order by x").collect());
+            assertEquals("[+I[1, 1], +I[2, 2]]", results.toString());
+        } finally {
+            tableEnv.executeSql("drop database db1 cascade");
+        }
+    }
+
     @Test
     public void testMultiInputBroadcast() throws Exception {
         TableEnvironment tableEnv = getTableEnvWithHiveCatalog();
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemCommitter.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemCommitter.java
index 0815ec973e4..795cd5e3157 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemCommitter.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemCommitter.java
@@ -28,19 +28,12 @@ import java.util.List;
 import java.util.Map;
 
 import static org.apache.flink.table.filesystem.PartitionTempFileManager.collectPartSpecToPaths;
-import static org.apache.flink.table.filesystem.PartitionTempFileManager.deleteCheckpoint;
-import static org.apache.flink.table.filesystem.PartitionTempFileManager.headCheckpoints;
 import static org.apache.flink.table.filesystem.PartitionTempFileManager.listTaskTemporaryPaths;
 
 /**
- * File system file committer implementation. It move all files to output path from temporary path.
+ * File system file committer implementation. It moves all files to output path from temporary path.
  *
- * <p>In a checkpoint: 1.Every task will create a {@link PartitionTempFileManager} to
- * initialization, it generate path for task writing. And clean the temporary path of task. 2.After
- * writing done for this checkpoint, need invoke {@link #commitUpToCheckpoint(long)}, will move the
- * temporary files to real output path.
- *
- * <p>Batch is a special case of Streaming, which has only one checkpoint.
+ * <p>It's used to commit data to FileSystem table in batch mode.
  *
  * <p>Data consistency: 1.For task failure: will launch a new task and create a {@link
  * PartitionTempFileManager}, this will clean previous temporary files (This simple design can make
@@ -78,28 +71,12 @@ class FileSystemCommitter implements Serializable {
         this.partitionColumnSize = partitionColumnSize;
     }
 
-    /**
-     * For committing job's output after successful batch job completion or one checkpoint finish
-     * for streaming job. Should move all files to final output paths.
-     *
-     * <p>NOTE: According to checkpoint notify mechanism of Flink, checkpoint may fail and be
-     * abandoned, so this method should commit all checkpoint ids that less than current checkpoint
-     * id (Includes failure checkpoints).
-     */
-    public void commitUpToCheckpoint(long toCpId) throws Exception {
+    /** For committing job's output after successful batch job completion. */
+    public void commitPartitions() throws Exception {
         FileSystem fs = factory.create(tmpPath.toUri());
+        List<Path> taskPaths = listTaskTemporaryPaths(fs, tmpPath);
 
         try (PartitionLoader loader = new PartitionLoader(overwrite, fs, metaStoreFactory)) {
-            for (long cp : headCheckpoints(fs, tmpPath, toCpId)) {
-                commitSingleCheckpoint(fs, loader, cp);
-            }
-        }
-    }
-
-    private void commitSingleCheckpoint(FileSystem fs, PartitionLoader loader, long checkpointId)
-            throws Exception {
-        try {
-            List<Path> taskPaths = listTaskTemporaryPaths(fs, tmpPath, checkpointId);
             if (partitionColumnSize > 0) {
                 for (Map.Entry<LinkedHashMap<String, String>, List<Path>> entry :
                         collectPartSpecToPaths(fs, taskPaths, partitionColumnSize).entrySet()) {
@@ -109,7 +86,9 @@ class FileSystemCommitter implements Serializable {
                 loader.loadNonPartition(taskPaths);
             }
         } finally {
-            deleteCheckpoint(fs, tmpPath, checkpointId);
+            for (Path taskPath : taskPaths) {
+                fs.delete(taskPath, true);
+            }
         }
     }
 }
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemOutputFormat.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemOutputFormat.java
index d07dcb2e3b3..7c632c7157b 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemOutputFormat.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/FileSystemOutputFormat.java
@@ -43,8 +43,6 @@ public class FileSystemOutputFormat<T> implements OutputFormat<T>, FinalizeOnMas
 
     private static final long serialVersionUID = 1L;
 
-    private static final long CHECKPOINT_ID = 0;
-
     private final FileSystemFactory fsFactory;
     private final TableMetaStoreFactory msFactory;
     private final boolean overwrite;
@@ -88,7 +86,7 @@ public class FileSystemOutputFormat<T> implements OutputFormat<T>, FinalizeOnMas
             FileSystemCommitter committer =
                     new FileSystemCommitter(
                             fsFactory, msFactory, overwrite, tmpPath, partitionColumns.length);
-            committer.commitUpToCheckpoint(CHECKPOINT_ID);
+            committer.commitPartitions();
         } catch (Exception e) {
             throw new TableException("Exception in finalizeGlobal", e);
         } finally {
@@ -108,8 +106,7 @@ public class FileSystemOutputFormat<T> implements OutputFormat<T>, FinalizeOnMas
     public void open(int taskNumber, int numTasks) throws IOException {
         try {
             PartitionTempFileManager fileManager =
-                    new PartitionTempFileManager(
-                            fsFactory, tmpPath, taskNumber, CHECKPOINT_ID, outputFileConfig);
+                    new PartitionTempFileManager(fsFactory, tmpPath, taskNumber, outputFileConfig);
             PartitionWriter.Context<T> context =
                     new PartitionWriter.Context<>(parameters, formatFactory);
             writer =
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/PartitionTempFileManager.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/PartitionTempFileManager.java
index 2ced198ff79..141e0ea651f 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/PartitionTempFileManager.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/filesystem/PartitionTempFileManager.java
@@ -32,52 +32,42 @@ import java.util.List;
 import java.util.Map;
 
 import static org.apache.flink.table.utils.PartitionPathUtils.searchPartSpecAndPaths;
-import static org.apache.flink.util.Preconditions.checkArgument;
 
 /**
  * Manage temporary files for writing files. Use special rules to organize directories for temporary
  * files.
  *
  * <p>Temporary file directory contains the following directory parts: 1.temporary base path
- * directory. 2.checkpoint id directory. 3.task id directory. 4.directories to specify partitioning.
- * 5.data files. eg: /tmp/cp-1/task-0/p0=1/p1=2/fileName.
+ * directory. 2.task id directory. 3.directories to specify partitioning. 4.data files. eg:
+ * /tmp/task-0/p0=1/p1=2/fileName.
  */
 @Internal
 public class PartitionTempFileManager {
 
-    private static final String CHECKPOINT_DIR_PREFIX = "cp-";
     private static final String TASK_DIR_PREFIX = "task-";
 
     private final int taskNumber;
-    private final long checkpointId;
     private final Path taskTmpDir;
     private final OutputFileConfig outputFileConfig;
 
     private transient int nameCounter = 0;
 
-    PartitionTempFileManager(
-            FileSystemFactory factory, Path tmpPath, int taskNumber, long checkpointId)
+    PartitionTempFileManager(FileSystemFactory factory, Path tmpPath, int taskNumber)
             throws IOException {
-        this(factory, tmpPath, taskNumber, checkpointId, new OutputFileConfig("", ""));
+        this(factory, tmpPath, taskNumber, new OutputFileConfig("", ""));
     }
 
     PartitionTempFileManager(
             FileSystemFactory factory,
             Path tmpPath,
             int taskNumber,
-            long checkpointId,
             OutputFileConfig outputFileConfig)
             throws IOException {
-        checkArgument(checkpointId != -1, "checkpoint id start with 0.");
         this.taskNumber = taskNumber;
-        this.checkpointId = checkpointId;
         this.outputFileConfig = outputFileConfig;
 
         // generate and clean task temp dir.
-        this.taskTmpDir =
-                new Path(
-                        new Path(tmpPath, checkpointName(checkpointId)),
-                        TASK_DIR_PREFIX + taskNumber);
+        this.taskTmpDir = new Path(tmpPath, TASK_DIR_PREFIX + taskNumber);
         factory.create(taskTmpDir.toUri()).delete(taskTmpDir, true);
     }
 
@@ -92,9 +82,8 @@ public class PartitionTempFileManager {
 
     private String newFileName() {
         return String.format(
-                "%s-%s-%s-file-%d%s",
+                "%s-%s-file-%d%s",
                 outputFileConfig.getPartPrefix(),
-                checkpointName(checkpointId),
                 taskName(taskNumber),
                 nameCounter++,
                 outputFileConfig.getPartSuffix());
@@ -104,56 +93,15 @@ public class PartitionTempFileManager {
         return fileName.startsWith(TASK_DIR_PREFIX);
     }
 
-    private static boolean isCheckpointDir(String fileName) {
-        return fileName.startsWith(CHECKPOINT_DIR_PREFIX);
-    }
-
-    private static long getCheckpointId(String fileName) {
-        return Long.parseLong(fileName.substring(3));
-    }
-
-    private static String checkpointName(long checkpointId) {
-        return CHECKPOINT_DIR_PREFIX + checkpointId;
-    }
-
     private static String taskName(int task) {
         return TASK_DIR_PREFIX + task;
     }
 
-    /** Delete checkpoint path. */
-    public static void deleteCheckpoint(FileSystem fs, Path basePath, long checkpointId)
-            throws IOException {
-        fs.delete(new Path(basePath, checkpointName(checkpointId)), true);
-    }
-
-    /**
-     * Returns checkpoints whose keys are less than or equal to {@code toCpId} in temporary base
-     * path.
-     */
-    public static long[] headCheckpoints(FileSystem fs, Path basePath, long toCpId)
-            throws IOException {
-        List<Long> cps = new ArrayList<>();
-
-        for (FileStatus taskStatus : fs.listStatus(basePath)) {
-            String name = taskStatus.getPath().getName();
-            if (isCheckpointDir(name)) {
-                long currentCp = getCheckpointId(name);
-                // commit paths that less than current checkpoint id.
-                if (currentCp <= toCpId) {
-                    cps.add(currentCp);
-                }
-            }
-        }
-        return cps.stream().mapToLong(v -> v).toArray();
-    }
-
     /** Returns task temporary paths in this checkpoint. */
-    public static List<Path> listTaskTemporaryPaths(FileSystem fs, Path basePath, long checkpointId)
-            throws Exception {
+    public static List<Path> listTaskTemporaryPaths(FileSystem fs, Path basePath) throws Exception {
         List<Path> taskTmpPaths = new ArrayList<>();
 
-        for (FileStatus taskStatus :
-                fs.listStatus(new Path(basePath, checkpointName(checkpointId)))) {
+        for (FileStatus taskStatus : fs.listStatus(basePath)) {
             if (isTaskDir(taskStatus.getPath().getName())) {
                 taskTmpPaths.add(taskStatus.getPath());
             }
diff --git a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemCommitterTest.java b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemCommitterTest.java
index 69ca08c3e75..a7840505681 100644
--- a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemCommitterTest.java
+++ b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemCommitterTest.java
@@ -70,25 +70,25 @@ public class FileSystemCommitterTest {
         FileSystemCommitter committer =
                 new FileSystemCommitter(fileSystemFactory, metaStoreFactory, true, tmpPath, 2);
 
-        createFile("cp-1/task-1/p1=0/p2=0/", "f1", "f2");
-        createFile("cp-1/task-2/p1=0/p2=0/", "f3");
-        createFile("cp-1/task-2/p1=0/p2=1/", "f4");
-        committer.commitUpToCheckpoint(1);
+        createFile("task-1/p1=0/p2=0/", "f1", "f2");
+        createFile("task-2/p1=0/p2=0/", "f3");
+        createFile("task-2/p1=0/p2=1/", "f4");
+        committer.commitPartitions();
         Assert.assertTrue(new File(outputFile, "p1=0/p2=0/f1").exists());
         Assert.assertTrue(new File(outputFile, "p1=0/p2=0/f2").exists());
         Assert.assertTrue(new File(outputFile, "p1=0/p2=0/f3").exists());
         Assert.assertTrue(new File(outputFile, "p1=0/p2=1/f4").exists());
 
-        createFile("cp-1/task-2/p1=0/p2=1/", "f5");
-        committer.commitUpToCheckpoint(1);
+        createFile("task-2/p1=0/p2=1/", "f5");
+        committer.commitPartitions();
         Assert.assertTrue(new File(outputFile, "p1=0/p2=0/f1").exists());
         Assert.assertTrue(new File(outputFile, "p1=0/p2=0/f2").exists());
         Assert.assertTrue(new File(outputFile, "p1=0/p2=0/f3").exists());
         Assert.assertTrue(new File(outputFile, "p1=0/p2=1/f5").exists());
 
         committer = new FileSystemCommitter(fileSystemFactory, metaStoreFactory, false, tmpPath, 2);
-        createFile("cp-1/task-2/p1=0/p2=1/", "f6");
-        committer.commitUpToCheckpoint(1);
+        createFile("task-2/p1=0/p2=1/", "f6");
+        committer.commitPartitions();
         Assert.assertTrue(new File(outputFile, "p1=0/p2=1/f5").exists());
         Assert.assertTrue(new File(outputFile, "p1=0/p2=1/f6").exists());
     }
@@ -98,20 +98,20 @@ public class FileSystemCommitterTest {
         FileSystemCommitter committer =
                 new FileSystemCommitter(fileSystemFactory, metaStoreFactory, true, tmpPath, 0);
 
-        createFile("cp-1/task-1/", "f1", "f2");
-        createFile("cp-1/task-2/", "f3");
-        committer.commitUpToCheckpoint(1);
+        createFile("task-1/", "f1", "f2");
+        createFile("task-2/", "f3");
+        committer.commitPartitions();
         Assert.assertTrue(new File(outputFile, "f1").exists());
         Assert.assertTrue(new File(outputFile, "f2").exists());
         Assert.assertTrue(new File(outputFile, "f3").exists());
 
-        createFile("cp-1/task-2/", "f4");
-        committer.commitUpToCheckpoint(1);
+        createFile("task-2/", "f4");
+        committer.commitPartitions();
         Assert.assertTrue(new File(outputFile, "f4").exists());
 
         committer = new FileSystemCommitter(fileSystemFactory, metaStoreFactory, false, tmpPath, 0);
-        createFile("cp-1/task-2/", "f5");
-        committer.commitUpToCheckpoint(1);
+        createFile("task-2/", "f5");
+        committer.commitPartitions();
         Assert.assertTrue(new File(outputFile, "f4").exists());
         Assert.assertTrue(new File(outputFile, "f5").exists());
     }
diff --git a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemOutputFormatTest.java b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemOutputFormatTest.java
index 6ca7f43baf7..057695b305d 100644
--- a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemOutputFormatTest.java
+++ b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/FileSystemOutputFormatTest.java
@@ -91,7 +91,7 @@ public class FileSystemOutputFormatTest {
         try (OneInputStreamOperatorTestHarness<Row, Object> testHarness =
                 createSink(false, false, false, new LinkedHashMap<>(), ref)) {
             writeUnorderedRecords(testHarness);
-            assertEquals(1, getFileContentByPath(new File(tmpFile, "cp-0")).size());
+            assertEquals(1, getFileContentByPath(tmpFile).size());
         }
 
         ref.get().finalizeGlobal(1);
@@ -121,7 +121,7 @@ public class FileSystemOutputFormatTest {
         try (OneInputStreamOperatorTestHarness<Row, Object> testHarness =
                 createSink(true, false, false, new LinkedHashMap<>(), ref)) {
             writeUnorderedRecords(testHarness);
-            assertEquals(1, getFileContentByPath(new File(tmpFile, "cp-0")).size());
+            assertEquals(1, getFileContentByPath(tmpFile).size());
         }
 
         ref.get().finalizeGlobal(1);
@@ -147,7 +147,7 @@ public class FileSystemOutputFormatTest {
             testHarness.processElement(new StreamRecord<>(Row.of("a2", 2), 1L));
             testHarness.processElement(new StreamRecord<>(Row.of("a2", 2), 1L));
             testHarness.processElement(new StreamRecord<>(Row.of("a3", 3), 1L));
-            assertEquals(1, getFileContentByPath(new File(tmpFile, "cp-0")).size());
+            assertEquals(1, getFileContentByPath(tmpFile).size());
         }
 
         ref.get().finalizeGlobal(1);
@@ -164,7 +164,7 @@ public class FileSystemOutputFormatTest {
         try (OneInputStreamOperatorTestHarness<Row, Object> testHarness =
                 createSink(false, true, false, new LinkedHashMap<>(), ref)) {
             writeUnorderedRecords(testHarness);
-            assertEquals(2, getFileContentByPath(new File(tmpFile, "cp-0")).size());
+            assertEquals(2, getFileContentByPath(tmpFile).size());
         }
 
         ref.get().finalizeGlobal(1);
@@ -190,7 +190,7 @@ public class FileSystemOutputFormatTest {
             testHarness.processElement(new StreamRecord<>(Row.of("a2", 2, "p1"), 1L));
             testHarness.processElement(new StreamRecord<>(Row.of("a3", 3, "p1"), 1L));
             testHarness.processElement(new StreamRecord<>(Row.of("a2", 2, "p2"), 1L));
-            assertEquals(2, getFileContentByPath(new File(tmpFile, "cp-0")).size());
+            assertEquals(2, getFileContentByPath(tmpFile).size());
         }
 
         ref.get().finalizeGlobal(1);
diff --git a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/PartitionWriterTest.java b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/PartitionWriterTest.java
index 934ad01a2da..d62ef2ac92f 100644
--- a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/PartitionWriterTest.java
+++ b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/filesystem/PartitionWriterTest.java
@@ -33,7 +33,6 @@ import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
@@ -45,37 +44,38 @@ public class PartitionWriterTest {
 
     @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();
 
-    private Map<String, List<Row>> records = new HashMap<>();
-
-    private OutputFormatFactory<Row> factory =
-            (OutputFormatFactory<Row>)
-                    path ->
-                            new OutputFormat<Row>() {
-                                @Override
-                                public void configure(Configuration parameters) {}
-
-                                @Override
-                                public void open(int taskNumber, int numTasks) {
-                                    records.put(getKey(), new ArrayList<>());
-                                }
-
-                                private String getKey() {
-                                    Path parent = path.getParent();
-                                    return parent.getName().startsWith("task-")
-                                            ? parent.getParent().getName()
-                                            : parent.getParent().getParent().getName()
-                                                    + Path.SEPARATOR
-                                                    + parent.getName();
-                                }
-
-                                @Override
-                                public void writeRecord(Row record) {
-                                    records.get(getKey()).add(record);
-                                }
-
-                                @Override
-                                public void close() {}
-                            };
+    private final Map<String, List<Row>> records = new LinkedHashMap<>();
+
+    private final OutputFormatFactory<Row> factory =
+            path ->
+                    new OutputFormat<Row>() {
+                        private static final long serialVersionUID = -5797045183913321175L;
+
+                        @Override
+                        public void configure(Configuration parameters) {}
+
+                        @Override
+                        public void open(int taskNumber, int numTasks) {
+                            records.put(getKey(), new ArrayList<>());
+                        }
+
+                        private String getKey() {
+                            Path parent = path.getParent();
+                            return parent.getName().startsWith("task-")
+                                    ? parent.getName()
+                                    : parent.getParent().getName()
+                                            + Path.SEPARATOR
+                                            + parent.getName();
+                        }
+
+                        @Override
+                        public void writeRecord(Row record) {
+                            records.get(getKey()).add(record);
+                        }
+
+                        @Override
+                        public void close() {}
+                    };
 
     private final String basePath = TEMP_FOLDER.newFolder().getPath();
 
@@ -86,8 +86,7 @@ public class PartitionWriterTest {
 
     private Path tmpPath = new Path(basePath);
 
-    private PartitionTempFileManager manager =
-            new PartitionTempFileManager(fsFactory, tmpPath, 0, 1);
+    private PartitionTempFileManager manager = new PartitionTempFileManager(fsFactory, tmpPath, 0);
 
     private PartitionComputer<Row> computer =
             new PartitionComputer<Row>() {
@@ -124,16 +123,16 @@ public class PartitionWriterTest {
         writer.write(Row.of("p1", 2));
         writer.write(Row.of("p2", 2));
         writer.close();
-        Assert.assertEquals("{cp-1=[p1,1, p1,2, p2,2]}", records.toString());
+        Assert.assertEquals("{task-0=[p1,1, p1,2, p2,2]}", records.toString());
 
-        manager = new PartitionTempFileManager(fsFactory, tmpPath, 0, 2);
+        manager = new PartitionTempFileManager(fsFactory, tmpPath, 1);
         writer = new SingleDirectoryWriter<>(context, manager, computer, new LinkedHashMap<>());
         writer.write(Row.of("p3", 3));
         writer.write(Row.of("p5", 5));
         writer.write(Row.of("p2", 2));
         writer.close();
         Assert.assertEquals(
-                "{cp-2=[p3,3, p5,5, p2,2], cp-1=[p1,1, p1,2, p2,2]}", records.toString());
+                "{task-0=[p1,1, p1,2, p2,2], task-1=[p3,3, p5,5, p2,2]}", records.toString());
     }
 
     @Test
@@ -145,16 +144,16 @@ public class PartitionWriterTest {
         writer.write(Row.of("p1", 2));
         writer.write(Row.of("p2", 2));
         writer.close();
-        Assert.assertEquals("{cp-1/p=p1=[p1,1, p1,2], cp-1/p=p2=[p2,2]}", records.toString());
+        Assert.assertEquals("{task-0/p=p1=[p1,1, p1,2], task-0/p=p2=[p2,2]}", records.toString());
 
-        manager = new PartitionTempFileManager(fsFactory, tmpPath, 0, 2);
+        manager = new PartitionTempFileManager(fsFactory, tmpPath, 1);
         writer = new GroupedPartitionWriter<>(context, manager, computer);
         writer.write(Row.of("p3", 3));
         writer.write(Row.of("p4", 5));
         writer.write(Row.of("p5", 2));
         writer.close();
         Assert.assertEquals(
-                "{cp-2/p=p5=[p5,2], cp-2/p=p4=[p4,5], cp-2/p=p3=[p3,3], cp-1/p=p1=[p1,1, p1,2], cp-1/p=p2=[p2,2]}",
+                "{task-0/p=p1=[p1,1, p1,2], task-0/p=p2=[p2,2], task-1/p=p3=[p3,3], task-1/p=p4=[p4,5], task-1/p=p5=[p5,2]}",
                 records.toString());
     }
 
@@ -167,16 +166,16 @@ public class PartitionWriterTest {
         writer.write(Row.of("p2", 2));
         writer.write(Row.of("p1", 2));
         writer.close();
-        Assert.assertEquals("{cp-1/p=p1=[p1,1, p1,2], cp-1/p=p2=[p2,2]}", records.toString());
+        Assert.assertEquals("{task-0/p=p1=[p1,1, p1,2], task-0/p=p2=[p2,2]}", records.toString());
 
-        manager = new PartitionTempFileManager(fsFactory, tmpPath, 0, 2);
+        manager = new PartitionTempFileManager(fsFactory, tmpPath, 1);
         writer = new DynamicPartitionWriter<>(context, manager, computer);
         writer.write(Row.of("p4", 5));
         writer.write(Row.of("p3", 3));
         writer.write(Row.of("p5", 2));
         writer.close();
         Assert.assertEquals(
-                "{cp-2/p=p5=[p5,2], cp-2/p=p4=[p4,5], cp-2/p=p3=[p3,3], cp-1/p=p1=[p1,1, p1,2], cp-1/p=p2=[p2,2]}",
+                "{task-0/p=p1=[p1,1, p1,2], task-0/p=p2=[p2,2], task-1/p=p4=[p4,5], task-1/p=p3=[p3,3], task-1/p=p5=[p5,2]}",
                 records.toString());
     }
 }
