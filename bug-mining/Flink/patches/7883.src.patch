diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/utils/DateTimeUtils.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/utils/DateTimeUtils.java
index 4346c437bb8..134a41905e4 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/utils/DateTimeUtils.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/utils/DateTimeUtils.java
@@ -568,7 +568,26 @@ public class DateTimeUtils {
         return ymdToUnixDate(y, m, d);
     }
 
-    public static Integer parseTime(String v) {
+    /**
+     * Parses a time string into milliseconds since midnight.
+     *
+     * <p>Supports various time formats:
+     *
+     * <ul>
+     *   <li>HH - hour only (e.g., "14")
+     *   <li>HH:mm - hour and minute (e.g., "14:30")
+     *   <li>HH:mm:ss - hour, minute, and second (e.g., "14:30:45")
+     *   <li>HH:mm:ss.fff - with fractional seconds (e.g., "14:30:45.123")
+     *   <li>Any of the above with timezone offset: [+|-]HH:mm (e.g., "14:30:45+02:00")
+     * </ul>
+     *
+     * <p>Follows W3C datetime format specification.
+     *
+     * @param v the time string to parse
+     * @return milliseconds since midnight (0-86399999), or {@code null} if parsing fails
+     * @see <a href="https://www.w3.org/TR/NOTE-datetime">W3C Date and Time Formats</a>
+     */
+    public static Integer parseTime(final String v) {
         final int start = 0;
         final int colon1 = v.indexOf(':', start);
         // timezone hh:mm:ss[.ssssss][[+|-]hh:mm:ss]
@@ -651,6 +670,11 @@ public class DateTimeUtils {
                 }
             }
         }
+
+        if (!isValidTime(hour, minute, second)) {
+            return null;
+        }
+
         hour += operator * timezoneHour;
         minute += operator * timezoneMinute;
         return hour * (int) MILLIS_PER_HOUR
@@ -659,6 +683,23 @@ public class DateTimeUtils {
                 + milli;
     }
 
+    /**
+     * Validates time components are within valid ranges.
+     *
+     * @param hour hour component (0-23)
+     * @param minute minute component (0-59)
+     * @param second second component (0-59)
+     * @return true if all components are valid, false otherwise
+     */
+    private static boolean isValidTime(int hour, int minute, int second) {
+        return hour >= 0
+                && hour <= 23
+                && minute >= 0
+                && minute <= 59
+                && second >= 0
+                && second <= 59;
+    }
+
     /**
      * Parses a fraction, multiplying the first character by {@code multiplier}, the second
      * character by {@code multiplier / 10}, the third character by {@code multiplier / 100}, and so
@@ -1500,10 +1541,53 @@ public class DateTimeUtils {
                         .toLocalDate());
     }
 
-    public static int timestampWithLocalZoneToTime(TimestampData ts, TimeZone tz) {
-        return toInternal(
-                LocalDateTime.ofInstant(Instant.ofEpochMilli(ts.getMillisecond()), tz.toZoneId())
-                        .toLocalTime());
+    public static int timestampWithoutLocalZoneToTime(TimestampData ts, int precision) {
+        final int millisecond = (int) (ts.getMillisecond() % DateTimeUtils.MILLIS_PER_DAY);
+        return applyTimePrecisionTruncation(millisecond, precision);
+    }
+
+    public static int timestampWithLocalZoneToTime(TimestampData ts, TimeZone tz, int precision) {
+        final int internal =
+                toInternal(
+                        LocalDateTime.ofInstant(
+                                        Instant.ofEpochMilli(ts.getMillisecond()), tz.toZoneId())
+                                .toLocalTime());
+        return applyTimePrecisionTruncation(internal, precision);
+    }
+
+    /**
+     * Applies precision truncation to time milliseconds.
+     *
+     * <p>This method truncates (not rounds) the time value to the specified precision. For
+     * precision 3 or higher, no truncation is needed since the input is already in millisecond
+     * resolution.
+     *
+     * <p>Examples with timeMillis = 12345 (representing 00:00:12.345):
+     *
+     * <table border="1">
+     *   <tr><th>Target Precision</th><th>Factor</th><th>Result</th><th>Time String</th></tr>
+     *   <tr><td>0</td><td>1000</td><td>12000</td><td>00:00:12.000</td></tr>
+     *   <tr><td>1</td><td>100</td><td>12300</td><td>00:00:12.300</td></tr>
+     *   <tr><td>2</td><td>10</td><td>12340</td><td>00:00:12.340</td></tr>
+     *   <tr><td>3</td><td>-</td><td>12345</td><td>00:00:12.345</td></tr>
+     * </table>
+     *
+     * @param timeMillis time value as milliseconds since midnight (0-86399999)
+     * @param precision the target precision for fractional seconds (0-9)
+     * @return the truncated time value in milliseconds
+     */
+    public static int applyTimePrecisionTruncation(int timeMillis, int precision) {
+        switch (precision) {
+            case 0:
+                return (timeMillis / 1000) * 1000;
+            case 1:
+                return (timeMillis / 100) * 100;
+            case 2:
+                return (timeMillis / 10) * 10;
+            default:
+                // precision 3 or higher, no truncation needed
+                return timeMillis;
+        }
     }
 
     public static TimestampData dateToTimestampWithLocalZone(int date, TimeZone tz) {
diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/BinaryToBinaryCastRule.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/BinaryToBinaryCastRule.java
index 72fbcfc9fdc..3d2f7a7c653 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/BinaryToBinaryCastRule.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/BinaryToBinaryCastRule.java
@@ -43,43 +43,85 @@ class BinaryToBinaryCastRule extends AbstractExpressionCodeGeneratorCastRule<byt
                         .build());
     }
 
-    /* Example generated code for BINARY(2):
-
-    // legacy behavior
-    ((byte[])(inputValue))
-
-    // new behavior
-    ((((byte[])(inputValue)).length == 2) ? (((byte[])(inputValue))) : (java.util.Arrays.copyOf(((byte[])(inputValue)), 2)))
-
-    */
-
+    /**
+     * Generates code for casting between BINARY and VARBINARY types.
+     *
+     * <p>For VARBINARY targets: preserves original length if it fits within the target constraint,
+     * otherwise truncates to target length.
+     *
+     * <p>For BINARY targets: pads shorter inputs to exact target length, truncates longer inputs.
+     *
+     * <p>Example generated code for {@code CAST(input AS VARBINARY(4))}:
+     *
+     * <p>New behavior:
+     *
+     * <pre>
+     * ((input.length <= 4) ? ((byte[])(inputValue)): java.util.Arrays.copyOf(((byte[])(inputValue)), 4))
+     * </pre>
+     *
+     * <p>Legacy behavior:
+     *
+     * <pre>
+     * ((byte[])(inputValue))
+     * </pre>
+     */
     @Override
     public String generateExpression(
             CodeGeneratorCastRule.Context context,
             String inputTerm,
             LogicalType inputLogicalType,
             LogicalType targetLogicalType) {
-        int inputLength = LogicalTypeChecks.getLength(inputLogicalType);
-        int targetLength = LogicalTypeChecks.getLength(targetLogicalType);
+        final int targetLength = LogicalTypeChecks.getLength(targetLogicalType);
 
+        // Legacy behavior: always return input unchanged
         if (context.legacyBehaviour()
-                || ((!couldTrim(targetLength)
-                                // Assume input length is respected by the source
-                                || (inputLength <= targetLength))
-                        && !couldPad(targetLogicalType, targetLength))) {
+                || noTransformationNeeded(inputLogicalType, targetLogicalType)) {
             return inputTerm;
-        } else {
-            return ternaryOperator(
-                    arrayLength(inputTerm) + " == " + targetLength,
-                    inputTerm,
-                    staticCall(Arrays.class, "copyOf", inputTerm, targetLength));
         }
+
+        // Generate runtime transformation code
+        final String operand = couldPad(targetLogicalType, targetLength) ? " == " : " <= ";
+        return ternaryOperator(
+                arrayLength(inputTerm) + operand + targetLength,
+                inputTerm,
+                staticCall(Arrays.class, "copyOf", inputTerm, targetLength));
+    }
+
+    /**
+     * Determines if no runtime transformation is needed for the cast.
+     *
+     * <p>No transformation is needed when:
+     *
+     * <ul>
+     *   <li>Target has no length constraint (unlimited length)
+     *   <li>Target is VARBINARY and input's declared length fits within target constraint
+     * </ul>
+     *
+     * <p>Transformation is always needed for BINARY targets (for padding/truncation).
+     */
+    private static boolean noTransformationNeeded(
+            LogicalType inputLogicalType, LogicalType targetLogicalType) {
+        final int inputLength = LogicalTypeChecks.getLength(inputLogicalType);
+        final int targetLength = LogicalTypeChecks.getLength(targetLogicalType);
+
+        // Target has no length constraint - always use input as-is
+        // or
+        // BINARY targets always need transformation for exact length semantics
+        if (!couldTrim(targetLength) || couldPad(targetLogicalType, targetLength)) {
+            return false;
+        }
+
+        // VARBINARY targets: no transformation if input fits within constraint
+        // (assumes input respects its declared length)
+        return inputLength <= targetLength;
     }
 
+    /** Determines if the target has a length constraint that could lead to trimming. */
     static boolean couldTrim(int targetLength) {
         return targetLength < BinaryType.MAX_LENGTH;
     }
 
+    /** Determines if the target is a BINARY with length constraint. */
     static boolean couldPad(LogicalType targetType, int targetLength) {
         return targetType.is(LogicalTypeRoot.BINARY) && targetLength < BinaryType.MAX_LENGTH;
     }
diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/StringToTimeCastRule.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/StringToTimeCastRule.java
index 49e47c41263..82605fddd33 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/StringToTimeCastRule.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/StringToTimeCastRule.java
@@ -22,6 +22,7 @@ import org.apache.flink.table.data.StringData;
 import org.apache.flink.table.types.logical.LogicalType;
 import org.apache.flink.table.types.logical.LogicalTypeFamily;
 import org.apache.flink.table.types.logical.LogicalTypeRoot;
+import org.apache.flink.table.types.logical.utils.LogicalTypeChecks;
 
 import static org.apache.flink.table.planner.codegen.calls.BuiltInMethods.STRING_DATA_TO_TIME;
 import static org.apache.flink.table.planner.functions.casting.CastRuleUtils.staticCall;
@@ -48,7 +49,8 @@ class StringToTimeCastRule extends AbstractExpressionCodeGeneratorCastRule<Strin
             String inputTerm,
             LogicalType inputLogicalType,
             LogicalType targetLogicalType) {
-        return staticCall(STRING_DATA_TO_TIME(), inputTerm);
+        final int targetPrecision = LogicalTypeChecks.getPrecision(targetLogicalType);
+        return staticCall(STRING_DATA_TO_TIME(), inputTerm, targetPrecision);
     }
 
     @Override
diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/TimestampToTimeCastRule.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/TimestampToTimeCastRule.java
index c37c71fe4c4..3914bc66e62 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/TimestampToTimeCastRule.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/casting/TimestampToTimeCastRule.java
@@ -22,11 +22,8 @@ import org.apache.flink.table.data.TimestampData;
 import org.apache.flink.table.planner.codegen.calls.BuiltInMethods;
 import org.apache.flink.table.types.logical.LogicalType;
 import org.apache.flink.table.types.logical.LogicalTypeRoot;
-import org.apache.flink.table.utils.DateTimeUtils;
+import org.apache.flink.table.types.logical.utils.LogicalTypeChecks;
 
-import static org.apache.flink.table.planner.functions.casting.CastRuleUtils.cast;
-import static org.apache.flink.table.planner.functions.casting.CastRuleUtils.methodCall;
-import static org.apache.flink.table.planner.functions.casting.CastRuleUtils.operator;
 import static org.apache.flink.table.planner.functions.casting.CastRuleUtils.staticCall;
 
 /**
@@ -54,21 +51,20 @@ class TimestampToTimeCastRule
             String inputTerm,
             LogicalType inputLogicalType,
             LogicalType targetLogicalType) {
+        final int targetPrecision = LogicalTypeChecks.getPrecision(targetLogicalType);
 
         if (inputLogicalType.is(LogicalTypeRoot.TIMESTAMP_WITHOUT_TIME_ZONE)) {
-            return cast(
-                    "int",
-                    operator(
-                            methodCall(inputTerm, "getMillisecond"),
-                            "%",
-                            DateTimeUtils.MILLIS_PER_DAY));
+            return staticCall(
+                    BuiltInMethods.TIMESTAMP_WITHOUT_LOCAL_TIME_ZONE_TO_TIME(),
+                    inputTerm,
+                    targetPrecision);
         } else if (inputLogicalType.is(LogicalTypeRoot.TIMESTAMP_WITH_LOCAL_TIME_ZONE)) {
             return staticCall(
                     BuiltInMethods.TIMESTAMP_WITH_LOCAL_TIME_ZONE_TO_TIME(),
                     inputTerm,
-                    context.getSessionTimeZoneTerm());
-        } else {
-            throw new IllegalArgumentException("This is a bug. Please file an issue.");
+                    context.getSessionTimeZoneTerm(),
+                    targetPrecision);
         }
+        throw new IllegalArgumentException("This is a bug. Please file an issue.");
     }
 }
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala
index 342440e77a6..61e5d66971f 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala
@@ -22,7 +22,6 @@ import org.apache.flink.api.common.serialization.SerializerConfigImpl
 import org.apache.flink.core.memory.MemorySegment
 import org.apache.flink.table.data._
 import org.apache.flink.table.data.binary._
-import org.apache.flink.table.data.binary.BinaryRowDataUtil.BYTE_ARRAY_BASE_OFFSET
 import org.apache.flink.table.data.util.DataFormatConverters
 import org.apache.flink.table.data.util.DataFormatConverters.IdentityConverter
 import org.apache.flink.table.data.utils.JoinedRowData
@@ -194,12 +193,13 @@ object CodeGenUtils {
     name
   }
 
-  // when casting we first need to unbox Primitives, for example,
-  // float a = 1.0f;
-  // byte b = (byte) a;
-  // works, but for boxed types we need this:
-  // Float a = 1.0f;
-  // Byte b = (byte)(float) a;
+  /**
+   * Returns the primitive Java type name for a given logical type.
+   *
+   * <p>For primitive logical types, returns the corresponding Java primitive type name (e.g.,
+   * "byte", "short", "int", "long", "float", "double", "boolean"). For non-primitive types, falls
+   * back to [[boxedTypeTermForType]].
+   */
   @tailrec
   def primitiveTypeTermForType(t: LogicalType): String = t.getTypeRoot match {
     // ordered by type root definition
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala
index be779031a59..e434e5ee989 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/BuiltInMethods.scala
@@ -340,11 +340,18 @@ object BuiltInMethods {
     classOf[TimestampData],
     classOf[TimeZone])
 
+  val TIMESTAMP_WITHOUT_LOCAL_TIME_ZONE_TO_TIME = Types.lookupMethod(
+    classOf[DateTimeUtils],
+    "timestampWithoutLocalZoneToTime",
+    classOf[TimestampData],
+    classOf[Int])
+
   val TIMESTAMP_WITH_LOCAL_TIME_ZONE_TO_TIME = Types.lookupMethod(
     classOf[DateTimeUtils],
     "timestampWithLocalZoneToTime",
     classOf[TimestampData],
-    classOf[TimeZone])
+    classOf[TimeZone],
+    classOf[Int])
 
   val DATE_TO_TIMESTAMP_WITH_LOCAL_TIME_ZONE = Types.lookupMethod(
     classOf[DateTimeUtils],
@@ -536,7 +543,11 @@ object BuiltInMethods {
     Types.lookupMethod(classOf[BinaryStringDataUtil], "toDate", classOf[BinaryStringData])
 
   val STRING_DATA_TO_TIME =
-    Types.lookupMethod(classOf[BinaryStringDataUtil], "toTime", classOf[BinaryStringData])
+    Types.lookupMethod(
+      classOf[BinaryStringDataUtil],
+      "toTime",
+      classOf[BinaryStringData],
+      classOf[Int])
 
   val STRING_DATA_TO_TIMESTAMP = Types.lookupMethod(
     classOf[BinaryStringDataUtil],
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/JsonCallGen.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/JsonCallGen.scala
index 5b90a636e1b..8d9d26ef7bb 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/JsonCallGen.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/JsonCallGen.scala
@@ -35,8 +35,13 @@ class JsonCallGen extends CallGenerator {
 
     val resultCode =
       s"""
-         |Object $rawResultTerm =
-         |    ${qualifyMethod(BuiltInMethods.JSON)}(${stringArg.resultTerm}.toString());
+         |${stringArg.code}
+         |Object $rawResultTerm;
+         |if (${stringArg.nullTerm}) {
+         |  $rawResultTerm = null;
+         |} else {
+         |  $rawResultTerm = ${qualifyMethod(BuiltInMethods.JSON)}(${stringArg.resultTerm}.toString());
+         |}
          |$nullTerm = $rawResultTerm == null;
          |$resultTerm = $BINARY_STRING.fromString(java.lang.String.valueOf($rawResultTerm));
          |""".stripMargin
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala
index a82eeb7280e..7a1dcd04739 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/calls/ScalarOperatorGens.scala
@@ -1155,8 +1155,14 @@ object ScalarOperatorGens {
               element
             } else {
               val tpe = fieldTypes(idx)
-              val resultTerm = primitiveDefaultValue(tpe)
-              GeneratedExpression(resultTerm, ALWAYS_NULL, NO_CODE, tpe, Some(null))
+              val defaultValue = primitiveDefaultValue(tpe)
+              val resultTypeTerm = primitiveTypeTermForType(tpe)
+              GeneratedExpression(
+                s"(($resultTypeTerm) $defaultValue)",
+                ALWAYS_NULL,
+                NO_CODE,
+                tpe,
+                Some(null))
             }
         }
         val row = generateLiteralRow(ctx, rowType, mapped)
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/BuiltInFunctionTestBase.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/BuiltInFunctionTestBase.java
index 2bafcc59f09..29a1cb0aca7 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/BuiltInFunctionTestBase.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/BuiltInFunctionTestBase.java
@@ -32,10 +32,12 @@ import org.apache.flink.table.catalog.DataTypeFactory;
 import org.apache.flink.table.expressions.DefaultSqlFactory;
 import org.apache.flink.table.expressions.Expression;
 import org.apache.flink.table.functions.BuiltInFunctionDefinition;
+import org.apache.flink.table.functions.ScalarFunction;
 import org.apache.flink.table.functions.UserDefinedFunction;
 import org.apache.flink.table.operations.ProjectQueryOperation;
 import org.apache.flink.table.types.AbstractDataType;
 import org.apache.flink.table.types.DataType;
+import org.apache.flink.table.types.inference.TypeInference;
 import org.apache.flink.test.junit5.InjectMiniCluster;
 import org.apache.flink.test.junit5.MiniClusterExtension;
 import org.apache.flink.types.Row;
@@ -64,6 +66,8 @@ import java.util.stream.Stream;
 import static java.util.Collections.emptyList;
 import static java.util.Collections.singletonList;
 import static org.apache.flink.core.testutils.FlinkAssertions.anyCauseMatches;
+import static org.apache.flink.table.api.Expressions.$;
+import static org.apache.flink.table.api.Expressions.call;
 import static org.apache.flink.table.api.Expressions.row;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
@@ -151,41 +155,98 @@ abstract class BuiltInFunctionTestBase {
 
         private @Nullable AbstractDataType<?>[] fieldDataTypes;
 
-        private TestSetSpec(BuiltInFunctionDefinition definition, @Nullable String description) {
+        private boolean supportsConstantFolding = false;
+
+        private TestSetSpec(
+                @Nullable BuiltInFunctionDefinition definition, @Nullable String description) {
             this.definition = definition;
             this.description = description;
             this.functions = new ArrayList<>();
             this.testItems = new ArrayList<>();
         }
 
+        /**
+         * Creates a new test specification for a built-in function.
+         *
+         * <p>The function definition is used for test organization and readability only. It does
+         * not affect test execution behavior, which is determined by the actual test methods like
+         * {@link #testSqlResult} or {@link #testTableApiResult}.
+         */
         static TestSetSpec forFunction(BuiltInFunctionDefinition definition) {
             return forFunction(definition, null);
         }
 
+        /**
+         * Creates a new test specification for a built-in function with description.
+         *
+         * <p>Both the function definition and description are used for test organization and
+         * readability only. They help identify what is being tested but do not affect the actual
+         * test execution behavior.
+         */
         static TestSetSpec forFunction(BuiltInFunctionDefinition definition, String description) {
             return new TestSetSpec(Preconditions.checkNotNull(definition), description);
         }
 
+        /**
+         * Creates a new test specification for arbitrary expressions.
+         *
+         * <p>The description is used for test organization and readability only. It helps identify
+         * what is being tested but does not affect the actual test execution behavior.
+         */
         static TestSetSpec forExpression(String description) {
             return new TestSetSpec(null, Preconditions.checkNotNull(description));
         }
 
+        /**
+         * Sets the field data for creating an input table.
+         *
+         * <p>If called with arguments, creates an input table with the provided data as a single
+         * row. SQL queries will include {@code FROM <inputTable>}. If called with no arguments or
+         * not called, no input table is created and SQL queries run as standalone expressions.
+         */
         TestSetSpec onFieldsWithData(Object... fieldData) {
             this.fieldData = fieldData;
             return this;
         }
 
+        /**
+         * Sets the data types for the input table fields.
+         *
+         * <p>Must be used together with {@link #onFieldsWithData(Object...)}. The number of data
+         * types should match the number of field data values. When used, constant folding is
+         * disabled to force runtime code generation paths.
+         */
         TestSetSpec andDataTypes(AbstractDataType<?>... fieldDataType) {
             this.fieldDataTypes = fieldDataType;
             return this;
         }
 
+        /**
+         * Registers a user-defined function under the class simple name for use in test
+         * expressions.
+         */
         TestSetSpec withFunction(Class<? extends UserDefinedFunction> functionClass) {
-            // the function will be registered under the class simple name
             this.functions.add(functionClass);
             return this;
         }
 
+        /**
+         * Enables constant folding for this test set.
+         *
+         * <p>When enabled, expressions can be optimized by the optimizer at compile time, allowing
+         * constants to be folded. This is useful for testing the optimizer's behavior with constant
+         * expressions.
+         *
+         * <p>When disabled (default), field accesses are wrapped with {@link IdentityFunction} to
+         * force runtime code generation and prevent constant folding.
+         *
+         * @see IdentityFunction
+         */
+        TestSetSpec withConstantFoldingEnabled() {
+            this.supportsConstantFolding = true;
+            return this;
+        }
+
         TestSetSpec testTableApiResult(
                 Expression expression, Object result, AbstractDataType<?> dataType) {
             return testTableApiResult(
@@ -271,6 +332,7 @@ abstract class BuiltInFunctionTestBase {
             return this;
         }
 
+        /** Tests both Table API and SQL expressions expecting successful results. */
         TestSetSpec testResult(
                 Expression expression,
                 String sqlExpression,
@@ -279,6 +341,7 @@ abstract class BuiltInFunctionTestBase {
             return testResult(expression, sqlExpression, result, dataType, dataType);
         }
 
+        /** Tests both Table API and SQL expressions expecting successful results. */
         TestSetSpec testResult(ResultSpec... resultSpecs) {
             final int cols = resultSpecs.length;
             final List<Expression> expressions = new ArrayList<>(cols);
@@ -298,6 +361,7 @@ abstract class BuiltInFunctionTestBase {
                     expressions, sqlExpressions, results, tableApiDataTypes, sqlDataTypes);
         }
 
+        /** Tests both Table API and SQL expressions expecting successful results. */
         TestSetSpec testResult(
                 Expression expression,
                 String sqlExpression,
@@ -312,6 +376,7 @@ abstract class BuiltInFunctionTestBase {
                     singletonList(sqlDataType));
         }
 
+        /** Tests both Table API and SQL expressions expecting successful results. */
         TestSetSpec testResult(
                 List<Expression> expression,
                 List<String> sqlExpression,
@@ -325,6 +390,7 @@ abstract class BuiltInFunctionTestBase {
             return this;
         }
 
+        /** Generates test cases from this specification. */
         Stream<TestCase> getTestCases(Configuration configuration) {
             return testItems.stream().map(testItem -> getTestCase(configuration, testItem));
         }
@@ -358,7 +424,28 @@ abstract class BuiltInFunctionTestBase {
                                                             DataTypes.FIELD(
                                                                     "f" + i, fieldDataTypes[i]))
                                             .toArray(DataTypes.UnresolvedField[]::new);
-                            inputTable = env.fromValues(DataTypes.ROW(fields), Row.of(fieldData));
+
+                            final Expression[] expressions =
+                                    IntStream.range(0, fieldDataTypes.length)
+                                            .mapToObj(i -> $(fields[i].getName()))
+                                            .toArray(Expression[]::new);
+
+                            final Expression[] aliasedExpressions =
+                                    IntStream.range(0, expressions.length)
+                                            .mapToObj(
+                                                    i ->
+                                                            call(
+                                                                            IdentityFunction.class,
+                                                                            expressions[i])
+                                                                    .as(fields[i].getName()))
+                                            .toArray(Expression[]::new);
+
+                            final Table table =
+                                    env.fromValues(DataTypes.ROW(fields), Row.of(fieldData));
+                            inputTable =
+                                    this.supportsConstantFolding
+                                            ? table
+                                            : table.select(aliasedExpressions);
                         }
 
                         testItem.test(env, inputTable, clusterClient);
@@ -685,4 +772,23 @@ abstract class BuiltInFunctionTestBase {
         return new ResultSpec(
                 tableApiExpression, sqlExpression, result, tableApiDataType, sqlQueryDataType);
     }
+
+    /** Identity function that forces the planner to skip constant folding. */
+    public static class IdentityFunction extends ScalarFunction {
+        public Object eval(Object input) {
+            return input;
+        }
+
+        @Override
+        public TypeInference getTypeInference(final DataTypeFactory typeFactory) {
+            return TypeInference.newBuilder()
+                    .outputTypeStrategy(c -> Optional.of(c.getArgumentDataTypes().get(0)))
+                    .build();
+        }
+
+        @Override
+        public boolean supportsConstantFolding() {
+            return false;
+        }
+    }
 }
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/CastFunctionITCase.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/CastFunctionITCase.java
index be0fd373d69..a5b31c0dbac 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/CastFunctionITCase.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/CastFunctionITCase.java
@@ -551,7 +551,7 @@ public class CastFunctionITCase extends BuiltInFunctionTestBase {
                         .failRuntime(STRING(), "Apache", NumberFormatException.class)
                         .fromCase(STRING(), "1.234", 1.234f)
                         .fromCase(STRING(), "123", 123.0f)
-                        .fromCase(STRING(), "-3276913443134", -3.27691403E12f)
+                        .fromCase(STRING(), "-3276913443134", -3.27691351E12f)
                         .fromCase(BOOLEAN(), true, 1.0f)
                         .fromCase(BOOLEAN(), false, 0.0f)
                         // Not supported - no fix
@@ -649,9 +649,9 @@ public class CastFunctionITCase extends BuiltInFunctionTestBase {
                                 BIGINT(), DEFAULT_POSITIVE_BIGINT, (double) DEFAULT_POSITIVE_BIGINT)
                         .fromCase(
                                 BIGINT(), DEFAULT_NEGATIVE_BIGINT, (double) DEFAULT_NEGATIVE_BIGINT)
-                        .fromCase(FLOAT(), DEFAULT_POSITIVE_FLOAT, 123.456d)
-                        .fromCase(FLOAT(), DEFAULT_NEGATIVE_FLOAT, -123.456)
-                        .fromCase(FLOAT(), 9234567891.12, 9234567891.12d)
+                        .fromCase(FLOAT(), DEFAULT_POSITIVE_FLOAT, 123.45600128173828d)
+                        .fromCase(FLOAT(), DEFAULT_NEGATIVE_FLOAT, -123.45600128173828d)
+                        .fromCase(FLOAT(), 9234567891.12, 9.234568192E9)
                         .fromCase(DOUBLE(), DEFAULT_POSITIVE_DOUBLE, DEFAULT_POSITIVE_DOUBLE)
                         .fromCase(DOUBLE(), DEFAULT_NEGATIVE_DOUBLE, DEFAULT_NEGATIVE_DOUBLE)
                         .fromCase(DOUBLE(), 1239234567891.1234567891234, 1.2392345678911235E12d)
@@ -720,12 +720,14 @@ public class CastFunctionITCase extends BuiltInFunctionTestBase {
                         .failRuntime(CHAR(3), "foo", DateTimeException.class)
                         .failRuntime(VARCHAR(5), "Flink", DateTimeException.class)
                         .failRuntime(STRING(), "Flink", DateTimeException.class)
-                        .fromCase(STRING(), "123", LocalTime.of(23, 0, 0))
-                        .fromCase(STRING(), "123:45", LocalTime.of(23, 45, 0))
+                        .failRuntime(STRING(), "123", DateTimeException.class)
+                        .failRuntime(STRING(), "123:45", DateTimeException.class)
                         .failRuntime(STRING(), "2021-09-27", DateTimeException.class)
                         .failRuntime(STRING(), "2021-09-27 12:34:56", DateTimeException.class)
                         // https://issues.apache.org/jira/browse/FLINK-17224 Fractional seconds are
                         // lost
+                        .fromCase(STRING(), "23", LocalTime.of(23, 0, 0, 0))
+                        .fromCase(STRING(), "23:45", LocalTime.of(23, 45, 0, 0))
                         .fromCase(STRING(), "12:34:56.123456789", LocalTime.of(12, 34, 56, 0))
                         .failRuntime(
                                 STRING(), "2021-09-27 12:34:56.123456789", DateTimeException.class)
@@ -742,7 +744,6 @@ public class CastFunctionITCase extends BuiltInFunctionTestBase {
                         .failValidation(FLOAT(), DEFAULT_POSITIVE_FLOAT)
                         .failValidation(DOUBLE(), DEFAULT_POSITIVE_DOUBLE)
                         .failValidation(DATE(), DEFAULT_DATE)
-                        //
                         .fromCase(TIME(5), DEFAULT_TIME, LocalTime.of(12, 34, 56, 0))
                         .fromCase(TIMESTAMP(), DEFAULT_TIMESTAMP, LocalTime.of(12, 34, 56, 0))
                         .fromCase(TIMESTAMP(4), DEFAULT_TIMESTAMP, LocalTime.of(12, 34, 56, 0))
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/RowFunctionITCase.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/RowFunctionITCase.java
index b9530aa101b..4e41f24a31a 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/RowFunctionITCase.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/RowFunctionITCase.java
@@ -80,6 +80,41 @@ class RowFunctionITCase extends BuiltInFunctionTestBase {
                                 DataTypes.ROW(
                                                 DataTypes.FIELD("i", DataTypes.INT()),
                                                 DataTypes.FIELD("s", DataTypes.STRING()))
+                                        .notNull()),
+                TestSetSpec.forFunction(BuiltInFunctionDefinitions.ROW, "cast row inputs")
+                        .onFieldsWithData(1, 2, 3, "true")
+                        .andDataTypes(
+                                DataTypes.INT(),
+                                DataTypes.INT(),
+                                DataTypes.INT(),
+                                DataTypes.STRING())
+                        .testResult(
+                                row(
+                                                $("f0").cast(DataTypes.SMALLINT().notNull()),
+                                                $("f1").cast(DataTypes.TINYINT().notNull()),
+                                                $("f2").cast(DataTypes.BIGINT().notNull()),
+                                                $("f3").cast(DataTypes.BOOLEAN().notNull()))
+                                        .cast(
+                                                DataTypes.ROW(
+                                                                DataTypes.FIELD(
+                                                                        "a", DataTypes.SMALLINT()),
+                                                                DataTypes.FIELD(
+                                                                        "b", DataTypes.TINYINT()),
+                                                                DataTypes.FIELD(
+                                                                        "c", DataTypes.BIGINT()),
+                                                                DataTypes.FIELD(
+                                                                        "d", DataTypes.BOOLEAN()))
+                                                        .notNull()),
+                                "CAST("
+                                        + "ROW("
+                                        + "CAST(f0 AS SMALLINT), CAST(f1 AS TINYINT), CAST(f2 AS BIGINT), CAST(f3 AS BOOLEAN)"
+                                        + ") AS ROW<a SMALLINT, b TINYINT, c BIGINT, d BOOLEAN>)",
+                                Row.of((short) 1, (byte) 2, 3L, true),
+                                DataTypes.ROW(
+                                                DataTypes.FIELD("a", DataTypes.SMALLINT()),
+                                                DataTypes.FIELD("b", DataTypes.TINYINT()),
+                                                DataTypes.FIELD("c", DataTypes.BIGINT()),
+                                                DataTypes.FIELD("d", DataTypes.BOOLEAN()))
                                         .notNull()));
     }
 
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/casting/CastRulesTest.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/casting/CastRulesTest.java
index c6d634577ca..768736d4c63 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/casting/CastRulesTest.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/casting/CastRulesTest.java
@@ -480,7 +480,7 @@ class CastRulesTest {
                         .fromCase(
                                 STRING(),
                                 fromString("12:34:56.123456789"),
-                                DateTimeUtils.toInternal(LocalTime.of(12, 34, 56, 123_000_000)))
+                                DateTimeUtils.toInternal(LocalTime.of(12, 34, 56, 0)))
                         .fail(
                                 STRING(),
                                 fromString("2021-09-27 12:34:56.123456789"),
@@ -488,11 +488,11 @@ class CastRulesTest {
                         .fromCase(
                                 TIMESTAMP(6),
                                 TIMESTAMP,
-                                DateTimeUtils.toInternal(LocalTime.of(12, 34, 56, 123_000_000)))
+                                DateTimeUtils.toInternal(LocalTime.of(12, 34, 56, 0)))
                         .fromCase(
                                 TIMESTAMP_LTZ(8),
                                 TIMESTAMP_LTZ,
-                                DateTimeUtils.toInternal(LocalTime.of(11, 34, 56, 123_000_000))),
+                                DateTimeUtils.toInternal(LocalTime.of(11, 34, 56, 0))),
                 CastTestSpecBuilder.testCastTo(TIMESTAMP(9))
                         .fail(CHAR(3), fromString("foo"), TableRuntimeException.class)
                         .fail(VARCHAR(5), fromString("Flink"), TableRuntimeException.class)
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/codegen/CodeGenUtilsTest.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/codegen/CodeGenUtilsTest.scala
index f6ac2704732..1df21ef523c 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/codegen/CodeGenUtilsTest.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/codegen/CodeGenUtilsTest.scala
@@ -17,18 +17,25 @@
  */
 package org.apache.flink.table.planner.codegen
 
+import org.apache.flink.api.common.typeutils.base.VoidSerializer
 import org.apache.flink.configuration.Configuration
+import org.apache.flink.table.catalog.ObjectIdentifier
+import org.apache.flink.table.types.logical._
 
 import org.junit.jupiter.api.Assertions.assertEquals
 import org.junit.jupiter.api.Test
+import org.junit.jupiter.params.ParameterizedTest
+import org.junit.jupiter.params.provider.{Arguments, MethodSource}
+
+import java.util.stream
 
 import scala.collection.mutable.ArrayBuffer
 
 class CodeGenUtilsTest {
-  private val classLoader = Thread.currentThread().getContextClassLoader
 
   @Test
   def testNewName(): Unit = {
+    val classLoader = Thread.currentThread().getContextClassLoader
     // Use name counter in CodeGenUtils.
     assertEquals("name$i0", CodeGenUtils.newName(null, "name"))
     assertEquals("name$i1", CodeGenUtils.newName(null, "name"))
@@ -58,4 +65,98 @@ class CodeGenUtilsTest {
     assertEquals(ArrayBuffer("name$7", "id$7"), CodeGenUtils.newNames(context4, "name", "id"))
     assertEquals(ArrayBuffer("name$8", "id$8"), CodeGenUtils.newNames(context4, "name", "id"))
   }
+
+  @ParameterizedTest
+  @MethodSource(Array("basicTypesTestData"))
+  def testPrimitiveDefaultValueForBasicTypes(
+      logicalType: LogicalType,
+      expectedDefault: String): Unit = {
+    assertEquals(expectedDefault, CodeGenUtils.primitiveDefaultValue(logicalType))
+  }
+
+  @ParameterizedTest
+  @MethodSource(Array("distinctTypeTestData"))
+  def testPrimitiveDefaultValueForDistinctType(
+      distinctType: DistinctType,
+      expectedDefault: String): Unit = {
+    assertEquals(expectedDefault, CodeGenUtils.primitiveDefaultValue(distinctType))
+  }
+
+}
+
+object CodeGenUtilsTest {
+
+  @MethodSource
+  def basicTypesTestData(): stream.Stream[Arguments] = {
+    java.util.stream.Stream.of(
+      // Basic primitive types
+      Arguments.of(new BooleanType(), "false"),
+      Arguments.of(new TinyIntType(), "-1"),
+      Arguments.of(new SmallIntType(), "-1"),
+      Arguments.of(new IntType(), "-1"),
+      Arguments.of(new BigIntType(), "-1L"),
+      Arguments.of(new FloatType(), "-1.0f"),
+      Arguments.of(new DoubleType(), "-1.0d"),
+
+      // Date/time types that map to int/long
+      Arguments.of(new DateType(), "-1"),
+      Arguments.of(new TimeType(), "-1"),
+      Arguments.of(new LocalZonedTimestampType(3), "null"),
+      Arguments.of(new TimestampType(3), "null"),
+
+      // Interval types
+      Arguments.of(
+        new YearMonthIntervalType(YearMonthIntervalType.YearMonthResolution.YEAR_TO_MONTH),
+        "-1"),
+      Arguments.of(
+        new DayTimeIntervalType(DayTimeIntervalType.DayTimeResolution.DAY_TO_SECOND),
+        "-1L"),
+
+      // String types
+      Arguments.of(new VarCharType(100), s"${CodeGenUtils.BINARY_STRING}.EMPTY_UTF8"),
+      Arguments.of(new CharType(10), s"${CodeGenUtils.BINARY_STRING}.EMPTY_UTF8"),
+
+      // Complex types that should return "null"
+      Arguments.of(new ArrayType(new IntType()), "null"),
+      Arguments.of(new MapType(new IntType(), new VarCharType()), "null"),
+      Arguments.of(RowType.of(new IntType(), new VarCharType()), "null"),
+      Arguments.of(new DecimalType(10, 2), "null"),
+      Arguments.of(new BinaryType(10), "null"),
+      Arguments.of(new VarBinaryType(100), "null"),
+      Arguments.of(new RawType(classOf[Void], VoidSerializer.INSTANCE), "null")
+    )
+  }
+
+  @MethodSource
+  def distinctTypeTestData(): stream.Stream[Arguments] = {
+    val objectIdentifier = ObjectIdentifier.of("catalog", "database", "distinct_type")
+    java.util.stream.Stream.of(
+      // Distinct types based on basic types
+      Arguments.of(
+        DistinctType
+          .newBuilder(objectIdentifier, new IntType())
+          .build(),
+        "-1"),
+      Arguments.of(
+        DistinctType
+          .newBuilder(objectIdentifier, new SmallIntType())
+          .build(),
+        "-1"),
+      Arguments.of(
+        DistinctType
+          .newBuilder(objectIdentifier, new TinyIntType())
+          .build(),
+        "-1"),
+      Arguments.of(
+        DistinctType
+          .newBuilder(objectIdentifier, new BigIntType())
+          .build(),
+        "-1L"),
+      Arguments.of(
+        DistinctType
+          .newBuilder(objectIdentifier, new BooleanType())
+          .build(),
+        "false")
+    )
+  }
 }
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/OverAggregateITCase.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/OverAggregateITCase.scala
index a02236f687c..b08a944b571 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/OverAggregateITCase.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/OverAggregateITCase.scala
@@ -1222,7 +1222,7 @@ class OverAggregateITCase extends BatchTestBase {
           3.14,
           "EFG",
           localDate("2017-05-20"),
-          localTime("09:46:18"),
+          localTime("09:45:58"),
           localDateTime("2015-11-19 10:00:01"),
           3,
           2,
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/utils/TestData.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/utils/TestData.scala
index 629b6b1aa6f..1b9e8ba2b7e 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/utils/TestData.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/utils/TestData.scala
@@ -473,7 +473,7 @@ object TestData {
       3.14,
       "EFG",
       localDate("2017-05-20"),
-      localTime("09:45:78"),
+      localTime("09:45:58"),
       localDateTime("2015-11-19 10:00:01")),
     row(
       4,
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/data/binary/BinaryStringDataUtil.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/data/binary/BinaryStringDataUtil.java
index 1cfdf939700..496d0dad508 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/data/binary/BinaryStringDataUtil.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/data/binary/BinaryStringDataUtil.java
@@ -594,13 +594,16 @@ public class BinaryStringDataUtil {
         return date;
     }
 
-    public static int toTime(BinaryStringData input) throws DateTimeException {
-        Integer date = DateTimeUtils.parseTime(input.toString());
-        if (date == null) {
-            throw new DateTimeException("For input string: '" + input + "'.");
-        }
-
-        return date;
+    public static int toTime(BinaryStringData input, int precision) throws DateTimeException {
+        Integer milliSeconds = DateTimeUtils.parseTime(input.toString());
+        if (milliSeconds == null) {
+            throw new DateTimeException(
+                    "Invalid time format: '"
+                            + input
+                            + "'. "
+                            + "Expected format: HH:mm:ss[.fff] where HH is 00-23, mm is 00-59, ss is 00-59");
+        }
+        return DateTimeUtils.applyTimePrecisionTruncation(milliSeconds, precision);
     }
 
     /** Used by {@code CAST(x as TIMESTAMP)}. */
