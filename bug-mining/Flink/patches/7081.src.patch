diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/agg/AggregateITCaseBase.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/agg/AggregateITCaseBase.scala
index 556f09eba54..5339396b9c8 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/agg/AggregateITCaseBase.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/agg/AggregateITCaseBase.scala
@@ -1184,6 +1184,34 @@ abstract class AggregateITCaseBase(testName: String) extends BatchTestBase {
     checkResult("select count(*) from src", Seq(row(3)))
   }
 
+  @Test
+  def testLeadAggFunction(): Unit = {
+    val data =
+      List(rowOf(2L, 15, "Hello"), rowOf(8L, 11, "Hello world"), rowOf(9L, 12, "Hello world!"))
+    val dataId = TestValuesTableFactory.registerData(data)
+    tEnv.executeSql(s"""
+                       |CREATE TABLE src(
+                       |  `id` BIGINT,
+                       |  `len` INT NOT NULL,
+                       |  `content` STRING,
+                       |  `proctime` AS PROCTIME()
+                       |) WITH (
+                       |  'connector' = 'values',
+                       |  'bounded' = 'true',
+                       |  'data-id' = '$dataId'
+                       |)
+                       |""".stripMargin)
+    val sql =
+      s"""
+         |select
+         |  LEAD(len) OVER w AS prev_quantity,
+         |  LEAD(len, 1, cast(null as int)) OVER w AS prev_quantity
+         |from src
+         |WINDOW w AS (ORDER BY proctime)
+         |""".stripMargin
+    checkResult(sql, Seq(row("11, 11"), row("12, 12"), row("null, null")))
+  }
+
   // TODO support csv
 //  @Test
 //  def testMultiGroupBys(): Unit = {
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/AggregateITCase.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/AggregateITCase.scala
index 81fa9674e58..c3ad4d938aa 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/AggregateITCase.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/AggregateITCase.scala
@@ -1765,4 +1765,35 @@ class AggregateITCase(aggMode: AggMode, miniBatch: MiniBatchMode, backend: State
     val expected = List("3")
     assertEquals(expected.sorted, sink.getRetractResults.sorted)
   }
+
+  @Test
+  def testLagAggFunction(): Unit = {
+    val data =
+      List(rowOf(2L, 15, "Hello"), rowOf(8L, 11, "Hello world"), rowOf(9L, 12, "Hello world!"))
+    val dataId = TestValuesTableFactory.registerData(data)
+    tEnv.executeSql(s"""
+                       |CREATE TABLE src(
+                       |  `id` BIGINT,
+                       |  `len` INT NOT NULL,
+                       |  `content` STRING,
+                       |  `proctime` AS PROCTIME()
+                       |) WITH (
+                       |  'connector' = 'values',
+                       |  'data-id' = '$dataId'
+                       |)
+                       |""".stripMargin)
+    val sink = new TestingRetractSink
+    val sql =
+      s"""
+         |select
+         |  LAG(len, 1, cast(null as int)) OVER w AS prev_quantity,
+         |  LAG(len) OVER w AS prev_quantity
+         |from src
+         |WINDOW w AS (ORDER BY proctime)
+         |""".stripMargin
+    tEnv.sqlQuery(sql).toRetractStream[Row].addSink(sink).setParallelism(1)
+    env.execute()
+    val expected = List("null,null", "15,15", "11,11")
+    assertEquals(expected, sink.getRetractResults)
+  }
 }
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/aggregate/LagAggFunction.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/aggregate/LagAggFunction.java
index da873d87217..6a611c14dc0 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/aggregate/LagAggFunction.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/aggregate/LagAggFunction.java
@@ -44,6 +44,15 @@ public class LagAggFunction<T> extends BuiltInAggregateFunction<T, LagAggFunctio
                 Arrays.stream(valueTypes)
                         .map(DataTypeUtils::toInternalDataType)
                         .toArray(DataType[]::new);
+        // The output value can only be not null if the default input arguments include a non-null
+        // default value.
+        if (!valueDataTypes[0].getLogicalType().isNullable()) {
+            if (valueDataTypes.length < 3
+                    || (valueDataTypes.length == 3
+                            && valueDataTypes[2].getLogicalType().isNullable())) {
+                valueDataTypes[0] = valueDataTypes[0].nullable();
+            }
+        }
         if (valueDataTypes.length == 3
                 && valueDataTypes[2].getLogicalType().getTypeRoot() != LogicalTypeRoot.NULL) {
             if (valueDataTypes[0].getConversionClass() != valueDataTypes[2].getConversionClass()) {
