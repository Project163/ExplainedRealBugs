diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java
index d1438eb8de5..2418b8321d3 100644
--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java
+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java
@@ -297,10 +297,10 @@ public class AvroSchemaConverter {
 	 * @return Avro's {@link Schema} matching this logical type.
 	 */
 	public static Schema convertToSchema(LogicalType logicalType) {
-		return convertToSchema(logicalType, 0);
+		return convertToSchema(logicalType, "record");
 	}
 
-	public static Schema convertToSchema(LogicalType logicalType, int rowTypeCounter) {
+	public static Schema convertToSchema(LogicalType logicalType, String rowName) {
 		int precision;
 		switch (logicalType.getTypeRoot()) {
 			case NULL:
@@ -359,13 +359,13 @@ public class AvroSchemaConverter {
 				// we have to make sure the record name is different in a Schema
 				SchemaBuilder.FieldAssembler<Schema> builder = SchemaBuilder
 					.builder()
-					.record("row_" + rowTypeCounter)
+					.record(rowName)
 					.fields();
-				rowTypeCounter++;
 				for (int i = 0; i < rowType.getFieldCount(); i++) {
+					String fieldName = rowName + "_" + fieldNames.get(i);
 					builder = builder
-						.name(fieldNames.get(i))
-						.type(convertToSchema(rowType.getTypeAt(i), rowTypeCounter))
+						.name(fieldName)
+						.type(convertToSchema(rowType.getTypeAt(i), fieldName))
 						.noDefault();
 				}
 				return builder.endRecord();
@@ -375,14 +375,14 @@ public class AvroSchemaConverter {
 					.builder()
 					.nullable()
 					.map()
-					.values(convertToSchema(extractValueTypeToAvroMap(logicalType), rowTypeCounter));
+					.values(convertToSchema(extractValueTypeToAvroMap(logicalType), rowName));
 			case ARRAY:
 				ArrayType arrayType = (ArrayType) logicalType;
 				return SchemaBuilder
 					.builder()
 					.nullable()
 					.array()
-					.items(convertToSchema(arrayType.getElementType(), rowTypeCounter));
+					.items(convertToSchema(arrayType.getElementType(), rowName));
 			case RAW:
 			case TIMESTAMP_WITH_LOCAL_TIME_ZONE:
 			default:
diff --git a/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java b/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java
index c1cada72b43..cfcb309f2c2 100644
--- a/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java
+++ b/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java
@@ -28,6 +28,7 @@ import org.apache.flink.table.types.DataType;
 import org.apache.flink.table.types.logical.RowType;
 import org.apache.flink.types.Row;
 
+import org.apache.avro.Schema;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.ExpectedException;
@@ -94,6 +95,59 @@ public class AvroSchemaConverterTest {
 		AvroSchemaConverter.convertToSchema(rowType);
 	}
 
+	@Test
+	public void testRowTypeAvroSchemaConversion() {
+		RowType rowType = (RowType) TableSchema.builder()
+			.field("row1", DataTypes.ROW(DataTypes.FIELD("a", DataTypes.STRING())))
+			.field("row2", DataTypes.ROW(DataTypes.FIELD("b", DataTypes.STRING())))
+			.field("row3", DataTypes.ROW(
+				DataTypes.FIELD("row3", DataTypes.ROW(DataTypes.FIELD("c", DataTypes.STRING())))))
+			.build().toRowDataType().getLogicalType();
+		Schema schema = AvroSchemaConverter.convertToSchema(rowType);
+		assertEquals("{\n" +
+			"  \"type\" : \"record\",\n" +
+			"  \"name\" : \"record\",\n" +
+			"  \"fields\" : [ {\n" +
+			"    \"name\" : \"record_row1\",\n" +
+			"    \"type\" : {\n" +
+			"      \"type\" : \"record\",\n" +
+			"      \"name\" : \"record_row1\",\n" +
+			"      \"fields\" : [ {\n" +
+			"        \"name\" : \"record_row1_a\",\n" +
+			"        \"type\" : [ \"string\", \"null\" ]\n" +
+			"      } ]\n" +
+			"    }\n" +
+			"  }, {\n" +
+			"    \"name\" : \"record_row2\",\n" +
+			"    \"type\" : {\n" +
+			"      \"type\" : \"record\",\n" +
+			"      \"name\" : \"record_row2\",\n" +
+			"      \"fields\" : [ {\n" +
+			"        \"name\" : \"record_row2_b\",\n" +
+			"        \"type\" : [ \"string\", \"null\" ]\n" +
+			"      } ]\n" +
+			"    }\n" +
+			"  }, {\n" +
+			"    \"name\" : \"record_row3\",\n" +
+			"    \"type\" : {\n" +
+			"      \"type\" : \"record\",\n" +
+			"      \"name\" : \"record_row3\",\n" +
+			"      \"fields\" : [ {\n" +
+			"        \"name\" : \"record_row3_row3\",\n" +
+			"        \"type\" : {\n" +
+			"          \"type\" : \"record\",\n" +
+			"          \"name\" : \"record_row3_row3\",\n" +
+			"          \"fields\" : [ {\n" +
+			"            \"name\" : \"record_row3_row3_c\",\n" +
+			"            \"type\" : [ \"string\", \"null\" ]\n" +
+			"          } ]\n" +
+			"        }\n" +
+			"      } ]\n" +
+			"    }\n" +
+			"  } ]\n" +
+			"}", schema.toString(true));
+	}
+
 	private void validateUserSchema(TypeInformation<?> actual) {
 		final TypeInformation<Row> address = Types.ROW_NAMED(
 			new String[]{
