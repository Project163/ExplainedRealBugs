diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java
index f78ea928b78..85c0e8e270d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java
@@ -227,7 +227,15 @@ public class RuntimeEnvironment implements Environment, Runnable {
 			}
 		}
 		catch (Throwable t) {
-			LOG.error("Error during running invokable: " + t.getMessage(), t);
+			String msg;
+
+			if(t.getMessage() != null){
+				msg = "Error during running invokable: " + t.getMessage();
+			} else {
+				msg = "Error during running invokable.";
+			}
+
+			LOG.error(msg, t);
 
 			if (!owner.isCanceledOrFailed()) {
 				// Perform clean up when the task failed and has been not canceled by the user
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
index 1399bce1af2..32a4e373929 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
@@ -31,7 +31,7 @@ import org.apache.flink.runtime.executiongraph.{ExecutionJobVertex, ExecutionGra
 import org.apache.flink.runtime.jobmanager.web.WebInfoServer
 import org.apache.flink.runtime.messages.ArchiveMessages.ArchiveExecutionGraph
 import org.apache.flink.runtime.messages.ExecutionGraphMessages.JobStatusChanged
-import org.apache.flink.runtime.messages.Messages.Acknowledge
+import org.apache.flink.runtime.messages.Messages.{Disconnect, Acknowledge}
 import org.apache.flink.runtime.security.SecurityUtils
 import org.apache.flink.runtime.security.SecurityUtils.FlinkSecuredRunner
 import org.apache.flink.runtime.taskmanager.TaskManager
@@ -112,6 +112,11 @@ class JobManager(val configuration: Configuration,
   override def postStop(): Unit = {
     log.info(s"Stopping job manager ${self.path}.")
 
+    // disconnect the registered task managers
+    instanceManager.getAllRegisteredInstances.asScala.foreach {
+      _.getTaskManager ! Disconnect("JobManager is shutting down")
+    }
+
     archive ! PoisonPill
     profiler.foreach( ref => ref ! PoisonPill )
 
@@ -159,7 +164,6 @@ class JobManager(val configuration: Configuration,
           profiler)
       }
 
-
     case RequestNumberRegisteredTaskManager =>
       sender ! instanceManager.getNumberOfRegisteredTaskManagers
 
@@ -194,8 +198,10 @@ class JobManager(val configuration: Configuration,
           case Some((executionGraph, _)) =>
             val originalSender = sender
             Future {
-              originalSender ! executionGraph.updateState(taskExecutionState)
+              val result = executionGraph.updateState(taskExecutionState)
+              originalSender ! result
             }
+            sender ! true
           case None => log.error("Cannot find execution graph for ID {} to change state to {}.",
             taskExecutionState.getJobID, taskExecutionState.getExecutionState)
             sender ! false
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobmanagerMessages.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobManagerMessages.scala
similarity index 100%
rename from flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobmanagerMessages.scala
rename to flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobManagerMessages.scala
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/Messages.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/Messages.scala
index 4f27761b4d7..91c3b2d9e87 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/Messages.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/Messages.scala
@@ -20,6 +20,16 @@ package org.apache.flink.runtime.messages
 
 object Messages {
 
+  /**
+   * Message to signal the successful reception of another message
+   */
   case object Acknowledge
 
+  /**
+   * Signals that the JobManager/TaskManager shall disconnect from the sender
+   * (TaskManager/JobManager)
+   * @param reason
+   */
+  case class Disconnect(reason: String)
+
 }
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
index c14ebca3626..ae192ce120c 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
@@ -46,7 +46,7 @@ import org.apache.flink.runtime.jobgraph.IntermediateDataSetID
 import org.apache.flink.runtime.jobmanager.JobManager
 import org.apache.flink.runtime.memorymanager.DefaultMemoryManager
 import org.apache.flink.runtime.messages.JobManagerMessages.UpdateTaskExecutionState
-import org.apache.flink.runtime.messages.Messages.Acknowledge
+import org.apache.flink.runtime.messages.Messages.{Disconnect, Acknowledge}
 import org.apache.flink.runtime.messages.RegistrationMessages.{AlreadyRegistered,
 RefuseRegistration, AcknowledgeRegistration, RegisterTaskManager}
 import org.apache.flink.runtime.messages.TaskManagerMessages._
@@ -106,6 +106,7 @@ import scala.collection.JavaConverters._
 
   var registrationDelay = 50 milliseconds
   var registrationDuration = 0 seconds
+  var registrationAttempts: Int = 0
 
   TaskManager.checkTempDirs(tmpDirPaths)
   val ioManager = new IOManagerAsync(tmpDirPaths)
@@ -131,11 +132,9 @@ import scala.collection.JavaConverters._
     log.info(TaskManager.getMemoryUsageStatsAsString(ManagementFactory.getMemoryMXBean))
   }
 
-  var libraryCacheManager: LibraryCacheManager = null
+  var libraryCacheManager: Option[LibraryCacheManager] = None
   var networkEnvironment: Option[NetworkEnvironment] = None
-  var registrationAttempts: Int = 0
-  var registered: Boolean = false
-  var currentJobManager = ActorRef.noSender
+  var currentJobManager: Option[ActorRef] = None
   var profilerListener: Option[ActorRef] = None
   var instanceID: InstanceID = null
   var heartbeatScheduler: Option[Cancellable] = None
@@ -155,18 +154,7 @@ import scala.collection.JavaConverters._
 
     cancelAndClearEverything(new Exception("Task Manager is shutting down."))
 
-    heartbeatScheduler foreach {
-      _.cancel()
-    }
-
-    networkEnvironment foreach {
-      ne =>
-        try {
-          ne.shutdown()
-        } catch {
-          case t: Throwable => log.error(t, "ChannelManager did not shutdown properly.")
-        }
-    }
+    cleanupTaskManager()
 
     ioManager.shutdown()
     memoryManager.shutdown()
@@ -177,38 +165,25 @@ import scala.collection.JavaConverters._
       case t: Throwable => log.error(t, "FileCache did not shutdown properly.")
     }
 
-    if (libraryCacheManager != null) {
-      try {
-        libraryCacheManager.shutdown()
-      }
-      catch {
-        case t: Throwable => log.error(t, "LibraryCacheManager did not shutdown properly.")
-      }
-    }
-
     if(log.isDebugEnabled){
       log.debug("Task manager {} is completely stopped.", self.path)
     }
   }
 
   private def tryJobManagerRegistration(): Unit = {
-    registrationDuration = 0 seconds
-
-    registered = false
-    currentJobManager = ActorRef.noSender
-
     context.system.scheduler.scheduleOnce(registrationDelay, self, RegisterAtJobManager)
   }
 
   override def receiveWithLogMessages: Receive = {
     case RegisterAtJobManager =>
-      if(!registered) {
+      if(currentJobManager.isEmpty) {
         registrationDuration += registrationDelay
         // double delay for exponential backoff
         registrationDelay *= 2
+        registrationAttempts += 1
 
         if (registrationDuration > maxRegistrationDuration) {
-          log.warning("TaskManager could not register at JobManager {} after {}.",
+          log.error("TaskManager could not register at JobManager {} after {}.",
             jobManagerAkkaURL,
             maxRegistrationDuration)
 
@@ -225,15 +200,15 @@ import scala.collection.JavaConverters._
       }
 
     case AcknowledgeRegistration(id, blobPort, profilerListener) =>
-      if(!registered) {
+      if(currentJobManager.isEmpty) {
         finishRegistration(sender, id, blobPort, profilerListener)
       } else {
         log.info("The TaskManager {} is already registered at the JobManager {}, but received " +
-          "another AcknowledgeRegistration message.", self.path, currentJobManager.path)
+          "another AcknowledgeRegistration message.", self.path, sender.path)
       }
 
     case AlreadyRegistered(id, blobPort, profilerListener) =>
-      if(!registered) {
+      if(currentJobManager.isEmpty) {
         log.warning("The TaskManager {} seems to be already registered at the JobManager {} even" +
           "though it has not yet finished the registration process.", self.path, sender.path)
 
@@ -245,7 +220,7 @@ import scala.collection.JavaConverters._
       }
 
     case RefuseRegistration(reason) =>
-      if(!registered) {
+      if(currentJobManager.isEmpty) {
         log.error("The registration of task manager {} was refused by the job manager {} " +
           "because {}.", self.path, jobManagerAkkaURL, reason)
 
@@ -288,31 +263,35 @@ import scala.collection.JavaConverters._
       unregisterTask(executionID)
 
     case updateMsg:UpdateTaskExecutionState =>
-      val futureResponse = (currentJobManager ? updateMsg)(timeout)
-
-      val jobID = updateMsg.taskExecutionState.getJobID
-      val executionID = updateMsg.taskExecutionState.getID
-      val executionState = updateMsg.taskExecutionState.getExecutionState
-
-      futureResponse.mapTo[Boolean].onComplete{
-        case Success(result) =>
-          if(!result){
-            self ! FailTask(executionID,
-              new IllegalStateException("Task has been disposed on JobManager."))
+      currentJobManager foreach {
+        jobManager => {
+          val futureResponse = (jobManager ? updateMsg)(timeout)
+
+          val jobID = updateMsg.taskExecutionState.getJobID
+          val executionID = updateMsg.taskExecutionState.getID
+          val executionState = updateMsg.taskExecutionState.getExecutionState
+
+          futureResponse.mapTo[Boolean].onComplete {
+            case Success(result) =>
+              if (!result) {
+                self ! FailTask(executionID,
+                  new IllegalStateException("Task has been disposed on JobManager."))
+              }
+
+              if (!result || executionState == ExecutionState.FINISHED || executionState ==
+                ExecutionState.CANCELED || executionState == ExecutionState.FAILED) {
+                self ! UnregisterTask(executionID)
+              }
+            case Failure(t) =>
+              log.error(t, "Execution state change notification failed for task {}" +
+                s"of job {}.", executionID, jobID)
+              self ! UnregisterTask(executionID)
           }
-
-          if (!result || executionState == ExecutionState.FINISHED || executionState ==
-            ExecutionState.CANCELED || executionState == ExecutionState.FAILED) {
-            self ! UnregisterTask(executionID)
-          }
-        case Failure(t) =>
-          log.warning(s"Execution state change notification failed for task $executionID " +
-            s"of job $jobID. Cause ${t.getMessage}.")
-          self ! UnregisterTask(executionID)
+        }
       }
 
     case SendHeartbeat =>
-      currentJobManager ! Heartbeat(instanceID)
+      currentJobManager foreach { _ ! Heartbeat(instanceID) }
 
     case LogMemoryUsage =>
       logMemoryStats()
@@ -327,7 +306,7 @@ import scala.collection.JavaConverters._
       sender ! StackTrace(instanceID, stackTraceStr)
 
     case NotifyWhenRegisteredAtJobManager =>
-      if (registered) {
+      if (currentJobManager.isDefined) {
         sender ! RegisteredAtJobManager
       } else {
         waitForRegistration += sender
@@ -347,7 +326,7 @@ import scala.collection.JavaConverters._
 
     case Terminated(jobManager) =>
       log.info("Job manager {} is no longer reachable. Cancelling all tasks and trying to " +
-        "reregister.", jobManager.path)
+        "reregister.", jobManagerAkkaURL)
 
       cancelAndClearEverything(new Throwable("Lost connection to JobManager"))
 
@@ -355,6 +334,16 @@ import scala.collection.JavaConverters._
 
       tryJobManagerRegistration()
 
+    case Disconnect(msg) =>
+      log.info("Job manager {} wants {} to disconnect. Reason {}.", jobManagerAkkaURL,
+        self.path, msg)
+
+      cancelAndClearEverything(new Throwable("Job manager wants me to disconnect."))
+
+      cleanupTaskManager()
+
+      tryJobManagerRegistration()
+
     case FailIntermediateResultPartitions(executionID) =>
       log.info("Fail intermediate result partitions associated with execution {}.", executionID)
       networkEnvironment foreach {
@@ -386,19 +375,24 @@ import scala.collection.JavaConverters._
     var task: Task = null
 
     try {
-      if (log.isDebugEnabled) {
-        startRegisteringTask = System.currentTimeMillis()
-      }
-      libraryCacheManager.registerTask(jobID, executionID, tdd.getRequiredJarFiles)
-      // triggers the download of all missing jar files from the job manager
-      libraryCacheManager.registerTask(jobID, executionID, tdd.getRequiredJarFiles)
+      val userCodeClassLoader = libraryCacheManager match {
+        case Some(manager) =>
+          if (log.isDebugEnabled) {
+            startRegisteringTask = System.currentTimeMillis()
+          }
 
-      if (log.isDebugEnabled) {
-        log.debug("Register task {} took {}s", executionID,
-          (System.currentTimeMillis() - startRegisteringTask) / 1000.0)
-      }
+          manager.registerTask(jobID, executionID, tdd.getRequiredJarFiles)
+          // triggers the download of all missing jar files from the job manager
+          manager.registerTask(jobID, executionID, tdd.getRequiredJarFiles)
+
+          if (log.isDebugEnabled) {
+            log.debug("Register task {} took {}s", executionID,
+              (System.currentTimeMillis() - startRegisteringTask) / 1000.0)
+          }
 
-      val userCodeClassLoader = libraryCacheManager.getClassLoader(jobID)
+          manager.getClassLoader(jobID)
+        case None => throw new IllegalStateException("There is no valid library cache manager.")
+      }
 
       if (userCodeClassLoader == null) {
         throw new RuntimeException("No user code Classloader available.")
@@ -413,11 +407,17 @@ import scala.collection.JavaConverters._
         case None =>
       }
 
-      val splitProvider = new TaskInputSplitProvider(currentJobManager, jobID, vertexID,
-        executionID, userCodeClassLoader, timeout)
+      val env = currentJobManager match {
+        case Some(jobManager) =>
+          val splitProvider = new TaskInputSplitProvider(jobManager, jobID, vertexID,
+            executionID, userCodeClassLoader, timeout)
 
-      val env = new RuntimeEnvironment(currentJobManager, task, tdd, userCodeClassLoader,
-        memoryManager, ioManager, splitProvider, bcVarManager, networkEnvironment.get)
+          new RuntimeEnvironment(jobManager, task, tdd, userCodeClassLoader,
+            memoryManager, ioManager, splitProvider, bcVarManager, networkEnvironment.get)
+
+        case None => throw new IllegalStateException("TaskManager has not yet registered at " +
+          "the JobManager.")
+      }
 
       task.setEnvironment(env)
 
@@ -465,7 +465,7 @@ import scala.collection.JavaConverters._
             removeAllTaskResources(task)
           }
 
-          libraryCacheManager.unregisterTask(jobID, executionID)
+          libraryCacheManager foreach { _.unregisterTask(jobID, executionID) }
         } catch {
           case t: Throwable => log.error(t, "Error during cleanup of task deployment.")
         }
@@ -475,23 +475,31 @@ import scala.collection.JavaConverters._
   }
 
   private def cleanupTaskManager(): Unit = {
-    context.unwatch(currentJobManager)
+    currentJobManager foreach {
+      context.unwatch(_)
+    }
 
     networkEnvironment foreach {
-      _.shutdown()
+      ne =>
+        try {
+          ne.shutdown()
+        } catch {
+          case t: Throwable => log.error(t, "ChannelManager did not shutdown properly.")
+        }
     }
 
     networkEnvironment = None
 
-    if(libraryCacheManager != null){
-      try {
-        libraryCacheManager.shutdown()
-      } catch {
-        case t: Throwable => log.error(t, "Could not shut down the library cache manager.")
-      }
+    libraryCacheManager foreach {
+      manager =>
+        try {
+          manager.shutdown()
+        } catch {
+          case t: Throwable => log.error(t, "Could not shut down the library cache manager.")
+        }
     }
 
-    libraryCacheManager = null
+    libraryCacheManager = None
 
     heartbeatScheduler foreach {
       _.cancel()
@@ -507,9 +515,10 @@ import scala.collection.JavaConverters._
     }
 
     profilerListener = None
-    currentJobManager = ActorRef.noSender
+    currentJobManager = None
     instanceID = null
-    registered = false
+    registrationAttempts = 0
+    registrationDuration = 0 seconds
   }
 
   private def updateTask(executionId: ExecutionAttemptID,
@@ -567,15 +576,15 @@ import scala.collection.JavaConverters._
 
   private def setupTaskManager(jobManager: ActorRef, id: InstanceID, blobPort: Int,
                                 profilerListener: Option[ActorRef]): Unit = {
-    registered = true
-    currentJobManager = jobManager
+
+    currentJobManager = Some(jobManager)
     this.profilerListener = profilerListener
     instanceID = id
 
     // watch job manager to detect when it dies
-    context.watch(currentJobManager)
+    context.watch(jobManager)
 
-    setupNetworkEnvironment()
+    setupNetworkEnvironment(jobManager)
     setupLibraryCacheManager(blobPort)
 
     // schedule regular heartbeat message for oneself
@@ -590,7 +599,7 @@ import scala.collection.JavaConverters._
     }
   }
 
-  private def setupNetworkEnvironment(): Unit = {
+  private def setupNetworkEnvironment(jobManager: ActorRef): Unit = {
     //shutdown existing network environment
     networkEnvironment foreach {
       ne =>
@@ -602,7 +611,7 @@ import scala.collection.JavaConverters._
     }
 
     try {
-      networkEnvironment = Some(new NetworkEnvironment(self, currentJobManager, timeout,
+      networkEnvironment = Some(new NetworkEnvironment(self, jobManager, timeout,
         networkConfig))
     } catch {
       case ioe: IOException =>
@@ -613,27 +622,29 @@ import scala.collection.JavaConverters._
 
   private def setupLibraryCacheManager(blobPort: Int): Unit = {
     // shutdown existing library cache manager first
-    if (libraryCacheManager != null) {
-      try {
-        libraryCacheManager.shutdown()
-      }
-      catch {
-        case t: Throwable => log.error(t, "Could not properly shut down LibraryCacheManager.")
+    libraryCacheManager foreach {
+      manager => {
+        try{
+          manager.shutdown()
+        } catch {
+          case t: Throwable => log.error(t, "Could not properly shut down LibraryCacheManager.")
+        }
       }
-      libraryCacheManager = null
     }
 
     // Check if a blob server is specified
     if (blobPort > 0) {
-      val address = new InetSocketAddress(currentJobManager.path.address.host.getOrElse
-        ("localhost"), blobPort)
+
+      val address = new InetSocketAddress(
+        currentJobManager.flatMap(_.path.address.host).getOrElse("localhost"),
+        blobPort)
 
       log.info("Determined BLOB server address to be {}.", address)
 
-      libraryCacheManager = new BlobLibraryCacheManager(
-                                     new BlobCache(address, configuration), cleanupInterval)
+      libraryCacheManager = Some(new BlobLibraryCacheManager(
+                                     new BlobCache(address, configuration), cleanupInterval))
     } else {
-      libraryCacheManager = new FallbackLibraryCacheManager
+      libraryCacheManager = Some(new FallbackLibraryCacheManager)
     }
   }
 
@@ -646,18 +657,17 @@ import scala.collection.JavaConverters._
 
       for (t <- runningTasks.values) {
         t.failExternally(cause)
-        runningTasks.remove(t.getExecutionId)
+        unregisterTask(t.getExecutionId)
       }
     }
   }
 
   private def unregisterTask(executionID: ExecutionAttemptID): Unit = {
-    log.info("Unregister task with execution ID {}.", executionID)
-
     runningTasks.remove(executionID) match {
       case Some(task) =>
+        log.info("Unregister task with execution ID {}.", executionID)
         removeAllTaskResources(task)
-        libraryCacheManager.unregisterTask(task.getJobID, executionID)
+        libraryCacheManager foreach { _.unregisterTask(task.getJobID, executionID) }
       case None =>
         if (log.isDebugEnabled) {
           log.debug("Cannot find task with ID {} to unregister.", executionID)
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala
index 87fca997d0f..895da46f35a 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala
@@ -19,12 +19,15 @@
 package org.apache.flink.runtime.testingUtils
 
 import akka.actor.{ActorRef, Props, ActorSystem}
+import akka.pattern.Patterns.gracefulStop
 import org.apache.flink.configuration.{ConfigConstants, Configuration}
 import org.apache.flink.runtime.jobmanager.{MemoryArchivist, JobManager}
 import org.apache.flink.runtime.minicluster.FlinkMiniCluster
 import org.apache.flink.runtime.net.NetUtils
 import org.apache.flink.runtime.taskmanager.TaskManager
 
+import scala.concurrent.Await
+
 /**
  * Testing cluster which starts the [[JobManager]] and [[TaskManager]] actors with testing support
  * in the same [[ActorSystem]].
@@ -71,4 +74,11 @@ FlinkMiniCluster(userConfiguration, singleActorSystem) {
       networkConnectionConfig) with TestingTaskManager), TaskManager.TASK_MANAGER_NAME + "_" +
       (index + 1))
   }
+    val stopped = gracefulStop(jobManagerActor, TestingUtils.TESTING_DURATION)
+    Await.result(stopped, TestingUtils.TESTING_DURATION)
+
+    jobManagerActorSystem.shutdown()
+    jobManagerActorSystem.awaitTermination()
+
+    jobManagerActorSystem = startJobManagerActorSystem()
 }
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala
index 566f6615693..f41e114705f 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala
@@ -111,6 +111,7 @@ trait TestingJobManager extends ActorLogMessages with WrapAsScala {
       import context.dispatcher
 
       Future.fold(responses)(true)(_ & _) pipeTo sender
+
     case NotifyWhenTaskManagerTerminated(taskManager) =>
       val waiting = waitForTaskManagerToBeTerminated.getOrElse(taskManager.path.name, Set())
       waitForTaskManagerToBeTerminated += taskManager.path.name -> (waiting + sender)
@@ -118,7 +119,7 @@ trait TestingJobManager extends ActorLogMessages with WrapAsScala {
     case msg@Terminated(taskManager) =>
       super.receiveWithLogMessages(msg)
 
-      waitForTaskManagerToBeTerminated.get(taskManager.path.name) foreach {
+      waitForTaskManagerToBeTerminated.remove(taskManager.path.name) foreach {
         _ foreach {
           listener =>
             listener ! TaskManagerTerminated(taskManager)
@@ -151,16 +152,23 @@ trait TestingJobManager extends ActorLogMessages with WrapAsScala {
 
     case msg@JobStatusChanged(jobID, newJobStatus, _, _) =>
       super.receiveWithLogMessages(msg)
-      waitForJobStatus.get(jobID) match {
+
+      val cleanup = waitForJobStatus.get(jobID) match {
         case Some(stateListener) =>
-          stateListener.get(newJobStatus) match {
+          stateListener.remove(newJobStatus) match {
             case Some(listeners) =>
               listeners foreach {
                 _ ! JobStatusIs(jobID, newJobStatus)
               }
             case _ =>
           }
-        case _ =>
+          stateListener.isEmpty
+
+        case _ => false
+      }
+
+      if (cleanup) {
+        waitForJobStatus.remove(jobID)
       }
   }
 
@@ -185,30 +193,24 @@ trait TestingJobManager extends ActorLogMessages with WrapAsScala {
   }
 
   def notifyListeners(jobID: JobID): Unit = {
-    val cleanupRunning = waitForAllVerticesToBeRunning.get(jobID) match {
-      case Some(listeners) if checkIfAllVerticesRunning(jobID) =>
-        for(listener <- listeners){
-          listener ! AllVerticesRunning(jobID)
-        }
-        true
-      case _ => false
-    }
-
-    if(cleanupRunning){
-      waitForAllVerticesToBeRunning.remove(jobID)
-    }
-
-    val cleanupRunningOrFinished = waitForAllVerticesToBeRunningOrFinished.get(jobID) match {
-      case Some(listeners) if checkIfAllVerticesRunningOrFinished(jobID) =>
-        for(listener <- listeners){
-          listener ! AllVerticesRunning(jobID)
-        }
-        true
-      case _ => false
+    if(checkIfAllVerticesRunning((jobID))) {
+      waitForAllVerticesToBeRunning.remove(jobID) match {
+        case Some(listeners) =>
+          for (listener <- listeners) {
+            listener ! AllVerticesRunning(jobID)
+          }
+        case _ =>
+      }
     }
 
-    if (cleanupRunningOrFinished) {
-      waitForAllVerticesToBeRunningOrFinished.remove(jobID)
+    if(checkIfAllVerticesRunningOrFinished(jobID)) {
+      waitForAllVerticesToBeRunningOrFinished.remove(jobID) match {
+        case Some(listeners) =>
+          for (listener <- listeners) {
+            listener ! AllVerticesRunning(jobID)
+          }
+        case _ =>
+      }
     }
   }
 }
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingMessages.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingMessages.scala
new file mode 100644
index 00000000000..52cc1f36ca1
--- /dev/null
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingMessages.scala
@@ -0,0 +1,24 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.testingUtils
+
+object TestingMessages {
+
+  case object DisableDisconnect
+}
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala
index abdb1731481..0ecbd046a0b 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala
@@ -22,10 +22,12 @@ import akka.actor.{Terminated, ActorRef}
 import org.apache.flink.runtime.ActorLogMessages
 import org.apache.flink.runtime.executiongraph.ExecutionAttemptID
 import org.apache.flink.runtime.jobgraph.JobID
+import org.apache.flink.runtime.messages.Messages.Disconnect
 import org.apache.flink.runtime.messages.TaskManagerMessages.UnregisterTask
 import org.apache.flink.runtime.taskmanager.TaskManager
 import org.apache.flink.runtime.testingUtils.TestingJobManagerMessages.NotifyWhenJobRemoved
 import org.apache.flink.runtime.ActorLogMessages
+import org.apache.flink.runtime.testingUtils.TestingMessages.DisableDisconnect
 import org.apache.flink.runtime.testingUtils.TestingTaskManagerMessages._
 
 import scala.concurrent.duration._
@@ -41,6 +43,8 @@ trait TestingTaskManager extends ActorLogMessages {
   val waitForJobRemoval = scala.collection.mutable.HashMap[JobID, Set[ActorRef]]()
   val waitForJobManagerToBeTerminated = scala.collection.mutable.HashMap[String, Set[ActorRef]]()
 
+  var disconnectDisabled = false
+
   abstract override def receiveWithLogMessages = {
     receiveTestMessages orElse super.receiveWithLogMessages
   }
@@ -60,7 +64,7 @@ trait TestingTaskManager extends ActorLogMessages {
       
     case UnregisterTask(executionID) =>
       super.receiveWithLogMessages(UnregisterTask(executionID))
-      waitForRemoval.get(executionID) match {
+      waitForRemoval.remove(executionID) match {
         case Some(actors) => for(actor <- actors) actor ! true
         case None =>
       }
@@ -77,7 +81,7 @@ trait TestingTaskManager extends ActorLogMessages {
         case None => sender ! ResponseNumActiveConnections(0)
       }
 
-  case NotifyWhenJobRemoved(jobID) =>
+    case NotifyWhenJobRemoved(jobID) =>
       if(runningTasks.values.exists(_.getJobID == jobID)){
         val set = waitForJobRemoval.getOrElse(jobID, Set())
         waitForJobRemoval += (jobID -> (set + sender))
@@ -92,7 +96,7 @@ trait TestingTaskManager extends ActorLogMessages {
 
     case CheckIfJobRemoved(jobID) =>
       if(runningTasks.values.forall(_.getJobID != jobID)){
-        waitForJobRemoval.get(jobID) match {
+        waitForJobRemoval.remove(jobID) match {
           case Some(listeners) => listeners foreach (_ ! true)
           case None =>
         }
@@ -108,10 +112,31 @@ trait TestingTaskManager extends ActorLogMessages {
     case msg@Terminated(jobManager) =>
       super.receiveWithLogMessages(msg)
 
-      waitForJobManagerToBeTerminated.get(jobManager.path.name) foreach {
+      waitForJobManagerToBeTerminated.remove(jobManager.path.name) foreach {
         _ foreach {
           _ ! JobManagerTerminated(jobManager)
         }
       }
+
+    case msg:Disconnect =>
+      super.receiveWithLogMessages(msg)
+
+      val jobManager = sender
+
+      waitForJobManagerToBeTerminated.remove(jobManager.path.name) foreach {
+        _ foreach {
+          _ ! JobManagerTerminated(jobManager)
+        }
+      }
+
+    case msg:Disconnect =>
+      if (!disconnectDisabled) {
+        super.receiveWithLogMessages(msg)
+      }
+
+    case DisableDisconnect =>
+      disconnectDisabled = true
   }
+
+
 }
diff --git a/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala b/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala
index 66b2438f2e3..3813beb2008 100644
--- a/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala
+++ b/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala
@@ -22,7 +22,7 @@ import akka.actor.{ActorSystem, PoisonPill}
 import akka.testkit.{ImplicitSender, TestKit}
 import org.apache.flink.configuration.{ConfigConstants, Configuration}
 import org.apache.flink.runtime.akka.AkkaUtils
-import org.apache.flink.runtime.messages.JobManagerMessages.RequestNumberRegisteredTaskManager
+import org.apache.flink.runtime.jobmanager.Tasks.{NoOpInvokable, BlockingNoOpInvokable}
 import org.apache.flink.runtime.testingUtils.TestingTaskManagerMessages.{JobManagerTerminated, NotifyWhenJobManagerTerminated}
 import org.apache.flink.test.util.ForkableFlinkMiniCluster
 import org.junit.runner.RunWith
@@ -55,6 +55,9 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
       val tm = cluster.getTaskManagers(0)
       val jm = cluster.getJobManager
 
+      // disable disconnect message to test death watch
+      tm ! DisableDisconnect
+
       try{
         jm ! RequestNumberRegisteredTaskManager
         expectMsg(1)
@@ -72,7 +75,62 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
         cluster.getJobManager ! RequestNumberRegisteredTaskManager
 
         expectMsg(1)
-      }finally{
+      } finally {
+        cluster.stop()
+      }
+    }
+  }
+
+  "The system" should {
+    "go into a clean state in case of a JobManager failure" in {
+      val num_slots = 20
+
+      val sender = new AbstractJobVertex("BlockingSender")
+      sender.setParallelism(num_slots)
+      sender.setInvokableClass(classOf[BlockingNoOpInvokable])
+      val jobGraph = new JobGraph("Blocking Testjob", sender)
+
+      val noOp = new AbstractJobVertex("NoOpInvokable")
+      noOp.setParallelism(num_slots)
+      noOp.setInvokableClass(classOf[NoOpInvokable])
+      val jobGraph2 = new JobGraph("NoOp Testjob", noOp)
+
+      val cluster = TestingUtils.startTestingClusterDeathWatch(num_slots/2, 2)
+
+      var jm = cluster.getJobManager
+      val tm = cluster.getTaskManagers(0)
+
+      try{
+        within(TestingUtils.TESTING_DURATION) {
+          jm ! SubmitJob(jobGraph)
+          expectMsg(SubmissionSuccess(jobGraph.getJobID))
+
+          tm ! NotifyWhenJobManagerTerminated(jm)
+
+          jm ! PoisonPill
+
+          expectMsgClass(classOf[JobManagerTerminated])
+
+          cluster.restartJobManager()
+
+          jm = cluster.getJobManager
+
+          cluster.waitForTaskManagersToBeRegistered()
+
+          jm ! SubmitJob(jobGraph2)
+          val response = expectMsgType[SubmissionResponse]
+
+          response match {
+            case SubmissionSuccess(jobID) => jobID should equal(jobGraph2.getJobID)
+            case SubmissionFailure(jobID, t) =>
+              fail("Submission of the second job failed.", t)
+          }
+
+          val result = expectMsgType[JobResultSuccess]
+
+          result.jobID should equal(jobGraph2.getJobID)
+        }
+      } finally {
         cluster.stop()
       }
     }
