diff --git a/.gitignore b/.gitignore
index 4e3a5ae2f2e..e89f6224eea 100644
--- a/.gitignore
+++ b/.gitignore
@@ -36,7 +36,6 @@ flink-python/dev/.conda/
 flink-python/dev/log/
 flink-python/dev/.stage.txt
 flink-python/.eggs/
-flink-python/pyflink/fn_execution/*_pb2.py
 atlassian-ide-plugin.xml
 out/
 /docs/api
diff --git a/flink-python/README.md b/flink-python/README.md
index db491503814..76df93dd776 100644
--- a/flink-python/README.md
+++ b/flink-python/README.md
@@ -28,3 +28,16 @@ We can enter the directory where this README.md file is located and run test cas
 ## Python Requirements
 
 PyFlink depends on Py4J (currently version 0.10.8.1) and CloudPickle (currently version 1.2.2).
+
+## Development notices
+
+Protocol buffer is used in this module and file `flink_fn_execution_pb2.py` is generated from `flink-fn-execution.proto`. Whenever `flink-fn-execution.proto` is updated, please re-generate `flink_fn_execution_pb2.py` by executing
+
+```
+python pyflink/gen_protos.py
+```
+
+PyFlink depends on the following libraries to execute the above script:
+1. grpcio-tools (>=1.3.5,<=1.14.2)
+2. setuptools (>=37.0.0)
+3. pip (>=8.0.0)
diff --git a/flink-python/pom.xml b/flink-python/pom.xml
index ffeb4864c5e..ed16daa09e3 100644
--- a/flink-python/pom.xml
+++ b/flink-python/pom.xml
@@ -327,26 +327,6 @@ under the License.
 					</execution>
 				</executions>
 			</plugin>
-			<plugin>
-				<artifactId>exec-maven-plugin</artifactId>
-				<groupId>org.codehaus.mojo</groupId>
-				<version>1.5.0</version>
-				<executions>
-					<execution>
-						<id>Protos Generation</id>
-						<phase>generate-sources</phase>
-						<goals>
-							<goal>exec</goal>
-						</goals>
-						<configuration>
-							<executable>python</executable>
-							<arguments>
-								<argument>${basedir}/pyflink/gen_protos.py</argument>
-							</arguments>
-						</configuration>
-					</execution>
-				</executions>
-			</plugin>
 		</plugins>
 	</build>
 </project>
diff --git a/flink-python/pyflink/fn_execution/flink_fn_execution_pb2.py b/flink-python/pyflink/fn_execution/flink_fn_execution_pb2.py
new file mode 100644
index 00000000000..b473673460a
--- /dev/null
+++ b/flink-python/pyflink/fn_execution/flink_fn_execution_pb2.py
@@ -0,0 +1,509 @@
+################################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one
+#  or more contributor license agreements.  See the NOTICE file
+#  distributed with this work for additional information
+#  regarding copyright ownership.  The ASF licenses this file
+#  to you under the Apache License, Version 2.0 (the
+#  "License"); you may not use this file except in compliance
+#  with the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+# limitations under the License.
+################################################################################
+# Generated by the protocol buffer compiler.  DO NOT EDIT!
+# source: flink-fn-execution.proto
+
+import sys
+_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
+from google.protobuf import descriptor as _descriptor
+from google.protobuf import message as _message
+from google.protobuf import reflection as _reflection
+from google.protobuf import symbol_database as _symbol_database
+from google.protobuf import descriptor_pb2
+# @@protoc_insertion_point(imports)
+
+_sym_db = _symbol_database.Default()
+
+
+
+
+DESCRIPTOR = _descriptor.FileDescriptor(
+  name='flink-fn-execution.proto',
+  package='org.apache.flink.fn_execution.v1',
+  syntax='proto3',
+  serialized_pb=_b('\n\x18\x66link-fn-execution.proto\x12 org.apache.flink.fn_execution.v1\"\xe2\x01\n\x13UserDefinedFunction\x12\x0f\n\x07payload\x18\x01 \x01(\x0c\x12K\n\x06inputs\x18\x02 \x03(\x0b\x32;.org.apache.flink.fn_execution.v1.UserDefinedFunction.Input\x1am\n\x05Input\x12\x44\n\x03udf\x18\x01 \x01(\x0b\x32\x35.org.apache.flink.fn_execution.v1.UserDefinedFunctionH\x00\x12\x15\n\x0binputOffset\x18\x02 \x01(\x05H\x00\x42\x07\n\x05input\"[\n\x14UserDefinedFunctions\x12\x43\n\x04udfs\x18\x01 \x03(\x0b\x32\x35.org.apache.flink.fn_execution.v1.UserDefinedFunction\"\x8d\x07\n\x06Schema\x12>\n\x06\x66ields\x18\x01 \x03(\x0b\x32..org.apache.flink.fn_execution.v1.Schema.Field\x1a\x97\x01\n\x07MapType\x12\x44\n\x08key_type\x18\x01 \x01(\x0b\x32\x32.org.apache.flink.fn_execution.v1.Schema.FieldType\x12\x46\n\nvalue_type\x18\x02 \x01(\x0b\x32\x32.org.apache.flink.fn_execution.v1.Schema.FieldType\x1a\xcd\x02\n\tFieldType\x12\x44\n\ttype_name\x18\x01 \x01(\x0e\x32\x31.org.apache.flink.fn_execution.v1.Schema.TypeName\x12\x10\n\x08nullable\x18\x02 \x01(\x08\x12U\n\x17\x63ollection_element_type\x18\x03 \x01(\x0b\x32\x32.org.apache.flink.fn_execution.v1.Schema.FieldTypeH\x00\x12\x44\n\x08map_type\x18\x04 \x01(\x0b\x32\x30.org.apache.flink.fn_execution.v1.Schema.MapTypeH\x00\x12>\n\nrow_schema\x18\x05 \x01(\x0b\x32(.org.apache.flink.fn_execution.v1.SchemaH\x00\x42\x0b\n\ttype_info\x1al\n\x05\x46ield\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x12@\n\x04type\x18\x03 \x01(\x0b\x32\x32.org.apache.flink.fn_execution.v1.Schema.FieldType\"\xea\x01\n\x08TypeName\x12\x07\n\x03ROW\x10\x00\x12\x0b\n\x07TINYINT\x10\x01\x12\x0c\n\x08SMALLINT\x10\x02\x12\x07\n\x03INT\x10\x03\x12\n\n\x06\x42IGINT\x10\x04\x12\x0b\n\x07\x44\x45\x43IMAL\x10\x05\x12\t\n\x05\x46LOAT\x10\x06\x12\n\n\x06\x44OUBLE\x10\x07\x12\x08\n\x04\x44\x41TE\x10\x08\x12\x08\n\x04TIME\x10\t\x12\x0c\n\x08\x44\x41TETIME\x10\n\x12\x0b\n\x07\x42OOLEAN\x10\x0b\x12\n\n\x06\x42INARY\x10\x0c\x12\r\n\tVARBINARY\x10\r\x12\x08\n\x04\x43HAR\x10\x0e\x12\x0b\n\x07VARCHAR\x10\x0f\x12\t\n\x05\x41RRAY\x10\x10\x12\x07\n\x03MAP\x10\x11\x12\x0c\n\x08MULTISET\x10\x12\x42-\n\x1forg.apache.flink.fnexecution.v1B\nFlinkFnApib\x06proto3')
+)
+
+
+
+_SCHEMA_TYPENAME = _descriptor.EnumDescriptor(
+  name='TypeName',
+  full_name='org.apache.flink.fn_execution.v1.Schema.TypeName',
+  filename=None,
+  file=DESCRIPTOR,
+  values=[
+    _descriptor.EnumValueDescriptor(
+      name='ROW', index=0, number=0,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='TINYINT', index=1, number=1,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='SMALLINT', index=2, number=2,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='INT', index=3, number=3,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='BIGINT', index=4, number=4,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='DECIMAL', index=5, number=5,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='FLOAT', index=6, number=6,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='DOUBLE', index=7, number=7,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='DATE', index=8, number=8,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='TIME', index=9, number=9,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='DATETIME', index=10, number=10,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='BOOLEAN', index=11, number=11,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='BINARY', index=12, number=12,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='VARBINARY', index=13, number=13,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='CHAR', index=14, number=14,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='VARCHAR', index=15, number=15,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='ARRAY', index=16, number=16,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='MAP', index=17, number=17,
+      options=None,
+      type=None),
+    _descriptor.EnumValueDescriptor(
+      name='MULTISET', index=18, number=18,
+      options=None,
+      type=None),
+  ],
+  containing_type=None,
+  options=None,
+  serialized_start=1060,
+  serialized_end=1294,
+)
+_sym_db.RegisterEnumDescriptor(_SCHEMA_TYPENAME)
+
+
+_USERDEFINEDFUNCTION_INPUT = _descriptor.Descriptor(
+  name='Input',
+  full_name='org.apache.flink.fn_execution.v1.UserDefinedFunction.Input',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='udf', full_name='org.apache.flink.fn_execution.v1.UserDefinedFunction.Input.udf', index=0,
+      number=1, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='inputOffset', full_name='org.apache.flink.fn_execution.v1.UserDefinedFunction.Input.inputOffset', index=1,
+      number=2, type=5, cpp_type=1, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  options=None,
+  is_extendable=False,
+  syntax='proto3',
+  extension_ranges=[],
+  oneofs=[
+    _descriptor.OneofDescriptor(
+      name='input', full_name='org.apache.flink.fn_execution.v1.UserDefinedFunction.Input.input',
+      index=0, containing_type=None, fields=[]),
+  ],
+  serialized_start=180,
+  serialized_end=289,
+)
+
+_USERDEFINEDFUNCTION = _descriptor.Descriptor(
+  name='UserDefinedFunction',
+  full_name='org.apache.flink.fn_execution.v1.UserDefinedFunction',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='payload', full_name='org.apache.flink.fn_execution.v1.UserDefinedFunction.payload', index=0,
+      number=1, type=12, cpp_type=9, label=1,
+      has_default_value=False, default_value=_b(""),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='inputs', full_name='org.apache.flink.fn_execution.v1.UserDefinedFunction.inputs', index=1,
+      number=2, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+  ],
+  extensions=[
+  ],
+  nested_types=[_USERDEFINEDFUNCTION_INPUT, ],
+  enum_types=[
+  ],
+  options=None,
+  is_extendable=False,
+  syntax='proto3',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=63,
+  serialized_end=289,
+)
+
+
+_USERDEFINEDFUNCTIONS = _descriptor.Descriptor(
+  name='UserDefinedFunctions',
+  full_name='org.apache.flink.fn_execution.v1.UserDefinedFunctions',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='udfs', full_name='org.apache.flink.fn_execution.v1.UserDefinedFunctions.udfs', index=0,
+      number=1, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  options=None,
+  is_extendable=False,
+  syntax='proto3',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=291,
+  serialized_end=382,
+)
+
+
+_SCHEMA_MAPTYPE = _descriptor.Descriptor(
+  name='MapType',
+  full_name='org.apache.flink.fn_execution.v1.Schema.MapType',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='key_type', full_name='org.apache.flink.fn_execution.v1.Schema.MapType.key_type', index=0,
+      number=1, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='value_type', full_name='org.apache.flink.fn_execution.v1.Schema.MapType.value_type', index=1,
+      number=2, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  options=None,
+  is_extendable=False,
+  syntax='proto3',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=460,
+  serialized_end=611,
+)
+
+_SCHEMA_FIELDTYPE = _descriptor.Descriptor(
+  name='FieldType',
+  full_name='org.apache.flink.fn_execution.v1.Schema.FieldType',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='type_name', full_name='org.apache.flink.fn_execution.v1.Schema.FieldType.type_name', index=0,
+      number=1, type=14, cpp_type=8, label=1,
+      has_default_value=False, default_value=0,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='nullable', full_name='org.apache.flink.fn_execution.v1.Schema.FieldType.nullable', index=1,
+      number=2, type=8, cpp_type=7, label=1,
+      has_default_value=False, default_value=False,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='collection_element_type', full_name='org.apache.flink.fn_execution.v1.Schema.FieldType.collection_element_type', index=2,
+      number=3, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='map_type', full_name='org.apache.flink.fn_execution.v1.Schema.FieldType.map_type', index=3,
+      number=4, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='row_schema', full_name='org.apache.flink.fn_execution.v1.Schema.FieldType.row_schema', index=4,
+      number=5, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  options=None,
+  is_extendable=False,
+  syntax='proto3',
+  extension_ranges=[],
+  oneofs=[
+    _descriptor.OneofDescriptor(
+      name='type_info', full_name='org.apache.flink.fn_execution.v1.Schema.FieldType.type_info',
+      index=0, containing_type=None, fields=[]),
+  ],
+  serialized_start=614,
+  serialized_end=947,
+)
+
+_SCHEMA_FIELD = _descriptor.Descriptor(
+  name='Field',
+  full_name='org.apache.flink.fn_execution.v1.Schema.Field',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='name', full_name='org.apache.flink.fn_execution.v1.Schema.Field.name', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=_b("").decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='description', full_name='org.apache.flink.fn_execution.v1.Schema.Field.description', index=1,
+      number=2, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=_b("").decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+    _descriptor.FieldDescriptor(
+      name='type', full_name='org.apache.flink.fn_execution.v1.Schema.Field.type', index=2,
+      number=3, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  options=None,
+  is_extendable=False,
+  syntax='proto3',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=949,
+  serialized_end=1057,
+)
+
+_SCHEMA = _descriptor.Descriptor(
+  name='Schema',
+  full_name='org.apache.flink.fn_execution.v1.Schema',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='fields', full_name='org.apache.flink.fn_execution.v1.Schema.fields', index=0,
+      number=1, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None, file=DESCRIPTOR),
+  ],
+  extensions=[
+  ],
+  nested_types=[_SCHEMA_MAPTYPE, _SCHEMA_FIELDTYPE, _SCHEMA_FIELD, ],
+  enum_types=[
+    _SCHEMA_TYPENAME,
+  ],
+  options=None,
+  is_extendable=False,
+  syntax='proto3',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=385,
+  serialized_end=1294,
+)
+
+_USERDEFINEDFUNCTION_INPUT.fields_by_name['udf'].message_type = _USERDEFINEDFUNCTION
+_USERDEFINEDFUNCTION_INPUT.containing_type = _USERDEFINEDFUNCTION
+_USERDEFINEDFUNCTION_INPUT.oneofs_by_name['input'].fields.append(
+  _USERDEFINEDFUNCTION_INPUT.fields_by_name['udf'])
+_USERDEFINEDFUNCTION_INPUT.fields_by_name['udf'].containing_oneof = _USERDEFINEDFUNCTION_INPUT.oneofs_by_name['input']
+_USERDEFINEDFUNCTION_INPUT.oneofs_by_name['input'].fields.append(
+  _USERDEFINEDFUNCTION_INPUT.fields_by_name['inputOffset'])
+_USERDEFINEDFUNCTION_INPUT.fields_by_name['inputOffset'].containing_oneof = _USERDEFINEDFUNCTION_INPUT.oneofs_by_name['input']
+_USERDEFINEDFUNCTION.fields_by_name['inputs'].message_type = _USERDEFINEDFUNCTION_INPUT
+_USERDEFINEDFUNCTIONS.fields_by_name['udfs'].message_type = _USERDEFINEDFUNCTION
+_SCHEMA_MAPTYPE.fields_by_name['key_type'].message_type = _SCHEMA_FIELDTYPE
+_SCHEMA_MAPTYPE.fields_by_name['value_type'].message_type = _SCHEMA_FIELDTYPE
+_SCHEMA_MAPTYPE.containing_type = _SCHEMA
+_SCHEMA_FIELDTYPE.fields_by_name['type_name'].enum_type = _SCHEMA_TYPENAME
+_SCHEMA_FIELDTYPE.fields_by_name['collection_element_type'].message_type = _SCHEMA_FIELDTYPE
+_SCHEMA_FIELDTYPE.fields_by_name['map_type'].message_type = _SCHEMA_MAPTYPE
+_SCHEMA_FIELDTYPE.fields_by_name['row_schema'].message_type = _SCHEMA
+_SCHEMA_FIELDTYPE.containing_type = _SCHEMA
+_SCHEMA_FIELDTYPE.oneofs_by_name['type_info'].fields.append(
+  _SCHEMA_FIELDTYPE.fields_by_name['collection_element_type'])
+_SCHEMA_FIELDTYPE.fields_by_name['collection_element_type'].containing_oneof = _SCHEMA_FIELDTYPE.oneofs_by_name['type_info']
+_SCHEMA_FIELDTYPE.oneofs_by_name['type_info'].fields.append(
+  _SCHEMA_FIELDTYPE.fields_by_name['map_type'])
+_SCHEMA_FIELDTYPE.fields_by_name['map_type'].containing_oneof = _SCHEMA_FIELDTYPE.oneofs_by_name['type_info']
+_SCHEMA_FIELDTYPE.oneofs_by_name['type_info'].fields.append(
+  _SCHEMA_FIELDTYPE.fields_by_name['row_schema'])
+_SCHEMA_FIELDTYPE.fields_by_name['row_schema'].containing_oneof = _SCHEMA_FIELDTYPE.oneofs_by_name['type_info']
+_SCHEMA_FIELD.fields_by_name['type'].message_type = _SCHEMA_FIELDTYPE
+_SCHEMA_FIELD.containing_type = _SCHEMA
+_SCHEMA.fields_by_name['fields'].message_type = _SCHEMA_FIELD
+_SCHEMA_TYPENAME.containing_type = _SCHEMA
+DESCRIPTOR.message_types_by_name['UserDefinedFunction'] = _USERDEFINEDFUNCTION
+DESCRIPTOR.message_types_by_name['UserDefinedFunctions'] = _USERDEFINEDFUNCTIONS
+DESCRIPTOR.message_types_by_name['Schema'] = _SCHEMA
+_sym_db.RegisterFileDescriptor(DESCRIPTOR)
+
+UserDefinedFunction = _reflection.GeneratedProtocolMessageType('UserDefinedFunction', (_message.Message,), dict(
+
+  Input = _reflection.GeneratedProtocolMessageType('Input', (_message.Message,), dict(
+    DESCRIPTOR = _USERDEFINEDFUNCTION_INPUT,
+    __module__ = 'flink_fn_execution_pb2'
+    # @@protoc_insertion_point(class_scope:org.apache.flink.fn_execution.v1.UserDefinedFunction.Input)
+    ))
+  ,
+  DESCRIPTOR = _USERDEFINEDFUNCTION,
+  __module__ = 'flink_fn_execution_pb2'
+  # @@protoc_insertion_point(class_scope:org.apache.flink.fn_execution.v1.UserDefinedFunction)
+  ))
+_sym_db.RegisterMessage(UserDefinedFunction)
+_sym_db.RegisterMessage(UserDefinedFunction.Input)
+
+UserDefinedFunctions = _reflection.GeneratedProtocolMessageType('UserDefinedFunctions', (_message.Message,), dict(
+  DESCRIPTOR = _USERDEFINEDFUNCTIONS,
+  __module__ = 'flink_fn_execution_pb2'
+  # @@protoc_insertion_point(class_scope:org.apache.flink.fn_execution.v1.UserDefinedFunctions)
+  ))
+_sym_db.RegisterMessage(UserDefinedFunctions)
+
+Schema = _reflection.GeneratedProtocolMessageType('Schema', (_message.Message,), dict(
+
+  MapType = _reflection.GeneratedProtocolMessageType('MapType', (_message.Message,), dict(
+    DESCRIPTOR = _SCHEMA_MAPTYPE,
+    __module__ = 'flink_fn_execution_pb2'
+    # @@protoc_insertion_point(class_scope:org.apache.flink.fn_execution.v1.Schema.MapType)
+    ))
+  ,
+
+  FieldType = _reflection.GeneratedProtocolMessageType('FieldType', (_message.Message,), dict(
+    DESCRIPTOR = _SCHEMA_FIELDTYPE,
+    __module__ = 'flink_fn_execution_pb2'
+    # @@protoc_insertion_point(class_scope:org.apache.flink.fn_execution.v1.Schema.FieldType)
+    ))
+  ,
+
+  Field = _reflection.GeneratedProtocolMessageType('Field', (_message.Message,), dict(
+    DESCRIPTOR = _SCHEMA_FIELD,
+    __module__ = 'flink_fn_execution_pb2'
+    # @@protoc_insertion_point(class_scope:org.apache.flink.fn_execution.v1.Schema.Field)
+    ))
+  ,
+  DESCRIPTOR = _SCHEMA,
+  __module__ = 'flink_fn_execution_pb2'
+  # @@protoc_insertion_point(class_scope:org.apache.flink.fn_execution.v1.Schema)
+  ))
+_sym_db.RegisterMessage(Schema)
+_sym_db.RegisterMessage(Schema.MapType)
+_sym_db.RegisterMessage(Schema.FieldType)
+_sym_db.RegisterMessage(Schema.Field)
+
+
+DESCRIPTOR.has_options = True
+DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n\037org.apache.flink.fnexecution.v1B\nFlinkFnApi'))
+# @@protoc_insertion_point(module_scope)
diff --git a/flink-python/pyflink/fn_execution/tests/test_flink_fn_execution_pb2_synced.py b/flink-python/pyflink/fn_execution/tests/test_flink_fn_execution_pb2_synced.py
new file mode 100644
index 00000000000..544e4f3a705
--- /dev/null
+++ b/flink-python/pyflink/fn_execution/tests/test_flink_fn_execution_pb2_synced.py
@@ -0,0 +1,43 @@
+################################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one
+#  or more contributor license agreements.  See the NOTICE file
+#  distributed with this work for additional information
+#  regarding copyright ownership.  The ASF licenses this file
+#  to you under the Apache License, Version 2.0 (the
+#  "License"); you may not use this file except in compliance
+#  with the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+# limitations under the License.
+################################################################################
+import filecmp
+import os
+
+from pyflink.gen_protos import generate_proto_files
+from pyflink.testing.test_case_utils import PyFlinkTestCase
+
+
+class FlinkFnExecutionSyncTests(PyFlinkTestCase):
+    """
+    Tests whether flink_fn_exeution_pb2.py is synced with flink-fn-execution.proto.
+    """
+
+    flink_fn_execution_pb2_file_name = "flink_fn_execution_pb2.py"
+    gen_protos_script = "gen_protos.py"
+    flink_fn_execution_proto_file_name = "flink-fn-execution.proto"
+
+    def test_flink_fn_execution_pb2_synced(self):
+        generate_proto_files('True', self.tempdir)
+        expected = os.path.join(self.tempdir, self.flink_fn_execution_pb2_file_name)
+        actual = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..',
+                              self.flink_fn_execution_pb2_file_name)
+        self.assertTrue(filecmp.cmp(expected, actual),
+                        'File %s should be re-generated by executing %s as %s has changed.'
+                        % (self.flink_fn_execution_pb2_file_name,
+                           self.gen_protos_script,
+                           self.flink_fn_execution_proto_file_name))
diff --git a/flink-python/pyflink/gen_protos.py b/flink-python/pyflink/gen_protos.py
index ce4ddd4010a..de54d5fb05e 100644
--- a/flink-python/pyflink/gen_protos.py
+++ b/flink-python/pyflink/gen_protos.py
@@ -34,25 +34,21 @@ import pkg_resources
 
 # latest grpcio-tools incompatible with latest protobuf 3.6.1.
 GRPC_TOOLS = 'grpcio-tools>=1.3.5,<=1.14.2'
+PROTO_PATHS = ['proto']
+PYFLINK_ROOT_PATH = os.path.dirname(os.path.abspath(__file__))
+DEFAULT_PYTHON_OUTPUT_PATH = os.path.join(PYFLINK_ROOT_PATH, 'fn_execution')
 
-PROTO_PATHS = [
-    os.path.join('proto'),
-]
 
-PYTHON_OUTPUT_PATH = os.path.join('fn_execution')
-
-
-def generate_proto_files(force=False):
+def generate_proto_files(force=True, output_dir=DEFAULT_PYTHON_OUTPUT_PATH):
     try:
         import grpc_tools  # noqa  # pylint: disable=unused-import
     except ImportError:
         warnings.warn('Installing grpcio-tools is recommended for development.')
 
-    py_sdk_root = os.path.dirname(os.path.abspath(__file__))
-    proto_dirs = [os.path.join(py_sdk_root, path) for path in PROTO_PATHS]
+    proto_dirs = [os.path.join(PYFLINK_ROOT_PATH, path) for path in PROTO_PATHS]
     proto_files = sum(
         [glob.glob(os.path.join(d, '*.proto')) for d in proto_dirs], [])
-    out_dir = os.path.join(py_sdk_root, PYTHON_OUTPUT_PATH)
+    out_dir = os.path.join(PYFLINK_ROOT_PATH, output_dir)
     out_files = [path for path in glob.glob(os.path.join(out_dir, '*_pb2.py'))]
 
     if out_files and not proto_files and not force:
@@ -84,12 +80,13 @@ def generate_proto_files(force=False):
             # Note that this requires a separate module from setup.py for Windows:
             # https://docs.python.org/2/library/multiprocessing.html#windows
             p = multiprocessing.Process(
-                target=_install_grpcio_tools_and_generate_proto_files)
+                target=_install_grpcio_tools_and_generate_proto_files(force, output_dir))
             p.start()
             p.join()
             if p.exitcode:
                 raise ValueError("Proto generation failed (see log for details).")
         else:
+            _check_grpcio_tools_version()
             logging.info('Regenerating out-of-date Python proto definitions.')
             builtin_protos = pkg_resources.resource_filename('grpc_tools', '_proto')
             args = (
@@ -104,6 +101,10 @@ def generate_proto_files(force=False):
                     'Protoc returned non-zero status (see logs for details): '
                     '%s' % ret_code)
 
+            for output_file in os.listdir(output_dir):
+                if output_file.endswith('_pb2.py'):
+                    _add_license_header(output_dir, output_file)
+
 
 # Though wheels are available for grpcio-tools, setup_requires uses
 # easy_install which doesn't understand them. This means that it is
@@ -111,9 +112,8 @@ def generate_proto_files(force=False):
 # protoc compiler). Instead, we attempt to install a wheel in a temporary
 # directory and add it to the path as needed.
 # See https://github.com/pypa/setuptools/issues/377
-def _install_grpcio_tools_and_generate_proto_files():
-    install_path = os.path.join(
-        os.path.dirname(os.path.abspath(__file__)), '..', '.eggs', 'grpcio-wheels')
+def _install_grpcio_tools_and_generate_proto_files(force, output_dir):
+    install_path = os.path.join(PYFLINK_ROOT_PATH, '..', '.eggs', 'grpcio-wheels')
     build_path = install_path + '-build'
     if os.path.exists(build_path):
         shutil.rmtree(build_path)
@@ -134,13 +134,51 @@ def _install_grpcio_tools_and_generate_proto_files():
         sys.stderr.flush()
         shutil.rmtree(build_path, ignore_errors=True)
     sys.path.append(install_obj.install_purelib)
+    pkg_resources.working_set.add_entry(install_obj.install_purelib)
     if install_obj.install_purelib != install_obj.install_platlib:
         sys.path.append(install_obj.install_platlib)
+        pkg_resources.working_set.add_entry(install_obj.install_platlib)
     try:
-        generate_proto_files()
+        generate_proto_files(force, output_dir)
     finally:
         sys.stderr.flush()
 
 
+def _add_license_header(dir, file_name):
+    with open(os.path.join(dir, file_name), 'r') as original_file:
+        original_data = original_file.read()
+        tmp_file_name = file_name + '.tmp'
+        with open(os.path.join(dir, tmp_file_name), 'w') as tmp_file:
+            tmp_file.write(
+                '################################################################################\n'
+                '#  Licensed to the Apache Software Foundation (ASF) under one\n'
+                '#  or more contributor license agreements.  See the NOTICE file\n'
+                '#  distributed with this work for additional information\n'
+                '#  regarding copyright ownership.  The ASF licenses this file\n'
+                '#  to you under the Apache License, Version 2.0 (the\n'
+                '#  "License"); you may not use this file except in compliance\n'
+                '#  with the License.  You may obtain a copy of the License at\n'
+                '#\n'
+                '#      http://www.apache.org/licenses/LICENSE-2.0\n'
+                '#\n'
+                '#  Unless required by applicable law or agreed to in writing, software\n'
+                '#  distributed under the License is distributed on an "AS IS" BASIS,\n'
+                '#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n'
+                '#  See the License for the specific language governing permissions and\n'
+                '# limitations under the License.\n'
+                '################################################################################\n'
+            )
+            tmp_file.write(original_data)
+            os.rename(os.path.join(dir, tmp_file_name), os.path.join(dir, file_name))
+
+
+def _check_grpcio_tools_version():
+    version = pkg_resources.get_distribution("grpcio-tools").parsed_version
+    from pkg_resources import parse_version
+    if version < parse_version('1.3.5') or version > parse_version('1.14.2'):
+        raise RuntimeError(
+            "Version of grpcio-tools must be between 1.3.5 and 1.14.2, got %s" % version)
+
+
 if __name__ == '__main__':
-    generate_proto_files(force=True)
+    generate_proto_files()
diff --git a/flink-python/pyflink/proto/flink-fn-execution.proto b/flink-python/pyflink/proto/flink-fn-execution.proto
index 190a362d928..db6582d39d7 100644
--- a/flink-python/pyflink/proto/flink-fn-execution.proto
+++ b/flink-python/pyflink/proto/flink-fn-execution.proto
@@ -16,6 +16,8 @@
  * limitations under the License.
  */
 
+// NOTE: File flink_fn_execution_pb2.py is generated from this file. Please re-generate it by calling
+// gen_protos.py whenever this file is changed.
 syntax = "proto3";
 
 package org.apache.flink.fn_execution.v1;
diff --git a/flink-python/pyflink/testing/test_case_utils.py b/flink-python/pyflink/testing/test_case_utils.py
index 21d3f09e629..888824ab7ca 100644
--- a/flink-python/pyflink/testing/test_case_utils.py
+++ b/flink-python/pyflink/testing/test_case_utils.py
@@ -27,7 +27,6 @@ from abc import abstractmethod
 from py4j.java_gateway import JavaObject
 from py4j.protocol import Py4JJavaError
 
-from pyflink import gen_protos
 from pyflink.table.sources import CsvTableSource
 from pyflink.dataset import ExecutionEnvironment
 from pyflink.datastream import StreamExecutionEnvironment
@@ -75,8 +74,6 @@ class PyFlinkTestCase(unittest.TestCase):
     def setUpClass(cls):
         cls.tempdir = tempfile.mkdtemp()
 
-        gen_protos.generate_proto_files()
-
         os.environ["FLINK_TESTING"] = "1"
         _find_flink_home()
 
diff --git a/flink-python/setup.py b/flink-python/setup.py
index f5b26da98e7..11c1c1909e1 100644
--- a/flink-python/setup.py
+++ b/flink-python/setup.py
@@ -23,12 +23,6 @@ import sys
 from shutil import copytree, copy, rmtree
 
 from setuptools import setup
-from setuptools.command.install import install
-from setuptools.command.build_py import build_py
-from setuptools.command.develop import develop
-from setuptools.command.egg_info import egg_info
-from setuptools.command.sdist import sdist
-from setuptools.command.test import test
 
 if sys.version_info < (2, 7):
     print("Python versions prior to 2.7 are not supported for PyFlink.",
@@ -68,24 +62,6 @@ README_FILE_TEMP_PATH = os.path.join("pyflink", "README.txt")
 in_flink_source = os.path.isfile("../flink-java/src/main/java/org/apache/flink/api/java/"
                                  "ExecutionEnvironment.java")
 
-
-# We must generate protos after setup_requires are installed.
-def generate_protos_first(original_cmd):
-    try:
-        # pylint: disable=wrong-import-position
-        from pyflink import gen_protos
-
-        class cmd(original_cmd, object):
-            def run(self):
-                gen_protos.generate_proto_files()
-                super(cmd, self).run()
-        return cmd
-    except ImportError:
-        import warnings
-        warnings.warn("Could not import gen_protos, skipping proto generation.")
-        return original_cmd
-
-
 try:
     if in_flink_source:
 
@@ -208,7 +184,7 @@ run sdist.
         license='https://www.apache.org/licenses/LICENSE-2.0',
         author='Flink Developers',
         author_email='dev@flink.apache.org',
-        install_requires=['py4j==0.10.8.1', 'python-dateutil', 'apache-beam==2.15.0',
+        install_requires=['py4j==0.10.8.1', 'python-dateutil==2.8.0', 'apache-beam==2.15.0',
                           'cloudpickle==1.2.2'],
         tests_require=['pytest==4.4.1'],
         description='Apache Flink Python API',
@@ -220,15 +196,7 @@ run sdist.
             'Programming Language :: Python :: 2.7',
             'Programming Language :: Python :: 3.5',
             'Programming Language :: Python :: 3.6',
-            'Programming Language :: Python :: 3.7'],
-        cmdclass={
-            'build_py': generate_protos_first(build_py),
-            'develop': generate_protos_first(develop),
-            'egg_info': generate_protos_first(egg_info),
-            'sdist': generate_protos_first(sdist),
-            'test': generate_protos_first(test),
-            'install': generate_protos_first(install),
-        },
+            'Programming Language :: Python :: 3.7']
     )
 finally:
     if in_flink_source:
diff --git a/pom.xml b/pom.xml
index aafec9a3fa1..08978f97463 100644
--- a/pom.xml
+++ b/pom.xml
@@ -1422,7 +1422,6 @@ under the License.
 						<exclude>flink-python/lib/**</exclude>
 						<exclude>flink-python/dev/download/**</exclude>
 						<exclude>flink-python/docs/_build/**</exclude>
-						<exclude>flink-python/pyflink/fn_execution/*_pb2.py</exclude>
 					</excludes>
 				</configuration>
 			</plugin>
