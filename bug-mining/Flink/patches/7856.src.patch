diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/DeltaJoinITCase.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/DeltaJoinITCase.scala
index eb8ba2a59ec..e4b15abb463 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/DeltaJoinITCase.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/DeltaJoinITCase.scala
@@ -35,6 +35,7 @@ import org.junit.jupiter.api.{BeforeEach, Test}
 import javax.annotation.Nullable
 
 import java.time.LocalDateTime
+import java.util.concurrent.TimeUnit
 
 import scala.collection.JavaConversions._
 
@@ -434,7 +435,7 @@ class DeltaJoinITCase extends StreamingTestBase {
 
     tEnv
       .executeSql(s"insert into testSnk select * from testLeft join testRight on $joinKeyStr")
-      .await()
+      .await(60, TimeUnit.SECONDS)
     val result = TestValuesTableFactory.getResultsAsStrings("testSnk")
 
     assertThat(result.sorted).isEqualTo(expected.sorted)
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/Epoch.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/Epoch.java
index c0e30e1198d..1c14d0d5bd3 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/Epoch.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/Epoch.java
@@ -18,8 +18,10 @@
 
 package org.apache.flink.table.runtime.operators.join.lookup.keyordered;
 
+import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.streaming.api.operators.async.queue.StreamElementQueueEntry;
 import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.util.Preconditions;
 
 import javax.annotation.Nullable;
 
@@ -71,6 +73,7 @@ public class Epoch<OUT> {
     }
 
     public void decrementCount() {
+        Preconditions.checkState(ongoingRecordCount > 0);
         ongoingRecordCount--;
     }
 
@@ -140,6 +143,11 @@ public class Epoch<OUT> {
                 "Epoch{watermark=%s, ongoingRecord=%d}", watermark, ongoingRecordCount);
     }
 
+    @VisibleForTesting
+    public int getOngoingRecordCount() {
+        return ongoingRecordCount;
+    }
+
     /** The status of an epoch. */
     enum EpochStatus {
         /**
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/EpochManager.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/EpochManager.java
index 0b5cdae1065..36992b33fe8 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/EpochManager.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/EpochManager.java
@@ -105,6 +105,11 @@ public class EpochManager<OUT> {
         return activeEpoch;
     }
 
+    @VisibleForTesting
+    public LinkedList<Epoch<OUT>> getOutputQueue() {
+        return outputQueue;
+    }
+
     private void tryFinishInQueue() {
         // If one epoch has been closed before and all records in
         // this epoch have finished, the epoch will be removed from the output queue.
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/TableAsyncExecutionController.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/TableAsyncExecutionController.java
index 01187ef3034..8f5645172d7 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/TableAsyncExecutionController.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/keyordered/TableAsyncExecutionController.java
@@ -161,6 +161,7 @@ public class TableAsyncExecutionController<IN, OUT, KEY> {
         if (epoch != null) {
             // only for recovery in case finding proper epoch in epochManager
             currentEpoch = epoch;
+            epoch.incrementCount();
         } else {
             currentEpoch = epochManager.onRecord();
         }
@@ -201,6 +202,11 @@ public class TableAsyncExecutionController<IN, OUT, KEY> {
         return epochManager.getActiveEpoch();
     }
 
+    @VisibleForTesting
+    public EpochManager<OUT> getEpochManager() {
+        return epochManager;
+    }
+
     @VisibleForTesting
     public int getBlockingSize() {
         return recordsBuffer.getBlockingSize();
diff --git a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/lookup/TableKeyedAsyncWaitOperatorTest.java b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/lookup/TableKeyedAsyncWaitOperatorTest.java
index 7afc042c7af..a2a8a70b04f 100644
--- a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/lookup/TableKeyedAsyncWaitOperatorTest.java
+++ b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/lookup/TableKeyedAsyncWaitOperatorTest.java
@@ -32,6 +32,7 @@ import org.apache.flink.streaming.util.TestHarnessUtil;
 import org.apache.flink.table.runtime.operators.TableKeyedAsyncWaitOperator;
 import org.apache.flink.table.runtime.operators.TableKeyedAsyncWaitOperatorFactory;
 import org.apache.flink.table.runtime.operators.join.lookup.keyordered.Epoch;
+import org.apache.flink.table.runtime.operators.join.lookup.keyordered.EpochManager;
 import org.apache.flink.table.runtime.operators.join.lookup.keyordered.TableAsyncExecutionController;
 import org.apache.flink.util.ExceptionUtils;
 
@@ -345,27 +346,47 @@ public class TableKeyedAsyncWaitOperatorTest {
         testHarness.initializeState(snapshot);
         testHarness.open();
 
+        Optional<Epoch<Integer>> epochWithMinWatermark = unwrapEpoch(testHarness, Long.MIN_VALUE);
+        assertThat(epochWithMinWatermark).isPresent();
+        assertThat(epochWithMinWatermark.get().getOngoingRecordCount()).isEqualTo(4);
+
+        testHarness.processWatermark(1000L);
         testHarness.processElement(new StreamRecord<>(5, initialTime + 5));
         testHarness.processElement(new StreamRecord<>(6, initialTime + 6));
         testHarness.processElement(new StreamRecord<>(7, initialTime + 7));
         testHarness.processElement(new StreamRecord<>(8, initialTime + 8));
-
-        ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();
-        expectedOutput.add(new StreamRecord<>(1, initialTime + 1));
-        expectedOutput.add(new StreamRecord<>(2, initialTime + 2));
-        expectedOutput.add(new StreamRecord<>(3, initialTime + 3));
-        expectedOutput.add(new StreamRecord<>(4, initialTime + 4));
-        expectedOutput.add(new StreamRecord<>(5, initialTime + 5));
-        expectedOutput.add(new StreamRecord<>(6, initialTime + 6));
-        expectedOutput.add(new StreamRecord<>(7, initialTime + 7));
-        expectedOutput.add(new StreamRecord<>(8, initialTime + 8));
+        Optional<Epoch<Integer>> epochWithMidWatermark = unwrapEpoch(testHarness, 1000L);
+        assertThat(epochWithMidWatermark).isPresent();
+        assertThat(epochWithMidWatermark.get().getOngoingRecordCount()).isEqualTo(4);
+
+        testHarness.processWatermark(Long.MAX_VALUE);
+        Optional<Epoch<Integer>> epochWithMaxWatermark = unwrapEpoch(testHarness, Long.MAX_VALUE);
+        assertThat(epochWithMaxWatermark).isPresent();
+        assertThat(epochWithMaxWatermark.get().getOngoingRecordCount()).isEqualTo(0);
+
+        expected.add(new Watermark(1000L));
+        expected.add(new StreamRecord<>(5, initialTime + 5));
+        expected.add(new StreamRecord<>(6, initialTime + 6));
+        expected.add(new StreamRecord<>(7, initialTime + 7));
+        expected.add(new StreamRecord<>(8, initialTime + 8));
+        expected.add(new Watermark(Long.MAX_VALUE));
 
         testLazyAsyncFunction.countDown();
         testHarness.endInput();
 
+        // TODO FLINK-37981 send Long.MAX watermark downstream
+        assertThat(unwrapEpochManager(testHarness).getOutputQueue().size()).isEqualTo(1);
+        assertThat(
+                        unwrapEpochManager(testHarness)
+                                .getOutputQueue()
+                                .get(0)
+                                .getWatermark()
+                                .getTimestamp())
+                .isEqualTo(Long.MAX_VALUE);
+
         TestHarnessUtil.assertOutputEqualsSorted(
                 "StateAndRestored Test Output was not correct.",
-                expectedOutput,
+                expected,
                 testHarness.getOutput(),
                 new StreamRecordComparator());
         testHarness.close();
@@ -483,4 +504,19 @@ public class TableKeyedAsyncWaitOperatorTest {
 
         assertThat(actualWatermarks).as(message).isEqualTo(expectedWatermarks);
     }
+
+    private EpochManager<Integer> unwrapEpochManager(
+            KeyedOneInputStreamOperatorTestHarness<Integer, Integer, Integer> testHarness) {
+        TableKeyedAsyncWaitOperator<Integer, Integer, Integer> operator =
+                (TableKeyedAsyncWaitOperator<Integer, Integer, Integer>) testHarness.getOperator();
+        TableAsyncExecutionController<Integer, Integer, Integer> asyncExecutionController =
+                operator.getAsyncExecutionController();
+        return asyncExecutionController.getEpochManager();
+    }
+
+    private Optional<Epoch<Integer>> unwrapEpoch(
+            KeyedOneInputStreamOperatorTestHarness<Integer, Integer, Integer> testHarness,
+            long targetEpochWatermark) {
+        return unwrapEpochManager(testHarness).getProperEpoch(new Watermark(targetEpochWatermark));
+    }
 }
