diff --git a/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcFileSystemITCase.java b/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcFileSystemITCase.java
index 704e1228271..18db17dd98f 100644
--- a/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcFileSystemITCase.java
+++ b/flink-formats/flink-orc/src/test/java/org/apache/flink/orc/OrcFileSystemITCase.java
@@ -38,6 +38,7 @@ import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.List;
+import java.util.concurrent.ExecutionException;
 
 /**
  * ITCase for {@link OrcFileSystemFormatFactory}.
@@ -110,7 +111,7 @@ public class OrcFileSystemITCase extends BatchFileSystemITCaseBase {
 	}
 
 	@Test
-	public void testOrcFilterPushDown(){
+	public void testOrcFilterPushDown() throws ExecutionException, InterruptedException {
 		super.tableEnv().executeSql(
 				"insert into orcFilterTable select x, y, a, b, " +
 						"case when y >= 10 then false else true end as c, " +
@@ -118,7 +119,7 @@ public class OrcFileSystemITCase extends BatchFileSystemITCaseBase {
 						"y * 3.14 as e, " +
 						"date '2020-01-01' as f, " +
 						"timestamp '2020-01-01 05:20:00' as g " +
-						"from originalT");
+						"from originalT").await();
 
 		check("select x, y from orcFilterTable where x = 'x11' and 11 = y",
 				Collections.singletonList(
diff --git a/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/streaming/util/TestStreamEnvironment.java b/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/streaming/util/TestStreamEnvironment.java
index 477d47eadbb..6ef16e2a6bd 100644
--- a/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/streaming/util/TestStreamEnvironment.java
+++ b/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/streaming/util/TestStreamEnvironment.java
@@ -18,20 +18,13 @@
 
 package org.apache.flink.streaming.util;
 
-import org.apache.flink.api.common.JobExecutionResult;
-import org.apache.flink.client.deployment.executors.LocalExecutor;
-import org.apache.flink.configuration.DeploymentOptions;
 import org.apache.flink.core.fs.Path;
-import org.apache.flink.runtime.jobgraph.JobGraph;
-import org.apache.flink.runtime.minicluster.JobExecutor;
 import org.apache.flink.runtime.minicluster.MiniCluster;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironmentFactory;
-import org.apache.flink.streaming.api.graph.StreamGraph;
-import org.apache.flink.util.Preconditions;
+import org.apache.flink.test.util.MiniClusterPipelineExecutorServiceLoader;
 
 import java.net.URL;
-import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 
@@ -40,75 +33,46 @@ import java.util.Collections;
  */
 public class TestStreamEnvironment extends StreamExecutionEnvironment {
 
-	/** The job executor to use to execute environment's jobs. */
-	private final JobExecutor jobExecutor;
-
-	private final Collection<Path> jarFiles;
-
-	private final Collection<URL> classPaths;
-
 	public TestStreamEnvironment(
-			JobExecutor jobExecutor,
+			MiniCluster miniCluster,
 			int parallelism,
 			Collection<Path> jarFiles,
 			Collection<URL> classPaths) {
-
-		this.jobExecutor = Preconditions.checkNotNull(jobExecutor);
-		this.jarFiles = Preconditions.checkNotNull(jarFiles);
-		this.classPaths = Preconditions.checkNotNull(classPaths);
-		getConfiguration().set(DeploymentOptions.TARGET, LocalExecutor.NAME);
-		getConfiguration().set(DeploymentOptions.ATTACHED, true);
+		super(
+				new MiniClusterPipelineExecutorServiceLoader(miniCluster),
+				MiniClusterPipelineExecutorServiceLoader.createConfiguration(jarFiles, classPaths),
+				null);
 
 		setParallelism(parallelism);
 	}
 
 	public TestStreamEnvironment(
-			JobExecutor jobExecutor,
+			MiniCluster miniCluster,
 			int parallelism) {
-		this(jobExecutor, parallelism, Collections.emptyList(), Collections.emptyList());
-	}
-
-	@Override
-	public JobExecutionResult execute(StreamGraph streamGraph) throws Exception {
-		final JobGraph jobGraph = streamGraph.getJobGraph();
-
-		for (Path jarFile : jarFiles) {
-			jobGraph.addJar(jarFile);
-		}
-
-		jobGraph.setClasspaths(new ArrayList<>(classPaths));
-
-		return jobExecutor.executeJobBlocking(jobGraph);
+		this(miniCluster, parallelism, Collections.emptyList(), Collections.emptyList());
 	}
 
-	// ------------------------------------------------------------------------
-
 	/**
 	 * Sets the streaming context environment to a TestStreamEnvironment that runs its programs on
 	 * the given cluster with the given default parallelism and the specified jar files and class
 	 * paths.
 	 *
-	 * @param jobExecutor The executor to execute the jobs on
+	 * @param miniCluster The MiniCluster to execute jobs on.
 	 * @param parallelism The default parallelism for the test programs.
 	 * @param jarFiles Additional jar files to execute the job with
 	 * @param classpaths Additional class paths to execute the job with
 	 */
 	public static void setAsContext(
-			final JobExecutor jobExecutor,
+			final MiniCluster miniCluster,
 			final int parallelism,
 			final Collection<Path> jarFiles,
 			final Collection<URL> classpaths) {
 
-		StreamExecutionEnvironmentFactory factory = new StreamExecutionEnvironmentFactory() {
-			@Override
-			public StreamExecutionEnvironment createExecutionEnvironment() {
-				return new TestStreamEnvironment(
-					jobExecutor,
-					parallelism,
-					jarFiles,
-					classpaths);
-			}
-		};
+		StreamExecutionEnvironmentFactory factory = () -> new TestStreamEnvironment(
+				miniCluster,
+				parallelism,
+				jarFiles,
+				classpaths);
 
 		initializeContextEnvironment(factory);
 	}
@@ -117,15 +81,15 @@ public class TestStreamEnvironment extends StreamExecutionEnvironment {
 	 * Sets the streaming context environment to a TestStreamEnvironment that runs its programs on
 	 * the given cluster with the given default parallelism.
 	 *
-	 * @param jobExecutor The executor to execute the jobs on
+	 * @param miniCluster The MiniCluster to execute jobs on.
 	 * @param parallelism The default parallelism for the test programs.
 	 */
-	public static void setAsContext(final JobExecutor jobExecutor, final int parallelism) {
+	public static void setAsContext(final MiniCluster miniCluster, final int parallelism) {
 		setAsContext(
-			jobExecutor,
-			parallelism,
-			Collections.emptyList(),
-			Collections.emptyList());
+				miniCluster,
+				parallelism,
+				Collections.emptyList(),
+				Collections.emptyList());
 	}
 
 	/**
diff --git a/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/MiniClusterPipelineExecutorServiceLoader.java b/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/MiniClusterPipelineExecutorServiceLoader.java
new file mode 100644
index 00000000000..a43793b04c4
--- /dev/null
+++ b/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/MiniClusterPipelineExecutorServiceLoader.java
@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.test.util;
+
+import org.apache.flink.api.dag.Pipeline;
+import org.apache.flink.client.deployment.executors.PipelineExecutorUtils;
+import org.apache.flink.configuration.ConfigUtils;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.DeploymentOptions;
+import org.apache.flink.configuration.PipelineOptions;
+import org.apache.flink.core.execution.JobClient;
+import org.apache.flink.core.execution.PipelineExecutor;
+import org.apache.flink.core.execution.PipelineExecutorFactory;
+import org.apache.flink.core.execution.PipelineExecutorServiceLoader;
+import org.apache.flink.core.fs.FileSystem;
+import org.apache.flink.core.fs.Path;
+import org.apache.flink.runtime.jobgraph.JobGraph;
+import org.apache.flink.runtime.minicluster.MiniCluster;
+import org.apache.flink.runtime.minicluster.MiniClusterJobClient;
+
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.Collection;
+import java.util.concurrent.CompletableFuture;
+import java.util.stream.Stream;
+
+/**
+ * A {@link PipelineExecutorServiceLoader} that is hardwired to return {@link PipelineExecutor
+ * PipelineExecutors} that use a given {@link MiniCluster}.
+ */
+public class MiniClusterPipelineExecutorServiceLoader implements PipelineExecutorServiceLoader {
+	public static final String NAME = "minicluster";
+
+	private final MiniCluster miniCluster;
+
+	public MiniClusterPipelineExecutorServiceLoader(MiniCluster miniCluster) {
+		this.miniCluster = miniCluster;
+	}
+
+	/**
+	 * Populates a {@link Configuration} that is compatible with this {@link
+	 * MiniClusterPipelineExecutorServiceLoader}.
+	 */
+	public static Configuration createConfiguration(
+			Collection<Path> jarFiles,
+			Collection<URL> classPaths) {
+		Configuration config = new Configuration();
+		ConfigUtils.encodeCollectionToConfig(
+				config,
+				PipelineOptions.JARS,
+				jarFiles,
+				MiniClusterPipelineExecutorServiceLoader::getAbsoluteURL);
+		ConfigUtils.encodeCollectionToConfig(
+				config,
+				PipelineOptions.CLASSPATHS,
+				classPaths,
+				URL::toString);
+		config.set(DeploymentOptions.TARGET, MiniClusterPipelineExecutorServiceLoader.NAME);
+		config.set(DeploymentOptions.ATTACHED, true);
+		return config;
+	}
+
+	private static String getAbsoluteURL(Path path) {
+		FileSystem fs;
+		try {
+			fs = path.getFileSystem();
+		} catch (IOException e) {
+			throw new RuntimeException(String.format("Could not get FileSystem from %s", path), e);
+		}
+		try {
+			return path.makeQualified(fs).toUri().toURL().toString();
+		} catch (MalformedURLException e) {
+			throw new RuntimeException(String.format("Could not get URL from %s", path), e);
+		}
+	}
+
+	@Override
+	public PipelineExecutorFactory getExecutorFactory(Configuration configuration) {
+		return new MiniClusterPipelineExecutorFactory(miniCluster);
+	}
+
+	@Override
+	public Stream<String> getExecutorNames() {
+		return Stream.of(MiniClusterPipelineExecutorServiceLoader.NAME);
+	}
+
+	private static class MiniClusterPipelineExecutorFactory implements PipelineExecutorFactory {
+		private final MiniCluster miniCluster;
+
+		public MiniClusterPipelineExecutorFactory(MiniCluster miniCluster) {
+			this.miniCluster = miniCluster;
+		}
+
+		@Override
+		public String getName() {
+			return MiniClusterPipelineExecutorServiceLoader.NAME;
+		}
+
+		@Override
+		public boolean isCompatibleWith(Configuration configuration) {
+			return true;
+		}
+
+		@Override
+		public PipelineExecutor getExecutor(Configuration configuration) {
+			return new MiniClusterExecutor(miniCluster);
+		}
+	}
+
+	private static class MiniClusterExecutor implements PipelineExecutor {
+
+		private final MiniCluster miniCluster;
+
+		public MiniClusterExecutor(MiniCluster miniCluster) {
+			this.miniCluster = miniCluster;
+		}
+
+		@Override
+		public CompletableFuture<JobClient> execute(
+				Pipeline pipeline,
+				Configuration configuration,
+				ClassLoader userCodeClassLoader) throws Exception {
+			final JobGraph jobGraph = PipelineExecutorUtils.getJobGraph(pipeline, configuration);
+			return miniCluster.submitJob(jobGraph)
+					.thenApply(result -> new MiniClusterJobClient(
+							result.getJobID(),
+							miniCluster,
+							userCodeClassLoader,
+							MiniClusterJobClient.JobFinalizationBehavior.NOTHING));
+		}
+	}
+}
diff --git a/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/TestEnvironment.java b/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/TestEnvironment.java
index 1b3e99d6a66..05e87b40569 100644
--- a/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/TestEnvironment.java
+++ b/flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/TestEnvironment.java
@@ -19,52 +19,37 @@
 package org.apache.flink.test.util;
 
 import org.apache.flink.api.common.JobExecutionResult;
-import org.apache.flink.api.common.Plan;
 import org.apache.flink.api.java.ExecutionEnvironment;
 import org.apache.flink.api.java.ExecutionEnvironmentFactory;
-import org.apache.flink.client.deployment.executors.LocalExecutor;
-import org.apache.flink.configuration.Configuration;
-import org.apache.flink.configuration.DeploymentOptions;
 import org.apache.flink.core.fs.Path;
-import org.apache.flink.optimizer.DataStatistics;
-import org.apache.flink.optimizer.Optimizer;
-import org.apache.flink.optimizer.plan.OptimizedPlan;
-import org.apache.flink.optimizer.plantranslate.JobGraphGenerator;
-import org.apache.flink.runtime.jobgraph.JobGraph;
-import org.apache.flink.runtime.minicluster.JobExecutor;
 import org.apache.flink.runtime.minicluster.MiniCluster;
 import org.apache.flink.util.Preconditions;
 
 import java.net.URL;
-import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 
 /**
- * A {@link ExecutionEnvironment} implementation which executes its jobs on a
- * {@link MiniCluster}.
+ * A {@link ExecutionEnvironment} implementation which executes its jobs on a {@link MiniCluster}.
  */
 public class TestEnvironment extends ExecutionEnvironment {
 
-	private final JobExecutor jobExecutor;
-
-	private final Collection<Path> jarFiles;
-
-	private final Collection<URL> classPaths;
+	private final MiniCluster miniCluster;
 
 	private TestEnvironment lastEnv;
 
 	public TestEnvironment(
-			JobExecutor jobExecutor,
+			MiniCluster miniCluster,
 			int parallelism,
 			boolean isObjectReuseEnabled,
 			Collection<Path> jarFiles,
 			Collection<URL> classPaths) {
-		this.jobExecutor = Preconditions.checkNotNull(jobExecutor);
-		this.jarFiles = Preconditions.checkNotNull(jarFiles);
-		this.classPaths = Preconditions.checkNotNull(classPaths);
-		getConfiguration().set(DeploymentOptions.TARGET, LocalExecutor.NAME);
-		getConfiguration().set(DeploymentOptions.ATTACHED, true);
+		super(
+				new MiniClusterPipelineExecutorServiceLoader(miniCluster),
+				MiniClusterPipelineExecutorServiceLoader.createConfiguration(jarFiles, classPaths),
+				null);
+
+		this.miniCluster = Preconditions.checkNotNull(miniCluster);
 
 		setParallelism(parallelism);
 
@@ -78,58 +63,33 @@ public class TestEnvironment extends ExecutionEnvironment {
 	}
 
 	public TestEnvironment(
-			JobExecutor executor,
+			MiniCluster executor,
 			int parallelism,
 			boolean isObjectReuseEnabled) {
 		this(
-			executor,
-			parallelism,
-			isObjectReuseEnabled,
-			Collections.emptyList(),
-			Collections.emptyList());
+				executor,
+				parallelism,
+				isObjectReuseEnabled,
+				Collections.emptyList(),
+				Collections.emptyList());
 	}
 
 	@Override
 	public JobExecutionResult getLastJobExecutionResult() {
 		if (lastEnv == null) {
 			return lastJobExecutionResult;
-		}
-		else {
+		} else {
 			return lastEnv.getLastJobExecutionResult();
 		}
 	}
 
-	@Override
-	public JobExecutionResult execute(String jobName) throws Exception {
-		OptimizedPlan op = compileProgram(jobName);
-
-		JobGraphGenerator jgg = new JobGraphGenerator();
-		JobGraph jobGraph = jgg.compileJobGraph(op);
-
-		for (Path jarFile: jarFiles) {
-			jobGraph.addJar(jarFile);
-		}
-
-		jobGraph.setClasspaths(new ArrayList<>(classPaths));
-
-		this.lastJobExecutionResult = jobExecutor.executeJobBlocking(jobGraph);
-		return this.lastJobExecutionResult;
-	}
-
-	private OptimizedPlan compileProgram(String jobName) {
-		Plan p = createProgramPlan(jobName);
-
-		Optimizer pc = new Optimizer(new DataStatistics(), new Configuration());
-		return pc.compile(p);
-	}
-
 	public void setAsContext() {
-		ExecutionEnvironmentFactory factory = new ExecutionEnvironmentFactory() {
-			@Override
-			public ExecutionEnvironment createExecutionEnvironment() {
-				lastEnv = new TestEnvironment(jobExecutor, getParallelism(), getConfig().isObjectReuseEnabled());
-				return lastEnv;
-			}
+		ExecutionEnvironmentFactory factory = () -> {
+			lastEnv = new TestEnvironment(
+					miniCluster,
+					getParallelism(),
+					getConfig().isObjectReuseEnabled());
+			return lastEnv;
 		};
 
 		initializeContextEnvironment(factory);
@@ -142,29 +102,24 @@ public class TestEnvironment extends ExecutionEnvironment {
 	 * environment executes the given jobs on a Flink mini cluster with the given default
 	 * parallelism and the additional jar files and class paths.
 	 *
-	 * @param jobExecutor The executor to run the jobs on
+	 * @param miniCluster The MiniCluster to execute jobs on.
 	 * @param parallelism The default parallelism
 	 * @param jarFiles Additional jar files to execute the job with
 	 * @param classPaths Additional class paths to execute the job with
 	 */
 	public static void setAsContext(
-		final JobExecutor jobExecutor,
-		final int parallelism,
-		final Collection<Path> jarFiles,
-		final Collection<URL> classPaths) {
-
-		ExecutionEnvironmentFactory factory = new ExecutionEnvironmentFactory() {
-			@Override
-			public ExecutionEnvironment createExecutionEnvironment() {
-				return new TestEnvironment(
-					jobExecutor,
-					parallelism,
-					false,
-					jarFiles,
-					classPaths
-				);
-			}
-		};
+			final MiniCluster miniCluster,
+			final int parallelism,
+			final Collection<Path> jarFiles,
+			final Collection<URL> classPaths) {
+
+		ExecutionEnvironmentFactory factory = () -> new TestEnvironment(
+				miniCluster,
+				parallelism,
+				false,
+				jarFiles,
+				classPaths
+		);
 
 		initializeContextEnvironment(factory);
 	}
@@ -174,15 +129,15 @@ public class TestEnvironment extends ExecutionEnvironment {
 	 * environment executes the given jobs on a Flink mini cluster with the given default
 	 * parallelism and the additional jar files and class paths.
 	 *
-	 * @param jobExecutor The executor to run the jobs on
+	 * @param miniCluster The MiniCluster to execute jobs on.
 	 * @param parallelism The default parallelism
 	 */
-	public static void setAsContext(final JobExecutor jobExecutor, final int parallelism) {
+	public static void setAsContext(final MiniCluster miniCluster, final int parallelism) {
 		setAsContext(
-			jobExecutor,
-			parallelism,
-			Collections.emptyList(),
-			Collections.emptyList());
+				miniCluster,
+				parallelism,
+				Collections.emptyList(),
+				Collections.emptyList());
 	}
 
 	public static void unsetAsContext() {
