diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java
index b734969fa7c..a6ac9dfb06c 100644
--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java
+++ b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java
@@ -209,6 +209,11 @@ public final class TestValuesTableFactory implements DynamicTableSourceFactory,
 		.stringType()
 		.defaultValue("DEFAULT"); // class path which implements DynamicTableSource
 
+	private static final ConfigOption<String> TABLE_SINK_CLASS = ConfigOptions
+		.key("table-sink-class")
+		.stringType()
+		.defaultValue("DEFAULT"); // class path which implements DynamicTableSink
+
 	private static final ConfigOption<String> LOOKUP_FUNCTION_CLASS  = ConfigOptions
 		.key("lookup-function-class")
 		.stringType()
@@ -315,15 +320,28 @@ public final class TestValuesTableFactory implements DynamicTableSourceFactory,
 	public DynamicTableSink createDynamicTableSink(Context context) {
 		FactoryUtil.TableFactoryHelper helper = FactoryUtil.createTableFactoryHelper(this, context);
 		helper.validate();
+		String sinkClass = helper.getOptions().get(TABLE_SINK_CLASS);
+
 		boolean isInsertOnly = helper.getOptions().get(SINK_INSERT_ONLY);
 		String runtimeSink = helper.getOptions().get(RUNTIME_SINK);
 		int expectedNum = helper.getOptions().get(SINK_EXPECTED_MESSAGES_NUM);
 		TableSchema schema = context.getCatalogTable().getSchema();
-		return new TestValuesTableSink(
-			schema,
-			context.getObjectIdentifier().getObjectName(),
-			isInsertOnly,
-			runtimeSink, expectedNum);
+		if (sinkClass.equals("DEFAULT")) {
+			return new TestValuesTableSink(
+				schema,
+				context.getObjectIdentifier().getObjectName(),
+				isInsertOnly,
+				runtimeSink, expectedNum);
+		} else {
+			try {
+				return InstantiationUtil.instantiate(
+					sinkClass,
+					DynamicTableSink.class,
+					Thread.currentThread().getContextClassLoader());
+			} catch (FlinkException e) {
+				throw new TableException("Can't instantiate class " + sinkClass, e);
+			}
+		}
 	}
 
 	@Override
@@ -342,6 +360,7 @@ public final class TestValuesTableFactory implements DynamicTableSourceFactory,
 			LOOKUP_FUNCTION_CLASS,
 			ASYNC_ENABLED,
 			TABLE_SOURCE_CLASS,
+			TABLE_SINK_CLASS,
 			SINK_INSERT_ONLY,
 			RUNTIME_SINK,
 			SINK_EXPECTED_MESSAGES_NUM,
@@ -847,4 +866,45 @@ public final class TestValuesTableFactory implements DynamicTableSourceFactory,
 			return "TestValues";
 		}
 	}
+
+	/**
+	 * A TableSink used for testing the implementation of {@link SinkFunction.Context}.
+	 */
+	public static class TestSinkContextTableSink implements DynamicTableSink {
+
+		public static final List<Long> ROWTIMES = new ArrayList<>();
+
+		@Override
+		public ChangelogMode getChangelogMode(ChangelogMode requestedMode) {
+			return ChangelogMode.insertOnly();
+		}
+
+		@Override
+		public SinkRuntimeProvider getSinkRuntimeProvider(Context context) {
+			// clear ROWTIMES first
+			synchronized (ROWTIMES) {
+				ROWTIMES.clear();
+			}
+			SinkFunction<RowData> sinkFunction = new SinkFunction<RowData>() {
+				private static final long serialVersionUID = -4871941979714977824L;
+				@Override
+				public void invoke(RowData value, Context context) throws Exception {
+					synchronized (ROWTIMES) {
+						ROWTIMES.add(context.timestamp());
+					}
+				}
+			};
+			return SinkFunctionProvider.of(sinkFunction);
+		}
+
+		@Override
+		public DynamicTableSink copy() {
+			return new TestSinkContextTableSink();
+		}
+
+		@Override
+		public String asSummaryString() {
+			return "TestSinkContextTableSink";
+		}
+	}
 }
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/table/TableSinkITCase.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/table/TableSinkITCase.scala
index 74dbfa06e09..27395b2360c 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/table/TableSinkITCase.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/table/TableSinkITCase.scala
@@ -22,16 +22,18 @@ import org.apache.flink.api.scala._
 import org.apache.flink.table.api._
 import org.apache.flink.table.api.bridge.scala._
 import org.apache.flink.table.planner.factories.TestValuesTableFactory
-import org.apache.flink.table.planner.factories.TestValuesTableFactory.changelogRow
+import org.apache.flink.table.planner.factories.TestValuesTableFactory.{TestSinkContextTableSink, changelogRow}
 import org.apache.flink.table.planner.runtime.utils.StreamingTestBase
 import org.apache.flink.table.planner.runtime.utils.TestData.{nullData4, smallTupleData3, tupleData3, tupleData5}
 import org.apache.flink.util.ExceptionUtils
-
 import org.junit.Assert.{assertEquals, assertFalse, assertTrue, fail}
 import org.junit.Test
 
 import java.lang.{Long => JLong}
 import java.math.{BigDecimal => JBigDecimal}
+import java.sql.Timestamp
+import java.time.{LocalDateTime, OffsetDateTime, ZoneId, ZoneOffset}
+import java.util.TimeZone
 
 import scala.collection.JavaConversions._
 
@@ -620,4 +622,93 @@ class TableSinkITCase extends StreamingTestBase {
     val expected = List("book,1,12", "book,4,11", "fruit,3,44")
     assertEquals(expected.sorted, result.sorted)
   }
+
+  @Test
+  def testSinkContext(): Unit = {
+    val data = List(
+      rowOf("1970-01-01 00:00:00.001", localDateTime(1L), 1, 1d),
+      rowOf("1970-01-01 00:00:00.002", localDateTime(2L), 1, 2d),
+      rowOf("1970-01-01 00:00:00.003", localDateTime(3L), 1, 2d),
+      rowOf("1970-01-01 00:00:00.004", localDateTime(4L), 1, 5d),
+      rowOf("1970-01-01 00:00:00.007", localDateTime(7L), 1, 3d),
+      rowOf("1970-01-01 00:00:00.008", localDateTime(8L), 1, 3d),
+      rowOf("1970-01-01 00:00:00.016", localDateTime(16L), 1, 4d))
+
+    val dataId: String = TestValuesTableFactory.registerData(data)
+
+    val sourceDDL =
+      s"""
+         |CREATE TABLE src (
+         |  log_ts STRING,
+         |  ts TIMESTAMP(3),
+         |  a INT,
+         |  b DOUBLE,
+         |  WATERMARK FOR ts AS ts - INTERVAL '0.001' SECOND
+         |) WITH (
+         |  'connector' = 'values',
+         |  'data-id' = '$dataId'
+         |)
+      """.stripMargin
+
+    val sinkDDL =
+      s"""
+         |CREATE TABLE sink (
+         |  log_ts STRING,
+         |  ts TIMESTAMP(3),
+         |  a INT,
+         |  b DOUBLE
+         |) WITH (
+         |  'connector' = 'values',
+         |  'table-sink-class' = '${classOf[TestSinkContextTableSink].getName}'
+         |)
+      """.stripMargin
+
+    tEnv.executeSql(sourceDDL)
+    tEnv.executeSql(sinkDDL)
+
+    //---------------------------------------------------------------------------------------
+    // Verify writing out a source directly with the rowtime attribute
+    //---------------------------------------------------------------------------------------
+
+    tEnv.executeSql("INSERT INTO sink SELECT * FROM src").await()
+
+    val expected = List(1000, 2000, 3000, 4000, 7000, 8000, 16000)
+    assertEquals(expected.sorted, TestSinkContextTableSink.ROWTIMES.sorted)
+
+    val sinkDDL2 =
+      s"""
+         |CREATE TABLE sink2 (
+         |  window_rowtime TIMESTAMP(3),
+         |  b DOUBLE
+         |) WITH (
+         |  'connector' = 'values',
+         |  'table-sink-class' = '${classOf[TestSinkContextTableSink].getName}'
+         |)
+      """.stripMargin
+    tEnv.executeSql(sinkDDL2)
+
+    //---------------------------------------------------------------------------------------
+    // Verify writing out with additional operator to generate a new rowtime attribute
+    //---------------------------------------------------------------------------------------
+
+    tEnv.executeSql(
+      """
+        |INSERT INTO sink2
+        |SELECT
+        |  TUMBLE_ROWTIME(ts, INTERVAL '5' SECOND),
+        |  SUM(b)
+        |FROM src
+        |GROUP BY TUMBLE(ts, INTERVAL '5' SECOND)
+        |""".stripMargin
+    ).await()
+
+    val expected2 = List(4999, 9999, 19999)
+    assertEquals(expected2.sorted, TestSinkContextTableSink.ROWTIMES.sorted)
+  }
+
+  // ------------------------------------------------------------------------------------------
+
+  private def localDateTime(epochSecond: Long): LocalDateTime = {
+    LocalDateTime.ofEpochSecond(epochSecond, 0, ZoneOffset.UTC)
+  }
 }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/sink/SinkOperator.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/sink/SinkOperator.java
index e7586d64751..a3fe744fc9a 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/sink/SinkOperator.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/sink/SinkOperator.java
@@ -32,6 +32,7 @@ import org.apache.flink.table.api.TableException;
 import org.apache.flink.table.api.config.ExecutionConfigOptions;
 import org.apache.flink.table.api.config.ExecutionConfigOptions.NotNullEnforcer;
 import org.apache.flink.table.data.RowData;
+import org.apache.flink.table.data.TimestampData;
 
 /**
  * A {@link StreamOperator} for executing {@link SinkFunction SinkFunctions}. This operator
@@ -140,8 +141,13 @@ public class SinkOperator extends AbstractUdfStreamOperator<Object, SinkFunction
 
 		@Override
 		public Long timestamp() {
-			if (rowtimeFieldIndex > 0) {
-				return element.getValue().getLong(rowtimeFieldIndex);
+			if (rowtimeFieldIndex >= 0) {
+				TimestampData timestamp = element.getValue().getTimestamp(rowtimeFieldIndex, 3);
+				if (timestamp != null) {
+					return timestamp.getMillisecond();
+				} else {
+					return null;
+				}
 			}
 			return null;
 		}
