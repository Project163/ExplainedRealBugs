diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/pom.xml b/flink-connectors/flink-connector-aws-kinesis-data-streams/pom.xml
index d0f19e38b5b..8e4b99b8270 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/pom.xml
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/pom.xml
@@ -85,6 +85,14 @@ under the License.
 			<scope>test</scope>
 		</dependency>
 
+		<dependency>
+			<groupId>org.apache.flink</groupId>
+			<artifactId>flink-connector-base</artifactId>
+			<version>${project.version}</version>
+			<type>test-jar</type>
+			<scope>test</scope>
+		</dependency>
+
 		<dependency>
 			<groupId>org.apache.flink</groupId>
 			<artifactId>flink-connector-aws-base</artifactId>
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSink.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSink.java
index 50ff4c1b249..e4b977967de 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSink.java
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSink.java
@@ -21,13 +21,13 @@ import org.apache.flink.annotation.Internal;
 import org.apache.flink.annotation.PublicEvolving;
 import org.apache.flink.api.connector.sink.SinkWriter;
 import org.apache.flink.connector.base.sink.AsyncSinkBase;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.core.io.SimpleVersionedSerializer;
 import org.apache.flink.util.Preconditions;
 
 import software.amazon.awssdk.services.kinesis.model.PutRecordsRequestEntry;
 
-import java.util.Collection;
 import java.util.List;
 import java.util.Optional;
 import java.util.Properties;
@@ -113,8 +113,8 @@ public class KinesisDataStreamsSink<InputT> extends AsyncSinkBase<InputT, PutRec
 
     @Internal
     @Override
-    public SinkWriter<InputT, Void, Collection<PutRecordsRequestEntry>> createWriter(
-            InitContext context, List<Collection<PutRecordsRequestEntry>> states) {
+    public SinkWriter<InputT, Void, BufferedRequestState<PutRecordsRequestEntry>> createWriter(
+            InitContext context, List<BufferedRequestState<PutRecordsRequestEntry>> states) {
         return new KinesisDataStreamsSinkWriter<>(
                 getElementConverter(),
                 context,
@@ -126,13 +126,14 @@ public class KinesisDataStreamsSink<InputT> extends AsyncSinkBase<InputT, PutRec
                 getMaxRecordSizeInBytes(),
                 failOnError,
                 streamName,
-                kinesisClientProperties);
+                kinesisClientProperties,
+                states);
     }
 
     @Internal
     @Override
-    public Optional<SimpleVersionedSerializer<Collection<PutRecordsRequestEntry>>>
+    public Optional<SimpleVersionedSerializer<BufferedRequestState<PutRecordsRequestEntry>>>
             getWriterStateSerializer() {
-        return Optional.empty();
+        return Optional.of(new KinesisDataStreamsStateSerializer());
     }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
index b291c120f41..50566dcc511 100644
--- a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsSinkWriter.java
@@ -21,6 +21,7 @@ import org.apache.flink.api.connector.sink.Sink;
 import org.apache.flink.connector.aws.util.AWSAsyncSinkUtil;
 import org.apache.flink.connector.aws.util.AWSGeneralUtil;
 import org.apache.flink.connector.base.sink.writer.AsyncSinkWriter;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.metrics.Counter;
 import org.apache.flink.metrics.groups.SinkWriterMetricGroup;
@@ -83,6 +84,34 @@ class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRe
             boolean failOnError,
             String streamName,
             Properties kinesisClientProperties) {
+        this(
+                elementConverter,
+                context,
+                maxBatchSize,
+                maxInFlightRequests,
+                maxBufferedRequests,
+                maxBatchSizeInBytes,
+                maxTimeInBufferMS,
+                maxRecordSizeInBytes,
+                failOnError,
+                streamName,
+                kinesisClientProperties,
+                Collections.emptyList());
+    }
+
+    KinesisDataStreamsSinkWriter(
+            ElementConverter<InputT, PutRecordsRequestEntry> elementConverter,
+            Sink.InitContext context,
+            int maxBatchSize,
+            int maxInFlightRequests,
+            int maxBufferedRequests,
+            long maxBatchSizeInBytes,
+            long maxTimeInBufferMS,
+            long maxRecordSizeInBytes,
+            boolean failOnError,
+            String streamName,
+            Properties kinesisClientProperties,
+            List<BufferedRequestState<PutRecordsRequestEntry>> states) {
         super(
                 elementConverter,
                 context,
@@ -91,7 +120,8 @@ class KinesisDataStreamsSinkWriter<InputT> extends AsyncSinkWriter<InputT, PutRe
                 maxBufferedRequests,
                 maxBatchSizeInBytes,
                 maxTimeInBufferMS,
-                maxRecordSizeInBytes);
+                maxRecordSizeInBytes,
+                states);
         this.failOnError = failOnError;
         this.streamName = streamName;
         this.metrics = context.metricGroup();
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsStateSerializer.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsStateSerializer.java
new file mode 100644
index 00000000000..f1986efa0ac
--- /dev/null
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/main/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsStateSerializer.java
@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.kinesis.sink;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.connector.base.sink.writer.AsyncSinkWriterStateSerializer;
+
+import software.amazon.awssdk.core.SdkBytes;
+import software.amazon.awssdk.services.kinesis.model.PutRecordsRequestEntry;
+
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+
+/** Kinesis Streams implementation {@link AsyncSinkWriterStateSerializer}. */
+@Internal
+public class KinesisDataStreamsStateSerializer
+        extends AsyncSinkWriterStateSerializer<PutRecordsRequestEntry> {
+    @Override
+    protected void serializeRequestToStream(PutRecordsRequestEntry request, DataOutputStream out)
+            throws IOException {
+        out.write(request.data().asByteArrayUnsafe());
+        serializePartitionKeyToStream(request.partitionKey(), out);
+        validateExplicitHashKey(request);
+    }
+
+    protected void serializePartitionKeyToStream(String partitionKey, DataOutputStream out)
+            throws IOException {
+        out.writeInt(partitionKey.length());
+        out.write(partitionKey.getBytes(StandardCharsets.UTF_8));
+    }
+
+    protected void validateExplicitHashKey(PutRecordsRequestEntry request) {
+        if (request.explicitHashKey() != null) {
+            throw new IllegalStateException(
+                    String.format(
+                            "KinesisDataStreamsStateSerializer is incompatible with ElementConverter."
+                                    + "Serializer version %d  does not support explicit hash key.",
+                            getVersion()));
+        }
+    }
+
+    @Override
+    protected PutRecordsRequestEntry deserializeRequestFromStream(
+            long requestSize, DataInputStream in) throws IOException {
+        byte[] requestData = new byte[(int) requestSize];
+        in.read(requestData);
+
+        return PutRecordsRequestEntry.builder()
+                .data(SdkBytes.fromByteArray(requestData))
+                .partitionKey(deserializePartitionKeyFromStream(in))
+                .build();
+    }
+
+    protected String deserializePartitionKeyFromStream(DataInputStream in) throws IOException {
+        int partitionKeyLength = in.readInt();
+        byte[] requestPartitionKeyData = new byte[(int) partitionKeyLength];
+        in.read(requestPartitionKeyData);
+        return new String(requestPartitionKeyData, StandardCharsets.UTF_8);
+    }
+
+    @Override
+    public int getVersion() {
+        return 1;
+    }
+}
diff --git a/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsStateSerializerTest.java b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsStateSerializerTest.java
new file mode 100644
index 00000000000..01a94156720
--- /dev/null
+++ b/flink-connectors/flink-connector-aws-kinesis-data-streams/src/test/java/org/apache/flink/connector/kinesis/sink/KinesisDataStreamsStateSerializerTest.java
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.kinesis.sink;
+
+import org.apache.flink.api.common.serialization.SimpleStringSchema;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
+import org.apache.flink.connector.base.sink.writer.ElementConverter;
+
+import org.junit.Test;
+import software.amazon.awssdk.services.kinesis.model.PutRecordsRequestEntry;
+
+import java.io.IOException;
+
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkWriterTestUtils.assertThatBufferStatesAreEqual;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkWriterTestUtils.getTestState;
+
+/** Test class for {@link KinesisDataStreamsStateSerializer}. */
+public class KinesisDataStreamsStateSerializerTest {
+
+    private static final ElementConverter<String, PutRecordsRequestEntry> ELEMENT_CONVERTER =
+            KinesisDataStreamsSinkElementConverter.<String>builder()
+                    .setSerializationSchema(new SimpleStringSchema())
+                    .setPartitionKeyGenerator(element -> String.valueOf(element.hashCode()))
+                    .build();
+
+    @Test
+    public void testSerializeAndDeserialize() throws IOException {
+        BufferedRequestState<PutRecordsRequestEntry> expectedState =
+                getTestState(ELEMENT_CONVERTER, this::getRequestSize);
+
+        KinesisDataStreamsStateSerializer serializer = new KinesisDataStreamsStateSerializer();
+        BufferedRequestState<PutRecordsRequestEntry> actualState =
+                serializer.deserialize(1, serializer.serialize(expectedState));
+        assertThatBufferStatesAreEqual(actualState, expectedState);
+    }
+
+    private int getRequestSize(PutRecordsRequestEntry requestEntry) {
+        return requestEntry.data().asByteArrayUnsafe().length;
+    }
+}
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSink.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSink.java
index 50f04d4ee1d..76fa0f7caed 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSink.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSink.java
@@ -20,13 +20,13 @@ package org.apache.flink.connector.firehose.sink;
 import org.apache.flink.annotation.PublicEvolving;
 import org.apache.flink.api.connector.sink.SinkWriter;
 import org.apache.flink.connector.base.sink.AsyncSinkBase;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.core.io.SimpleVersionedSerializer;
 import org.apache.flink.util.Preconditions;
 
 import software.amazon.awssdk.services.firehose.model.Record;
 
-import java.util.Collection;
 import java.util.List;
 import java.util.Optional;
 import java.util.Properties;
@@ -92,8 +92,8 @@ public class KinesisFirehoseSink<InputT> extends AsyncSinkBase<InputT, Record> {
     }
 
     @Override
-    public SinkWriter<InputT, Void, Collection<Record>> createWriter(
-            InitContext context, List<Collection<Record>> states) {
+    public SinkWriter<InputT, Void, BufferedRequestState<Record>> createWriter(
+            InitContext context, List<BufferedRequestState<Record>> states) {
         return new KinesisFirehoseSinkWriter<>(
                 getElementConverter(),
                 context,
@@ -105,11 +105,13 @@ public class KinesisFirehoseSink<InputT> extends AsyncSinkBase<InputT, Record> {
                 getMaxRecordSizeInBytes(),
                 failOnError,
                 deliveryStreamName,
-                firehoseClientProperties);
+                firehoseClientProperties,
+                states);
     }
 
     @Override
-    public Optional<SimpleVersionedSerializer<Collection<Record>>> getWriterStateSerializer() {
-        return Optional.empty();
+    public Optional<SimpleVersionedSerializer<BufferedRequestState<Record>>>
+            getWriterStateSerializer() {
+        return Optional.of(new KinesisFirehoseStateSerializer());
     }
 }
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
index 0d6ff23ea46..47ce6e3a06d 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriter.java
@@ -22,6 +22,7 @@ import org.apache.flink.api.connector.sink.Sink;
 import org.apache.flink.connector.aws.util.AWSAsyncSinkUtil;
 import org.apache.flink.connector.aws.util.AWSGeneralUtil;
 import org.apache.flink.connector.base.sink.writer.AsyncSinkWriter;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.metrics.Counter;
 import org.apache.flink.metrics.groups.SinkWriterMetricGroup;
@@ -103,6 +104,34 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
             boolean failOnError,
             String deliveryStreamName,
             Properties firehoseClientProperties) {
+        this(
+                elementConverter,
+                context,
+                maxBatchSize,
+                maxInFlightRequests,
+                maxBufferedRequests,
+                maxBatchSizeInBytes,
+                maxTimeInBufferMS,
+                maxRecordSizeInBytes,
+                failOnError,
+                deliveryStreamName,
+                firehoseClientProperties,
+                Collections.emptyList());
+    }
+
+    KinesisFirehoseSinkWriter(
+            ElementConverter<InputT, Record> elementConverter,
+            Sink.InitContext context,
+            int maxBatchSize,
+            int maxInFlightRequests,
+            int maxBufferedRequests,
+            long maxBatchSizeInBytes,
+            long maxTimeInBufferMS,
+            long maxRecordSizeInBytes,
+            boolean failOnError,
+            String deliveryStreamName,
+            Properties firehoseClientProperties,
+            List<BufferedRequestState<Record>> initialStates) {
         super(
                 elementConverter,
                 context,
@@ -111,7 +140,8 @@ class KinesisFirehoseSinkWriter<InputT> extends AsyncSinkWriter<InputT, Record>
                 maxBufferedRequests,
                 maxBatchSizeInBytes,
                 maxTimeInBufferMS,
-                maxRecordSizeInBytes);
+                maxRecordSizeInBytes,
+                initialStates);
         this.failOnError = failOnError;
         this.deliveryStreamName = deliveryStreamName;
         this.metrics = context.metricGroup();
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseStateSerializer.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseStateSerializer.java
new file mode 100644
index 00000000000..36162e66498
--- /dev/null
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/main/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseStateSerializer.java
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.firehose.sink;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.connector.base.sink.writer.AsyncSinkWriterStateSerializer;
+
+import software.amazon.awssdk.core.SdkBytes;
+import software.amazon.awssdk.services.firehose.model.Record;
+
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+
+/** Kinesis Firehose implementation {@link AsyncSinkWriterStateSerializer}. */
+@Internal
+public class KinesisFirehoseStateSerializer extends AsyncSinkWriterStateSerializer<Record> {
+    @Override
+    protected void serializeRequestToStream(Record request, DataOutputStream out)
+            throws IOException {
+        out.write(request.data().asByteArrayUnsafe());
+    }
+
+    @Override
+    protected Record deserializeRequestFromStream(long requestSize, DataInputStream in)
+            throws IOException {
+        byte[] requestData = new byte[(int) requestSize];
+        in.read(requestData);
+        return Record.builder().data(SdkBytes.fromByteArray(requestData)).build();
+    }
+
+    @Override
+    public int getVersion() {
+        return 1;
+    }
+}
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java
index d840033716b..87731272c43 100644
--- a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseSinkWriterTest.java
@@ -20,6 +20,7 @@ package org.apache.flink.connector.firehose.sink;
 import org.apache.flink.api.common.serialization.SimpleStringSchema;
 import org.apache.flink.api.connector.sink.SinkWriter;
 import org.apache.flink.connector.aws.config.AWSConfigConstants;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.connector.base.sink.writer.TestSinkInitContext;
 
@@ -32,7 +33,6 @@ import software.amazon.awssdk.services.firehose.model.Record;
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
-import java.util.Collection;
 import java.util.Properties;
 
 import static org.apache.flink.connector.aws.config.AWSConfigConstants.AWS_ENDPOINT;
@@ -95,7 +95,7 @@ public class KinesisFirehoseSinkWriterTest {
                         true,
                         "test-stream",
                         prop);
-        SinkWriter<String, Void, Collection<Record>> writer =
+        SinkWriter<String, Void, BufferedRequestState<Record>> writer =
                 kinesisFirehoseSink.createWriter(ctx, new ArrayList<>());
 
         for (int i = 0; i < 12; i++) {
diff --git a/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseStateSerializerTest.java b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseStateSerializerTest.java
new file mode 100644
index 00000000000..ce4268e96df
--- /dev/null
+++ b/flink-connectors/flink-connector-aws-kinesis-firehose/src/test/java/org/apache/flink/connector/firehose/sink/KinesisFirehoseStateSerializerTest.java
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.firehose.sink;
+
+import org.apache.flink.api.common.serialization.SimpleStringSchema;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
+import org.apache.flink.connector.base.sink.writer.ElementConverter;
+
+import org.junit.Test;
+import software.amazon.awssdk.services.firehose.model.Record;
+
+import java.io.IOException;
+
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkWriterTestUtils.assertThatBufferStatesAreEqual;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkWriterTestUtils.getTestState;
+
+/** Test class for {@link KinesisFirehoseStateSerializer}. */
+public class KinesisFirehoseStateSerializerTest {
+
+    private static final ElementConverter<String, Record> ELEMENT_CONVERTER =
+            KinesisFirehoseSinkElementConverter.<String>builder()
+                    .setSerializationSchema(new SimpleStringSchema())
+                    .build();
+
+    @Test
+    public void testSerializeAndDeserialize() throws IOException {
+        BufferedRequestState<Record> expectedState =
+                getTestState(ELEMENT_CONVERTER, this::getRequestSize);
+
+        KinesisFirehoseStateSerializer serializer = new KinesisFirehoseStateSerializer();
+        BufferedRequestState<Record> actualState =
+                serializer.deserialize(1, serializer.serialize(expectedState));
+
+        assertThatBufferStatesAreEqual(actualState, expectedState);
+    }
+
+    private int getRequestSize(Record requestEntry) {
+        return requestEntry.data().asByteArrayUnsafe().length;
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/AsyncSinkBase.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/AsyncSinkBase.java
index 80487997c01..872e95133bd 100644
--- a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/AsyncSinkBase.java
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/AsyncSinkBase.java
@@ -21,12 +21,12 @@ import org.apache.flink.annotation.PublicEvolving;
 import org.apache.flink.api.connector.sink.Committer;
 import org.apache.flink.api.connector.sink.GlobalCommitter;
 import org.apache.flink.api.connector.sink.Sink;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.connector.base.sink.writer.ElementConverter;
 import org.apache.flink.core.io.SimpleVersionedSerializer;
 import org.apache.flink.util.Preconditions;
 
 import java.io.Serializable;
-import java.util.Collection;
 import java.util.Optional;
 
 /**
@@ -49,7 +49,7 @@ import java.util.Optional;
  */
 @PublicEvolving
 public abstract class AsyncSinkBase<InputT, RequestEntryT extends Serializable>
-        implements Sink<InputT, Void, Collection<RequestEntryT>, Void> {
+        implements Sink<InputT, Void, BufferedRequestState<RequestEntryT>, Void> {
 
     private final ElementConverter<InputT, RequestEntryT> elementConverter;
     private final int maxBatchSize;
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java
index 263164e4d5b..0457b08bd78 100644
--- a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriter.java
@@ -29,14 +29,11 @@ import java.io.IOException;
 import java.io.Serializable;
 import java.util.ArrayDeque;
 import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
 import java.util.Collections;
 import java.util.Deque;
 import java.util.List;
 import java.util.ListIterator;
 import java.util.function.Consumer;
-import java.util.stream.Collectors;
 
 /**
  * A generic sink writer that handles the general behaviour of a sink such as batching and flushing,
@@ -52,7 +49,7 @@ import java.util.stream.Collectors;
  */
 @PublicEvolving
 public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable>
-        implements SinkWriter<InputT, Void, Collection<RequestEntryT>> {
+        implements SinkWriter<InputT, Void, BufferedRequestState<RequestEntryT>> {
 
     private final MailboxExecutor mailboxExecutor;
     private final Sink.ProcessingTimeService timeService;
@@ -209,6 +206,28 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
             long maxBatchSizeInBytes,
             long maxTimeInBufferMS,
             long maxRecordSizeInBytes) {
+        this(
+                elementConverter,
+                context,
+                maxBatchSize,
+                maxInFlightRequests,
+                maxBufferedRequests,
+                maxBatchSizeInBytes,
+                maxTimeInBufferMS,
+                maxRecordSizeInBytes,
+                Collections.emptyList());
+    }
+
+    public AsyncSinkWriter(
+            ElementConverter<InputT, RequestEntryT> elementConverter,
+            Sink.InitContext context,
+            int maxBatchSize,
+            int maxInFlightRequests,
+            int maxBufferedRequests,
+            long maxBatchSizeInBytes,
+            long maxTimeInBufferMS,
+            long maxRecordSizeInBytes,
+            List<BufferedRequestState<RequestEntryT>> states) {
         this.elementConverter = elementConverter;
         this.mailboxExecutor = context.getMailboxExecutor();
         this.timeService = context.getProcessingTimeService();
@@ -250,6 +269,7 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
                                     throw exception;
                                 },
                                 "A fatal exception occurred in the sink that cannot be recovered from or should not be retried.");
+        initialize(states);
     }
 
     private void registerCallback() {
@@ -406,11 +426,33 @@ public abstract class AsyncSinkWriter<InputT, RequestEntryT extends Serializable
      * a failure/restart of the application.
      */
     @Override
-    public List<Collection<RequestEntryT>> snapshotState() {
-        return Arrays.asList(
-                bufferedRequestEntries.stream()
-                        .map(RequestEntryWrapper::getRequestEntry)
-                        .collect(Collectors.toList()));
+    public List<BufferedRequestState<RequestEntryT>> snapshotState() {
+        return Collections.singletonList(new BufferedRequestState<>((bufferedRequestEntries)));
+    }
+
+    protected void initialize(List<BufferedRequestState<RequestEntryT>> states) {
+        if (states.isEmpty()) {
+            return;
+        }
+
+        if (states.size() > 1) {
+            throw new IllegalStateException(
+                    "Writer failed to initialize due to multiple initial states.");
+        }
+
+        BufferedRequestState<RequestEntryT> state = states.get(0);
+        this.bufferedRequestEntries.addAll(state.getBufferedRequestEntries());
+
+        for (RequestEntryWrapper<RequestEntryT> wrapper : bufferedRequestEntries) {
+            if (wrapper.getSize() > maxRecordSizeInBytes) {
+                throw new IllegalStateException(
+                        String.format(
+                                "State contains record of size %d which exceeds sink maximum record size %d.",
+                                wrapper.getSize(), maxRecordSizeInBytes));
+            }
+        }
+
+        this.bufferedRequestEntriesTotalSizeInBytes = state.getStateSize();
     }
 
     @Override
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterStateSerializer.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterStateSerializer.java
new file mode 100644
index 00000000000..61d6771348f
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterStateSerializer.java
@@ -0,0 +1,100 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.core.io.SimpleVersionedSerializer;
+
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+
+/**
+ * Serializer class for {@link AsyncSinkWriter} state.
+ *
+ * @param <RequestEntryT> Writer Request Entry type
+ */
+@Internal
+public abstract class AsyncSinkWriterStateSerializer<RequestEntryT extends Serializable>
+        implements SimpleVersionedSerializer<BufferedRequestState<RequestEntryT>> {
+    private static final long DATA_IDENTIFIER = -1;
+
+    /**
+     * Serializes state in form of
+     * [DATA_IDENTIFIER,NUM_OF_ELEMENTS,SIZE1,REQUEST1,SIZE2,REQUEST2....].
+     */
+    @Override
+    public byte[] serialize(BufferedRequestState<RequestEntryT> obj) throws IOException {
+        Collection<RequestEntryWrapper<RequestEntryT>> bufferState =
+                obj.getBufferedRequestEntries();
+
+        try (final ByteArrayOutputStream baos = new ByteArrayOutputStream();
+                final DataOutputStream out = new DataOutputStream(baos)) {
+
+            out.writeLong(DATA_IDENTIFIER);
+            out.writeInt(bufferState.size());
+
+            for (RequestEntryWrapper<RequestEntryT> wrapper : bufferState) {
+                out.writeLong(wrapper.getSize());
+                serializeRequestToStream(wrapper.getRequestEntry(), out);
+            }
+
+            return baos.toByteArray();
+        }
+    }
+
+    @Override
+    public BufferedRequestState<RequestEntryT> deserialize(int version, byte[] serialized)
+            throws IOException {
+        try (final ByteArrayInputStream bais = new ByteArrayInputStream(serialized);
+                final DataInputStream in = new DataInputStream(bais)) {
+
+            validateIdentifier(in);
+
+            int size = in.readInt();
+            List<RequestEntryWrapper<RequestEntryT>> serializedState = new ArrayList<>();
+
+            for (int i = 0; i < size; i++) {
+                long requestSize = in.readLong();
+                RequestEntryT request = deserializeRequestFromStream(requestSize, in);
+                serializedState.add(new RequestEntryWrapper<>(request, requestSize));
+            }
+
+            return new BufferedRequestState<>(serializedState);
+        }
+    }
+
+    protected abstract void serializeRequestToStream(RequestEntryT request, DataOutputStream out)
+            throws IOException;
+
+    protected abstract RequestEntryT deserializeRequestFromStream(
+            long requestSize, DataInputStream in) throws IOException;
+
+    private void validateIdentifier(DataInputStream in) throws IOException {
+        if (in.readLong() != DATA_IDENTIFIER) {
+            throw new IllegalStateException("Corrupted data to deserialize");
+        }
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/BufferedRequestState.java b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/BufferedRequestState.java
new file mode 100644
index 00000000000..6f0caf8e81d
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/main/java/org/apache/flink/connector/base/sink/writer/BufferedRequestState.java
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import org.apache.flink.annotation.PublicEvolving;
+
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Deque;
+import java.util.List;
+
+/**
+ * Class holding state of {@link AsyncSinkWriter} needed at taking a snapshot. The state captures
+ * the {@code bufferedRequestEntries} buffer for the writer at snapshot to resume the requests. This
+ * guarantees at least once semantic in sending requests where restoring from a snapshot where
+ * buffered requests were flushed to the sink will cause duplicate requests.
+ *
+ * @param <RequestEntryT> request type.
+ */
+@PublicEvolving
+public class BufferedRequestState<RequestEntryT extends Serializable> implements Serializable {
+    private final List<RequestEntryWrapper<RequestEntryT>> bufferedRequestEntries;
+    private final long stateSize;
+
+    public BufferedRequestState(Deque<RequestEntryWrapper<RequestEntryT>> bufferedRequestEntries) {
+        this.bufferedRequestEntries = new ArrayList<>(bufferedRequestEntries);
+        this.stateSize = calculateStateSize();
+    }
+
+    public BufferedRequestState(List<RequestEntryWrapper<RequestEntryT>> bufferedRequestEntries) {
+        this.bufferedRequestEntries = new ArrayList<>(bufferedRequestEntries);
+        this.stateSize = calculateStateSize();
+    }
+
+    public List<RequestEntryWrapper<RequestEntryT>> getBufferedRequestEntries() {
+        return bufferedRequestEntries;
+    }
+
+    public long getStateSize() {
+        return stateSize;
+    }
+
+    private long calculateStateSize() {
+        long stateSize = 0;
+        for (RequestEntryWrapper<RequestEntryT> requestEntryWrapper : bufferedRequestEntries) {
+            stateSize += requestEntryWrapper.getSize();
+        }
+
+        return stateSize;
+    }
+
+    public static <T extends Serializable> BufferedRequestState<T> emptyState() {
+        return new BufferedRequestState<>(Collections.emptyList());
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/ArrayListAsyncSink.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/ArrayListAsyncSink.java
index 946e97684d5..a7680839d31 100644
--- a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/ArrayListAsyncSink.java
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/ArrayListAsyncSink.java
@@ -19,10 +19,10 @@ package org.apache.flink.connector.base.sink;
 
 import org.apache.flink.api.connector.sink.SinkWriter;
 import org.apache.flink.connector.base.sink.writer.AsyncSinkWriter;
+import org.apache.flink.connector.base.sink.writer.BufferedRequestState;
 import org.apache.flink.core.io.SimpleVersionedSerializer;
 
 import java.util.Arrays;
-import java.util.Collection;
 import java.util.List;
 import java.util.Optional;
 import java.util.function.Consumer;
@@ -52,8 +52,8 @@ public class ArrayListAsyncSink extends AsyncSinkBase<String, Integer> {
     }
 
     @Override
-    public SinkWriter<String, Void, Collection<Integer>> createWriter(
-            InitContext context, List<Collection<Integer>> states) {
+    public SinkWriter<String, Void, BufferedRequestState<Integer>> createWriter(
+            InitContext context, List<BufferedRequestState<Integer>> states) {
         /* SinkWriter implementing {@code submitRequestEntries} that is used to define the persistence
          * logic into {@code ArrayListDestination}.
          */
@@ -86,7 +86,8 @@ public class ArrayListAsyncSink extends AsyncSinkBase<String, Integer> {
     }
 
     @Override
-    public Optional<SimpleVersionedSerializer<Collection<Integer>>> getWriterStateSerializer() {
+    public Optional<SimpleVersionedSerializer<BufferedRequestState<Integer>>>
+            getWriterStateSerializer() {
         return Optional.empty();
     }
 }
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterStateSerializerTest.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterStateSerializerTest.java
new file mode 100644
index 00000000000..5fe2ccd8a44
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterStateSerializerTest.java
@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import org.junit.Test;
+
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkWriterTestUtils.assertThatBufferStatesAreEqual;
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkWriterTestUtils.getTestState;
+
+/** Test class for {@link AsyncSinkWriterStateSerializer}. */
+public class AsyncSinkWriterStateSerializerTest {
+
+    @Test
+    public void testSerializeAndDeSerialize() throws IOException {
+        AsyncSinkWriterStateSerializerImpl stateSerializer =
+                new AsyncSinkWriterStateSerializerImpl();
+        BufferedRequestState<String> state =
+                getTestState((element, context) -> element, String::length);
+        BufferedRequestState<String> deserializedState =
+                stateSerializer.deserialize(0, stateSerializer.serialize(state));
+
+        assertThatBufferStatesAreEqual(state, deserializedState);
+    }
+
+    private static class AsyncSinkWriterStateSerializerImpl
+            extends AsyncSinkWriterStateSerializer<String> {
+
+        @Override
+        protected void serializeRequestToStream(String request, DataOutputStream out)
+                throws IOException {
+            out.write(request.getBytes(StandardCharsets.UTF_8));
+        }
+
+        @Override
+        protected String deserializeRequestFromStream(long requestSize, DataInputStream in)
+                throws IOException {
+            byte[] requestData = new byte[(int) requestSize];
+            in.read(requestData);
+            return new String(requestData, StandardCharsets.UTF_8);
+        }
+
+        @Override
+        public int getVersion() {
+            return 1;
+        }
+    }
+}
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java
index 00a08b19190..671f6c6897f 100644
--- a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTest.java
@@ -26,6 +26,7 @@ import org.junit.Test;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
@@ -36,6 +37,8 @@ import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
 import java.util.stream.Collectors;
 
+import static org.apache.flink.connector.base.sink.writer.AsyncSinkWriterTestUtils.assertThatBufferStatesAreEqual;
+import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
 import static org.junit.jupiter.api.Assertions.assertEquals;
 import static org.junit.jupiter.api.Assertions.assertFalse;
 import static org.junit.jupiter.api.Assertions.assertThrows;
@@ -122,7 +125,7 @@ public class AsyncSinkWriterTest {
             sink.write(String.valueOf(i));
         }
         assertEquals(20, res.size());
-        assertEquals(Arrays.asList(20, 21, 22), new ArrayList<>(sink.snapshotState().get(0)));
+        assertThatBufferStatesAreEqual(sink.wrapRequests(20, 21, 22), getWriterState(sink));
     }
 
     @Test
@@ -192,11 +195,12 @@ public class AsyncSinkWriterTest {
 
         sink.write("25");
         sink.write("55");
-        assertEquals(Arrays.asList(25, 55), new ArrayList<>(sink.snapshotState().get(0)));
+        assertThatBufferStatesAreEqual(sink.wrapRequests(25, 55), getWriterState(sink));
         assertEquals(0, res.size());
 
         sink.write("75");
-        assertEquals(Arrays.asList(), new ArrayList<>(sink.snapshotState().get(0)));
+        assertThatBufferStatesAreEqual(BufferedRequestState.emptyState(), getWriterState(sink));
+
         assertEquals(3, res.size());
     }
 
@@ -216,9 +220,9 @@ public class AsyncSinkWriterTest {
         sink.write("75");
         sink.write("95");
         sink.write("955");
-        assertEquals(Arrays.asList(95, 955), new ArrayList<>(sink.snapshotState().get(0)));
+        assertThatBufferStatesAreEqual(sink.wrapRequests(95, 955), getWriterState(sink));
         sink.prepareCommit(true);
-        assertEquals(Arrays.asList(), new ArrayList<>(sink.snapshotState().get(0)));
+        assertThatBufferStatesAreEqual(BufferedRequestState.emptyState(), getWriterState(sink));
     }
 
     @Test
@@ -321,7 +325,7 @@ public class AsyncSinkWriterTest {
 
         // Everything is saved
         assertEquals(Arrays.asList(25, 55, 965, 75, 95, 45, 955, 550, 35, 535), res);
-        assertEquals(0, sink.snapshotState().get(0).size());
+        assertEquals(0, getWriterState(sink).getStateSize());
     }
 
     @Test
@@ -420,7 +424,7 @@ public class AsyncSinkWriterTest {
             throws IOException, InterruptedException {
         sink.write(x);
         assertEquals(y, res);
-        assertEquals(z, new ArrayList<>(sink.snapshotState().get(0)));
+        assertThatBufferStatesAreEqual(sink.wrapRequests(z), getWriterState(sink));
     }
 
     @Test
@@ -606,6 +610,106 @@ public class AsyncSinkWriterTest {
         assertEquals(98, res.size());
     }
 
+    @Test
+    public void prepareCommitFlushesInflightElementsIfFlushIsSetToFalse() throws Exception {
+        AsyncSinkWriterImpl sink =
+                new AsyncSinkWriterImplBuilder()
+                        .context(sinkInitContext)
+                        .maxBatchSize(3)
+                        .maxInFlightRequests(1)
+                        .maxBufferedRequests(10)
+                        .simulateFailures(true)
+                        .build();
+        sink.write(String.valueOf(225)); // buffer :[225]
+        sink.write(String.valueOf(0)); // buffer [225,0]
+        sink.write(String.valueOf(1)); // buffer [225,0,1] -- flushing
+        sink.write(String.valueOf(2)); // flushing -- request should have [225,0,1], [225] fails,
+        // buffer has [2]
+        assertEquals(2, res.size());
+        sink.prepareCommit(false); // inflight should be added to  buffer still [225, 2]
+        assertEquals(2, res.size());
+        sink.prepareCommit(true); // buffer now flushed []
+        assertEquals(Arrays.asList(0, 1, 225, 2), res);
+    }
+
+    @Test
+    public void testThatIntermittentlyFailingEntriesAreEnqueuedOnToTheBufferAfterSnapshot()
+            throws IOException, InterruptedException {
+        AsyncSinkWriterImpl sink =
+                new AsyncSinkWriterImplBuilder()
+                        .context(sinkInitContext)
+                        .maxBatchSize(10)
+                        .maxInFlightRequests(1)
+                        .maxBufferedRequests(100)
+                        .maxBatchSizeInBytes(110)
+                        .maxTimeInBufferMS(1000)
+                        .maxRecordSizeInBytes(110)
+                        .simulateFailures(true)
+                        .build();
+
+        sink.write(String.valueOf(225)); // Buffer: 100/110B; 2/10 elements; 0 inflight
+        sink.write(String.valueOf(1)); //   Buffer: 104/110B; 3/10 elements; 0 inflight
+        sink.write(String.valueOf(2)); //   Buffer: 108/110B; 4/10 elements; 0 inflight
+        sink.write(String.valueOf(3)); //   Buffer: 112/110B; 5/10 elements; 0 inflight -- flushing
+        assertEquals(2, res.size()); // Request was [225, 1, 2], element 225 failed
+
+        // buffer should be [3] with [225] inflight
+        sink.prepareCommit(false); // Buffer: [225,3] - > 8/110; 2/10 elements; 0 inflight
+        assertEquals(2, res.size()); //
+        List<BufferedRequestState<Integer>> states = sink.snapshotState();
+        AsyncSinkWriterImpl newSink =
+                new AsyncSinkWriterImplBuilder()
+                        .context(sinkInitContext)
+                        .maxBatchSize(10)
+                        .maxInFlightRequests(1)
+                        .maxBufferedRequests(100)
+                        .maxBatchSizeInBytes(110)
+                        .maxTimeInBufferMS(1000)
+                        .maxRecordSizeInBytes(110)
+                        .simulateFailures(false)
+                        .buildWithState(states);
+
+        newSink.write(String.valueOf(4)); //   Buffer:   12/15B; 3/10 elements; 0 inflight
+        newSink.write(String.valueOf(5)); //   Buffer:  16/15B; 4/10 elements; 0 inflight --flushing
+        assertEquals(Arrays.asList(1, 2, 225, 3, 4), res);
+        // Buffer: [5]; 0 inflight
+    }
+
+    @Test
+    public void testThatRecordOfSizeBiggerThanMaximumFailsSinkInitialization()
+            throws IOException, InterruptedException {
+        AsyncSinkWriterImpl sink =
+                new AsyncSinkWriterImplBuilder()
+                        .context(sinkInitContext)
+                        .maxBatchSize(10)
+                        .maxInFlightRequests(1)
+                        .maxBufferedRequests(100)
+                        .maxBatchSizeInBytes(110)
+                        .maxTimeInBufferMS(1000)
+                        .maxRecordSizeInBytes(110)
+                        .simulateFailures(true)
+                        .build();
+
+        sink.write(String.valueOf(225)); // Buffer: 100/110B; 1/10 elements; 0 inflight
+        sink.prepareCommit(false);
+        List<BufferedRequestState<Integer>> states = sink.snapshotState();
+        assertThatExceptionOfType(IllegalStateException.class)
+                .isThrownBy(
+                        () ->
+                                new AsyncSinkWriterImplBuilder()
+                                        .context(sinkInitContext)
+                                        .maxBatchSize(10)
+                                        .maxInFlightRequests(1)
+                                        .maxBufferedRequests(100)
+                                        .maxBatchSizeInBytes(110)
+                                        .maxTimeInBufferMS(1000)
+                                        .maxRecordSizeInBytes(15)
+                                        .simulateFailures(false)
+                                        .buildWithState(states))
+                .withMessageContaining(
+                        "State contains record of size 100 which exceeds sink maximum record size 15.");
+    }
+
     @Test
     public void testThatOneAndOnlyOneCallbackIsEverRegistered() throws Exception {
         AsyncSinkWriterImpl sink =
@@ -822,6 +926,13 @@ public class AsyncSinkWriterTest {
                 "Executor Service stuck at termination, not terminated after 500ms!");
     }
 
+    private BufferedRequestState<Integer> getWriterState(
+            AsyncSinkWriter<String, Integer> sinkWriter) {
+        List<BufferedRequestState<Integer>> states = sinkWriter.snapshotState();
+        assertEquals(states.size(), 1);
+        return states.get(0);
+    }
+
     private class AsyncSinkWriterImpl extends AsyncSinkWriter<String, Integer> {
 
         private final Set<Integer> failedFirstAttempts = new HashSet<>();
@@ -838,6 +949,31 @@ public class AsyncSinkWriterTest {
                 long maxRecordSizeInBytes,
                 boolean simulateFailures,
                 int delay) {
+            this(
+                    context,
+                    maxBatchSize,
+                    maxInFlightRequests,
+                    maxBufferedRequests,
+                    maxBatchSizeInBytes,
+                    maxTimeInBufferMS,
+                    maxRecordSizeInBytes,
+                    simulateFailures,
+                    delay,
+                    Collections.emptyList());
+        }
+
+        private AsyncSinkWriterImpl(
+                Sink.InitContext context,
+                int maxBatchSize,
+                int maxInFlightRequests,
+                int maxBufferedRequests,
+                long maxBatchSizeInBytes,
+                long maxTimeInBufferMS,
+                long maxRecordSizeInBytes,
+                boolean simulateFailures,
+                int delay,
+                List<BufferedRequestState<Integer>> bufferedState) {
+
             super(
                     (elem, ctx) -> Integer.parseInt(elem),
                     context,
@@ -846,7 +982,8 @@ public class AsyncSinkWriterTest {
                     maxBufferedRequests,
                     maxBatchSizeInBytes,
                     maxTimeInBufferMS,
-                    maxRecordSizeInBytes);
+                    maxRecordSizeInBytes,
+                    bufferedState);
             this.simulateFailures = simulateFailures;
             this.delay = delay;
         }
@@ -917,6 +1054,19 @@ public class AsyncSinkWriterTest {
         protected long getSizeInBytes(Integer requestEntry) {
             return requestEntry > 200 && simulateFailures ? 100 : 4;
         }
+
+        public BufferedRequestState<Integer> wrapRequests(Integer... requests) {
+            return wrapRequests(Arrays.asList(requests));
+        }
+
+        public BufferedRequestState<Integer> wrapRequests(List<Integer> requests) {
+            List<RequestEntryWrapper<Integer>> wrapperList = new ArrayList<>();
+            for (Integer request : requests) {
+                wrapperList.add(new RequestEntryWrapper<>(request, getSizeInBytes(request)));
+            }
+
+            return new BufferedRequestState<>(wrapperList);
+        }
     }
 
     /** A builder for {@link AsyncSinkWriterImpl}. */
@@ -989,6 +1139,21 @@ public class AsyncSinkWriterTest {
                     simulateFailures,
                     delay);
         }
+
+        private AsyncSinkWriterImpl buildWithState(
+                List<BufferedRequestState<Integer>> bufferedState) {
+            return new AsyncSinkWriterImpl(
+                    context,
+                    maxBatchSize,
+                    maxInFlightRequests,
+                    maxBufferedRequests,
+                    maxBatchSizeInBytes,
+                    maxTimeInBufferMS,
+                    maxRecordSizeInBytes,
+                    simulateFailures,
+                    delay,
+                    bufferedState);
+        }
     }
 
     /**
diff --git a/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTestUtils.java b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTestUtils.java
new file mode 100644
index 00000000000..b8e49b55b59
--- /dev/null
+++ b/flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/sink/writer/AsyncSinkWriterTestUtils.java
@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.base.sink.writer;
+
+import java.io.Serializable;
+import java.util.List;
+import java.util.function.Function;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.junit.jupiter.api.Assertions.assertEquals;
+
+/** Utils class for {@link AsyncSinkWriter} related test. */
+public class AsyncSinkWriterTestUtils {
+
+    public static <T extends Serializable> BufferedRequestState<T> getTestState(
+            ElementConverter<String, T> elementConverter,
+            Function<T, Integer> requestSizeExtractor) {
+        return new BufferedRequestState<>(
+                IntStream.range(0, 100)
+                        .mapToObj(i -> String.format("value:%d", i))
+                        .map(element -> elementConverter.apply(element, null))
+                        .map(
+                                request ->
+                                        new RequestEntryWrapper<>(
+                                                request, requestSizeExtractor.apply(request)))
+                        .collect(Collectors.toList()));
+    }
+
+    public static <T extends Serializable> void assertThatBufferStatesAreEqual(
+            BufferedRequestState<T> actual, BufferedRequestState<T> expected) {
+        // Equal states must have equal sizes
+        assertEquals(actual.getStateSize(), expected.getStateSize());
+
+        // Equal states must have the same number of requests.
+        int actualLength = actual.getBufferedRequestEntries().size();
+        assertEquals(actualLength, expected.getBufferedRequestEntries().size());
+
+        List<RequestEntryWrapper<T>> actualRequests = actual.getBufferedRequestEntries();
+        List<RequestEntryWrapper<T>> expectedRequests = expected.getBufferedRequestEntries();
+
+        // Equal states must have same requests in the same order.
+        for (int i = 0; i < actualLength; i++) {
+            assertEquals(
+                    actualRequests.get(i).getRequestEntry(),
+                    expectedRequests.get(i).getRequestEntry());
+            assertEquals(actualRequests.get(i).getSize(), expectedRequests.get(i).getSize());
+        }
+    }
+}
