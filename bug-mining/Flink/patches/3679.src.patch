diff --git a/flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java b/flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java
index d09cdee84ae..f2c6aa15e37 100644
--- a/flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java
+++ b/flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java
@@ -155,11 +155,22 @@ public class RestClusterClient<T> implements ClusterClient<T> {
 	private ScheduledExecutorService retryExecutorService;
 
 	public RestClusterClient(Configuration config, T clusterId) throws Exception {
+		this(
+			config,
+			clusterId,
+			HighAvailabilityServicesUtils.createClientHAService(config));
+	}
+
+	public RestClusterClient(
+			Configuration config,
+			T clusterId,
+			ClientHighAvailabilityServices clientHAServices) throws Exception {
 		this(
 			config,
 			null,
 			clusterId,
-			new ExponentialWaitStrategy(10L, 2000L));
+			new ExponentialWaitStrategy(10L, 2000L),
+			clientHAServices);
 	}
 
 	@VisibleForTesting
@@ -168,7 +179,20 @@ public class RestClusterClient<T> implements ClusterClient<T> {
 		@Nullable RestClient restClient,
 		T clusterId,
 		WaitStrategy waitStrategy) throws Exception {
+		this(
+			configuration,
+			restClient,
+			clusterId,
+			waitStrategy,
+			HighAvailabilityServicesUtils.createClientHAService(configuration));
+	}
 
+	private RestClusterClient(
+		Configuration configuration,
+		@Nullable RestClient restClient,
+		T clusterId,
+		WaitStrategy waitStrategy,
+		ClientHighAvailabilityServices clientHAServices) throws Exception {
 		this.configuration = checkNotNull(configuration);
 
 		this.restClusterClientConfiguration = RestClusterClientConfiguration.fromConfiguration(configuration);
@@ -182,7 +206,7 @@ public class RestClusterClient<T> implements ClusterClient<T> {
 		this.waitStrategy = checkNotNull(waitStrategy);
 		this.clusterId = checkNotNull(clusterId);
 
-		this.clientHAServices = HighAvailabilityServicesUtils.createClientHAService(configuration);
+		this.clientHAServices = checkNotNull(clientHAServices);
 
 		this.webMonitorRetrievalService = clientHAServices.getClusterRestEndpointLeaderRetriever();
 		this.retryExecutorService = Executors.newSingleThreadScheduledExecutor(new ExecutorThreadFactory("Flink-RestClusterClient-Retry"));
diff --git a/flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesClusterDescriptor.java b/flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesClusterDescriptor.java
index 9d1195440ca..9b5c73e8866 100644
--- a/flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesClusterDescriptor.java
+++ b/flink-kubernetes/src/main/java/org/apache/flink/kubernetes/KubernetesClusterDescriptor.java
@@ -27,6 +27,7 @@ import org.apache.flink.client.program.ClusterClientProvider;
 import org.apache.flink.client.program.rest.RestClusterClient;
 import org.apache.flink.configuration.BlobServerOptions;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.HighAvailabilityOptions;
 import org.apache.flink.configuration.JobManagerOptions;
 import org.apache.flink.configuration.RestOptions;
 import org.apache.flink.configuration.TaskManagerOptions;
@@ -39,7 +40,10 @@ import org.apache.flink.kubernetes.kubeclient.resources.KubernetesService;
 import org.apache.flink.kubernetes.utils.Constants;
 import org.apache.flink.kubernetes.utils.KubernetesUtils;
 import org.apache.flink.runtime.entrypoint.ClusterEntrypoint;
+import org.apache.flink.runtime.highavailability.HighAvailabilityServicesUtils;
+import org.apache.flink.runtime.highavailability.nonha.standalone.StandaloneClientHAServices;
 import org.apache.flink.runtime.jobgraph.JobGraph;
+import org.apache.flink.runtime.jobmanager.HighAvailabilityMode;
 import org.apache.flink.util.FlinkException;
 
 import org.slf4j.Logger;
@@ -91,7 +95,13 @@ public class KubernetesClusterDescriptor implements ClusterDescriptor<String> {
 			}
 
 			try {
-				return new RestClusterClient<>(configuration, clusterId);
+				// Flink client will always use Kubernetes service to contact with jobmanager. So we have a pre-configured web
+				// monitor address. Using StandaloneClientHAServices to create RestClusterClient is reasonable.
+				return new RestClusterClient<>(
+					configuration,
+					clusterId,
+					new StandaloneClientHAServices(HighAvailabilityServicesUtils.getWebMonitorAddress(
+						configuration, HighAvailabilityServicesUtils.AddressResolution.TRY_ADDRESS_RESOLUTION)));
 			} catch (Exception e) {
 				client.handleException(e);
 				throw new RuntimeException(new ClusterRetrieveException("Could not create the RestClusterClient.", e));
diff --git a/flink-kubernetes/src/test/java/org/apache/flink/kubernetes/KubernetesClusterDescriptorTest.java b/flink-kubernetes/src/test/java/org/apache/flink/kubernetes/KubernetesClusterDescriptorTest.java
index 167f1641538..51f519f49e2 100644
--- a/flink-kubernetes/src/test/java/org/apache/flink/kubernetes/KubernetesClusterDescriptorTest.java
+++ b/flink-kubernetes/src/test/java/org/apache/flink/kubernetes/KubernetesClusterDescriptorTest.java
@@ -18,14 +18,17 @@
 
 package org.apache.flink.kubernetes;
 
+import org.apache.flink.client.deployment.ClusterDeploymentException;
 import org.apache.flink.client.deployment.ClusterSpecification;
 import org.apache.flink.client.program.ClusterClient;
 import org.apache.flink.configuration.BlobServerOptions;
+import org.apache.flink.configuration.HighAvailabilityOptions;
 import org.apache.flink.configuration.JobManagerOptions;
 import org.apache.flink.configuration.TaskManagerOptions;
 import org.apache.flink.kubernetes.configuration.KubernetesConfigOptionsInternal;
 import org.apache.flink.kubernetes.kubeclient.FlinkKubeClient;
 import org.apache.flink.kubernetes.utils.Constants;
+import org.apache.flink.runtime.jobmanager.HighAvailabilityMode;
 
 import io.fabric8.kubernetes.api.model.Container;
 import io.fabric8.kubernetes.api.model.Service;
@@ -43,23 +46,12 @@ import static org.junit.Assert.assertEquals;
  */
 public class KubernetesClusterDescriptorTest extends KubernetesTestBase {
 
+	private final ClusterSpecification clusterSpecification = new ClusterSpecification.ClusterSpecificationBuilder()
+		.createClusterSpecification();
+
 	@Test
 	public void testDeploySessionCluster() throws Exception {
-		final FlinkKubeClient flinkKubeClient = getFabric8FlinkKubeClient();
-		final KubernetesClusterDescriptor descriptor = new KubernetesClusterDescriptor(FLINK_CONFIG, flinkKubeClient);
-
-		final ClusterSpecification clusterSpecification = new ClusterSpecification.ClusterSpecificationBuilder()
-			.setMasterMemoryMB(1234)
-			.setTaskManagerMemoryMB(1222)
-			.setSlotsPerTaskManager(1)
-			.createClusterSpecification();
-
-		final ClusterClient<String> clusterClient =
-				descriptor.deploySessionCluster(clusterSpecification).getClusterClient();
-
-		assertEquals(CLUSTER_ID, clusterClient.getClusterId());
-		assertEquals(String.format("http://%s:8081", MOCK_SERVICE_IP), clusterClient.getWebInterfaceURL());
-
+		final ClusterClient<String> clusterClient = deploySessionCluster();
 		// Check updated flink config options
 		assertEquals(String.valueOf(Constants.BLOB_SERVER_PORT), FLINK_CONFIG.getString(BlobServerOptions.PORT));
 		assertEquals(String.valueOf(Constants.TASK_MANAGER_RPC_PORT), FLINK_CONFIG.getString(TaskManagerOptions.RPC_PORT));
@@ -95,6 +87,15 @@ public class KubernetesClusterDescriptorTest extends KubernetesTestBase {
 		clusterClient.close();
 	}
 
+	@Test
+	public void testDeployHighAvailabilitySessionCluster() throws ClusterDeploymentException {
+		FLINK_CONFIG.setString(HighAvailabilityOptions.HA_MODE, HighAvailabilityMode.ZOOKEEPER.toString());
+
+		final ClusterClient<String> clusterClient = deploySessionCluster();
+
+		clusterClient.close();
+	}
+
 	@Test
 	public void testKillCluster() throws Exception {
 		final FlinkKubeClient flinkKubeClient = getFabric8FlinkKubeClient();
@@ -118,4 +119,18 @@ public class KubernetesClusterDescriptorTest extends KubernetesTestBase {
 			services.get(0).getMetadata().getOwnerReferences().get(0).getUid());
 	}
 
+	private ClusterClient<String> deploySessionCluster() throws ClusterDeploymentException {
+		final FlinkKubeClient flinkKubeClient = getFabric8FlinkKubeClient();
+		final KubernetesClusterDescriptor descriptor = new KubernetesClusterDescriptor(FLINK_CONFIG, flinkKubeClient);
+
+		final ClusterClient<String> clusterClient = descriptor
+			.deploySessionCluster(clusterSpecification)
+			.getClusterClient();
+
+		assertEquals(CLUSTER_ID, clusterClient.getClusterId());
+		// Both HA and non-HA mode, the web interface should always be the Kubernetes exposed service address.
+		assertEquals(String.format("http://%s:8081", MOCK_SERVICE_IP), clusterClient.getWebInterfaceURL());
+
+		return clusterClient;
+	}
 }
