diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsDataView.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsDataView.java
index b8888cfcb38..30ad6693fba 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsDataView.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsDataView.java
@@ -18,9 +18,11 @@
 
 package org.apache.flink.runtime.io.network.partition.hybrid;
 
+import org.apache.flink.runtime.io.network.buffer.Buffer;
 import org.apache.flink.runtime.io.network.buffer.Buffer.DataType;
 import org.apache.flink.runtime.io.network.partition.ResultSubpartition.BufferAndBacklog;
 
+import java.util.Collection;
 import java.util.Optional;
 
 /**
@@ -35,18 +37,22 @@ public interface HsDataView {
      * <p>Only invoked by consumer thread.
      *
      * @param nextBufferToConsume next buffer index to consume.
+     * @param buffersToRecycle buffers to recycle if needed.
      * @return If the target buffer does exist, return buffer and next buffer's backlog, otherwise
      *     return {@link Optional#empty()}.
      */
-    Optional<BufferAndBacklog> consumeBuffer(int nextBufferToConsume) throws Throwable;
+    Optional<BufferAndBacklog> consumeBuffer(
+            int nextBufferToConsume, Collection<Buffer> buffersToRecycle) throws Throwable;
 
     /**
      * Get dataType of next buffer to consume.
      *
      * @param nextBufferToConsume next buffer index to consume
+     * @param buffersToRecycle buffers to recycle if needed.
      * @return next buffer's dataType. If not found in memory, return {@link DataType#NONE}.
      */
-    DataType peekNextToConsumeDataType(int nextBufferToConsume);
+    DataType peekNextToConsumeDataType(
+            int nextBufferToConsume, Collection<Buffer> buffersToRecycle);
 
     /**
      * Get the number of buffers backlog.
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumer.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumer.java
index 7878d68bc33..9d10a6bbde7 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumer.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumer.java
@@ -27,7 +27,9 @@ import javax.annotation.Nullable;
 import javax.annotation.concurrent.GuardedBy;
 
 import java.io.IOException;
+import java.util.ArrayDeque;
 import java.util.Optional;
+import java.util.Queue;
 
 import static org.apache.flink.util.Preconditions.checkNotNull;
 import static org.apache.flink.util.Preconditions.checkState;
@@ -73,14 +75,17 @@ public class HsSubpartitionConsumer
     @Nullable
     @Override
     public BufferAndBacklog getNextBuffer() {
+        Queue<Buffer> buffersToRecycle = new ArrayDeque<>();
         try {
             synchronized (lock) {
                 checkNotNull(diskDataView, "disk data view must be not null.");
                 checkNotNull(memoryDataView, "memory data view must be not null.");
 
-                Optional<BufferAndBacklog> bufferToConsume = tryReadFromDisk();
+                Optional<BufferAndBacklog> bufferToConsume = tryReadFromDisk(buffersToRecycle);
                 if (!bufferToConsume.isPresent()) {
-                    bufferToConsume = memoryDataView.consumeBuffer(lastConsumedBufferIndex + 1);
+                    bufferToConsume =
+                            memoryDataView.consumeBuffer(
+                                    lastConsumedBufferIndex + 1, buffersToRecycle);
                 }
                 updateConsumingStatus(bufferToConsume);
                 return bufferToConsume.map(this::handleBacklog).orElse(null);
@@ -89,6 +94,11 @@ public class HsSubpartitionConsumer
             // release subpartition reader outside of lock to avoid deadlock.
             releaseInternal(cause);
             return null;
+        } finally {
+            // recycle buffers outside of lock to avoid deadlock.
+            while (!buffersToRecycle.isEmpty()) {
+                buffersToRecycle.poll().recycleBuffer();
+            }
         }
     }
 
@@ -232,10 +242,11 @@ public class HsSubpartitionConsumer
     }
 
     @GuardedBy("lock")
-    private Optional<BufferAndBacklog> tryReadFromDisk() throws Throwable {
+    private Optional<BufferAndBacklog> tryReadFromDisk(Queue<Buffer> buffersToRecycle)
+            throws Throwable {
         final int nextBufferIndexToConsume = lastConsumedBufferIndex + 1;
         return checkNotNull(diskDataView)
-                .consumeBuffer(nextBufferIndexToConsume)
+                .consumeBuffer(nextBufferIndexToConsume, buffersToRecycle)
                 .map(
                         bufferAndBacklog -> {
                             if (bufferAndBacklog.getNextDataType() == Buffer.DataType.NONE) {
@@ -244,7 +255,8 @@ public class HsSubpartitionConsumer
                                         bufferAndBacklog.buffersInBacklog(),
                                         checkNotNull(memoryDataView)
                                                 .peekNextToConsumeDataType(
-                                                        nextBufferIndexToConsume + 1),
+                                                        nextBufferIndexToConsume + 1,
+                                                        buffersToRecycle),
                                         bufferAndBacklog.getSequenceNumber());
                             }
                             return bufferAndBacklog;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManager.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManager.java
index 606ffa32bbf..30cf2e91898 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManager.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManager.java
@@ -25,6 +25,7 @@ import org.apache.flink.util.function.SupplierWithException;
 
 import javax.annotation.concurrent.GuardedBy;
 
+import java.util.Collection;
 import java.util.Deque;
 import java.util.LinkedList;
 import java.util.Optional;
@@ -84,6 +85,7 @@ public class HsSubpartitionConsumerMemoryDataManager implements HsDataView {
      * return the buffer and backlog.
      *
      * @param toConsumeIndex index of buffer to be consumed.
+     * @param buffersToRecycle buffers to recycle if needed.
      * @return If the head of {@link #unConsumedBuffers} is target, return optional of the buffer
      *     and backlog. Otherwise, return {@link Optional#empty()}.
      */
@@ -91,7 +93,8 @@ public class HsSubpartitionConsumerMemoryDataManager implements HsDataView {
     // Note that: callWithLock ensure that code block guarded by resultPartitionReadLock and
     // subpartitionLock.
     @Override
-    public Optional<ResultSubpartition.BufferAndBacklog> consumeBuffer(int toConsumeIndex) {
+    public Optional<ResultSubpartition.BufferAndBacklog> consumeBuffer(
+            int toConsumeIndex, Collection<Buffer> buffersToRecycle) {
         Optional<Tuple2<HsBufferContext, Buffer.DataType>> bufferAndNextDataType =
                 callWithLock(
                         () -> {
@@ -125,6 +128,7 @@ public class HsSubpartitionConsumerMemoryDataManager implements HsDataView {
      * If so, return the next buffer's data type.
      *
      * @param nextToConsumeIndex index of the buffer to be consumed next time.
+     * @param buffersToRecycle buffers to recycle if needed.
      * @return If the head of {@link #unConsumedBuffers} is target, return the buffer's data type.
      *     Otherwise, return {@link Buffer.DataType#NONE}.
      */
@@ -132,7 +136,8 @@ public class HsSubpartitionConsumerMemoryDataManager implements HsDataView {
     // Note that: callWithLock ensure that code block guarded by resultPartitionReadLock and
     // consumerLock.
     @Override
-    public Buffer.DataType peekNextToConsumeDataType(int nextToConsumeIndex) {
+    public Buffer.DataType peekNextToConsumeDataType(
+            int nextToConsumeIndex, Collection<Buffer> buffersToRecycle) {
         return callWithLock(() -> peekNextToConsumeDataTypeInternal(nextToConsumeIndex));
     }
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImpl.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImpl.java
index e9ca896ac3c..003cd951678 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImpl.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImpl.java
@@ -32,6 +32,8 @@ import javax.annotation.concurrent.GuardedBy;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.channels.FileChannel;
+import java.util.ArrayDeque;
+import java.util.Collection;
 import java.util.Deque;
 import java.util.Objects;
 import java.util.Optional;
@@ -228,9 +230,10 @@ public class HsSubpartitionFileReaderImpl implements HsSubpartitionFileReader {
     }
 
     @Override
-    public Optional<ResultSubpartition.BufferAndBacklog> consumeBuffer(int nextBufferToConsume)
-            throws Throwable {
-        if (!checkAndGetFirstBufferIndexOrError(nextBufferToConsume).isPresent()) {
+    public Optional<ResultSubpartition.BufferAndBacklog> consumeBuffer(
+            int nextBufferToConsume, Collection<Buffer> buffersToRecycle) throws Throwable {
+        if (!checkAndGetFirstBufferIndexOrError(nextBufferToConsume, buffersToRecycle)
+                .isPresent()) {
             return Optional.empty();
         }
 
@@ -254,11 +257,12 @@ public class HsSubpartitionFileReaderImpl implements HsSubpartitionFileReader {
     }
 
     @Override
-    public Buffer.DataType peekNextToConsumeDataType(int nextBufferToConsume) {
+    public Buffer.DataType peekNextToConsumeDataType(
+            int nextBufferToConsume, Collection<Buffer> buffersToRecycle) {
         Buffer.DataType dataType = Buffer.DataType.NONE;
         try {
             dataType =
-                    checkAndGetFirstBufferIndexOrError(nextBufferToConsume)
+                    checkAndGetFirstBufferIndexOrError(nextBufferToConsume, buffersToRecycle)
                             .map(BufferIndexOrError::getDataType)
                             .orElse(Buffer.DataType.NONE);
         } catch (Throwable throwable) {
@@ -269,9 +273,19 @@ public class HsSubpartitionFileReaderImpl implements HsSubpartitionFileReader {
 
     @Override
     public void releaseDataView() {
+        Queue<Buffer> bufferToRecycle = new ArrayDeque<>();
         synchronized (lock) {
             isReleased = true;
+            // all loaded buffers should be recycled after data view released.
+            while (!loadedBuffers.isEmpty()) {
+                BufferIndexOrError bufferIndexOrError = loadedBuffers.poll();
+                if (bufferIndexOrError.getBuffer().isPresent()) {
+                    bufferToRecycle.add(bufferIndexOrError.getBuffer().get());
+                }
+            }
         }
+        // recycle buffers outside of lock to avoid deadlock.
+        bufferToRecycle.forEach(Buffer::recycleBuffer);
         fileReaderReleaser.accept(this);
     }
 
@@ -284,8 +298,8 @@ public class HsSubpartitionFileReaderImpl implements HsSubpartitionFileReader {
     //  Internal Methods
     // ------------------------------------------------------------------------
 
-    private Optional<BufferIndexOrError> checkAndGetFirstBufferIndexOrError(int expectedBufferIndex)
-            throws Throwable {
+    private Optional<BufferIndexOrError> checkAndGetFirstBufferIndexOrError(
+            int expectedBufferIndex, Collection<Buffer> buffersToRecycle) throws Throwable {
         BufferIndexOrError peek = loadedBuffers.peek();
         while (peek != null) {
             if (peek.getThrowable().isPresent()) {
@@ -298,7 +312,7 @@ public class HsSubpartitionFileReaderImpl implements HsSubpartitionFileReader {
                 // Because the update of consumption progress may be delayed, there is a
                 // very small probability to load the buffer that has been consumed from memory.
                 // Skip these buffers directly to avoid repeated consumption.
-                loadedBuffers.poll();
+                buffersToRecycle.add(checkNotNull(loadedBuffers.poll()).buffer);
                 peek = loadedBuffers.peek();
             }
         }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsFileDataManagerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsFileDataManagerTest.java
index bb6b1de3fa7..202f8e8ba8d 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsFileDataManagerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsFileDataManagerTest.java
@@ -45,6 +45,7 @@ import java.nio.file.Path;
 import java.nio.file.StandardOpenOption;
 import java.time.Duration;
 import java.util.ArrayDeque;
+import java.util.Collection;
 import java.util.Optional;
 import java.util.Queue;
 import java.util.Random;
@@ -484,12 +485,13 @@ class HsFileDataManagerTest {
 
         @Override
         public Optional<ResultSubpartition.BufferAndBacklog> consumeBuffer(
-                int nextBufferToConsume) {
+                int nextBufferToConsume, Collection<Buffer> buffersToRecycle) {
             return Optional.empty();
         }
 
         @Override
-        public Buffer.DataType peekNextToConsumeDataType(int nextBufferToConsume) {
+        public Buffer.DataType peekNextToConsumeDataType(
+                int nextBufferToConsume, Collection<Buffer> buffersToRecycle) {
             return Buffer.DataType.NONE;
         }
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManagerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManagerTest.java
index 9cb8d8b1751..00d89b086c2 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManagerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionConsumerMemoryDataManagerTest.java
@@ -25,6 +25,7 @@ import org.apache.flink.runtime.io.network.partition.ResultSubpartition;
 import org.junit.jupiter.api.Test;
 
 import java.util.ArrayDeque;
+import java.util.Collections;
 import java.util.Optional;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.locks.ReentrantLock;
@@ -48,7 +49,9 @@ class HsSubpartitionConsumerMemoryDataManagerTest {
                 createSubpartitionConsumerMemoryDataManager(memoryDataManagerOperation);
 
         subpartitionConsumerMemoryDataManager.addBuffer(createBufferContext(0, false));
-        assertThat(subpartitionConsumerMemoryDataManager.peekNextToConsumeDataType(1))
+        assertThat(
+                        subpartitionConsumerMemoryDataManager.peekNextToConsumeDataType(
+                                1, new ArrayDeque<>()))
                 .isEqualTo(Buffer.DataType.NONE);
     }
 
@@ -68,7 +71,9 @@ class HsSubpartitionConsumerMemoryDataManagerTest {
         buffer1.release();
         buffer2.release();
 
-        assertThat(subpartitionConsumerMemoryDataManager.peekNextToConsumeDataType(2))
+        assertThat(
+                        subpartitionConsumerMemoryDataManager.peekNextToConsumeDataType(
+                                2, Collections.emptyList()))
                 .isEqualTo(Buffer.DataType.EVENT_BUFFER);
     }
 
@@ -80,7 +85,8 @@ class HsSubpartitionConsumerMemoryDataManagerTest {
                 createSubpartitionConsumerMemoryDataManager(memoryDataManagerOperation);
 
         subpartitionConsumerMemoryDataManager.addBuffer(createBufferContext(0, false));
-        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(1)).isNotPresent();
+        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(1, Collections.emptyList()))
+                .isNotPresent();
     }
 
     @Test
@@ -99,7 +105,8 @@ class HsSubpartitionConsumerMemoryDataManagerTest {
         buffer1.release();
         buffer2.release();
 
-        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(2)).isPresent();
+        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(2, Collections.emptyList()))
+                .isPresent();
     }
 
     @Test
@@ -112,7 +119,7 @@ class HsSubpartitionConsumerMemoryDataManagerTest {
         subpartitionConsumerMemoryDataManager.addBuffer(createBufferContext(0, false));
 
         Optional<ResultSubpartition.BufferAndBacklog> bufferOpt =
-                subpartitionConsumerMemoryDataManager.consumeBuffer(0);
+                subpartitionConsumerMemoryDataManager.consumeBuffer(0, Collections.emptyList());
         assertThat(bufferOpt)
                 .hasValueSatisfying(
                         (bufferAndBacklog ->
@@ -132,21 +139,21 @@ class HsSubpartitionConsumerMemoryDataManagerTest {
         subpartitionConsumerMemoryDataManager.addInitialBuffers(initialBuffers);
         subpartitionConsumerMemoryDataManager.addBuffer(createBufferContext(2, true));
 
-        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(0))
+        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(0, Collections.emptyList()))
                 .hasValueSatisfying(
                         bufferAndBacklog -> {
                             assertThat(bufferAndBacklog.getSequenceNumber()).isEqualTo(0);
                             assertThat(bufferAndBacklog.buffer().getDataType())
                                     .isEqualTo(Buffer.DataType.DATA_BUFFER);
                         });
-        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(1))
+        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(1, Collections.emptyList()))
                 .hasValueSatisfying(
                         bufferAndBacklog -> {
                             assertThat(bufferAndBacklog.getSequenceNumber()).isEqualTo(1);
                             assertThat(bufferAndBacklog.buffer().getDataType())
                                     .isEqualTo(Buffer.DataType.DATA_BUFFER);
                         });
-        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(2))
+        assertThat(subpartitionConsumerMemoryDataManager.consumeBuffer(2, Collections.emptyList()))
                 .hasValueSatisfying(
                         bufferAndBacklog -> {
                             assertThat(bufferAndBacklog.getSequenceNumber()).isEqualTo(2);
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImplTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImplTest.java
index 2c828e8e424..cea52653a70 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImplTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionFileReaderImplTest.java
@@ -51,6 +51,7 @@ import java.nio.file.Path;
 import java.nio.file.StandardOpenOption;
 import java.util.ArrayDeque;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.Deque;
 import java.util.List;
 import java.util.Queue;
@@ -394,6 +395,46 @@ class HsSubpartitionFileReaderImplTest {
         assertThat(fileReader1).isGreaterThan(fileReader2);
     }
 
+    @Test
+    void testRecycleBuffersForConsumeBuffer() throws Throwable {
+        TestingSubpartitionConsumerInternalOperation viewNotifier =
+                new TestingSubpartitionConsumerInternalOperation();
+        HsSubpartitionFileReaderImpl subpartitionFileReader =
+                createSubpartitionFileReader(0, viewNotifier);
+        writeDataToFile(0, 0, 0, 4);
+
+        Queue<MemorySegment> memorySegments = createsMemorySegments(4);
+        subpartitionFileReader.prepareForScheduling();
+        // trigger reading, add buffer to queue.
+        subpartitionFileReader.readBuffers(memorySegments, (ignore) -> {});
+        ArrayList<Buffer> buffers = new ArrayList<>();
+        // expected buffer index is 2, buffer 0 & 1 should be recycled.
+        subpartitionFileReader.consumeBuffer(2, buffers);
+        assertThat(buffers).hasSize(2);
+        assertThat(buffers).element(0).satisfies((buffer -> assertBufferContentEqualTo(buffer, 0)));
+        assertThat(buffers).element(1).satisfies((buffer -> assertBufferContentEqualTo(buffer, 1)));
+    }
+
+    @Test
+    void testRecycleBuffersForPeekNextToConsumeDataType() throws Throwable {
+        TestingSubpartitionConsumerInternalOperation viewNotifier =
+                new TestingSubpartitionConsumerInternalOperation();
+        HsSubpartitionFileReaderImpl subpartitionFileReader =
+                createSubpartitionFileReader(0, viewNotifier);
+        writeDataToFile(0, 0, 0, 4);
+
+        Queue<MemorySegment> memorySegments = createsMemorySegments(4);
+        subpartitionFileReader.prepareForScheduling();
+        // trigger reading, add buffer to queue.
+        subpartitionFileReader.readBuffers(memorySegments, (ignore) -> {});
+        ArrayList<Buffer> buffers = new ArrayList<>();
+        // expected buffer index is 2, buffer 0 & 1 should be recycled.
+        subpartitionFileReader.peekNextToConsumeDataType(2, buffers);
+        assertThat(buffers).hasSize(2);
+        assertThat(buffers).element(0).satisfies((buffer -> assertBufferContentEqualTo(buffer, 0)));
+        assertThat(buffers).element(1).satisfies((buffer -> assertBufferContentEqualTo(buffer, 1)));
+    }
+
     @Test
     void testConsumeBuffer() throws Throwable {
         TestingSubpartitionConsumerInternalOperation viewNotifier =
@@ -402,7 +443,7 @@ class HsSubpartitionFileReaderImplTest {
                 createSubpartitionFileReader(0, viewNotifier);
 
         // if no preload data in file reader, return Optional.empty.
-        assertThat(subpartitionFileReader.consumeBuffer(0)).isNotPresent();
+        assertThat(subpartitionFileReader.consumeBuffer(0, Collections.emptyList())).isNotPresent();
 
         // buffers in file: (0-0, 0-1, 0-2)
         writeDataToFile(0, 0, 0, 3);
@@ -413,7 +454,7 @@ class HsSubpartitionFileReaderImplTest {
         subpartitionFileReader.readBuffers(memorySegments, (ignore) -> {});
 
         // if nextBufferToConsume is equal to peek elements index.
-        assertThat(subpartitionFileReader.consumeBuffer(0))
+        assertThat(subpartitionFileReader.consumeBuffer(0, new ArrayList<>()))
                 .hasValueSatisfying(
                         (bufferAndBacklog -> {
                             assertThat(bufferAndBacklog.getNextDataType())
@@ -430,11 +471,11 @@ class HsSubpartitionFileReaderImplTest {
                         }));
 
         // if nextBufferToConsume is less than peek elements index, return Optional.empty.
-        assertThat(subpartitionFileReader.consumeBuffer(0)).isNotPresent();
+        assertThat(subpartitionFileReader.consumeBuffer(0, Collections.emptyList())).isNotPresent();
 
         // if nextBufferToConsume is greater than peek elements index, skip this buffer and keep
         // looking.
-        assertThat(subpartitionFileReader.consumeBuffer(2))
+        assertThat(subpartitionFileReader.consumeBuffer(2, new ArrayList<>()))
                 .hasValueSatisfying(
                         (bufferAndBacklog -> {
                             assertThat(bufferAndBacklog.getNextDataType()).isEqualTo(DataType.NONE);
@@ -459,11 +500,14 @@ class HsSubpartitionFileReaderImplTest {
 
         subpartitionFileReader.fail(new RuntimeException("expected exception."));
 
-        assertThatThrownBy(() -> subpartitionFileReader.peekNextToConsumeDataType(0))
+        assertThatThrownBy(
+                        () ->
+                                subpartitionFileReader.peekNextToConsumeDataType(
+                                        0, Collections.emptyList()))
                 .isInstanceOf(RuntimeException.class)
                 .hasMessageContaining("expected exception.");
 
-        assertThatThrownBy(() -> subpartitionFileReader.consumeBuffer(0))
+        assertThatThrownBy(() -> subpartitionFileReader.consumeBuffer(0, Collections.emptyList()))
                 .isInstanceOf(RuntimeException.class)
                 .hasMessageContaining("expected exception.");
     }
@@ -476,7 +520,8 @@ class HsSubpartitionFileReaderImplTest {
                 createSubpartitionFileReader(0, viewNotifier);
 
         // if no preload data in file reader, return DataType.NONE.
-        assertThat(subpartitionFileReader.peekNextToConsumeDataType(0)).isEqualTo(DataType.NONE);
+        assertThat(subpartitionFileReader.peekNextToConsumeDataType(0, new ArrayList<>()))
+                .isEqualTo(DataType.NONE);
 
         // buffers in file: (0-0, 0-1, 0-2)
         writeDataToFile(0, 0, 3);
@@ -487,15 +532,16 @@ class HsSubpartitionFileReaderImplTest {
         subpartitionFileReader.readBuffers(memorySegments, (ignore) -> {});
 
         // if nextBufferToConsume is equal to peek elements index, return the real DataType.
-        assertThat(subpartitionFileReader.peekNextToConsumeDataType(0))
+        assertThat(subpartitionFileReader.peekNextToConsumeDataType(0, Collections.emptyList()))
                 .isEqualTo(DataType.DATA_BUFFER);
 
         // if nextBufferToConsume is greater than peek elements index, skip this buffer and keep
         // looking.
-        assertThat(subpartitionFileReader.peekNextToConsumeDataType(2))
+        assertThat(subpartitionFileReader.peekNextToConsumeDataType(2, new ArrayList<>()))
                 .isEqualTo(DataType.EVENT_BUFFER);
         // if nextBufferToConsume is less than peek elements index, return DataType.NONE.
-        assertThat(subpartitionFileReader.peekNextToConsumeDataType(1)).isEqualTo(DataType.NONE);
+        assertThat(subpartitionFileReader.peekNextToConsumeDataType(1, Collections.emptyList()))
+                .isEqualTo(DataType.NONE);
     }
 
     /**
@@ -573,13 +619,21 @@ class HsSubpartitionFileReaderImplTest {
                         viewNotifier,
                         (ignore) -> isReleased.complete(null));
 
-        writeDataToFile(0, 0, 2);
+        writeDataToFile(0, 0, 4);
         subpartitionFileReader.prepareForScheduling();
         Queue<MemorySegment> memorySegments = createsMemorySegments(2);
+        Queue<MemorySegment> recycledBuffers = new ArrayDeque<>();
+        subpartitionFileReader.readBuffers(memorySegments, recycledBuffers::add);
+        assertThat(memorySegments).isEmpty();
+
         subpartitionFileReader.releaseDataView();
+        assertThat(subpartitionFileReader.getLoadedBuffers()).isEmpty();
+        assertThat(recycledBuffers).hasSize(2);
 
-        subpartitionFileReader.readBuffers(memorySegments, (ignore) -> {});
+        memorySegments = createsMemorySegments(2);
+        subpartitionFileReader.readBuffers(memorySegments, recycledBuffers::add);
         assertThat(memorySegments).hasSize(2);
+        assertThat(recycledBuffers).hasSize(2);
         assertThat(isReleased).isCompleted();
     }
 
@@ -715,4 +769,9 @@ class HsSubpartitionFileReaderImplTest {
         bufferWithHeaders[index] = header;
         bufferWithHeaders[index + 1] = buffer.getNioBufferReadable();
     }
+
+    private static void assertBufferContentEqualTo(Buffer buffer, int expectedValue) {
+        assertThat(buffer.getNioBufferReadable().order(ByteOrder.nativeOrder()).getInt())
+                .isEqualTo(expectedValue);
+    }
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java
index 998c87397f1..5417f84f69e 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java
@@ -165,7 +165,7 @@ class HsSubpartitionMemoryDataManagerTest {
                 subpartitionMemoryDataManager.registerNewConsumer(DEFAULT);
         ArrayList<Optional<BufferAndBacklog>> bufferAndBacklogOpts = new ArrayList<>();
         for (int i = 0; i < numDataBuffers + 1; i++) {
-            bufferAndBacklogOpts.add(consumer.consumeBuffer(i));
+            bufferAndBacklogOpts.add(consumer.consumeBuffer(i, Collections.emptyList()));
         }
         checkConsumedBufferAndNextDataType(
                 numRecordsPerBuffer, bufferDecompressor, expectedRecords, bufferAndBacklogOpts);
@@ -205,8 +205,8 @@ class HsSubpartitionMemoryDataManagerTest {
         subpartitionMemoryDataManager.spillSubpartitionBuffers(toStartSpilling, spilledDoneFuture);
 
         // consume buffer 0, 1
-        consumer.consumeBuffer(0);
-        consumer.consumeBuffer(1);
+        consumer.consumeBuffer(0, Collections.emptyList());
+        consumer.consumeBuffer(1, Collections.emptyList());
 
         checkBufferIndex(
                 subpartitionMemoryDataManager.getBuffersSatisfyStatus(SpillStatus.ALL, ALL_ANY),
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/TestingHsDataView.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/TestingHsDataView.java
index 343bd9586df..bf547249fce 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/TestingHsDataView.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/TestingHsDataView.java
@@ -22,6 +22,7 @@ import org.apache.flink.runtime.io.network.buffer.Buffer;
 import org.apache.flink.runtime.io.network.partition.ResultSubpartition;
 import org.apache.flink.util.function.FunctionWithException;
 
+import java.util.Collection;
 import java.util.Optional;
 import java.util.function.Function;
 import java.util.function.Supplier;
@@ -57,13 +58,14 @@ public class TestingHsDataView implements HsDataView {
     }
 
     @Override
-    public Optional<ResultSubpartition.BufferAndBacklog> consumeBuffer(int nextBufferToConsume)
-            throws Throwable {
+    public Optional<ResultSubpartition.BufferAndBacklog> consumeBuffer(
+            int nextBufferToConsume, Collection<Buffer> buffersToRecycle) throws Throwable {
         return consumeBufferFunction.apply(nextBufferToConsume);
     }
 
     @Override
-    public Buffer.DataType peekNextToConsumeDataType(int nextBufferToConsume) {
+    public Buffer.DataType peekNextToConsumeDataType(
+            int nextBufferToConsume, Collection<Buffer> buffersToRecycle) {
         return peekNextToConsumeDataTypeFunction.apply(nextBufferToConsume);
     }
 
