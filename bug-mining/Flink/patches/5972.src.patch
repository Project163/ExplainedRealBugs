diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/harness/RankHarnessTest.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/harness/RankHarnessTest.scala
index a80cf0ae4c1..3c97370339d 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/harness/RankHarnessTest.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/harness/RankHarnessTest.scala
@@ -19,9 +19,12 @@
 package org.apache.flink.table.planner.runtime.harness
 
 import org.apache.flink.api.scala._
+import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness
 import org.apache.flink.table.api._
 import org.apache.flink.table.api.bridge.scala._
 import org.apache.flink.table.api.bridge.scala.internal.StreamTableEnvironmentImpl
+import org.apache.flink.table.data.RowData
+import org.apache.flink.table.planner.JInt
 import org.apache.flink.table.planner.runtime.utils.JavaUserDefinedTableFunctions
 import org.apache.flink.table.planner.runtime.utils.StreamingWithStateTestBase.StateBackendMode
 import org.apache.flink.table.runtime.util.RowDataHarnessAssertor
@@ -220,4 +223,234 @@ class RankHarnessTest(mode: StateBackendMode) extends HarnessTestBase(mode) {
     assertor.assertOutputEqualsSorted("result mismatch", expectedOutput, result)
     testHarness.close()
   }
+
+  def prepareUpdateRankWithRowNumberTester():
+    (KeyedOneInputStreamOperatorTestHarness[RowData, RowData, RowData], RowDataHarnessAssertor) = {
+    val data = new mutable.MutableList[(String, Int, Int)]
+    val t = env.fromCollection(data).toTable(tEnv, 'word, 'cnt, 'type)
+    tEnv.createTemporaryView("T", t)
+    tEnv.getConfig.setIdleStateRetention(Duration.ofSeconds(1))
+
+    val sql =
+      """
+        |SELECT word, cnt, rank_num
+        |FROM (
+        |  SELECT word, cnt,
+        |      ROW_NUMBER() OVER (PARTITION BY type ORDER BY cnt DESC) as rank_num
+        |  FROM (
+        |     select word, type, sum(cnt) filter (where cnt > 0) cnt from T group by word, type
+        |   )
+        |  )
+        |WHERE rank_num <= 6
+      """.stripMargin
+
+    val t1 = tEnv.sqlQuery(sql)
+
+    val testHarness = createHarnessTester(
+      t1.toRetractStream[Row],
+      "Rank(strategy=[UpdateFastStrategy")
+    val assertor = new RowDataHarnessAssertor(
+      Array(
+        DataTypes.STRING().getLogicalType,
+        DataTypes.INT().getLogicalType,
+        DataTypes.INT().getLogicalType,
+        DataTypes.BIGINT().getLogicalType))
+    (testHarness, assertor)
+  }
+
+  @Test
+  def testUpdateRankWithRowNumberSortKeyDropsToLast(): Unit = {
+    val (testHarness, assertor) = prepareUpdateRankWithRowNumberTester()
+    testHarness.open()
+
+    testHarness.processElement(binaryRecord(INSERT, "a", 1: JInt, 100: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "b", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "c", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "d", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "e", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "f", 1: JInt, 70: JInt))
+
+    testHarness.processElement(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 10: JInt))
+
+    val result = dropWatermarks(testHarness.getOutput.toArray)
+    val expectedOutput = new ConcurrentLinkedQueue[Object]()
+
+    expectedOutput.add(binaryRecord(INSERT, "a", 1: JInt, 100: JInt, 1L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "b", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "f", 1: JInt, 70: JInt, 6L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "b", 1: JInt, 90: JInt, 2L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "c", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "d", 1: JInt, 80: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "e", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "f", 1: JInt, 70: JInt, 6L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "f", 1: JInt, 70: JInt, 5L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 10: JInt, 6L: JLong))
+
+    assertor.assertOutputEqualsSorted("result mismatch", expectedOutput, result)
+    testHarness.close()
+  }
+
+  @Test
+  def testUpdateRankWithRowNumberSortKeyDropsButRankUnchange(): Unit = {
+    val (testHarness, assertor) = prepareUpdateRankWithRowNumberTester()
+    testHarness.open()
+
+    testHarness.processElement(binaryRecord(INSERT, "a", 1: JInt, 100: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "b", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "c", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "d", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "e", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "f", 1: JInt, 70: JInt))
+
+    testHarness.processElement(binaryRecord(UPDATE_AFTER, "c", 1: JInt, 88: JInt))
+
+    val result = dropWatermarks(testHarness.getOutput.toArray)
+    val expectedOutput = new ConcurrentLinkedQueue[Object]()
+
+    expectedOutput.add(binaryRecord(INSERT, "a", 1: JInt, 100: JInt, 1L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "b", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "f", 1: JInt, 70: JInt, 6L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "c", 1: JInt, 88: JInt, 3L: JLong))
+
+    assertor.assertOutputEqualsSorted("result mismatch", expectedOutput, result)
+    testHarness.close()
+  }
+
+  @Test
+  def testUpdateRankWithRowNumberSortKeyDropsToNotLast(): Unit = {
+    val (testHarness, assertor) = prepareUpdateRankWithRowNumberTester()
+    testHarness.open()
+
+    testHarness.processElement(binaryRecord(INSERT, "a", 1: JInt, 100: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "b", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "c", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "d", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "e", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "f", 1: JInt, 70: JInt))
+
+    testHarness.processElement(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 80: JInt))
+
+    val result = dropWatermarks(testHarness.getOutput.toArray)
+    val expectedOutput = new ConcurrentLinkedQueue[Object]()
+
+    expectedOutput.add(binaryRecord(INSERT, "a", 1: JInt, 100: JInt, 1L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "b", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "f", 1: JInt, 70: JInt, 6L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "b", 1: JInt, 90: JInt, 2L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "c", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "d", 1: JInt, 80: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "e", 1: JInt, 80: JInt, 4L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 80: JInt, 5L: JLong))
+
+    assertor.assertOutputEqualsSorted("result mismatch", expectedOutput, result)
+    testHarness.close()
+  }
+
+  @Test
+  def testUpdateRankWithRowNumberCandidatesLargerThanRankEnd(): Unit = {
+    val (testHarness, assertor) = prepareUpdateRankWithRowNumberTester()
+    testHarness.open()
+
+    testHarness.processElement(binaryRecord(INSERT, "a", 1: JInt, 100: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "b", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "c", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "d", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "e", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "f", 1: JInt, 70: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "g", 1: JInt, 60: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "h", 1: JInt, 50: JInt))
+
+    testHarness.processElement(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 80: JInt))
+
+    val result = dropWatermarks(testHarness.getOutput.toArray)
+    val expectedOutput = new ConcurrentLinkedQueue[Object]()
+
+    expectedOutput.add(binaryRecord(INSERT, "a", 1: JInt, 100: JInt, 1L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "b", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "f", 1: JInt, 70: JInt, 6L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "b", 1: JInt, 90: JInt, 2L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "c", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "d", 1: JInt, 80: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "e", 1: JInt, 80: JInt, 4L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 80: JInt, 5L: JLong))
+
+    assertor.assertOutputEqualsSorted("result mismatch", expectedOutput, result)
+    testHarness.close()
+  }
+
+  @Test
+  def testUpdateRankWithRowNumberSortKeyDropsOutOfRandEnd(): Unit = {
+    // Calc Top6: 8 candidates, old rank 2 drops to rank 7 (but it is still "rank 6")
+    val (testHarness, assertor) = prepareUpdateRankWithRowNumberTester()
+    testHarness.open()
+
+    testHarness.processElement(binaryRecord(INSERT, "a", 1: JInt, 100: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "b", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "c", 1: JInt, 90: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "d", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "e", 1: JInt, 80: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "f", 1: JInt, 70: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "g", 1: JInt, 60: JInt))
+    testHarness.processElement(binaryRecord(INSERT, "h", 1: JInt, 50: JInt))
+
+    testHarness.processElement(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 55: JInt))
+
+    val result = dropWatermarks(testHarness.getOutput.toArray)
+    val expectedOutput = new ConcurrentLinkedQueue[Object]()
+
+    expectedOutput.add(binaryRecord(INSERT, "a", 1: JInt, 100: JInt, 1L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "b", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(INSERT, "f", 1: JInt, 70: JInt, 6L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "b", 1: JInt, 90: JInt, 2L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "c", 1: JInt, 90: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "c", 1: JInt, 90: JInt, 2L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "d", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "d", 1: JInt, 80: JInt, 3L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "e", 1: JInt, 80: JInt, 5L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "e", 1: JInt, 80: JInt, 4L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_BEFORE, "f", 1: JInt, 70: JInt, 6L: JLong))
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "f", 1: JInt, 70: JInt, 5L: JLong))
+
+    expectedOutput.add(binaryRecord(UPDATE_AFTER, "b", 1: JInt, 55: JInt, 6L: JLong))
+
+    assertor.assertOutputEqualsSorted("result mismatch", expectedOutput, result)
+    testHarness.close()
+  }
 }
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/rank/UpdatableTopNFunction.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/rank/UpdatableTopNFunction.java
index b2e3717cf56..41c538530c9 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/rank/UpdatableTopNFunction.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/rank/UpdatableTopNFunction.java
@@ -32,6 +32,8 @@ import org.apache.flink.runtime.state.FunctionInitializationContext;
 import org.apache.flink.runtime.state.FunctionSnapshotContext;
 import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;
 import org.apache.flink.table.data.RowData;
+import org.apache.flink.table.data.conversion.DataStructureConverter;
+import org.apache.flink.table.data.conversion.RowRowConverter;
 import org.apache.flink.table.runtime.generated.GeneratedRecordComparator;
 import org.apache.flink.table.runtime.keyselector.RowDataKeySelector;
 import org.apache.flink.table.runtime.typeutils.InternalTypeInfo;
@@ -75,6 +77,13 @@ public class UpdatableTopNFunction extends AbstractTopNFunction implements Check
     private final InternalTypeInfo<RowData> rowKeyType;
     private final long cacheSize;
 
+    // flag to skip records with non-exist error instead to fail, true by default.
+    private final boolean lenient = true;
+
+    // data converter for logging only.
+    private transient DataStructureConverter rowConverter;
+    private transient DataStructureConverter sortKeyConverter;
+
     // a map state stores mapping from row key to record which is in topN
     // in tuple2, f0 is the record row, f1 is the index in the list of the same sort_key
     // the f1 is used to preserve the record order in the same sort_key
@@ -138,6 +147,14 @@ public class UpdatableTopNFunction extends AbstractTopNFunction implements Check
                 getDefaultTopNSize(),
                 lruCacheSize);
 
+        this.rowConverter = RowRowConverter.create(inputRowType.getDataType());
+        this.sortKeyConverter =
+                RowRowConverter.create(
+                        ((RowDataKeySelector) sortKeySelector).getProducedType().getDataType());
+
+        rowConverter.open(getRuntimeContext().getUserCodeClassLoader());
+        sortKeyConverter.open(getRuntimeContext().getUserCodeClassLoader());
+
         TupleTypeInfo<Tuple2<RowData, Integer>> valueTypeInfo =
                 new TupleTypeInfo<>(inputRowType, Types.INT);
         MapStateDescriptor<RowData, Tuple2<RowData, Integer>> mapStateDescriptor =
@@ -249,7 +266,8 @@ public class UpdatableTopNFunction extends AbstractTopNFunction implements Check
             // the new sort key must be higher than old sort key, this is guaranteed by rules
             RankRow oldRow = rowKeyMap.get(rowKey);
             RowData oldSortKey = sortKeySelector.getKey(oldRow.row);
-            if (oldSortKey.equals(sortKey)) {
+            int compare = sortKeyComparator.compare(sortKey, oldSortKey);
+            if (compare == 0) {
                 // sort key is not changed, so the rank is the same, only output the row
                 Tuple2<Integer, Integer> rankAndInnerRank = rowNumber(sortKey, rowKey, buffer);
                 int rank = rankAndInnerRank.f0;
@@ -258,20 +276,47 @@ public class UpdatableTopNFunction extends AbstractTopNFunction implements Check
                 collectUpdateBefore(out, oldRow.row, rank); // retract old record
                 collectUpdateAfter(out, inputRow, rank);
                 return;
-            }
-
-            Tuple2<Integer, Integer> oldRankAndInnerRank = rowNumber(oldSortKey, rowKey, buffer);
-            int oldRank = oldRankAndInnerRank.f0;
-            // remove old sort key
-            buffer.remove(oldSortKey, rowKey);
-            // add new sort key
-            int size = buffer.put(sortKey, rowKey);
-            rowKeyMap.put(rowKey, new RankRow(inputRowSer.copy(inputRow), size, true));
-            // update inner rank of records under the old sort key
-            updateInnerRank(oldSortKey);
+            } else {
+                Tuple2<Integer, Integer> oldRankAndInnerRank =
+                        rowNumber(oldSortKey, rowKey, buffer);
+                int oldRank = oldRankAndInnerRank.f0;
+                // remove old sort key
+                buffer.remove(oldSortKey, rowKey);
+                // add new sort key
+                int size = buffer.put(sortKey, rowKey);
+                rowKeyMap.put(rowKey, new RankRow(inputRowSer.copy(inputRow), size, true));
+                // update inner rank of records under the old sort key
+                updateInnerRank(oldSortKey);
 
-            // emit records
-            emitRecordsWithRowNumber(sortKey, inputRow, out, oldSortKey, oldRow, oldRank);
+                if (compare < 0) {
+                    // sortKey is higher than oldSortKey
+                    emitRecordsWithRowNumber(sortKey, inputRow, out, oldSortKey, oldRow, oldRank);
+                } else {
+                    String inputRowStr = rowConverter.toExternal(inputRow).toString();
+                    String errorMsg =
+                            String.format(
+                                    "The input retract record:{%s}'s sort key: %s is lower than old"
+                                            + " sort key: %s, this break the monotonicity on sort key field"
+                                            + " which is guaranteed by the sql semantic. It's highly "
+                                            + "possible upstream stateful operator has shorter state ttl "
+                                            + "than the stream records is that cause the staled record "
+                                            + "cleared by state ttl.",
+                                    inputRowStr,
+                                    sortKeyConverter.toExternal(sortKey).toString(),
+                                    sortKeyConverter.toExternal(oldSortKey).toString());
+                    if (lenient) {
+                        LOG.warn(errorMsg);
+                        Tuple2<Integer, Integer> newRankAndInnerRank =
+                                rowNumber(sortKey, rowKey, buffer);
+                        int newRank = newRankAndInnerRank.f0;
+                        // affect rank range: [oldRank, newRank]
+                        emitRecordsWithRowNumberIgnoreStateError(
+                                inputRow, newRank, oldRow, oldRank, out);
+                    } else {
+                        throw new RuntimeException(errorMsg);
+                    }
+                }
+            }
         } else if (checkSortKeyInBufferRange(sortKey, buffer)) {
             // it is a new record but is in the topN, insert sort key into buffer
             int size = buffer.put(sortKey, rowKey);
@@ -312,6 +357,37 @@ public class UpdatableTopNFunction extends AbstractTopNFunction implements Check
                 "Failed to find the sortKey, rowkey in the buffer. This should never happen");
     }
 
+    private void emitRecordsWithRowNumberIgnoreStateError(
+            RowData newRow, int newRank, RankRow oldRow, int oldRank, Collector<RowData> out) {
+        Iterator<Map.Entry<RowData, Collection<RowData>>> iterator = buffer.entrySet().iterator();
+        int currentRank = 0;
+        RowData currentRow = null;
+
+        // emit UB of the old row first
+        collectUpdateBefore(out, oldRow.row, oldRank);
+        // update all other affected rank rows
+        affected:
+        while (iterator.hasNext()) {
+            Map.Entry<RowData, Collection<RowData>> entry = iterator.next();
+            Collection<RowData> rowKeys = entry.getValue();
+            Iterator<RowData> rowKeyIter = rowKeys.iterator();
+            while (rowKeyIter.hasNext()) {
+                RowData rowKey = rowKeyIter.next();
+                currentRank += 1;
+                currentRow = rowKeyMap.get(rowKey).row;
+                if (currentRank == newRank) {
+                    break affected;
+                }
+                if (oldRank <= currentRank) {
+                    collectUpdateBefore(out, currentRow, currentRank + 1);
+                    collectUpdateAfter(out, currentRow, currentRank);
+                }
+            }
+        }
+        // at last emit UA of the new row
+        collectUpdateAfter(out, newRow, newRank);
+    }
+
     private void emitRecordsWithRowNumber(RowData sortKey, RowData inputRow, Collector<RowData> out)
             throws Exception {
         emitRecordsWithRowNumber(sortKey, inputRow, out, null, null, -1);
