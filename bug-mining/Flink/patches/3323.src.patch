diff --git a/docs/dev/table/connect.md b/docs/dev/table/connect.md
index 520662026e2..e760059cd50 100644
--- a/docs/dev/table/connect.md
+++ b/docs/dev/table/connect.md
@@ -1857,6 +1857,7 @@ Use the old one for stream/batch filesystem operations for now.
   new OldCsv()
     .field("field1", Types.STRING)    // required: ordered format fields
     .field("field2", Types.TIMESTAMP)
+    .deriveSchema()                   // or use the table's schema
     .fieldDelimiter(",")              // optional: string delimiter "," by default
     .lineDelimiter("\n")              // optional: string delimiter "\n" by default
     .quoteCharacter('"')              // optional: single character for string values, empty by default
@@ -1892,6 +1893,7 @@ format:
       type: VARCHAR
     - name: field2
       type: TIMESTAMP
+  derive-schema: true        # or use the table's schema
   field-delimiter: ","       # optional: string delimiter "," by default
   line-delimiter: "\n"       # optional: string delimiter "\n" by default
   quote-character: '"'       # optional: single character for string values, empty by default
@@ -1912,7 +1914,9 @@ CREATE TABLE MyUserTable (
   'format.fields.0.type' = 'FLOAT',
   'format.fields.1.name' = 'rideTime',
   'format.fields.1.type' = 'TIMESTAMP',
-  
+
+  'format.derive-schema' = 'true',        -- or use the table's schema'
+
   'format.field-delimiter' = ',',         -- optional: string delimiter "," by default
   'format.line-delimiter' = '\n',         -- optional: string delimiter "\n" by default
   'format.quote-character' = '"',         -- optional: single character for string values, empty by default
diff --git a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsv.java b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsv.java
index f7cdc9f6d5d..378d466110c 100644
--- a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsv.java
+++ b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsv.java
@@ -31,6 +31,7 @@ import java.util.Map;
 import java.util.Optional;
 import java.util.stream.Collectors;
 
+import static org.apache.flink.table.descriptors.FormatDescriptorValidator.FORMAT_DERIVE_SCHEMA;
 import static org.apache.flink.table.descriptors.OldCsvValidator.FORMAT_COMMENT_PREFIX;
 import static org.apache.flink.table.descriptors.OldCsvValidator.FORMAT_FIELDS;
 import static org.apache.flink.table.descriptors.OldCsvValidator.FORMAT_FIELD_DELIMITER;
@@ -62,6 +63,7 @@ public class OldCsv extends FormatDescriptor {
 	private Optional<String> commentPrefix = Optional.empty();
 	private Optional<Boolean> isIgnoreFirstLine = Optional.empty();
 	private Optional<Boolean> lenient = Optional.empty();
+	private Optional<Boolean> deriveSchema = Optional.empty();
 
 	public OldCsv() {
 		super(FORMAT_TYPE_VALUE, 1);
@@ -168,6 +170,19 @@ public class OldCsv extends FormatDescriptor {
 		return this;
 	}
 
+	/**
+	 * Derives the format schema from the table's schema. Required if no format schema is defined.
+	 *
+	 * <p>This allows for defining schema information only once.
+	 *
+	 * <p>The names, types, and fields' order of the format are determined by the table's
+	 * schema.
+	 */
+	public OldCsv deriveSchema() {
+		this.deriveSchema = Optional.of(true);
+		return this;
+	}
+
 	@Override
 	protected Map<String, String> toFormatProperties() {
 		DescriptorProperties properties = new DescriptorProperties();
@@ -175,15 +190,19 @@ public class OldCsv extends FormatDescriptor {
 		fieldDelim.ifPresent(s -> properties.putString(FORMAT_FIELD_DELIMITER, s));
 		lineDelim.ifPresent(s -> properties.putString(FORMAT_LINE_DELIMITER, s));
 
-		List<String> subKeys = Arrays.asList(
+		if (deriveSchema.isPresent() && deriveSchema.get()) {
+			properties.putBoolean(FORMAT_DERIVE_SCHEMA, true);
+		} else {
+			List<String> subKeys = Arrays.asList(
 				DescriptorProperties.TABLE_SCHEMA_NAME,
 				DescriptorProperties.TABLE_SCHEMA_TYPE);
 
-		List<List<String>> subValues = schema.entrySet().stream()
+			List<List<String>> subValues = schema.entrySet().stream()
 				.map(e -> Arrays.asList(e.getKey(), e.getValue()))
 				.collect(Collectors.toList());
 
-		properties.putIndexedFixedProperties(FORMAT_FIELDS, subKeys, subValues);
+			properties.putIndexedFixedProperties(FORMAT_FIELDS, subKeys, subValues);
+		}
 
 		quoteCharacter.ifPresent(character -> properties.putCharacter(FORMAT_QUOTE_CHARACTER, character));
 		commentPrefix.ifPresent(s -> properties.putString(FORMAT_COMMENT_PREFIX, s));
diff --git a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsvValidator.java b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsvValidator.java
index 1264494f9b1..9f8476db96c 100644
--- a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsvValidator.java
+++ b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/descriptors/OldCsvValidator.java
@@ -19,6 +19,7 @@
 package org.apache.flink.table.descriptors;
 
 import org.apache.flink.annotation.Internal;
+import org.apache.flink.table.api.ValidationException;
 
 /**
  * Validator for {@link OldCsv}.
@@ -49,6 +50,20 @@ public class OldCsvValidator extends FormatDescriptorValidator {
 		properties.validateString(FORMAT_COMMENT_PREFIX, true, 1);
 		properties.validateBoolean(FORMAT_IGNORE_FIRST_LINE, true);
 		properties.validateBoolean(FORMAT_IGNORE_PARSE_ERRORS, true);
-		properties.validateTableSchema(FORMAT_FIELDS, false);
+		properties.validateBoolean(FormatDescriptorValidator.FORMAT_DERIVE_SCHEMA, true);
+
+		final boolean hasSchema = properties.hasPrefix(FORMAT_FIELDS);
+		final boolean isDerived = properties
+			.getOptionalBoolean(FormatDescriptorValidator.FORMAT_DERIVE_SCHEMA)
+			.orElse(false);
+		if (isDerived && hasSchema) {
+			throw new ValidationException(
+				"Format cannot define a schema and derive from the table's schema at the same time.");
+		} else if (hasSchema) {
+			properties.validateTableSchema(FORMAT_FIELDS, false);
+		} else if (!isDerived) {
+			throw new ValidationException(
+				"A definition of a schema or derivation from the table's schema is required.");
+		}
 	}
 }
diff --git a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/CsvTableSinkFactoryBase.java b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/CsvTableSinkFactoryBase.java
index 9c83b4a3897..735136bf5ec 100644
--- a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/CsvTableSinkFactoryBase.java
+++ b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/CsvTableSinkFactoryBase.java
@@ -23,6 +23,7 @@ import org.apache.flink.table.api.TableException;
 import org.apache.flink.table.api.TableSchema;
 import org.apache.flink.table.descriptors.DescriptorProperties;
 import org.apache.flink.table.descriptors.FileSystemValidator;
+import org.apache.flink.table.descriptors.FormatDescriptorValidator;
 import org.apache.flink.table.descriptors.OldCsvValidator;
 import org.apache.flink.table.descriptors.SchemaValidator;
 import org.apache.flink.table.factories.TableFactory;
@@ -66,6 +67,7 @@ public abstract class CsvTableSinkFactoryBase implements TableFactory {
 		// format
 		properties.add(FORMAT_FIELDS + ".#." + DescriptorProperties.TABLE_SCHEMA_TYPE);
 		properties.add(FORMAT_FIELDS + ".#." + DescriptorProperties.TABLE_SCHEMA_NAME);
+		properties.add(FormatDescriptorValidator.FORMAT_DERIVE_SCHEMA);
 		properties.add(FORMAT_FIELD_DELIMITER);
 		properties.add(CONNECTOR_PATH);
 		// schema
@@ -87,12 +89,16 @@ public abstract class CsvTableSinkFactoryBase implements TableFactory {
 		new SchemaValidator(isStreaming, false, false).validate(params);
 
 		// build
-		TableSchema formatSchema = params.getTableSchema(FORMAT_FIELDS);
 		TableSchema tableSchema = params.getTableSchema(SCHEMA);
-
-		if (!formatSchema.equals(tableSchema)) {
-			throw new TableException(
+		boolean isDerived = params
+			.getOptionalBoolean(FormatDescriptorValidator.FORMAT_DERIVE_SCHEMA)
+			.orElse(false);
+		if (!isDerived) {
+			TableSchema formatSchema = params.getTableSchema(FORMAT_FIELDS);
+			if (!formatSchema.equals(tableSchema)) {
+				throw new TableException(
 					"Encodings that differ from the schema are not supported yet for CsvTableSink.");
+			}
 		}
 
 		String path = params.getString(CONNECTOR_PATH);
@@ -100,7 +106,7 @@ public abstract class CsvTableSinkFactoryBase implements TableFactory {
 
 		CsvTableSink csvTableSink = new CsvTableSink(path, fieldDelimiter);
 
-		return (CsvTableSink) csvTableSink.configure(formatSchema.getFieldNames(), formatSchema.getFieldTypes());
+		return (CsvTableSink) csvTableSink.configure(tableSchema.getFieldNames(), tableSchema.getFieldTypes());
 	}
 
 }
diff --git a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sources/CsvTableSourceFactoryBase.java b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sources/CsvTableSourceFactoryBase.java
index 4dc8e403401..e1cf4051a56 100644
--- a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sources/CsvTableSourceFactoryBase.java
+++ b/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sources/CsvTableSourceFactoryBase.java
@@ -23,6 +23,7 @@ import org.apache.flink.table.api.TableException;
 import org.apache.flink.table.api.TableSchema;
 import org.apache.flink.table.descriptors.DescriptorProperties;
 import org.apache.flink.table.descriptors.FileSystemValidator;
+import org.apache.flink.table.descriptors.FormatDescriptorValidator;
 import org.apache.flink.table.descriptors.OldCsvValidator;
 import org.apache.flink.table.descriptors.SchemaValidator;
 import org.apache.flink.table.factories.TableFactory;
@@ -71,6 +72,7 @@ public abstract class CsvTableSourceFactoryBase implements TableFactory {
 		// format
 		properties.add(FORMAT_FIELDS + ".#." + DescriptorProperties.TABLE_SCHEMA_TYPE);
 		properties.add(FORMAT_FIELDS + ".#." + DescriptorProperties.TABLE_SCHEMA_NAME);
+		properties.add(FormatDescriptorValidator.FORMAT_DERIVE_SCHEMA);
 		properties.add(FORMAT_FIELD_DELIMITER);
 		properties.add(FORMAT_LINE_DELIMITER);
 		properties.add(FORMAT_QUOTE_CHARACTER);
@@ -99,22 +101,27 @@ public abstract class CsvTableSourceFactoryBase implements TableFactory {
 		// build
 		CsvTableSource.Builder csvTableSourceBuilder = new CsvTableSource.Builder();
 
-		TableSchema formatSchema = params.getTableSchema(FORMAT_FIELDS);
 		TableSchema tableSchema = params.getTableSchema(SCHEMA);
-
-		// the CsvTableSource needs some rework first
-		// for now the schema must be equal to the encoding
-		if (!formatSchema.equals(tableSchema)) {
-			throw new TableException(
+		boolean isDerived = params
+			.getOptionalBoolean(FormatDescriptorValidator.FORMAT_DERIVE_SCHEMA)
+			.orElse(false);
+
+		if (!isDerived) {
+			TableSchema formatSchema = params.getTableSchema(FORMAT_FIELDS);
+			// the CsvTableSource needs some rework first
+			// for now the schema must be equal to the encoding
+			if (!formatSchema.equals(tableSchema)) {
+				throw new TableException(
 					"Encodings that differ from the schema are not supported yet for CsvTableSources.");
+			}
 		}
 
 		params.getOptionalString(CONNECTOR_PATH).ifPresent(csvTableSourceBuilder::path);
 		params.getOptionalString(FORMAT_FIELD_DELIMITER).ifPresent(csvTableSourceBuilder::fieldDelimiter);
 		params.getOptionalString(FORMAT_LINE_DELIMITER).ifPresent(csvTableSourceBuilder::lineDelimiter);
 
-		for (int i = 0; i < formatSchema.getFieldCount(); ++i) {
-			csvTableSourceBuilder.field(formatSchema.getFieldNames()[i], formatSchema.getFieldTypes()[i]);
+		for (int i = 0; i < tableSchema.getFieldCount(); ++i) {
+			csvTableSourceBuilder.field(tableSchema.getFieldNames()[i], tableSchema.getFieldTypes()[i]);
 		}
 		params.getOptionalCharacter(FORMAT_QUOTE_CHARACTER).ifPresent(csvTableSourceBuilder::quoteCharacter);
 		params.getOptionalString(FORMAT_COMMENT_PREFIX).ifPresent(csvTableSourceBuilder::commentPrefix);
diff --git a/flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/factories/CsvTableSinkFactoryTest.java b/flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/factories/CsvTableSinkFactoryTest.java
new file mode 100644
index 00000000000..aa1a9e50d87
--- /dev/null
+++ b/flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/factories/CsvTableSinkFactoryTest.java
@@ -0,0 +1,135 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.factories;
+
+import org.apache.flink.api.common.typeinfo.Types;
+import org.apache.flink.table.api.DataTypes;
+import org.apache.flink.table.api.TableSchema;
+import org.apache.flink.table.descriptors.DescriptorProperties;
+import org.apache.flink.table.sinks.CsvTableSink;
+import org.apache.flink.table.sinks.TableSink;
+import org.apache.flink.table.sources.CsvTableSource;
+import org.apache.flink.table.sources.TableSource;
+
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.apache.flink.table.descriptors.OldCsvValidator.FORMAT_FIELDS;
+import static org.apache.flink.table.descriptors.Schema.SCHEMA;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+/**
+ * Tests for CsvTableSourceFactory and CsvTableSinkFactory.
+ */
+@RunWith(Parameterized.class)
+public class CsvTableSinkFactoryTest {
+
+	private static TableSchema testingSchema = TableSchema.builder()
+		.field("myfield", DataTypes.STRING())
+		.field("myfield2", DataTypes.INT())
+		.field("myfield3", DataTypes.MAP(DataTypes.STRING(), DataTypes.INT()))
+		.field("myfield4", DataTypes.ROW(DataTypes.FIELD("nested_f1", DataTypes.BIGINT())))
+		.field("myfield5", Types.PRIMITIVE_ARRAY(Types.SHORT))
+		.build();
+
+	@Parameterized.Parameter
+	public boolean deriveSchema;
+
+	@Parameterized.Parameters(name = "deriveSchema = {0}")
+	public static Boolean[] getDeriveSchema() {
+		return new Boolean[]{true, false};
+	}
+
+	@Test
+	public void testAppendTableSinkFactory() {
+		DescriptorProperties descriptor = createDescriptor(testingSchema);
+		descriptor.putString("update-mode", "append");
+		TableSink sink = createTableSink(descriptor);
+
+		assertTrue(sink instanceof CsvTableSink);
+		assertEquals(testingSchema.toRowDataType(), sink.getConsumedDataType());
+	}
+
+	@Test
+	public void testBatchTableSinkFactory() {
+		DescriptorProperties descriptor = createDescriptor(testingSchema);
+		TableSink sink = createTableSink(descriptor);
+
+		assertTrue(sink instanceof CsvTableSink);
+		assertEquals(testingSchema.toRowDataType(), sink.getConsumedDataType());
+	}
+
+	@Test
+	public void testAppendTableSourceFactory() {
+		DescriptorProperties descriptor = createDescriptor(testingSchema);
+		descriptor.putString("update-mode", "append");
+		TableSource sink = createTableSource(descriptor);
+
+		assertTrue(sink instanceof CsvTableSource);
+		assertEquals(testingSchema.toRowDataType(), sink.getProducedDataType());
+	}
+
+	@Test
+	public void testBatchTableSourceFactory() {
+		DescriptorProperties descriptor = createDescriptor(testingSchema);
+		TableSource sink = createTableSource(descriptor);
+
+		assertTrue(sink instanceof CsvTableSource);
+		assertEquals(testingSchema.toRowDataType(), sink.getProducedDataType());
+	}
+
+	private DescriptorProperties createDescriptor(TableSchema schema) {
+		Map<String, String> properties = new HashMap<>();
+		properties.put("connector.type", "filesystem");
+		properties.put("connector.property-version", "1");
+		properties.put("connector.path", "/path/to/csv");
+
+		// schema
+		properties.put("format.type", "csv");
+		properties.put("format.property-version", "1");
+		properties.put("format.field-delimiter", ";");
+
+		DescriptorProperties descriptor = new DescriptorProperties(true);
+		descriptor.putProperties(properties);
+		descriptor.putTableSchema(SCHEMA, schema);
+		if (deriveSchema) {
+			descriptor.putBoolean("format.derive-schema", deriveSchema);
+		} else {
+			descriptor.putTableSchema(FORMAT_FIELDS, testingSchema);
+		}
+		return descriptor;
+	}
+
+	private static TableSource<?> createTableSource(DescriptorProperties descriptor) {
+		return TableFactoryService
+			.find(TableSourceFactory.class, descriptor.asMap())
+			.createTableSource(descriptor.asMap());
+	}
+
+	private static TableSink<?> createTableSink(DescriptorProperties descriptor) {
+		return TableFactoryService
+			.find(TableSinkFactory.class, descriptor.asMap())
+			.createTableSink(descriptor.asMap());
+	}
+}
