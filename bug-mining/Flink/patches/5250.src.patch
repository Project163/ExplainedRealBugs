diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java
index 5e00afc2329..2703146d3c1 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java
@@ -108,6 +108,7 @@ import java.util.Set;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CompletionException;
 import java.util.concurrent.Executor;
+import java.util.function.Function;
 import java.util.stream.Collectors;
 import java.util.stream.StreamSupport;
 
@@ -247,28 +248,46 @@ public abstract class SchedulerBase implements SchedulerNG, CheckpointScheduling
         }
     }
 
+    private static int normalizeParallelism(int parallelism) {
+        if (parallelism == ExecutionConfig.PARALLELISM_DEFAULT) {
+            return 1;
+        }
+        return parallelism;
+    }
+
+    /**
+     * Get a default value to use for a given vertex's max parallelism if none was specified.
+     *
+     * @param vertex the vertex to compute a default max parallelism for
+     * @return the computed max parallelism
+     */
+    public static int getDefaultMaxParallelism(JobVertex vertex) {
+        return KeyGroupRangeAssignment.computeDefaultMaxParallelism(
+                normalizeParallelism(vertex.getParallelism()));
+    }
+
     /**
      * Compute the {@link VertexParallelismStore} for all given vertices, which will set defaults
-     * and ensure that the returned store contains valid parallelisms.
+     * and ensure that the returned store contains valid parallelisms, with a custom function for
+     * default max parallelism calculation.
      *
      * @param vertices the vertices to compute parallelism for
+     * @param defaultMaxParallelismFunc a function for computing a default max parallelism if none
+     *     is specified on a given vertex
      * @return the computed parallelism store
      */
     public static VertexParallelismStore computeVertexParallelismStore(
-            Iterable<JobVertex> vertices) {
+            Iterable<JobVertex> vertices, Function<JobVertex, Integer> defaultMaxParallelismFunc) {
         DefaultVertexParallelismStore store = new DefaultVertexParallelismStore();
 
         for (JobVertex vertex : vertices) {
-            int parallelism = vertex.getParallelism();
-            if (vertex.getParallelism() == ExecutionConfig.PARALLELISM_DEFAULT) {
-                parallelism = 1;
-            }
+            int parallelism = normalizeParallelism(vertex.getParallelism());
 
             int maxParallelism = vertex.getMaxParallelism();
             final boolean autoConfigured;
             // if no max parallelism was configured by the user, we calculate and set a default
             if (maxParallelism == JobVertex.MAX_PARALLELISM_DEFAULT) {
-                maxParallelism = KeyGroupRangeAssignment.computeDefaultMaxParallelism(parallelism);
+                maxParallelism = defaultMaxParallelismFunc.apply(vertex);
                 autoConfigured = true;
             } else {
                 autoConfigured = false;
@@ -291,6 +310,18 @@ public abstract class SchedulerBase implements SchedulerNG, CheckpointScheduling
         return store;
     }
 
+    /**
+     * Compute the {@link VertexParallelismStore} for all given vertices, which will set defaults
+     * and ensure that the returned store contains valid parallelisms.
+     *
+     * @param vertices the vertices to compute parallelism for
+     * @return the computed parallelism store
+     */
+    public static VertexParallelismStore computeVertexParallelismStore(
+            Iterable<JobVertex> vertices) {
+        return computeVertexParallelismStore(vertices, SchedulerBase::getDefaultMaxParallelism);
+    }
+
     /**
      * Compute the {@link VertexParallelismStore} for all vertices of a given job graph, which will
      * set defaults and ensure that the returned store contains valid parallelisms.
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveScheduler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveScheduler.java
index cb33a045011..ba045104c58 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveScheduler.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveScheduler.java
@@ -100,7 +100,6 @@ import org.apache.flink.runtime.scheduler.adaptive.allocator.VertexParallelism;
 import org.apache.flink.runtime.scheduler.adaptive.scalingpolicy.ReactiveScaleUpController;
 import org.apache.flink.runtime.scheduler.adaptive.scalingpolicy.ScaleUpController;
 import org.apache.flink.runtime.state.KeyGroupRange;
-import org.apache.flink.runtime.state.KeyGroupRangeAssignment;
 import org.apache.flink.runtime.util.ResourceCounter;
 import org.apache.flink.util.ExceptionUtils;
 import org.apache.flink.util.FlinkException;
@@ -124,6 +123,7 @@ import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.Executor;
 import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.TimeUnit;
+import java.util.function.Function;
 
 /**
  * A {@link SchedulerNG} implementation that uses the declarative resource management and
@@ -297,28 +297,32 @@ public class AdaptiveScheduler
      * executing the graph we should respect what we are actually given.
      *
      * @param vertices The vertices to store parallelism information for
-     * @param adjustParallelisms Whether to adjust the parallelisms
+     * @param adjustParallelism Whether to adjust the parallelism
+     * @param defaultMaxParallelismFunc a function for computing a default max parallelism if none
+     *     is specified on a given vertex
      * @return The parallelism store.
      */
     @VisibleForTesting
     static VertexParallelismStore computeReactiveModeVertexParallelismStore(
-            Iterable<JobVertex> vertices, boolean adjustParallelisms) {
+            Iterable<JobVertex> vertices,
+            Function<JobVertex, Integer> defaultMaxParallelismFunc,
+            boolean adjustParallelism) {
         DefaultVertexParallelismStore store = new DefaultVertexParallelismStore();
 
         for (JobVertex vertex : vertices) {
             // if no max parallelism was configured by the user, we calculate and set a default
+            final int maxParallelism =
+                    vertex.getMaxParallelism() == JobVertex.MAX_PARALLELISM_DEFAULT
+                            ? defaultMaxParallelismFunc.apply(vertex)
+                            : vertex.getMaxParallelism();
+            // If the parallelism has already been adjusted, respect what has been configured in the
+            // vertex. Otherwise, scale it to the max parallelism to attempt to be "as parallel as
+            // possible"
             final int parallelism;
-            final int maxParallelism;
-            if (adjustParallelisms) {
-                maxParallelism =
-                        vertex.getMaxParallelism() == JobVertex.MAX_PARALLELISM_DEFAULT
-                                ? KeyGroupRangeAssignment.computeDefaultMaxParallelism(
-                                        vertex.getParallelism())
-                                : vertex.getMaxParallelism();
+            if (adjustParallelism) {
                 parallelism = maxParallelism;
             } else {
                 parallelism = vertex.getParallelism();
-                maxParallelism = vertex.getMaxParallelism();
             }
 
             VertexParallelismInformation parallelismInfo =
@@ -352,7 +356,8 @@ public class AdaptiveScheduler
     private static VertexParallelismStore computeVertexParallelismStore(
             JobGraph jobGraph, SchedulerExecutionMode executionMode) {
         if (executionMode == SchedulerExecutionMode.REACTIVE) {
-            return computeReactiveModeVertexParallelismStore(jobGraph.getVertices(), true);
+            return computeReactiveModeVertexParallelismStore(
+                    jobGraph.getVertices(), SchedulerBase::getDefaultMaxParallelism, true);
         }
         return SchedulerBase.computeVertexParallelismStore(jobGraph);
     }
@@ -363,15 +368,21 @@ public class AdaptiveScheduler
      *
      * @param jobGraph The job graph for execution.
      * @param executionMode The mode of scheduler execution.
+     * @param defaultMaxParallelismFunc a function for computing a default max parallelism if none
+     *     is specified on a given vertex
      * @return The parallelism store.
      */
     @VisibleForTesting
     static VertexParallelismStore computeVertexParallelismStoreForExecution(
-            JobGraph jobGraph, SchedulerExecutionMode executionMode) {
+            JobGraph jobGraph,
+            SchedulerExecutionMode executionMode,
+            Function<JobVertex, Integer> defaultMaxParallelismFunc) {
         if (executionMode == SchedulerExecutionMode.REACTIVE) {
-            return computeReactiveModeVertexParallelismStore(jobGraph.getVertices(), false);
+            return computeReactiveModeVertexParallelismStore(
+                    jobGraph.getVertices(), defaultMaxParallelismFunc, false);
         }
-        return SchedulerBase.computeVertexParallelismStore(jobGraph);
+        return SchedulerBase.computeVertexParallelismStore(
+                jobGraph.getVertices(), defaultMaxParallelismFunc);
     }
 
     private void newResourcesAvailable(Collection<? extends PhysicalSlot> physicalSlots) {
@@ -891,18 +902,22 @@ public class AdaptiveScheduler
             for (JobVertex vertex : adjustedJobGraph.getVertices()) {
                 JobVertexID id = vertex.getID();
 
-                // use the originally computed max parallelism for constant runs,
-                // and the determined "available parallelism" to use
+                // use the determined "available parallelism" to use
                 // the resources we have access to
                 vertex.setParallelism(vertexParallelism.getParallelism(id));
-
-                VertexParallelismInformation vertexParallelismInfo =
-                        initialParallelismStore.getParallelismInfo(id);
-                vertex.setMaxParallelism(vertexParallelismInfo.getMaxParallelism());
             }
 
+            // use the originally configured max parallelism
+            // as the default for consistent runs
             adjustedParallelismStore =
-                    computeVertexParallelismStoreForExecution(adjustedJobGraph, executionMode);
+                    computeVertexParallelismStoreForExecution(
+                            adjustedJobGraph,
+                            executionMode,
+                            (vertex) -> {
+                                VertexParallelismInformation vertexParallelismInfo =
+                                        initialParallelismStore.getParallelismInfo(vertex.getID());
+                                return vertexParallelismInfo.getMaxParallelism();
+                            });
         } catch (Exception exception) {
             return FutureUtils.completedExceptionally(exception);
         }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerComputeReactiveModeVertexParallelismTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerComputeReactiveModeVertexParallelismTest.java
index 8ce3fec29d2..0d99693eda2 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerComputeReactiveModeVertexParallelismTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerComputeReactiveModeVertexParallelismTest.java
@@ -19,6 +19,7 @@
 package org.apache.flink.runtime.scheduler.adaptive;
 
 import org.apache.flink.runtime.jobgraph.JobVertex;
+import org.apache.flink.runtime.scheduler.SchedulerBase;
 import org.apache.flink.runtime.scheduler.VertexParallelismInformation;
 import org.apache.flink.runtime.scheduler.VertexParallelismStore;
 import org.apache.flink.util.TestLogger;
@@ -32,9 +33,6 @@ import java.util.Collections;
 
 import static org.apache.flink.runtime.executiongraph.ExecutionGraphTestUtils.createNoOpVertex;
 import static org.apache.flink.runtime.state.KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.not;
-import static org.junit.Assume.assumeThat;
 
 /** Test vertex parallelism configuration for the {@link AdaptiveScheduler} in Reactive mode. */
 @RunWith(Parameterized.class)
@@ -82,15 +80,12 @@ public class AdaptiveSchedulerComputeReactiveModeVertexParallelismTest extends T
 
     @Test
     public void testCreateStoreWithoutAdjustedParallelism() {
-        assumeThat(
-                "max parallelism must be set",
-                maxParallelism,
-                is(not(JobVertex.MAX_PARALLELISM_DEFAULT)));
-
         JobVertex jobVertex = createNoOpVertex("test", parallelism, maxParallelism);
         VertexParallelismStore store =
                 AdaptiveScheduler.computeReactiveModeVertexParallelismStore(
-                        Collections.singleton(jobVertex), false);
+                        Collections.singleton(jobVertex),
+                        SchedulerBase::getDefaultMaxParallelism,
+                        false);
 
         VertexParallelismInformation info = store.getParallelismInfo(jobVertex.getID());
 
@@ -108,7 +103,9 @@ public class AdaptiveSchedulerComputeReactiveModeVertexParallelismTest extends T
         JobVertex jobVertex = createNoOpVertex("test", parallelism, maxParallelism);
         VertexParallelismStore store =
                 AdaptiveScheduler.computeReactiveModeVertexParallelismStore(
-                        Collections.singleton(jobVertex), true);
+                        Collections.singleton(jobVertex),
+                        SchedulerBase::getDefaultMaxParallelism,
+                        true);
 
         VertexParallelismInformation info = store.getParallelismInfo(jobVertex.getID());
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerTest.java
index 8859dbbb60a..3a7500d2b9c 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/adaptive/AdaptiveSchedulerTest.java
@@ -38,6 +38,7 @@ import org.apache.flink.runtime.deployment.TaskDeploymentDescriptor;
 import org.apache.flink.runtime.execution.ExecutionState;
 import org.apache.flink.runtime.execution.SuppressRestartsException;
 import org.apache.flink.runtime.executiongraph.ArchivedExecutionGraph;
+import org.apache.flink.runtime.executiongraph.ArchivedExecutionJobVertex;
 import org.apache.flink.runtime.executiongraph.ExecutionAttemptID;
 import org.apache.flink.runtime.executiongraph.TaskExecutionStateTransition;
 import org.apache.flink.runtime.executiongraph.failover.flip1.NoRestartBackoffTimeStrategy;
@@ -46,10 +47,8 @@ import org.apache.flink.runtime.executiongraph.utils.SimpleAckingTaskManagerGate
 import org.apache.flink.runtime.io.network.partition.ResultPartitionID;
 import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;
 import org.apache.flink.runtime.jobgraph.JobGraph;
-import org.apache.flink.runtime.jobgraph.JobGraphTestUtils;
 import org.apache.flink.runtime.jobgraph.JobVertex;
 import org.apache.flink.runtime.jobgraph.OperatorID;
-import org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable;
 import org.apache.flink.runtime.jobgraph.tasks.CheckpointCoordinatorConfiguration;
 import org.apache.flink.runtime.jobgraph.tasks.JobCheckpointingSettings;
 import org.apache.flink.runtime.jobmanager.PartitionProducerDisposedException;
@@ -63,6 +62,8 @@ import org.apache.flink.runtime.operators.coordination.CoordinationRequest;
 import org.apache.flink.runtime.operators.coordination.TaskNotRunningException;
 import org.apache.flink.runtime.operators.coordination.TestOperatorEvent;
 import org.apache.flink.runtime.rest.handler.legacy.utils.ArchivedExecutionGraphBuilder;
+import org.apache.flink.runtime.scheduler.SchedulerBase;
+import org.apache.flink.runtime.scheduler.SchedulerNG;
 import org.apache.flink.runtime.scheduler.VertexParallelismInformation;
 import org.apache.flink.runtime.scheduler.VertexParallelismStore;
 import org.apache.flink.runtime.scheduler.adaptive.allocator.TestingSlotAllocator;
@@ -101,6 +102,7 @@ import java.util.function.Consumer;
 
 import static org.apache.flink.core.testutils.FlinkMatchers.futureFailedWith;
 import static org.apache.flink.runtime.executiongraph.ExecutionGraphTestUtils.createNoOpVertex;
+import static org.apache.flink.runtime.jobgraph.JobGraphTestUtils.streamingJobGraph;
 import static org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPoolTest.createSlotOffersForResourceRequirements;
 import static org.apache.flink.runtime.jobmaster.slotpool.SlotPoolTestUtils.offerSlots;
 import static org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups.createUnregisteredJobManagerMetricGroup;
@@ -114,7 +116,7 @@ import static org.junit.Assert.assertThat;
 public class AdaptiveSchedulerTest extends TestLogger {
 
     private static final int PARALLELISM = 4;
-    private static final JobVertex JOB_VERTEX;
+    private static final JobVertex JOB_VERTEX = createNoOpVertex("v1", PARALLELISM);
 
     @ClassRule public static final TemporaryFolder TEMPORARY_FOLDER = new TemporaryFolder();
 
@@ -122,12 +124,6 @@ public class AdaptiveSchedulerTest extends TestLogger {
     public static final TestExecutorResource<ScheduledExecutorService> TEST_EXECUTOR_RESOURCE =
             new TestExecutorResource<>(Executors::newSingleThreadScheduledExecutor);
 
-    static {
-        JOB_VERTEX = new JobVertex("v1");
-        JOB_VERTEX.setParallelism(PARALLELISM);
-        JOB_VERTEX.setInvokableClass(AbstractInvokable.class);
-    }
-
     private final ManuallyTriggeredComponentMainThreadExecutor mainThreadExecutor =
             new ManuallyTriggeredComponentMainThreadExecutor(Thread.currentThread());
 
@@ -440,14 +436,7 @@ public class AdaptiveSchedulerTest extends TestLogger {
         final SubmissionBufferingTaskManagerGateway taskManagerGateway =
                 new SubmissionBufferingTaskManagerGateway(1 + PARALLELISM);
 
-        taskManagerGateway.setCancelConsumer(
-                executionAttemptId ->
-                        singleThreadMainThreadExecutor.execute(
-                                () ->
-                                        scheduler.updateTaskExecutionState(
-                                                new TaskExecutionState(
-                                                        executionAttemptId,
-                                                        ExecutionState.CANCELED))));
+        taskManagerGateway.setCancelConsumer(createCancelConsumer(scheduler));
 
         singleThreadMainThreadExecutor.execute(
                 () -> {
@@ -674,6 +663,78 @@ public class AdaptiveSchedulerTest extends TestLogger {
         assertThat(firstState.onLeaveNewStateArgument.equals(DummyState.class), is(true));
     }
 
+    @Test
+    public void testConsistentMaxParallelism() throws Exception {
+        final int parallelism = 240;
+        final int expectedMaxParallelism =
+                KeyGroupRangeAssignment.computeDefaultMaxParallelism(parallelism);
+        final JobVertex vertex = createNoOpVertex(parallelism);
+        final JobGraph jobGraph = streamingJobGraph(vertex);
+
+        final DefaultDeclarativeSlotPool declarativeSlotPool =
+                createDeclarativeSlotPool(jobGraph.getJobID());
+
+        final Configuration configuration = new Configuration();
+        configuration.set(JobManagerOptions.RESOURCE_WAIT_TIMEOUT, Duration.ofMillis(1L));
+
+        final AdaptiveScheduler scheduler =
+                new AdaptiveSchedulerBuilder(jobGraph, singleThreadMainThreadExecutor)
+                        .setDeclarativeSlotPool(declarativeSlotPool)
+                        .setJobMasterConfiguration(configuration)
+                        .build();
+
+        final SubmissionBufferingTaskManagerGateway taskManagerGateway =
+                new SubmissionBufferingTaskManagerGateway(1 + parallelism);
+        taskManagerGateway.setCancelConsumer(createCancelConsumer(scheduler));
+
+        // offer just enough resources to run at the lowest possible parallelism
+        singleThreadMainThreadExecutor.execute(
+                () -> {
+                    scheduler.startScheduling();
+                    offerSlots(
+                            declarativeSlotPool,
+                            createSlotOffersForResourceRequirements(
+                                    ResourceCounter.withResource(ResourceProfile.UNKNOWN, 1)),
+                            taskManagerGateway);
+                });
+
+        // Wait for task to be submitted
+        taskManagerGateway.waitForSubmissions(1, Duration.ofSeconds(5));
+
+        ArchivedExecutionGraph executionGraph =
+                getArchivedExecutionGraphForRunningJob(scheduler).get();
+        ArchivedExecutionJobVertex archivedVertex = executionGraph.getJobVertex(vertex.getID());
+
+        // ensure that the parallelism was submitted based on what is available
+        assertThat(archivedVertex.getParallelism(), is(1));
+        // and that the max parallelism was submitted based on what was configured
+        assertThat(archivedVertex.getMaxParallelism(), is(expectedMaxParallelism));
+
+        // offer the resources to run at full parallelism
+        singleThreadMainThreadExecutor.execute(
+                () -> {
+                    offerSlots(
+                            declarativeSlotPool,
+                            createSlotOffersForResourceRequirements(
+                                    ResourceCounter.withResource(
+                                            ResourceProfile.UNKNOWN, parallelism)),
+                            taskManagerGateway);
+                });
+
+        // wait for the job to be re-submitted
+        taskManagerGateway.waitForSubmissions(parallelism, Duration.ofSeconds(5));
+
+        ArchivedExecutionGraph resubmittedExecutionGraph =
+                getArchivedExecutionGraphForRunningJob(scheduler).get();
+        ArchivedExecutionJobVertex resubmittedArchivedVertex =
+                resubmittedExecutionGraph.getJobVertex(vertex.getID());
+
+        // ensure that the parallelism was submitted based on what is available
+        assertThat(resubmittedArchivedVertex.getParallelism(), is(parallelism));
+        // and that the max parallelism was submitted based on what was configured
+        assertThat(resubmittedArchivedVertex.getMaxParallelism(), is(expectedMaxParallelism));
+    }
+
     // ---------------------------------------------------------------------------------------------
     // Failure handling tests
     // ---------------------------------------------------------------------------------------------
@@ -833,11 +894,13 @@ public class AdaptiveSchedulerTest extends TestLogger {
     public void testComputeVertexParallelismStoreForExecutionInReactiveMode() {
         JobVertex v1 = createNoOpVertex("v1", 1, 50);
         JobVertex v2 = createNoOpVertex("v2", 50, 50);
-        JobGraph graph = JobGraphTestUtils.streamingJobGraph(v1, v2);
+        JobGraph graph = streamingJobGraph(v1, v2);
 
         VertexParallelismStore parallelismStore =
                 AdaptiveScheduler.computeVertexParallelismStoreForExecution(
-                        graph, SchedulerExecutionMode.REACTIVE);
+                        graph,
+                        SchedulerExecutionMode.REACTIVE,
+                        SchedulerBase::getDefaultMaxParallelism);
 
         for (JobVertex vertex : graph.getVertices()) {
             VertexParallelismInformation info = parallelismStore.getParallelismInfo(vertex.getID());
@@ -851,10 +914,11 @@ public class AdaptiveSchedulerTest extends TestLogger {
     public void testComputeVertexParallelismStoreForExecutionInDefaultMode() {
         JobVertex v1 = createNoOpVertex("v1", 1, 50);
         JobVertex v2 = createNoOpVertex("v2", 50, 50);
-        JobGraph graph = JobGraphTestUtils.streamingJobGraph(v1, v2);
+        JobGraph graph = streamingJobGraph(v1, v2);
 
         VertexParallelismStore parallelismStore =
-                AdaptiveScheduler.computeVertexParallelismStoreForExecution(graph, null);
+                AdaptiveScheduler.computeVertexParallelismStoreForExecution(
+                        graph, null, SchedulerBase::getDefaultMaxParallelism);
 
         for (JobVertex vertex : graph.getVertices()) {
             VertexParallelismInformation info = parallelismStore.getParallelismInfo(vertex.getID());
@@ -868,6 +932,28 @@ public class AdaptiveSchedulerTest extends TestLogger {
     // Utils
     // ---------------------------------------------------------------------------------------------
 
+    private CompletableFuture<ArchivedExecutionGraph> getArchivedExecutionGraphForRunningJob(
+            SchedulerNG scheduler) {
+        return CompletableFuture.supplyAsync(
+                () -> {
+                    ArchivedExecutionGraph graph = null;
+                    while (graph == null || graph.getState() != JobStatus.RUNNING) {
+                        graph = scheduler.requestJob().getArchivedExecutionGraph();
+                    }
+                    return graph;
+                },
+                singleThreadMainThreadExecutor);
+    }
+
+    private Consumer<ExecutionAttemptID> createCancelConsumer(SchedulerNG scheduler) {
+        return executionAttemptId ->
+                singleThreadMainThreadExecutor.execute(
+                        () ->
+                                scheduler.updateTaskExecutionState(
+                                        new TaskExecutionState(
+                                                executionAttemptId, ExecutionState.CANCELED)));
+    }
+
     @Nonnull
     private static DefaultDeclarativeSlotPool createDeclarativeSlotPool(JobID jobId) {
         return new DefaultDeclarativeSlotPool(
@@ -879,7 +965,7 @@ public class AdaptiveSchedulerTest extends TestLogger {
     }
 
     private static JobGraph createJobGraph() {
-        return JobGraphTestUtils.streamingJobGraph(JOB_VERTEX);
+        return streamingJobGraph(JOB_VERTEX);
     }
 
     private static class LifecycleMethodCapturingState extends DummyState {
