diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/common/TieredStorageConfiguration.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/common/TieredStorageConfiguration.java
index abc6c955d53..1979c115851 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/common/TieredStorageConfiguration.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/common/TieredStorageConfiguration.java
@@ -89,8 +89,6 @@ public class TieredStorageConfiguration {
 
     private final float numBuffersTriggerFlushRatio;
 
-    private final int diskIOSchedulerMaxBuffersReadAhead;
-
     private final Duration diskIOSchedulerRequestTimeout;
 
     private final float minReserveDiskSpaceFraction;
@@ -110,7 +108,6 @@ public class TieredStorageConfiguration {
             int diskTierNumBytesPerSegment,
             int remoteTierNumBytesPerSegment,
             float numBuffersTriggerFlushRatio,
-            int diskIOSchedulerMaxBuffersReadAhead,
             Duration diskIOSchedulerRequestTimeout,
             float minReserveDiskSpaceFraction,
             List<TierFactory> tierFactories,
@@ -125,7 +122,6 @@ public class TieredStorageConfiguration {
         this.diskTierNumBytesPerSegment = diskTierNumBytesPerSegment;
         this.remoteTierNumBytesPerSegment = remoteTierNumBytesPerSegment;
         this.numBuffersTriggerFlushRatio = numBuffersTriggerFlushRatio;
-        this.diskIOSchedulerMaxBuffersReadAhead = diskIOSchedulerMaxBuffersReadAhead;
         this.diskIOSchedulerRequestTimeout = diskIOSchedulerRequestTimeout;
         this.minReserveDiskSpaceFraction = minReserveDiskSpaceFraction;
         this.tierFactories = tierFactories;
@@ -241,16 +237,6 @@ public class TieredStorageConfiguration {
         return numBuffersTriggerFlushRatio;
     }
 
-    /**
-     * The number of buffers to read ahead at most for each subpartition in {@link DiskIOScheduler},
-     * which can be used to prevent other consumers from starving.
-     *
-     * @return buffer number.
-     */
-    public int getDiskIOSchedulerMaxBuffersReadAhead() {
-        return diskIOSchedulerMaxBuffersReadAhead;
-    }
-
     /**
      * Maximum time to wait when requesting read buffers from the buffer pool before throwing an
      * exception in {@link DiskIOScheduler}.
@@ -322,8 +308,6 @@ public class TieredStorageConfiguration {
 
         private float numBuffersTriggerFlushRatio = DEFAULT_NUM_BUFFERS_TRIGGER_FLUSH_RATIO;
 
-        private int diskTierMaxBuffersReadAhead = DEFAULT_DISK_TIER_MAX_BUFFERS_READ_AHEAD;
-
         private Duration diskTierBufferRequestTimeout = DEFAULT_DISK_TIER_BUFFER_REQUEST_TIMEOUT;
 
         private float minReserveDiskSpaceFraction = DEFAULT_MIN_RESERVE_DISK_SPACE_FRACTION;
@@ -395,11 +379,6 @@ public class TieredStorageConfiguration {
             return this;
         }
 
-        public Builder setDiskTierMaxBuffersReadAhead(int diskTierMaxBuffersReadAhead) {
-            this.diskTierMaxBuffersReadAhead = diskTierMaxBuffersReadAhead;
-            return this;
-        }
-
         public Builder setDiskTierBufferRequestTimeout(Duration diskTierBufferRequestTimeout) {
             this.diskTierBufferRequestTimeout = diskTierBufferRequestTimeout;
             return this;
@@ -438,7 +417,6 @@ public class TieredStorageConfiguration {
                     diskTierNumBytesPerSegment,
                     remoteTierNumBytesPerSegment,
                     numBuffersTriggerFlushRatio,
-                    diskTierMaxBuffersReadAhead,
                     diskTierBufferRequestTimeout,
                     minReserveDiskSpaceFraction,
                     tierFactories,
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/shuffle/TieredResultPartitionFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/shuffle/TieredResultPartitionFactory.java
index eb54970441b..538fda6a0f0 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/shuffle/TieredResultPartitionFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/shuffle/TieredResultPartitionFactory.java
@@ -206,8 +206,7 @@ public class TieredResultPartitionFactory {
                             Math.max(
                                     2 * batchShuffleReadBufferPool.getNumBuffersPerRequest(),
                                     numberOfSubpartitions),
-                            tieredStorageConfiguration.getDiskIOSchedulerBufferRequestTimeout(),
-                            tieredStorageConfiguration.getDiskIOSchedulerMaxBuffersReadAhead());
+                            tieredStorageConfiguration.getDiskIOSchedulerBufferRequestTimeout());
             tierProducerAgents.add(producerAgent);
             tieredStorageMemorySpecs.add(
                     new TieredStorageMemorySpec(producerAgent, tierExclusiveBuffers.get(index)));
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/TierFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/TierFactory.java
index fabdd57992c..c404720d86e 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/TierFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/TierFactory.java
@@ -47,8 +47,7 @@ public interface TierFactory {
             BatchShuffleReadBufferPool bufferPool,
             ScheduledExecutorService ioExecutor,
             int maxRequestedBuffers,
-            Duration bufferRequestTimeout,
-            int maxBufferReadAhead);
+            Duration bufferRequestTimeout);
 
     /** Creates the consumer-side agent of a Tier. */
     TierConsumerAgent createConsumerAgent(
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java
index bceb5e55c0b..5594f7bcb57 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java
@@ -48,6 +48,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Queue;
+import java.util.concurrent.RejectedExecutionException;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
@@ -80,12 +81,6 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
      */
     private final BatchShuffleReadBufferPool bufferPool;
 
-    /**
-     * The maximum number of buffers that can be allocated and still not recycled for a
-     * subpartition, which ensures that each subpartition can be consumed evenly.
-     */
-    private final int maxBufferReadAhead;
-
     /**
      * The maximum number of buffers that can be allocated and still not recycled by a single {@link
      * DiskIOScheduler} for all subpartitions. This ensures that different {@link DiskIOScheduler}s
@@ -126,7 +121,6 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
             ScheduledExecutorService ioExecutor,
             int maxRequestedBuffers,
             Duration bufferRequestTimeout,
-            int maxBufferReadAhead,
             BiFunction<Integer, Integer, Integer> firstBufferIndexInSegmentRetriever,
             PartitionFileReader partitionFileReader) {
         this.partitionId = partitionId;
@@ -134,7 +128,6 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
         this.ioExecutor = checkNotNull(ioExecutor);
         this.maxRequestedBuffers = maxRequestedBuffers;
         this.bufferRequestTimeout = checkNotNull(bufferRequestTimeout);
-        this.maxBufferReadAhead = maxBufferReadAhead;
         this.firstBufferIndexInSegmentRetriever = firstBufferIndexInSegmentRetriever;
         this.partitionFileReader = partitionFileReader;
         bufferPool.registerRequester(this);
@@ -148,7 +141,11 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
             isRunning = false;
         }
         if (numBuffersRead == 0) {
-            ioExecutor.schedule(this::triggerScheduling, 5, TimeUnit.MILLISECONDS);
+            try {
+                ioExecutor.schedule(this::triggerScheduling, 5, TimeUnit.MILLISECONDS);
+            } catch (RejectedExecutionException e) {
+                ignoreRejectedExecutionOnShutdown(e);
+            }
         } else {
             triggerScheduling();
         }
@@ -302,18 +299,22 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
                             <= maxRequestedBuffers
                     && numRequestedBuffers < bufferPool.getAverageBuffersPerRequester()) {
                 isRunning = true;
-                ioExecutor.execute(
-                        () -> {
-                            try {
-                                run();
-                            } catch (Throwable throwable) {
-                                LOG.error("Failed to read data.", throwable);
-                                // handle un-expected exception as unhandledExceptionHandler is not
-                                // worked for ScheduledExecutorService.
-                                FatalExitExceptionHandler.INSTANCE.uncaughtException(
-                                        Thread.currentThread(), throwable);
-                            }
-                        });
+                try {
+                    ioExecutor.execute(
+                            () -> {
+                                try {
+                                    run();
+                                } catch (Throwable throwable) {
+                                    LOG.error("Failed to read data.", throwable);
+                                    // handle un-expected exception as unhandledExceptionHandler is
+                                    // not worked for ScheduledExecutorService.
+                                    FatalExitExceptionHandler.INSTANCE.uncaughtException(
+                                            Thread.currentThread(), throwable);
+                                }
+                            });
+                } catch (RejectedExecutionException e) {
+                    ignoreRejectedExecutionOnShutdown(e);
+                }
             }
         }
     }
@@ -322,6 +323,12 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
         return bufferPool.getLastBufferOperationTimestamp() + bufferRequestTimeout.toMillis();
     }
 
+    private void ignoreRejectedExecutionOnShutdown(RejectedExecutionException e) {
+        LOG.warn(
+                "Attempt to submit a task to the shut down batch read thread pool should be ignored. No more tasks should be accepted.",
+                e);
+    }
+
     /**
      * The {@link ScheduledSubpartitionReader} is responsible for reading a subpartition from disk,
      * and is scheduled by the {@link DiskIOScheduler}.
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierFactory.java
index 4806e2346e4..db1cdb46b12 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierFactory.java
@@ -90,8 +90,7 @@ public class DiskTierFactory implements TierFactory {
             BatchShuffleReadBufferPool bufferPool,
             ScheduledExecutorService ioExecutor,
             int maxRequestedBuffers,
-            Duration bufferRequestTimeout,
-            int maxBufferReadAhead) {
+            Duration bufferRequestTimeout) {
         ProducerMergedPartitionFileIndex partitionFileIndex =
                 new ProducerMergedPartitionFileIndex(
                         isBroadcastOnly ? 1 : numSubpartitions,
@@ -122,8 +121,7 @@ public class DiskTierFactory implements TierFactory {
                 bufferPool,
                 ioExecutor,
                 maxRequestedBuffers,
-                bufferRequestTimeout,
-                maxBufferReadAhead);
+                bufferRequestTimeout);
     }
 
     @Override
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgent.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgent.java
index acd8c3a392d..041374dd7d3 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgent.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgent.java
@@ -98,8 +98,7 @@ public class DiskTierProducerAgent implements TierProducerAgent, NettyServicePro
             BatchShuffleReadBufferPool bufferPool,
             ScheduledExecutorService ioExecutor,
             int maxRequestedBuffers,
-            Duration bufferRequestTimeout,
-            int maxBufferReadAhead) {
+            Duration bufferRequestTimeout) {
         checkArgument(
                 numBytesPerSegment >= bufferSizeBytes,
                 "One segment should contain at least one buffer.");
@@ -134,7 +133,6 @@ public class DiskTierProducerAgent implements TierProducerAgent, NettyServicePro
                         ioExecutor,
                         maxRequestedBuffers,
                         bufferRequestTimeout,
-                        maxBufferReadAhead,
                         this::retrieveFirstBufferIndexInSegment,
                         partitionFileReader);
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/memory/MemoryTierFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/memory/MemoryTierFactory.java
index 8bb3cf3834b..c23a9806179 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/memory/MemoryTierFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/memory/MemoryTierFactory.java
@@ -68,8 +68,7 @@ public class MemoryTierFactory implements TierFactory {
             BatchShuffleReadBufferPool bufferPool,
             ScheduledExecutorService ioExecutor,
             int maxRequestedBuffers,
-            Duration bufferRequestTimeout,
-            int maxBufferReadAhead) {
+            Duration bufferRequestTimeout) {
         return new MemoryTierProducerAgent(
                 partitionID,
                 numSubpartitions,
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierFactory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierFactory.java
index ada6dd1d560..0596c200068 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierFactory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierFactory.java
@@ -71,8 +71,7 @@ public class RemoteTierFactory implements TierFactory {
             BatchShuffleReadBufferPool bufferPool,
             ScheduledExecutorService ioExecutor,
             int maxRequestedBuffers,
-            Duration bufferRequestTimeout,
-            int maxBufferReadAhead) {
+            Duration bufferRequestTimeout) {
         PartitionFileWriter partitionFileWriter =
                 SegmentPartitionFile.createPartitionFileWriter(remoteStoragePath, numSubpartitions);
         return new RemoteTierProducerAgent(
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/DiskIOSchedulerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/DiskIOSchedulerTest.java
index 8d453d00f2e..de7e18b28df 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/DiskIOSchedulerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/DiskIOSchedulerTest.java
@@ -33,6 +33,7 @@ import org.apache.flink.runtime.io.network.partition.hybrid.tiered.netty.Testing
 import org.apache.flink.runtime.io.network.partition.hybrid.tiered.tier.disk.DiskIOScheduler;
 import org.apache.flink.util.ExceptionUtils;
 
+import org.jetbrains.annotations.NotNull;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -45,8 +46,13 @@ import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
+import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
 
+import static org.apache.flink.runtime.io.disk.BatchShuffleReadBufferPool.NUM_BYTES_PER_REQUEST;
 import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.assertThatNoException;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
 
 /** Tests for {@link DiskIOScheduler}. */
@@ -58,11 +64,13 @@ class DiskIOSchedulerTest {
     private static final TieredStorageSubpartitionId DEFAULT_SUBPARTITION_ID =
             new TieredStorageSubpartitionId(0);
 
-    private static final int BUFFER_POOL_SIZE = 1;
+    private static final int TOTAL_BYTES = 2 * NUM_BYTES_PER_REQUEST;
 
-    private static final Duration DEFAULT_BUFFER_REQUEST_TIMEOUT = Duration.ofMinutes(5);
+    private static final int BUFFER_SIZE = NUM_BYTES_PER_REQUEST / 4;
+
+    private static final int MAX_REQUEST_BUFFER = Integer.MAX_VALUE;
 
-    private static final int DEFAULT_MAX_READ_AHEAD = 5;
+    private static final Duration DEFAULT_BUFFER_REQUEST_TIMEOUT = Duration.ofMinutes(5);
 
     private BatchShuffleReadBufferPool bufferPool;
 
@@ -78,8 +86,8 @@ class DiskIOSchedulerTest {
 
     @BeforeEach
     void before() {
-        this.ioExecutor = new ManuallyTriggeredScheduledExecutorService();
-        this.bufferPool = new BatchShuffleReadBufferPool(BUFFER_POOL_SIZE, BUFFER_POOL_SIZE);
+        this.ioExecutor = new TestingScheduledExecutorService();
+        this.bufferPool = new BatchShuffleReadBufferPool(TOTAL_BYTES, BUFFER_SIZE);
         this.bufferPool.initialize();
         this.segmentIdFuture = new CompletableFuture<>();
         this.readerReleaseFuture = new CompletableFuture<>();
@@ -89,14 +97,17 @@ class DiskIOSchedulerTest {
                         DEFAULT_PARTITION_ID,
                         bufferPool,
                         ioExecutor,
-                        BUFFER_POOL_SIZE,
+                        MAX_REQUEST_BUFFER,
                         DEFAULT_BUFFER_REQUEST_TIMEOUT,
-                        DEFAULT_MAX_READ_AHEAD,
                         (subpartitionId, bufferIndex) ->
                                 firstBufferIndexInSegment.get(subpartitionId).get(bufferIndex),
                         new TestingPartitionFileReader.Builder()
                                 .setReadBufferSupplier(
                                         (bufferIndex, segmentId) -> {
+                                            if (segmentIdFuture.isDone()) {
+                                                return new PartitionFileReader.ReadBufferResult(
+                                                        Collections.emptyList(), true, null);
+                                            }
                                             segmentIdFuture.complete(segmentId);
                                             return new PartitionFileReader.ReadBufferResult(
                                                     Collections.singletonList(
@@ -257,6 +268,25 @@ class DiskIOSchedulerTest {
         assertThat(waitFuture2).isDone();
     }
 
+    /**
+     * The executor service for batch shuffle read shouldn't throw {@link
+     * RejectedExecutionException} if the worker thread is attempting to add new jobs when the
+     * service is already shutdown. This behavior is important to ensure graceful handling of
+     * scenarios where worker threads couldn't be immediately aware of the TaskManager's shutdown
+     * status.
+     */
+    @Test
+    void testRejectedExecutionIsIgnoredOnShutdown() {
+        TestingNettyConnectionWriter nettyConnectionWriter =
+                new TestingNettyConnectionWriter.Builder().build();
+        diskIOScheduler.connectionEstablished(DEFAULT_SUBPARTITION_ID, nettyConnectionWriter);
+        assertThat(ioExecutor.numQueuedRunnables()).isEqualTo(1);
+        assertThatNoException().isThrownBy(() -> ioExecutor.trigger());
+        assertThat(ioExecutor.numQueuedRunnables()).isEqualTo(1);
+        ioExecutor.shutdown();
+        assertThatNoException().isThrownBy(() -> ioExecutor.trigger());
+    }
+
     private List<Map<Integer, Integer>> createFirstBufferIndexInSegment() {
         Map<Integer, Integer> firstBufferIndexInSegment0 = new HashMap<>();
         Map<Integer, Integer> firstBufferIndexInSegment1 = new HashMap<>();
@@ -267,4 +297,20 @@ class DiskIOSchedulerTest {
         list.add(firstBufferIndexInSegment1);
         return list;
     }
+
+    /**
+     * This manually triggered executor service will throw {@link RejectedExecutionException} if the
+     * new job is added when the service shuts down.
+     */
+    private static class TestingScheduledExecutorService
+            extends ManuallyTriggeredScheduledExecutorService {
+        @Override
+        @NotNull
+        public ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit) {
+            if (super.isTerminated()) {
+                throw new RejectedExecutionException();
+            }
+            return super.schedule(command, delay, unit);
+        }
+    }
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/storage/TestingTierFactory.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/storage/TestingTierFactory.java
index 16ec4c8b24c..92eb64c5d35 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/storage/TestingTierFactory.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/storage/TestingTierFactory.java
@@ -74,8 +74,7 @@ public class TestingTierFactory implements TierFactory {
             BatchShuffleReadBufferPool bufferPool,
             ScheduledExecutorService ioExecutor,
             int maxRequestedBuffers,
-            Duration bufferRequestTimeout,
-            int maxBufferReadAhead) {
+            Duration bufferRequestTimeout) {
         return tierProducerAgentSupplier.get();
     }
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgentTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgentTest.java
index 58c09ff9df1..ad46b370013 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgentTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskTierProducerAgentTest.java
@@ -224,7 +224,6 @@ public class DiskTierProducerAgentTest {
                 new BatchShuffleReadBufferPool(1, 1),
                 new ManuallyTriggeredScheduledExecutorService(),
                 0,
-                Duration.ofMinutes(5),
-                0);
+                Duration.ofMinutes(5));
     }
 }
