diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/FunctionCodeGenerator.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/FunctionCodeGenerator.scala
index 91fd2ff4c51..fc4d77e9061 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/FunctionCodeGenerator.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/FunctionCodeGenerator.scala
@@ -179,11 +179,10 @@ object FunctionCodeGenerator {
       input2Term: String = CodeGenUtils.DEFAULT_INPUT2_TERM): GeneratedJoinCondition = {
     val funcName = newName(name)
 
-    val baseClass = classOf[JoinCondition]
-
     val funcCode =
       j"""
-      public class $funcName implements ${baseClass.getCanonicalName} {
+      public class $funcName extends ${className[AbstractRichFunction]}
+          implements ${className[JoinCondition]} {
 
         ${ctx.reuseMemberCode()}
 
@@ -193,6 +192,11 @@ object FunctionCodeGenerator {
 
         ${ctx.reuseConstructorCode(funcName)}
 
+        @Override
+        public void open(${className[Configuration]} parameters) throws Exception {
+          ${ctx.reuseOpenCode()}
+        }
+
         @Override
         public boolean apply($BASE_ROW $input1Term, $BASE_ROW $input2Term) throws Exception {
           ${ctx.reusePerRecordCode()}
@@ -200,6 +204,12 @@ object FunctionCodeGenerator {
           ${ctx.reuseInputUnboxingCode()}
           $bodyCode
         }
+
+        @Override
+        public void close() throws Exception {
+          super.close();
+          ${ctx.reuseCloseCode()}
+        }
       }
      """.stripMargin
 
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/LongHashJoinGenerator.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/LongHashJoinGenerator.scala
index 98286e45fbf..a682070e161 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/LongHashJoinGenerator.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/codegen/LongHashJoinGenerator.scala
@@ -18,9 +18,10 @@
 
 package org.apache.flink.table.codegen
 
+import org.apache.flink.configuration.Configuration
 import org.apache.flink.metrics.Gauge
 import org.apache.flink.table.api.TableConfig
-import org.apache.flink.table.codegen.CodeGenUtils.{BASE_ROW, BINARY_ROW, baseRowFieldReadAccess, newName}
+import org.apache.flink.table.codegen.CodeGenUtils.{BASE_ROW, BINARY_ROW, baseRowFieldReadAccess, className, newName}
 import org.apache.flink.table.codegen.OperatorCodeGenerator.generateCollect
 import org.apache.flink.table.dataformat.{BaseRow, JoinedRow}
 import org.apache.flink.table.generated.{GeneratedJoinCondition, GeneratedProjection}
@@ -136,6 +137,9 @@ object LongHashJoinGenerator {
     ctx.addReusableMember(s"${condFunc.getClassName} condFunc;")
     val condRefs = ctx.addReusableObject(condFunc.getReferences, "condRefs")
     ctx.addReusableInitStatement(s"condFunc = new ${condFunc.getClassName}($condRefs);")
+    ctx.addReusableOpenStatement(s"condFunc.setRuntimeContext(getRuntimeContext());")
+    ctx.addReusableOpenStatement(s"condFunc.open(new ${className[Configuration]}());")
+    ctx.addReusableCloseStatement(s"condFunc.close();")
 
     val gauge = classOf[Gauge[_]].getCanonicalName
     ctx.addReusableOpenStatement(
diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/codegen/LongHashJoinGeneratorTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/codegen/LongHashJoinGeneratorTest.java
index 718ec488495..550e41dcda9 100644
--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/codegen/LongHashJoinGeneratorTest.java
+++ b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/codegen/LongHashJoinGeneratorTest.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.table.codegen;
 
+import org.apache.flink.api.common.functions.AbstractRichFunction;
 import org.apache.flink.table.api.TableConfig;
 import org.apache.flink.table.dataformat.BaseRow;
 import org.apache.flink.table.generated.GeneratedJoinCondition;
@@ -79,7 +80,7 @@ public class LongHashJoinGeneratorTest extends Int2HashJoinOperatorTest {
 	/**
 	 * Test cond.
 	 */
-	public static class MyJoinCondition implements JoinCondition {
+	public static class MyJoinCondition extends AbstractRichFunction implements JoinCondition {
 
 		public MyJoinCondition(Object[] reference) {}
 
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala
index 51e7b39b55f..04db0bfb359 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/expressions/utils/userDefinedScalarFunctions.scala
@@ -313,6 +313,22 @@ object Func20 extends ScalarFunction {
   }
 }
 
+class FuncWithOpen extends ScalarFunction {
+  private var permitted: Boolean = false
+
+  override def open(context: FunctionContext): Unit = {
+    permitted = true
+  }
+
+  def eval(x: Int): Boolean = {
+    permitted
+  }
+
+  override def close(): Unit = {
+    permitted = false
+  }
+}
+
 class SplitUDF(deterministic: Boolean) extends ScalarFunction {
   def eval(x: String, sep: String, index: Int): String = {
     val splits = StringUtils.splitByWholeSeparator(x, sep)
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/batch/sql/join/JoinITCase.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/batch/sql/join/JoinITCase.scala
index 61d55cba693..16e7e5e1002 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/batch/sql/join/JoinITCase.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/batch/sql/join/JoinITCase.scala
@@ -23,6 +23,7 @@ import org.apache.flink.api.common.typeinfo.BasicTypeInfo.{INT_TYPE_INFO, LONG_T
 import org.apache.flink.api.common.typeutils.TypeComparator
 import org.apache.flink.api.java.typeutils.{GenericTypeInfo, RowTypeInfo}
 import org.apache.flink.table.api.{TableConfigOptions, Types}
+import org.apache.flink.table.expressions.utils.FuncWithOpen
 import org.apache.flink.table.runtime.CodeGenOperatorFactory
 import org.apache.flink.table.runtime.batch.sql.join.JoinType.{BroadcastHashJoin, HashJoin, JoinType, NestedLoopJoin, SortMergeJoin}
 import org.apache.flink.table.runtime.utils.BatchTestBase
@@ -785,6 +786,18 @@ class JoinITCase() extends BatchTestBase {
       )
     )
   }
+
+  @Test
+  def testJoinWithUDFFilter(): Unit = {
+    tEnv.registerFunction("funcWithOpen", new FuncWithOpen)
+    checkResult(
+      "SELECT c, g FROM SmallTable3 join Table5 on funcWithOpen(a + d) where b = e",
+      Seq(
+        row("Hi", "Hallo"),
+        row("Hello", "Hallo Welt"),
+        row("Hello world", "Hallo Welt"))
+    )
+  }
 }
 
 class GenericTypeInfoWithoutComparator[T](clazz: Class[T]) extends GenericTypeInfo[T](clazz) {
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/stream/sql/JoinITCase.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/stream/sql/JoinITCase.scala
index c9fcfcb95bf..9c9180f85a1 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/stream/sql/JoinITCase.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/runtime/stream/sql/JoinITCase.scala
@@ -21,9 +21,11 @@ package org.apache.flink.table.runtime.stream.sql
 import org.apache.flink.api.scala._
 import org.apache.flink.streaming.api.TimeCharacteristic
 import org.apache.flink.table.api.scala._
+import org.apache.flink.table.expressions.utils.FuncWithOpen
 import org.apache.flink.table.runtime.utils.StreamingWithStateTestBase.StateBackendMode
 import org.apache.flink.table.runtime.utils._
 import org.apache.flink.types.Row
+
 import org.junit.Assert._
 import org.junit.Test
 import org.junit.runner.RunWith
@@ -1106,4 +1108,23 @@ class JoinITCase(state: StateBackendMode) extends StreamingWithStateTestBase(sta
     val expected = List("500")
     assertEquals(expected.sorted, sink.getRetractResults.sorted)
   }
+
+  @Test
+  def testJoinWithUDFFilter(): Unit = {
+    val ds1 = failingDataSource(TestData.smallTupleData3).toTable(tEnv, 'a, 'b, 'c)
+    val ds2 = failingDataSource(TestData.tupleData5).toTable(tEnv, 'd, 'e, 'f, 'g, 'h)
+
+    tEnv.registerTable("T3", ds1)
+    tEnv.registerTable("T5", ds2)
+    tEnv.registerFunction("funcWithOpen", new FuncWithOpen)
+
+    val sql = "SELECT c, g FROM T3 join T5 on funcWithOpen(a + d) where b = e"
+
+    val sink = new TestingRetractSink
+    tEnv.sqlQuery(sql).toRetractStream[Row].addSink(sink).setParallelism(1)
+    env.execute()
+
+    val expected = Seq("Hi,Hallo", "Hello,Hallo Welt", "Hello world,Hallo Welt")
+    assertEquals(expected.sorted, sink.getRetractResults.sorted)
+  }
 }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/generated/JoinCondition.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/generated/JoinCondition.java
index b047b0f8cbb..212ed5d9885 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/generated/JoinCondition.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/generated/JoinCondition.java
@@ -18,12 +18,13 @@
 
 package org.apache.flink.table.generated;
 
+import org.apache.flink.api.common.functions.RichFunction;
 import org.apache.flink.table.dataformat.BaseRow;
 
 /**
  * Interface for code generated condition function for [[org.apache.calcite.rel.core.Join]].
  */
-public interface JoinCondition {
+public interface JoinCondition extends RichFunction {
 
 	/**
 	 * @return true if the join condition stays true for the joined row (in1, in2)
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/HashJoinOperator.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/HashJoinOperator.java
index 18b6d3bf4ab..b4b21b1e6f4 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/HashJoinOperator.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/HashJoinOperator.java
@@ -19,6 +19,7 @@
 package org.apache.flink.table.runtime.join;
 
 import org.apache.flink.configuration.AlgorithmOptions;
+import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.operators.TwoInputStreamOperator;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.table.dataformat.BaseRow;
@@ -27,6 +28,7 @@ import org.apache.flink.table.dataformat.GenericRow;
 import org.apache.flink.table.dataformat.JoinedRow;
 import org.apache.flink.table.generated.GeneratedJoinCondition;
 import org.apache.flink.table.generated.GeneratedProjection;
+import org.apache.flink.table.generated.JoinCondition;
 import org.apache.flink.table.runtime.TableStreamOperator;
 import org.apache.flink.table.runtime.hashtable.BinaryHashTable;
 import org.apache.flink.table.runtime.util.RowIterator;
@@ -66,6 +68,7 @@ public abstract class HashJoinOperator extends TableStreamOperator<BaseRow>
 	private transient BaseRow probeSideNullRow;
 	private transient JoinedRow joinedRow;
 	private transient boolean buildEnd;
+	private transient JoinCondition condition;
 
 	HashJoinOperator(HashJoinParameter parameter) {
 		this.parameter = parameter;
@@ -89,6 +92,10 @@ public abstract class HashJoinOperator extends TableStreamOperator<BaseRow>
 
 		int parallel = getRuntimeContext().getNumberOfParallelSubtasks();
 
+		this.condition = parameter.condFuncCode.newInstance(cl);
+		condition.setRuntimeContext(getRuntimeContext());
+		condition.open(new Configuration());
+
 		this.table = new BinaryHashTable(
 				getContainingTask().getJobConfiguration(),
 				getContainingTask(),
@@ -104,7 +111,7 @@ public abstract class HashJoinOperator extends TableStreamOperator<BaseRow>
 				parameter.buildRowCount / parallel,
 				hashJoinUseBitMaps,
 				type,
-				parameter.condFuncCode.newInstance(cl),
+				condition,
 				reverseJoinFunction,
 				parameter.filterNullKeys,
 				parameter.tryDistinctBuildRow);
@@ -192,6 +199,7 @@ public abstract class HashJoinOperator extends TableStreamOperator<BaseRow>
 			this.table.free();
 			this.table = null;
 		}
+		condition.close();
 	}
 
 	public static HashJoinOperator newHashJoinOperator(
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/SortMergeJoinOperator.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/SortMergeJoinOperator.java
index 16415d26059..503b19353b5 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/SortMergeJoinOperator.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/SortMergeJoinOperator.java
@@ -172,6 +172,8 @@ public class SortMergeJoinOperator extends TableStreamOperator<BaseRow>
 
 		keyComparator = genKeyComparator.newInstance(cl);
 		this.condFunc = condFuncCode.newInstance(cl);
+		condFunc.setRuntimeContext(getRuntimeContext());
+		condFunc.open(new Configuration());
 
 		projection1 = projectionCode1.newInstance(cl);
 		projection2 = projectionCode2.newInstance(cl);
@@ -456,6 +458,7 @@ public class SortMergeJoinOperator extends TableStreamOperator<BaseRow>
 		if (this.sorter2 != null) {
 			this.sorter2.close();
 		}
+		condFunc.close();
 	}
 
 }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/stream/AbstractStreamingJoinOperator.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/stream/AbstractStreamingJoinOperator.java
index 75ef1d7c0b4..b9c46426535 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/stream/AbstractStreamingJoinOperator.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/join/stream/AbstractStreamingJoinOperator.java
@@ -18,7 +18,9 @@
 
 package org.apache.flink.table.runtime.join.stream;
 
+import org.apache.flink.api.common.functions.AbstractRichFunction;
 import org.apache.flink.api.java.tuple.Tuple2;
+import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
 import org.apache.flink.streaming.api.operators.TimestampedCollector;
 import org.apache.flink.streaming.api.operators.TwoInputStreamOperator;
@@ -76,7 +78,7 @@ public abstract class AbstractStreamingJoinOperator extends AbstractStreamOperat
 	protected final long minRetentionTime;
 	protected final boolean stateCleaningEnabled;
 
-	protected transient JoinCondition joinCondition;
+	protected transient JoinConditionWithNullFilters joinCondition;
 	protected transient TimestampedCollector<BaseRow> collector;
 
 	public AbstractStreamingJoinOperator(
@@ -103,17 +105,26 @@ public abstract class AbstractStreamingJoinOperator extends AbstractStreamOperat
 	public void open() throws Exception {
 		super.open();
 
-		this.joinCondition = new JoinConditionWithNullFilters(
-			generatedJoinCondition.newInstance(getRuntimeContext().getUserCodeClassLoader()));
+		JoinCondition condition = generatedJoinCondition.newInstance(getRuntimeContext().getUserCodeClassLoader());
+		condition.setRuntimeContext(getRuntimeContext());
+		condition.open(new Configuration());
+
+		this.joinCondition = new JoinConditionWithNullFilters(condition);
 
 		this.collector = new TimestampedCollector<>(output);
 	}
 
+	@Override
+	public void close() throws Exception {
+		super.close();
+		joinCondition.backingJoinCondition.close();
+	}
+
 	// ----------------------------------------------------------------------------------------
 	// Utility Classes
 	// ----------------------------------------------------------------------------------------
 
-	private class JoinConditionWithNullFilters implements JoinCondition {
+	private class JoinConditionWithNullFilters extends AbstractRichFunction implements JoinCondition {
 
 		final JoinCondition backingJoinCondition;
 
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2HashJoinOperatorTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2HashJoinOperatorTest.java
index a4adf7627bb..d1b671b39a2 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2HashJoinOperatorTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2HashJoinOperatorTest.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.table.runtime.join;
 
+import org.apache.flink.api.common.functions.AbstractRichFunction;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.streaming.api.operators.StreamOperator;
@@ -409,7 +410,7 @@ public class Int2HashJoinOperatorTest implements Serializable {
 				new GeneratedJoinCondition("", "", new Object[0]) {
 					@Override
 					public JoinCondition newInstance(ClassLoader classLoader) {
-						return (in1, in2) -> true;
+						return new TrueCondition();
 					}
 				},
 				reverseJoinFunction, new boolean[]{true},
@@ -428,4 +429,15 @@ public class Int2HashJoinOperatorTest implements Serializable {
 				false, 20, 10000,
 				10000, RowType.of(new IntType()));
 	}
+
+	/**
+	 * Test util.
+	 */
+	public static class TrueCondition extends AbstractRichFunction implements JoinCondition {
+
+		@Override
+		public boolean apply(BaseRow in1, BaseRow in2) {
+			return true;
+		}
+	}
 }
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2SortMergeJoinOperatorTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2SortMergeJoinOperatorTest.java
index a4d33aac424..1402c116279 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2SortMergeJoinOperatorTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/Int2SortMergeJoinOperatorTest.java
@@ -190,7 +190,7 @@ public class Int2SortMergeJoinOperatorTest {
 				new GeneratedJoinCondition("", "", new Object[0]) {
 					@Override
 					public JoinCondition newInstance(ClassLoader classLoader) {
-						return (in1, in2) -> true;
+						return new Int2HashJoinOperatorTest.TrueCondition();
 					}
 				},
 				new GeneratedProjection("", "", new Object[0]) {
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2HashJoinOperatorTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2HashJoinOperatorTest.java
index 1b2f3c5560f..37ec351bf9c 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2HashJoinOperatorTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2HashJoinOperatorTest.java
@@ -313,7 +313,7 @@ public class String2HashJoinOperatorTest implements Serializable {
 				new GeneratedJoinCondition("", "", new Object[0]) {
 					@Override
 					public JoinCondition newInstance(ClassLoader classLoader) {
-						return (in1, in2) -> true;
+						return new Int2HashJoinOperatorTest.TrueCondition();
 					}
 				},
 				reverseJoinFunction, new boolean[]{true},
diff --git a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2SortMergeJoinOperatorTest.java b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2SortMergeJoinOperatorTest.java
index 36e5979ac77..4c148eaca3a 100644
--- a/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2SortMergeJoinOperatorTest.java
+++ b/flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/join/String2SortMergeJoinOperatorTest.java
@@ -170,7 +170,7 @@ public class String2SortMergeJoinOperatorTest {
 				new GeneratedJoinCondition("", "", new Object[0]) {
 					@Override
 					public JoinCondition newInstance(ClassLoader classLoader) {
-						return (in1, in2) -> true;
+						return new Int2HashJoinOperatorTest.TrueCondition();
 					}
 				},
 				new GeneratedProjection("", "", new Object[0]) {
