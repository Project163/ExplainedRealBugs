diff --git a/docs/data/sql_functions.yml b/docs/data/sql_functions.yml
index 3b40568268c..a28f36280c9 100644
--- a/docs/data/sql_functions.yml
+++ b/docs/data/sql_functions.yml
@@ -515,8 +515,22 @@ conditional:
     description: Returns resultX when the first conditionX is met. When no condition is met, returns result_z if it is provided and returns NULL otherwise.
   - sql: NULLIF(value1, value2)
     description: Returns NULL if value1 is equal to value2; returns value1 otherwise. E.g., NULLIF(5, 5) returns NULL; NULLIF(5, 0) returns 5.
-  - sql: COALESCE(value1, value2 [, value3]*)
-    description: Returns the first value that is not NULL from value1, value2, .... E.g., COALESCE(NULL, 5) returns 5.
+  - sql: COALESCE(value1 [, value2]*)
+    table: coalesce(value1, [, value2]*)
+    description: |
+      Returns the first argument that is not NULL.
+
+      If all arguments are NULL, it returns NULL as well. The return type is the least restrictive, common type of all of its arguments.
+      The return type is nullable if all arguments are nullable as well.
+
+      ```
+      -- Returns 'default'
+      COALESCE(NULL, 'default')
+
+      -- Returns the first non-null value among f0 and f1,
+      -- or 'default' if f0 and f1 are both NULL
+      COALESCE(f0, f1, 'default')
+      ```
   - sql: IF(condition, true_value, false_value)
     description: Returns the true_value if condition is met, otherwise false_value. E.g., IF(5 > 3, 5, 3) returns 5.
   - sql: IFNULL(input, null_replacement)
diff --git a/flink-python/pyflink/table/expressions.py b/flink-python/pyflink/table/expressions.py
index 4e2d91d5a3d..56ff899ec06 100644
--- a/flink-python/pyflink/table/expressions.py
+++ b/flink-python/pyflink/table/expressions.py
@@ -550,6 +550,29 @@ def if_then_else(condition: Union[bool, Expression[bool]], if_true, if_false) ->
     return _ternary_op("ifThenElse", condition, if_true, if_false)
 
 
+def coalesce(*args) -> Expression:
+    """
+    Returns the first argument that is not NULL.
+
+    If all arguments are NULL, it returns NULL as well.
+    The return type is the least restrictive, common type of all of its arguments.
+    The return type is nullable if all arguments are nullable as well.
+
+    Examples:
+    ::
+
+        >>> coalesce(None, "default") # Returns "default"
+        >>> # Returns the first non-null value among f0 and f1,
+        >>> # or "default" if f0 and f1 are both null
+        >>> coalesce(col("f0"), col("f1"), "default")
+
+    :param args: the input expressions.
+    """
+    gateway = get_gateway()
+    args = to_jarray(gateway.jvm.Object, [_get_java_expression(arg) for arg in args])
+    return _unary_op("coalesce", args)
+
+
 def with_columns(head, *tails) -> Expression:
     """
     Creates an expression that selects a range of columns. It can be used wherever an array of
diff --git a/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/Expressions.java b/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/Expressions.java
index c21bf134829..c73046a10f8 100644
--- a/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/Expressions.java
+++ b/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/Expressions.java
@@ -536,6 +536,28 @@ public final class Expressions {
         return apiCall(BuiltInFunctionDefinitions.IF, condition, ifTrue, ifFalse);
     }
 
+    /**
+     * Returns the first argument that is not NULL.
+     *
+     * <p>If all arguments are NULL, it returns NULL as well. The return type is the least
+     * restrictive, common type of all of its arguments. The return type is nullable if all
+     * arguments are nullable as well.
+     *
+     * <p>Examples:
+     *
+     * <pre>{@code
+     * // Returns "default"
+     * coalesce(null, "default")
+     * // Returns the first non-null value among f0 and f1, or "default" if f0 and f1 are both null
+     * coalesce($("f0"), $("f1"), "default")
+     * }</pre>
+     *
+     * @param args the input expressions.
+     */
+    public static ApiExpression coalesce(Object... args) {
+        return apiCall(BuiltInFunctionDefinitions.COALESCE, args);
+    }
+
     /**
      * Creates an expression that selects a range of columns. It can be used wherever an array of
      * expression is accepted such as function calls, projections, or groupings.
diff --git a/flink-table/flink-table-api-scala/src/main/scala/org/apache/flink/table/api/ImplicitExpressionConversions.scala b/flink-table/flink-table-api-scala/src/main/scala/org/apache/flink/table/api/ImplicitExpressionConversions.scala
index d14009bb7a5..c7e73c88d55 100644
--- a/flink-table/flink-table-api-scala/src/main/scala/org/apache/flink/table/api/ImplicitExpressionConversions.scala
+++ b/flink-table/flink-table-api-scala/src/main/scala/org/apache/flink/table/api/ImplicitExpressionConversions.scala
@@ -726,6 +726,28 @@ trait ImplicitExpressionConversions {
     Expressions.ifThenElse(condition, ifTrue, ifFalse)
   }
 
+  /**
+   * Returns the first argument that is not NULL.
+   *
+   * If all arguments are NULL, it returns NULL as well. The return type is the least
+   * restrictive, common type of all of its arguments. The return type is nullable if all
+   * arguments are nullable as well.
+   *
+   * Examples:
+   * {{{
+   * // Returns "default"
+   * coalesce(null, "default")
+   *
+   * // Returns the first non-null value among f0 and f1, or "default" if f0 and f1 are both null
+   * coalesce($"f0", $"f1", "default")
+   * }}}
+   *
+   * @param args the input expressions.
+   */
+  def coalesce(args: Expression*): Expression = {
+    Expressions.coalesce(args: _*)
+  }
+
   /**
     * Creates an expression that selects a range of columns. It can be used wherever an array of
     * expression is accepted such as function calls, projections, or groupings.
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/BuiltInFunctionDefinitions.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/BuiltInFunctionDefinitions.java
index f5964c89584..a0e257fe462 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/BuiltInFunctionDefinitions.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/functions/BuiltInFunctionDefinitions.java
@@ -70,6 +70,7 @@ import static org.apache.flink.table.types.inference.TypeStrategies.explicit;
 import static org.apache.flink.table.types.inference.TypeStrategies.first;
 import static org.apache.flink.table.types.inference.TypeStrategies.forceNullable;
 import static org.apache.flink.table.types.inference.TypeStrategies.matchFamily;
+import static org.apache.flink.table.types.inference.TypeStrategies.nullableIfAllArgs;
 import static org.apache.flink.table.types.inference.TypeStrategies.nullableIfArgs;
 import static org.apache.flink.table.types.inference.TypeStrategies.varyingString;
 import static org.apache.flink.table.types.inference.strategies.SpecificInputTypeStrategies.TWO_EQUALS_COMPARABLE;
@@ -125,6 +126,16 @@ public final class BuiltInFunctionDefinitions {
                             "org.apache.flink.table.runtime.functions.scalar.SourceWatermarkFunction")
                     .build();
 
+    public static final BuiltInFunctionDefinition COALESCE =
+            BuiltInFunctionDefinition.newBuilder()
+                    .name("COALESCE")
+                    .kind(SCALAR)
+                    .inputTypeStrategy(varyingSequence(COMMON_ARG_NULLABLE, COMMON_ARG_NULLABLE))
+                    .outputTypeStrategy(nullableIfAllArgs(COMMON))
+                    .runtimeClass(
+                            "org.apache.flink.table.runtime.functions.scalar.CoalesceFunction")
+                    .build();
+
     // --------------------------------------------------------------------------------------------
     // Logic functions
     // --------------------------------------------------------------------------------------------
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java
index 9dd5781a084..421fd71b405 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java
@@ -94,7 +94,7 @@ public final class TypeStrategies {
      */
     public static TypeStrategy nullableIfArgs(
             ConstantArgumentCount includedArgs, TypeStrategy initialStrategy) {
-        return new NullableIfArgsTypeStrategy(includedArgs, initialStrategy);
+        return new NullableIfArgsTypeStrategy(includedArgs, initialStrategy, false);
     }
 
     /**
@@ -105,6 +105,23 @@ public final class TypeStrategies {
         return nullableIfArgs(ConstantArgumentCount.any(), initialStrategy);
     }
 
+    /**
+     * A type strategy that can be used to make a result type nullable if all the selected input
+     * arguments are nullable. Otherwise the type will be non-nullable.
+     */
+    public static TypeStrategy nullableIfAllArgs(
+            ConstantArgumentCount includedArgs, TypeStrategy initialStrategy) {
+        return new NullableIfArgsTypeStrategy(includedArgs, initialStrategy, true);
+    }
+
+    /**
+     * A type strategy that can be used to make a result type nullable if all the input arguments is
+     * nullable. Otherwise the type will be not null.
+     */
+    public static TypeStrategy nullableIfAllArgs(TypeStrategy initialStrategy) {
+        return nullableIfAllArgs(ConstantArgumentCount.any(), initialStrategy);
+    }
+
     /**
      * A type strategy that ensures that the result type is either {@link LogicalTypeRoot#VARCHAR}
      * or {@link LogicalTypeRoot#VARBINARY} from their corresponding non-varying roots.
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/strategies/NullableIfArgsTypeStrategy.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/strategies/NullableIfArgsTypeStrategy.java
index ffe2bf3b331..b1b0137188f 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/strategies/NullableIfArgsTypeStrategy.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/strategies/NullableIfArgsTypeStrategy.java
@@ -23,6 +23,7 @@ import org.apache.flink.table.types.DataType;
 import org.apache.flink.table.types.inference.CallContext;
 import org.apache.flink.table.types.inference.ConstantArgumentCount;
 import org.apache.flink.table.types.inference.TypeStrategy;
+import org.apache.flink.table.types.logical.LogicalType;
 import org.apache.flink.util.Preconditions;
 
 import java.util.List;
@@ -31,8 +32,8 @@ import java.util.Optional;
 import java.util.stream.IntStream;
 
 /**
- * A type strategy that can be used to make a result type nullable if any of the selected input
- * arguments is nullable. Otherwise the type will be not null.
+ * A type strategy that can be used to make a result type nullable if any or all of the selected
+ * input arguments are nullable. Otherwise the type will be not null.
  */
 @Internal
 public final class NullableIfArgsTypeStrategy implements TypeStrategy {
@@ -41,10 +42,15 @@ public final class NullableIfArgsTypeStrategy implements TypeStrategy {
 
     private final TypeStrategy initialStrategy;
 
+    private final boolean nullableIfAllArgsNullable;
+
     public NullableIfArgsTypeStrategy(
-            ConstantArgumentCount includedArguments, TypeStrategy initialStrategy) {
+            ConstantArgumentCount includedArguments,
+            TypeStrategy initialStrategy,
+            boolean nullableIfAllArgsNullable) {
         this.includedArguments = Preconditions.checkNotNull(includedArguments);
         this.initialStrategy = Preconditions.checkNotNull(initialStrategy);
+        this.nullableIfAllArgsNullable = nullableIfAllArgsNullable;
     }
 
     @Override
@@ -70,12 +76,20 @@ public final class NullableIfArgsTypeStrategy implements TypeStrategy {
                                                     .orElse(argumentDataTypes.size()),
                                             argumentDataTypes.size());
 
-                            final boolean isNullableArgument =
-                                    IntStream.range(fromArg, toArg)
-                                            .mapToObj(argumentDataTypes::get)
-                                            .anyMatch(
-                                                    dataType ->
-                                                            dataType.getLogicalType().isNullable());
+                            final boolean isNullableArgument;
+                            if (nullableIfAllArgsNullable) {
+                                isNullableArgument =
+                                        IntStream.range(fromArg, toArg)
+                                                .mapToObj(argumentDataTypes::get)
+                                                .map(DataType::getLogicalType)
+                                                .allMatch(LogicalType::isNullable);
+                            } else {
+                                isNullableArgument =
+                                        IntStream.range(fromArg, toArg)
+                                                .mapToObj(argumentDataTypes::get)
+                                                .map(DataType::getLogicalType)
+                                                .anyMatch(LogicalType::isNullable);
+                            }
 
                             if (isNullableArgument) {
                                 return inferredDataType.nullable();
@@ -95,11 +109,12 @@ public final class NullableIfArgsTypeStrategy implements TypeStrategy {
         }
         NullableIfArgsTypeStrategy that = (NullableIfArgsTypeStrategy) o;
         return includedArguments.equals(that.includedArguments)
-                && initialStrategy.equals(that.initialStrategy);
+                && initialStrategy.equals(that.initialStrategy)
+                && nullableIfAllArgsNullable == that.nullableIfAllArgsNullable;
     }
 
     @Override
     public int hashCode() {
-        return Objects.hash(includedArguments, initialStrategy);
+        return Objects.hash(includedArguments, initialStrategy, nullableIfAllArgsNullable);
     }
 }
diff --git a/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java b/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java
index 1014b10517b..448ca28f7ac 100644
--- a/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java
+++ b/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java
@@ -31,6 +31,7 @@ import java.util.Optional;
 import static org.apache.flink.table.types.inference.TypeStrategies.MISSING;
 import static org.apache.flink.table.types.inference.TypeStrategies.argument;
 import static org.apache.flink.table.types.inference.TypeStrategies.explicit;
+import static org.apache.flink.table.types.inference.TypeStrategies.nullableIfAllArgs;
 import static org.apache.flink.table.types.inference.TypeStrategies.nullableIfArgs;
 import static org.apache.flink.table.types.inference.TypeStrategies.varyingString;
 
@@ -119,6 +120,17 @@ public class TypeStrategiesTest extends TypeStrategiesTestBase {
                                 DataTypes.BIGINT().notNull(),
                                 DataTypes.VARCHAR(2).notNull())
                         .expectDataType(DataTypes.BOOLEAN().notNull()),
+                TypeStrategiesTestBase.TestSpec.forStrategy(
+                                "Cascading to not null because one argument is not null",
+                                nullableIfAllArgs(TypeStrategies.COMMON))
+                        .inputTypes(DataTypes.VARCHAR(2).notNull(), DataTypes.VARCHAR(2).nullable())
+                        .expectDataType(DataTypes.VARCHAR(2).notNull()),
+                TypeStrategiesTestBase.TestSpec.forStrategy(
+                                "Cascading to nullable because all args are nullable",
+                                nullableIfAllArgs(TypeStrategies.COMMON))
+                        .inputTypes(
+                                DataTypes.VARCHAR(2).nullable(), DataTypes.VARCHAR(2).nullable())
+                        .expectDataType(DataTypes.VARCHAR(2).nullable()),
                 TypeStrategiesTestBase.TestSpec.forStrategy(
                                 "Find a common type", TypeStrategies.COMMON)
                         .inputTypes(
diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/FlinkSqlOperatorTable.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/FlinkSqlOperatorTable.java
index c0809d21f87..089de962e9f 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/FlinkSqlOperatorTable.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/FlinkSqlOperatorTable.java
@@ -1088,7 +1088,6 @@ public class FlinkSqlOperatorTable extends ReflectiveSqlOperatorTable {
     public static final SqlFunction ABS = SqlStdOperatorTable.ABS;
     public static final SqlFunction EXP = SqlStdOperatorTable.EXP;
     public static final SqlFunction NULLIF = SqlStdOperatorTable.NULLIF;
-    public static final SqlFunction COALESCE = SqlStdOperatorTable.COALESCE;
     public static final SqlFunction FLOOR = SqlStdOperatorTable.FLOOR;
     public static final SqlFunction CEIL = SqlStdOperatorTable.CEIL;
     public static final SqlFunction LOCALTIME = SqlStdOperatorTable.LOCALTIME;
diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRule.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRule.java
new file mode 100644
index 00000000000..83817e75994
--- /dev/null
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRule.java
@@ -0,0 +1,195 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.planner.plan.rules.logical;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;
+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;
+import org.apache.flink.table.planner.plan.utils.FlinkRexUtil;
+
+import org.apache.calcite.plan.RelOptRule;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Calc;
+import org.apache.calcite.rel.core.Filter;
+import org.apache.calcite.rel.core.Join;
+import org.apache.calcite.rel.core.Project;
+import org.apache.calcite.rex.RexCall;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.rex.RexShuttle;
+import org.apache.calcite.sql.SqlOperator;
+
+import java.util.List;
+import java.util.function.Predicate;
+
+/**
+ * Removes unreachable {@link BuiltInFunctionDefinitions#COALESCE} arguments.
+ *
+ * <p>An unreachable COALESCE argument is defined as any argument after the first argument in the
+ * argument list with a non-null type.
+ */
+@Internal
+public class RemoveUnreachableCoalesceArgumentsRule
+        extends RelRule<RemoveUnreachableCoalesceArgumentsRule.Config> {
+
+    public static final RelOptRule PROJECT_INSTANCE =
+            Config.EMPTY.as(Config.class).withProject().toRule();
+    public static final RelOptRule FILTER_INSTANCE =
+            Config.EMPTY.as(Config.class).withFilter().toRule();
+    public static final RelOptRule JOIN_INSTANCE =
+            Config.EMPTY.as(Config.class).withJoin().toRule();
+    public static final RelOptRule CALC_INSTANCE =
+            Config.EMPTY.as(Config.class).withCalc().toRule();
+
+    private static final UnreachableCoalesceArgumentsRemoveRexShuttle REX_SHUTTLE_INSTANCE =
+            new UnreachableCoalesceArgumentsRemoveRexShuttle();
+
+    public RemoveUnreachableCoalesceArgumentsRule(Config config) {
+        super(config);
+    }
+
+    @Override
+    public void onMatch(RelOptRuleCall call) {
+        final RelNode relNode = call.rel(0);
+        call.transformTo(relNode.accept(REX_SHUTTLE_INSTANCE));
+    }
+
+    private static class UnreachableCoalesceArgumentsRemoveRexShuttle extends RexShuttle {
+
+        @Override
+        public RexNode visitCall(RexCall call) {
+            call = (RexCall) super.visitCall(call);
+
+            // Not a coalesce invocation, skip it
+            if (!operatorIsCoalesce(call.getOperator())) {
+                return call;
+            }
+
+            final int firstNonNullableArgIndex = getFirstNonNullableArgumentIndex(call);
+
+            // If it's the first argument, just return the argument without the coalesce invocation
+            if (firstNonNullableArgIndex == 0) {
+                return call.operands.get(0);
+            }
+
+            // If it's the last argument, or no non-null argument was found, return the original
+            // call
+            if (firstNonNullableArgIndex == call.operands.size() - 1
+                    || firstNonNullableArgIndex == -1) {
+                return call;
+            }
+
+            // Return the coalesce invocation with a trimmed argument list
+            final List<RexNode> trimmedOperandsList =
+                    call.operands.subList(0, firstNonNullableArgIndex + 1);
+            return call.clone(call.getType(), trimmedOperandsList);
+        }
+
+        private int getFirstNonNullableArgumentIndex(RexCall call) {
+            for (int argIndex = 0; argIndex < call.operands.size(); argIndex++) {
+                if (!call.operands.get(argIndex).getType().isNullable()) {
+                    return argIndex;
+                }
+            }
+            return -1;
+        }
+    }
+
+    private static boolean hasCoalesceInvocation(RexNode node) {
+        return FlinkRexUtil.hasOperatorCallMatching(
+                node, RemoveUnreachableCoalesceArgumentsRule::operatorIsCoalesce);
+    }
+
+    private static boolean operatorIsCoalesce(SqlOperator op) {
+        return op instanceof BridgingSqlFunction
+                && ((BridgingSqlFunction) op)
+                        .getDefinition()
+                        .equals(BuiltInFunctionDefinitions.COALESCE);
+    }
+
+    // ---------------------------------------------------------------------------------------------
+
+    /** Configuration for {@link RemoveUnreachableCoalesceArgumentsRule}. */
+    public interface Config extends RelRule.Config {
+
+        @Override
+        default RelOptRule toRule() {
+            return new RemoveUnreachableCoalesceArgumentsRule(this);
+        }
+
+        default Config withProject() {
+            Predicate<Project> projectPredicate =
+                    lp ->
+                            lp.getProjects().stream()
+                                    .anyMatch(
+                                            RemoveUnreachableCoalesceArgumentsRule
+                                                    ::hasCoalesceInvocation);
+            final RelRule.OperandTransform projectTransform =
+                    operandBuilder ->
+                            operandBuilder
+                                    .operand(Project.class)
+                                    .predicate(projectPredicate)
+                                    .anyInputs();
+
+            return withOperandSupplier(projectTransform).as(Config.class);
+        }
+
+        default Config withFilter() {
+            Predicate<Filter> filterPredicate =
+                    lf ->
+                            RemoveUnreachableCoalesceArgumentsRule.hasCoalesceInvocation(
+                                    lf.getCondition());
+            final RelRule.OperandTransform filterTransform =
+                    operandBuilder ->
+                            operandBuilder
+                                    .operand(Filter.class)
+                                    .predicate(filterPredicate)
+                                    .anyInputs();
+
+            return withOperandSupplier(filterTransform).as(Config.class);
+        }
+
+        default Config withJoin() {
+            Predicate<Join> joinPredicate =
+                    lj ->
+                            RemoveUnreachableCoalesceArgumentsRule.hasCoalesceInvocation(
+                                    lj.getCondition());
+            final RelRule.OperandTransform joinTransform =
+                    operandBuilder ->
+                            operandBuilder.operand(Join.class).predicate(joinPredicate).anyInputs();
+
+            return withOperandSupplier(joinTransform).as(Config.class);
+        }
+
+        default Config withCalc() {
+            Predicate<Calc> calcPredicate =
+                    lc ->
+                            lc.getProgram().getExprList().stream()
+                                    .anyMatch(
+                                            RemoveUnreachableCoalesceArgumentsRule
+                                                    ::hasCoalesceInvocation);
+            final RelRule.OperandTransform joinTransform =
+                    operandBuilder ->
+                            operandBuilder.operand(Calc.class).predicate(calcPredicate).anyInputs();
+
+            return withOperandSupplier(joinTransform).as(Config.class);
+        }
+    }
+}
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkBatchRuleSets.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkBatchRuleSets.scala
index c6cec963905..d89eec569da 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkBatchRuleSets.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkBatchRuleSets.scala
@@ -19,10 +19,9 @@
 package org.apache.flink.table.planner.plan.rules
 
 import org.apache.flink.table.planner.plan.nodes.logical._
-import org.apache.flink.table.planner.plan.rules.logical._
+import org.apache.flink.table.planner.plan.rules.logical.{RemoveUnreachableCoalesceArgumentsRule, _}
 import org.apache.flink.table.planner.plan.rules.physical.FlinkExpandConversionRule
 import org.apache.flink.table.planner.plan.rules.physical.batch._
-
 import org.apache.calcite.rel.core.RelFactories
 import org.apache.calcite.rel.logical.{LogicalIntersect, LogicalMinus, LogicalUnion}
 import org.apache.calcite.rel.rules._
@@ -78,14 +77,13 @@ object FlinkBatchRuleSets {
   )
 
   /**
-    * RuleSet to rewrite coalesce to case when
-    */
-  private val REWRITE_COALESCE_RULES: RuleSet = RuleSets.ofList(
-    // rewrite coalesce to case when
-    RewriteCoalesceRule.FILTER_INSTANCE,
-    RewriteCoalesceRule.PROJECT_INSTANCE,
-    RewriteCoalesceRule.JOIN_INSTANCE,
-    RewriteCoalesceRule.CALC_INSTANCE
+   * RuleSet to simplify coalesce invocations
+   */
+  private val SIMPLIFY_COALESCE_RULES: RuleSet = RuleSets.ofList(
+    RemoveUnreachableCoalesceArgumentsRule.PROJECT_INSTANCE,
+    RemoveUnreachableCoalesceArgumentsRule.FILTER_INSTANCE,
+    RemoveUnreachableCoalesceArgumentsRule.JOIN_INSTANCE,
+    RemoveUnreachableCoalesceArgumentsRule.CALC_INSTANCE
   )
 
   private val LIMIT_RULES: RuleSet = RuleSets.ofList(
@@ -108,7 +106,7 @@ object FlinkBatchRuleSets {
     */
   val DEFAULT_REWRITE_RULES: RuleSet = RuleSets.ofList((
     PREDICATE_SIMPLIFY_EXPRESSION_RULES.asScala ++
-      REWRITE_COALESCE_RULES.asScala ++
+      SIMPLIFY_COALESCE_RULES.asScala ++
       REDUCE_EXPRESSION_RULES.asScala ++
       List(
         // Transform window to LogicalWindowAggregate
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkStreamRuleSets.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkStreamRuleSets.scala
index e2f765ba2b3..0039c330a33 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkStreamRuleSets.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/FlinkStreamRuleSets.scala
@@ -88,14 +88,13 @@ object FlinkStreamRuleSets {
   )
 
   /**
-    * RuleSet to rewrite coalesce to case when
-    */
-  private val REWRITE_COALESCE_RULES: RuleSet = RuleSets.ofList(
-    // rewrite coalesce to case when
-    RewriteCoalesceRule.FILTER_INSTANCE,
-    RewriteCoalesceRule.PROJECT_INSTANCE,
-    RewriteCoalesceRule.JOIN_INSTANCE,
-    RewriteCoalesceRule.CALC_INSTANCE
+   * RuleSet to simplify coalesce invocations
+   */
+  private val SIMPLIFY_COALESCE_RULES: RuleSet = RuleSets.ofList(
+    RemoveUnreachableCoalesceArgumentsRule.PROJECT_INSTANCE,
+    RemoveUnreachableCoalesceArgumentsRule.FILTER_INSTANCE,
+    RemoveUnreachableCoalesceArgumentsRule.JOIN_INSTANCE,
+    RemoveUnreachableCoalesceArgumentsRule.CALC_INSTANCE
   )
 
   /**
@@ -113,7 +112,7 @@ object FlinkStreamRuleSets {
     */
   val DEFAULT_REWRITE_RULES: RuleSet = RuleSets.ofList((
     PREDICATE_SIMPLIFY_EXPRESSION_RULES.asScala ++
-      REWRITE_COALESCE_RULES.asScala ++
+      SIMPLIFY_COALESCE_RULES.asScala ++
       REDUCE_EXPRESSION_RULES.asScala ++
       List(
         //removes constant keys from an Agg
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/logical/RewriteCoalesceRule.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/logical/RewriteCoalesceRule.scala
deleted file mode 100644
index 079a6f66ffd..00000000000
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/rules/logical/RewriteCoalesceRule.scala
+++ /dev/null
@@ -1,237 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.table.planner.plan.rules.logical
-
-import com.google.common.collect.ImmutableList
-import org.apache.calcite.plan.RelOptRule.{any, operand}
-import org.apache.calcite.plan.{RelOptRule, RelOptRuleCall}
-import org.apache.calcite.rel.RelNode
-import org.apache.calcite.rel.core.{Calc, Filter, Join, Project}
-import org.apache.calcite.rel.logical.{LogicalCalc, LogicalFilter, LogicalJoin, LogicalProject}
-import org.apache.calcite.rex._
-import org.apache.calcite.sql.SqlKind
-import org.apache.calcite.sql.fun.SqlStdOperatorTable
-import org.apache.calcite.tools.RelBuilder
-import org.apache.calcite.util.Util
-
-import scala.collection.JavaConversions._
-
-/**
-  * Collection of planner rules that transform `Coalesce` to `Case When` RexNode trees.
-  *
-  * <p>Currently this is only used for natural join, for explicit Coalesce
-  * Calcite already replace it with Case When.
-  *
-  * <p>There are four transformation contexts:
-  * <ul>
-  * <li>Project project list
-  * <li>Join condition
-  * <li>Filter condition
-  * <li>Calc expression list
-  * </ul>
-  */
-abstract class RewriteCoalesceRule[T <: RelNode](
-    clazz: Class[T],
-    description: String)
-  extends RelOptRule(
-    operand(clazz, any),
-    description) {
-
-  private class CoalesceToCaseShuttle(rexBuilder: RexBuilder) extends RexShuttle {
-    override def visitCall(call: RexCall): RexNode = {
-      call.getKind match {
-        case SqlKind.COALESCE =>
-          val operands = call.getOperands
-          if (operands.size == 1) {
-            operands.head
-          } else {
-            val operandsExceptLast = Util.skipLast(call.getOperands)
-            val args: ImmutableList.Builder[RexNode] = ImmutableList.builder()
-            operandsExceptLast.foreach { operand =>
-              args.add(rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL, operand), operand)
-            }
-            args.add(call.getOperands.last)
-            rexBuilder.makeCall(SqlStdOperatorTable.CASE, args.build)
-          }
-        case _ => super.visitCall(call)
-      }
-    }
-  }
-
-  protected def replace(input: RexNode,
-      rexBuilder: RexBuilder): RexNode = {
-    val shuttle = new CoalesceToCaseShuttle(rexBuilder)
-    input.accept(shuttle)
-  }
-
-  protected def existsCoalesce(rexNode: RexNode): Boolean = {
-    class CoalesceFinder extends RexVisitorImpl[Unit](true) {
-      var found = false
-
-      override def visitCall(call: RexCall): Unit = {
-        call.getKind match {
-          case SqlKind.COALESCE => found = true
-          case _ => super.visitCall(call)
-        }
-      }
-
-      def isFound: Boolean = found
-    }
-    val finder = new CoalesceFinder
-    rexNode.accept(finder)
-    finder.isFound
-  }
-
-}
-
-/**
-  * Planner rule that rewrites `Coalesce` in filter condition to `Case When`.
-  */
-class FilterRewriteCoalesceRule extends
-  RewriteCoalesceRule(
-    classOf[LogicalFilter],
-    "FilterRewriteCoalesceRule") {
-  override def matches(call: RelOptRuleCall): Boolean = {
-    val filter: Filter = call.rel(0)
-    existsCoalesce(filter.getCondition)
-  }
-
-  override def onMatch(call: RelOptRuleCall): Unit = {
-    val filter: Filter = call.rel(0)
-    val relBuilder: RelBuilder = call.builder()
-    val rexBuilder: RexBuilder = relBuilder.getRexBuilder
-    // transform the filter recursively, may change all the Coalesce in the filter
-    // to Case when, this is ok for us now, cause the filter will never be matched again
-    // by this rule after the transformation.
-    val newCondition = replace(filter.getCondition, rexBuilder)
-    val newFilter = relBuilder
-      .push(filter.getInput)
-      .filter(newCondition)
-      .build()
-    call.transformTo(newFilter)
-  }
-}
-
-/**
-  * Planner rule that rewrites `Coalesce` in project list to `Case When`.
-  */
-class ProjectRewriteCoalesceRule extends
-  RewriteCoalesceRule(
-    classOf[LogicalProject],
-    "ProjectRewriteCoalesceRule") {
-  override def matches(call: RelOptRuleCall): Boolean = {
-    val prj: Project = call.rel(0)
-    prj.getProjects.exists(p => existsCoalesce(p))
-  }
-
-  override def onMatch(call: RelOptRuleCall): Unit = {
-    val prj: Project = call.rel(0)
-    val relBuilder: RelBuilder = call.builder()
-    val rexBuilder: RexBuilder = relBuilder.getRexBuilder
-    // transform the project recursively, may change all the Coalesce in the project
-    // to Case when, this is ok for us now, cause the project will never be matched again
-    // by this rule after the transformation.
-    val newProjects = prj.getProjects.map(p => replace(p, rexBuilder))
-    val newProject = relBuilder
-      .push(prj.getInput)
-      .project(newProjects)
-      .build()
-    call.transformTo(newProject)
-  }
-}
-
-/**
-  * Planner rule that rewrites `Coalesce` in join condition to `Case When`.
-  */
-class JoinRewriteCoalesceRule extends
-  RewriteCoalesceRule(
-    classOf[LogicalJoin],
-    "JoinRewriteCoalesceRule") {
-  override def matches(call: RelOptRuleCall): Boolean = {
-    val prj: Join = call.rel(0)
-    existsCoalesce(prj.getCondition)
-  }
-
-  override def onMatch(call: RelOptRuleCall): Unit = {
-    val join: Join = call.rel(0)
-    val relBuilder: RelBuilder = call.builder()
-    val rexBuilder: RexBuilder = relBuilder.getRexBuilder
-    val newCondition = replace(join.getCondition, rexBuilder)
-    // transform the join recursively, may change all the Coalesce in the join
-    // to Case when, this is ok for us now, cause the join will never be matched again
-    // by this rule after the transformation.
-    val newJoin = join.copy(
-      join.getTraitSet,
-      newCondition,
-      join.getLeft,
-      join.getRight,
-      join.getJoinType,
-      join.isSemiJoinDone)
-    call.transformTo(newJoin)
-  }
-}
-
-/**
-  * Planner rule that rewrites `Coalesce` in calc expression list to `Case When`.
-  */
-class CalcRewriteCoalesceRule extends
-  RewriteCoalesceRule(
-    classOf[LogicalCalc],
-    "CalcRewriteCoalesceRule") {
-  override def matches(call: RelOptRuleCall): Boolean = {
-    val calc: Calc = call.rel(0)
-    val program = calc.getProgram
-    val exprList = program.getExprList
-    exprList.exists(p => existsCoalesce(p))
-  }
-
-  override def onMatch(call: RelOptRuleCall): Unit = {
-    val calc: Calc = call.rel(0)
-    val relBuilder: RelBuilder = call.builder()
-    val rexBuilder: RexBuilder = relBuilder.getRexBuilder
-    // transform the Calc recursively, may change all the Coalesce in the Calc
-    // to Case when, this is ok for us now, cause the Calc will never be matched again
-    // by this rule after the transformation.
-    val program = calc.getProgram
-    val exprList = program.getExprList.map(expr => replace(expr, rexBuilder))
-    val builder: RexProgramBuilder = new RexProgramBuilder(
-      calc.getInput.getRowType, calc.getCluster.getRexBuilder)
-    val list = exprList.map(expr => builder.registerInput(expr))
-    if (program.getCondition != null) {
-      val conditionIndex = program.getCondition.getIndex
-      builder.addCondition(list.get(conditionIndex))
-    }
-    program.getProjectList.zipWithIndex.foreach {
-      case (projectExpr, idx) =>
-        val index = projectExpr.getIndex
-        builder.addProject(list.get(index).getIndex,
-          program.getOutputRowType.getFieldNames.get(idx))
-    }
-
-    val newCalc = calc.copy(calc.getTraitSet, calc.getInput, builder.getProgram)
-    call.transformTo(newCalc)
-  }
-}
-
-object RewriteCoalesceRule {
-  val FILTER_INSTANCE = new FilterRewriteCoalesceRule
-  val PROJECT_INSTANCE = new ProjectRewriteCoalesceRule
-  val JOIN_INSTANCE = new JoinRewriteCoalesceRule
-  val CALC_INSTANCE = new CalcRewriteCoalesceRule
-}
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/utils/FlinkRexUtil.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/utils/FlinkRexUtil.scala
index adc37701d0c..feeec2e45b8 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/utils/FlinkRexUtil.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/plan/utils/FlinkRexUtil.scala
@@ -22,7 +22,6 @@ import org.apache.flink.configuration.ConfigOption
 import org.apache.flink.configuration.ConfigOptions.key
 import org.apache.flink.table.planner.JList
 import org.apache.flink.table.planner.plan.utils.ExpressionFormat.ExpressionFormat
-
 import com.google.common.base.Function
 import com.google.common.collect.{ImmutableList, Lists}
 import org.apache.calcite.plan.{RelOptPredicateList, RelOptUtil}
@@ -30,12 +29,12 @@ import org.apache.calcite.rel.`type`.RelDataType
 import org.apache.calcite.rex._
 import org.apache.calcite.sql.fun.SqlStdOperatorTable
 import org.apache.calcite.sql.fun.SqlStdOperatorTable._
-import org.apache.calcite.sql.{SqlAsOperator, SqlKind}
+import org.apache.calcite.sql.{SqlAsOperator, SqlKind, SqlOperator}
 import org.apache.calcite.util.{ControlFlowException, ImmutableBitSet, Sarg, Util}
 
 import java.lang.{Iterable => JIterable}
 import java.util
-
+import java.util.function.Predicate
 import scala.collection.JavaConversions._
 import scala.collection.mutable
 
@@ -535,6 +534,29 @@ object FlinkRexUtil {
         throw new IllegalArgumentException(s"Unknown expression type '${expr.getClass}': $expr")
     }
   }
+
+  /**
+   * Similar to [[RexUtil#findOperatorCall(SqlOperator, RexNode)]],
+   * but with a broader predicate support and returning a boolean.
+   */
+  def hasOperatorCallMatching(expr: RexNode, predicate: Predicate[SqlOperator]): Boolean = {
+    try {
+      val visitor = new RexVisitorImpl[Void](true) {
+        override def visitCall(call: RexCall): Void = {
+          if (predicate.test(call.getOperator)) {
+            throw new Util.FoundOne(call)
+          }
+          super.visitCall(call)
+        }
+      }
+      expr.accept(visitor)
+    } catch {
+      case e: Util.FoundOne =>
+        Util.swallow(e, null)
+        return true
+    }
+    false
+  }
 }
 
 /**
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/CoalesceFunctionITCase.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/CoalesceFunctionITCase.java
new file mode 100644
index 00000000000..5ef20dd9336
--- /dev/null
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/functions/CoalesceFunctionITCase.java
@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.planner.functions;
+
+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;
+
+import org.junit.runners.Parameterized;
+
+import java.util.Collections;
+import java.util.List;
+
+import static org.apache.flink.table.api.DataTypes.BIGINT;
+import static org.apache.flink.table.api.DataTypes.INT;
+import static org.apache.flink.table.api.Expressions.$;
+import static org.apache.flink.table.api.Expressions.coalesce;
+
+/** Test {@link BuiltInFunctionDefinitions#COALESCE} and its return type. */
+public class CoalesceFunctionITCase extends BuiltInFunctionTestBase {
+
+    @Parameterized.Parameters(name = "{index}: {0}")
+    public static List<TestSpec> testData() {
+        return Collections.singletonList(
+                TestSpec.forFunction(BuiltInFunctionDefinitions.COALESCE)
+                        .onFieldsWithData(null, null, 1)
+                        .andDataTypes(BIGINT().nullable(), INT().nullable(), INT().notNull())
+                        .testResult(
+                                coalesce($("f0"), $("f1")),
+                                "COALESCE(f0, f1)",
+                                null,
+                                BIGINT().nullable())
+                        .testResult(
+                                coalesce($("f0"), $("f2")),
+                                "COALESCE(f0, f2)",
+                                1L,
+                                BIGINT().notNull())
+                        .testResult(
+                                coalesce($("f1"), $("f2")), "COALESCE(f1, f2)", 1, INT().notNull())
+                        .testResult(
+                                coalesce($("f0"), 1),
+                                "COALESCE(f0, 1)",
+                                1L,
+                                // In this case, the return type is not null because we have a
+                                // constant in the function invocation
+                                BIGINT().notNull()));
+    }
+}
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRuleTest.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRuleTest.java
new file mode 100644
index 00000000000..bbc427fe3e1
--- /dev/null
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRuleTest.java
@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.planner.plan.rules.logical;
+
+import org.apache.flink.table.api.Schema;
+import org.apache.flink.table.api.TableConfig;
+import org.apache.flink.table.api.TableDescriptor;
+import org.apache.flink.table.planner.factories.TableFactoryHarness;
+import org.apache.flink.table.planner.utils.StreamTableTestUtil;
+import org.apache.flink.table.planner.utils.TableTestBase;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.apache.flink.table.api.DataTypes.STRING;
+
+/** Test rule {@link RemoveUnreachableCoalesceArgumentsRule}. */
+public class RemoveUnreachableCoalesceArgumentsRuleTest extends TableTestBase {
+
+    private StreamTableTestUtil util;
+
+    @Before
+    public void before() {
+        util = streamTestUtil(TableConfig.getDefault());
+
+        final TableDescriptor sourceDescriptor =
+                TableFactoryHarness.newBuilder()
+                        .schema(
+                                Schema.newBuilder()
+                                        .column("f0", STRING().nullable())
+                                        .column("f1", STRING().notNull())
+                                        .column("f2", STRING().nullable())
+                                        .build())
+                        .unboundedScanSource()
+                        .build();
+
+        util.tableEnv().createTable("T", sourceDescriptor);
+    }
+
+    @Test
+    public void testOnlyLastNonNull() {
+        util.verifyRelPlan("SELECT COALESCE(f0, f1) FROM T");
+    }
+
+    @Test
+    public void testAllNullable() {
+        util.verifyRelPlan("SELECT COALESCE(f0, f2) FROM T");
+    }
+
+    @Test
+    public void testDropLastConstant() {
+        util.verifyRelPlan("SELECT COALESCE(f0, f1, '-') FROM T");
+    }
+
+    @Test
+    public void testDropCoalesce() {
+        util.verifyRelPlan("SELECT COALESCE(f1, '-') FROM T");
+    }
+
+    @Test
+    public void testFilterCoalesce() {
+        util.verifyRelPlan("SELECT * FROM T WHERE COALESCE(f0, f1, '-') = 'abc'");
+    }
+
+    @Test
+    public void testJoinCoalesce() {
+        util.verifyRelPlan(
+                "SELECT * FROM T t1 LEFT JOIN T t2 ON COALESCE(t1.f0, '-', t1.f2) = t2.f0");
+    }
+}
diff --git a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/agg/GroupingSetsTest.xml b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/agg/GroupingSetsTest.xml
index f70de6b78e6..5fcda623fac 100644
--- a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/agg/GroupingSetsTest.xml
+++ b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/agg/GroupingSetsTest.xml
@@ -769,14 +769,14 @@ GROUP BY GROUPING SETS ((a, b), (a, b, c))
     </Resource>
     <Resource name="ast">
       <![CDATA[
-LogicalProject(a=[$0], b=[$1], EXPR$2=[CASE(IS NOT NULL($2), CAST($2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL, _UTF-16LE'empty':VARCHAR(2147483647) CHARACTER SET "UTF-16LE")], EXPR$3=[$3])
+LogicalProject(a=[$0], b=[$1], EXPR$2=[coalesce($2, _UTF-16LE'empty')], EXPR$3=[$3])
 +- LogicalAggregate(group=[{0, 1, 2}], groups=[[{0, 1, 2}, {0, 1}]], EXPR$3=[AVG($3)])
    +- LogicalTableScan(table=[[default_catalog, default_database, t1]])
 ]]>
     </Resource>
     <Resource name="optimized exec plan">
       <![CDATA[
-Calc(select=[a, b, CASE(c IS NOT NULL, CAST(c), _UTF-16LE'empty':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS EXPR$2, EXPR$3])
+Calc(select=[a, b, coalesce(c, _UTF-16LE'empty') AS EXPR$2, EXPR$3])
 +- HashAggregate(isMerge=[true], groupBy=[a, b, c, $e], select=[a, b, c, $e, Final_AVG(sum$0, count$1) AS EXPR$3])
    +- Exchange(distribution=[hash[a, b, c, $e]])
       +- LocalHashAggregate(groupBy=[a, b, c, $e], select=[a, b, c, $e, Partial_AVG(d) AS (sum$0, count$1)])
diff --git a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/NestedLoopJoinTest.xml b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/NestedLoopJoinTest.xml
index 753f90bfdc0..9c5e769032f 100644
--- a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/NestedLoopJoinTest.xml
+++ b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/NestedLoopJoinTest.xml
@@ -193,7 +193,7 @@ LogicalProject(a=[COALESCE($0, $3)], b=[$1], c=[$2], b0=[$4], c0=[$5])
     </Resource>
     <Resource name="optimized exec plan">
       <![CDATA[
-Calc(select=[CASE(a IS NOT NULL, a, a0) AS $f0, b, c, b0, c0])
+Calc(select=[COALESCE(a, a0) AS a, b, c, b0, c0])
 +- NestedLoopJoin(joinType=[FullOuterJoin], where=[(a = a0)], select=[a, b, c, a0, b0, c0], build=[left])
    :- Exchange(distribution=[single])
    :  +- LegacyTableSourceScan(table=[[default_catalog, default_database, MyTable1, source: [TestTableSource(a, b, c)]]], fields=[a, b, c])
diff --git a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/ShuffledHashJoinTest.xml b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/ShuffledHashJoinTest.xml
index d37bb9383ed..f8fc67e6457 100644
--- a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/ShuffledHashJoinTest.xml
+++ b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/ShuffledHashJoinTest.xml
@@ -106,7 +106,7 @@ LogicalProject(a=[COALESCE($0, $3)], b=[$1], c=[$2], b0=[$4], c0=[$5])
     </Resource>
     <Resource name="optimized exec plan">
       <![CDATA[
-Calc(select=[CASE(a IS NOT NULL, a, a0) AS $f0, b, c, b0, c0])
+Calc(select=[COALESCE(a, a0) AS a, b, c, b0, c0])
 +- HashJoin(joinType=[FullOuterJoin], where=[(a = a0)], select=[a, b, c, a0, b0, c0], build=[right])
    :- Exchange(distribution=[hash[a]])
    :  +- LegacyTableSourceScan(table=[[default_catalog, default_database, MyTable1, source: [TestTableSource(a, b, c)]]], fields=[a, b, c])
diff --git a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/SortMergeJoinTest.xml b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/SortMergeJoinTest.xml
index 1be6bd2d24b..e033f245a98 100644
--- a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/SortMergeJoinTest.xml
+++ b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/batch/sql/join/SortMergeJoinTest.xml
@@ -106,7 +106,7 @@ LogicalProject(a=[COALESCE($0, $3)], b=[$1], c=[$2], b0=[$4], c0=[$5])
     </Resource>
     <Resource name="optimized exec plan">
       <![CDATA[
-Calc(select=[CASE(a IS NOT NULL, a, a0) AS $f0, b, c, b0, c0])
+Calc(select=[COALESCE(a, a0) AS a, b, c, b0, c0])
 +- SortMergeJoin(joinType=[FullOuterJoin], where=[(a = a0)], select=[a, b, c, a0, b0, c0])
    :- Exchange(distribution=[hash[a]])
    :  +- LegacyTableSourceScan(table=[[default_catalog, default_database, MyTable1, source: [TestTableSource(a, b, c)]]], fields=[a, b, c])
diff --git a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRuleTest.xml b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRuleTest.xml
new file mode 100644
index 00000000000..c3637353cd0
--- /dev/null
+++ b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/rules/logical/RemoveUnreachableCoalesceArgumentsRuleTest.xml
@@ -0,0 +1,130 @@
+<?xml version="1.0" ?>
+<!--
+Licensed to the Apache Software Foundation (ASF) under one or more
+contributor license agreements.  See the NOTICE file distributed with
+this work for additional information regarding copyright ownership.
+The ASF licenses this file to you under the Apache License, Version 2.0
+(the "License"); you may not use this file except in compliance with
+the License.  You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+-->
+<Root>
+  <TestCase name="testAllNullable">
+    <Resource name="sql">
+      <![CDATA[SELECT COALESCE(f0, f2) FROM T]]>
+    </Resource>
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(EXPR$0=[COALESCE($0, $2)])
++- LogicalTableScan(table=[[default_catalog, default_database, T]])
+]]>
+    </Resource>
+    <Resource name="optimized rel plan">
+      <![CDATA[
+Calc(select=[COALESCE(f0, f2) AS EXPR$0])
++- TableSourceScan(table=[[default_catalog, default_database, T]], fields=[f0, f1, f2])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testDropCoalesce">
+    <Resource name="sql">
+      <![CDATA[SELECT COALESCE(f1, '-') FROM T]]>
+    </Resource>
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(EXPR$0=[COALESCE($1, _UTF-16LE'-')])
++- LogicalTableScan(table=[[default_catalog, default_database, T]])
+]]>
+    </Resource>
+    <Resource name="optimized rel plan">
+      <![CDATA[
+Calc(select=[f1 AS EXPR$0])
++- TableSourceScan(table=[[default_catalog, default_database, T]], fields=[f0, f1, f2])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testOnlyLastNonNull">
+    <Resource name="sql">
+      <![CDATA[SELECT COALESCE(f0, f1) FROM T]]>
+    </Resource>
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(EXPR$0=[COALESCE($0, $1)])
++- LogicalTableScan(table=[[default_catalog, default_database, T]])
+]]>
+    </Resource>
+    <Resource name="optimized rel plan">
+      <![CDATA[
+Calc(select=[COALESCE(f0, f1) AS EXPR$0])
++- TableSourceScan(table=[[default_catalog, default_database, T]], fields=[f0, f1, f2])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testDropLastConstant">
+    <Resource name="sql">
+      <![CDATA[SELECT COALESCE(f0, f1, '-') FROM T]]>
+    </Resource>
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(EXPR$0=[COALESCE($0, $1, _UTF-16LE'-')])
++- LogicalTableScan(table=[[default_catalog, default_database, T]])
+]]>
+    </Resource>
+    <Resource name="optimized rel plan">
+      <![CDATA[
+Calc(select=[COALESCE(f0, f1) AS EXPR$0])
++- TableSourceScan(table=[[default_catalog, default_database, T]], fields=[f0, f1, f2])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testJoinCoalesce">
+    <Resource name="sql">
+      <![CDATA[SELECT * FROM T t1 LEFT JOIN T t2 ON COALESCE(t1.f0, '-', t1.f2) = t2.f0]]>
+    </Resource>
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(f0=[$0], f1=[$1], f2=[$2], f00=[$4], f10=[$5], f20=[$6])
++- LogicalJoin(condition=[=($3, $4)], joinType=[left])
+   :- LogicalProject(f0=[$0], f1=[$1], f2=[$2], $f3=[COALESCE($0, _UTF-16LE'-', $2)])
+   :  +- LogicalTableScan(table=[[default_catalog, default_database, T]])
+   +- LogicalTableScan(table=[[default_catalog, default_database, T]])
+]]>
+    </Resource>
+    <Resource name="optimized rel plan">
+      <![CDATA[
+Calc(select=[f0, f1, f2, f00, f10, f20])
++- Join(joinType=[LeftOuterJoin], where=[=($f3, f00)], select=[f0, f1, f2, $f3, f00, f10, f20], leftInputSpec=[NoUniqueKey], rightInputSpec=[NoUniqueKey])
+   :- Exchange(distribution=[hash[$f3]])
+   :  +- Calc(select=[f0, f1, f2, COALESCE(f0, _UTF-16LE'-') AS $f3])
+   :     +- TableSourceScan(table=[[default_catalog, default_database, T]], fields=[f0, f1, f2])
+   +- Exchange(distribution=[hash[f0]])
+      +- TableSourceScan(table=[[default_catalog, default_database, T]], fields=[f0, f1, f2])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testFilterCoalesce">
+    <Resource name="sql">
+      <![CDATA[SELECT * FROM T WHERE COALESCE(f0, f1, '-') = 'abc']]>
+    </Resource>
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(f0=[$0], f1=[$1], f2=[$2])
++- LogicalFilter(condition=[=(COALESCE($0, $1, _UTF-16LE'-'), _UTF-16LE'abc')])
+   +- LogicalTableScan(table=[[default_catalog, default_database, T]])
+]]>
+    </Resource>
+    <Resource name="optimized rel plan">
+      <![CDATA[
+Calc(select=[f0, f1, f2], where=[=(COALESCE(f0, f1), _UTF-16LE'abc':VARCHAR(2147483647) CHARACTER SET "UTF-16LE")])
++- TableSourceScan(table=[[default_catalog, default_database, T]], fields=[f0, f1, f2])
+]]>
+    </Resource>
+  </TestCase>
+</Root>
diff --git a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/agg/GroupingSetsTest.xml b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/agg/GroupingSetsTest.xml
index 581a5a6017a..e6eb14a0e18 100644
--- a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/agg/GroupingSetsTest.xml
+++ b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/agg/GroupingSetsTest.xml
@@ -704,14 +704,14 @@ GROUP BY GROUPING SETS ((a, b), (a, b, c))
     </Resource>
     <Resource name="ast">
       <![CDATA[
-LogicalProject(a=[$0], b=[$1], EXPR$2=[CASE(IS NOT NULL($2), CAST($2):VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL, _UTF-16LE'empty':VARCHAR(2147483647) CHARACTER SET "UTF-16LE")], EXPR$3=[$3])
+LogicalProject(a=[$0], b=[$1], EXPR$2=[coalesce($2, _UTF-16LE'empty')], EXPR$3=[$3])
 +- LogicalAggregate(group=[{0, 1, 2}], groups=[[{0, 1, 2}, {0, 1}]], EXPR$3=[AVG($3)])
    +- LogicalTableScan(table=[[default_catalog, default_database, t1]])
 ]]>
     </Resource>
     <Resource name="optimized exec plan">
       <![CDATA[
-Calc(select=[a, b, CASE(c IS NOT NULL, CAST(c), _UTF-16LE'empty':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS EXPR$2, EXPR$3])
+Calc(select=[a, b, coalesce(c, _UTF-16LE'empty') AS EXPR$2, EXPR$3])
 +- GroupAggregate(groupBy=[a, b, c, $e], select=[a, b, c, $e, AVG(d) AS EXPR$3])
    +- Exchange(distribution=[hash[a, b, c, $e]])
       +- Expand(projects=[{a, b, c, d, 0 AS $e}, {a, b, null AS c, d, 1 AS $e}])
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/plan/rules/logical/RewriteCoalesceRuleTest.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/plan/rules/logical/RewriteCoalesceRuleTest.scala
deleted file mode 100644
index 22e4f1907b7..00000000000
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/plan/rules/logical/RewriteCoalesceRuleTest.scala
+++ /dev/null
@@ -1,142 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.table.planner.plan.rules.logical
-
-import org.apache.flink.api.scala._
-import org.apache.flink.table.api._
-import org.apache.flink.table.api.bridge.scala._
-import org.apache.flink.table.planner.codegen.CodeGenException
-import org.apache.flink.table.planner.plan.optimize.program.{BatchOptimizeContext, FlinkChainedProgram, FlinkHepRuleSetProgramBuilder, HEP_RULES_EXECUTION_TYPE}
-import org.apache.flink.table.planner.plan.rules.FlinkBatchRuleSets
-import org.apache.flink.table.planner.utils.TableTestBase
-
-import org.apache.calcite.plan.hep.HepMatchOrder
-import org.junit.{Before, Test}
-
-import java.sql.Date
-
-/**
-  * Test for [[RewriteCoalesceRule]].
-  */
-class RewriteCoalesceRuleTest extends TableTestBase {
-  private val util = batchTestUtil()
-
-  @Before
-  def setup(): Unit = {
-    val programs = new FlinkChainedProgram[BatchOptimizeContext]()
-    programs.addLast(
-      "default_rewrite",
-      FlinkHepRuleSetProgramBuilder.newBuilder
-        .setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE)
-        .setHepMatchOrder(HepMatchOrder.BOTTOM_UP)
-        .add(FlinkBatchRuleSets.DEFAULT_REWRITE_RULES)
-        .build())
-    util.replaceBatchProgram(programs)
-
-    util.addTableSource[(Int, String, String, Int, Date, Double, Double, Int)](
-      "scott_emp", 'empno, 'ename, 'job, 'mgr, 'hiredate, 'sal, 'comm, 'deptno)
-    util.addTableSource[(Int, String, String)]("scott_dept", 'deptno, 'dname, 'loc)
-  }
-
-  @Test
-  def testCalcite1018(): Unit = {
-    val sqlQuery =
-      """
-        |select * from (select * from scott_emp) e left join (
-        |    select * from scott_dept d) using (deptno)
-        |    order by empno limit 10
-      """.stripMargin
-    util.verifyRelPlan(sqlQuery)
-  }
-
-  @Test
-  def testCoalesceConstantReduce(): Unit = {
-    val sqlQuery =
-      """
-        |select * from lateral (select * from scott_emp) as e
-        |    join (table scott_dept) using (deptno)
-        |    where e.deptno = 10
-      """.stripMargin
-    util.verifyRelPlan(sqlQuery)
-  }
-
-  @Test(expected = classOf[CodeGenException])
-  // TODO remove expected exception after [FLINK-12371] merged
-  def testCalcite864_1(): Unit = {
-    val sqlQuery =
-      """
-        |select *
-        |    from scott_emp as e
-        |    join scott_dept as d using (deptno)
-        |    where sal = (
-        |      select max(sal)
-        |      from scott_emp as e2
-        |      join scott_dept as d2 using (deptno)
-        |      where d2.deptno = d.deptno)
-      """.stripMargin
-    util.verifyRelPlan(sqlQuery)
-  }
-
-  @Test(expected = classOf[CodeGenException])
-  // TODO remove expected exception after [FLINK-12371] merged
-  def testCalcite864_3(): Unit = {
-    val sqlQuery =
-      """
-        |select *
-        |    from scott_emp as e
-        |    join scott_dept as d using (deptno)
-        |    where d.dname = (
-        |      select max(dname)
-        |      from scott_dept as d2
-        |      where d2.deptno = d.deptno)
-      """.stripMargin
-    util.verifyRelPlan(sqlQuery)
-  }
-
-  @Test
-  def testNaturalJoinWithPredicates(): Unit = {
-    val sqlQuery =
-      """
-        |select * from scott_dept natural join scott_emp where empno = 1
-      """.stripMargin
-    util.verifyRelPlan(sqlQuery)
-  }
-
-  @Test
-  def testNaturalJoinLeftOuter(): Unit = {
-    val sqlQuery =
-      """
-        |SELECT * FROM scott_dept
-        |    natural left join scott_emp
-        |    order by scott_dept.deptno, scott_emp.deptno
-      """.stripMargin
-    util.verifyRelPlan(sqlQuery)
-  }
-
-  @Test
-  def testNaturalJoinRightOuter(): Unit = {
-    val sqlQuery =
-      """
-        |SELECT * FROM scott_dept
-        |    natural right join scott_emp
-        |    order by scott_dept.deptno, scott_emp.deptno
-      """.stripMargin
-    util.verifyRelPlan(sqlQuery)
-  }
-}
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/CoalesceFunction.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/CoalesceFunction.java
new file mode 100644
index 00000000000..4f2253c7810
--- /dev/null
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/CoalesceFunction.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.runtime.functions.scalar;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;
+import org.apache.flink.table.functions.SpecializedFunction.SpecializedContext;
+
+import javax.annotation.Nullable;
+
+/** Implementation of {@link BuiltInFunctionDefinitions#COALESCE}. */
+@Internal
+public class CoalesceFunction extends BuiltInScalarFunction {
+
+    public CoalesceFunction(SpecializedContext context) {
+        super(BuiltInFunctionDefinitions.COALESCE, context);
+    }
+
+    public @Nullable Object eval(Object... args) {
+        for (Object arg : args) {
+            if (arg != null) {
+                return arg;
+            }
+        }
+        return null;
+    }
+}
