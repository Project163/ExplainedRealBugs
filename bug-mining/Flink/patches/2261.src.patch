diff --git a/flink-end-to-end-tests/test-scripts/common.sh b/flink-end-to-end-tests/test-scripts/common.sh
index 7492f365afd..e6d21a26b09 100644
--- a/flink-end-to-end-tests/test-scripts/common.sh
+++ b/flink-end-to-end-tests/test-scripts/common.sh
@@ -75,6 +75,7 @@ function stop_cluster {
       | grep -v "RejectedExecutionException" \
       | grep -v "An exception was thrown by an exception handler" \
       | grep -v "java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/exceptions/YarnException" \
+      | grep -v "java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration" \
       | grep -iq "error"; then
     echo "Found error in log files:"
     cat $FLINK_DIR/log/*
@@ -92,7 +93,9 @@ function stop_cluster {
       | grep -v "RejectedExecutionException" \
       | grep -v "An exception was thrown by an exception handler" \
       | grep -v "Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.yarn.exceptions.YarnException" \
+      | grep -v "Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration" \
       | grep -v "java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/exceptions/YarnException" \
+      | grep -v "java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration" \
       | grep -iq "exception"; then
     echo "Found exception in log files:"
     cat $FLINK_DIR/log/*
diff --git a/flink-yarn-tests/pom.xml b/flink-yarn-tests/pom.xml
index b5a86b4b8f2..0b05b287b24 100644
--- a/flink-yarn-tests/pom.xml
+++ b/flink-yarn-tests/pom.xml
@@ -378,6 +378,14 @@ under the License.
 							<overWrite>true</overWrite>
 							<destFileName>StreamingWordCount.jar</destFileName>
 						</artifactItem>
+						<artifactItem>
+							<groupId>org.apache.flink</groupId>
+							<artifactId>flink-examples-streaming_${scala.binary.version}</artifactId>
+							<type>jar</type>
+							<classifier>WindowJoin</classifier>
+							<overWrite>true</overWrite>
+							<destFileName>WindowJoin.jar</destFileName>
+						</artifactItem>
 					</artifactItems>
 					<outputDirectory>${project.build.directory}/programs</outputDirectory>
 					<overWriteReleases>false</overWriteReleases>
diff --git a/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YarnConfigurationITCase.java b/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YarnConfigurationITCase.java
new file mode 100644
index 00000000000..2a1b099399a
--- /dev/null
+++ b/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YarnConfigurationITCase.java
@@ -0,0 +1,194 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.yarn;
+
+import org.apache.flink.api.common.time.Time;
+import org.apache.flink.client.cli.CliFrontend;
+import org.apache.flink.client.deployment.ClusterSpecification;
+import org.apache.flink.client.program.ClusterClient;
+import org.apache.flink.client.program.PackagedProgram;
+import org.apache.flink.client.program.PackagedProgramUtils;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.ResourceManagerOptions;
+import org.apache.flink.configuration.TaskManagerOptions;
+import org.apache.flink.runtime.clusterframework.ContaineredTaskManagerParameters;
+import org.apache.flink.runtime.jobgraph.JobGraph;
+import org.apache.flink.runtime.rest.RestClient;
+import org.apache.flink.runtime.rest.RestClientConfiguration;
+import org.apache.flink.runtime.rest.messages.EmptyMessageParameters;
+import org.apache.flink.runtime.rest.messages.EmptyRequestBody;
+import org.apache.flink.runtime.rest.messages.taskmanager.TaskManagerInfo;
+import org.apache.flink.runtime.rest.messages.taskmanager.TaskManagersHeaders;
+import org.apache.flink.runtime.rest.messages.taskmanager.TaskManagersInfo;
+import org.apache.flink.runtime.testingUtils.TestingUtils;
+
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ContainerReport;
+import org.apache.hadoop.yarn.client.api.YarnClient;
+import org.apache.hadoop.yarn.conf.YarnConfiguration;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+
+import java.io.File;
+import java.net.URI;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.List;
+import java.util.concurrent.CompletableFuture;
+
+import static org.hamcrest.Matchers.closeTo;
+import static org.hamcrest.Matchers.is;
+import static org.junit.Assert.assertThat;
+
+/**
+ * Test cases which ensure that the Yarn containers are started with the correct
+ * settings.
+ */
+public class YarnConfigurationITCase extends YarnTestBase {
+
+	private static final Time TIMEOUT = Time.seconds(10L);
+
+	@Rule
+	public TemporaryFolder temporaryFolder = new TemporaryFolder();
+
+	/**
+	 * Tests that the Flink components are started with the correct
+	 * memory settings.
+	 */
+	@Test(timeout = 60000)
+	public void testFlinkContainerMemory() throws Exception {
+		final YarnClient yarnClient = getYarnClient();
+		final Configuration configuration = new Configuration(flinkConfiguration);
+
+		final int masterMemory = 64;
+		final int taskManagerMemory = 128;
+		final int slotsPerTaskManager = 3;
+
+		// disable heap cutoff min
+		configuration.setInteger(ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN, 0);
+		configuration.setLong(TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MIN, (1L << 20));
+		configuration.setLong(TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MAX, (4L << 20));
+
+		final YarnConfiguration yarnConfiguration = getYarnConfiguration();
+		final Flip6YarnClusterDescriptor clusterDescriptor = new Flip6YarnClusterDescriptor(
+			configuration,
+			yarnConfiguration,
+			CliFrontend.getConfigurationDirectoryFromEnv(),
+			yarnClient,
+			true);
+
+		clusterDescriptor.setLocalJarPath(new Path(flinkUberjar.getAbsolutePath()));
+		clusterDescriptor.addShipFiles(Arrays.asList(flinkLibFolder.listFiles()));
+
+		final File streamingWordCountFile = new File("target/programs/WindowJoin.jar");
+
+		assertThat(streamingWordCountFile.exists(), is(true));
+
+		final PackagedProgram packagedProgram = new PackagedProgram(streamingWordCountFile);
+		final JobGraph jobGraph = PackagedProgramUtils.createJobGraph(packagedProgram, configuration, 1);
+
+		try {
+			final ClusterSpecification clusterSpecification = new ClusterSpecification.ClusterSpecificationBuilder()
+				.setMasterMemoryMB(masterMemory)
+				.setTaskManagerMemoryMB(taskManagerMemory)
+				.setSlotsPerTaskManager(slotsPerTaskManager)
+				.createClusterSpecification();
+
+			final ClusterClient<ApplicationId> clusterClient = clusterDescriptor.deployJobCluster(clusterSpecification, jobGraph, true);
+
+			final ApplicationId clusterId = clusterClient.getClusterId();
+
+			final RestClient restClient = new RestClient(RestClientConfiguration.fromConfiguration(configuration), TestingUtils.defaultExecutor());
+
+			try {
+				final ApplicationReport applicationReport = yarnClient.getApplicationReport(clusterId);
+
+				final ApplicationAttemptId currentApplicationAttemptId = applicationReport.getCurrentApplicationAttemptId();
+
+				// wait until we have second container allocated
+				List<ContainerReport> containers = yarnClient.getContainers(currentApplicationAttemptId);
+
+				while (containers.size() < 2) {
+					// this is nasty but Yarn does not offer a better way to wait
+					Thread.sleep(50L);
+					containers = yarnClient.getContainers(currentApplicationAttemptId);
+				}
+
+				for (ContainerReport container : containers) {
+					if (container.getContainerId().getId() == 1) {
+						// this should be the application master
+						assertThat(container.getAllocatedResource().getMemory(), is(masterMemory));
+					} else {
+						assertThat(container.getAllocatedResource().getMemory(), is(taskManagerMemory));
+					}
+				}
+
+				final URI webURI = new URI(clusterClient.getWebInterfaceURL());
+
+				CompletableFuture<TaskManagersInfo> taskManagersInfoCompletableFuture;
+				Collection<TaskManagerInfo> taskManagerInfos;
+
+				while (true) {
+					taskManagersInfoCompletableFuture = restClient.sendRequest(
+						webURI.getHost(),
+						webURI.getPort(),
+						TaskManagersHeaders.getInstance(),
+						EmptyMessageParameters.getInstance(),
+						EmptyRequestBody.getInstance());
+
+					final TaskManagersInfo taskManagersInfo = taskManagersInfoCompletableFuture.get();
+
+					taskManagerInfos = taskManagersInfo.getTaskManagerInfos();
+
+					if (taskManagerInfos.isEmpty()) {
+						Thread.sleep(100L);
+					} else {
+						break;
+					}
+				}
+
+				// there should be at least one TaskManagerInfo
+				final TaskManagerInfo taskManagerInfo = taskManagerInfos.iterator().next();
+
+				assertThat(taskManagerInfo.getNumberSlots(), is(slotsPerTaskManager));
+
+				final ContaineredTaskManagerParameters containeredTaskManagerParameters = ContaineredTaskManagerParameters.create(
+					configuration,
+					taskManagerMemory,
+					slotsPerTaskManager);
+
+				final long expectedHeadSize = containeredTaskManagerParameters.taskManagerHeapSizeMB() << 20L;
+
+				assertThat((double) taskManagerInfo.getHardwareDescription().getSizeOfJvmHeap() / (double) expectedHeadSize, is(closeTo(1.0, 0.1)));
+			} finally {
+				restClient.shutdown(TIMEOUT);
+				clusterClient.shutdown();
+			}
+
+			clusterDescriptor.terminateCluster(clusterId);
+
+		} finally {
+			clusterDescriptor.close();
+		}
+	}
+}
diff --git a/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YarnTestBase.java b/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YarnTestBase.java
index b74a1557bb2..3ec805e5058 100644
--- a/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YarnTestBase.java
+++ b/flink-yarn-tests/src/test/java/org/apache/flink/yarn/YarnTestBase.java
@@ -55,6 +55,8 @@ import org.slf4j.LoggerFactory;
 import org.slf4j.Marker;
 import org.slf4j.MarkerFactory;
 
+import javax.annotation.Nullable;
+
 import java.io.BufferedWriter;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
@@ -73,6 +75,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Scanner;
+import java.util.UUID;
 import java.util.concurrent.ConcurrentMap;
 import java.util.regex.Pattern;
 
@@ -140,9 +143,15 @@ public abstract class YarnTestBase extends TestLogger {
 	 */
 	protected static File tempConfPathForSecureRun = null;
 
+	private YarnClient yarnClient = null;
+
+	protected org.apache.flink.configuration.Configuration flinkConfiguration;
+
+	protected boolean flip6;
+
 	static {
 		YARN_CONFIGURATION = new YarnConfiguration();
-		YARN_CONFIGURATION.setInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 512);
+		YARN_CONFIGURATION.setInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 32);
 		YARN_CONFIGURATION.setInt(YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_MB, 4096); // 4096 is the available memory anyways
 		YARN_CONFIGURATION.setBoolean(YarnConfiguration.YARN_MINICLUSTER_FIXED_PORTS, true);
 		YARN_CONFIGURATION.setBoolean(YarnConfiguration.RM_SCHEDULER_INCLUDE_PORT_IN_NODE_NAME, true);
@@ -186,15 +195,11 @@ public abstract class YarnTestBase extends TestLogger {
 		}
 	}
 
-	private YarnClient yarnClient = null;
-	protected org.apache.flink.configuration.Configuration flinkConfiguration;
-	protected boolean flip6;
-
 	@Before
 	public void checkClusterEmpty() throws IOException, YarnException {
 		if (yarnClient == null) {
 			yarnClient = YarnClient.createYarnClient();
-			yarnClient.init(YARN_CONFIGURATION);
+			yarnClient.init(getYarnConfiguration());
 			yarnClient.start();
 		}
 
@@ -213,6 +218,7 @@ public abstract class YarnTestBase extends TestLogger {
 		flip6 = CoreOptions.FLIP6_MODE.equalsIgnoreCase(flinkConfiguration.getString(CoreOptions.MODE));
 	}
 
+	@Nullable
 	protected YarnClient getYarnClient() {
 		return yarnClient;
 	}
@@ -409,15 +415,15 @@ public abstract class YarnTestBase extends TestLogger {
 		return count;
 	}
 
-	public static void startYARNSecureMode(Configuration conf, String principal, String keytab) {
+	public static void startYARNSecureMode(YarnConfiguration conf, String principal, String keytab) {
 		start(conf, principal, keytab);
 	}
 
-	public static void startYARNWithConfig(Configuration conf) {
+	public static void startYARNWithConfig(YarnConfiguration conf) {
 		start(conf, null, null);
 	}
 
-	private static void start(Configuration conf, String principal, String keytab) {
+	private static void start(YarnConfiguration conf, String principal, String keytab) {
 		// set the home directory to a temp directory. Flink on YARN is using the home dir to distribute the file
 		File homeDir = null;
 		try {
@@ -444,7 +450,12 @@ public abstract class YarnTestBase extends TestLogger {
 		try {
 			LOG.info("Starting up MiniYARNCluster");
 			if (yarnCluster == null) {
-				yarnCluster = new MiniYARNCluster(conf.get(YarnTestBase.TEST_CLUSTER_NAME_KEY), NUM_NODEMANAGERS, 1, 1);
+				final String testName = conf.get(YarnTestBase.TEST_CLUSTER_NAME_KEY);
+				yarnCluster = new MiniYARNCluster(
+					testName == null ? "YarnTest_" + UUID.randomUUID() : testName,
+					NUM_NODEMANAGERS,
+					1,
+					1);
 
 				yarnCluster.init(conf);
 				yarnCluster.start();
diff --git a/flink-yarn/src/main/java/org/apache/flink/yarn/AbstractYarnClusterDescriptor.java b/flink-yarn/src/main/java/org/apache/flink/yarn/AbstractYarnClusterDescriptor.java
index bdb59b11b5f..bdb471a142f 100644
--- a/flink-yarn/src/main/java/org/apache/flink/yarn/AbstractYarnClusterDescriptor.java
+++ b/flink-yarn/src/main/java/org/apache/flink/yarn/AbstractYarnClusterDescriptor.java
@@ -33,6 +33,7 @@ import org.apache.flink.configuration.JobManagerOptions;
 import org.apache.flink.configuration.ResourceManagerOptions;
 import org.apache.flink.configuration.RestOptions;
 import org.apache.flink.configuration.SecurityOptions;
+import org.apache.flink.configuration.TaskManagerOptions;
 import org.apache.flink.runtime.akka.AkkaUtils;
 import org.apache.flink.runtime.clusterframework.BootstrapTools;
 import org.apache.flink.runtime.entrypoint.ClusterEntrypoint;
@@ -800,10 +801,15 @@ public abstract class AbstractYarnClusterDescriptor implements ClusterDescriptor
 			homeDir,
 			"");
 
+		// set the right configuration values for the TaskManager
 		configuration.setInteger(
-			ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS,
+			TaskManagerOptions.NUM_TASK_SLOTS,
 			clusterSpecification.getSlotsPerTaskManager());
 
+		configuration.setInteger(
+			TaskManagerOptions.TASK_MANAGER_HEAP_MEMORY,
+			clusterSpecification.getTaskManagerMemoryMB());
+
 		// Upload the flink configuration
 		// write out configuration file
 		File tmpConfigurationFile = File.createTempFile(appId + "-flink-conf.yaml", null);
diff --git a/flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java b/flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java
index f3ec04bf1e6..46ef81bed17 100644
--- a/flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java
+++ b/flink-yarn/src/main/java/org/apache/flink/yarn/YarnResourceManager.java
@@ -20,6 +20,7 @@ package org.apache.flink.yarn;
 
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.TaskManagerOptions;
 import org.apache.flink.runtime.clusterframework.ApplicationStatus;
 import org.apache.flink.runtime.clusterframework.ContaineredTaskManagerParameters;
 import org.apache.flink.runtime.clusterframework.types.ResourceID;
@@ -75,18 +76,9 @@ public class YarnResourceManager extends ResourceManager<YarnWorkerNode> impleme
 	/** YARN container map. Package private for unit test purposes. */
 	final ConcurrentMap<ResourceID, YarnWorkerNode> workerNodeMap;
 
-	/** The default registration timeout for task executor in seconds. */
-	private static final int DEFAULT_TASK_MANAGER_REGISTRATION_DURATION = 300;
-
 	/** The heartbeat interval while the resource master is waiting for containers. */
 	private static final int FAST_YARN_HEARTBEAT_INTERVAL_MS = 500;
 
-	/** The default heartbeat interval during regular operation. */
-	private static final int DEFAULT_YARN_HEARTBEAT_INTERVAL_MS = 5000;
-
-	/** The default memory of task executor to allocate (in MB). */
-	private static final int DEFAULT_TSK_EXECUTOR_MEMORY_SIZE = 1024;
-
 	/** Environment variable name of the final container id used by the YarnResourceManager.
 	 * Container ID generation may vary across Hadoop versions. */
 	static final String ENV_FLINK_CONTAINER_ID = "_FLINK_CONTAINER_ID";
@@ -105,6 +97,12 @@ public class YarnResourceManager extends ResourceManager<YarnWorkerNode> impleme
 	@Nullable
 	private final String webInterfaceUrl;
 
+	private final int defaultTaskManagerMemoryMB;
+
+	private final int defaultNumSlots;
+
+	private final int defaultCpus;
+
 	/** Client to communicate with the Resource Manager (YARN's master). */
 	private AMRMClientAsync<AMRMClient.ContainerRequest> resourceManagerClient;
 
@@ -163,6 +161,9 @@ public class YarnResourceManager extends ResourceManager<YarnWorkerNode> impleme
 		numPendingContainerRequests = 0;
 
 		this.webInterfaceUrl = webInterfaceUrl;
+		this.defaultTaskManagerMemoryMB = flinkConfig.getInteger(TaskManagerOptions.TASK_MANAGER_HEAP_MEMORY);
+		this.defaultNumSlots = flinkConfig.getInteger(TaskManagerOptions.NUM_TASK_SLOTS);
+		this.defaultCpus = flinkConfig.getInteger(YarnConfigOptions.VCORES, defaultNumSlots);
 	}
 
 	protected AMRMClientAsync<AMRMClient.ContainerRequest> createAndStartResourceManagerClient(
@@ -285,8 +286,8 @@ public class YarnResourceManager extends ResourceManager<YarnWorkerNode> impleme
 		// Priority for worker containers - priorities are intra-application
 		//TODO: set priority according to the resource allocated
 		Priority priority = Priority.newInstance(generatePriority(resourceProfile));
-		int mem = resourceProfile.getMemoryInMB() < 0 ? DEFAULT_TSK_EXECUTOR_MEMORY_SIZE : (int) resourceProfile.getMemoryInMB();
-		int vcore = resourceProfile.getCpuCores() < 1 ? 1 : (int) resourceProfile.getCpuCores();
+		int mem = resourceProfile.getMemoryInMB() < 0 ? defaultTaskManagerMemoryMB : (int) resourceProfile.getMemoryInMB();
+		int vcore = resourceProfile.getCpuCores() < 1 ? defaultCpus : (int) resourceProfile.getCpuCores();
 		Resource capability = Resource.newInstance(mem, vcore);
 		requestYarnContainer(capability, priority);
 	}
@@ -445,8 +446,10 @@ public class YarnResourceManager extends ResourceManager<YarnWorkerNode> impleme
 		// init the ContainerLaunchContext
 		final String currDir = env.get(ApplicationConstants.Environment.PWD.key());
 
+		final int numSlots = flinkConfig.getInteger(TaskManagerOptions.NUM_TASK_SLOTS);
+
 		final ContaineredTaskManagerParameters taskManagerParameters =
-				ContaineredTaskManagerParameters.create(flinkConfig, resource.getMemory(), 1);
+				ContaineredTaskManagerParameters.create(flinkConfig, resource.getMemory(), numSlots);
 
 		log.info("TaskExecutor {} will be started with container size {} MB, JVM heap size {} MB, " +
 				"JVM direct memory limit {} MB",
diff --git a/flink-yarn/src/test/java/org/apache/flink/yarn/FlinkYarnSessionCliTest.java b/flink-yarn/src/test/java/org/apache/flink/yarn/FlinkYarnSessionCliTest.java
index 0a02474243a..20ce314399f 100644
--- a/flink-yarn/src/test/java/org/apache/flink/yarn/FlinkYarnSessionCliTest.java
+++ b/flink-yarn/src/test/java/org/apache/flink/yarn/FlinkYarnSessionCliTest.java
@@ -21,6 +21,8 @@ package org.apache.flink.yarn;
 import org.apache.flink.client.deployment.ClusterSpecification;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.HighAvailabilityOptions;
+import org.apache.flink.configuration.JobManagerOptions;
+import org.apache.flink.configuration.TaskManagerOptions;
 import org.apache.flink.util.FlinkException;
 import org.apache.flink.util.TestLogger;
 import org.apache.flink.yarn.cli.FlinkYarnSessionCli;
@@ -42,7 +44,9 @@ import java.nio.file.Files;
 import java.nio.file.StandardOpenOption;
 import java.util.Map;
 
+import static org.hamcrest.Matchers.is;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertThat;
 import static org.junit.Assert.assertTrue;
 
 /**
@@ -249,6 +253,66 @@ public class FlinkYarnSessionCliTest extends TestLogger {
 		assertEquals(TEST_YARN_APPLICATION_ID_2, clusterId);
 	}
 
+	/**
+	 * Tests that the command line arguments override the configuration settings
+	 * when the {@link ClusterSpecification} is created.
+	 */
+	@Test
+	public void testCommandLineClusterSpecification() throws Exception {
+		final Configuration configuration = new Configuration();
+		configuration.setInteger(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY, 1337);
+		configuration.setInteger(TaskManagerOptions.TASK_MANAGER_HEAP_MEMORY, 7331);
+		configuration.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 2);
+
+		final int jobManagerMemory = 42;
+		final int taskManagerMemory = 41;
+		final int slotsPerTaskManager = 30;
+		final String[] args = {"-yjm", String.valueOf(jobManagerMemory), "-ytm", String.valueOf(taskManagerMemory), "-ys", String.valueOf(slotsPerTaskManager)};
+		final FlinkYarnSessionCli flinkYarnSessionCli = new FlinkYarnSessionCli(
+			configuration,
+			tmp.getRoot().getAbsolutePath(),
+			"y",
+			"yarn");
+
+		CommandLine commandLine = flinkYarnSessionCli.parseCommandLineOptions(args, false);
+
+		final ClusterSpecification clusterSpecification = flinkYarnSessionCli.getClusterSpecification(commandLine);
+
+		assertThat(clusterSpecification.getMasterMemoryMB(), is(jobManagerMemory));
+		assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(taskManagerMemory));
+		assertThat(clusterSpecification.getSlotsPerTaskManager(), is(slotsPerTaskManager));
+	}
+
+	/**
+	 * Tests that the configuration settings are used to create the
+	 * {@link ClusterSpecification}.
+	 */
+	@Test
+	public void testConfigurationClusterSpecification() throws Exception {
+		final Configuration configuration = new Configuration();
+		final int jobManagerMemory = 1337;
+		configuration.setInteger(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY, jobManagerMemory);
+		final int taskManagerMemory = 7331;
+		configuration.setInteger(TaskManagerOptions.TASK_MANAGER_HEAP_MEMORY, taskManagerMemory);
+		final int slotsPerTaskManager = 42;
+		configuration.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, slotsPerTaskManager);
+
+		final String[] args = {};
+		final FlinkYarnSessionCli flinkYarnSessionCli = new FlinkYarnSessionCli(
+			configuration,
+			tmp.getRoot().getAbsolutePath(),
+			"y",
+			"yarn");
+
+		CommandLine commandLine = flinkYarnSessionCli.parseCommandLineOptions(args, false);
+
+		final ClusterSpecification clusterSpecification = flinkYarnSessionCli.getClusterSpecification(commandLine);
+
+		assertThat(clusterSpecification.getMasterMemoryMB(), is(jobManagerMemory));
+		assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(taskManagerMemory));
+		assertThat(clusterSpecification.getSlotsPerTaskManager(), is(slotsPerTaskManager));
+	}
+
 	///////////
 	// Utils //
 	///////////
