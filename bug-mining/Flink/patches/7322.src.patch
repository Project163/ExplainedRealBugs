diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/PartitionFileReader.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/PartitionFileReader.java
index 25920194597..c8d1d488f4a 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/PartitionFileReader.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/PartitionFileReader.java
@@ -50,6 +50,7 @@ public interface PartitionFileReader {
      *     the last read has a partial buffer, it will construct a full buffer during the read
      *     process.
      * @return null if there is no data otherwise return a read buffer result.
+     * @throws IOException if an error happens.
      */
     @Nullable
     ReadBufferResult readBuffer(
@@ -84,13 +85,15 @@ public interface PartitionFileReader {
      *     Flink, and it should be directly tied to the file format. The field can be null if the
      *     current file reader has no the read progress
      * @return the priority of the {@link PartitionFileReader}.
+     * @throws IOException if an error happens.
      */
     long getPriority(
             TieredStoragePartitionId partitionId,
             TieredStorageSubpartitionId subpartitionId,
             int segmentId,
             int bufferIndex,
-            @Nullable ReadProgress readProgress);
+            @Nullable ReadProgress readProgress)
+            throws IOException;
 
     /** Release the {@link PartitionFileReader}. */
     void release();
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/ProducerMergedPartitionFileReader.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/ProducerMergedPartitionFileReader.java
index 702a67213cc..ef57d7b604b 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/ProducerMergedPartitionFileReader.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/ProducerMergedPartitionFileReader.java
@@ -134,7 +134,8 @@ public class ProducerMergedPartitionFileReader implements PartitionFileReader {
             TieredStorageSubpartitionId subpartitionId,
             int segmentId,
             int bufferIndex,
-            @Nullable ReadProgress readProgress) {
+            @Nullable ReadProgress readProgress)
+            throws IOException {
         lazyInitializeFileChannel();
 
         ProducerMergedReadProgress progress = convertToCurrentReadProgress(readProgress);
@@ -164,13 +165,9 @@ public class ProducerMergedPartitionFileReader implements PartitionFileReader {
      * Initialize the file channel in a lazy manner, which can reduce usage of the file descriptor
      * resource.
      */
-    private void lazyInitializeFileChannel() {
+    private void lazyInitializeFileChannel() throws IOException {
         if (fileChannel == null) {
-            try {
-                fileChannel = FileChannel.open(dataFilePath, StandardOpenOption.READ);
-            } catch (IOException e) {
-                ExceptionUtils.rethrow(e, "Failed to open file channel.");
-            }
+            fileChannel = FileChannel.open(dataFilePath, StandardOpenOption.READ);
         }
     }
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/SegmentPartitionFileReader.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/SegmentPartitionFileReader.java
index 8c07c505949..82a21a61c7f 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/SegmentPartitionFileReader.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/SegmentPartitionFileReader.java
@@ -141,7 +141,8 @@ public class SegmentPartitionFileReader implements PartitionFileReader {
             TieredStorageSubpartitionId subpartitionId,
             int segmentId,
             int bufferIndex,
-            @Nullable ReadProgress readProgress) {
+            @Nullable ReadProgress readProgress)
+            throws IOException {
         // noop
         return -1;
     }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java
index addb53e3955..d7baf588d4d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/disk/DiskIOScheduler.java
@@ -206,9 +206,9 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
         Queue<MemorySegment> buffers;
         try {
             buffers = allocateBuffers();
-        } catch (Exception exception) {
-            failScheduledReaders(scheduledReaders, exception);
-            LOG.error("Failed to request buffers for data reading.", exception);
+        } catch (Exception e) {
+            notifyDownstreamSubpartitionFailed(
+                    scheduledReaders, e, "Failed to request buffers for data reading.");
             return 0;
         }
 
@@ -223,9 +223,11 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
             }
             try {
                 scheduledReader.loadDiskDataToBuffers(buffers, this);
-            } catch (Exception throwable) {
-                failScheduledReaders(Collections.singletonList(scheduledReader), throwable);
-                LOG.debug("Failed to read shuffle data.", throwable);
+            } catch (IOException e) {
+                notifyDownstreamSubpartitionFailed(
+                        Collections.singletonList(scheduledReader),
+                        e,
+                        "Failed to read shuffle data.");
             }
         }
         int numBuffersRead = numBuffersAllocated - buffers.size();
@@ -242,7 +244,12 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
             scheduledReaders = new ArrayList<>(allScheduledReaders.values());
         }
         for (ScheduledSubpartitionReader reader : scheduledReaders) {
-            reader.prepareForScheduling();
+            try {
+                reader.prepareForScheduling();
+            } catch (IOException e) {
+                notifyDownstreamSubpartitionFailed(
+                        Collections.singletonList(reader), e, "Failed to prepare for scheduling.");
+            }
         }
         Collections.sort(scheduledReaders);
         return scheduledReaders;
@@ -269,26 +276,32 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
                         TaskManagerOptions.NETWORK_BATCH_SHUFFLE_READ_MEMORY.key()));
     }
 
-    private void failScheduledReaders(
-            List<ScheduledSubpartitionReader> scheduledReaders, Throwable failureCause) {
+    /**
+     * Send an error response to the downstream to notify the specific subpartition has been failed.
+     * The {@link ScheduledSubpartitionReader} responsible for the failed subpartition will also be
+     * removed from the {@link DiskIOScheduler}.
+     *
+     * @param scheduledReaders the readers of the failed subpartitions.
+     * @param failureCause the failure cause in the error response.
+     * @param errorLog the log printed in the {@link DiskIOScheduler}.
+     */
+    private void notifyDownstreamSubpartitionFailed(
+            List<ScheduledSubpartitionReader> scheduledReaders,
+            Throwable failureCause,
+            String errorLog) {
         for (ScheduledSubpartitionReader scheduledReader : scheduledReaders) {
             synchronized (lock) {
                 allScheduledReaders.remove(scheduledReader.getId());
             }
             scheduledReader.failReader(failureCause);
         }
+        LOG.error(errorLog);
     }
 
     private void releaseBuffers(Queue<MemorySegment> buffers) {
         if (!buffers.isEmpty()) {
-            try {
-                bufferPool.recycle(buffers);
-                buffers.clear();
-            } catch (Throwable throwable) {
-                // this should never happen so just trigger fatal error
-                FatalExitExceptionHandler.INSTANCE.uncaughtException(
-                        Thread.currentThread(), throwable);
-            }
+            bufferPool.recycle(buffers);
+            buffers.clear();
         }
     }
 
@@ -305,12 +318,12 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
                             () -> {
                                 try {
                                     run();
-                                } catch (Throwable throwable) {
-                                    LOG.error("Failed to read data.", throwable);
+                                } catch (Throwable t) {
+                                    LOG.error("Failed to read data.", t);
                                     // handle un-expected exception as unhandledExceptionHandler is
                                     // not worked for ScheduledExecutorService.
                                     FatalExitExceptionHandler.INSTANCE.uncaughtException(
-                                            Thread.currentThread(), throwable);
+                                            Thread.currentThread(), t);
                                 }
                             });
                 } catch (RejectedExecutionException e) {
@@ -388,9 +401,9 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
                             buffers.add(memorySegment);
                             break;
                         }
-                    } catch (Throwable throwable) {
+                    } catch (IOException exception) {
                         buffers.add(memorySegment);
-                        throw throwable;
+                        throw exception;
                     }
 
                     List<Buffer> readBuffers = readBufferResult.getReadBuffers();
@@ -416,7 +429,7 @@ public class DiskIOScheduler implements Runnable, BufferRecycler, NettyServicePr
             return Long.compare(getPriority(), reader.getPriority());
         }
 
-        private void prepareForScheduling() {
+        private void prepareForScheduling() throws IOException {
             if (nextSegmentId < 0) {
                 updateSegmentId();
             }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/TestingPartitionFileReader.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/TestingPartitionFileReader.java
index c88b68ac486..f0c04f86594 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/TestingPartitionFileReader.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/file/TestingPartitionFileReader.java
@@ -68,7 +68,8 @@ public class TestingPartitionFileReader implements PartitionFileReader {
             TieredStorageSubpartitionId subpartitionId,
             int segmentId,
             int bufferIndex,
-            @Nullable ReadProgress readProgress) {
+            @Nullable ReadProgress readProgress)
+            throws IOException {
         return getPriorityFunction.apply(subpartitionId.getSubpartitionId());
     }
 
