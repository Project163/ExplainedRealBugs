diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java
index 72b782b9a66..755b6b8d536 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/SchedulerBase.java
@@ -402,6 +402,8 @@ public abstract class SchedulerBase implements SchedulerNG, CheckpointScheduling
     protected void restoreState(
             final Set<ExecutionVertexID> vertices, final boolean isGlobalRecovery)
             throws Exception {
+        vertexEndOfDataListener.restoreVertices(vertices);
+
         final CheckpointCoordinator checkpointCoordinator =
                 executionGraph.getCheckpointCoordinator();
 
@@ -1107,4 +1109,9 @@ public abstract class SchedulerBase implements SchedulerNG, CheckpointScheduling
     JobID getJobId() {
         return jobGraph.getJobID();
     }
+
+    @VisibleForTesting
+    VertexEndOfDataListener getVertexEndOfDataListener() {
+        return vertexEndOfDataListener;
+    }
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/VertexEndOfDataListener.java b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/VertexEndOfDataListener.java
index 1cdd64c756a..167a027185d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/VertexEndOfDataListener.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/VertexEndOfDataListener.java
@@ -23,11 +23,13 @@ import org.apache.flink.runtime.executiongraph.ExecutionGraph;
 import org.apache.flink.runtime.executiongraph.ExecutionJobVertex;
 import org.apache.flink.runtime.jobgraph.JobGraph;
 import org.apache.flink.runtime.jobgraph.JobVertexID;
+import org.apache.flink.runtime.scheduler.strategy.ExecutionVertexID;
 
 import java.util.BitSet;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
+import java.util.Set;
 
 /**
  * Records the end of data event of each task, and allows for checking whether all tasks of a {@link
@@ -73,4 +75,12 @@ public class VertexEndOfDataListener {
         }
         return true;
     }
+
+    public void restoreVertices(Set<ExecutionVertexID> executionVertices) {
+        for (ExecutionVertexID executionVertex : executionVertices) {
+            JobVertexID jobVertexId = executionVertex.getJobVertexId();
+            tasksReachedEndOfData.putIfAbsent(jobVertexId, new BitSet());
+            tasksReachedEndOfData.get(jobVertexId).set(executionVertex.getSubtaskIndex(), false);
+        }
+    }
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/DefaultSchedulerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/DefaultSchedulerTest.java
index 01dd7977909..d15d0e0736a 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/DefaultSchedulerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/DefaultSchedulerTest.java
@@ -641,6 +641,28 @@ public class DefaultSchedulerTest extends TestLogger {
         assertThat(deployedExecutionVertices).contains(executionVertexId, executionVertexId);
     }
 
+    @Test
+    void testRestoreVertexEndOfDataListener() throws Exception {
+        final JobGraph jobGraph = singleNonParallelJobVertexJobGraph();
+        enableCheckpointing(jobGraph, null, null, Long.MAX_VALUE - 1, true);
+
+        final DefaultScheduler scheduler = createSchedulerAndStartScheduling(jobGraph);
+        final ArchivedExecutionVertex onlyExecutionVertex =
+                Iterables.getOnlyElement(
+                        scheduler
+                                .requestJob()
+                                .getArchivedExecutionGraph()
+                                .getAllExecutionVertices());
+        final ExecutionAttemptID attemptId =
+                onlyExecutionVertex.getCurrentExecutionAttempt().getAttemptId();
+
+        scheduler.notifyEndOfData(attemptId);
+        assertThat(scheduler.getVertexEndOfDataListener().areAllTasksEndOfData()).isTrue();
+
+        scheduler.restoreState(Collections.singleton(attemptId.getExecutionVertexId()), true);
+        assertThat(scheduler.getVertexEndOfDataListener().areAllTasksEndOfData()).isFalse();
+    }
+
     /**
      * This test covers the use-case where a global fail-over is followed by a local task failure.
      * It verifies (besides checking the expected deployments) that the assert in the global
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/SchedulerTestingUtils.java b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/SchedulerTestingUtils.java
index 64913ce2e1f..7cdc35b0912 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/SchedulerTestingUtils.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/SchedulerTestingUtils.java
@@ -108,18 +108,35 @@ public class SchedulerTestingUtils {
             final JobGraph jobGraph,
             @Nullable StateBackend stateBackend,
             @Nullable CheckpointStorage checkpointStorage) {
+        enableCheckpointing(
+                jobGraph,
+                stateBackend,
+                checkpointStorage,
+                Long.MAX_VALUE, // disable periodical checkpointing
+                false);
+    }
+
+    public static void enableCheckpointing(
+            final JobGraph jobGraph,
+            @Nullable StateBackend stateBackend,
+            @Nullable CheckpointStorage checkpointStorage,
+            long checkpointInterval,
+            boolean enableCheckpointsAfterTasksFinish) {
 
         final CheckpointCoordinatorConfiguration config =
-                new CheckpointCoordinatorConfiguration(
-                        Long.MAX_VALUE, // disable periodical checkpointing
-                        DEFAULT_CHECKPOINT_TIMEOUT_MS,
-                        0,
-                        1,
-                        CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION,
-                        false,
-                        false,
-                        0,
-                        0);
+                new CheckpointCoordinatorConfiguration.CheckpointCoordinatorConfigurationBuilder()
+                        .setCheckpointInterval(checkpointInterval)
+                        .setCheckpointTimeout(DEFAULT_CHECKPOINT_TIMEOUT_MS)
+                        .setMinPauseBetweenCheckpoints(0)
+                        .setMaxConcurrentCheckpoints(1)
+                        .setCheckpointRetentionPolicy(
+                                CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION)
+                        .setExactlyOnce(false)
+                        .setUnalignedCheckpointsEnabled(false)
+                        .setTolerableCheckpointFailureNumber(0)
+                        .setCheckpointIdOfIgnoredInFlightData(0)
+                        .setEnableCheckpointsAfterTasksFinish(enableCheckpointsAfterTasksFinish)
+                        .build();
 
         SerializedValue<StateBackend> serializedStateBackend = null;
         if (stateBackend != null) {
diff --git a/flink-tests/src/test/java/org/apache/flink/test/checkpointing/CheckpointAfterAllTasksFinishedITCase.java b/flink-tests/src/test/java/org/apache/flink/test/checkpointing/CheckpointAfterAllTasksFinishedITCase.java
index 442fe87ca15..276199e7149 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/checkpointing/CheckpointAfterAllTasksFinishedITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/checkpointing/CheckpointAfterAllTasksFinishedITCase.java
@@ -71,15 +71,15 @@ public class CheckpointAfterAllTasksFinishedITCase extends AbstractTestBase {
     public void setUp() {
         env = StreamExecutionEnvironment.getExecutionEnvironment();
         env.setParallelism(4);
-        env.setRestartStrategy(RestartStrategies.noRestart());
         smallResult = sharedObjects.add(new CopyOnWriteArrayList<>());
         bigResult = sharedObjects.add(new CopyOnWriteArrayList<>());
     }
 
     @Test
     public void testImmediateCheckpointing() throws Exception {
+        env.setRestartStrategy(RestartStrategies.noRestart());
         env.enableCheckpointing(Long.MAX_VALUE - 1);
-        StreamGraph streamGraph = getStreamGraph(env, false);
+        StreamGraph streamGraph = getStreamGraph(env, false, false);
         env.execute(streamGraph);
         assertThat(smallResult.get().size()).isEqualTo(SMALL_SOURCE_NUM_RECORDS);
         assertThat(bigResult.get().size()).isEqualTo(BIG_SOURCE_NUM_RECORDS);
@@ -96,9 +96,10 @@ public class CheckpointAfterAllTasksFinishedITCase extends AbstractTestBase {
         try (MiniCluster miniCluster = new MiniCluster(cfg)) {
             miniCluster.start();
 
+            env.setRestartStrategy(RestartStrategies.noRestart());
             env.enableCheckpointing(100);
             IntegerStreamSource.latch = new CountDownLatch(1);
-            JobGraph jobGraph = getStreamGraph(env, true).getJobGraph();
+            JobGraph jobGraph = getStreamGraph(env, true, false).getJobGraph();
             miniCluster.submitJob(jobGraph).get();
 
             CommonTestUtils.waitForSubtasksToFinish(
@@ -118,7 +119,7 @@ public class CheckpointAfterAllTasksFinishedITCase extends AbstractTestBase {
             bigResult.get().clear();
 
             env.enableCheckpointing(Long.MAX_VALUE - 1);
-            JobGraph restoredJobGraph = getStreamGraph(env, true).getJobGraph();
+            JobGraph restoredJobGraph = getStreamGraph(env, true, false).getJobGraph();
             restoredJobGraph.setSavepointRestoreSettings(
                     SavepointRestoreSettings.forPath(savepointPath, false));
             miniCluster.submitJob(restoredJobGraph).get();
@@ -128,16 +129,52 @@ public class CheckpointAfterAllTasksFinishedITCase extends AbstractTestBase {
             miniCluster.requestJobResult(restoredJobGraph.getJobID()).get();
             assertThat(smallResult.get().size()).isEqualTo(SMALL_SOURCE_NUM_RECORDS);
             assertThat(bigResult.get().size()).isEqualTo(BIG_SOURCE_NUM_RECORDS);
+        } finally {
+            IntegerStreamSource.latch = null;
         }
     }
 
-    private StreamGraph getStreamGraph(StreamExecutionEnvironment env, boolean block) {
-        env.addSource(new IntegerStreamSource(SMALL_SOURCE_NUM_RECORDS, false))
+    @Test
+    public void testFailoverAfterSomeTasksFinished() throws Exception {
+        final MiniClusterConfiguration cfg =
+                new MiniClusterConfiguration.Builder()
+                        .withRandomPorts()
+                        .setNumTaskManagers(1)
+                        .setNumSlotsPerTaskManager(4)
+                        .build();
+        try (MiniCluster miniCluster = new MiniCluster(cfg)) {
+            miniCluster.start();
+
+            env.enableCheckpointing(100);
+            IntegerStreamSource.latch = new CountDownLatch(1);
+            JobGraph jobGraph = getStreamGraph(env, true, true).getJobGraph();
+            miniCluster.submitJob(jobGraph).get();
+
+            CommonTestUtils.waitForSubtasksToFinish(
+                    miniCluster,
+                    jobGraph.getJobID(),
+                    findVertexByName(jobGraph, "passA -> Sink: sinkA").getID(),
+                    false);
+            bigResult.get().clear();
+            IntegerStreamSource.latch.countDown();
+
+            miniCluster.requestJobResult(jobGraph.getJobID()).get();
+            assertThat(smallResult.get().size()).isEqualTo(SMALL_SOURCE_NUM_RECORDS);
+            assertThat(bigResult.get().size()).isEqualTo(BIG_SOURCE_NUM_RECORDS);
+        } finally {
+            IntegerStreamSource.latch = null;
+        }
+    }
+
+    private StreamGraph getStreamGraph(
+            StreamExecutionEnvironment env, boolean block, boolean needFailover) {
+
+        env.addSource(new IntegerStreamSource(SMALL_SOURCE_NUM_RECORDS, false, false))
                 .transform("passA", Types.INT, new PassThroughOperator())
                 .addSink(new CollectSink(smallResult))
                 .name("sinkA");
 
-        env.addSource(new IntegerStreamSource(BIG_SOURCE_NUM_RECORDS, block))
+        env.addSource(new IntegerStreamSource(BIG_SOURCE_NUM_RECORDS, block, needFailover))
                 .transform("passB", Types.INT, new PassThroughOperator())
                 .addSink(new CollectSink(bigResult))
                 .name("sinkB");
@@ -157,16 +194,19 @@ public class CheckpointAfterAllTasksFinishedITCase extends AbstractTestBase {
 
         private static final long serialVersionUID = 1L;
         private static CountDownLatch latch;
+        private static boolean failedBefore;
 
         private final int numRecords;
         private boolean block;
         private volatile boolean running;
         private int emittedCount;
+        private boolean needFailover;
 
-        public IntegerStreamSource(int numRecords, boolean block) {
+        public IntegerStreamSource(int numRecords, boolean block, boolean needFailover) {
             this.numRecords = numRecords;
             this.running = true;
             this.block = block;
+            this.needFailover = needFailover;
             this.emittedCount = 0;
         }
 
@@ -181,6 +221,10 @@ public class CheckpointAfterAllTasksFinishedITCase extends AbstractTestBase {
             if (block && latch != null) {
                 latch.await();
             }
+            if (needFailover && !failedBefore) {
+                failedBefore = true;
+                throw new RuntimeException("forced failure");
+            }
         }
 
         @Override
